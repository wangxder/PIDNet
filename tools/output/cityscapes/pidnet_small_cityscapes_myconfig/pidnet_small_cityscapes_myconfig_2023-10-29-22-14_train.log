2023-10-29 22:14:22,378 Namespace(cfg='/media/zfy/新加卷/WJJ/py_project/PIDNet/configs/cityscapes/pidnet_small_cityscapes_myconfig.yaml', opts=[], seed=304)
2023-10-29 22:14:22,378 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: cityscapes
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 19
  ROOT: /media/zfy/新加卷/WJJ/RegSeg/datasets/
  TEST_SET: cityscapes/val.lst
  TRAIN_SET: cityscapes/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: owner
  NUM_OUTPUTS: 2
  PRETRAINED: /media/zfy/新加卷/WJJ/py_project/PIDNet/pretrained_models/cityscapes/PIDNet_S_Cityscapes_val.pt
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 1
  FLIP_TEST: False
  IMAGE_SIZE: [2048, 1024]
  MODEL_FILE: /media/zfy/新加卷/WJJ/py_project/PIDNet/pretrained_models/cityscapes/PIDNet_S_Cityscapes_val.pt
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 484
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 255
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2023-10-29 22:14:55,299 Namespace(cfg='/media/zfy/新加卷/WJJ/py_project/PIDNet/configs/cityscapes/pidnet_small_cityscapes_myconfig.yaml', opts=[], seed=304)
2023-10-29 22:14:55,299 AUTO_RESUME: False
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: cityscapes
  EXTRA_TRAIN_SET: 
  NUM_CLASSES: 19
  ROOT: /media/zfy/新加卷/WJJ/RegSeg/datasets/
  TEST_SET: cityscapes/val.lst
  TRAIN_SET: cityscapes/train.lst
GPUS: (0,)
LOG_DIR: log
LOSS:
  BALANCE_WEIGHTS: [0.4, 1.0]
  CLASS_BALANCE: False
  OHEMKEEP: 131072
  OHEMTHRES: 0.9
  SB_WEIGHTS: 1.0
  USE_OHEM: True
MODEL:
  ALIGN_CORNERS: True
  NAME: owner
  NUM_OUTPUTS: 2
  PRETRAINED: /media/zfy/新加卷/WJJ/py_project/PIDNet/pretrained_models/cityscapes/PIDNet_S_Cityscapes_val.pt
OUTPUT_DIR: output
PIN_MEMORY: True
PRINT_FREQ: 10
TEST:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 1
  FLIP_TEST: False
  IMAGE_SIZE: [2048, 1024]
  MODEL_FILE: /media/zfy/新加卷/WJJ/py_project/PIDNet/pretrained_models/cityscapes/PIDNet_S_Cityscapes_val.pt
  MULTI_SCALE: False
  OUTPUT_INDEX: 1
TRAIN:
  BASE_SIZE: 2048
  BATCH_SIZE_PER_GPU: 6
  BEGIN_EPOCH: 0
  END_EPOCH: 484
  EXTRA_EPOCH: 0
  EXTRA_LR: 0.001
  FLIP: True
  IGNORE_LABEL: 255
  IMAGE_SIZE: [1024, 1024]
  LR: 0.01
  MOMENTUM: 0.9
  MULTI_SCALE: True
  NESTEROV: False
  OPTIMIZER: sgd
  RESUME: False
  SCALE_FACTOR: 16
  SHUFFLE: True
  WD: 0.0005
WORKERS: 6
2023-10-29 22:14:55,411 Attention!!!
2023-10-29 22:14:55,412 Loaded 479 parameters!
2023-10-29 22:14:55,412 Over!!!
2023-10-29 22:15:04,452 Epoch: [0/484] Iter:[0/495], Time: 8.03, lr: [0.01], Loss: 2.051436, Acc:0.682926, Semantic loss: 0.580896, BCE loss: 0.888621, SB loss: 0.581920
2023-10-29 22:15:07,981 Epoch: [0/484] Iter:[10/495], Time: 1.05, lr: [0.009999624341815547], Loss: 2.252780, Acc:0.783350, Semantic loss: 0.753252, BCE loss: 0.800033, SB loss: 0.699495
2023-10-29 22:15:12,894 Epoch: [0/484] Iter:[20/495], Time: 0.78, lr: [0.009999248682063035], Loss: 2.680905, Acc:0.750299, Semantic loss: 0.945186, BCE loss: 0.860526, SB loss: 0.875193
2023-10-29 22:15:18,760 Epoch: [0/484] Iter:[30/495], Time: 0.72, lr: [0.0099988730207424], Loss: 2.962712, Acc:0.739303, Semantic loss: 1.089191, BCE loss: 0.923648, SB loss: 0.949874
2023-10-29 22:15:25,363 Epoch: [0/484] Iter:[40/495], Time: 0.71, lr: [0.009998497357853565], Loss: 3.033091, Acc:0.723480, Semantic loss: 1.129038, BCE loss: 0.900291, SB loss: 1.003762
2023-10-29 22:15:31,557 Epoch: [0/484] Iter:[50/495], Time: 0.69, lr: [0.009998121693396457], Loss: 3.138759, Acc:0.707535, Semantic loss: 1.196981, BCE loss: 0.876491, SB loss: 1.065287
2023-10-29 22:15:36,759 Epoch: [0/484] Iter:[60/495], Time: 0.66, lr: [0.009997746027371007], Loss: 3.207544, Acc:0.701667, Semantic loss: 1.245706, BCE loss: 0.870266, SB loss: 1.091572
2023-10-29 22:15:44,181 Epoch: [0/484] Iter:[70/495], Time: 0.67, lr: [0.009997370359777142], Loss: 3.228366, Acc:0.693947, Semantic loss: 1.249273, BCE loss: 0.874652, SB loss: 1.104441
2023-10-29 22:15:50,370 Epoch: [0/484] Iter:[80/495], Time: 0.67, lr: [0.00999699469061479], Loss: 3.254664, Acc:0.690339, Semantic loss: 1.253238, BCE loss: 0.878505, SB loss: 1.122922
2023-10-29 22:15:55,704 Epoch: [0/484] Iter:[90/495], Time: 0.65, lr: [0.009996619019883878], Loss: 3.218800, Acc:0.694669, Semantic loss: 1.231587, BCE loss: 0.866410, SB loss: 1.120803
2023-10-29 22:16:01,891 Epoch: [0/484] Iter:[100/495], Time: 0.65, lr: [0.009996243347584335], Loss: 3.207680, Acc:0.694985, Semantic loss: 1.221788, BCE loss: 0.854639, SB loss: 1.131253
2023-10-29 22:16:09,607 Epoch: [0/484] Iter:[110/495], Time: 0.66, lr: [0.009995867673716087], Loss: 3.223752, Acc:0.698786, Semantic loss: 1.231070, BCE loss: 0.852154, SB loss: 1.140527
2023-10-29 22:16:15,717 Epoch: [0/484] Iter:[120/495], Time: 0.66, lr: [0.009995491998279066], Loss: 3.213360, Acc:0.699878, Semantic loss: 1.225389, BCE loss: 0.851096, SB loss: 1.136875
2023-10-29 22:16:22,964 Epoch: [0/484] Iter:[130/495], Time: 0.66, lr: [0.009995116321273197], Loss: 3.165006, Acc:0.700875, Semantic loss: 1.198973, BCE loss: 0.844765, SB loss: 1.121268
2023-10-29 22:16:29,189 Epoch: [0/484] Iter:[140/495], Time: 0.66, lr: [0.009994740642698407], Loss: 3.143409, Acc:0.706793, Semantic loss: 1.182213, BCE loss: 0.842540, SB loss: 1.118656
2023-10-29 22:16:34,639 Epoch: [0/484] Iter:[150/495], Time: 0.65, lr: [0.009994364962554627], Loss: 3.124279, Acc:0.710428, Semantic loss: 1.172520, BCE loss: 0.837109, SB loss: 1.114650
2023-10-29 22:16:40,376 Epoch: [0/484] Iter:[160/495], Time: 0.65, lr: [0.009993989280841782], Loss: 3.097817, Acc:0.709835, Semantic loss: 1.160939, BCE loss: 0.829809, SB loss: 1.107069
2023-10-29 22:16:47,008 Epoch: [0/484] Iter:[170/495], Time: 0.65, lr: [0.009993613597559802], Loss: 3.068077, Acc:0.710985, Semantic loss: 1.150132, BCE loss: 0.821460, SB loss: 1.096486
2023-10-29 22:16:52,320 Epoch: [0/484] Iter:[180/495], Time: 0.64, lr: [0.009993237912708614], Loss: 3.052189, Acc:0.711959, Semantic loss: 1.143034, BCE loss: 0.816372, SB loss: 1.092783
2023-10-29 22:16:58,643 Epoch: [0/484] Iter:[190/495], Time: 0.64, lr: [0.009992862226288144], Loss: 3.035045, Acc:0.710263, Semantic loss: 1.135157, BCE loss: 0.812787, SB loss: 1.087100
2023-10-29 22:17:06,211 Epoch: [0/484] Iter:[200/495], Time: 0.65, lr: [0.009992486538298326], Loss: 3.030017, Acc:0.712044, Semantic loss: 1.132143, BCE loss: 0.812499, SB loss: 1.085375
2023-10-29 22:17:10,936 Epoch: [0/484] Iter:[210/495], Time: 0.64, lr: [0.009992110848739081], Loss: 3.022864, Acc:0.712665, Semantic loss: 1.132422, BCE loss: 0.809745, SB loss: 1.080697
2023-10-29 22:17:17,594 Epoch: [0/484] Iter:[220/495], Time: 0.64, lr: [0.00999173515761034], Loss: 3.022081, Acc:0.712248, Semantic loss: 1.132642, BCE loss: 0.807010, SB loss: 1.082429
2023-10-29 22:17:23,678 Epoch: [0/484] Iter:[230/495], Time: 0.64, lr: [0.00999135946491203], Loss: 3.009067, Acc:0.713148, Semantic loss: 1.129487, BCE loss: 0.800560, SB loss: 1.079020
2023-10-29 22:17:29,259 Epoch: [0/484] Iter:[240/495], Time: 0.63, lr: [0.009990983770644082], Loss: 2.997860, Acc:0.712151, Semantic loss: 1.126361, BCE loss: 0.793301, SB loss: 1.078198
2023-10-29 22:17:34,413 Epoch: [0/484] Iter:[250/495], Time: 0.63, lr: [0.00999060807480642], Loss: 2.994676, Acc:0.711821, Semantic loss: 1.126096, BCE loss: 0.790022, SB loss: 1.078558
2023-10-29 22:17:40,218 Epoch: [0/484] Iter:[260/495], Time: 0.63, lr: [0.00999023237739897], Loss: 2.986522, Acc:0.711779, Semantic loss: 1.121697, BCE loss: 0.788391, SB loss: 1.076435
2023-10-29 22:17:46,531 Epoch: [0/484] Iter:[270/495], Time: 0.63, lr: [0.009989856678421664], Loss: 2.981622, Acc:0.712588, Semantic loss: 1.119178, BCE loss: 0.787774, SB loss: 1.074670
2023-10-29 22:17:52,242 Epoch: [0/484] Iter:[280/495], Time: 0.63, lr: [0.009989480977874433], Loss: 2.960890, Acc:0.713544, Semantic loss: 1.109482, BCE loss: 0.783325, SB loss: 1.068083
2023-10-29 22:17:58,847 Epoch: [0/484] Iter:[290/495], Time: 0.63, lr: [0.009989105275757196], Loss: 2.956455, Acc:0.714572, Semantic loss: 1.110749, BCE loss: 0.779942, SB loss: 1.065764
2023-10-29 22:18:03,396 Epoch: [0/484] Iter:[300/495], Time: 0.62, lr: [0.009988729572069886], Loss: 2.953696, Acc:0.714317, Semantic loss: 1.110710, BCE loss: 0.778516, SB loss: 1.064471
2023-10-29 22:18:08,569 Epoch: [0/484] Iter:[310/495], Time: 0.62, lr: [0.009988353866812433], Loss: 2.940826, Acc:0.714742, Semantic loss: 1.105501, BCE loss: 0.774722, SB loss: 1.060603
2023-10-29 22:18:14,786 Epoch: [0/484] Iter:[320/495], Time: 0.62, lr: [0.009987978159984761], Loss: 2.933494, Acc:0.714536, Semantic loss: 1.103168, BCE loss: 0.771979, SB loss: 1.058347
2023-10-29 22:18:20,471 Epoch: [0/484] Iter:[330/495], Time: 0.62, lr: [0.009987602451586797], Loss: 2.929731, Acc:0.715911, Semantic loss: 1.102585, BCE loss: 0.770144, SB loss: 1.057002
2023-10-29 22:18:26,591 Epoch: [0/484] Iter:[340/495], Time: 0.62, lr: [0.009987226741618473], Loss: 2.920063, Acc:0.716630, Semantic loss: 1.096589, BCE loss: 0.769186, SB loss: 1.054288
2023-10-29 22:18:33,486 Epoch: [0/484] Iter:[350/495], Time: 0.62, lr: [0.009986851030079713], Loss: 2.912342, Acc:0.717697, Semantic loss: 1.093090, BCE loss: 0.767334, SB loss: 1.051918
2023-10-29 22:18:38,214 Epoch: [0/484] Iter:[360/495], Time: 0.61, lr: [0.009986475316970446], Loss: 2.905434, Acc:0.718766, Semantic loss: 1.089859, BCE loss: 0.765185, SB loss: 1.050390
2023-10-29 22:18:44,620 Epoch: [0/484] Iter:[370/495], Time: 0.61, lr: [0.009986099602290603], Loss: 2.903747, Acc:0.718632, Semantic loss: 1.089826, BCE loss: 0.763778, SB loss: 1.050144
2023-10-29 22:18:51,015 Epoch: [0/484] Iter:[380/495], Time: 0.62, lr: [0.009985723886040104], Loss: 2.892996, Acc:0.719659, Semantic loss: 1.086601, BCE loss: 0.760577, SB loss: 1.045818
2023-10-29 22:18:57,628 Epoch: [0/484] Iter:[390/495], Time: 0.62, lr: [0.009985348168218885], Loss: 2.885014, Acc:0.720755, Semantic loss: 1.082576, BCE loss: 0.757938, SB loss: 1.044500
2023-10-29 22:19:02,521 Epoch: [0/484] Iter:[400/495], Time: 0.61, lr: [0.00998497244882687], Loss: 2.879445, Acc:0.721580, Semantic loss: 1.080241, BCE loss: 0.756521, SB loss: 1.042683
2023-10-29 22:19:09,095 Epoch: [0/484] Iter:[410/495], Time: 0.61, lr: [0.009984596727863988], Loss: 2.870033, Acc:0.721494, Semantic loss: 1.076251, BCE loss: 0.754460, SB loss: 1.039323
2023-10-29 22:19:14,834 Epoch: [0/484] Iter:[420/495], Time: 0.61, lr: [0.009984221005330163], Loss: 2.862770, Acc:0.722764, Semantic loss: 1.072441, BCE loss: 0.753242, SB loss: 1.037087
2023-10-29 22:19:20,743 Epoch: [0/484] Iter:[430/495], Time: 0.61, lr: [0.009983845281225328], Loss: 2.854425, Acc:0.723322, Semantic loss: 1.068970, BCE loss: 0.751616, SB loss: 1.033839
2023-10-29 22:19:27,064 Epoch: [0/484] Iter:[440/495], Time: 0.61, lr: [0.009983469555549409], Loss: 2.845761, Acc:0.723174, Semantic loss: 1.066139, BCE loss: 0.748021, SB loss: 1.031601
2023-10-29 22:19:32,602 Epoch: [0/484] Iter:[450/495], Time: 0.61, lr: [0.009983093828302331], Loss: 2.842530, Acc:0.723990, Semantic loss: 1.064182, BCE loss: 0.747661, SB loss: 1.030687
2023-10-29 22:19:39,378 Epoch: [0/484] Iter:[460/495], Time: 0.61, lr: [0.009982718099484023], Loss: 2.839788, Acc:0.724581, Semantic loss: 1.063495, BCE loss: 0.746950, SB loss: 1.029343
2023-10-29 22:19:45,839 Epoch: [0/484] Iter:[470/495], Time: 0.61, lr: [0.009982342369094416], Loss: 2.838460, Acc:0.725072, Semantic loss: 1.064240, BCE loss: 0.745178, SB loss: 1.029042
2023-10-29 22:19:50,312 Epoch: [0/484] Iter:[480/495], Time: 0.61, lr: [0.009981966637133435], Loss: 2.830988, Acc:0.726271, Semantic loss: 1.060193, BCE loss: 0.744399, SB loss: 1.026396
2023-10-29 22:19:54,770 Epoch: [0/484] Iter:[490/495], Time: 0.61, lr: [0.009981590903601007], Loss: 2.824139, Acc:0.726712, Semantic loss: 1.057477, BCE loss: 0.742661, SB loss: 1.024001
2023-10-29 22:22:47,985 0 [8.58340396e-01 4.13486315e-01 6.82299643e-01 3.27372522e-02
 1.27500718e-01 2.61512797e-01 6.02666102e-02 3.02444318e-01
 7.21477281e-01 2.38834123e-01 7.33229783e-01 3.98181594e-01
 0.00000000e+00 6.32342313e-01 0.00000000e+00 1.72435063e-04
 1.51111395e-04 1.42107564e-04 4.27067096e-01] 0.3100097839870033
2023-10-29 22:22:47,986 1 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01] 0.31878821445549826
2023-10-29 22:22:47,989 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:22:48,337 Loss: 4.648, MeanIU:  0.3188, Best_mIoU:  0.3188
2023-10-29 22:22:48,338 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01]
2023-10-29 22:22:50,180 Epoch: [1/484] Iter:[0/495], Time: 1.81, lr: [0.009981403036245477], Loss: 2.429366, Acc:0.666929, Semantic loss: 0.952207, BCE loss: 0.447238, SB loss: 1.029920
2023-10-29 22:22:53,906 Epoch: [1/484] Iter:[10/495], Time: 0.50, lr: [0.009981027300355745], Loss: 2.729320, Acc:0.719594, Semantic loss: 1.069711, BCE loss: 0.632311, SB loss: 1.027299
2023-10-29 22:22:57,420 Epoch: [1/484] Iter:[20/495], Time: 0.43, lr: [0.009980651562894387], Loss: 2.745244, Acc:0.721821, Semantic loss: 1.076702, BCE loss: 0.648137, SB loss: 1.020404
2023-10-29 22:23:00,928 Epoch: [1/484] Iter:[30/495], Time: 0.41, lr: [0.009980275823861328], Loss: 2.668356, Acc:0.739073, Semantic loss: 1.017100, BCE loss: 0.662540, SB loss: 0.988717
2023-10-29 22:23:04,528 Epoch: [1/484] Iter:[40/495], Time: 0.39, lr: [0.009979900083256497], Loss: 2.639109, Acc:0.741046, Semantic loss: 0.989641, BCE loss: 0.671379, SB loss: 0.978089
2023-10-29 22:23:08,183 Epoch: [1/484] Iter:[50/495], Time: 0.39, lr: [0.009979524341079826], Loss: 2.644147, Acc:0.737279, Semantic loss: 0.988110, BCE loss: 0.681385, SB loss: 0.974652
2023-10-29 22:23:11,832 Epoch: [1/484] Iter:[60/495], Time: 0.38, lr: [0.009979148597331235], Loss: 2.648677, Acc:0.744768, Semantic loss: 0.982769, BCE loss: 0.690882, SB loss: 0.975025
2023-10-29 22:23:15,345 Epoch: [1/484] Iter:[70/495], Time: 0.38, lr: [0.009978772852010659], Loss: 2.647191, Acc:0.750105, Semantic loss: 0.976634, BCE loss: 0.697265, SB loss: 0.973293
2023-10-29 22:23:18,870 Epoch: [1/484] Iter:[80/495], Time: 0.38, lr: [0.009978397105118018], Loss: 2.688544, Acc:0.748174, Semantic loss: 1.010744, BCE loss: 0.691501, SB loss: 0.986298
2023-10-29 22:23:22,438 Epoch: [1/484] Iter:[90/495], Time: 0.37, lr: [0.009978021356653247], Loss: 2.681811, Acc:0.746916, Semantic loss: 1.009248, BCE loss: 0.688169, SB loss: 0.984394
2023-10-29 22:23:25,902 Epoch: [1/484] Iter:[100/495], Time: 0.37, lr: [0.00997764560661627], Loss: 2.641452, Acc:0.748189, Semantic loss: 0.985140, BCE loss: 0.682727, SB loss: 0.973585
2023-10-29 22:23:29,347 Epoch: [1/484] Iter:[110/495], Time: 0.37, lr: [0.009977269855007015], Loss: 2.617569, Acc:0.750767, Semantic loss: 0.974931, BCE loss: 0.678841, SB loss: 0.963797
2023-10-29 22:23:32,780 Epoch: [1/484] Iter:[120/495], Time: 0.37, lr: [0.00997689410182541], Loss: 2.617294, Acc:0.749637, Semantic loss: 0.971662, BCE loss: 0.688339, SB loss: 0.957293
2023-10-29 22:23:36,335 Epoch: [1/484] Iter:[130/495], Time: 0.37, lr: [0.009976518347071382], Loss: 2.604836, Acc:0.747997, Semantic loss: 0.964572, BCE loss: 0.689185, SB loss: 0.951079
2023-10-29 22:23:39,867 Epoch: [1/484] Iter:[140/495], Time: 0.37, lr: [0.00997614259074486], Loss: 2.594574, Acc:0.751987, Semantic loss: 0.959891, BCE loss: 0.687978, SB loss: 0.946706
2023-10-29 22:23:43,508 Epoch: [1/484] Iter:[150/495], Time: 0.37, lr: [0.009975766832845769], Loss: 2.587028, Acc:0.752760, Semantic loss: 0.959397, BCE loss: 0.684236, SB loss: 0.943395
2023-10-29 22:23:46,980 Epoch: [1/484] Iter:[160/495], Time: 0.36, lr: [0.009975391073374038], Loss: 2.590008, Acc:0.755060, Semantic loss: 0.961727, BCE loss: 0.685933, SB loss: 0.942349
2023-10-29 22:23:50,408 Epoch: [1/484] Iter:[170/495], Time: 0.36, lr: [0.009975015312329596], Loss: 2.565758, Acc:0.753590, Semantic loss: 0.950537, BCE loss: 0.681137, SB loss: 0.934084
2023-10-29 22:23:53,899 Epoch: [1/484] Iter:[180/495], Time: 0.36, lr: [0.00997463954971237], Loss: 2.563259, Acc:0.754009, Semantic loss: 0.948713, BCE loss: 0.677471, SB loss: 0.937075
2023-10-29 22:23:57,514 Epoch: [1/484] Iter:[190/495], Time: 0.36, lr: [0.009974263785522287], Loss: 2.555883, Acc:0.755135, Semantic loss: 0.947962, BCE loss: 0.672824, SB loss: 0.935096
2023-10-29 22:24:01,135 Epoch: [1/484] Iter:[200/495], Time: 0.36, lr: [0.009973888019759273], Loss: 2.562780, Acc:0.754138, Semantic loss: 0.956974, BCE loss: 0.669436, SB loss: 0.936370
2023-10-29 22:24:04,787 Epoch: [1/484] Iter:[210/495], Time: 0.36, lr: [0.009973512252423256], Loss: 2.547031, Acc:0.754341, Semantic loss: 0.950925, BCE loss: 0.667077, SB loss: 0.929030
2023-10-29 22:24:08,438 Epoch: [1/484] Iter:[220/495], Time: 0.36, lr: [0.009973136483514167], Loss: 2.542719, Acc:0.755641, Semantic loss: 0.947072, BCE loss: 0.669060, SB loss: 0.926586
2023-10-29 22:24:12,095 Epoch: [1/484] Iter:[230/495], Time: 0.36, lr: [0.009972760713031931], Loss: 2.536006, Acc:0.755571, Semantic loss: 0.943050, BCE loss: 0.666932, SB loss: 0.926025
2023-10-29 22:24:15,694 Epoch: [1/484] Iter:[240/495], Time: 0.36, lr: [0.009972384940976476], Loss: 2.537174, Acc:0.756111, Semantic loss: 0.943348, BCE loss: 0.669334, SB loss: 0.924492
2023-10-29 22:24:19,305 Epoch: [1/484] Iter:[250/495], Time: 0.36, lr: [0.009972009167347728], Loss: 2.528361, Acc:0.755442, Semantic loss: 0.938595, BCE loss: 0.666092, SB loss: 0.923674
2023-10-29 22:24:22,962 Epoch: [1/484] Iter:[260/495], Time: 0.36, lr: [0.009971633392145617], Loss: 2.529803, Acc:0.755302, Semantic loss: 0.940758, BCE loss: 0.665530, SB loss: 0.923514
2023-10-29 22:24:26,576 Epoch: [1/484] Iter:[270/495], Time: 0.36, lr: [0.00997125761537007], Loss: 2.520800, Acc:0.755803, Semantic loss: 0.934756, BCE loss: 0.665190, SB loss: 0.920854
2023-10-29 22:24:30,155 Epoch: [1/484] Iter:[280/495], Time: 0.36, lr: [0.009970881837021012], Loss: 2.522647, Acc:0.757007, Semantic loss: 0.935324, BCE loss: 0.665390, SB loss: 0.921932
2023-10-29 22:24:33,800 Epoch: [1/484] Iter:[290/495], Time: 0.36, lr: [0.009970506057098373], Loss: 2.516340, Acc:0.757064, Semantic loss: 0.930695, BCE loss: 0.664058, SB loss: 0.921587
2023-10-29 22:24:37,505 Epoch: [1/484] Iter:[300/495], Time: 0.36, lr: [0.009970130275602083], Loss: 2.510761, Acc:0.758744, Semantic loss: 0.927353, BCE loss: 0.665118, SB loss: 0.918290
2023-10-29 22:24:41,172 Epoch: [1/484] Iter:[310/495], Time: 0.36, lr: [0.009969754492532065], Loss: 2.504664, Acc:0.759281, Semantic loss: 0.925145, BCE loss: 0.662970, SB loss: 0.916549
2023-10-29 22:24:44,929 Epoch: [1/484] Iter:[320/495], Time: 0.36, lr: [0.009969378707888246], Loss: 2.498465, Acc:0.758102, Semantic loss: 0.921732, BCE loss: 0.661798, SB loss: 0.914935
2023-10-29 22:24:48,654 Epoch: [1/484] Iter:[330/495], Time: 0.36, lr: [0.009969002921670555], Loss: 2.504239, Acc:0.758229, Semantic loss: 0.926313, BCE loss: 0.660475, SB loss: 0.917451
2023-10-29 22:24:52,376 Epoch: [1/484] Iter:[340/495], Time: 0.36, lr: [0.009968627133878923], Loss: 2.505612, Acc:0.757950, Semantic loss: 0.929405, BCE loss: 0.659690, SB loss: 0.916517
2023-10-29 22:24:56,153 Epoch: [1/484] Iter:[350/495], Time: 0.36, lr: [0.009968251344513275], Loss: 2.511438, Acc:0.758593, Semantic loss: 0.932986, BCE loss: 0.659411, SB loss: 0.919041
2023-10-29 22:25:00,014 Epoch: [1/484] Iter:[360/495], Time: 0.36, lr: [0.009967875553573534], Loss: 2.517362, Acc:0.759708, Semantic loss: 0.936694, BCE loss: 0.660190, SB loss: 0.920477
2023-10-29 22:25:03,737 Epoch: [1/484] Iter:[370/495], Time: 0.36, lr: [0.009967499761059633], Loss: 2.516202, Acc:0.760432, Semantic loss: 0.935483, BCE loss: 0.659660, SB loss: 0.921059
2023-10-29 22:25:07,495 Epoch: [1/484] Iter:[380/495], Time: 0.37, lr: [0.009967123966971499], Loss: 2.515296, Acc:0.762520, Semantic loss: 0.934216, BCE loss: 0.661318, SB loss: 0.919761
2023-10-29 22:25:11,178 Epoch: [1/484] Iter:[390/495], Time: 0.37, lr: [0.009966748171309058], Loss: 2.522557, Acc:0.762586, Semantic loss: 0.938948, BCE loss: 0.661888, SB loss: 0.921720
2023-10-29 22:25:14,790 Epoch: [1/484] Iter:[400/495], Time: 0.37, lr: [0.009966372374072236], Loss: 2.520638, Acc:0.762665, Semantic loss: 0.937444, BCE loss: 0.661876, SB loss: 0.921318
2023-10-29 22:25:18,702 Epoch: [1/484] Iter:[410/495], Time: 0.37, lr: [0.009965996575260963], Loss: 2.516679, Acc:0.762153, Semantic loss: 0.935466, BCE loss: 0.661874, SB loss: 0.919339
2023-10-29 22:25:22,435 Epoch: [1/484] Iter:[420/495], Time: 0.37, lr: [0.009965620774875169], Loss: 2.515970, Acc:0.762066, Semantic loss: 0.934286, BCE loss: 0.662786, SB loss: 0.918898
2023-10-29 22:25:26,074 Epoch: [1/484] Iter:[430/495], Time: 0.37, lr: [0.009965244972914775], Loss: 2.514210, Acc:0.762395, Semantic loss: 0.932735, BCE loss: 0.662641, SB loss: 0.918834
2023-10-29 22:25:29,811 Epoch: [1/484] Iter:[440/495], Time: 0.37, lr: [0.009964869169379711], Loss: 2.514418, Acc:0.762297, Semantic loss: 0.933613, BCE loss: 0.661880, SB loss: 0.918925
2023-10-29 22:25:33,572 Epoch: [1/484] Iter:[450/495], Time: 0.37, lr: [0.009964493364269906], Loss: 2.513542, Acc:0.762523, Semantic loss: 0.932936, BCE loss: 0.661561, SB loss: 0.919045
2023-10-29 22:25:37,372 Epoch: [1/484] Iter:[460/495], Time: 0.37, lr: [0.009964117557585287], Loss: 2.511276, Acc:0.763203, Semantic loss: 0.931986, BCE loss: 0.661799, SB loss: 0.917491
2023-10-29 22:25:41,118 Epoch: [1/484] Iter:[470/495], Time: 0.37, lr: [0.009963741749325778], Loss: 2.509623, Acc:0.763769, Semantic loss: 0.931557, BCE loss: 0.661057, SB loss: 0.917009
2023-10-29 22:25:44,770 Epoch: [1/484] Iter:[480/495], Time: 0.37, lr: [0.009963365939491311], Loss: 2.513226, Acc:0.764294, Semantic loss: 0.933417, BCE loss: 0.661792, SB loss: 0.918017
2023-10-29 22:25:48,325 Epoch: [1/484] Iter:[490/495], Time: 0.37, lr: [0.009962990128081812], Loss: 2.512059, Acc:0.764483, Semantic loss: 0.932799, BCE loss: 0.661634, SB loss: 0.917626
2023-10-29 22:25:49,704 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:25:49,949 Loss: 4.648, MeanIU:  0.3188, Best_mIoU:  0.3188
2023-10-29 22:25:49,949 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01]
2023-10-29 22:25:52,050 Epoch: [2/484] Iter:[0/495], Time: 2.07, lr: [0.009962802221786402], Loss: 2.544115, Acc:0.768515, Semantic loss: 0.877125, BCE loss: 0.857600, SB loss: 0.809390
2023-10-29 22:25:56,211 Epoch: [2/484] Iter:[10/495], Time: 0.57, lr: [0.00996242640801422], Loss: 2.603369, Acc:0.789248, Semantic loss: 0.933481, BCE loss: 0.739351, SB loss: 0.930537
2023-10-29 22:26:00,014 Epoch: [2/484] Iter:[20/495], Time: 0.48, lr: [0.009962050592666818], Loss: 2.476727, Acc:0.760248, Semantic loss: 0.908402, BCE loss: 0.661036, SB loss: 0.907290
2023-10-29 22:26:03,867 Epoch: [2/484] Iter:[30/495], Time: 0.45, lr: [0.009961674775744136], Loss: 2.489935, Acc:0.767894, Semantic loss: 0.911735, BCE loss: 0.682817, SB loss: 0.895383
2023-10-29 22:26:07,533 Epoch: [2/484] Iter:[40/495], Time: 0.43, lr: [0.009961298957246092], Loss: 2.440933, Acc:0.763094, Semantic loss: 0.894116, BCE loss: 0.665325, SB loss: 0.881492
2023-10-29 22:26:11,232 Epoch: [2/484] Iter:[50/495], Time: 0.42, lr: [0.009960923137172615], Loss: 2.425773, Acc:0.762601, Semantic loss: 0.892595, BCE loss: 0.657972, SB loss: 0.875206
2023-10-29 22:26:15,010 Epoch: [2/484] Iter:[60/495], Time: 0.41, lr: [0.009960547315523633], Loss: 2.409029, Acc:0.764163, Semantic loss: 0.883885, BCE loss: 0.656501, SB loss: 0.868642
2023-10-29 22:26:18,757 Epoch: [2/484] Iter:[70/495], Time: 0.41, lr: [0.009960171492299077], Loss: 2.411382, Acc:0.763035, Semantic loss: 0.885723, BCE loss: 0.654032, SB loss: 0.871627
2023-10-29 22:26:22,451 Epoch: [2/484] Iter:[80/495], Time: 0.40, lr: [0.009959795667498867], Loss: 2.411467, Acc:0.763521, Semantic loss: 0.888735, BCE loss: 0.651359, SB loss: 0.871373
2023-10-29 22:26:26,148 Epoch: [2/484] Iter:[90/495], Time: 0.40, lr: [0.009959419841122938], Loss: 2.419260, Acc:0.760901, Semantic loss: 0.894903, BCE loss: 0.649188, SB loss: 0.875169
2023-10-29 22:26:30,006 Epoch: [2/484] Iter:[100/495], Time: 0.40, lr: [0.009959044013171211], Loss: 2.407825, Acc:0.759592, Semantic loss: 0.893265, BCE loss: 0.640901, SB loss: 0.873659
2023-10-29 22:26:33,703 Epoch: [2/484] Iter:[110/495], Time: 0.39, lr: [0.009958668183643618], Loss: 2.413485, Acc:0.756992, Semantic loss: 0.893245, BCE loss: 0.643857, SB loss: 0.876383
2023-10-29 22:26:37,505 Epoch: [2/484] Iter:[120/495], Time: 0.39, lr: [0.009958292352540084], Loss: 2.406411, Acc:0.756325, Semantic loss: 0.888636, BCE loss: 0.643448, SB loss: 0.874327
2023-10-29 22:26:41,193 Epoch: [2/484] Iter:[130/495], Time: 0.39, lr: [0.009957916519860537], Loss: 2.426850, Acc:0.757949, Semantic loss: 0.899040, BCE loss: 0.650564, SB loss: 0.877246
2023-10-29 22:26:44,795 Epoch: [2/484] Iter:[140/495], Time: 0.39, lr: [0.009957540685604902], Loss: 2.429877, Acc:0.756947, Semantic loss: 0.903833, BCE loss: 0.647068, SB loss: 0.878975
2023-10-29 22:26:48,477 Epoch: [2/484] Iter:[150/495], Time: 0.39, lr: [0.00995716484977311], Loss: 2.421000, Acc:0.757097, Semantic loss: 0.902189, BCE loss: 0.643560, SB loss: 0.875250
2023-10-29 22:26:52,112 Epoch: [2/484] Iter:[160/495], Time: 0.39, lr: [0.009956789012365087], Loss: 2.410907, Acc:0.758574, Semantic loss: 0.896112, BCE loss: 0.644479, SB loss: 0.870317
2023-10-29 22:26:55,771 Epoch: [2/484] Iter:[170/495], Time: 0.38, lr: [0.00995641317338076], Loss: 2.416902, Acc:0.758280, Semantic loss: 0.900029, BCE loss: 0.644264, SB loss: 0.872610
2023-10-29 22:26:59,491 Epoch: [2/484] Iter:[180/495], Time: 0.38, lr: [0.009956037332820054], Loss: 2.422075, Acc:0.757573, Semantic loss: 0.905295, BCE loss: 0.643320, SB loss: 0.873461
2023-10-29 22:27:03,214 Epoch: [2/484] Iter:[190/495], Time: 0.38, lr: [0.0099556614906829], Loss: 2.412450, Acc:0.758750, Semantic loss: 0.898287, BCE loss: 0.642617, SB loss: 0.871547
2023-10-29 22:27:06,897 Epoch: [2/484] Iter:[200/495], Time: 0.38, lr: [0.009955285646969224], Loss: 2.409316, Acc:0.759657, Semantic loss: 0.895260, BCE loss: 0.641932, SB loss: 0.872123
2023-10-29 22:27:10,666 Epoch: [2/484] Iter:[210/495], Time: 0.38, lr: [0.009954909801678952], Loss: 2.403575, Acc:0.760167, Semantic loss: 0.890672, BCE loss: 0.639714, SB loss: 0.873189
2023-10-29 22:27:14,276 Epoch: [2/484] Iter:[220/495], Time: 0.38, lr: [0.009954533954812012], Loss: 2.408877, Acc:0.760502, Semantic loss: 0.893088, BCE loss: 0.642556, SB loss: 0.873233
2023-10-29 22:27:17,884 Epoch: [2/484] Iter:[230/495], Time: 0.38, lr: [0.009954158106368334], Loss: 2.408834, Acc:0.760135, Semantic loss: 0.894670, BCE loss: 0.642859, SB loss: 0.871306
2023-10-29 22:27:21,531 Epoch: [2/484] Iter:[240/495], Time: 0.38, lr: [0.009953782256347838], Loss: 2.405141, Acc:0.760382, Semantic loss: 0.892941, BCE loss: 0.642540, SB loss: 0.869659
2023-10-29 22:27:25,246 Epoch: [2/484] Iter:[250/495], Time: 0.38, lr: [0.00995340640475046], Loss: 2.405496, Acc:0.760145, Semantic loss: 0.893398, BCE loss: 0.642370, SB loss: 0.869727
2023-10-29 22:27:28,992 Epoch: [2/484] Iter:[260/495], Time: 0.38, lr: [0.009953030551576121], Loss: 2.403178, Acc:0.760374, Semantic loss: 0.889905, BCE loss: 0.643778, SB loss: 0.869494
2023-10-29 22:27:32,567 Epoch: [2/484] Iter:[270/495], Time: 0.38, lr: [0.00995265469682475], Loss: 2.406876, Acc:0.760942, Semantic loss: 0.891392, BCE loss: 0.644674, SB loss: 0.870810
2023-10-29 22:27:36,185 Epoch: [2/484] Iter:[280/495], Time: 0.38, lr: [0.009952278840496277], Loss: 2.402165, Acc:0.760753, Semantic loss: 0.891176, BCE loss: 0.642564, SB loss: 0.868425
2023-10-29 22:27:39,787 Epoch: [2/484] Iter:[290/495], Time: 0.38, lr: [0.009951902982590626], Loss: 2.406756, Acc:0.759954, Semantic loss: 0.894645, BCE loss: 0.642631, SB loss: 0.869480
2023-10-29 22:27:43,468 Epoch: [2/484] Iter:[300/495], Time: 0.38, lr: [0.009951527123107722], Loss: 2.410955, Acc:0.758661, Semantic loss: 0.897710, BCE loss: 0.641799, SB loss: 0.871445
2023-10-29 22:27:47,151 Epoch: [2/484] Iter:[310/495], Time: 0.38, lr: [0.009951151262047498], Loss: 2.422948, Acc:0.759067, Semantic loss: 0.904223, BCE loss: 0.644460, SB loss: 0.874264
2023-10-29 22:27:50,794 Epoch: [2/484] Iter:[320/495], Time: 0.38, lr: [0.009950775399409877], Loss: 2.415776, Acc:0.759908, Semantic loss: 0.898965, BCE loss: 0.643870, SB loss: 0.872941
2023-10-29 22:27:54,520 Epoch: [2/484] Iter:[330/495], Time: 0.38, lr: [0.009950399535194786], Loss: 2.414212, Acc:0.760633, Semantic loss: 0.898070, BCE loss: 0.643154, SB loss: 0.872988
2023-10-29 22:27:58,226 Epoch: [2/484] Iter:[340/495], Time: 0.38, lr: [0.009950023669402156], Loss: 2.414680, Acc:0.760999, Semantic loss: 0.898126, BCE loss: 0.643468, SB loss: 0.873086
2023-10-29 22:28:01,876 Epoch: [2/484] Iter:[350/495], Time: 0.38, lr: [0.009949647802031912], Loss: 2.414659, Acc:0.760853, Semantic loss: 0.898165, BCE loss: 0.642999, SB loss: 0.873495
2023-10-29 22:28:05,450 Epoch: [2/484] Iter:[360/495], Time: 0.38, lr: [0.00994927193308398], Loss: 2.416574, Acc:0.760628, Semantic loss: 0.899268, BCE loss: 0.642366, SB loss: 0.874941
2023-10-29 22:28:09,210 Epoch: [2/484] Iter:[370/495], Time: 0.38, lr: [0.009948896062558289], Loss: 2.414809, Acc:0.761682, Semantic loss: 0.898494, BCE loss: 0.641975, SB loss: 0.874339
2023-10-29 22:28:12,890 Epoch: [2/484] Iter:[380/495], Time: 0.38, lr: [0.009948520190454764], Loss: 2.415340, Acc:0.761951, Semantic loss: 0.899768, BCE loss: 0.640829, SB loss: 0.874742
2023-10-29 22:28:16,528 Epoch: [2/484] Iter:[390/495], Time: 0.37, lr: [0.009948144316773334], Loss: 2.416280, Acc:0.761167, Semantic loss: 0.900162, BCE loss: 0.642015, SB loss: 0.874103
2023-10-29 22:28:20,179 Epoch: [2/484] Iter:[400/495], Time: 0.37, lr: [0.009947768441513925], Loss: 2.423813, Acc:0.762039, Semantic loss: 0.903327, BCE loss: 0.644545, SB loss: 0.875941
2023-10-29 22:28:23,857 Epoch: [2/484] Iter:[410/495], Time: 0.37, lr: [0.009947392564676465], Loss: 2.421788, Acc:0.761712, Semantic loss: 0.902398, BCE loss: 0.643857, SB loss: 0.875532
2023-10-29 22:28:27,467 Epoch: [2/484] Iter:[420/495], Time: 0.37, lr: [0.009947016686260883], Loss: 2.428161, Acc:0.762431, Semantic loss: 0.905800, BCE loss: 0.645379, SB loss: 0.876982
2023-10-29 22:28:31,110 Epoch: [2/484] Iter:[430/495], Time: 0.37, lr: [0.009946640806267101], Loss: 2.425452, Acc:0.762749, Semantic loss: 0.903115, BCE loss: 0.646374, SB loss: 0.875963
2023-10-29 22:28:34,681 Epoch: [2/484] Iter:[440/495], Time: 0.37, lr: [0.00994626492469505], Loss: 2.426117, Acc:0.762421, Semantic loss: 0.904167, BCE loss: 0.644755, SB loss: 0.877195
2023-10-29 22:28:38,313 Epoch: [2/484] Iter:[450/495], Time: 0.37, lr: [0.009945889041544656], Loss: 2.426337, Acc:0.762157, Semantic loss: 0.904205, BCE loss: 0.643753, SB loss: 0.878378
2023-10-29 22:28:41,972 Epoch: [2/484] Iter:[460/495], Time: 0.37, lr: [0.009945513156815846], Loss: 2.426072, Acc:0.762200, Semantic loss: 0.903678, BCE loss: 0.643708, SB loss: 0.878686
2023-10-29 22:28:45,621 Epoch: [2/484] Iter:[470/495], Time: 0.37, lr: [0.009945137270508548], Loss: 2.428637, Acc:0.762261, Semantic loss: 0.905542, BCE loss: 0.643593, SB loss: 0.879503
2023-10-29 22:28:49,356 Epoch: [2/484] Iter:[480/495], Time: 0.37, lr: [0.009944761382622689], Loss: 2.428612, Acc:0.762486, Semantic loss: 0.905196, BCE loss: 0.644319, SB loss: 0.879097
2023-10-29 22:28:52,883 Epoch: [2/484] Iter:[490/495], Time: 0.37, lr: [0.009944385493158193], Loss: 2.429174, Acc:0.762593, Semantic loss: 0.904820, BCE loss: 0.645486, SB loss: 0.878868
2023-10-29 22:28:54,249 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:28:54,484 Loss: 4.648, MeanIU:  0.3188, Best_mIoU:  0.3188
2023-10-29 22:28:54,485 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01]
2023-10-29 22:28:56,508 Epoch: [3/484] Iter:[0/495], Time: 2.00, lr: [0.009944197547833935], Loss: 2.238081, Acc:0.798341, Semantic loss: 0.734161, BCE loss: 0.730525, SB loss: 0.773395
2023-10-29 22:29:00,490 Epoch: [3/484] Iter:[10/495], Time: 0.54, lr: [0.009943821656001352], Loss: 2.202508, Acc:0.814406, Semantic loss: 0.814176, BCE loss: 0.577314, SB loss: 0.811018
2023-10-29 22:29:04,069 Epoch: [3/484] Iter:[20/495], Time: 0.45, lr: [0.009943445762589952], Loss: 2.282142, Acc:0.787469, Semantic loss: 0.831306, BCE loss: 0.604088, SB loss: 0.846749
2023-10-29 22:29:07,769 Epoch: [3/484] Iter:[30/495], Time: 0.43, lr: [0.009943069867599661], Loss: 2.328953, Acc:0.782812, Semantic loss: 0.854546, BCE loss: 0.627565, SB loss: 0.846842
2023-10-29 22:29:11,348 Epoch: [3/484] Iter:[40/495], Time: 0.41, lr: [0.009942693971030408], Loss: 2.367946, Acc:0.786170, Semantic loss: 0.872767, BCE loss: 0.639057, SB loss: 0.856123
2023-10-29 22:29:14,984 Epoch: [3/484] Iter:[50/495], Time: 0.40, lr: [0.009942318072882119], Loss: 2.398785, Acc:0.782712, Semantic loss: 0.895375, BCE loss: 0.641412, SB loss: 0.861998
2023-10-29 22:29:18,563 Epoch: [3/484] Iter:[60/495], Time: 0.39, lr: [0.009941942173154722], Loss: 2.384263, Acc:0.782433, Semantic loss: 0.878877, BCE loss: 0.643970, SB loss: 0.861417
2023-10-29 22:29:22,234 Epoch: [3/484] Iter:[70/495], Time: 0.39, lr: [0.009941566271848144], Loss: 2.359672, Acc:0.777690, Semantic loss: 0.862942, BCE loss: 0.638611, SB loss: 0.858118
2023-10-29 22:29:25,888 Epoch: [3/484] Iter:[80/495], Time: 0.39, lr: [0.00994119036896231], Loss: 2.360546, Acc:0.780562, Semantic loss: 0.868793, BCE loss: 0.633811, SB loss: 0.857943
2023-10-29 22:29:29,528 Epoch: [3/484] Iter:[90/495], Time: 0.38, lr: [0.009940814464497148], Loss: 2.349245, Acc:0.784503, Semantic loss: 0.863891, BCE loss: 0.628286, SB loss: 0.857067
2023-10-29 22:29:33,257 Epoch: [3/484] Iter:[100/495], Time: 0.38, lr: [0.009940438558452586], Loss: 2.354543, Acc:0.784263, Semantic loss: 0.867279, BCE loss: 0.630949, SB loss: 0.856315
2023-10-29 22:29:36,957 Epoch: [3/484] Iter:[110/495], Time: 0.38, lr: [0.00994006265082855], Loss: 2.352865, Acc:0.785295, Semantic loss: 0.861521, BCE loss: 0.635941, SB loss: 0.855403
2023-10-29 22:29:40,745 Epoch: [3/484] Iter:[120/495], Time: 0.38, lr: [0.009939686741624968], Loss: 2.368095, Acc:0.782626, Semantic loss: 0.873252, BCE loss: 0.635958, SB loss: 0.858884
2023-10-29 22:29:44,383 Epoch: [3/484] Iter:[130/495], Time: 0.38, lr: [0.009939310830841765], Loss: 2.387456, Acc:0.782218, Semantic loss: 0.882493, BCE loss: 0.642072, SB loss: 0.862891
2023-10-29 22:29:47,962 Epoch: [3/484] Iter:[140/495], Time: 0.38, lr: [0.009938934918478871], Loss: 2.381199, Acc:0.778851, Semantic loss: 0.878697, BCE loss: 0.639496, SB loss: 0.863007
2023-10-29 22:29:51,613 Epoch: [3/484] Iter:[150/495], Time: 0.38, lr: [0.009938559004536211], Loss: 2.378760, Acc:0.774305, Semantic loss: 0.880133, BCE loss: 0.639089, SB loss: 0.859539
2023-10-29 22:29:55,352 Epoch: [3/484] Iter:[160/495], Time: 0.38, lr: [0.009938183089013711], Loss: 2.371926, Acc:0.773600, Semantic loss: 0.877254, BCE loss: 0.638475, SB loss: 0.856197
2023-10-29 22:29:59,032 Epoch: [3/484] Iter:[170/495], Time: 0.38, lr: [0.009937807171911301], Loss: 2.379124, Acc:0.771284, Semantic loss: 0.879635, BCE loss: 0.641531, SB loss: 0.857958
2023-10-29 22:30:02,757 Epoch: [3/484] Iter:[180/495], Time: 0.38, lr: [0.009937431253228905], Loss: 2.372114, Acc:0.773305, Semantic loss: 0.875677, BCE loss: 0.639511, SB loss: 0.856926
2023-10-29 22:30:06,508 Epoch: [3/484] Iter:[190/495], Time: 0.38, lr: [0.00993705533296645], Loss: 2.380049, Acc:0.771187, Semantic loss: 0.883332, BCE loss: 0.639234, SB loss: 0.857483
2023-10-29 22:30:10,255 Epoch: [3/484] Iter:[200/495], Time: 0.38, lr: [0.009936679411123866], Loss: 2.376740, Acc:0.771217, Semantic loss: 0.880692, BCE loss: 0.638083, SB loss: 0.857964
2023-10-29 22:30:13,886 Epoch: [3/484] Iter:[210/495], Time: 0.38, lr: [0.009936303487701078], Loss: 2.372174, Acc:0.773579, Semantic loss: 0.877586, BCE loss: 0.637869, SB loss: 0.856719
2023-10-29 22:30:17,514 Epoch: [3/484] Iter:[220/495], Time: 0.38, lr: [0.009935927562698012], Loss: 2.376053, Acc:0.773376, Semantic loss: 0.884250, BCE loss: 0.634139, SB loss: 0.857664
2023-10-29 22:30:21,237 Epoch: [3/484] Iter:[230/495], Time: 0.38, lr: [0.009935551636114594], Loss: 2.370110, Acc:0.773893, Semantic loss: 0.880085, BCE loss: 0.632965, SB loss: 0.857060
2023-10-29 22:30:24,843 Epoch: [3/484] Iter:[240/495], Time: 0.37, lr: [0.009935175707950756], Loss: 2.369369, Acc:0.774798, Semantic loss: 0.881314, BCE loss: 0.631499, SB loss: 0.856556
2023-10-29 22:30:28,531 Epoch: [3/484] Iter:[250/495], Time: 0.37, lr: [0.00993479977820642], Loss: 2.362014, Acc:0.773752, Semantic loss: 0.878021, BCE loss: 0.629042, SB loss: 0.854952
2023-10-29 22:30:32,155 Epoch: [3/484] Iter:[260/495], Time: 0.37, lr: [0.009934423846881516], Loss: 2.363020, Acc:0.772717, Semantic loss: 0.878824, BCE loss: 0.625761, SB loss: 0.858435
2023-10-29 22:30:35,861 Epoch: [3/484] Iter:[270/495], Time: 0.37, lr: [0.009934047913975967], Loss: 2.357534, Acc:0.773395, Semantic loss: 0.876101, BCE loss: 0.624169, SB loss: 0.857264
2023-10-29 22:30:39,526 Epoch: [3/484] Iter:[280/495], Time: 0.37, lr: [0.009933671979489704], Loss: 2.355819, Acc:0.773532, Semantic loss: 0.875511, BCE loss: 0.623638, SB loss: 0.856670
2023-10-29 22:30:43,230 Epoch: [3/484] Iter:[290/495], Time: 0.37, lr: [0.009933296043422652], Loss: 2.357487, Acc:0.774266, Semantic loss: 0.876722, BCE loss: 0.623584, SB loss: 0.857180
2023-10-29 22:30:46,912 Epoch: [3/484] Iter:[300/495], Time: 0.37, lr: [0.00993292010577474], Loss: 2.360771, Acc:0.774929, Semantic loss: 0.879822, BCE loss: 0.622720, SB loss: 0.858228
2023-10-29 22:30:50,562 Epoch: [3/484] Iter:[310/495], Time: 0.37, lr: [0.00993254416654589], Loss: 2.365710, Acc:0.774739, Semantic loss: 0.881988, BCE loss: 0.624826, SB loss: 0.858897
2023-10-29 22:30:54,216 Epoch: [3/484] Iter:[320/495], Time: 0.37, lr: [0.009932168225736034], Loss: 2.366380, Acc:0.774530, Semantic loss: 0.882953, BCE loss: 0.625081, SB loss: 0.858347
2023-10-29 22:30:57,850 Epoch: [3/484] Iter:[330/495], Time: 0.37, lr: [0.009931792283345096], Loss: 2.361036, Acc:0.773936, Semantic loss: 0.880920, BCE loss: 0.623623, SB loss: 0.856494
2023-10-29 22:31:01,508 Epoch: [3/484] Iter:[340/495], Time: 0.37, lr: [0.009931416339373002], Loss: 2.365776, Acc:0.773582, Semantic loss: 0.885292, BCE loss: 0.622225, SB loss: 0.858259
2023-10-29 22:31:05,265 Epoch: [3/484] Iter:[350/495], Time: 0.37, lr: [0.009931040393819682], Loss: 2.367924, Acc:0.773743, Semantic loss: 0.886689, BCE loss: 0.621949, SB loss: 0.859286
2023-10-29 22:31:08,989 Epoch: [3/484] Iter:[360/495], Time: 0.37, lr: [0.009930664446685061], Loss: 2.371014, Acc:0.773331, Semantic loss: 0.887179, BCE loss: 0.622871, SB loss: 0.860965
2023-10-29 22:31:12,791 Epoch: [3/484] Iter:[370/495], Time: 0.37, lr: [0.009930288497969066], Loss: 2.377886, Acc:0.773112, Semantic loss: 0.891771, BCE loss: 0.622850, SB loss: 0.863265
2023-10-29 22:31:16,481 Epoch: [3/484] Iter:[380/495], Time: 0.37, lr: [0.009929912547671626], Loss: 2.379345, Acc:0.773759, Semantic loss: 0.892158, BCE loss: 0.622832, SB loss: 0.864355
2023-10-29 22:31:20,075 Epoch: [3/484] Iter:[390/495], Time: 0.37, lr: [0.009929536595792663], Loss: 2.389484, Acc:0.773538, Semantic loss: 0.899549, BCE loss: 0.623024, SB loss: 0.866910
2023-10-29 22:31:23,767 Epoch: [3/484] Iter:[400/495], Time: 0.37, lr: [0.009929160642332107], Loss: 2.390357, Acc:0.772793, Semantic loss: 0.899695, BCE loss: 0.622551, SB loss: 0.868111
2023-10-29 22:31:27,398 Epoch: [3/484] Iter:[410/495], Time: 0.37, lr: [0.009928784687289884], Loss: 2.390557, Acc:0.772534, Semantic loss: 0.899260, BCE loss: 0.622083, SB loss: 0.869214
2023-10-29 22:31:31,033 Epoch: [3/484] Iter:[420/495], Time: 0.37, lr: [0.009928408730665923], Loss: 2.383105, Acc:0.772709, Semantic loss: 0.894912, BCE loss: 0.621024, SB loss: 0.867169
2023-10-29 22:31:34,748 Epoch: [3/484] Iter:[430/495], Time: 0.37, lr: [0.009928032772460148], Loss: 2.384517, Acc:0.773272, Semantic loss: 0.894516, BCE loss: 0.623444, SB loss: 0.866557
2023-10-29 22:31:38,376 Epoch: [3/484] Iter:[440/495], Time: 0.37, lr: [0.009927656812672487], Loss: 2.387020, Acc:0.773493, Semantic loss: 0.894394, BCE loss: 0.625500, SB loss: 0.867126
2023-10-29 22:31:42,000 Epoch: [3/484] Iter:[450/495], Time: 0.37, lr: [0.009927280851302865], Loss: 2.380496, Acc:0.772665, Semantic loss: 0.892111, BCE loss: 0.623091, SB loss: 0.865294
2023-10-29 22:31:45,673 Epoch: [3/484] Iter:[460/495], Time: 0.37, lr: [0.009926904888351212], Loss: 2.379154, Acc:0.772526, Semantic loss: 0.892954, BCE loss: 0.622054, SB loss: 0.864146
2023-10-29 22:31:49,368 Epoch: [3/484] Iter:[470/495], Time: 0.37, lr: [0.009926528923817452], Loss: 2.380992, Acc:0.771783, Semantic loss: 0.894777, BCE loss: 0.621966, SB loss: 0.864249
2023-10-29 22:31:52,994 Epoch: [3/484] Iter:[480/495], Time: 0.37, lr: [0.009926152957701514], Loss: 2.387856, Acc:0.772064, Semantic loss: 0.898353, BCE loss: 0.623752, SB loss: 0.865751
2023-10-29 22:31:56,488 Epoch: [3/484] Iter:[490/495], Time: 0.37, lr: [0.009925776990003323], Loss: 2.385255, Acc:0.772192, Semantic loss: 0.896587, BCE loss: 0.624040, SB loss: 0.864628
2023-10-29 22:31:57,880 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:31:58,117 Loss: 4.648, MeanIU:  0.3188, Best_mIoU:  0.3188
2023-10-29 22:31:58,117 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01]
2023-10-29 22:32:00,198 Epoch: [4/484] Iter:[0/495], Time: 2.05, lr: [0.00992558900556086], Loss: 2.153292, Acc:0.740817, Semantic loss: 0.759857, BCE loss: 0.578934, SB loss: 0.814501
2023-10-29 22:32:03,970 Epoch: [4/484] Iter:[10/495], Time: 0.53, lr: [0.009925213035489154], Loss: 2.386591, Acc:0.744026, Semantic loss: 0.880183, BCE loss: 0.640947, SB loss: 0.865461
2023-10-29 22:32:07,733 Epoch: [4/484] Iter:[20/495], Time: 0.46, lr: [0.009924837063835009], Loss: 2.396756, Acc:0.744334, Semantic loss: 0.897803, BCE loss: 0.612518, SB loss: 0.886436
2023-10-29 22:32:11,478 Epoch: [4/484] Iter:[30/495], Time: 0.43, lr: [0.00992446109059836], Loss: 2.548669, Acc:0.748942, Semantic loss: 0.994740, BCE loss: 0.627866, SB loss: 0.926063
2023-10-29 22:32:15,222 Epoch: [4/484] Iter:[40/495], Time: 0.42, lr: [0.009924085115779125], Loss: 2.465642, Acc:0.746555, Semantic loss: 0.934286, BCE loss: 0.624193, SB loss: 0.907163
2023-10-29 22:32:18,899 Epoch: [4/484] Iter:[50/495], Time: 0.41, lr: [0.009923709139377236], Loss: 2.418102, Acc:0.756110, Semantic loss: 0.899600, BCE loss: 0.624976, SB loss: 0.893526
2023-10-29 22:32:22,590 Epoch: [4/484] Iter:[60/495], Time: 0.40, lr: [0.009923333161392617], Loss: 2.396771, Acc:0.756574, Semantic loss: 0.892028, BCE loss: 0.614657, SB loss: 0.890086
2023-10-29 22:32:26,177 Epoch: [4/484] Iter:[70/495], Time: 0.39, lr: [0.0099229571818252], Loss: 2.391303, Acc:0.756883, Semantic loss: 0.893803, BCE loss: 0.608853, SB loss: 0.888647
2023-10-29 22:32:29,854 Epoch: [4/484] Iter:[80/495], Time: 0.39, lr: [0.009922581200674905], Loss: 2.400168, Acc:0.757439, Semantic loss: 0.902968, BCE loss: 0.608793, SB loss: 0.888408
2023-10-29 22:32:33,575 Epoch: [4/484] Iter:[90/495], Time: 0.39, lr: [0.009922205217941661], Loss: 2.412591, Acc:0.762700, Semantic loss: 0.904356, BCE loss: 0.617811, SB loss: 0.890424
2023-10-29 22:32:37,247 Epoch: [4/484] Iter:[100/495], Time: 0.39, lr: [0.009921829233625395], Loss: 2.413075, Acc:0.767436, Semantic loss: 0.904947, BCE loss: 0.623492, SB loss: 0.884636
2023-10-29 22:32:41,033 Epoch: [4/484] Iter:[110/495], Time: 0.39, lr: [0.009921453247726036], Loss: 2.385887, Acc:0.771407, Semantic loss: 0.891402, BCE loss: 0.621330, SB loss: 0.873154
2023-10-29 22:32:44,709 Epoch: [4/484] Iter:[120/495], Time: 0.38, lr: [0.009921077260243508], Loss: 2.382725, Acc:0.772039, Semantic loss: 0.889243, BCE loss: 0.620200, SB loss: 0.873283
2023-10-29 22:32:48,513 Epoch: [4/484] Iter:[130/495], Time: 0.38, lr: [0.009920701271177735], Loss: 2.388521, Acc:0.769228, Semantic loss: 0.898036, BCE loss: 0.614902, SB loss: 0.875583
2023-10-29 22:32:52,298 Epoch: [4/484] Iter:[140/495], Time: 0.38, lr: [0.00992032528052865], Loss: 2.404855, Acc:0.766268, Semantic loss: 0.907333, BCE loss: 0.613388, SB loss: 0.884134
2023-10-29 22:32:56,095 Epoch: [4/484] Iter:[150/495], Time: 0.38, lr: [0.009919949288296176], Loss: 2.418714, Acc:0.765332, Semantic loss: 0.914139, BCE loss: 0.616349, SB loss: 0.888226
2023-10-29 22:32:59,715 Epoch: [4/484] Iter:[160/495], Time: 0.38, lr: [0.00991957329448024], Loss: 2.416355, Acc:0.766679, Semantic loss: 0.912199, BCE loss: 0.614171, SB loss: 0.889985
2023-10-29 22:33:03,372 Epoch: [4/484] Iter:[170/495], Time: 0.38, lr: [0.009919197299080768], Loss: 2.410716, Acc:0.766291, Semantic loss: 0.908424, BCE loss: 0.612945, SB loss: 0.889347
2023-10-29 22:33:07,018 Epoch: [4/484] Iter:[180/495], Time: 0.38, lr: [0.009918821302097688], Loss: 2.415514, Acc:0.765345, Semantic loss: 0.913705, BCE loss: 0.612021, SB loss: 0.889789
2023-10-29 22:33:10,738 Epoch: [4/484] Iter:[190/495], Time: 0.38, lr: [0.009918445303530926], Loss: 2.411808, Acc:0.763946, Semantic loss: 0.912087, BCE loss: 0.610892, SB loss: 0.888828
2023-10-29 22:33:14,462 Epoch: [4/484] Iter:[200/495], Time: 0.38, lr: [0.009918069303380407], Loss: 2.411174, Acc:0.763195, Semantic loss: 0.910480, BCE loss: 0.611609, SB loss: 0.889084
2023-10-29 22:33:18,208 Epoch: [4/484] Iter:[210/495], Time: 0.38, lr: [0.00991769330164606], Loss: 2.403926, Acc:0.762826, Semantic loss: 0.906901, BCE loss: 0.610888, SB loss: 0.886136
2023-10-29 22:33:21,840 Epoch: [4/484] Iter:[220/495], Time: 0.38, lr: [0.009917317298327814], Loss: 2.401915, Acc:0.764323, Semantic loss: 0.904990, BCE loss: 0.612103, SB loss: 0.884821
2023-10-29 22:33:25,473 Epoch: [4/484] Iter:[230/495], Time: 0.38, lr: [0.00991694129342559], Loss: 2.398274, Acc:0.764044, Semantic loss: 0.904079, BCE loss: 0.611736, SB loss: 0.882460
2023-10-29 22:33:29,131 Epoch: [4/484] Iter:[240/495], Time: 0.38, lr: [0.009916565286939318], Loss: 2.388164, Acc:0.763793, Semantic loss: 0.899609, BCE loss: 0.609160, SB loss: 0.879395
2023-10-29 22:33:32,892 Epoch: [4/484] Iter:[250/495], Time: 0.38, lr: [0.009916189278868922], Loss: 2.384697, Acc:0.763288, Semantic loss: 0.900123, BCE loss: 0.608688, SB loss: 0.875886
2023-10-29 22:33:36,635 Epoch: [4/484] Iter:[260/495], Time: 0.38, lr: [0.00991581326921433], Loss: 2.383959, Acc:0.764636, Semantic loss: 0.898924, BCE loss: 0.611468, SB loss: 0.873567
2023-10-29 22:33:40,212 Epoch: [4/484] Iter:[270/495], Time: 0.38, lr: [0.00991543725797547], Loss: 2.381403, Acc:0.764646, Semantic loss: 0.897961, BCE loss: 0.611546, SB loss: 0.871896
2023-10-29 22:33:43,931 Epoch: [4/484] Iter:[280/495], Time: 0.38, lr: [0.009915061245152268], Loss: 2.378128, Acc:0.764089, Semantic loss: 0.897925, BCE loss: 0.610062, SB loss: 0.870141
2023-10-29 22:33:47,678 Epoch: [4/484] Iter:[290/495], Time: 0.38, lr: [0.009914685230744649], Loss: 2.374480, Acc:0.765124, Semantic loss: 0.894474, BCE loss: 0.611310, SB loss: 0.868696
2023-10-29 22:33:51,406 Epoch: [4/484] Iter:[300/495], Time: 0.38, lr: [0.00991430921475254], Loss: 2.384899, Acc:0.764489, Semantic loss: 0.902054, BCE loss: 0.610673, SB loss: 0.872172
2023-10-29 22:33:55,066 Epoch: [4/484] Iter:[310/495], Time: 0.38, lr: [0.00991393319717587], Loss: 2.384035, Acc:0.764335, Semantic loss: 0.901079, BCE loss: 0.611740, SB loss: 0.871216
2023-10-29 22:33:58,694 Epoch: [4/484] Iter:[320/495], Time: 0.38, lr: [0.009913557178014563], Loss: 2.384368, Acc:0.763101, Semantic loss: 0.902265, BCE loss: 0.610355, SB loss: 0.871748
2023-10-29 22:34:02,367 Epoch: [4/484] Iter:[330/495], Time: 0.38, lr: [0.009913181157268544], Loss: 2.383804, Acc:0.763331, Semantic loss: 0.900192, BCE loss: 0.612513, SB loss: 0.871099
2023-10-29 22:34:06,030 Epoch: [4/484] Iter:[340/495], Time: 0.37, lr: [0.009912805134937743], Loss: 2.381305, Acc:0.764049, Semantic loss: 0.897841, BCE loss: 0.612330, SB loss: 0.871134
2023-10-29 22:34:09,779 Epoch: [4/484] Iter:[350/495], Time: 0.37, lr: [0.009912429111022086], Loss: 2.382369, Acc:0.764630, Semantic loss: 0.899273, BCE loss: 0.611134, SB loss: 0.871962
2023-10-29 22:34:13,488 Epoch: [4/484] Iter:[360/495], Time: 0.37, lr: [0.009912053085521498], Loss: 2.380429, Acc:0.765124, Semantic loss: 0.898025, BCE loss: 0.611747, SB loss: 0.870657
2023-10-29 22:34:17,248 Epoch: [4/484] Iter:[370/495], Time: 0.37, lr: [0.009911677058435906], Loss: 2.383479, Acc:0.766233, Semantic loss: 0.900075, BCE loss: 0.611745, SB loss: 0.871659
2023-10-29 22:34:20,858 Epoch: [4/484] Iter:[380/495], Time: 0.37, lr: [0.009911301029765238], Loss: 2.381776, Acc:0.767072, Semantic loss: 0.898105, BCE loss: 0.613203, SB loss: 0.870468
2023-10-29 22:34:24,614 Epoch: [4/484] Iter:[390/495], Time: 0.37, lr: [0.00991092499950942], Loss: 2.384037, Acc:0.768459, Semantic loss: 0.898290, BCE loss: 0.615159, SB loss: 0.870589
2023-10-29 22:34:28,372 Epoch: [4/484] Iter:[400/495], Time: 0.37, lr: [0.009910548967668374], Loss: 2.384468, Acc:0.768638, Semantic loss: 0.899127, BCE loss: 0.614927, SB loss: 0.870414
2023-10-29 22:34:32,116 Epoch: [4/484] Iter:[410/495], Time: 0.37, lr: [0.009910172934242033], Loss: 2.384693, Acc:0.769325, Semantic loss: 0.898862, BCE loss: 0.615694, SB loss: 0.870137
2023-10-29 22:34:35,803 Epoch: [4/484] Iter:[420/495], Time: 0.37, lr: [0.00990979689923032], Loss: 2.389670, Acc:0.769331, Semantic loss: 0.902848, BCE loss: 0.616105, SB loss: 0.870717
2023-10-29 22:34:39,479 Epoch: [4/484] Iter:[430/495], Time: 0.37, lr: [0.009909420862633163], Loss: 2.388653, Acc:0.768975, Semantic loss: 0.902989, BCE loss: 0.615867, SB loss: 0.869797
2023-10-29 22:34:43,080 Epoch: [4/484] Iter:[440/495], Time: 0.37, lr: [0.009909044824450486], Loss: 2.392713, Acc:0.768152, Semantic loss: 0.905385, BCE loss: 0.617066, SB loss: 0.870262
2023-10-29 22:34:46,762 Epoch: [4/484] Iter:[450/495], Time: 0.37, lr: [0.009908668784682217], Loss: 2.394366, Acc:0.767552, Semantic loss: 0.906915, BCE loss: 0.617126, SB loss: 0.870325
2023-10-29 22:34:50,366 Epoch: [4/484] Iter:[460/495], Time: 0.37, lr: [0.009908292743328285], Loss: 2.389809, Acc:0.767698, Semantic loss: 0.903976, BCE loss: 0.617449, SB loss: 0.868384
2023-10-29 22:34:54,078 Epoch: [4/484] Iter:[470/495], Time: 0.37, lr: [0.009907916700388613], Loss: 2.386162, Acc:0.768657, Semantic loss: 0.903517, BCE loss: 0.615567, SB loss: 0.867078
2023-10-29 22:34:57,766 Epoch: [4/484] Iter:[480/495], Time: 0.37, lr: [0.009907540655863127], Loss: 2.384446, Acc:0.769234, Semantic loss: 0.902180, BCE loss: 0.615241, SB loss: 0.867025
2023-10-29 22:35:01,308 Epoch: [4/484] Iter:[490/495], Time: 0.37, lr: [0.009907164609751756], Loss: 2.379457, Acc:0.770232, Semantic loss: 0.900282, BCE loss: 0.614062, SB loss: 0.865113
2023-10-29 22:35:02,703 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:35:02,950 Loss: 4.648, MeanIU:  0.3188, Best_mIoU:  0.3188
2023-10-29 22:35:02,950 [8.92282161e-01 5.17786996e-01 3.08672911e-01 3.51473520e-02
 2.83635424e-02 6.40102476e-02 4.05068142e-02 2.85914734e-01
 4.26429165e-01 2.82637702e-01 8.38741442e-01 5.86304477e-01
 2.68093594e-01 7.61882568e-01 0.00000000e+00 1.41045409e-01
 1.51232037e-05 5.43500582e-03 5.73706831e-01]
2023-10-29 22:35:04,851 Epoch: [5/484] Iter:[0/495], Time: 1.86, lr: [0.009906976586101339], Loss: 2.039046, Acc:0.693308, Semantic loss: 0.779886, BCE loss: 0.487457, SB loss: 0.771703
2023-10-29 22:35:08,984 Epoch: [5/484] Iter:[10/495], Time: 0.55, lr: [0.009906600537611], Loss: 2.236344, Acc:0.769326, Semantic loss: 0.817533, BCE loss: 0.599942, SB loss: 0.818869
2023-10-29 22:35:12,671 Epoch: [5/484] Iter:[20/495], Time: 0.46, lr: [0.009906224487534594], Loss: 2.176412, Acc:0.770070, Semantic loss: 0.778730, BCE loss: 0.601885, SB loss: 0.795797
2023-10-29 22:35:16,436 Epoch: [5/484] Iter:[30/495], Time: 0.43, lr: [0.009905848435872042], Loss: 2.214264, Acc:0.768505, Semantic loss: 0.796382, BCE loss: 0.606941, SB loss: 0.810941
2023-10-29 22:35:20,096 Epoch: [5/484] Iter:[40/495], Time: 0.42, lr: [0.009905472382623272], Loss: 2.248795, Acc:0.772084, Semantic loss: 0.825430, BCE loss: 0.604258, SB loss: 0.819107
2023-10-29 22:35:23,839 Epoch: [5/484] Iter:[50/495], Time: 0.41, lr: [0.009905096327788212], Loss: 2.264705, Acc:0.781600, Semantic loss: 0.833927, BCE loss: 0.611298, SB loss: 0.819480
2023-10-29 22:35:27,522 Epoch: [5/484] Iter:[60/495], Time: 0.40, lr: [0.009904720271366787], Loss: 2.287444, Acc:0.777370, Semantic loss: 0.857126, BCE loss: 0.609692, SB loss: 0.820626
2023-10-29 22:35:31,199 Epoch: [5/484] Iter:[70/495], Time: 0.40, lr: [0.009904344213358925], Loss: 2.295337, Acc:0.776520, Semantic loss: 0.858144, BCE loss: 0.612951, SB loss: 0.824242
2023-10-29 22:35:34,912 Epoch: [5/484] Iter:[80/495], Time: 0.39, lr: [0.00990396815376455], Loss: 2.317142, Acc:0.781392, Semantic loss: 0.869283, BCE loss: 0.621697, SB loss: 0.826162
2023-10-29 22:35:38,607 Epoch: [5/484] Iter:[90/495], Time: 0.39, lr: [0.00990359209258359], Loss: 2.300001, Acc:0.783626, Semantic loss: 0.861452, BCE loss: 0.614774, SB loss: 0.823775
2023-10-29 22:35:42,274 Epoch: [5/484] Iter:[100/495], Time: 0.39, lr: [0.009903216029815972], Loss: 2.281585, Acc:0.778927, Semantic loss: 0.852527, BCE loss: 0.608995, SB loss: 0.820063
2023-10-29 22:35:45,973 Epoch: [5/484] Iter:[110/495], Time: 0.39, lr: [0.00990283996546162], Loss: 2.291900, Acc:0.780174, Semantic loss: 0.862957, BCE loss: 0.604774, SB loss: 0.824168
2023-10-29 22:35:49,678 Epoch: [5/484] Iter:[120/495], Time: 0.39, lr: [0.009902463899520464], Loss: 2.301471, Acc:0.777583, Semantic loss: 0.871038, BCE loss: 0.601673, SB loss: 0.828761
2023-10-29 22:35:53,328 Epoch: [5/484] Iter:[130/495], Time: 0.38, lr: [0.009902087831992425], Loss: 2.317406, Acc:0.776842, Semantic loss: 0.882874, BCE loss: 0.600973, SB loss: 0.833559
2023-10-29 22:35:57,060 Epoch: [5/484] Iter:[140/495], Time: 0.38, lr: [0.009901711762877434], Loss: 2.318473, Acc:0.775205, Semantic loss: 0.884179, BCE loss: 0.600036, SB loss: 0.834258
2023-10-29 22:36:00,876 Epoch: [5/484] Iter:[150/495], Time: 0.38, lr: [0.009901335692175415], Loss: 2.319098, Acc:0.775657, Semantic loss: 0.879733, BCE loss: 0.604877, SB loss: 0.834489
2023-10-29 22:36:04,562 Epoch: [5/484] Iter:[160/495], Time: 0.38, lr: [0.009900959619886296], Loss: 2.332008, Acc:0.775074, Semantic loss: 0.887473, BCE loss: 0.605132, SB loss: 0.839403
2023-10-29 22:36:08,299 Epoch: [5/484] Iter:[170/495], Time: 0.38, lr: [0.009900583546010004], Loss: 2.325887, Acc:0.774311, Semantic loss: 0.883907, BCE loss: 0.603169, SB loss: 0.838810
2023-10-29 22:36:12,004 Epoch: [5/484] Iter:[180/495], Time: 0.38, lr: [0.009900207470546462], Loss: 2.323260, Acc:0.774900, Semantic loss: 0.880052, BCE loss: 0.603739, SB loss: 0.839469
2023-10-29 22:36:15,791 Epoch: [5/484] Iter:[190/495], Time: 0.38, lr: [0.009899831393495597], Loss: 2.333587, Acc:0.775505, Semantic loss: 0.887115, BCE loss: 0.606373, SB loss: 0.840099
2023-10-29 22:36:19,449 Epoch: [5/484] Iter:[200/495], Time: 0.38, lr: [0.009899455314857338], Loss: 2.339014, Acc:0.777731, Semantic loss: 0.888659, BCE loss: 0.606603, SB loss: 0.843752
2023-10-29 22:36:23,263 Epoch: [5/484] Iter:[210/495], Time: 0.38, lr: [0.00989907923463161], Loss: 2.338713, Acc:0.777083, Semantic loss: 0.886250, BCE loss: 0.607546, SB loss: 0.844917
2023-10-29 22:36:26,929 Epoch: [5/484] Iter:[220/495], Time: 0.38, lr: [0.009898703152818336], Loss: 2.343854, Acc:0.776292, Semantic loss: 0.888752, BCE loss: 0.607198, SB loss: 0.847904
2023-10-29 22:36:30,562 Epoch: [5/484] Iter:[230/495], Time: 0.38, lr: [0.009898327069417446], Loss: 2.342918, Acc:0.775692, Semantic loss: 0.890259, BCE loss: 0.605964, SB loss: 0.846695
2023-10-29 22:36:34,201 Epoch: [5/484] Iter:[240/495], Time: 0.38, lr: [0.009897950984428867], Loss: 2.353943, Acc:0.773710, Semantic loss: 0.898023, BCE loss: 0.605297, SB loss: 0.850623
2023-10-29 22:36:37,905 Epoch: [5/484] Iter:[250/495], Time: 0.38, lr: [0.009897574897852524], Loss: 2.356294, Acc:0.770859, Semantic loss: 0.899936, BCE loss: 0.604711, SB loss: 0.851646
2023-10-29 22:36:41,635 Epoch: [5/484] Iter:[260/495], Time: 0.38, lr: [0.009897198809688342], Loss: 2.355134, Acc:0.770517, Semantic loss: 0.899714, BCE loss: 0.604272, SB loss: 0.851148
2023-10-29 22:36:45,442 Epoch: [5/484] Iter:[270/495], Time: 0.38, lr: [0.009896822719936247], Loss: 2.356703, Acc:0.771034, Semantic loss: 0.898035, BCE loss: 0.606568, SB loss: 0.852100
2023-10-29 22:36:49,368 Epoch: [5/484] Iter:[280/495], Time: 0.38, lr: [0.00989644662859617], Loss: 2.354512, Acc:0.770216, Semantic loss: 0.897205, BCE loss: 0.604441, SB loss: 0.852866
2023-10-29 22:36:53,119 Epoch: [5/484] Iter:[290/495], Time: 0.38, lr: [0.00989607053566803], Loss: 2.359087, Acc:0.770722, Semantic loss: 0.898352, BCE loss: 0.606235, SB loss: 0.854500
2023-10-29 22:36:56,825 Epoch: [5/484] Iter:[300/495], Time: 0.38, lr: [0.009895694441151761], Loss: 2.355350, Acc:0.769385, Semantic loss: 0.895473, BCE loss: 0.605306, SB loss: 0.854572
2023-10-29 22:37:00,702 Epoch: [5/484] Iter:[310/495], Time: 0.38, lr: [0.00989531834504728], Loss: 2.359465, Acc:0.769819, Semantic loss: 0.896656, BCE loss: 0.606404, SB loss: 0.856405
2023-10-29 22:37:04,459 Epoch: [5/484] Iter:[320/495], Time: 0.38, lr: [0.009894942247354524], Loss: 2.370675, Acc:0.770890, Semantic loss: 0.901449, BCE loss: 0.609605, SB loss: 0.859622
2023-10-29 22:37:08,295 Epoch: [5/484] Iter:[330/495], Time: 0.38, lr: [0.00989456614807341], Loss: 2.373253, Acc:0.769647, Semantic loss: 0.901650, BCE loss: 0.610880, SB loss: 0.860723
2023-10-29 22:37:12,126 Epoch: [5/484] Iter:[340/495], Time: 0.38, lr: [0.00989419004720387], Loss: 2.374621, Acc:0.768727, Semantic loss: 0.902164, BCE loss: 0.610175, SB loss: 0.862282
2023-10-29 22:37:15,889 Epoch: [5/484] Iter:[350/495], Time: 0.38, lr: [0.009893813944745825], Loss: 2.373379, Acc:0.768038, Semantic loss: 0.900824, BCE loss: 0.609812, SB loss: 0.862743
2023-10-29 22:37:19,633 Epoch: [5/484] Iter:[360/495], Time: 0.38, lr: [0.009893437840699206], Loss: 2.380469, Acc:0.767936, Semantic loss: 0.904376, BCE loss: 0.611522, SB loss: 0.864571
2023-10-29 22:37:23,519 Epoch: [5/484] Iter:[370/495], Time: 0.38, lr: [0.009893061735063938], Loss: 2.377544, Acc:0.767402, Semantic loss: 0.901453, BCE loss: 0.610941, SB loss: 0.865149
2023-10-29 22:37:27,310 Epoch: [5/484] Iter:[380/495], Time: 0.38, lr: [0.009892685627839947], Loss: 2.374154, Acc:0.766871, Semantic loss: 0.899533, BCE loss: 0.610184, SB loss: 0.864438
2023-10-29 22:37:31,126 Epoch: [5/484] Iter:[390/495], Time: 0.38, lr: [0.009892309519027156], Loss: 2.376623, Acc:0.766803, Semantic loss: 0.901639, BCE loss: 0.610439, SB loss: 0.864545
2023-10-29 22:37:35,002 Epoch: [5/484] Iter:[400/495], Time: 0.38, lr: [0.009891933408625498], Loss: 2.376955, Acc:0.766647, Semantic loss: 0.901393, BCE loss: 0.612198, SB loss: 0.863365
2023-10-29 22:37:38,789 Epoch: [5/484] Iter:[410/495], Time: 0.38, lr: [0.009891557296634892], Loss: 2.378995, Acc:0.766829, Semantic loss: 0.902255, BCE loss: 0.614338, SB loss: 0.862401
2023-10-29 22:37:42,674 Epoch: [5/484] Iter:[420/495], Time: 0.38, lr: [0.00989118118305527], Loss: 2.377184, Acc:0.767503, Semantic loss: 0.899624, BCE loss: 0.615641, SB loss: 0.861919
2023-10-29 22:37:46,475 Epoch: [5/484] Iter:[430/495], Time: 0.38, lr: [0.009890805067886553], Loss: 2.375317, Acc:0.767383, Semantic loss: 0.898195, BCE loss: 0.616158, SB loss: 0.860964
2023-10-29 22:37:50,282 Epoch: [5/484] Iter:[440/495], Time: 0.38, lr: [0.00989042895112867], Loss: 2.370058, Acc:0.766787, Semantic loss: 0.894930, BCE loss: 0.615346, SB loss: 0.859782
2023-10-29 22:37:54,079 Epoch: [5/484] Iter:[450/495], Time: 0.38, lr: [0.009890052832781547], Loss: 2.367270, Acc:0.766982, Semantic loss: 0.893683, BCE loss: 0.615164, SB loss: 0.858423
2023-10-29 22:37:57,865 Epoch: [5/484] Iter:[460/495], Time: 0.38, lr: [0.009889676712845111], Loss: 2.364843, Acc:0.766870, Semantic loss: 0.892577, BCE loss: 0.614703, SB loss: 0.857563
2023-10-29 22:38:01,660 Epoch: [5/484] Iter:[470/495], Time: 0.38, lr: [0.009889300591319285], Loss: 2.360116, Acc:0.767252, Semantic loss: 0.891099, BCE loss: 0.612644, SB loss: 0.856373
2023-10-29 22:38:05,411 Epoch: [5/484] Iter:[480/495], Time: 0.38, lr: [0.009888924468203998], Loss: 2.360324, Acc:0.767484, Semantic loss: 0.891315, BCE loss: 0.612540, SB loss: 0.856469
2023-10-29 22:38:09,023 Epoch: [5/484] Iter:[490/495], Time: 0.38, lr: [0.009888548343499176], Loss: 2.365231, Acc:0.766788, Semantic loss: 0.895646, BCE loss: 0.612742, SB loss: 0.856843
2023-10-29 22:41:01,390 0 [8.95787133e-01 4.32064204e-01 7.61580632e-01 6.49118338e-02
 9.48299181e-02 3.39559908e-01 3.26775533e-01 4.72422804e-01
 8.32835769e-01 3.13703689e-01 8.12723521e-01 4.12477702e-01
 3.78771980e-04 6.88326008e-01 2.46327725e-05 4.53197683e-03
 4.07054584e-04 1.17382067e-03 4.79831229e-01] 0.3649655864536376
2023-10-29 22:41:01,391 1 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804] 0.4990029451521876
2023-10-29 22:41:01,394 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:41:01,757 Loss: 2.409, MeanIU:  0.4990, Best_mIoU:  0.4990
2023-10-29 22:41:01,757 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804]
2023-10-29 22:41:03,999 Epoch: [6/484] Iter:[0/495], Time: 2.21, lr: [0.009888360280550665], Loss: 3.027719, Acc:0.749025, Semantic loss: 1.137862, BCE loss: 0.996001, SB loss: 0.893856
2023-10-29 22:41:07,928 Epoch: [6/484] Iter:[10/495], Time: 0.56, lr: [0.009887984153461399], Loss: 2.492366, Acc:0.761993, Semantic loss: 0.922983, BCE loss: 0.666262, SB loss: 0.903121
2023-10-29 22:41:11,487 Epoch: [6/484] Iter:[20/495], Time: 0.46, lr: [0.009887608024782415], Loss: 2.430249, Acc:0.786735, Semantic loss: 0.879139, BCE loss: 0.677628, SB loss: 0.873482
2023-10-29 22:41:15,038 Epoch: [6/484] Iter:[30/495], Time: 0.43, lr: [0.009887231894513635], Loss: 2.476309, Acc:0.773248, Semantic loss: 0.942465, BCE loss: 0.649898, SB loss: 0.883947
2023-10-29 22:41:18,676 Epoch: [6/484] Iter:[40/495], Time: 0.41, lr: [0.009886855762654986], Loss: 2.416105, Acc:0.778001, Semantic loss: 0.911290, BCE loss: 0.634675, SB loss: 0.870140
2023-10-29 22:41:22,189 Epoch: [6/484] Iter:[50/495], Time: 0.40, lr: [0.009886479629206394], Loss: 2.412411, Acc:0.779192, Semantic loss: 0.910945, BCE loss: 0.643869, SB loss: 0.857596
2023-10-29 22:41:25,822 Epoch: [6/484] Iter:[60/495], Time: 0.39, lr: [0.009886103494167787], Loss: 2.395892, Acc:0.778868, Semantic loss: 0.901111, BCE loss: 0.634294, SB loss: 0.860488
2023-10-29 22:41:29,284 Epoch: [6/484] Iter:[70/495], Time: 0.39, lr: [0.00988572735753909], Loss: 2.422927, Acc:0.775571, Semantic loss: 0.919063, BCE loss: 0.633251, SB loss: 0.870613
2023-10-29 22:41:32,828 Epoch: [6/484] Iter:[80/495], Time: 0.38, lr: [0.00988535121932023], Loss: 2.410983, Acc:0.774305, Semantic loss: 0.917265, BCE loss: 0.629944, SB loss: 0.863774
2023-10-29 22:41:36,372 Epoch: [6/484] Iter:[90/495], Time: 0.38, lr: [0.00988497507951113], Loss: 2.400281, Acc:0.773880, Semantic loss: 0.915096, BCE loss: 0.625243, SB loss: 0.859942
2023-10-29 22:41:39,980 Epoch: [6/484] Iter:[100/495], Time: 0.38, lr: [0.009884598938111718], Loss: 2.405919, Acc:0.773602, Semantic loss: 0.919279, BCE loss: 0.624895, SB loss: 0.861746
2023-10-29 22:41:43,556 Epoch: [6/484] Iter:[110/495], Time: 0.38, lr: [0.00988422279512192], Loss: 2.375392, Acc:0.774049, Semantic loss: 0.899387, BCE loss: 0.622865, SB loss: 0.853139
2023-10-29 22:41:47,222 Epoch: [6/484] Iter:[120/495], Time: 0.38, lr: [0.009883846650541664], Loss: 2.366177, Acc:0.776677, Semantic loss: 0.892161, BCE loss: 0.622464, SB loss: 0.851551
2023-10-29 22:41:50,820 Epoch: [6/484] Iter:[130/495], Time: 0.37, lr: [0.00988347050437087], Loss: 2.374997, Acc:0.781016, Semantic loss: 0.895603, BCE loss: 0.626214, SB loss: 0.853180
2023-10-29 22:41:54,440 Epoch: [6/484] Iter:[140/495], Time: 0.37, lr: [0.009883094356609471], Loss: 2.349167, Acc:0.781146, Semantic loss: 0.883133, BCE loss: 0.621800, SB loss: 0.844234
2023-10-29 22:41:58,053 Epoch: [6/484] Iter:[150/495], Time: 0.37, lr: [0.00988271820725739], Loss: 2.346190, Acc:0.779193, Semantic loss: 0.886509, BCE loss: 0.615161, SB loss: 0.844520
2023-10-29 22:42:01,724 Epoch: [6/484] Iter:[160/495], Time: 0.37, lr: [0.009882342056314554], Loss: 2.351677, Acc:0.776203, Semantic loss: 0.892053, BCE loss: 0.612884, SB loss: 0.846740
2023-10-29 22:42:05,464 Epoch: [6/484] Iter:[170/495], Time: 0.37, lr: [0.009881965903780885], Loss: 2.353444, Acc:0.774345, Semantic loss: 0.894661, BCE loss: 0.612412, SB loss: 0.846372
2023-10-29 22:42:09,101 Epoch: [6/484] Iter:[180/495], Time: 0.37, lr: [0.009881589749656314], Loss: 2.339291, Acc:0.773351, Semantic loss: 0.886570, BCE loss: 0.610429, SB loss: 0.842292
2023-10-29 22:42:12,850 Epoch: [6/484] Iter:[190/495], Time: 0.37, lr: [0.009881213593940766], Loss: 2.335299, Acc:0.772639, Semantic loss: 0.884799, BCE loss: 0.611983, SB loss: 0.838517
2023-10-29 22:42:16,496 Epoch: [6/484] Iter:[200/495], Time: 0.37, lr: [0.009880837436634165], Loss: 2.327413, Acc:0.773142, Semantic loss: 0.878921, BCE loss: 0.612683, SB loss: 0.835810
2023-10-29 22:42:20,096 Epoch: [6/484] Iter:[210/495], Time: 0.37, lr: [0.009880461277736436], Loss: 2.329380, Acc:0.774285, Semantic loss: 0.875759, BCE loss: 0.616142, SB loss: 0.837478
2023-10-29 22:42:23,754 Epoch: [6/484] Iter:[220/495], Time: 0.37, lr: [0.00988008511724751], Loss: 2.324670, Acc:0.774682, Semantic loss: 0.872851, BCE loss: 0.615748, SB loss: 0.836071
2023-10-29 22:42:27,398 Epoch: [6/484] Iter:[230/495], Time: 0.37, lr: [0.009879708955167309], Loss: 2.321297, Acc:0.773992, Semantic loss: 0.872083, BCE loss: 0.614778, SB loss: 0.834436
2023-10-29 22:42:31,082 Epoch: [6/484] Iter:[240/495], Time: 0.37, lr: [0.00987933279149576], Loss: 2.335044, Acc:0.774853, Semantic loss: 0.879001, BCE loss: 0.616185, SB loss: 0.839858
2023-10-29 22:42:34,660 Epoch: [6/484] Iter:[250/495], Time: 0.37, lr: [0.009878956626232787], Loss: 2.329348, Acc:0.775830, Semantic loss: 0.875480, BCE loss: 0.616240, SB loss: 0.837628
2023-10-29 22:42:38,353 Epoch: [6/484] Iter:[260/495], Time: 0.37, lr: [0.00987858045937832], Loss: 2.327465, Acc:0.776007, Semantic loss: 0.876078, BCE loss: 0.615133, SB loss: 0.836254
2023-10-29 22:42:42,195 Epoch: [6/484] Iter:[270/495], Time: 0.37, lr: [0.009878204290932282], Loss: 2.330791, Acc:0.775242, Semantic loss: 0.881238, BCE loss: 0.611978, SB loss: 0.837575
2023-10-29 22:42:45,848 Epoch: [6/484] Iter:[280/495], Time: 0.37, lr: [0.009877828120894598], Loss: 2.331556, Acc:0.776115, Semantic loss: 0.881845, BCE loss: 0.612094, SB loss: 0.837617
2023-10-29 22:42:49,464 Epoch: [6/484] Iter:[290/495], Time: 0.37, lr: [0.009877451949265197], Loss: 2.330830, Acc:0.775330, Semantic loss: 0.880781, BCE loss: 0.612178, SB loss: 0.837872
2023-10-29 22:42:53,131 Epoch: [6/484] Iter:[300/495], Time: 0.37, lr: [0.009877075776044004], Loss: 2.326707, Acc:0.776117, Semantic loss: 0.878425, BCE loss: 0.610378, SB loss: 0.837905
2023-10-29 22:42:56,825 Epoch: [6/484] Iter:[310/495], Time: 0.37, lr: [0.009876699601230943], Loss: 2.322540, Acc:0.776011, Semantic loss: 0.876529, BCE loss: 0.609473, SB loss: 0.836537
2023-10-29 22:43:00,578 Epoch: [6/484] Iter:[320/495], Time: 0.37, lr: [0.009876323424825941], Loss: 2.318425, Acc:0.776566, Semantic loss: 0.876692, BCE loss: 0.606940, SB loss: 0.834793
2023-10-29 22:43:04,360 Epoch: [6/484] Iter:[330/495], Time: 0.37, lr: [0.009875947246828927], Loss: 2.312250, Acc:0.776097, Semantic loss: 0.873897, BCE loss: 0.604157, SB loss: 0.834196
2023-10-29 22:43:08,003 Epoch: [6/484] Iter:[340/495], Time: 0.37, lr: [0.009875571067239821], Loss: 2.311595, Acc:0.775818, Semantic loss: 0.874931, BCE loss: 0.603125, SB loss: 0.833539
2023-10-29 22:43:11,660 Epoch: [6/484] Iter:[350/495], Time: 0.37, lr: [0.009875194886058553], Loss: 2.307097, Acc:0.775825, Semantic loss: 0.872877, BCE loss: 0.602105, SB loss: 0.832115
2023-10-29 22:43:15,454 Epoch: [6/484] Iter:[360/495], Time: 0.37, lr: [0.009874818703285045], Loss: 2.307426, Acc:0.776886, Semantic loss: 0.872017, BCE loss: 0.604134, SB loss: 0.831275
2023-10-29 22:43:19,070 Epoch: [6/484] Iter:[370/495], Time: 0.37, lr: [0.00987444251891923], Loss: 2.305614, Acc:0.776982, Semantic loss: 0.872550, BCE loss: 0.601128, SB loss: 0.831936
2023-10-29 22:43:22,704 Epoch: [6/484] Iter:[380/495], Time: 0.37, lr: [0.009874066332961028], Loss: 2.302427, Acc:0.775820, Semantic loss: 0.871989, BCE loss: 0.598782, SB loss: 0.831656
2023-10-29 22:43:26,507 Epoch: [6/484] Iter:[390/495], Time: 0.37, lr: [0.009873690145410365], Loss: 2.301211, Acc:0.777215, Semantic loss: 0.870239, BCE loss: 0.599943, SB loss: 0.831029
2023-10-29 22:43:30,130 Epoch: [6/484] Iter:[400/495], Time: 0.37, lr: [0.009873313956267168], Loss: 2.302560, Acc:0.776559, Semantic loss: 0.871092, BCE loss: 0.599645, SB loss: 0.831823
2023-10-29 22:43:33,947 Epoch: [6/484] Iter:[410/495], Time: 0.37, lr: [0.009872937765531364], Loss: 2.300732, Acc:0.775671, Semantic loss: 0.869414, BCE loss: 0.599598, SB loss: 0.831721
2023-10-29 22:43:37,731 Epoch: [6/484] Iter:[420/495], Time: 0.37, lr: [0.009872561573202878], Loss: 2.313979, Acc:0.775681, Semantic loss: 0.877941, BCE loss: 0.600169, SB loss: 0.835869
2023-10-29 22:43:41,481 Epoch: [6/484] Iter:[430/495], Time: 0.37, lr: [0.009872185379281636], Loss: 2.315684, Acc:0.776340, Semantic loss: 0.876971, BCE loss: 0.602481, SB loss: 0.836232
2023-10-29 22:43:45,202 Epoch: [6/484] Iter:[440/495], Time: 0.37, lr: [0.009871809183767562], Loss: 2.315324, Acc:0.775828, Semantic loss: 0.876759, BCE loss: 0.600919, SB loss: 0.837647
2023-10-29 22:43:48,916 Epoch: [6/484] Iter:[450/495], Time: 0.37, lr: [0.009871432986660584], Loss: 2.329344, Acc:0.774778, Semantic loss: 0.884055, BCE loss: 0.603519, SB loss: 0.841770
2023-10-29 22:43:52,664 Epoch: [6/484] Iter:[460/495], Time: 0.37, lr: [0.009871056787960627], Loss: 2.335705, Acc:0.774279, Semantic loss: 0.888494, BCE loss: 0.603301, SB loss: 0.843910
2023-10-29 22:43:56,313 Epoch: [6/484] Iter:[470/495], Time: 0.37, lr: [0.009870680587667617], Loss: 2.331680, Acc:0.774281, Semantic loss: 0.885707, BCE loss: 0.602632, SB loss: 0.843342
2023-10-29 22:44:00,130 Epoch: [6/484] Iter:[480/495], Time: 0.37, lr: [0.00987030438578148], Loss: 2.330480, Acc:0.773662, Semantic loss: 0.885833, BCE loss: 0.601096, SB loss: 0.843551
2023-10-29 22:44:03,611 Epoch: [6/484] Iter:[490/495], Time: 0.37, lr: [0.009869928182302142], Loss: 2.335679, Acc:0.773297, Semantic loss: 0.889786, BCE loss: 0.600914, SB loss: 0.844979
2023-10-29 22:44:05,027 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:44:05,269 Loss: 2.409, MeanIU:  0.4990, Best_mIoU:  0.4990
2023-10-29 22:44:05,269 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804]
2023-10-29 22:44:07,127 Epoch: [7/484] Iter:[0/495], Time: 1.82, lr: [0.009869740079964998], Loss: 1.801063, Acc:0.766140, Semantic loss: 0.637972, BCE loss: 0.449804, SB loss: 0.713287
2023-10-29 22:44:11,140 Epoch: [7/484] Iter:[10/495], Time: 0.53, lr: [0.009869363874095718], Loss: 2.383285, Acc:0.757400, Semantic loss: 0.883229, BCE loss: 0.636535, SB loss: 0.863521
2023-10-29 22:44:14,742 Epoch: [7/484] Iter:[20/495], Time: 0.45, lr: [0.00986898766663305], Loss: 2.364059, Acc:0.763577, Semantic loss: 0.866305, BCE loss: 0.647040, SB loss: 0.850714
2023-10-29 22:44:18,372 Epoch: [7/484] Iter:[30/495], Time: 0.42, lr: [0.00986861145757692], Loss: 2.298753, Acc:0.754596, Semantic loss: 0.849983, BCE loss: 0.607648, SB loss: 0.841122
2023-10-29 22:44:22,036 Epoch: [7/484] Iter:[40/495], Time: 0.41, lr: [0.009868235246927256], Loss: 2.267948, Acc:0.766045, Semantic loss: 0.841242, BCE loss: 0.596416, SB loss: 0.830290
2023-10-29 22:44:25,683 Epoch: [7/484] Iter:[50/495], Time: 0.40, lr: [0.009867859034683983], Loss: 2.277412, Acc:0.771710, Semantic loss: 0.841798, BCE loss: 0.606724, SB loss: 0.828890
2023-10-29 22:44:29,421 Epoch: [7/484] Iter:[60/495], Time: 0.40, lr: [0.009867482820847024], Loss: 2.257291, Acc:0.768860, Semantic loss: 0.829564, BCE loss: 0.598291, SB loss: 0.829436
2023-10-29 22:44:33,162 Epoch: [7/484] Iter:[70/495], Time: 0.39, lr: [0.009867106605416308], Loss: 2.267109, Acc:0.769724, Semantic loss: 0.836486, BCE loss: 0.596289, SB loss: 0.834333
2023-10-29 22:44:36,975 Epoch: [7/484] Iter:[80/495], Time: 0.39, lr: [0.009866730388391757], Loss: 2.300437, Acc:0.773109, Semantic loss: 0.857507, BCE loss: 0.600859, SB loss: 0.842071
2023-10-29 22:44:40,776 Epoch: [7/484] Iter:[90/495], Time: 0.39, lr: [0.009866354169773302], Loss: 2.343844, Acc:0.769793, Semantic loss: 0.875350, BCE loss: 0.608502, SB loss: 0.859993
2023-10-29 22:44:44,481 Epoch: [7/484] Iter:[100/495], Time: 0.39, lr: [0.009865977949560864], Loss: 2.352392, Acc:0.768367, Semantic loss: 0.876784, BCE loss: 0.612281, SB loss: 0.863327
2023-10-29 22:44:48,234 Epoch: [7/484] Iter:[110/495], Time: 0.39, lr: [0.00986560172775437], Loss: 2.358049, Acc:0.769581, Semantic loss: 0.876348, BCE loss: 0.616212, SB loss: 0.865488
2023-10-29 22:44:51,918 Epoch: [7/484] Iter:[120/495], Time: 0.39, lr: [0.009865225504353748], Loss: 2.360515, Acc:0.769473, Semantic loss: 0.876415, BCE loss: 0.620632, SB loss: 0.863468
2023-10-29 22:44:55,606 Epoch: [7/484] Iter:[130/495], Time: 0.38, lr: [0.00986484927935892], Loss: 2.348418, Acc:0.771331, Semantic loss: 0.872535, BCE loss: 0.615146, SB loss: 0.860737
2023-10-29 22:44:59,337 Epoch: [7/484] Iter:[140/495], Time: 0.38, lr: [0.009864473052769815], Loss: 2.334127, Acc:0.773198, Semantic loss: 0.864379, BCE loss: 0.616697, SB loss: 0.853051
2023-10-29 22:45:03,119 Epoch: [7/484] Iter:[150/495], Time: 0.38, lr: [0.009864096824586357], Loss: 2.313662, Acc:0.772898, Semantic loss: 0.855379, BCE loss: 0.611605, SB loss: 0.846678
2023-10-29 22:45:06,850 Epoch: [7/484] Iter:[160/495], Time: 0.38, lr: [0.009863720594808471], Loss: 2.316511, Acc:0.774096, Semantic loss: 0.857692, BCE loss: 0.611110, SB loss: 0.847709
2023-10-29 22:45:10,505 Epoch: [7/484] Iter:[170/495], Time: 0.38, lr: [0.009863344363436085], Loss: 2.316016, Acc:0.775465, Semantic loss: 0.860283, BCE loss: 0.607666, SB loss: 0.848067
2023-10-29 22:45:14,183 Epoch: [7/484] Iter:[180/495], Time: 0.38, lr: [0.009862968130469123], Loss: 2.313460, Acc:0.774397, Semantic loss: 0.861682, BCE loss: 0.604718, SB loss: 0.847060
2023-10-29 22:45:17,956 Epoch: [7/484] Iter:[190/495], Time: 0.38, lr: [0.00986259189590751], Loss: 2.316714, Acc:0.774142, Semantic loss: 0.863723, BCE loss: 0.605739, SB loss: 0.847252
2023-10-29 22:45:21,648 Epoch: [7/484] Iter:[200/495], Time: 0.38, lr: [0.009862215659751174], Loss: 2.329025, Acc:0.773140, Semantic loss: 0.871579, BCE loss: 0.603280, SB loss: 0.854165
2023-10-29 22:45:25,362 Epoch: [7/484] Iter:[210/495], Time: 0.38, lr: [0.009861839422000038], Loss: 2.322809, Acc:0.773139, Semantic loss: 0.867163, BCE loss: 0.602482, SB loss: 0.853164
2023-10-29 22:45:29,063 Epoch: [7/484] Iter:[220/495], Time: 0.38, lr: [0.009861463182654028], Loss: 2.327727, Acc:0.771631, Semantic loss: 0.867979, BCE loss: 0.605920, SB loss: 0.853828
2023-10-29 22:45:32,791 Epoch: [7/484] Iter:[230/495], Time: 0.38, lr: [0.009861086941713072], Loss: 2.326833, Acc:0.772355, Semantic loss: 0.867317, BCE loss: 0.606777, SB loss: 0.852739
2023-10-29 22:45:36,516 Epoch: [7/484] Iter:[240/495], Time: 0.38, lr: [0.009860710699177095], Loss: 2.327297, Acc:0.771781, Semantic loss: 0.867113, BCE loss: 0.607683, SB loss: 0.852501
2023-10-29 22:45:40,226 Epoch: [7/484] Iter:[250/495], Time: 0.38, lr: [0.00986033445504602], Loss: 2.325419, Acc:0.771089, Semantic loss: 0.868059, BCE loss: 0.604951, SB loss: 0.852409
2023-10-29 22:45:43,859 Epoch: [7/484] Iter:[260/495], Time: 0.38, lr: [0.009859958209319775], Loss: 2.324633, Acc:0.770784, Semantic loss: 0.867893, BCE loss: 0.604509, SB loss: 0.852231
2023-10-29 22:45:47,687 Epoch: [7/484] Iter:[270/495], Time: 0.38, lr: [0.009859581961998284], Loss: 2.328013, Acc:0.772270, Semantic loss: 0.869735, BCE loss: 0.605374, SB loss: 0.852905
2023-10-29 22:45:51,400 Epoch: [7/484] Iter:[280/495], Time: 0.38, lr: [0.009859205713081475], Loss: 2.326189, Acc:0.773030, Semantic loss: 0.869523, BCE loss: 0.604401, SB loss: 0.852265
2023-10-29 22:45:55,081 Epoch: [7/484] Iter:[290/495], Time: 0.38, lr: [0.009858829462569272], Loss: 2.323815, Acc:0.772814, Semantic loss: 0.868664, BCE loss: 0.604076, SB loss: 0.851075
2023-10-29 22:45:58,794 Epoch: [7/484] Iter:[300/495], Time: 0.38, lr: [0.0098584532104616], Loss: 2.322796, Acc:0.772085, Semantic loss: 0.869231, BCE loss: 0.602334, SB loss: 0.851232
2023-10-29 22:46:02,560 Epoch: [7/484] Iter:[310/495], Time: 0.38, lr: [0.009858076956758385], Loss: 2.315051, Acc:0.772157, Semantic loss: 0.866161, BCE loss: 0.599710, SB loss: 0.849180
2023-10-29 22:46:06,180 Epoch: [7/484] Iter:[320/495], Time: 0.38, lr: [0.009857700701459552], Loss: 2.318568, Acc:0.771883, Semantic loss: 0.869422, BCE loss: 0.599724, SB loss: 0.849421
2023-10-29 22:46:09,884 Epoch: [7/484] Iter:[330/495], Time: 0.38, lr: [0.00985732444456503], Loss: 2.315483, Acc:0.769984, Semantic loss: 0.868823, BCE loss: 0.598751, SB loss: 0.847910
2023-10-29 22:46:13,691 Epoch: [7/484] Iter:[340/495], Time: 0.38, lr: [0.00985694818607474], Loss: 2.314788, Acc:0.770612, Semantic loss: 0.867823, BCE loss: 0.599823, SB loss: 0.847141
2023-10-29 22:46:17,439 Epoch: [7/484] Iter:[350/495], Time: 0.38, lr: [0.009856571925988612], Loss: 2.315812, Acc:0.771529, Semantic loss: 0.867134, BCE loss: 0.601553, SB loss: 0.847126
2023-10-29 22:46:21,253 Epoch: [7/484] Iter:[360/495], Time: 0.38, lr: [0.009856195664306566], Loss: 2.315368, Acc:0.772197, Semantic loss: 0.867590, BCE loss: 0.600440, SB loss: 0.847339
2023-10-29 22:46:25,077 Epoch: [7/484] Iter:[370/495], Time: 0.38, lr: [0.009855819401028533], Loss: 2.320685, Acc:0.771599, Semantic loss: 0.871383, BCE loss: 0.601729, SB loss: 0.847573
2023-10-29 22:46:28,769 Epoch: [7/484] Iter:[380/495], Time: 0.38, lr: [0.009855443136154433], Loss: 2.322609, Acc:0.770942, Semantic loss: 0.874755, BCE loss: 0.599719, SB loss: 0.848135
2023-10-29 22:46:32,538 Epoch: [7/484] Iter:[390/495], Time: 0.38, lr: [0.009855066869684199], Loss: 2.319048, Acc:0.771247, Semantic loss: 0.872635, BCE loss: 0.599099, SB loss: 0.847313
2023-10-29 22:46:36,306 Epoch: [7/484] Iter:[400/495], Time: 0.38, lr: [0.00985469060161775], Loss: 2.316529, Acc:0.772036, Semantic loss: 0.871839, BCE loss: 0.598038, SB loss: 0.846652
2023-10-29 22:46:40,041 Epoch: [7/484] Iter:[410/495], Time: 0.38, lr: [0.009854314331955013], Loss: 2.313122, Acc:0.772628, Semantic loss: 0.869229, BCE loss: 0.598585, SB loss: 0.845308
2023-10-29 22:46:43,762 Epoch: [7/484] Iter:[420/495], Time: 0.38, lr: [0.009853938060695913], Loss: 2.310109, Acc:0.773305, Semantic loss: 0.868331, BCE loss: 0.598260, SB loss: 0.843518
2023-10-29 22:46:47,409 Epoch: [7/484] Iter:[430/495], Time: 0.38, lr: [0.00985356178784038], Loss: 2.308852, Acc:0.773963, Semantic loss: 0.867736, BCE loss: 0.598108, SB loss: 0.843009
2023-10-29 22:46:51,155 Epoch: [7/484] Iter:[440/495], Time: 0.38, lr: [0.009853185513388334], Loss: 2.306574, Acc:0.773567, Semantic loss: 0.867346, BCE loss: 0.596282, SB loss: 0.842945
2023-10-29 22:46:54,872 Epoch: [7/484] Iter:[450/495], Time: 0.38, lr: [0.009852809237339704], Loss: 2.306070, Acc:0.773978, Semantic loss: 0.866809, BCE loss: 0.596542, SB loss: 0.842720
2023-10-29 22:46:58,533 Epoch: [7/484] Iter:[460/495], Time: 0.38, lr: [0.009852432959694414], Loss: 2.302867, Acc:0.774172, Semantic loss: 0.864946, BCE loss: 0.596509, SB loss: 0.841412
2023-10-29 22:47:02,336 Epoch: [7/484] Iter:[470/495], Time: 0.38, lr: [0.009852056680452389], Loss: 2.304528, Acc:0.773712, Semantic loss: 0.866392, BCE loss: 0.596965, SB loss: 0.841171
2023-10-29 22:47:06,137 Epoch: [7/484] Iter:[480/495], Time: 0.38, lr: [0.009851680399613554], Loss: 2.301999, Acc:0.773987, Semantic loss: 0.864616, BCE loss: 0.596897, SB loss: 0.840487
2023-10-29 22:47:09,665 Epoch: [7/484] Iter:[490/495], Time: 0.38, lr: [0.009851304117177837], Loss: 2.306143, Acc:0.774069, Semantic loss: 0.866682, BCE loss: 0.597625, SB loss: 0.841835
2023-10-29 22:47:11,082 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:47:11,321 Loss: 2.409, MeanIU:  0.4990, Best_mIoU:  0.4990
2023-10-29 22:47:11,322 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804]
2023-10-29 22:47:13,605 Epoch: [8/484] Iter:[0/495], Time: 2.25, lr: [0.009851115975361124], Loss: 2.306160, Acc:0.895052, Semantic loss: 0.704424, BCE loss: 0.815452, SB loss: 0.786285
2023-10-29 22:47:17,575 Epoch: [8/484] Iter:[10/495], Time: 0.57, lr: [0.009850739690529941], Loss: 2.310697, Acc:0.761992, Semantic loss: 0.796205, BCE loss: 0.662127, SB loss: 0.852365
2023-10-29 22:47:21,285 Epoch: [8/484] Iter:[20/495], Time: 0.47, lr: [0.009850363404101689], Loss: 2.281079, Acc:0.781398, Semantic loss: 0.808546, BCE loss: 0.647883, SB loss: 0.824650
2023-10-29 22:47:24,957 Epoch: [8/484] Iter:[30/495], Time: 0.44, lr: [0.009849987116076292], Loss: 2.300450, Acc:0.779718, Semantic loss: 0.853995, BCE loss: 0.626767, SB loss: 0.819688
2023-10-29 22:47:28,713 Epoch: [8/484] Iter:[40/495], Time: 0.42, lr: [0.009849610826453676], Loss: 2.283029, Acc:0.781101, Semantic loss: 0.848842, BCE loss: 0.614467, SB loss: 0.819721
2023-10-29 22:47:32,381 Epoch: [8/484] Iter:[50/495], Time: 0.41, lr: [0.009849234535233767], Loss: 2.258614, Acc:0.787367, Semantic loss: 0.832464, BCE loss: 0.615992, SB loss: 0.810158
2023-10-29 22:47:36,083 Epoch: [8/484] Iter:[60/495], Time: 0.41, lr: [0.00984885824241649], Loss: 2.285620, Acc:0.791736, Semantic loss: 0.855570, BCE loss: 0.617051, SB loss: 0.812999
2023-10-29 22:47:39,758 Epoch: [8/484] Iter:[70/495], Time: 0.40, lr: [0.00984848194800177], Loss: 2.256341, Acc:0.792395, Semantic loss: 0.837871, BCE loss: 0.613469, SB loss: 0.805002
2023-10-29 22:47:43,433 Epoch: [8/484] Iter:[80/495], Time: 0.40, lr: [0.009848105651989531], Loss: 2.269097, Acc:0.790732, Semantic loss: 0.841719, BCE loss: 0.619774, SB loss: 0.807604
2023-10-29 22:47:47,180 Epoch: [8/484] Iter:[90/495], Time: 0.39, lr: [0.009847729354379702], Loss: 2.274932, Acc:0.790315, Semantic loss: 0.846837, BCE loss: 0.614178, SB loss: 0.813918
2023-10-29 22:47:50,855 Epoch: [8/484] Iter:[100/495], Time: 0.39, lr: [0.009847353055172207], Loss: 2.287647, Acc:0.786798, Semantic loss: 0.854536, BCE loss: 0.612074, SB loss: 0.821036
2023-10-29 22:47:54,650 Epoch: [8/484] Iter:[110/495], Time: 0.39, lr: [0.00984697675436697], Loss: 2.280473, Acc:0.786865, Semantic loss: 0.848944, BCE loss: 0.611951, SB loss: 0.819577
2023-10-29 22:47:58,350 Epoch: [8/484] Iter:[120/495], Time: 0.39, lr: [0.009846600451963916], Loss: 2.260811, Acc:0.786198, Semantic loss: 0.838278, BCE loss: 0.607166, SB loss: 0.815368
2023-10-29 22:48:02,065 Epoch: [8/484] Iter:[130/495], Time: 0.39, lr: [0.009846224147962972], Loss: 2.263510, Acc:0.785347, Semantic loss: 0.838083, BCE loss: 0.612181, SB loss: 0.813245
2023-10-29 22:48:05,790 Epoch: [8/484] Iter:[140/495], Time: 0.39, lr: [0.009845847842364064], Loss: 2.263139, Acc:0.784476, Semantic loss: 0.842814, BCE loss: 0.605944, SB loss: 0.814382
2023-10-29 22:48:09,548 Epoch: [8/484] Iter:[150/495], Time: 0.39, lr: [0.009845471535167117], Loss: 2.271688, Acc:0.785247, Semantic loss: 0.848695, BCE loss: 0.608516, SB loss: 0.814478
2023-10-29 22:48:13,307 Epoch: [8/484] Iter:[160/495], Time: 0.38, lr: [0.009845095226372053], Loss: 2.265563, Acc:0.784729, Semantic loss: 0.842954, BCE loss: 0.608774, SB loss: 0.813835
2023-10-29 22:48:17,060 Epoch: [8/484] Iter:[170/495], Time: 0.38, lr: [0.0098447189159788], Loss: 2.264100, Acc:0.786494, Semantic loss: 0.842648, BCE loss: 0.609625, SB loss: 0.811826
2023-10-29 22:48:20,743 Epoch: [8/484] Iter:[180/495], Time: 0.38, lr: [0.009844342603987285], Loss: 2.292549, Acc:0.783773, Semantic loss: 0.862572, BCE loss: 0.606435, SB loss: 0.823542
2023-10-29 22:48:24,480 Epoch: [8/484] Iter:[190/495], Time: 0.38, lr: [0.009843966290397431], Loss: 2.290607, Acc:0.784558, Semantic loss: 0.859033, BCE loss: 0.605708, SB loss: 0.825866
2023-10-29 22:48:28,121 Epoch: [8/484] Iter:[200/495], Time: 0.38, lr: [0.009843589975209163], Loss: 2.291666, Acc:0.782645, Semantic loss: 0.861481, BCE loss: 0.602264, SB loss: 0.827921
2023-10-29 22:48:31,896 Epoch: [8/484] Iter:[210/495], Time: 0.38, lr: [0.00984321365842241], Loss: 2.290640, Acc:0.784311, Semantic loss: 0.859614, BCE loss: 0.602302, SB loss: 0.828723
2023-10-29 22:48:35,627 Epoch: [8/484] Iter:[220/495], Time: 0.38, lr: [0.009842837340037092], Loss: 2.288815, Acc:0.783505, Semantic loss: 0.858400, BCE loss: 0.602949, SB loss: 0.827465
2023-10-29 22:48:39,201 Epoch: [8/484] Iter:[230/495], Time: 0.38, lr: [0.009842461020053138], Loss: 2.294401, Acc:0.782159, Semantic loss: 0.864156, BCE loss: 0.601437, SB loss: 0.828809
2023-10-29 22:48:42,934 Epoch: [8/484] Iter:[240/495], Time: 0.38, lr: [0.009842084698470472], Loss: 2.288972, Acc:0.781744, Semantic loss: 0.862916, BCE loss: 0.598693, SB loss: 0.827363
2023-10-29 22:48:46,684 Epoch: [8/484] Iter:[250/495], Time: 0.38, lr: [0.00984170837528902], Loss: 2.289471, Acc:0.782052, Semantic loss: 0.861958, BCE loss: 0.598605, SB loss: 0.828908
2023-10-29 22:48:50,408 Epoch: [8/484] Iter:[260/495], Time: 0.38, lr: [0.009841332050508706], Loss: 2.286004, Acc:0.782839, Semantic loss: 0.860210, BCE loss: 0.597362, SB loss: 0.828433
2023-10-29 22:48:54,190 Epoch: [8/484] Iter:[270/495], Time: 0.38, lr: [0.009840955724129456], Loss: 2.286259, Acc:0.782805, Semantic loss: 0.860282, BCE loss: 0.598197, SB loss: 0.827780
2023-10-29 22:48:57,936 Epoch: [8/484] Iter:[280/495], Time: 0.38, lr: [0.009840579396151194], Loss: 2.289264, Acc:0.782806, Semantic loss: 0.861407, BCE loss: 0.598580, SB loss: 0.829277
2023-10-29 22:49:01,687 Epoch: [8/484] Iter:[290/495], Time: 0.38, lr: [0.009840203066573848], Loss: 2.292495, Acc:0.782458, Semantic loss: 0.862512, BCE loss: 0.601092, SB loss: 0.828892
2023-10-29 22:49:05,453 Epoch: [8/484] Iter:[300/495], Time: 0.38, lr: [0.009839826735397341], Loss: 2.286711, Acc:0.782364, Semantic loss: 0.858790, BCE loss: 0.599921, SB loss: 0.828000
2023-10-29 22:49:09,265 Epoch: [8/484] Iter:[310/495], Time: 0.38, lr: [0.0098394504026216], Loss: 2.288355, Acc:0.782610, Semantic loss: 0.860377, BCE loss: 0.600193, SB loss: 0.827785
2023-10-29 22:49:12,893 Epoch: [8/484] Iter:[320/495], Time: 0.38, lr: [0.009839074068246549], Loss: 2.289089, Acc:0.781896, Semantic loss: 0.860748, BCE loss: 0.599534, SB loss: 0.828806
2023-10-29 22:49:16,734 Epoch: [8/484] Iter:[330/495], Time: 0.38, lr: [0.009838697732272113], Loss: 2.284156, Acc:0.782195, Semantic loss: 0.858012, BCE loss: 0.599216, SB loss: 0.826929
2023-10-29 22:49:20,474 Epoch: [8/484] Iter:[340/495], Time: 0.38, lr: [0.009838321394698217], Loss: 2.286896, Acc:0.782158, Semantic loss: 0.859900, BCE loss: 0.598909, SB loss: 0.828088
2023-10-29 22:49:24,205 Epoch: [8/484] Iter:[350/495], Time: 0.38, lr: [0.00983794505552479], Loss: 2.292865, Acc:0.781495, Semantic loss: 0.864430, BCE loss: 0.598431, SB loss: 0.830004
2023-10-29 22:49:27,907 Epoch: [8/484] Iter:[360/495], Time: 0.38, lr: [0.00983756871475175], Loss: 2.293502, Acc:0.781730, Semantic loss: 0.864848, BCE loss: 0.598017, SB loss: 0.830637
2023-10-29 22:49:31,682 Epoch: [8/484] Iter:[370/495], Time: 0.38, lr: [0.009837192372379028], Loss: 2.295618, Acc:0.782198, Semantic loss: 0.865607, BCE loss: 0.598021, SB loss: 0.831989
2023-10-29 22:49:35,519 Epoch: [8/484] Iter:[380/495], Time: 0.38, lr: [0.00983681602840655], Loss: 2.295893, Acc:0.782608, Semantic loss: 0.866648, BCE loss: 0.597211, SB loss: 0.832034
2023-10-29 22:49:39,361 Epoch: [8/484] Iter:[390/495], Time: 0.38, lr: [0.009836439682834236], Loss: 2.291716, Acc:0.782325, Semantic loss: 0.864108, BCE loss: 0.596539, SB loss: 0.831070
2023-10-29 22:49:43,155 Epoch: [8/484] Iter:[400/495], Time: 0.38, lr: [0.009836063335662015], Loss: 2.286524, Acc:0.784110, Semantic loss: 0.860275, BCE loss: 0.597158, SB loss: 0.829090
2023-10-29 22:49:46,848 Epoch: [8/484] Iter:[410/495], Time: 0.38, lr: [0.009835686986889811], Loss: 2.286531, Acc:0.783683, Semantic loss: 0.860893, BCE loss: 0.596217, SB loss: 0.829421
2023-10-29 22:49:50,590 Epoch: [8/484] Iter:[420/495], Time: 0.38, lr: [0.009835310636517549], Loss: 2.287612, Acc:0.783239, Semantic loss: 0.862165, BCE loss: 0.595776, SB loss: 0.829671
2023-10-29 22:49:54,294 Epoch: [8/484] Iter:[430/495], Time: 0.38, lr: [0.009834934284545153], Loss: 2.288110, Acc:0.782294, Semantic loss: 0.862777, BCE loss: 0.595068, SB loss: 0.830265
2023-10-29 22:49:58,121 Epoch: [8/484] Iter:[440/495], Time: 0.38, lr: [0.009834557930972552], Loss: 2.288545, Acc:0.782366, Semantic loss: 0.862190, BCE loss: 0.596088, SB loss: 0.830268
2023-10-29 22:50:02,032 Epoch: [8/484] Iter:[450/495], Time: 0.38, lr: [0.009834181575799667], Loss: 2.288621, Acc:0.783169, Semantic loss: 0.862205, BCE loss: 0.595853, SB loss: 0.830563
2023-10-29 22:50:05,815 Epoch: [8/484] Iter:[460/495], Time: 0.38, lr: [0.009833805219026426], Loss: 2.287525, Acc:0.783596, Semantic loss: 0.861891, BCE loss: 0.595363, SB loss: 0.830272
2023-10-29 22:50:09,532 Epoch: [8/484] Iter:[470/495], Time: 0.38, lr: [0.009833428860652754], Loss: 2.288307, Acc:0.783444, Semantic loss: 0.862384, BCE loss: 0.595667, SB loss: 0.830256
2023-10-29 22:50:13,258 Epoch: [8/484] Iter:[480/495], Time: 0.38, lr: [0.009833052500678573], Loss: 2.287182, Acc:0.783829, Semantic loss: 0.861316, BCE loss: 0.596766, SB loss: 0.829099
2023-10-29 22:50:16,853 Epoch: [8/484] Iter:[490/495], Time: 0.38, lr: [0.009832676139103812], Loss: 2.286621, Acc:0.784017, Semantic loss: 0.861621, BCE loss: 0.596442, SB loss: 0.828557
2023-10-29 22:50:18,278 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:50:18,516 Loss: 2.409, MeanIU:  0.4990, Best_mIoU:  0.4990
2023-10-29 22:50:18,516 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804]
2023-10-29 22:50:20,318 Epoch: [9/484] Iter:[0/495], Time: 1.77, lr: [0.00983248795771619], Loss: 2.000528, Acc:0.600364, Semantic loss: 0.785557, BCE loss: 0.345186, SB loss: 0.869786
2023-10-29 22:50:24,360 Epoch: [9/484] Iter:[10/495], Time: 0.53, lr: [0.009832111593740415], Loss: 2.220631, Acc:0.774500, Semantic loss: 0.841660, BCE loss: 0.541501, SB loss: 0.837469
2023-10-29 22:50:28,116 Epoch: [9/484] Iter:[20/495], Time: 0.46, lr: [0.009831735228163871], Loss: 2.239157, Acc:0.793537, Semantic loss: 0.850636, BCE loss: 0.560683, SB loss: 0.827837
2023-10-29 22:50:31,888 Epoch: [9/484] Iter:[30/495], Time: 0.43, lr: [0.009831358860986485], Loss: 2.209043, Acc:0.769967, Semantic loss: 0.841324, BCE loss: 0.549622, SB loss: 0.818096
2023-10-29 22:50:35,615 Epoch: [9/484] Iter:[40/495], Time: 0.42, lr: [0.009830982492208179], Loss: 2.182626, Acc:0.779766, Semantic loss: 0.827675, BCE loss: 0.538535, SB loss: 0.816416
2023-10-29 22:50:39,363 Epoch: [9/484] Iter:[50/495], Time: 0.41, lr: [0.00983060612182888], Loss: 2.182429, Acc:0.779149, Semantic loss: 0.834109, BCE loss: 0.536290, SB loss: 0.812029
2023-10-29 22:50:43,085 Epoch: [9/484] Iter:[60/495], Time: 0.40, lr: [0.00983022974984851], Loss: 2.185435, Acc:0.779856, Semantic loss: 0.827958, BCE loss: 0.549425, SB loss: 0.808051
2023-10-29 22:50:46,898 Epoch: [9/484] Iter:[70/495], Time: 0.40, lr: [0.009829853376267001], Loss: 2.211830, Acc:0.782886, Semantic loss: 0.835337, BCE loss: 0.567089, SB loss: 0.809403
2023-10-29 22:50:50,607 Epoch: [9/484] Iter:[80/495], Time: 0.40, lr: [0.009829477001084271], Loss: 2.212047, Acc:0.785237, Semantic loss: 0.836613, BCE loss: 0.567111, SB loss: 0.808323
2023-10-29 22:50:54,331 Epoch: [9/484] Iter:[90/495], Time: 0.39, lr: [0.009829100624300247], Loss: 2.209656, Acc:0.783360, Semantic loss: 0.833701, BCE loss: 0.567440, SB loss: 0.808515
2023-10-29 22:50:58,193 Epoch: [9/484] Iter:[100/495], Time: 0.39, lr: [0.009828724245914857], Loss: 2.207803, Acc:0.782747, Semantic loss: 0.831157, BCE loss: 0.567989, SB loss: 0.808657
2023-10-29 22:51:02,014 Epoch: [9/484] Iter:[110/495], Time: 0.39, lr: [0.009828347865928023], Loss: 2.235585, Acc:0.781739, Semantic loss: 0.848368, BCE loss: 0.571702, SB loss: 0.815514
2023-10-29 22:51:05,817 Epoch: [9/484] Iter:[120/495], Time: 0.39, lr: [0.009827971484339669], Loss: 2.236631, Acc:0.781552, Semantic loss: 0.841667, BCE loss: 0.577737, SB loss: 0.817227
2023-10-29 22:51:09,693 Epoch: [9/484] Iter:[130/495], Time: 0.39, lr: [0.009827595101149724], Loss: 2.243679, Acc:0.781921, Semantic loss: 0.844199, BCE loss: 0.578896, SB loss: 0.820583
2023-10-29 22:51:13,393 Epoch: [9/484] Iter:[140/495], Time: 0.39, lr: [0.009827218716358109], Loss: 2.240865, Acc:0.781699, Semantic loss: 0.840596, BCE loss: 0.581694, SB loss: 0.818575
2023-10-29 22:51:17,263 Epoch: [9/484] Iter:[150/495], Time: 0.39, lr: [0.009826842329964754], Loss: 2.245854, Acc:0.781870, Semantic loss: 0.841622, BCE loss: 0.584105, SB loss: 0.820128
2023-10-29 22:51:21,087 Epoch: [9/484] Iter:[160/495], Time: 0.39, lr: [0.009826465941969578], Loss: 2.240573, Acc:0.781806, Semantic loss: 0.841209, BCE loss: 0.581711, SB loss: 0.817653
2023-10-29 22:51:24,742 Epoch: [9/484] Iter:[170/495], Time: 0.39, lr: [0.009826089552372512], Loss: 2.244611, Acc:0.781131, Semantic loss: 0.842887, BCE loss: 0.581283, SB loss: 0.820441
2023-10-29 22:51:28,493 Epoch: [9/484] Iter:[180/495], Time: 0.39, lr: [0.009825713161173474], Loss: 2.254812, Acc:0.782017, Semantic loss: 0.846691, BCE loss: 0.586479, SB loss: 0.821642
2023-10-29 22:51:32,189 Epoch: [9/484] Iter:[190/495], Time: 0.39, lr: [0.009825336768372396], Loss: 2.249395, Acc:0.784227, Semantic loss: 0.842338, BCE loss: 0.588810, SB loss: 0.818246
2023-10-29 22:51:36,085 Epoch: [9/484] Iter:[200/495], Time: 0.39, lr: [0.009824960373969198], Loss: 2.249699, Acc:0.783730, Semantic loss: 0.845264, BCE loss: 0.585285, SB loss: 0.819150
2023-10-29 22:51:39,874 Epoch: [9/484] Iter:[210/495], Time: 0.39, lr: [0.009824583977963808], Loss: 2.247288, Acc:0.783578, Semantic loss: 0.842722, BCE loss: 0.585162, SB loss: 0.819404
2023-10-29 22:51:43,647 Epoch: [9/484] Iter:[220/495], Time: 0.39, lr: [0.00982420758035615], Loss: 2.252193, Acc:0.783142, Semantic loss: 0.845746, BCE loss: 0.587876, SB loss: 0.818571
2023-10-29 22:51:47,362 Epoch: [9/484] Iter:[230/495], Time: 0.38, lr: [0.009823831181146148], Loss: 2.251884, Acc:0.783241, Semantic loss: 0.846986, BCE loss: 0.586062, SB loss: 0.818836
2023-10-29 22:51:51,250 Epoch: [9/484] Iter:[240/495], Time: 0.38, lr: [0.00982345478033373], Loss: 2.258510, Acc:0.782698, Semantic loss: 0.849302, BCE loss: 0.589469, SB loss: 0.819739
2023-10-29 22:51:54,956 Epoch: [9/484] Iter:[250/495], Time: 0.38, lr: [0.009823078377918817], Loss: 2.255911, Acc:0.783703, Semantic loss: 0.849183, BCE loss: 0.588274, SB loss: 0.818454
2023-10-29 22:51:58,840 Epoch: [9/484] Iter:[260/495], Time: 0.38, lr: [0.009822701973901336], Loss: 2.260441, Acc:0.783404, Semantic loss: 0.851520, BCE loss: 0.589511, SB loss: 0.819411
2023-10-29 22:52:02,631 Epoch: [9/484] Iter:[270/495], Time: 0.38, lr: [0.009822325568281212], Loss: 2.257234, Acc:0.782652, Semantic loss: 0.849527, BCE loss: 0.588873, SB loss: 0.818834
2023-10-29 22:52:06,581 Epoch: [9/484] Iter:[280/495], Time: 0.38, lr: [0.00982194916105837], Loss: 2.253127, Acc:0.782580, Semantic loss: 0.846701, BCE loss: 0.588359, SB loss: 0.818067
2023-10-29 22:52:10,269 Epoch: [9/484] Iter:[290/495], Time: 0.38, lr: [0.009821572752232733], Loss: 2.259031, Acc:0.782553, Semantic loss: 0.850050, BCE loss: 0.589581, SB loss: 0.819400
2023-10-29 22:52:14,101 Epoch: [9/484] Iter:[300/495], Time: 0.38, lr: [0.00982119634180423], Loss: 2.254756, Acc:0.781698, Semantic loss: 0.847785, BCE loss: 0.588848, SB loss: 0.818123
2023-10-29 22:52:17,961 Epoch: [9/484] Iter:[310/495], Time: 0.38, lr: [0.009820819929772781], Loss: 2.267076, Acc:0.780212, Semantic loss: 0.858629, BCE loss: 0.587355, SB loss: 0.821092
2023-10-29 22:52:21,734 Epoch: [9/484] Iter:[320/495], Time: 0.38, lr: [0.009820443516138314], Loss: 2.271515, Acc:0.779744, Semantic loss: 0.861728, BCE loss: 0.587993, SB loss: 0.821794
2023-10-29 22:52:25,408 Epoch: [9/484] Iter:[330/495], Time: 0.38, lr: [0.009820067100900755], Loss: 2.270229, Acc:0.778974, Semantic loss: 0.860305, BCE loss: 0.587779, SB loss: 0.822145
2023-10-29 22:52:29,158 Epoch: [9/484] Iter:[340/495], Time: 0.38, lr: [0.009819690684060025], Loss: 2.266814, Acc:0.778077, Semantic loss: 0.858361, BCE loss: 0.585786, SB loss: 0.822667
2023-10-29 22:52:33,046 Epoch: [9/484] Iter:[350/495], Time: 0.38, lr: [0.00981931426561605], Loss: 2.266033, Acc:0.777627, Semantic loss: 0.858536, BCE loss: 0.585285, SB loss: 0.822212
2023-10-29 22:52:36,959 Epoch: [9/484] Iter:[360/495], Time: 0.38, lr: [0.009818937845568759], Loss: 2.262649, Acc:0.778114, Semantic loss: 0.855347, BCE loss: 0.585576, SB loss: 0.821726
2023-10-29 22:52:40,833 Epoch: [9/484] Iter:[370/495], Time: 0.38, lr: [0.009818561423918072], Loss: 2.258909, Acc:0.778906, Semantic loss: 0.852442, BCE loss: 0.585881, SB loss: 0.820585
2023-10-29 22:52:44,700 Epoch: [9/484] Iter:[380/495], Time: 0.38, lr: [0.009818185000663915], Loss: 2.262588, Acc:0.778842, Semantic loss: 0.854342, BCE loss: 0.586368, SB loss: 0.821878
2023-10-29 22:52:48,509 Epoch: [9/484] Iter:[390/495], Time: 0.38, lr: [0.009817808575806216], Loss: 2.259050, Acc:0.779072, Semantic loss: 0.852915, BCE loss: 0.585250, SB loss: 0.820885
2023-10-29 22:52:52,414 Epoch: [9/484] Iter:[400/495], Time: 0.38, lr: [0.009817432149344895], Loss: 2.261263, Acc:0.778749, Semantic loss: 0.854300, BCE loss: 0.586339, SB loss: 0.820624
2023-10-29 22:52:56,442 Epoch: [9/484] Iter:[410/495], Time: 0.38, lr: [0.00981705572127988], Loss: 2.256546, Acc:0.778327, Semantic loss: 0.851310, BCE loss: 0.585703, SB loss: 0.819534
2023-10-29 22:53:00,359 Epoch: [9/484] Iter:[420/495], Time: 0.38, lr: [0.009816679291611093], Loss: 2.258618, Acc:0.779392, Semantic loss: 0.852426, BCE loss: 0.586130, SB loss: 0.820062
2023-10-29 22:53:04,208 Epoch: [9/484] Iter:[430/495], Time: 0.38, lr: [0.009816302860338464], Loss: 2.260125, Acc:0.779439, Semantic loss: 0.852646, BCE loss: 0.587637, SB loss: 0.819842
2023-10-29 22:53:07,985 Epoch: [9/484] Iter:[440/495], Time: 0.38, lr: [0.009815926427461914], Loss: 2.258786, Acc:0.779388, Semantic loss: 0.852461, BCE loss: 0.586747, SB loss: 0.819578
2023-10-29 22:53:11,779 Epoch: [9/484] Iter:[450/495], Time: 0.38, lr: [0.009815549992981369], Loss: 2.256340, Acc:0.779244, Semantic loss: 0.851770, BCE loss: 0.585805, SB loss: 0.818766
2023-10-29 22:53:15,571 Epoch: [9/484] Iter:[460/495], Time: 0.38, lr: [0.009815173556896751], Loss: 2.260981, Acc:0.778848, Semantic loss: 0.855353, BCE loss: 0.586153, SB loss: 0.819475
2023-10-29 22:53:19,327 Epoch: [9/484] Iter:[470/495], Time: 0.38, lr: [0.009814797119207989], Loss: 2.256551, Acc:0.779319, Semantic loss: 0.852528, BCE loss: 0.585260, SB loss: 0.818762
2023-10-29 22:53:23,339 Epoch: [9/484] Iter:[480/495], Time: 0.38, lr: [0.009814420679915005], Loss: 2.257985, Acc:0.779087, Semantic loss: 0.852968, BCE loss: 0.584257, SB loss: 0.820760
2023-10-29 22:53:26,963 Epoch: [9/484] Iter:[490/495], Time: 0.38, lr: [0.009814044239017725], Loss: 2.258321, Acc:0.778700, Semantic loss: 0.852175, BCE loss: 0.585205, SB loss: 0.820941
2023-10-29 22:53:28,393 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:53:28,640 Loss: 2.409, MeanIU:  0.4990, Best_mIoU:  0.4990
2023-10-29 22:53:28,641 [0.93932634 0.64853194 0.84415076 0.07363807 0.07241822 0.43607096
 0.51168526 0.63411606 0.86333425 0.39107454 0.9039966  0.57651359
 0.40851821 0.83692088 0.09685367 0.22693964 0.00853329 0.35088565
 0.65754804]
2023-10-29 22:53:30,917 Epoch: [10/484] Iter:[0/495], Time: 2.24, lr: [0.00981385601796745], Loss: 2.245132, Acc:0.865311, Semantic loss: 0.834244, BCE loss: 0.552680, SB loss: 0.858209
2023-10-29 22:53:35,034 Epoch: [10/484] Iter:[10/495], Time: 0.58, lr: [0.009813479574663586], Loss: 2.323085, Acc:0.827544, Semantic loss: 0.839156, BCE loss: 0.661583, SB loss: 0.822346
2023-10-29 22:53:38,965 Epoch: [10/484] Iter:[20/495], Time: 0.49, lr: [0.009813103129755236], Loss: 2.316654, Acc:0.818856, Semantic loss: 0.842331, BCE loss: 0.668727, SB loss: 0.805595
2023-10-29 22:53:42,735 Epoch: [10/484] Iter:[30/495], Time: 0.45, lr: [0.009812726683242326], Loss: 2.262702, Acc:0.820710, Semantic loss: 0.816142, BCE loss: 0.648793, SB loss: 0.797767
2023-10-29 22:53:46,431 Epoch: [10/484] Iter:[40/495], Time: 0.43, lr: [0.009812350235124783], Loss: 2.228700, Acc:0.825131, Semantic loss: 0.805812, BCE loss: 0.631672, SB loss: 0.791215
2023-10-29 22:53:50,121 Epoch: [10/484] Iter:[50/495], Time: 0.42, lr: [0.00981197378540253], Loss: 2.222759, Acc:0.815594, Semantic loss: 0.808015, BCE loss: 0.624469, SB loss: 0.790275
2023-10-29 22:53:53,821 Epoch: [10/484] Iter:[60/495], Time: 0.41, lr: [0.009811597334075491], Loss: 2.215015, Acc:0.809349, Semantic loss: 0.805418, BCE loss: 0.615463, SB loss: 0.794134
2023-10-29 22:53:57,631 Epoch: [10/484] Iter:[70/495], Time: 0.41, lr: [0.009811220881143591], Loss: 2.218097, Acc:0.806627, Semantic loss: 0.820440, BCE loss: 0.604615, SB loss: 0.793042
2023-10-29 22:54:01,713 Epoch: [10/484] Iter:[80/495], Time: 0.41, lr: [0.009810844426606754], Loss: 2.200696, Acc:0.803829, Semantic loss: 0.812091, BCE loss: 0.599867, SB loss: 0.788739
2023-10-29 22:54:05,720 Epoch: [10/484] Iter:[90/495], Time: 0.41, lr: [0.009810467970464908], Loss: 2.205643, Acc:0.803941, Semantic loss: 0.816707, BCE loss: 0.596176, SB loss: 0.792761
2023-10-29 22:54:09,567 Epoch: [10/484] Iter:[100/495], Time: 0.40, lr: [0.009810091512717976], Loss: 2.231895, Acc:0.803471, Semantic loss: 0.827116, BCE loss: 0.604876, SB loss: 0.799903
2023-10-29 22:54:13,303 Epoch: [10/484] Iter:[110/495], Time: 0.40, lr: [0.009809715053365881], Loss: 2.202111, Acc:0.795912, Semantic loss: 0.815236, BCE loss: 0.591491, SB loss: 0.795383
2023-10-29 22:54:17,010 Epoch: [10/484] Iter:[120/495], Time: 0.40, lr: [0.00980933859240855], Loss: 2.211168, Acc:0.794814, Semantic loss: 0.821403, BCE loss: 0.591166, SB loss: 0.798599
2023-10-29 22:54:20,732 Epoch: [10/484] Iter:[130/495], Time: 0.40, lr: [0.009808962129845906], Loss: 2.214390, Acc:0.793683, Semantic loss: 0.822495, BCE loss: 0.590893, SB loss: 0.801002
2023-10-29 22:54:24,480 Epoch: [10/484] Iter:[140/495], Time: 0.40, lr: [0.009808585665677876], Loss: 2.221356, Acc:0.793744, Semantic loss: 0.828949, BCE loss: 0.589635, SB loss: 0.802771
2023-10-29 22:54:28,249 Epoch: [10/484] Iter:[150/495], Time: 0.39, lr: [0.009808209199904383], Loss: 2.219704, Acc:0.791032, Semantic loss: 0.827469, BCE loss: 0.588356, SB loss: 0.803878
2023-10-29 22:54:32,003 Epoch: [10/484] Iter:[160/495], Time: 0.39, lr: [0.00980783273252535], Loss: 2.223695, Acc:0.791913, Semantic loss: 0.827692, BCE loss: 0.590368, SB loss: 0.805634
2023-10-29 22:54:35,730 Epoch: [10/484] Iter:[170/495], Time: 0.39, lr: [0.009807456263540706], Loss: 2.224917, Acc:0.792328, Semantic loss: 0.827814, BCE loss: 0.592753, SB loss: 0.804349
2023-10-29 22:54:39,404 Epoch: [10/484] Iter:[180/495], Time: 0.39, lr: [0.009807079792950372], Loss: 2.226641, Acc:0.792124, Semantic loss: 0.828967, BCE loss: 0.593778, SB loss: 0.803896
2023-10-29 22:54:43,207 Epoch: [10/484] Iter:[190/495], Time: 0.39, lr: [0.009806703320754274], Loss: 2.220005, Acc:0.791074, Semantic loss: 0.826210, BCE loss: 0.592101, SB loss: 0.801693
2023-10-29 22:54:47,146 Epoch: [10/484] Iter:[200/495], Time: 0.39, lr: [0.009806326846952335], Loss: 2.218743, Acc:0.792000, Semantic loss: 0.825319, BCE loss: 0.592159, SB loss: 0.801265
2023-10-29 22:54:50,846 Epoch: [10/484] Iter:[210/495], Time: 0.39, lr: [0.009805950371544483], Loss: 2.216055, Acc:0.790937, Semantic loss: 0.823734, BCE loss: 0.591731, SB loss: 0.800590
2023-10-29 22:54:54,665 Epoch: [10/484] Iter:[220/495], Time: 0.39, lr: [0.009805573894530642], Loss: 2.214857, Acc:0.789595, Semantic loss: 0.823534, BCE loss: 0.590712, SB loss: 0.800611
2023-10-29 22:54:58,380 Epoch: [10/484] Iter:[230/495], Time: 0.39, lr: [0.009805197415910735], Loss: 2.213268, Acc:0.789056, Semantic loss: 0.823072, BCE loss: 0.590800, SB loss: 0.799396
2023-10-29 22:55:02,093 Epoch: [10/484] Iter:[240/495], Time: 0.39, lr: [0.009804820935684685], Loss: 2.214244, Acc:0.789718, Semantic loss: 0.823259, BCE loss: 0.591562, SB loss: 0.799423
2023-10-29 22:55:05,797 Epoch: [10/484] Iter:[250/495], Time: 0.39, lr: [0.00980444445385242], Loss: 2.218572, Acc:0.789994, Semantic loss: 0.825279, BCE loss: 0.591218, SB loss: 0.802075
2023-10-29 22:55:09,481 Epoch: [10/484] Iter:[260/495], Time: 0.39, lr: [0.009804067970413862], Loss: 2.223594, Acc:0.789922, Semantic loss: 0.830129, BCE loss: 0.591366, SB loss: 0.802099
2023-10-29 22:55:13,334 Epoch: [10/484] Iter:[270/495], Time: 0.39, lr: [0.00980369148536894], Loss: 2.226035, Acc:0.790009, Semantic loss: 0.828647, BCE loss: 0.594747, SB loss: 0.802640
2023-10-29 22:55:17,133 Epoch: [10/484] Iter:[280/495], Time: 0.39, lr: [0.009803314998717573], Loss: 2.220963, Acc:0.790631, Semantic loss: 0.824958, BCE loss: 0.593040, SB loss: 0.802965
2023-10-29 22:55:20,855 Epoch: [10/484] Iter:[290/495], Time: 0.39, lr: [0.009802938510459687], Loss: 2.219420, Acc:0.790387, Semantic loss: 0.824187, BCE loss: 0.592439, SB loss: 0.802794
2023-10-29 22:55:24,616 Epoch: [10/484] Iter:[300/495], Time: 0.39, lr: [0.009802562020595212], Loss: 2.218971, Acc:0.790972, Semantic loss: 0.822536, BCE loss: 0.592306, SB loss: 0.804129
2023-10-29 22:55:28,375 Epoch: [10/484] Iter:[310/495], Time: 0.38, lr: [0.009802185529124065], Loss: 2.215870, Acc:0.789896, Semantic loss: 0.820913, BCE loss: 0.590856, SB loss: 0.804101
2023-10-29 22:55:32,304 Epoch: [10/484] Iter:[320/495], Time: 0.39, lr: [0.009801809036046175], Loss: 2.218696, Acc:0.790756, Semantic loss: 0.823817, BCE loss: 0.591694, SB loss: 0.803185
2023-10-29 22:55:36,034 Epoch: [10/484] Iter:[330/495], Time: 0.38, lr: [0.009801432541361467], Loss: 2.225431, Acc:0.790986, Semantic loss: 0.828128, BCE loss: 0.592789, SB loss: 0.804513
2023-10-29 22:55:39,779 Epoch: [10/484] Iter:[340/495], Time: 0.38, lr: [0.009801056045069862], Loss: 2.222895, Acc:0.790772, Semantic loss: 0.827615, BCE loss: 0.591730, SB loss: 0.803551
2023-10-29 22:55:43,571 Epoch: [10/484] Iter:[350/495], Time: 0.38, lr: [0.009800679547171285], Loss: 2.226921, Acc:0.790782, Semantic loss: 0.828533, BCE loss: 0.594329, SB loss: 0.804059
2023-10-29 22:55:47,256 Epoch: [10/484] Iter:[360/495], Time: 0.38, lr: [0.009800303047665665], Loss: 2.227951, Acc:0.790612, Semantic loss: 0.829342, BCE loss: 0.594322, SB loss: 0.804287
2023-10-29 22:55:50,952 Epoch: [10/484] Iter:[370/495], Time: 0.38, lr: [0.009799926546552923], Loss: 2.227485, Acc:0.790310, Semantic loss: 0.829600, BCE loss: 0.593952, SB loss: 0.803933
2023-10-29 22:55:54,727 Epoch: [10/484] Iter:[380/495], Time: 0.38, lr: [0.009799550043832985], Loss: 2.232820, Acc:0.790437, Semantic loss: 0.830972, BCE loss: 0.595877, SB loss: 0.805970
2023-10-29 22:55:58,451 Epoch: [10/484] Iter:[390/495], Time: 0.38, lr: [0.009799173539505773], Loss: 2.233097, Acc:0.789826, Semantic loss: 0.830302, BCE loss: 0.596383, SB loss: 0.806412
2023-10-29 22:56:02,257 Epoch: [10/484] Iter:[400/495], Time: 0.38, lr: [0.009798797033571213], Loss: 2.238877, Acc:0.790285, Semantic loss: 0.833542, BCE loss: 0.596106, SB loss: 0.809230
2023-10-29 22:56:06,038 Epoch: [10/484] Iter:[410/495], Time: 0.38, lr: [0.009798420526029233], Loss: 2.236923, Acc:0.790243, Semantic loss: 0.832731, BCE loss: 0.595553, SB loss: 0.808639
2023-10-29 22:56:09,818 Epoch: [10/484] Iter:[420/495], Time: 0.38, lr: [0.009798044016879752], Loss: 2.239945, Acc:0.790100, Semantic loss: 0.834754, BCE loss: 0.595400, SB loss: 0.809791
2023-10-29 22:56:13,597 Epoch: [10/484] Iter:[430/495], Time: 0.38, lr: [0.009797667506122695], Loss: 2.237845, Acc:0.789528, Semantic loss: 0.834475, BCE loss: 0.593252, SB loss: 0.810118
2023-10-29 22:56:17,397 Epoch: [10/484] Iter:[440/495], Time: 0.38, lr: [0.009797290993757991], Loss: 2.245678, Acc:0.790118, Semantic loss: 0.838352, BCE loss: 0.594893, SB loss: 0.812432
2023-10-29 22:56:21,250 Epoch: [10/484] Iter:[450/495], Time: 0.38, lr: [0.00979691447978556], Loss: 2.248193, Acc:0.789640, Semantic loss: 0.840534, BCE loss: 0.594589, SB loss: 0.813070
2023-10-29 22:56:25,044 Epoch: [10/484] Iter:[460/495], Time: 0.38, lr: [0.009796537964205333], Loss: 2.249730, Acc:0.789203, Semantic loss: 0.840748, BCE loss: 0.595383, SB loss: 0.813598
2023-10-29 22:56:28,728 Epoch: [10/484] Iter:[470/495], Time: 0.38, lr: [0.009796161447017223], Loss: 2.250066, Acc:0.789049, Semantic loss: 0.840503, BCE loss: 0.595486, SB loss: 0.814077
2023-10-29 22:56:32,455 Epoch: [10/484] Iter:[480/495], Time: 0.38, lr: [0.009795784928221165], Loss: 2.250158, Acc:0.788144, Semantic loss: 0.840125, BCE loss: 0.595078, SB loss: 0.814955
2023-10-29 22:56:36,009 Epoch: [10/484] Iter:[490/495], Time: 0.38, lr: [0.00979540840781708], Loss: 2.245643, Acc:0.788562, Semantic loss: 0.838114, BCE loss: 0.593606, SB loss: 0.813922
2023-10-29 22:59:32,903 0 [9.30980059e-01 6.00062231e-01 7.95921872e-01 6.40143455e-02
 1.11212500e-01 3.69915344e-01 4.39781103e-01 5.24287350e-01
 8.71907067e-01 4.47572925e-01 8.50548011e-01 4.83062476e-01
 6.22474676e-05 7.67636688e-01 0.00000000e+00 1.01980628e-02
 2.69420741e-02 2.62422902e-02 4.53066278e-01] 0.4091269959672466
2023-10-29 22:59:32,903 1 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959] 0.5969785979974611
2023-10-29 22:59:32,906 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 22:59:33,296 Loss: 2.246, MeanIU:  0.5970, Best_mIoU:  0.5970
2023-10-29 22:59:33,296 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959]
2023-10-29 22:59:35,286 Epoch: [11/484] Iter:[0/495], Time: 1.96, lr: [0.009795220147012004], Loss: 1.854068, Acc:0.689063, Semantic loss: 0.650726, BCE loss: 0.495151, SB loss: 0.708191
2023-10-29 22:59:39,167 Epoch: [11/484] Iter:[10/495], Time: 0.53, lr: [0.009794843624195734], Loss: 2.171042, Acc:0.786373, Semantic loss: 0.817231, BCE loss: 0.608114, SB loss: 0.745698
2023-10-29 22:59:42,738 Epoch: [11/484] Iter:[20/495], Time: 0.45, lr: [0.00979446709977125], Loss: 2.283066, Acc:0.779116, Semantic loss: 0.866965, BCE loss: 0.607030, SB loss: 0.809072
2023-10-29 22:59:46,214 Epoch: [11/484] Iter:[30/495], Time: 0.42, lr: [0.009794090573738472], Loss: 2.278048, Acc:0.782505, Semantic loss: 0.856599, BCE loss: 0.613167, SB loss: 0.808282
2023-10-29 22:59:49,949 Epoch: [11/484] Iter:[40/495], Time: 0.41, lr: [0.009793714046097328], Loss: 2.283314, Acc:0.780009, Semantic loss: 0.857353, BCE loss: 0.612016, SB loss: 0.813945
2023-10-29 22:59:53,409 Epoch: [11/484] Iter:[50/495], Time: 0.39, lr: [0.009793337516847743], Loss: 2.337383, Acc:0.778618, Semantic loss: 0.888051, BCE loss: 0.623133, SB loss: 0.826199
2023-10-29 22:59:57,037 Epoch: [11/484] Iter:[60/495], Time: 0.39, lr: [0.009792960985989637], Loss: 2.320596, Acc:0.776420, Semantic loss: 0.870444, BCE loss: 0.624683, SB loss: 0.825469
2023-10-29 23:00:00,665 Epoch: [11/484] Iter:[70/495], Time: 0.38, lr: [0.009792584453522936], Loss: 2.325497, Acc:0.778376, Semantic loss: 0.872672, BCE loss: 0.619378, SB loss: 0.833447
2023-10-29 23:00:04,250 Epoch: [11/484] Iter:[80/495], Time: 0.38, lr: [0.009792207919447567], Loss: 2.291143, Acc:0.783182, Semantic loss: 0.850076, BCE loss: 0.616345, SB loss: 0.824723
2023-10-29 23:00:07,899 Epoch: [11/484] Iter:[90/495], Time: 0.38, lr: [0.009791831383763452], Loss: 2.296352, Acc:0.789424, Semantic loss: 0.855001, BCE loss: 0.615030, SB loss: 0.826321
2023-10-29 23:00:11,548 Epoch: [11/484] Iter:[100/495], Time: 0.38, lr: [0.009791454846470518], Loss: 2.290160, Acc:0.786408, Semantic loss: 0.851770, BCE loss: 0.610235, SB loss: 0.828154
2023-10-29 23:00:15,181 Epoch: [11/484] Iter:[110/495], Time: 0.38, lr: [0.009791078307568686], Loss: 2.299366, Acc:0.785390, Semantic loss: 0.862669, BCE loss: 0.605845, SB loss: 0.830851
2023-10-29 23:00:18,889 Epoch: [11/484] Iter:[120/495], Time: 0.38, lr: [0.009790701767057883], Loss: 2.298810, Acc:0.784767, Semantic loss: 0.859021, BCE loss: 0.608409, SB loss: 0.831381
2023-10-29 23:00:22,554 Epoch: [11/484] Iter:[130/495], Time: 0.38, lr: [0.00979032522493803], Loss: 2.317526, Acc:0.783734, Semantic loss: 0.868800, BCE loss: 0.613898, SB loss: 0.834827
2023-10-29 23:00:26,145 Epoch: [11/484] Iter:[140/495], Time: 0.37, lr: [0.009789948681209054], Loss: 2.296758, Acc:0.782332, Semantic loss: 0.858667, BCE loss: 0.609151, SB loss: 0.828941
2023-10-29 23:00:29,761 Epoch: [11/484] Iter:[150/495], Time: 0.37, lr: [0.00978957213587088], Loss: 2.289673, Acc:0.784244, Semantic loss: 0.852461, BCE loss: 0.610604, SB loss: 0.826607
2023-10-29 23:00:33,478 Epoch: [11/484] Iter:[160/495], Time: 0.37, lr: [0.009789195588923431], Loss: 2.294235, Acc:0.782381, Semantic loss: 0.860777, BCE loss: 0.604744, SB loss: 0.828714
2023-10-29 23:00:37,125 Epoch: [11/484] Iter:[170/495], Time: 0.37, lr: [0.009788819040366633], Loss: 2.295231, Acc:0.781746, Semantic loss: 0.861108, BCE loss: 0.605834, SB loss: 0.828289
2023-10-29 23:00:40,776 Epoch: [11/484] Iter:[180/495], Time: 0.37, lr: [0.009788442490200406], Loss: 2.284519, Acc:0.783051, Semantic loss: 0.854253, BCE loss: 0.606679, SB loss: 0.823586
2023-10-29 23:00:44,390 Epoch: [11/484] Iter:[190/495], Time: 0.37, lr: [0.00978806593842468], Loss: 2.275897, Acc:0.782668, Semantic loss: 0.849436, BCE loss: 0.604767, SB loss: 0.821695
2023-10-29 23:00:48,113 Epoch: [11/484] Iter:[200/495], Time: 0.37, lr: [0.009787689385039376], Loss: 2.278521, Acc:0.782224, Semantic loss: 0.852014, BCE loss: 0.604007, SB loss: 0.822500
2023-10-29 23:00:51,841 Epoch: [11/484] Iter:[210/495], Time: 0.37, lr: [0.009787312830044416], Loss: 2.271997, Acc:0.779216, Semantic loss: 0.851201, BCE loss: 0.598773, SB loss: 0.822023
2023-10-29 23:00:55,540 Epoch: [11/484] Iter:[220/495], Time: 0.37, lr: [0.00978693627343973], Loss: 2.270539, Acc:0.778341, Semantic loss: 0.851013, BCE loss: 0.597627, SB loss: 0.821899
2023-10-29 23:00:59,226 Epoch: [11/484] Iter:[230/495], Time: 0.37, lr: [0.00978655971522524], Loss: 2.265653, Acc:0.778377, Semantic loss: 0.849163, BCE loss: 0.595676, SB loss: 0.820815
2023-10-29 23:01:02,968 Epoch: [11/484] Iter:[240/495], Time: 0.37, lr: [0.00978618315540087], Loss: 2.267599, Acc:0.779064, Semantic loss: 0.849841, BCE loss: 0.595636, SB loss: 0.822122
2023-10-29 23:01:06,798 Epoch: [11/484] Iter:[250/495], Time: 0.37, lr: [0.009785806593966542], Loss: 2.268015, Acc:0.779002, Semantic loss: 0.850841, BCE loss: 0.595492, SB loss: 0.821683
2023-10-29 23:01:10,497 Epoch: [11/484] Iter:[260/495], Time: 0.37, lr: [0.009785430030922183], Loss: 2.262969, Acc:0.779366, Semantic loss: 0.848109, BCE loss: 0.594539, SB loss: 0.820322
2023-10-29 23:01:14,164 Epoch: [11/484] Iter:[270/495], Time: 0.37, lr: [0.009785053466267719], Loss: 2.260778, Acc:0.780044, Semantic loss: 0.846395, BCE loss: 0.595642, SB loss: 0.818741
2023-10-29 23:01:17,901 Epoch: [11/484] Iter:[280/495], Time: 0.37, lr: [0.00978467690000307], Loss: 2.254066, Acc:0.779661, Semantic loss: 0.842921, BCE loss: 0.593495, SB loss: 0.817650
2023-10-29 23:01:21,556 Epoch: [11/484] Iter:[290/495], Time: 0.37, lr: [0.009784300332128161], Loss: 2.255043, Acc:0.780704, Semantic loss: 0.843267, BCE loss: 0.595266, SB loss: 0.816510
2023-10-29 23:01:25,187 Epoch: [11/484] Iter:[300/495], Time: 0.37, lr: [0.00978392376264292], Loss: 2.260375, Acc:0.779410, Semantic loss: 0.847868, BCE loss: 0.594875, SB loss: 0.817631
2023-10-29 23:01:28,953 Epoch: [11/484] Iter:[310/495], Time: 0.37, lr: [0.009783547191547268], Loss: 2.263682, Acc:0.778865, Semantic loss: 0.850664, BCE loss: 0.595051, SB loss: 0.817967
2023-10-29 23:01:32,689 Epoch: [11/484] Iter:[320/495], Time: 0.37, lr: [0.00978317061884113], Loss: 2.269012, Acc:0.778164, Semantic loss: 0.851194, BCE loss: 0.598526, SB loss: 0.819292
2023-10-29 23:01:36,333 Epoch: [11/484] Iter:[330/495], Time: 0.37, lr: [0.009782794044524428], Loss: 2.269787, Acc:0.778802, Semantic loss: 0.850315, BCE loss: 0.599871, SB loss: 0.819600
2023-10-29 23:01:40,066 Epoch: [11/484] Iter:[340/495], Time: 0.37, lr: [0.00978241746859709], Loss: 2.267345, Acc:0.778527, Semantic loss: 0.849000, BCE loss: 0.598326, SB loss: 0.820019
2023-10-29 23:01:43,733 Epoch: [11/484] Iter:[350/495], Time: 0.37, lr: [0.00978204089105904], Loss: 2.267995, Acc:0.777928, Semantic loss: 0.850990, BCE loss: 0.597569, SB loss: 0.819437
2023-10-29 23:01:47,495 Epoch: [11/484] Iter:[360/495], Time: 0.37, lr: [0.0097816643119102], Loss: 2.267654, Acc:0.778581, Semantic loss: 0.851831, BCE loss: 0.597152, SB loss: 0.818671
2023-10-29 23:01:51,154 Epoch: [11/484] Iter:[370/495], Time: 0.37, lr: [0.009781287731150494], Loss: 2.264865, Acc:0.778556, Semantic loss: 0.849625, BCE loss: 0.597164, SB loss: 0.818075
2023-10-29 23:01:54,877 Epoch: [11/484] Iter:[380/495], Time: 0.37, lr: [0.009780911148779848], Loss: 2.261854, Acc:0.778217, Semantic loss: 0.849809, BCE loss: 0.594877, SB loss: 0.817168
2023-10-29 23:01:58,596 Epoch: [11/484] Iter:[390/495], Time: 0.37, lr: [0.009780534564798184], Loss: 2.267224, Acc:0.777350, Semantic loss: 0.852842, BCE loss: 0.596167, SB loss: 0.818215
2023-10-29 23:02:02,444 Epoch: [11/484] Iter:[400/495], Time: 0.37, lr: [0.00978015797920543], Loss: 2.268083, Acc:0.778644, Semantic loss: 0.852434, BCE loss: 0.597134, SB loss: 0.818515
2023-10-29 23:02:06,266 Epoch: [11/484] Iter:[410/495], Time: 0.37, lr: [0.009779781392001505], Loss: 2.265835, Acc:0.778941, Semantic loss: 0.850630, BCE loss: 0.596788, SB loss: 0.818418
2023-10-29 23:02:10,099 Epoch: [11/484] Iter:[420/495], Time: 0.37, lr: [0.009779404803186339], Loss: 2.264884, Acc:0.779290, Semantic loss: 0.849483, BCE loss: 0.596641, SB loss: 0.818760
2023-10-29 23:02:13,798 Epoch: [11/484] Iter:[430/495], Time: 0.37, lr: [0.009779028212759852], Loss: 2.266849, Acc:0.779642, Semantic loss: 0.850230, BCE loss: 0.598480, SB loss: 0.818139
2023-10-29 23:02:17,469 Epoch: [11/484] Iter:[440/495], Time: 0.37, lr: [0.00977865162072197], Loss: 2.265913, Acc:0.779669, Semantic loss: 0.850639, BCE loss: 0.597757, SB loss: 0.817517
2023-10-29 23:02:21,185 Epoch: [11/484] Iter:[450/495], Time: 0.37, lr: [0.009778275027072614], Loss: 2.265593, Acc:0.779926, Semantic loss: 0.851307, BCE loss: 0.597459, SB loss: 0.816827
2023-10-29 23:02:24,865 Epoch: [11/484] Iter:[460/495], Time: 0.37, lr: [0.009777898431811713], Loss: 2.268865, Acc:0.778964, Semantic loss: 0.854872, BCE loss: 0.596669, SB loss: 0.817324
2023-10-29 23:02:28,575 Epoch: [11/484] Iter:[470/495], Time: 0.37, lr: [0.009777521834939188], Loss: 2.274595, Acc:0.778890, Semantic loss: 0.858417, BCE loss: 0.597432, SB loss: 0.818746
2023-10-29 23:02:32,281 Epoch: [11/484] Iter:[480/495], Time: 0.37, lr: [0.009777145236454964], Loss: 2.276599, Acc:0.778763, Semantic loss: 0.860035, BCE loss: 0.597432, SB loss: 0.819133
2023-10-29 23:02:35,924 Epoch: [11/484] Iter:[490/495], Time: 0.37, lr: [0.009776768636358964], Loss: 2.276905, Acc:0.779386, Semantic loss: 0.859283, BCE loss: 0.598049, SB loss: 0.819573
2023-10-29 23:02:37,362 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:02:37,605 Loss: 2.246, MeanIU:  0.5970, Best_mIoU:  0.5970
2023-10-29 23:02:37,605 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959]
2023-10-29 23:02:39,851 Epoch: [12/484] Iter:[0/495], Time: 2.21, lr: [0.009776580335706525], Loss: 2.092230, Acc:0.750289, Semantic loss: 0.769957, BCE loss: 0.556967, SB loss: 0.765306
2023-10-29 23:02:44,060 Epoch: [12/484] Iter:[10/495], Time: 0.58, lr: [0.00977620373319272], Loss: 2.485372, Acc:0.787427, Semantic loss: 0.965672, BCE loss: 0.644157, SB loss: 0.875543
2023-10-29 23:02:47,938 Epoch: [12/484] Iter:[20/495], Time: 0.49, lr: [0.009775827129066952], Loss: 2.340892, Acc:0.784606, Semantic loss: 0.889695, BCE loss: 0.615020, SB loss: 0.836177
2023-10-29 23:02:51,590 Epoch: [12/484] Iter:[30/495], Time: 0.45, lr: [0.009775450523329144], Loss: 2.288430, Acc:0.785532, Semantic loss: 0.867228, BCE loss: 0.596098, SB loss: 0.825104
2023-10-29 23:02:55,227 Epoch: [12/484] Iter:[40/495], Time: 0.43, lr: [0.009775073915979217], Loss: 2.291317, Acc:0.777812, Semantic loss: 0.861718, BCE loss: 0.609122, SB loss: 0.820477
2023-10-29 23:02:58,998 Epoch: [12/484] Iter:[50/495], Time: 0.42, lr: [0.0097746973070171], Loss: 2.281920, Acc:0.772149, Semantic loss: 0.861425, BCE loss: 0.604400, SB loss: 0.816095
2023-10-29 23:03:02,763 Epoch: [12/484] Iter:[60/495], Time: 0.41, lr: [0.009774320696442712], Loss: 2.267191, Acc:0.777395, Semantic loss: 0.847088, BCE loss: 0.608519, SB loss: 0.811585
2023-10-29 23:03:06,571 Epoch: [12/484] Iter:[70/495], Time: 0.41, lr: [0.009773944084255982], Loss: 2.268785, Acc:0.781501, Semantic loss: 0.845716, BCE loss: 0.609396, SB loss: 0.813673
2023-10-29 23:03:10,373 Epoch: [12/484] Iter:[80/495], Time: 0.40, lr: [0.00977356747045683], Loss: 2.247911, Acc:0.780109, Semantic loss: 0.840292, BCE loss: 0.596852, SB loss: 0.810766
2023-10-29 23:03:14,094 Epoch: [12/484] Iter:[90/495], Time: 0.40, lr: [0.009773190855045183], Loss: 2.247138, Acc:0.785023, Semantic loss: 0.841581, BCE loss: 0.596355, SB loss: 0.809202
2023-10-29 23:03:17,818 Epoch: [12/484] Iter:[100/495], Time: 0.40, lr: [0.009772814238020964], Loss: 2.238745, Acc:0.781909, Semantic loss: 0.839262, BCE loss: 0.588705, SB loss: 0.810778
2023-10-29 23:03:21,601 Epoch: [12/484] Iter:[110/495], Time: 0.40, lr: [0.009772437619384094], Loss: 2.247326, Acc:0.782046, Semantic loss: 0.848203, BCE loss: 0.586872, SB loss: 0.812252
2023-10-29 23:03:25,290 Epoch: [12/484] Iter:[120/495], Time: 0.39, lr: [0.009772060999134503], Loss: 2.261962, Acc:0.783382, Semantic loss: 0.854822, BCE loss: 0.587789, SB loss: 0.819351
2023-10-29 23:03:29,036 Epoch: [12/484] Iter:[130/495], Time: 0.39, lr: [0.009771684377272112], Loss: 2.251974, Acc:0.784505, Semantic loss: 0.849582, BCE loss: 0.585581, SB loss: 0.816811
2023-10-29 23:03:32,800 Epoch: [12/484] Iter:[140/495], Time: 0.39, lr: [0.009771307753796846], Loss: 2.261241, Acc:0.785216, Semantic loss: 0.854503, BCE loss: 0.587136, SB loss: 0.819601
2023-10-29 23:03:36,571 Epoch: [12/484] Iter:[150/495], Time: 0.39, lr: [0.009770931128708624], Loss: 2.267995, Acc:0.785769, Semantic loss: 0.856734, BCE loss: 0.590057, SB loss: 0.821204
2023-10-29 23:03:40,297 Epoch: [12/484] Iter:[160/495], Time: 0.39, lr: [0.009770554502007377], Loss: 2.261127, Acc:0.785031, Semantic loss: 0.854224, BCE loss: 0.587340, SB loss: 0.819563
2023-10-29 23:03:44,007 Epoch: [12/484] Iter:[170/495], Time: 0.39, lr: [0.009770177873693026], Loss: 2.261986, Acc:0.785845, Semantic loss: 0.852269, BCE loss: 0.589440, SB loss: 0.820278
2023-10-29 23:03:47,762 Epoch: [12/484] Iter:[180/495], Time: 0.39, lr: [0.009769801243765495], Loss: 2.258187, Acc:0.784284, Semantic loss: 0.851124, BCE loss: 0.587419, SB loss: 0.819644
2023-10-29 23:03:51,532 Epoch: [12/484] Iter:[190/495], Time: 0.39, lr: [0.009769424612224707], Loss: 2.253942, Acc:0.783939, Semantic loss: 0.850672, BCE loss: 0.584159, SB loss: 0.819111
2023-10-29 23:03:55,280 Epoch: [12/484] Iter:[200/495], Time: 0.39, lr: [0.009769047979070588], Loss: 2.264090, Acc:0.784044, Semantic loss: 0.857713, BCE loss: 0.583734, SB loss: 0.822643
2023-10-29 23:03:58,926 Epoch: [12/484] Iter:[210/495], Time: 0.39, lr: [0.009768671344303061], Loss: 2.272994, Acc:0.784305, Semantic loss: 0.861445, BCE loss: 0.587382, SB loss: 0.824168
2023-10-29 23:04:02,633 Epoch: [12/484] Iter:[220/495], Time: 0.38, lr: [0.00976829470792205], Loss: 2.266791, Acc:0.784555, Semantic loss: 0.857074, BCE loss: 0.586114, SB loss: 0.823603
2023-10-29 23:04:06,539 Epoch: [12/484] Iter:[230/495], Time: 0.38, lr: [0.00976791806992748], Loss: 2.270972, Acc:0.785883, Semantic loss: 0.858987, BCE loss: 0.588605, SB loss: 0.823380
2023-10-29 23:04:10,278 Epoch: [12/484] Iter:[240/495], Time: 0.38, lr: [0.009767541430319271], Loss: 2.270875, Acc:0.785207, Semantic loss: 0.861884, BCE loss: 0.586105, SB loss: 0.822885
2023-10-29 23:04:14,052 Epoch: [12/484] Iter:[250/495], Time: 0.38, lr: [0.009767164789097352], Loss: 2.273739, Acc:0.783571, Semantic loss: 0.864751, BCE loss: 0.586204, SB loss: 0.822784
2023-10-29 23:04:17,901 Epoch: [12/484] Iter:[260/495], Time: 0.38, lr: [0.009766788146261644], Loss: 2.280032, Acc:0.783351, Semantic loss: 0.866942, BCE loss: 0.589060, SB loss: 0.824029
2023-10-29 23:04:21,636 Epoch: [12/484] Iter:[270/495], Time: 0.38, lr: [0.00976641150181207], Loss: 2.278557, Acc:0.783254, Semantic loss: 0.863843, BCE loss: 0.590124, SB loss: 0.824591
2023-10-29 23:04:25,469 Epoch: [12/484] Iter:[280/495], Time: 0.38, lr: [0.009766034855748559], Loss: 2.275247, Acc:0.783340, Semantic loss: 0.861591, BCE loss: 0.589969, SB loss: 0.823687
2023-10-29 23:04:29,291 Epoch: [12/484] Iter:[290/495], Time: 0.38, lr: [0.00976565820807103], Loss: 2.277101, Acc:0.785204, Semantic loss: 0.861248, BCE loss: 0.592480, SB loss: 0.823373
2023-10-29 23:04:32,983 Epoch: [12/484] Iter:[300/495], Time: 0.38, lr: [0.009765281558779409], Loss: 2.279895, Acc:0.784385, Semantic loss: 0.864270, BCE loss: 0.592722, SB loss: 0.822903
2023-10-29 23:04:36,763 Epoch: [12/484] Iter:[310/495], Time: 0.38, lr: [0.009764904907873618], Loss: 2.276727, Acc:0.784453, Semantic loss: 0.862225, BCE loss: 0.591674, SB loss: 0.822827
2023-10-29 23:04:40,415 Epoch: [12/484] Iter:[320/495], Time: 0.38, lr: [0.009764528255353584], Loss: 2.278681, Acc:0.783609, Semantic loss: 0.864536, BCE loss: 0.591869, SB loss: 0.822276
2023-10-29 23:04:44,233 Epoch: [12/484] Iter:[330/495], Time: 0.38, lr: [0.00976415160121923], Loss: 2.278688, Acc:0.782419, Semantic loss: 0.864602, BCE loss: 0.592451, SB loss: 0.821635
2023-10-29 23:04:47,954 Epoch: [12/484] Iter:[340/495], Time: 0.38, lr: [0.009763774945470477], Loss: 2.278529, Acc:0.782043, Semantic loss: 0.863984, BCE loss: 0.591044, SB loss: 0.823501
2023-10-29 23:04:51,679 Epoch: [12/484] Iter:[350/495], Time: 0.38, lr: [0.009763398288107251], Loss: 2.278002, Acc:0.782997, Semantic loss: 0.862793, BCE loss: 0.591813, SB loss: 0.823396
2023-10-29 23:04:55,528 Epoch: [12/484] Iter:[360/495], Time: 0.38, lr: [0.009763021629129476], Loss: 2.270193, Acc:0.782348, Semantic loss: 0.859555, BCE loss: 0.588319, SB loss: 0.822319
2023-10-29 23:04:59,315 Epoch: [12/484] Iter:[370/495], Time: 0.38, lr: [0.009762644968537076], Loss: 2.271288, Acc:0.782908, Semantic loss: 0.859644, BCE loss: 0.589183, SB loss: 0.822461
2023-10-29 23:05:03,146 Epoch: [12/484] Iter:[380/495], Time: 0.38, lr: [0.009762268306329976], Loss: 2.272093, Acc:0.783402, Semantic loss: 0.860002, BCE loss: 0.589172, SB loss: 0.822919
2023-10-29 23:05:06,811 Epoch: [12/484] Iter:[390/495], Time: 0.38, lr: [0.009761891642508095], Loss: 2.280128, Acc:0.782822, Semantic loss: 0.865338, BCE loss: 0.591053, SB loss: 0.823736
2023-10-29 23:05:10,552 Epoch: [12/484] Iter:[400/495], Time: 0.38, lr: [0.009761514977071364], Loss: 2.273703, Acc:0.783276, Semantic loss: 0.861898, BCE loss: 0.589418, SB loss: 0.822388
2023-10-29 23:05:14,271 Epoch: [12/484] Iter:[410/495], Time: 0.38, lr: [0.009761138310019702], Loss: 2.267647, Acc:0.783508, Semantic loss: 0.857841, BCE loss: 0.588274, SB loss: 0.821533
2023-10-29 23:05:17,965 Epoch: [12/484] Iter:[420/495], Time: 0.38, lr: [0.009760761641353035], Loss: 2.269502, Acc:0.782690, Semantic loss: 0.860022, BCE loss: 0.586853, SB loss: 0.822627
2023-10-29 23:05:21,777 Epoch: [12/484] Iter:[430/495], Time: 0.38, lr: [0.009760384971071283], Loss: 2.264280, Acc:0.782327, Semantic loss: 0.857125, BCE loss: 0.585821, SB loss: 0.821333
2023-10-29 23:05:25,647 Epoch: [12/484] Iter:[440/495], Time: 0.38, lr: [0.009760008299174375], Loss: 2.267095, Acc:0.783246, Semantic loss: 0.857507, BCE loss: 0.587781, SB loss: 0.821808
2023-10-29 23:05:29,373 Epoch: [12/484] Iter:[450/495], Time: 0.38, lr: [0.009759631625662232], Loss: 2.268636, Acc:0.783276, Semantic loss: 0.858301, BCE loss: 0.588326, SB loss: 0.822008
2023-10-29 23:05:33,249 Epoch: [12/484] Iter:[460/495], Time: 0.38, lr: [0.009759254950534776], Loss: 2.269753, Acc:0.783348, Semantic loss: 0.859555, BCE loss: 0.588131, SB loss: 0.822067
2023-10-29 23:05:36,996 Epoch: [12/484] Iter:[470/495], Time: 0.38, lr: [0.009758878273791934], Loss: 2.268771, Acc:0.784309, Semantic loss: 0.858643, BCE loss: 0.588983, SB loss: 0.821146
2023-10-29 23:05:40,773 Epoch: [12/484] Iter:[480/495], Time: 0.38, lr: [0.00975850159543363], Loss: 2.266828, Acc:0.784391, Semantic loss: 0.857492, BCE loss: 0.588892, SB loss: 0.820444
2023-10-29 23:05:44,322 Epoch: [12/484] Iter:[490/495], Time: 0.38, lr: [0.009758124915459786], Loss: 2.270163, Acc:0.784017, Semantic loss: 0.859088, BCE loss: 0.589518, SB loss: 0.821556
2023-10-29 23:05:45,775 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:05:46,019 Loss: 2.246, MeanIU:  0.5970, Best_mIoU:  0.5970
2023-10-29 23:05:46,019 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959]
2023-10-29 23:05:48,070 Epoch: [13/484] Iter:[0/495], Time: 2.02, lr: [0.009757936574867013], Loss: 2.154431, Acc:0.809580, Semantic loss: 0.838605, BCE loss: 0.602224, SB loss: 0.713603
2023-10-29 23:05:52,091 Epoch: [13/484] Iter:[10/495], Time: 0.55, lr: [0.009757559892469717], Loss: 2.200815, Acc:0.795061, Semantic loss: 0.825617, BCE loss: 0.596390, SB loss: 0.778807
2023-10-29 23:05:55,848 Epoch: [13/484] Iter:[20/495], Time: 0.47, lr: [0.009757183208456692], Loss: 2.224173, Acc:0.801232, Semantic loss: 0.864508, BCE loss: 0.557325, SB loss: 0.802340
2023-10-29 23:05:59,635 Epoch: [13/484] Iter:[30/495], Time: 0.44, lr: [0.009756806522827859], Loss: 2.241699, Acc:0.801741, Semantic loss: 0.859376, BCE loss: 0.558189, SB loss: 0.824134
2023-10-29 23:06:03,340 Epoch: [13/484] Iter:[40/495], Time: 0.42, lr: [0.009756429835583145], Loss: 2.241690, Acc:0.787440, Semantic loss: 0.856997, BCE loss: 0.565547, SB loss: 0.819146
2023-10-29 23:06:06,997 Epoch: [13/484] Iter:[50/495], Time: 0.41, lr: [0.009756053146722472], Loss: 2.255963, Acc:0.781042, Semantic loss: 0.861876, BCE loss: 0.566964, SB loss: 0.827123
2023-10-29 23:06:10,743 Epoch: [13/484] Iter:[60/495], Time: 0.40, lr: [0.009755676456245763], Loss: 2.248126, Acc:0.778497, Semantic loss: 0.854703, BCE loss: 0.570334, SB loss: 0.823090
2023-10-29 23:06:14,504 Epoch: [13/484] Iter:[70/495], Time: 0.40, lr: [0.009755299764152944], Loss: 2.232497, Acc:0.779709, Semantic loss: 0.838269, BCE loss: 0.573364, SB loss: 0.820864
2023-10-29 23:06:18,283 Epoch: [13/484] Iter:[80/495], Time: 0.40, lr: [0.009754923070443938], Loss: 2.216146, Acc:0.778274, Semantic loss: 0.826191, BCE loss: 0.574090, SB loss: 0.815865
2023-10-29 23:06:22,035 Epoch: [13/484] Iter:[90/495], Time: 0.40, lr: [0.009754546375118666], Loss: 2.209574, Acc:0.779676, Semantic loss: 0.820134, BCE loss: 0.573284, SB loss: 0.816156
2023-10-29 23:06:25,727 Epoch: [13/484] Iter:[100/495], Time: 0.39, lr: [0.009754169678177054], Loss: 2.211350, Acc:0.781932, Semantic loss: 0.824403, BCE loss: 0.578052, SB loss: 0.808896
2023-10-29 23:06:29,481 Epoch: [13/484] Iter:[110/495], Time: 0.39, lr: [0.009753792979619029], Loss: 2.210303, Acc:0.781446, Semantic loss: 0.826366, BCE loss: 0.577642, SB loss: 0.806295
2023-10-29 23:06:33,214 Epoch: [13/484] Iter:[120/495], Time: 0.39, lr: [0.009753416279444508], Loss: 2.211374, Acc:0.778753, Semantic loss: 0.830520, BCE loss: 0.574861, SB loss: 0.805992
2023-10-29 23:06:37,112 Epoch: [13/484] Iter:[130/495], Time: 0.39, lr: [0.00975303957765342], Loss: 2.200763, Acc:0.780373, Semantic loss: 0.826870, BCE loss: 0.569997, SB loss: 0.803896
2023-10-29 23:06:40,843 Epoch: [13/484] Iter:[140/495], Time: 0.39, lr: [0.009752662874245685], Loss: 2.196737, Acc:0.781601, Semantic loss: 0.825528, BCE loss: 0.565498, SB loss: 0.805711
2023-10-29 23:06:44,497 Epoch: [13/484] Iter:[150/495], Time: 0.39, lr: [0.009752286169221231], Loss: 2.204718, Acc:0.779982, Semantic loss: 0.830552, BCE loss: 0.566261, SB loss: 0.807905
2023-10-29 23:06:48,375 Epoch: [13/484] Iter:[160/495], Time: 0.39, lr: [0.009751909462579976], Loss: 2.212640, Acc:0.779740, Semantic loss: 0.834072, BCE loss: 0.569924, SB loss: 0.808643
2023-10-29 23:06:52,122 Epoch: [13/484] Iter:[170/495], Time: 0.39, lr: [0.009751532754321848], Loss: 2.216301, Acc:0.779380, Semantic loss: 0.836531, BCE loss: 0.569838, SB loss: 0.809931
2023-10-29 23:06:55,863 Epoch: [13/484] Iter:[180/495], Time: 0.39, lr: [0.009751156044446771], Loss: 2.217783, Acc:0.778711, Semantic loss: 0.837792, BCE loss: 0.570097, SB loss: 0.809894
2023-10-29 23:06:59,576 Epoch: [13/484] Iter:[190/495], Time: 0.38, lr: [0.009750779332954665], Loss: 2.213639, Acc:0.778594, Semantic loss: 0.837220, BCE loss: 0.567536, SB loss: 0.808883
2023-10-29 23:07:03,419 Epoch: [13/484] Iter:[200/495], Time: 0.38, lr: [0.009750402619845456], Loss: 2.208182, Acc:0.779165, Semantic loss: 0.832662, BCE loss: 0.568159, SB loss: 0.807362
2023-10-29 23:07:07,305 Epoch: [13/484] Iter:[210/495], Time: 0.39, lr: [0.009750025905119067], Loss: 2.206766, Acc:0.779314, Semantic loss: 0.833291, BCE loss: 0.567037, SB loss: 0.806438
2023-10-29 23:07:11,157 Epoch: [13/484] Iter:[220/495], Time: 0.39, lr: [0.009749649188775423], Loss: 2.213641, Acc:0.781368, Semantic loss: 0.835934, BCE loss: 0.570084, SB loss: 0.807622
2023-10-29 23:07:14,995 Epoch: [13/484] Iter:[230/495], Time: 0.39, lr: [0.009749272470814446], Loss: 2.215865, Acc:0.781827, Semantic loss: 0.835376, BCE loss: 0.572229, SB loss: 0.808260
2023-10-29 23:07:18,731 Epoch: [13/484] Iter:[240/495], Time: 0.38, lr: [0.009748895751236062], Loss: 2.213713, Acc:0.782838, Semantic loss: 0.833645, BCE loss: 0.571871, SB loss: 0.808197
2023-10-29 23:07:22,508 Epoch: [13/484] Iter:[250/495], Time: 0.38, lr: [0.00974851903004019], Loss: 2.211826, Acc:0.783383, Semantic loss: 0.832118, BCE loss: 0.571854, SB loss: 0.807854
2023-10-29 23:07:26,161 Epoch: [13/484] Iter:[260/495], Time: 0.38, lr: [0.009748142307226757], Loss: 2.212351, Acc:0.784514, Semantic loss: 0.832568, BCE loss: 0.573289, SB loss: 0.806495
2023-10-29 23:07:29,986 Epoch: [13/484] Iter:[270/495], Time: 0.38, lr: [0.009747765582795689], Loss: 2.210110, Acc:0.785463, Semantic loss: 0.830748, BCE loss: 0.573604, SB loss: 0.805758
2023-10-29 23:07:33,753 Epoch: [13/484] Iter:[280/495], Time: 0.38, lr: [0.009747388856746904], Loss: 2.208648, Acc:0.785592, Semantic loss: 0.830721, BCE loss: 0.573401, SB loss: 0.804526
2023-10-29 23:07:37,573 Epoch: [13/484] Iter:[290/495], Time: 0.38, lr: [0.009747012129080327], Loss: 2.212091, Acc:0.784923, Semantic loss: 0.831706, BCE loss: 0.575368, SB loss: 0.805016
2023-10-29 23:07:41,347 Epoch: [13/484] Iter:[300/495], Time: 0.38, lr: [0.009746635399795884], Loss: 2.213941, Acc:0.786006, Semantic loss: 0.832289, BCE loss: 0.575729, SB loss: 0.805923
2023-10-29 23:07:45,088 Epoch: [13/484] Iter:[310/495], Time: 0.38, lr: [0.009746258668893499], Loss: 2.225474, Acc:0.785841, Semantic loss: 0.840601, BCE loss: 0.575882, SB loss: 0.808991
2023-10-29 23:07:48,843 Epoch: [13/484] Iter:[320/495], Time: 0.38, lr: [0.009745881936373092], Loss: 2.227180, Acc:0.787045, Semantic loss: 0.841715, BCE loss: 0.577521, SB loss: 0.807943
2023-10-29 23:07:52,554 Epoch: [13/484] Iter:[330/495], Time: 0.38, lr: [0.009745505202234588], Loss: 2.228376, Acc:0.787648, Semantic loss: 0.843555, BCE loss: 0.577212, SB loss: 0.807609
2023-10-29 23:07:56,270 Epoch: [13/484] Iter:[340/495], Time: 0.38, lr: [0.009745128466477912], Loss: 2.237561, Acc:0.786714, Semantic loss: 0.851419, BCE loss: 0.575959, SB loss: 0.810184
2023-10-29 23:07:59,965 Epoch: [13/484] Iter:[350/495], Time: 0.38, lr: [0.009744751729102987], Loss: 2.237995, Acc:0.787308, Semantic loss: 0.850845, BCE loss: 0.577070, SB loss: 0.810080
2023-10-29 23:08:03,811 Epoch: [13/484] Iter:[360/495], Time: 0.38, lr: [0.009744374990109736], Loss: 2.242011, Acc:0.787257, Semantic loss: 0.853726, BCE loss: 0.577815, SB loss: 0.810469
2023-10-29 23:08:07,546 Epoch: [13/484] Iter:[370/495], Time: 0.38, lr: [0.00974399824949808], Loss: 2.241617, Acc:0.787108, Semantic loss: 0.853402, BCE loss: 0.577573, SB loss: 0.810642
2023-10-29 23:08:11,248 Epoch: [13/484] Iter:[380/495], Time: 0.38, lr: [0.009743621507267947], Loss: 2.241836, Acc:0.786734, Semantic loss: 0.852572, BCE loss: 0.578316, SB loss: 0.810947
2023-10-29 23:08:14,988 Epoch: [13/484] Iter:[390/495], Time: 0.38, lr: [0.00974324476341926], Loss: 2.239302, Acc:0.786529, Semantic loss: 0.850087, BCE loss: 0.578992, SB loss: 0.810223
2023-10-29 23:08:18,798 Epoch: [13/484] Iter:[400/495], Time: 0.38, lr: [0.009742868017951942], Loss: 2.239403, Acc:0.786049, Semantic loss: 0.851071, BCE loss: 0.578298, SB loss: 0.810034
2023-10-29 23:08:22,609 Epoch: [13/484] Iter:[410/495], Time: 0.38, lr: [0.009742491270865912], Loss: 2.242696, Acc:0.785678, Semantic loss: 0.852271, BCE loss: 0.579747, SB loss: 0.810677
2023-10-29 23:08:26,438 Epoch: [13/484] Iter:[420/495], Time: 0.38, lr: [0.009742114522161099], Loss: 2.249941, Acc:0.785731, Semantic loss: 0.856740, BCE loss: 0.580492, SB loss: 0.812708
2023-10-29 23:08:30,242 Epoch: [13/484] Iter:[430/495], Time: 0.38, lr: [0.009741737771837424], Loss: 2.250417, Acc:0.784391, Semantic loss: 0.855762, BCE loss: 0.581780, SB loss: 0.812874
2023-10-29 23:08:34,034 Epoch: [13/484] Iter:[440/495], Time: 0.38, lr: [0.009741361019894812], Loss: 2.251059, Acc:0.783137, Semantic loss: 0.857554, BCE loss: 0.580921, SB loss: 0.812584
2023-10-29 23:08:37,776 Epoch: [13/484] Iter:[450/495], Time: 0.38, lr: [0.009740984266333184], Loss: 2.249365, Acc:0.782911, Semantic loss: 0.855476, BCE loss: 0.581675, SB loss: 0.812215
2023-10-29 23:08:41,524 Epoch: [13/484] Iter:[460/495], Time: 0.38, lr: [0.009740607511152468], Loss: 2.247708, Acc:0.783564, Semantic loss: 0.853684, BCE loss: 0.582033, SB loss: 0.811991
2023-10-29 23:08:45,194 Epoch: [13/484] Iter:[470/495], Time: 0.38, lr: [0.009740230754352581], Loss: 2.244423, Acc:0.782506, Semantic loss: 0.852150, BCE loss: 0.580852, SB loss: 0.811420
2023-10-29 23:08:49,112 Epoch: [13/484] Iter:[480/495], Time: 0.38, lr: [0.009739853995933452], Loss: 2.242743, Acc:0.782519, Semantic loss: 0.851074, BCE loss: 0.580795, SB loss: 0.810874
2023-10-29 23:08:52,664 Epoch: [13/484] Iter:[490/495], Time: 0.38, lr: [0.009739477235895001], Loss: 2.241870, Acc:0.782551, Semantic loss: 0.850066, BCE loss: 0.581510, SB loss: 0.810294
2023-10-29 23:08:54,071 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:08:54,331 Loss: 2.246, MeanIU:  0.5970, Best_mIoU:  0.5970
2023-10-29 23:08:54,331 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959]
2023-10-29 23:08:56,501 Epoch: [14/484] Iter:[0/495], Time: 2.13, lr: [0.009739288855268508], Loss: 1.893213, Acc:0.876814, Semantic loss: 0.656858, BCE loss: 0.532392, SB loss: 0.703963
2023-10-29 23:09:00,583 Epoch: [14/484] Iter:[10/495], Time: 0.57, lr: [0.009738912092800934], Loss: 2.159360, Acc:0.777238, Semantic loss: 0.797358, BCE loss: 0.577920, SB loss: 0.784083
2023-10-29 23:09:04,484 Epoch: [14/484] Iter:[20/495], Time: 0.48, lr: [0.009738535328713847], Loss: 2.129678, Acc:0.790938, Semantic loss: 0.788201, BCE loss: 0.548910, SB loss: 0.792567
2023-10-29 23:09:08,289 Epoch: [14/484] Iter:[30/495], Time: 0.45, lr: [0.00973815856300717], Loss: 2.259392, Acc:0.776545, Semantic loss: 0.871129, BCE loss: 0.569741, SB loss: 0.818522
2023-10-29 23:09:12,163 Epoch: [14/484] Iter:[40/495], Time: 0.43, lr: [0.009737781795680831], Loss: 2.326371, Acc:0.769683, Semantic loss: 0.905872, BCE loss: 0.587053, SB loss: 0.833446
2023-10-29 23:09:15,915 Epoch: [14/484] Iter:[50/495], Time: 0.42, lr: [0.00973740502673475], Loss: 2.313466, Acc:0.768645, Semantic loss: 0.893502, BCE loss: 0.592136, SB loss: 0.827828
2023-10-29 23:09:19,845 Epoch: [14/484] Iter:[60/495], Time: 0.42, lr: [0.009737028256168848], Loss: 2.299543, Acc:0.771255, Semantic loss: 0.880990, BCE loss: 0.596274, SB loss: 0.822279
2023-10-29 23:09:23,727 Epoch: [14/484] Iter:[70/495], Time: 0.41, lr: [0.009736651483983052], Loss: 2.299832, Acc:0.773883, Semantic loss: 0.874178, BCE loss: 0.597644, SB loss: 0.828009
2023-10-29 23:09:27,520 Epoch: [14/484] Iter:[80/495], Time: 0.41, lr: [0.009736274710177285], Loss: 2.271913, Acc:0.772992, Semantic loss: 0.856523, BCE loss: 0.593310, SB loss: 0.822081
2023-10-29 23:09:31,288 Epoch: [14/484] Iter:[90/495], Time: 0.41, lr: [0.009735897934751471], Loss: 2.274303, Acc:0.773006, Semantic loss: 0.855780, BCE loss: 0.598580, SB loss: 0.819943
2023-10-29 23:09:35,054 Epoch: [14/484] Iter:[100/495], Time: 0.40, lr: [0.00973552115770553], Loss: 2.259509, Acc:0.772388, Semantic loss: 0.848622, BCE loss: 0.594113, SB loss: 0.816774
2023-10-29 23:09:38,749 Epoch: [14/484] Iter:[110/495], Time: 0.40, lr: [0.009735144379039388], Loss: 2.250564, Acc:0.775800, Semantic loss: 0.847475, BCE loss: 0.587730, SB loss: 0.815358
2023-10-29 23:09:42,586 Epoch: [14/484] Iter:[120/495], Time: 0.40, lr: [0.009734767598752967], Loss: 2.247767, Acc:0.776019, Semantic loss: 0.850664, BCE loss: 0.581844, SB loss: 0.815259
2023-10-29 23:09:46,343 Epoch: [14/484] Iter:[130/495], Time: 0.40, lr: [0.009734390816846196], Loss: 2.254464, Acc:0.776807, Semantic loss: 0.853750, BCE loss: 0.585945, SB loss: 0.814769
2023-10-29 23:09:50,114 Epoch: [14/484] Iter:[140/495], Time: 0.40, lr: [0.009734014033318989], Loss: 2.250065, Acc:0.777969, Semantic loss: 0.852646, BCE loss: 0.584067, SB loss: 0.813352
2023-10-29 23:09:53,861 Epoch: [14/484] Iter:[150/495], Time: 0.39, lr: [0.009733637248171273], Loss: 2.243617, Acc:0.778969, Semantic loss: 0.849138, BCE loss: 0.583677, SB loss: 0.810802
2023-10-29 23:09:57,590 Epoch: [14/484] Iter:[160/495], Time: 0.39, lr: [0.009733260461402975], Loss: 2.248688, Acc:0.779147, Semantic loss: 0.854336, BCE loss: 0.580391, SB loss: 0.813960
2023-10-29 23:10:01,371 Epoch: [14/484] Iter:[170/495], Time: 0.39, lr: [0.009732883673014016], Loss: 2.237904, Acc:0.779030, Semantic loss: 0.849108, BCE loss: 0.577739, SB loss: 0.811057
2023-10-29 23:10:05,159 Epoch: [14/484] Iter:[180/495], Time: 0.39, lr: [0.009732506883004317], Loss: 2.233741, Acc:0.778573, Semantic loss: 0.848032, BCE loss: 0.577614, SB loss: 0.808095
2023-10-29 23:10:09,025 Epoch: [14/484] Iter:[190/495], Time: 0.39, lr: [0.009732130091373803], Loss: 2.231346, Acc:0.779691, Semantic loss: 0.845453, BCE loss: 0.577170, SB loss: 0.808723
2023-10-29 23:10:12,810 Epoch: [14/484] Iter:[200/495], Time: 0.39, lr: [0.009731753298122398], Loss: 2.231542, Acc:0.781008, Semantic loss: 0.844607, BCE loss: 0.577738, SB loss: 0.809197
2023-10-29 23:10:16,699 Epoch: [14/484] Iter:[210/495], Time: 0.39, lr: [0.009731376503250025], Loss: 2.232256, Acc:0.781743, Semantic loss: 0.846246, BCE loss: 0.578173, SB loss: 0.807837
2023-10-29 23:10:20,456 Epoch: [14/484] Iter:[220/495], Time: 0.39, lr: [0.009730999706756609], Loss: 2.227367, Acc:0.782225, Semantic loss: 0.843303, BCE loss: 0.576773, SB loss: 0.807291
2023-10-29 23:10:24,320 Epoch: [14/484] Iter:[230/495], Time: 0.39, lr: [0.009730622908642067], Loss: 2.227525, Acc:0.782849, Semantic loss: 0.841598, BCE loss: 0.579624, SB loss: 0.806303
2023-10-29 23:10:28,149 Epoch: [14/484] Iter:[240/495], Time: 0.39, lr: [0.00973024610890633], Loss: 2.229208, Acc:0.783852, Semantic loss: 0.840802, BCE loss: 0.582762, SB loss: 0.805643
2023-10-29 23:10:31,879 Epoch: [14/484] Iter:[250/495], Time: 0.39, lr: [0.009729869307549318], Loss: 2.229567, Acc:0.784530, Semantic loss: 0.839579, BCE loss: 0.584519, SB loss: 0.805468
2023-10-29 23:10:35,746 Epoch: [14/484] Iter:[260/495], Time: 0.39, lr: [0.009729492504570952], Loss: 2.220408, Acc:0.784754, Semantic loss: 0.834607, BCE loss: 0.581444, SB loss: 0.804357
2023-10-29 23:10:39,494 Epoch: [14/484] Iter:[270/495], Time: 0.39, lr: [0.00972911569997116], Loss: 2.221321, Acc:0.785061, Semantic loss: 0.835746, BCE loss: 0.580029, SB loss: 0.805546
2023-10-29 23:10:43,289 Epoch: [14/484] Iter:[280/495], Time: 0.39, lr: [0.00972873889374986], Loss: 2.221642, Acc:0.784928, Semantic loss: 0.836540, BCE loss: 0.578393, SB loss: 0.806709
2023-10-29 23:10:47,047 Epoch: [14/484] Iter:[290/495], Time: 0.39, lr: [0.009728362085906979], Loss: 2.220992, Acc:0.785217, Semantic loss: 0.836545, BCE loss: 0.578247, SB loss: 0.806200
2023-10-29 23:10:50,778 Epoch: [14/484] Iter:[300/495], Time: 0.39, lr: [0.00972798527644244], Loss: 2.225079, Acc:0.783824, Semantic loss: 0.841108, BCE loss: 0.578401, SB loss: 0.805570
2023-10-29 23:10:54,529 Epoch: [14/484] Iter:[310/495], Time: 0.39, lr: [0.009727608465356164], Loss: 2.224638, Acc:0.783431, Semantic loss: 0.841931, BCE loss: 0.578394, SB loss: 0.804312
2023-10-29 23:10:58,315 Epoch: [14/484] Iter:[320/495], Time: 0.39, lr: [0.009727231652648076], Loss: 2.225505, Acc:0.783161, Semantic loss: 0.842173, BCE loss: 0.579066, SB loss: 0.804267
2023-10-29 23:11:02,091 Epoch: [14/484] Iter:[330/495], Time: 0.39, lr: [0.009726854838318099], Loss: 2.225422, Acc:0.782549, Semantic loss: 0.841142, BCE loss: 0.578957, SB loss: 0.805323
2023-10-29 23:11:05,814 Epoch: [14/484] Iter:[340/495], Time: 0.39, lr: [0.009726478022366156], Loss: 2.225795, Acc:0.782337, Semantic loss: 0.841212, BCE loss: 0.578912, SB loss: 0.805671
2023-10-29 23:11:09,540 Epoch: [14/484] Iter:[350/495], Time: 0.39, lr: [0.009726101204792168], Loss: 2.227953, Acc:0.781262, Semantic loss: 0.844810, BCE loss: 0.577511, SB loss: 0.805632
2023-10-29 23:11:13,356 Epoch: [14/484] Iter:[360/495], Time: 0.38, lr: [0.009725724385596064], Loss: 2.231029, Acc:0.781137, Semantic loss: 0.846534, BCE loss: 0.578571, SB loss: 0.805924
2023-10-29 23:11:17,040 Epoch: [14/484] Iter:[370/495], Time: 0.38, lr: [0.009725347564777762], Loss: 2.234517, Acc:0.781528, Semantic loss: 0.848281, BCE loss: 0.580160, SB loss: 0.806077
2023-10-29 23:11:20,833 Epoch: [14/484] Iter:[380/495], Time: 0.38, lr: [0.009724970742337188], Loss: 2.231011, Acc:0.781861, Semantic loss: 0.845736, BCE loss: 0.579188, SB loss: 0.806087
2023-10-29 23:11:24,730 Epoch: [14/484] Iter:[390/495], Time: 0.38, lr: [0.009724593918274262], Loss: 2.229772, Acc:0.781756, Semantic loss: 0.846033, BCE loss: 0.578091, SB loss: 0.805648
2023-10-29 23:11:28,509 Epoch: [14/484] Iter:[400/495], Time: 0.38, lr: [0.009724217092588909], Loss: 2.228491, Acc:0.781647, Semantic loss: 0.845491, BCE loss: 0.577402, SB loss: 0.805597
2023-10-29 23:11:32,264 Epoch: [14/484] Iter:[410/495], Time: 0.38, lr: [0.009723840265281055], Loss: 2.222245, Acc:0.782781, Semantic loss: 0.841827, BCE loss: 0.577114, SB loss: 0.803304
2023-10-29 23:11:35,989 Epoch: [14/484] Iter:[420/495], Time: 0.38, lr: [0.009723463436350617], Loss: 2.218338, Acc:0.783362, Semantic loss: 0.840082, BCE loss: 0.576206, SB loss: 0.802050
2023-10-29 23:11:39,648 Epoch: [14/484] Iter:[430/495], Time: 0.38, lr: [0.009723086605797524], Loss: 2.224961, Acc:0.783063, Semantic loss: 0.845534, BCE loss: 0.575905, SB loss: 0.803522
2023-10-29 23:11:43,415 Epoch: [14/484] Iter:[440/495], Time: 0.38, lr: [0.009722709773621696], Loss: 2.225678, Acc:0.782680, Semantic loss: 0.845641, BCE loss: 0.575340, SB loss: 0.804697
2023-10-29 23:11:47,185 Epoch: [14/484] Iter:[450/495], Time: 0.38, lr: [0.009722332939823056], Loss: 2.225226, Acc:0.782871, Semantic loss: 0.842855, BCE loss: 0.576905, SB loss: 0.805466
2023-10-29 23:11:50,974 Epoch: [14/484] Iter:[460/495], Time: 0.38, lr: [0.009721956104401528], Loss: 2.226974, Acc:0.782906, Semantic loss: 0.843820, BCE loss: 0.577264, SB loss: 0.805891
2023-10-29 23:11:54,796 Epoch: [14/484] Iter:[470/495], Time: 0.38, lr: [0.009721579267357035], Loss: 2.225959, Acc:0.783446, Semantic loss: 0.843114, BCE loss: 0.576980, SB loss: 0.805865
2023-10-29 23:11:58,561 Epoch: [14/484] Iter:[480/495], Time: 0.38, lr: [0.009721202428689502], Loss: 2.221058, Acc:0.783369, Semantic loss: 0.839947, BCE loss: 0.576929, SB loss: 0.804182
2023-10-29 23:12:02,125 Epoch: [14/484] Iter:[490/495], Time: 0.38, lr: [0.00972082558839885], Loss: 2.222749, Acc:0.782616, Semantic loss: 0.840652, BCE loss: 0.577531, SB loss: 0.804565
2023-10-29 23:12:03,564 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:12:03,805 Loss: 2.246, MeanIU:  0.5970, Best_mIoU:  0.5970
2023-10-29 23:12:03,805 [0.96564549 0.7616704  0.8828955  0.35154767 0.39111574 0.47985872
 0.62006938 0.67616728 0.89869655 0.59296894 0.91513277 0.70714747
 0.49042479 0.90626764 0.47638834 0.08624594 0.15167549 0.29579567
 0.69287959]
2023-10-29 23:12:05,879 Epoch: [15/484] Iter:[0/495], Time: 2.04, lr: [0.00972063716764483], Loss: 1.954233, Acc:0.823867, Semantic loss: 0.702174, BCE loss: 0.510706, SB loss: 0.741353
2023-10-29 23:12:09,915 Epoch: [15/484] Iter:[10/495], Time: 0.55, lr: [0.009720260324919353], Loss: 2.020504, Acc:0.794314, Semantic loss: 0.740252, BCE loss: 0.534898, SB loss: 0.745353
2023-10-29 23:12:13,672 Epoch: [15/484] Iter:[20/495], Time: 0.47, lr: [0.009719883480570566], Loss: 2.075897, Acc:0.776165, Semantic loss: 0.772464, BCE loss: 0.525379, SB loss: 0.778054
2023-10-29 23:12:17,400 Epoch: [15/484] Iter:[30/495], Time: 0.44, lr: [0.009719506634598392], Loss: 2.155735, Acc:0.774448, Semantic loss: 0.825932, BCE loss: 0.544646, SB loss: 0.785157
2023-10-29 23:12:21,208 Epoch: [15/484] Iter:[40/495], Time: 0.42, lr: [0.009719129787002755], Loss: 2.195205, Acc:0.775947, Semantic loss: 0.843012, BCE loss: 0.553700, SB loss: 0.798494
2023-10-29 23:12:24,934 Epoch: [15/484] Iter:[50/495], Time: 0.41, lr: [0.009718752937783572], Loss: 2.167535, Acc:0.772086, Semantic loss: 0.832500, BCE loss: 0.539216, SB loss: 0.795819
2023-10-29 23:12:28,642 Epoch: [15/484] Iter:[60/495], Time: 0.41, lr: [0.009718376086940773], Loss: 2.198771, Acc:0.767698, Semantic loss: 0.854838, BCE loss: 0.541282, SB loss: 0.802650
2023-10-29 23:12:32,356 Epoch: [15/484] Iter:[70/495], Time: 0.40, lr: [0.009717999234474277], Loss: 2.205836, Acc:0.773209, Semantic loss: 0.848406, BCE loss: 0.552039, SB loss: 0.805392
2023-10-29 23:12:36,053 Epoch: [15/484] Iter:[80/495], Time: 0.40, lr: [0.00971762238038401], Loss: 2.221086, Acc:0.778930, Semantic loss: 0.852418, BCE loss: 0.560866, SB loss: 0.807802
2023-10-29 23:12:39,821 Epoch: [15/484] Iter:[90/495], Time: 0.40, lr: [0.00971724552466989], Loss: 2.217122, Acc:0.782819, Semantic loss: 0.844451, BCE loss: 0.565491, SB loss: 0.807181
2023-10-29 23:12:43,618 Epoch: [15/484] Iter:[100/495], Time: 0.39, lr: [0.009716868667331846], Loss: 2.226346, Acc:0.782927, Semantic loss: 0.843567, BCE loss: 0.573215, SB loss: 0.809564
2023-10-29 23:12:47,381 Epoch: [15/484] Iter:[110/495], Time: 0.39, lr: [0.009716491808369799], Loss: 2.215062, Acc:0.785124, Semantic loss: 0.837834, BCE loss: 0.572339, SB loss: 0.804889
2023-10-29 23:12:51,083 Epoch: [15/484] Iter:[120/495], Time: 0.39, lr: [0.009716114947783669], Loss: 2.228845, Acc:0.783891, Semantic loss: 0.844191, BCE loss: 0.575704, SB loss: 0.808950
2023-10-29 23:12:54,831 Epoch: [15/484] Iter:[130/495], Time: 0.39, lr: [0.009715738085573383], Loss: 2.227400, Acc:0.784743, Semantic loss: 0.841678, BCE loss: 0.575511, SB loss: 0.810211
2023-10-29 23:12:58,575 Epoch: [15/484] Iter:[140/495], Time: 0.39, lr: [0.009715361221738864], Loss: 2.234478, Acc:0.782622, Semantic loss: 0.845594, BCE loss: 0.575891, SB loss: 0.812993
2023-10-29 23:13:02,333 Epoch: [15/484] Iter:[150/495], Time: 0.39, lr: [0.009714984356280031], Loss: 2.233727, Acc:0.784400, Semantic loss: 0.844687, BCE loss: 0.576706, SB loss: 0.812334
2023-10-29 23:13:06,130 Epoch: [15/484] Iter:[160/495], Time: 0.39, lr: [0.00971460748919681], Loss: 2.227577, Acc:0.783679, Semantic loss: 0.843253, BCE loss: 0.573890, SB loss: 0.810433
2023-10-29 23:13:09,820 Epoch: [15/484] Iter:[170/495], Time: 0.39, lr: [0.009714230620489124], Loss: 2.220864, Acc:0.784931, Semantic loss: 0.835058, BCE loss: 0.577809, SB loss: 0.807997
2023-10-29 23:13:13,541 Epoch: [15/484] Iter:[180/495], Time: 0.39, lr: [0.009713853750156895], Loss: 2.219339, Acc:0.782458, Semantic loss: 0.835206, BCE loss: 0.575505, SB loss: 0.808628
2023-10-29 23:13:17,269 Epoch: [15/484] Iter:[190/495], Time: 0.38, lr: [0.009713476878200048], Loss: 2.215746, Acc:0.782831, Semantic loss: 0.831923, BCE loss: 0.574318, SB loss: 0.809505
2023-10-29 23:13:21,087 Epoch: [15/484] Iter:[200/495], Time: 0.38, lr: [0.0097131000046185], Loss: 2.221215, Acc:0.780793, Semantic loss: 0.835081, BCE loss: 0.574287, SB loss: 0.811847
2023-10-29 23:13:24,910 Epoch: [15/484] Iter:[210/495], Time: 0.38, lr: [0.009712723129412182], Loss: 2.222653, Acc:0.780607, Semantic loss: 0.837400, BCE loss: 0.572080, SB loss: 0.813174
2023-10-29 23:13:28,719 Epoch: [15/484] Iter:[220/495], Time: 0.38, lr: [0.009712346252581012], Loss: 2.234564, Acc:0.780623, Semantic loss: 0.843568, BCE loss: 0.575063, SB loss: 0.815933
2023-10-29 23:13:32,353 Epoch: [15/484] Iter:[230/495], Time: 0.38, lr: [0.009711969374124914], Loss: 2.231999, Acc:0.781763, Semantic loss: 0.842462, BCE loss: 0.574491, SB loss: 0.815046
2023-10-29 23:13:36,186 Epoch: [15/484] Iter:[240/495], Time: 0.38, lr: [0.009711592494043813], Loss: 2.230495, Acc:0.782007, Semantic loss: 0.842002, BCE loss: 0.574482, SB loss: 0.814012
2023-10-29 23:13:39,929 Epoch: [15/484] Iter:[250/495], Time: 0.38, lr: [0.009711215612337627], Loss: 2.230753, Acc:0.781461, Semantic loss: 0.843517, BCE loss: 0.573731, SB loss: 0.813504
2023-10-29 23:13:43,630 Epoch: [15/484] Iter:[260/495], Time: 0.38, lr: [0.009710838729006284], Loss: 2.232346, Acc:0.780855, Semantic loss: 0.846920, BCE loss: 0.572456, SB loss: 0.812971
2023-10-29 23:13:47,365 Epoch: [15/484] Iter:[270/495], Time: 0.38, lr: [0.009710461844049703], Loss: 2.229167, Acc:0.781124, Semantic loss: 0.845717, BCE loss: 0.570559, SB loss: 0.812891
2023-10-29 23:13:51,045 Epoch: [15/484] Iter:[280/495], Time: 0.38, lr: [0.009710084957467809], Loss: 2.231923, Acc:0.780240, Semantic loss: 0.848011, BCE loss: 0.570791, SB loss: 0.813122
2023-10-29 23:13:54,858 Epoch: [15/484] Iter:[290/495], Time: 0.38, lr: [0.009709708069260527], Loss: 2.226441, Acc:0.780874, Semantic loss: 0.844958, BCE loss: 0.569407, SB loss: 0.812076
2023-10-29 23:13:58,562 Epoch: [15/484] Iter:[300/495], Time: 0.38, lr: [0.009709331179427775], Loss: 2.226653, Acc:0.781579, Semantic loss: 0.844165, BCE loss: 0.570465, SB loss: 0.812023
2023-10-29 23:14:02,453 Epoch: [15/484] Iter:[310/495], Time: 0.38, lr: [0.00970895428796948], Loss: 2.224708, Acc:0.781625, Semantic loss: 0.842616, BCE loss: 0.570388, SB loss: 0.811704
2023-10-29 23:14:06,310 Epoch: [15/484] Iter:[320/495], Time: 0.38, lr: [0.009708577394885561], Loss: 2.231455, Acc:0.781296, Semantic loss: 0.845061, BCE loss: 0.572327, SB loss: 0.814067
2023-10-29 23:14:10,087 Epoch: [15/484] Iter:[330/495], Time: 0.38, lr: [0.009708200500175946], Loss: 2.230882, Acc:0.782008, Semantic loss: 0.844125, BCE loss: 0.573817, SB loss: 0.812940
2023-10-29 23:14:14,058 Epoch: [15/484] Iter:[340/495], Time: 0.38, lr: [0.009707823603840553], Loss: 2.228497, Acc:0.781782, Semantic loss: 0.842677, BCE loss: 0.574087, SB loss: 0.811733
2023-10-29 23:14:17,754 Epoch: [15/484] Iter:[350/495], Time: 0.38, lr: [0.009707446705879308], Loss: 2.227835, Acc:0.781453, Semantic loss: 0.841750, BCE loss: 0.574257, SB loss: 0.811827
2023-10-29 23:14:21,602 Epoch: [15/484] Iter:[360/495], Time: 0.38, lr: [0.00970706980629213], Loss: 2.224106, Acc:0.781294, Semantic loss: 0.839309, BCE loss: 0.573670, SB loss: 0.811127
2023-10-29 23:14:25,388 Epoch: [15/484] Iter:[370/495], Time: 0.38, lr: [0.009706692905078949], Loss: 2.220032, Acc:0.781439, Semantic loss: 0.837874, BCE loss: 0.572430, SB loss: 0.809728
2023-10-29 23:14:29,149 Epoch: [15/484] Iter:[380/495], Time: 0.38, lr: [0.009706316002239682], Loss: 2.223420, Acc:0.781869, Semantic loss: 0.840176, BCE loss: 0.573487, SB loss: 0.809757
2023-10-29 23:14:32,902 Epoch: [15/484] Iter:[390/495], Time: 0.38, lr: [0.009705939097774252], Loss: 2.227817, Acc:0.781889, Semantic loss: 0.841977, BCE loss: 0.575113, SB loss: 0.810727
2023-10-29 23:14:36,608 Epoch: [15/484] Iter:[400/495], Time: 0.38, lr: [0.009705562191682582], Loss: 2.229038, Acc:0.782537, Semantic loss: 0.841265, BCE loss: 0.576012, SB loss: 0.811762
2023-10-29 23:14:40,467 Epoch: [15/484] Iter:[410/495], Time: 0.38, lr: [0.009705185283964598], Loss: 2.227795, Acc:0.782614, Semantic loss: 0.839715, BCE loss: 0.575777, SB loss: 0.812303
2023-10-29 23:14:44,293 Epoch: [15/484] Iter:[420/495], Time: 0.38, lr: [0.009704808374620219], Loss: 2.227756, Acc:0.782583, Semantic loss: 0.839419, BCE loss: 0.576139, SB loss: 0.812198
2023-10-29 23:14:48,093 Epoch: [15/484] Iter:[430/495], Time: 0.38, lr: [0.009704431463649372], Loss: 2.232880, Acc:0.783068, Semantic loss: 0.842619, BCE loss: 0.577097, SB loss: 0.813164
2023-10-29 23:14:51,990 Epoch: [15/484] Iter:[440/495], Time: 0.38, lr: [0.009704054551051973], Loss: 2.234443, Acc:0.782835, Semantic loss: 0.843574, BCE loss: 0.577291, SB loss: 0.813578
2023-10-29 23:14:55,773 Epoch: [15/484] Iter:[450/495], Time: 0.38, lr: [0.009703677636827954], Loss: 2.232525, Acc:0.783178, Semantic loss: 0.842091, BCE loss: 0.577753, SB loss: 0.812681
2023-10-29 23:14:59,553 Epoch: [15/484] Iter:[460/495], Time: 0.38, lr: [0.009703300720977229], Loss: 2.232529, Acc:0.783054, Semantic loss: 0.843071, BCE loss: 0.577196, SB loss: 0.812261
2023-10-29 23:15:03,341 Epoch: [15/484] Iter:[470/495], Time: 0.38, lr: [0.009702923803499726], Loss: 2.233124, Acc:0.782762, Semantic loss: 0.843881, BCE loss: 0.576613, SB loss: 0.812630
2023-10-29 23:15:07,117 Epoch: [15/484] Iter:[480/495], Time: 0.38, lr: [0.009702546884395365], Loss: 2.231742, Acc:0.782868, Semantic loss: 0.842868, BCE loss: 0.576005, SB loss: 0.812869
2023-10-29 23:15:10,665 Epoch: [15/484] Iter:[490/495], Time: 0.38, lr: [0.009702169963664072], Loss: 2.231189, Acc:0.782881, Semantic loss: 0.842784, BCE loss: 0.575881, SB loss: 0.812524
2023-10-29 23:18:08,809 0 [0.93335846 0.64243306 0.80230056 0.11626585 0.19922304 0.39211054
 0.38762458 0.5653428  0.87848945 0.36280048 0.84297446 0.55517447
 0.00979306 0.78573323 0.00446898 0.02027749 0.02348017 0.0480094
 0.51848466] 0.42570235583892324
2023-10-29 23:18:08,809 1 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ] 0.6427429970704217
2023-10-29 23:18:08,813 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:18:09,172 Loss: 2.056, MeanIU:  0.6427, Best_mIoU:  0.6427
2023-10-29 23:18:09,172 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ]
2023-10-29 23:18:11,402 Epoch: [16/484] Iter:[0/495], Time: 2.20, lr: [0.0097019815026883], Loss: 2.107845, Acc:0.836357, Semantic loss: 0.755897, BCE loss: 0.590448, SB loss: 0.761501
2023-10-29 23:18:15,415 Epoch: [16/484] Iter:[10/495], Time: 0.56, lr: [0.009701604579516462], Loss: 2.071972, Acc:0.789025, Semantic loss: 0.738211, BCE loss: 0.569004, SB loss: 0.764756
2023-10-29 23:18:18,999 Epoch: [16/484] Iter:[20/495], Time: 0.47, lr: [0.009701227654717494], Loss: 2.087042, Acc:0.803248, Semantic loss: 0.759175, BCE loss: 0.560519, SB loss: 0.767348
2023-10-29 23:18:22,547 Epoch: [16/484] Iter:[30/495], Time: 0.43, lr: [0.009700850728291324], Loss: 2.155438, Acc:0.794184, Semantic loss: 0.807776, BCE loss: 0.558256, SB loss: 0.789405
2023-10-29 23:18:26,144 Epoch: [16/484] Iter:[40/495], Time: 0.41, lr: [0.009700473800237872], Loss: 2.171609, Acc:0.781354, Semantic loss: 0.818378, BCE loss: 0.558583, SB loss: 0.794647
2023-10-29 23:18:29,766 Epoch: [16/484] Iter:[50/495], Time: 0.40, lr: [0.00970009687055706], Loss: 2.165324, Acc:0.785175, Semantic loss: 0.811784, BCE loss: 0.559700, SB loss: 0.793840
2023-10-29 23:18:33,305 Epoch: [16/484] Iter:[60/495], Time: 0.40, lr: [0.009699719939248811], Loss: 2.180555, Acc:0.782467, Semantic loss: 0.832129, BCE loss: 0.555629, SB loss: 0.792797
2023-10-29 23:18:36,887 Epoch: [16/484] Iter:[70/495], Time: 0.39, lr: [0.00969934300631305], Loss: 2.197775, Acc:0.775013, Semantic loss: 0.843361, BCE loss: 0.554132, SB loss: 0.800282
2023-10-29 23:18:40,669 Epoch: [16/484] Iter:[80/495], Time: 0.39, lr: [0.009698966071749698], Loss: 2.202152, Acc:0.777547, Semantic loss: 0.842975, BCE loss: 0.554055, SB loss: 0.805122
2023-10-29 23:18:44,418 Epoch: [16/484] Iter:[90/495], Time: 0.39, lr: [0.00969858913555868], Loss: 2.216458, Acc:0.774847, Semantic loss: 0.849722, BCE loss: 0.555008, SB loss: 0.811729
2023-10-29 23:18:48,043 Epoch: [16/484] Iter:[100/495], Time: 0.38, lr: [0.009698212197739912], Loss: 2.218798, Acc:0.776150, Semantic loss: 0.844130, BCE loss: 0.566555, SB loss: 0.808112
2023-10-29 23:18:51,772 Epoch: [16/484] Iter:[110/495], Time: 0.38, lr: [0.009697835258293324], Loss: 2.251166, Acc:0.777401, Semantic loss: 0.861194, BCE loss: 0.571084, SB loss: 0.818889
2023-10-29 23:18:55,494 Epoch: [16/484] Iter:[120/495], Time: 0.38, lr: [0.009697458317218837], Loss: 2.266581, Acc:0.776441, Semantic loss: 0.864403, BCE loss: 0.578014, SB loss: 0.824164
2023-10-29 23:18:59,127 Epoch: [16/484] Iter:[130/495], Time: 0.38, lr: [0.00969708137451637], Loss: 2.270638, Acc:0.779052, Semantic loss: 0.864607, BCE loss: 0.580956, SB loss: 0.825075
2023-10-29 23:19:02,818 Epoch: [16/484] Iter:[140/495], Time: 0.38, lr: [0.009696704430185851], Loss: 2.256974, Acc:0.778483, Semantic loss: 0.857609, BCE loss: 0.576469, SB loss: 0.822896
2023-10-29 23:19:06,470 Epoch: [16/484] Iter:[150/495], Time: 0.38, lr: [0.0096963274842272], Loss: 2.244234, Acc:0.781431, Semantic loss: 0.851695, BCE loss: 0.573023, SB loss: 0.819516
2023-10-29 23:19:10,070 Epoch: [16/484] Iter:[160/495], Time: 0.38, lr: [0.009695950536640336], Loss: 2.245890, Acc:0.781148, Semantic loss: 0.850543, BCE loss: 0.574233, SB loss: 0.821114
2023-10-29 23:19:13,851 Epoch: [16/484] Iter:[170/495], Time: 0.38, lr: [0.009695573587425189], Loss: 2.239669, Acc:0.781606, Semantic loss: 0.848022, BCE loss: 0.573742, SB loss: 0.817905
2023-10-29 23:19:17,594 Epoch: [16/484] Iter:[180/495], Time: 0.38, lr: [0.009695196636581674], Loss: 2.236453, Acc:0.781245, Semantic loss: 0.848128, BCE loss: 0.571421, SB loss: 0.816904
2023-10-29 23:19:21,255 Epoch: [16/484] Iter:[190/495], Time: 0.38, lr: [0.00969481968410972], Loss: 2.240685, Acc:0.781182, Semantic loss: 0.852601, BCE loss: 0.571901, SB loss: 0.816183
2023-10-29 23:19:25,051 Epoch: [16/484] Iter:[200/495], Time: 0.38, lr: [0.009694442730009247], Loss: 2.243354, Acc:0.780758, Semantic loss: 0.854394, BCE loss: 0.572975, SB loss: 0.815986
2023-10-29 23:19:28,715 Epoch: [16/484] Iter:[210/495], Time: 0.38, lr: [0.009694065774280176], Loss: 2.249287, Acc:0.781351, Semantic loss: 0.857865, BCE loss: 0.574193, SB loss: 0.817229
2023-10-29 23:19:32,415 Epoch: [16/484] Iter:[220/495], Time: 0.38, lr: [0.009693688816922433], Loss: 2.249236, Acc:0.780020, Semantic loss: 0.857522, BCE loss: 0.574298, SB loss: 0.817416
2023-10-29 23:19:36,194 Epoch: [16/484] Iter:[230/495], Time: 0.38, lr: [0.009693311857935939], Loss: 2.247286, Acc:0.781776, Semantic loss: 0.856046, BCE loss: 0.576241, SB loss: 0.814999
2023-10-29 23:19:39,913 Epoch: [16/484] Iter:[240/495], Time: 0.38, lr: [0.009692934897320614], Loss: 2.251509, Acc:0.782715, Semantic loss: 0.859483, BCE loss: 0.577522, SB loss: 0.814504
2023-10-29 23:19:43,578 Epoch: [16/484] Iter:[250/495], Time: 0.38, lr: [0.009692557935076385], Loss: 2.242818, Acc:0.781898, Semantic loss: 0.854250, BCE loss: 0.578355, SB loss: 0.810214
2023-10-29 23:19:47,383 Epoch: [16/484] Iter:[260/495], Time: 0.38, lr: [0.009692180971203172], Loss: 2.240241, Acc:0.782290, Semantic loss: 0.851760, BCE loss: 0.578674, SB loss: 0.809807
2023-10-29 23:19:51,147 Epoch: [16/484] Iter:[270/495], Time: 0.38, lr: [0.009691804005700898], Loss: 2.242142, Acc:0.782833, Semantic loss: 0.854566, BCE loss: 0.578811, SB loss: 0.808766
2023-10-29 23:19:54,914 Epoch: [16/484] Iter:[280/495], Time: 0.38, lr: [0.009691427038569485], Loss: 2.242313, Acc:0.782427, Semantic loss: 0.853791, BCE loss: 0.580240, SB loss: 0.808282
2023-10-29 23:19:58,740 Epoch: [16/484] Iter:[290/495], Time: 0.38, lr: [0.009691050069808858], Loss: 2.240887, Acc:0.784334, Semantic loss: 0.852489, BCE loss: 0.580965, SB loss: 0.807433
2023-10-29 23:20:02,511 Epoch: [16/484] Iter:[300/495], Time: 0.38, lr: [0.009690673099418937], Loss: 2.246087, Acc:0.784237, Semantic loss: 0.855377, BCE loss: 0.581882, SB loss: 0.808829
2023-10-29 23:20:06,311 Epoch: [16/484] Iter:[310/495], Time: 0.38, lr: [0.009690296127399646], Loss: 2.251561, Acc:0.785519, Semantic loss: 0.855926, BCE loss: 0.586844, SB loss: 0.808791
2023-10-29 23:20:10,169 Epoch: [16/484] Iter:[320/495], Time: 0.38, lr: [0.009689919153750906], Loss: 2.249528, Acc:0.785416, Semantic loss: 0.853665, BCE loss: 0.586081, SB loss: 0.809782
2023-10-29 23:20:14,001 Epoch: [16/484] Iter:[330/495], Time: 0.38, lr: [0.00968954217847264], Loss: 2.251473, Acc:0.784751, Semantic loss: 0.855734, BCE loss: 0.584935, SB loss: 0.810804
2023-10-29 23:20:17,748 Epoch: [16/484] Iter:[340/495], Time: 0.38, lr: [0.00968916520156477], Loss: 2.251537, Acc:0.785541, Semantic loss: 0.854688, BCE loss: 0.586734, SB loss: 0.810114
2023-10-29 23:20:21,453 Epoch: [16/484] Iter:[350/495], Time: 0.38, lr: [0.00968878822302722], Loss: 2.246384, Acc:0.785663, Semantic loss: 0.851605, BCE loss: 0.586302, SB loss: 0.808477
2023-10-29 23:20:25,320 Epoch: [16/484] Iter:[360/495], Time: 0.38, lr: [0.009688411242859914], Loss: 2.245205, Acc:0.785813, Semantic loss: 0.851664, BCE loss: 0.584914, SB loss: 0.808627
2023-10-29 23:20:29,075 Epoch: [16/484] Iter:[370/495], Time: 0.38, lr: [0.009688034261062772], Loss: 2.247264, Acc:0.785838, Semantic loss: 0.853231, BCE loss: 0.585079, SB loss: 0.808955
2023-10-29 23:20:32,959 Epoch: [16/484] Iter:[380/495], Time: 0.38, lr: [0.009687657277635714], Loss: 2.246523, Acc:0.786263, Semantic loss: 0.853693, BCE loss: 0.583864, SB loss: 0.808966
2023-10-29 23:20:36,669 Epoch: [16/484] Iter:[390/495], Time: 0.38, lr: [0.009687280292578667], Loss: 2.249443, Acc:0.784840, Semantic loss: 0.855265, BCE loss: 0.584443, SB loss: 0.809734
2023-10-29 23:20:40,435 Epoch: [16/484] Iter:[400/495], Time: 0.38, lr: [0.009686903305891552], Loss: 2.251743, Acc:0.784418, Semantic loss: 0.854800, BCE loss: 0.585727, SB loss: 0.811215
2023-10-29 23:20:44,246 Epoch: [16/484] Iter:[410/495], Time: 0.38, lr: [0.00968652631757429], Loss: 2.247014, Acc:0.784101, Semantic loss: 0.851950, BCE loss: 0.584468, SB loss: 0.810596
2023-10-29 23:20:48,023 Epoch: [16/484] Iter:[420/495], Time: 0.38, lr: [0.009686149327626806], Loss: 2.247859, Acc:0.784401, Semantic loss: 0.852714, BCE loss: 0.584738, SB loss: 0.810408
2023-10-29 23:20:51,740 Epoch: [16/484] Iter:[430/495], Time: 0.38, lr: [0.00968577233604902], Loss: 2.247220, Acc:0.784010, Semantic loss: 0.852681, BCE loss: 0.584782, SB loss: 0.809757
2023-10-29 23:20:55,485 Epoch: [16/484] Iter:[440/495], Time: 0.38, lr: [0.009685395342840858], Loss: 2.248331, Acc:0.785001, Semantic loss: 0.852544, BCE loss: 0.585631, SB loss: 0.810156
2023-10-29 23:20:59,239 Epoch: [16/484] Iter:[450/495], Time: 0.38, lr: [0.00968501834800224], Loss: 2.243977, Acc:0.786094, Semantic loss: 0.849883, BCE loss: 0.585036, SB loss: 0.809059
2023-10-29 23:21:02,993 Epoch: [16/484] Iter:[460/495], Time: 0.38, lr: [0.009684641351533086], Loss: 2.241378, Acc:0.786756, Semantic loss: 0.847589, BCE loss: 0.586087, SB loss: 0.807701
2023-10-29 23:21:06,883 Epoch: [16/484] Iter:[470/495], Time: 0.38, lr: [0.009684264353433322], Loss: 2.241731, Acc:0.786958, Semantic loss: 0.846812, BCE loss: 0.586937, SB loss: 0.807982
2023-10-29 23:21:10,560 Epoch: [16/484] Iter:[480/495], Time: 0.38, lr: [0.00968388735370287], Loss: 2.242963, Acc:0.786692, Semantic loss: 0.847310, BCE loss: 0.586315, SB loss: 0.809337
2023-10-29 23:21:14,113 Epoch: [16/484] Iter:[490/495], Time: 0.38, lr: [0.009683510352341652], Loss: 2.242518, Acc:0.786514, Semantic loss: 0.847088, BCE loss: 0.586539, SB loss: 0.808891
2023-10-29 23:21:15,540 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:21:15,786 Loss: 2.056, MeanIU:  0.6427, Best_mIoU:  0.6427
2023-10-29 23:21:15,786 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ]
2023-10-29 23:21:17,730 Epoch: [17/484] Iter:[0/495], Time: 1.91, lr: [0.009683321851049479], Loss: 2.557447, Acc:0.612596, Semantic loss: 1.111045, BCE loss: 0.567908, SB loss: 0.878495
2023-10-29 23:21:21,694 Epoch: [17/484] Iter:[10/495], Time: 0.53, lr: [0.009682944847241966], Loss: 2.300348, Acc:0.755850, Semantic loss: 0.887362, BCE loss: 0.593104, SB loss: 0.819881
2023-10-29 23:21:25,492 Epoch: [17/484] Iter:[20/495], Time: 0.46, lr: [0.009682567841803491], Loss: 2.165782, Acc:0.785276, Semantic loss: 0.820727, BCE loss: 0.564985, SB loss: 0.780070
2023-10-29 23:21:29,356 Epoch: [17/484] Iter:[30/495], Time: 0.44, lr: [0.00968219083473398], Loss: 2.205242, Acc:0.783444, Semantic loss: 0.837489, BCE loss: 0.577510, SB loss: 0.790243
2023-10-29 23:21:33,308 Epoch: [17/484] Iter:[40/495], Time: 0.43, lr: [0.009681813826033352], Loss: 2.212369, Acc:0.794762, Semantic loss: 0.837395, BCE loss: 0.582608, SB loss: 0.792365
2023-10-29 23:21:37,092 Epoch: [17/484] Iter:[50/495], Time: 0.42, lr: [0.00968143681570153], Loss: 2.218729, Acc:0.801850, Semantic loss: 0.828035, BCE loss: 0.598636, SB loss: 0.792058
2023-10-29 23:21:40,844 Epoch: [17/484] Iter:[60/495], Time: 0.41, lr: [0.009681059803738441], Loss: 2.215643, Acc:0.797029, Semantic loss: 0.819710, BCE loss: 0.598850, SB loss: 0.797082
2023-10-29 23:21:44,687 Epoch: [17/484] Iter:[70/495], Time: 0.41, lr: [0.009680682790144], Loss: 2.178416, Acc:0.801979, Semantic loss: 0.804047, BCE loss: 0.584431, SB loss: 0.789938
2023-10-29 23:21:48,448 Epoch: [17/484] Iter:[80/495], Time: 0.40, lr: [0.009680305774918133], Loss: 2.201242, Acc:0.798231, Semantic loss: 0.816078, BCE loss: 0.584620, SB loss: 0.800543
2023-10-29 23:21:52,145 Epoch: [17/484] Iter:[90/495], Time: 0.40, lr: [0.009679928758060764], Loss: 2.225250, Acc:0.800029, Semantic loss: 0.835989, BCE loss: 0.582569, SB loss: 0.806693
2023-10-29 23:21:55,904 Epoch: [17/484] Iter:[100/495], Time: 0.40, lr: [0.009679551739571813], Loss: 2.227718, Acc:0.795828, Semantic loss: 0.838511, BCE loss: 0.581463, SB loss: 0.807744
2023-10-29 23:21:59,755 Epoch: [17/484] Iter:[110/495], Time: 0.40, lr: [0.009679174719451204], Loss: 2.215573, Acc:0.796406, Semantic loss: 0.831490, BCE loss: 0.579983, SB loss: 0.804099
2023-10-29 23:22:03,559 Epoch: [17/484] Iter:[120/495], Time: 0.39, lr: [0.009678797697698856], Loss: 2.214374, Acc:0.797437, Semantic loss: 0.835976, BCE loss: 0.572863, SB loss: 0.805536
2023-10-29 23:22:07,545 Epoch: [17/484] Iter:[130/495], Time: 0.39, lr: [0.009678420674314694], Loss: 2.232067, Acc:0.793969, Semantic loss: 0.847541, BCE loss: 0.570716, SB loss: 0.813810
2023-10-29 23:22:11,283 Epoch: [17/484] Iter:[140/495], Time: 0.39, lr: [0.009678043649298642], Loss: 2.239403, Acc:0.794510, Semantic loss: 0.848073, BCE loss: 0.576598, SB loss: 0.814732
2023-10-29 23:22:15,095 Epoch: [17/484] Iter:[150/495], Time: 0.39, lr: [0.009677666622650618], Loss: 2.254461, Acc:0.790101, Semantic loss: 0.857227, BCE loss: 0.579703, SB loss: 0.817530
2023-10-29 23:22:18,882 Epoch: [17/484] Iter:[160/495], Time: 0.39, lr: [0.009677289594370546], Loss: 2.255365, Acc:0.787730, Semantic loss: 0.859692, BCE loss: 0.575527, SB loss: 0.820146
2023-10-29 23:22:22,641 Epoch: [17/484] Iter:[170/495], Time: 0.39, lr: [0.009676912564458351], Loss: 2.267513, Acc:0.785791, Semantic loss: 0.866095, BCE loss: 0.577960, SB loss: 0.823458
2023-10-29 23:22:26,387 Epoch: [17/484] Iter:[180/495], Time: 0.39, lr: [0.00967653553291395], Loss: 2.271645, Acc:0.783716, Semantic loss: 0.869500, BCE loss: 0.578100, SB loss: 0.824045
2023-10-29 23:22:30,182 Epoch: [17/484] Iter:[190/495], Time: 0.39, lr: [0.009676158499737271], Loss: 2.265407, Acc:0.783758, Semantic loss: 0.867384, BCE loss: 0.576242, SB loss: 0.821781
2023-10-29 23:22:34,028 Epoch: [17/484] Iter:[200/495], Time: 0.39, lr: [0.009675781464928234], Loss: 2.263568, Acc:0.785312, Semantic loss: 0.863710, BCE loss: 0.579690, SB loss: 0.820168
2023-10-29 23:22:37,720 Epoch: [17/484] Iter:[210/495], Time: 0.39, lr: [0.009675404428486759], Loss: 2.263124, Acc:0.785382, Semantic loss: 0.864374, BCE loss: 0.581573, SB loss: 0.817176
2023-10-29 23:22:41,419 Epoch: [17/484] Iter:[220/495], Time: 0.39, lr: [0.00967502739041277], Loss: 2.258607, Acc:0.785902, Semantic loss: 0.860954, BCE loss: 0.581884, SB loss: 0.815769
2023-10-29 23:22:45,173 Epoch: [17/484] Iter:[230/495], Time: 0.39, lr: [0.009674650350706191], Loss: 2.250505, Acc:0.784634, Semantic loss: 0.856424, BCE loss: 0.580133, SB loss: 0.813947
2023-10-29 23:22:49,064 Epoch: [17/484] Iter:[240/495], Time: 0.39, lr: [0.00967427330936694], Loss: 2.245761, Acc:0.786569, Semantic loss: 0.853000, BCE loss: 0.578953, SB loss: 0.813808
2023-10-29 23:22:52,932 Epoch: [17/484] Iter:[250/495], Time: 0.39, lr: [0.009673896266394944], Loss: 2.244413, Acc:0.788089, Semantic loss: 0.851212, BCE loss: 0.579815, SB loss: 0.813386
2023-10-29 23:22:56,777 Epoch: [17/484] Iter:[260/495], Time: 0.39, lr: [0.009673519221790123], Loss: 2.242900, Acc:0.788866, Semantic loss: 0.850810, BCE loss: 0.579416, SB loss: 0.812674
2023-10-29 23:23:00,642 Epoch: [17/484] Iter:[270/495], Time: 0.39, lr: [0.009673142175552398], Loss: 2.246090, Acc:0.788757, Semantic loss: 0.852283, BCE loss: 0.578844, SB loss: 0.814962
2023-10-29 23:23:04,414 Epoch: [17/484] Iter:[280/495], Time: 0.39, lr: [0.009672765127681691], Loss: 2.243113, Acc:0.788818, Semantic loss: 0.851937, BCE loss: 0.577467, SB loss: 0.813708
2023-10-29 23:23:08,130 Epoch: [17/484] Iter:[290/495], Time: 0.39, lr: [0.009672388078177928], Loss: 2.248606, Acc:0.787708, Semantic loss: 0.856197, BCE loss: 0.576811, SB loss: 0.815598
2023-10-29 23:23:11,932 Epoch: [17/484] Iter:[300/495], Time: 0.39, lr: [0.009672011027041029], Loss: 2.242122, Acc:0.787976, Semantic loss: 0.851663, BCE loss: 0.575651, SB loss: 0.814808
2023-10-29 23:23:15,651 Epoch: [17/484] Iter:[310/495], Time: 0.39, lr: [0.009671633974270916], Loss: 2.242497, Acc:0.787288, Semantic loss: 0.852393, BCE loss: 0.576514, SB loss: 0.813590
2023-10-29 23:23:19,394 Epoch: [17/484] Iter:[320/495], Time: 0.38, lr: [0.00967125691986751], Loss: 2.239689, Acc:0.788510, Semantic loss: 0.850300, BCE loss: 0.577147, SB loss: 0.812241
2023-10-29 23:23:23,312 Epoch: [17/484] Iter:[330/495], Time: 0.39, lr: [0.009670879863830735], Loss: 2.237804, Acc:0.787886, Semantic loss: 0.850983, BCE loss: 0.575253, SB loss: 0.811568
2023-10-29 23:23:27,060 Epoch: [17/484] Iter:[340/495], Time: 0.38, lr: [0.00967050280616051], Loss: 2.238855, Acc:0.786962, Semantic loss: 0.851097, BCE loss: 0.575897, SB loss: 0.811861
2023-10-29 23:23:30,759 Epoch: [17/484] Iter:[350/495], Time: 0.38, lr: [0.009670125746856762], Loss: 2.240678, Acc:0.786865, Semantic loss: 0.851796, BCE loss: 0.576456, SB loss: 0.812426
2023-10-29 23:23:34,515 Epoch: [17/484] Iter:[360/495], Time: 0.38, lr: [0.00966974868591941], Loss: 2.237521, Acc:0.786432, Semantic loss: 0.850017, BCE loss: 0.576854, SB loss: 0.810649
2023-10-29 23:23:38,242 Epoch: [17/484] Iter:[370/495], Time: 0.38, lr: [0.00966937162334838], Loss: 2.237323, Acc:0.785773, Semantic loss: 0.848566, BCE loss: 0.578334, SB loss: 0.810423
2023-10-29 23:23:42,010 Epoch: [17/484] Iter:[380/495], Time: 0.38, lr: [0.009668994559143588], Loss: 2.234829, Acc:0.785418, Semantic loss: 0.846135, BCE loss: 0.578064, SB loss: 0.810631
2023-10-29 23:23:45,778 Epoch: [17/484] Iter:[390/495], Time: 0.38, lr: [0.00966861749330496], Loss: 2.233219, Acc:0.785646, Semantic loss: 0.844297, BCE loss: 0.578395, SB loss: 0.810527
2023-10-29 23:23:49,534 Epoch: [17/484] Iter:[400/495], Time: 0.38, lr: [0.009668240425832416], Loss: 2.233796, Acc:0.786345, Semantic loss: 0.843926, BCE loss: 0.579312, SB loss: 0.810558
2023-10-29 23:23:53,307 Epoch: [17/484] Iter:[410/495], Time: 0.38, lr: [0.009667863356725882], Loss: 2.232148, Acc:0.786262, Semantic loss: 0.843278, BCE loss: 0.579147, SB loss: 0.809724
2023-10-29 23:23:57,173 Epoch: [17/484] Iter:[420/495], Time: 0.38, lr: [0.009667486285985275], Loss: 2.228003, Acc:0.785989, Semantic loss: 0.841494, BCE loss: 0.577374, SB loss: 0.809134
2023-10-29 23:24:00,926 Epoch: [17/484] Iter:[430/495], Time: 0.38, lr: [0.009667109213610522], Loss: 2.223520, Acc:0.786391, Semantic loss: 0.840091, BCE loss: 0.576174, SB loss: 0.807255
2023-10-29 23:24:04,858 Epoch: [17/484] Iter:[440/495], Time: 0.38, lr: [0.009666732139601541], Loss: 2.223623, Acc:0.787056, Semantic loss: 0.839287, BCE loss: 0.576904, SB loss: 0.807432
2023-10-29 23:24:08,592 Epoch: [17/484] Iter:[450/495], Time: 0.38, lr: [0.009666355063958257], Loss: 2.227038, Acc:0.787321, Semantic loss: 0.842419, BCE loss: 0.576942, SB loss: 0.807676
2023-10-29 23:24:12,379 Epoch: [17/484] Iter:[460/495], Time: 0.38, lr: [0.009665977986680589], Loss: 2.229788, Acc:0.786961, Semantic loss: 0.843493, BCE loss: 0.577342, SB loss: 0.808953
2023-10-29 23:24:16,112 Epoch: [17/484] Iter:[470/495], Time: 0.38, lr: [0.009665600907768463], Loss: 2.225818, Acc:0.786616, Semantic loss: 0.841199, BCE loss: 0.575535, SB loss: 0.809083
2023-10-29 23:24:19,880 Epoch: [17/484] Iter:[480/495], Time: 0.38, lr: [0.009665223827221799], Loss: 2.229386, Acc:0.786440, Semantic loss: 0.844668, BCE loss: 0.575383, SB loss: 0.809336
2023-10-29 23:24:23,440 Epoch: [17/484] Iter:[490/495], Time: 0.38, lr: [0.009664846745040518], Loss: 2.229544, Acc:0.785775, Semantic loss: 0.845878, BCE loss: 0.574188, SB loss: 0.809478
2023-10-29 23:24:24,897 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:24:25,139 Loss: 2.056, MeanIU:  0.6427, Best_mIoU:  0.6427
2023-10-29 23:24:25,139 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ]
2023-10-29 23:24:27,163 Epoch: [18/484] Iter:[0/495], Time: 1.99, lr: [0.009664658203336873], Loss: 1.650052, Acc:0.746947, Semantic loss: 0.574928, BCE loss: 0.436597, SB loss: 0.638527
2023-10-29 23:24:31,177 Epoch: [18/484] Iter:[10/495], Time: 0.55, lr: [0.009664281118703523], Loss: 1.980201, Acc:0.802106, Semantic loss: 0.728681, BCE loss: 0.520071, SB loss: 0.731449
2023-10-29 23:24:34,968 Epoch: [18/484] Iter:[20/495], Time: 0.47, lr: [0.009663904032435361], Loss: 2.093664, Acc:0.799390, Semantic loss: 0.795459, BCE loss: 0.537989, SB loss: 0.760217
2023-10-29 23:24:38,719 Epoch: [18/484] Iter:[30/495], Time: 0.44, lr: [0.009663526944532312], Loss: 2.058194, Acc:0.798994, Semantic loss: 0.772532, BCE loss: 0.534491, SB loss: 0.751172
2023-10-29 23:24:42,416 Epoch: [18/484] Iter:[40/495], Time: 0.42, lr: [0.009663149854994293], Loss: 2.087482, Acc:0.803710, Semantic loss: 0.765605, BCE loss: 0.564080, SB loss: 0.757796
2023-10-29 23:24:46,169 Epoch: [18/484] Iter:[50/495], Time: 0.41, lr: [0.009662772763821234], Loss: 2.093725, Acc:0.807378, Semantic loss: 0.773264, BCE loss: 0.563216, SB loss: 0.757245
2023-10-29 23:24:49,951 Epoch: [18/484] Iter:[60/495], Time: 0.41, lr: [0.00966239567101305], Loss: 2.101571, Acc:0.805271, Semantic loss: 0.777301, BCE loss: 0.560238, SB loss: 0.764032
2023-10-29 23:24:53,667 Epoch: [18/484] Iter:[70/495], Time: 0.40, lr: [0.009662018576569665], Loss: 2.116038, Acc:0.801980, Semantic loss: 0.784759, BCE loss: 0.564034, SB loss: 0.767245
2023-10-29 23:24:57,369 Epoch: [18/484] Iter:[80/495], Time: 0.40, lr: [0.009661641480491001], Loss: 2.114463, Acc:0.802180, Semantic loss: 0.783576, BCE loss: 0.563131, SB loss: 0.767755
2023-10-29 23:25:01,105 Epoch: [18/484] Iter:[90/495], Time: 0.39, lr: [0.009661264382776981], Loss: 2.111027, Acc:0.798597, Semantic loss: 0.784545, BCE loss: 0.558923, SB loss: 0.767559
2023-10-29 23:25:04,998 Epoch: [18/484] Iter:[100/495], Time: 0.39, lr: [0.009660887283427526], Loss: 2.104568, Acc:0.802222, Semantic loss: 0.782939, BCE loss: 0.554814, SB loss: 0.766816
2023-10-29 23:25:08,825 Epoch: [18/484] Iter:[110/495], Time: 0.39, lr: [0.009660510182442558], Loss: 2.127411, Acc:0.801584, Semantic loss: 0.795156, BCE loss: 0.559808, SB loss: 0.772447
2023-10-29 23:25:12,536 Epoch: [18/484] Iter:[120/495], Time: 0.39, lr: [0.009660133079822001], Loss: 2.138724, Acc:0.804046, Semantic loss: 0.799186, BCE loss: 0.566065, SB loss: 0.773472
2023-10-29 23:25:16,259 Epoch: [18/484] Iter:[130/495], Time: 0.39, lr: [0.009659755975565775], Loss: 2.137751, Acc:0.803371, Semantic loss: 0.798815, BCE loss: 0.563875, SB loss: 0.775061
2023-10-29 23:25:20,026 Epoch: [18/484] Iter:[140/495], Time: 0.39, lr: [0.0096593788696738], Loss: 2.148345, Acc:0.801952, Semantic loss: 0.804820, BCE loss: 0.564178, SB loss: 0.779348
2023-10-29 23:25:23,841 Epoch: [18/484] Iter:[150/495], Time: 0.39, lr: [0.009659001762146001], Loss: 2.140230, Acc:0.802034, Semantic loss: 0.798764, BCE loss: 0.560840, SB loss: 0.780626
2023-10-29 23:25:27,555 Epoch: [18/484] Iter:[160/495], Time: 0.39, lr: [0.009658624652982301], Loss: 2.141828, Acc:0.802992, Semantic loss: 0.797901, BCE loss: 0.563954, SB loss: 0.779973
2023-10-29 23:25:31,240 Epoch: [18/484] Iter:[170/495], Time: 0.39, lr: [0.009658247542182618], Loss: 2.147376, Acc:0.802027, Semantic loss: 0.800675, BCE loss: 0.564191, SB loss: 0.782511
2023-10-29 23:25:34,992 Epoch: [18/484] Iter:[180/495], Time: 0.39, lr: [0.009657870429746876], Loss: 2.137577, Acc:0.797987, Semantic loss: 0.796397, BCE loss: 0.558989, SB loss: 0.782191
2023-10-29 23:25:38,732 Epoch: [18/484] Iter:[190/495], Time: 0.39, lr: [0.009657493315674998], Loss: 2.135281, Acc:0.795445, Semantic loss: 0.796710, BCE loss: 0.558427, SB loss: 0.780145
2023-10-29 23:25:42,483 Epoch: [18/484] Iter:[200/495], Time: 0.38, lr: [0.009657116199966903], Loss: 2.137133, Acc:0.793495, Semantic loss: 0.799899, BCE loss: 0.556139, SB loss: 0.781096
2023-10-29 23:25:46,301 Epoch: [18/484] Iter:[210/495], Time: 0.38, lr: [0.009656739082622516], Loss: 2.138871, Acc:0.791601, Semantic loss: 0.800881, BCE loss: 0.556569, SB loss: 0.781421
2023-10-29 23:25:49,993 Epoch: [18/484] Iter:[220/495], Time: 0.38, lr: [0.009656361963641757], Loss: 2.139390, Acc:0.790659, Semantic loss: 0.801959, BCE loss: 0.556508, SB loss: 0.780923
2023-10-29 23:25:53,737 Epoch: [18/484] Iter:[230/495], Time: 0.38, lr: [0.009655984843024549], Loss: 2.142190, Acc:0.790493, Semantic loss: 0.803467, BCE loss: 0.557627, SB loss: 0.781097
2023-10-29 23:25:57,439 Epoch: [18/484] Iter:[240/495], Time: 0.38, lr: [0.009655607720770813], Loss: 2.148515, Acc:0.789633, Semantic loss: 0.808212, BCE loss: 0.558100, SB loss: 0.782203
2023-10-29 23:26:01,267 Epoch: [18/484] Iter:[250/495], Time: 0.38, lr: [0.009655230596880471], Loss: 2.149567, Acc:0.791651, Semantic loss: 0.810029, BCE loss: 0.557931, SB loss: 0.781607
2023-10-29 23:26:05,074 Epoch: [18/484] Iter:[260/495], Time: 0.38, lr: [0.009654853471353444], Loss: 2.145922, Acc:0.791991, Semantic loss: 0.807733, BCE loss: 0.557237, SB loss: 0.780951
2023-10-29 23:26:08,817 Epoch: [18/484] Iter:[270/495], Time: 0.38, lr: [0.009654476344189656], Loss: 2.143580, Acc:0.791683, Semantic loss: 0.806032, BCE loss: 0.556576, SB loss: 0.780972
2023-10-29 23:26:12,724 Epoch: [18/484] Iter:[280/495], Time: 0.38, lr: [0.009654099215389029], Loss: 2.147383, Acc:0.792383, Semantic loss: 0.807516, BCE loss: 0.558602, SB loss: 0.781265
2023-10-29 23:26:16,462 Epoch: [18/484] Iter:[290/495], Time: 0.38, lr: [0.009653722084951482], Loss: 2.152506, Acc:0.792856, Semantic loss: 0.811486, BCE loss: 0.559345, SB loss: 0.781676
2023-10-29 23:26:20,216 Epoch: [18/484] Iter:[300/495], Time: 0.38, lr: [0.009653344952876938], Loss: 2.153618, Acc:0.792045, Semantic loss: 0.811958, BCE loss: 0.559221, SB loss: 0.782439
2023-10-29 23:26:23,931 Epoch: [18/484] Iter:[310/495], Time: 0.38, lr: [0.009652967819165323], Loss: 2.153398, Acc:0.790997, Semantic loss: 0.811247, BCE loss: 0.560018, SB loss: 0.782133
2023-10-29 23:26:27,734 Epoch: [18/484] Iter:[320/495], Time: 0.38, lr: [0.009652590683816553], Loss: 2.151429, Acc:0.791751, Semantic loss: 0.809287, BCE loss: 0.560626, SB loss: 0.781517
2023-10-29 23:26:31,605 Epoch: [18/484] Iter:[330/495], Time: 0.38, lr: [0.009652213546830551], Loss: 2.154257, Acc:0.791372, Semantic loss: 0.811191, BCE loss: 0.560678, SB loss: 0.782389
2023-10-29 23:26:35,406 Epoch: [18/484] Iter:[340/495], Time: 0.38, lr: [0.00965183640820724], Loss: 2.158494, Acc:0.791258, Semantic loss: 0.811983, BCE loss: 0.562843, SB loss: 0.783667
2023-10-29 23:26:39,174 Epoch: [18/484] Iter:[350/495], Time: 0.38, lr: [0.009651459267946541], Loss: 2.156341, Acc:0.792032, Semantic loss: 0.809944, BCE loss: 0.563254, SB loss: 0.783143
2023-10-29 23:26:42,927 Epoch: [18/484] Iter:[360/495], Time: 0.38, lr: [0.009651082126048378], Loss: 2.156976, Acc:0.791878, Semantic loss: 0.809874, BCE loss: 0.564220, SB loss: 0.782882
2023-10-29 23:26:46,751 Epoch: [18/484] Iter:[370/495], Time: 0.38, lr: [0.00965070498251267], Loss: 2.162578, Acc:0.791586, Semantic loss: 0.812545, BCE loss: 0.565955, SB loss: 0.784078
2023-10-29 23:26:50,523 Epoch: [18/484] Iter:[380/495], Time: 0.38, lr: [0.00965032783733934], Loss: 2.162851, Acc:0.792371, Semantic loss: 0.810449, BCE loss: 0.567904, SB loss: 0.784498
2023-10-29 23:26:54,286 Epoch: [18/484] Iter:[390/495], Time: 0.38, lr: [0.00964995069052831], Loss: 2.165983, Acc:0.792026, Semantic loss: 0.812710, BCE loss: 0.568474, SB loss: 0.784799
2023-10-29 23:26:58,022 Epoch: [18/484] Iter:[400/495], Time: 0.38, lr: [0.009649573542079503], Loss: 2.163918, Acc:0.792343, Semantic loss: 0.811317, BCE loss: 0.567775, SB loss: 0.784826
2023-10-29 23:27:01,798 Epoch: [18/484] Iter:[410/495], Time: 0.38, lr: [0.009649196391992838], Loss: 2.166128, Acc:0.792074, Semantic loss: 0.812080, BCE loss: 0.568147, SB loss: 0.785901
2023-10-29 23:27:05,508 Epoch: [18/484] Iter:[420/495], Time: 0.38, lr: [0.009648819240268237], Loss: 2.168837, Acc:0.792033, Semantic loss: 0.813045, BCE loss: 0.569094, SB loss: 0.786698
2023-10-29 23:27:09,290 Epoch: [18/484] Iter:[430/495], Time: 0.38, lr: [0.009648442086905625], Loss: 2.167316, Acc:0.791947, Semantic loss: 0.812272, BCE loss: 0.569024, SB loss: 0.786020
2023-10-29 23:27:13,006 Epoch: [18/484] Iter:[440/495], Time: 0.38, lr: [0.00964806493190492], Loss: 2.172949, Acc:0.791805, Semantic loss: 0.815430, BCE loss: 0.570038, SB loss: 0.787481
2023-10-29 23:27:16,812 Epoch: [18/484] Iter:[450/495], Time: 0.38, lr: [0.009647687775266046], Loss: 2.171527, Acc:0.791827, Semantic loss: 0.813644, BCE loss: 0.570645, SB loss: 0.787238
2023-10-29 23:27:20,569 Epoch: [18/484] Iter:[460/495], Time: 0.38, lr: [0.009647310616988923], Loss: 2.170098, Acc:0.792678, Semantic loss: 0.811942, BCE loss: 0.571190, SB loss: 0.786966
2023-10-29 23:27:24,354 Epoch: [18/484] Iter:[470/495], Time: 0.38, lr: [0.009646933457073474], Loss: 2.174413, Acc:0.792011, Semantic loss: 0.814445, BCE loss: 0.572093, SB loss: 0.787875
2023-10-29 23:27:28,086 Epoch: [18/484] Iter:[480/495], Time: 0.38, lr: [0.009646556295519622], Loss: 2.172859, Acc:0.791240, Semantic loss: 0.814104, BCE loss: 0.570687, SB loss: 0.788068
2023-10-29 23:27:31,687 Epoch: [18/484] Iter:[490/495], Time: 0.38, lr: [0.009646179132327284], Loss: 2.176042, Acc:0.790774, Semantic loss: 0.816474, BCE loss: 0.570498, SB loss: 0.789070
2023-10-29 23:27:33,126 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:27:33,362 Loss: 2.056, MeanIU:  0.6427, Best_mIoU:  0.6427
2023-10-29 23:27:33,362 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ]
2023-10-29 23:27:35,536 Epoch: [19/484] Iter:[0/495], Time: 2.14, lr: [0.00964599055011666], Loss: 1.915148, Acc:0.820101, Semantic loss: 0.816403, BCE loss: 0.410799, SB loss: 0.687945
2023-10-29 23:27:39,622 Epoch: [19/484] Iter:[10/495], Time: 0.57, lr: [0.009645613384466454], Loss: 2.297424, Acc:0.774519, Semantic loss: 0.909124, BCE loss: 0.546357, SB loss: 0.841943
2023-10-29 23:27:43,439 Epoch: [19/484] Iter:[20/495], Time: 0.48, lr: [0.009645236217177567], Loss: 2.331013, Acc:0.771299, Semantic loss: 0.897561, BCE loss: 0.593962, SB loss: 0.839490
2023-10-29 23:27:47,277 Epoch: [19/484] Iter:[30/495], Time: 0.45, lr: [0.009644859048249925], Loss: 2.299850, Acc:0.772261, Semantic loss: 0.878720, BCE loss: 0.584672, SB loss: 0.836458
2023-10-29 23:27:50,892 Epoch: [19/484] Iter:[40/495], Time: 0.43, lr: [0.009644481877683447], Loss: 2.246610, Acc:0.768231, Semantic loss: 0.852095, BCE loss: 0.570968, SB loss: 0.823547
2023-10-29 23:27:54,637 Epoch: [19/484] Iter:[50/495], Time: 0.42, lr: [0.009644104705478055], Loss: 2.188718, Acc:0.773844, Semantic loss: 0.824127, BCE loss: 0.559922, SB loss: 0.804669
2023-10-29 23:27:58,481 Epoch: [19/484] Iter:[60/495], Time: 0.41, lr: [0.00964372753163367], Loss: 2.198098, Acc:0.777873, Semantic loss: 0.824052, BCE loss: 0.571348, SB loss: 0.802698
2023-10-29 23:28:02,210 Epoch: [19/484] Iter:[70/495], Time: 0.41, lr: [0.009643350356150217], Loss: 2.193347, Acc:0.776432, Semantic loss: 0.819806, BCE loss: 0.568843, SB loss: 0.804697
2023-10-29 23:28:06,026 Epoch: [19/484] Iter:[80/495], Time: 0.40, lr: [0.009642973179027615], Loss: 2.201239, Acc:0.780141, Semantic loss: 0.826652, BCE loss: 0.566063, SB loss: 0.808524
2023-10-29 23:28:09,913 Epoch: [19/484] Iter:[90/495], Time: 0.40, lr: [0.009642596000265784], Loss: 2.192174, Acc:0.782777, Semantic loss: 0.817166, BCE loss: 0.568566, SB loss: 0.806443
2023-10-29 23:28:13,763 Epoch: [19/484] Iter:[100/495], Time: 0.40, lr: [0.00964221881986465], Loss: 2.185230, Acc:0.784490, Semantic loss: 0.816849, BCE loss: 0.565187, SB loss: 0.803194
2023-10-29 23:28:17,492 Epoch: [19/484] Iter:[110/495], Time: 0.40, lr: [0.00964184163782413], Loss: 2.191918, Acc:0.785766, Semantic loss: 0.822072, BCE loss: 0.567921, SB loss: 0.801925
2023-10-29 23:28:21,224 Epoch: [19/484] Iter:[120/495], Time: 0.40, lr: [0.009641464454144148], Loss: 2.194773, Acc:0.784545, Semantic loss: 0.824882, BCE loss: 0.568081, SB loss: 0.801811
2023-10-29 23:28:24,949 Epoch: [19/484] Iter:[130/495], Time: 0.39, lr: [0.009641087268824627], Loss: 2.196571, Acc:0.783977, Semantic loss: 0.825130, BCE loss: 0.570842, SB loss: 0.800599
2023-10-29 23:28:28,700 Epoch: [19/484] Iter:[140/495], Time: 0.39, lr: [0.009640710081865487], Loss: 2.191477, Acc:0.784022, Semantic loss: 0.822966, BCE loss: 0.571578, SB loss: 0.796933
2023-10-29 23:28:32,445 Epoch: [19/484] Iter:[150/495], Time: 0.39, lr: [0.00964033289326665], Loss: 2.195721, Acc:0.782179, Semantic loss: 0.824179, BCE loss: 0.572256, SB loss: 0.799286
2023-10-29 23:28:36,227 Epoch: [19/484] Iter:[160/495], Time: 0.39, lr: [0.009639955703028035], Loss: 2.198808, Acc:0.782714, Semantic loss: 0.826272, BCE loss: 0.571133, SB loss: 0.801403
2023-10-29 23:28:40,030 Epoch: [19/484] Iter:[170/495], Time: 0.39, lr: [0.009639578511149566], Loss: 2.199502, Acc:0.784389, Semantic loss: 0.825159, BCE loss: 0.573348, SB loss: 0.800994
2023-10-29 23:28:43,862 Epoch: [19/484] Iter:[180/495], Time: 0.39, lr: [0.009639201317631168], Loss: 2.203915, Acc:0.786465, Semantic loss: 0.825973, BCE loss: 0.574863, SB loss: 0.803079
2023-10-29 23:28:47,580 Epoch: [19/484] Iter:[190/495], Time: 0.39, lr: [0.009638824122472755], Loss: 2.202700, Acc:0.784336, Semantic loss: 0.825710, BCE loss: 0.573121, SB loss: 0.803869
2023-10-29 23:28:51,283 Epoch: [19/484] Iter:[200/495], Time: 0.39, lr: [0.009638446925674254], Loss: 2.206847, Acc:0.781681, Semantic loss: 0.829440, BCE loss: 0.573279, SB loss: 0.804128
2023-10-29 23:28:55,035 Epoch: [19/484] Iter:[210/495], Time: 0.39, lr: [0.009638069727235585], Loss: 2.207841, Acc:0.781672, Semantic loss: 0.831002, BCE loss: 0.572381, SB loss: 0.804458
2023-10-29 23:28:58,858 Epoch: [19/484] Iter:[220/495], Time: 0.39, lr: [0.00963769252715667], Loss: 2.206535, Acc:0.780589, Semantic loss: 0.827772, BCE loss: 0.575991, SB loss: 0.802772
2023-10-29 23:29:02,666 Epoch: [19/484] Iter:[230/495], Time: 0.39, lr: [0.009637315325437431], Loss: 2.200837, Acc:0.781643, Semantic loss: 0.824777, BCE loss: 0.575520, SB loss: 0.800541
2023-10-29 23:29:06,548 Epoch: [19/484] Iter:[240/495], Time: 0.39, lr: [0.009636938122077787], Loss: 2.203210, Acc:0.782393, Semantic loss: 0.825174, BCE loss: 0.576046, SB loss: 0.801990
2023-10-29 23:29:10,333 Epoch: [19/484] Iter:[250/495], Time: 0.39, lr: [0.009636560917077661], Loss: 2.202862, Acc:0.780791, Semantic loss: 0.826022, BCE loss: 0.575157, SB loss: 0.801683
2023-10-29 23:29:14,100 Epoch: [19/484] Iter:[260/495], Time: 0.39, lr: [0.009636183710436976], Loss: 2.206023, Acc:0.780825, Semantic loss: 0.826492, BCE loss: 0.577936, SB loss: 0.801596
2023-10-29 23:29:17,920 Epoch: [19/484] Iter:[270/495], Time: 0.39, lr: [0.00963580650215565], Loss: 2.205233, Acc:0.780189, Semantic loss: 0.827341, BCE loss: 0.576755, SB loss: 0.801137
2023-10-29 23:29:21,620 Epoch: [19/484] Iter:[280/495], Time: 0.39, lr: [0.00963542929223361], Loss: 2.202986, Acc:0.781349, Semantic loss: 0.825633, BCE loss: 0.577978, SB loss: 0.799375
2023-10-29 23:29:25,599 Epoch: [19/484] Iter:[290/495], Time: 0.39, lr: [0.009635052080670774], Loss: 2.203614, Acc:0.781598, Semantic loss: 0.825886, BCE loss: 0.577745, SB loss: 0.799983
2023-10-29 23:29:29,369 Epoch: [19/484] Iter:[300/495], Time: 0.39, lr: [0.009634674867467061], Loss: 2.222898, Acc:0.781536, Semantic loss: 0.840677, BCE loss: 0.579493, SB loss: 0.802728
2023-10-29 23:29:33,077 Epoch: [19/484] Iter:[310/495], Time: 0.38, lr: [0.009634297652622397], Loss: 2.228268, Acc:0.780213, Semantic loss: 0.844469, BCE loss: 0.579118, SB loss: 0.804680
2023-10-29 23:29:36,750 Epoch: [19/484] Iter:[320/495], Time: 0.38, lr: [0.0096339204361367], Loss: 2.223896, Acc:0.779694, Semantic loss: 0.842367, BCE loss: 0.578457, SB loss: 0.803072
2023-10-29 23:29:40,492 Epoch: [19/484] Iter:[330/495], Time: 0.38, lr: [0.009633543218009896], Loss: 2.226256, Acc:0.779599, Semantic loss: 0.842843, BCE loss: 0.579330, SB loss: 0.804083
2023-10-29 23:29:44,269 Epoch: [19/484] Iter:[340/495], Time: 0.38, lr: [0.009633165998241901], Loss: 2.221967, Acc:0.779568, Semantic loss: 0.840742, BCE loss: 0.578046, SB loss: 0.803179
2023-10-29 23:29:48,035 Epoch: [19/484] Iter:[350/495], Time: 0.38, lr: [0.009632788776832641], Loss: 2.222929, Acc:0.780193, Semantic loss: 0.840877, BCE loss: 0.577936, SB loss: 0.804117
2023-10-29 23:29:51,815 Epoch: [19/484] Iter:[360/495], Time: 0.38, lr: [0.009632411553782035], Loss: 2.221842, Acc:0.781301, Semantic loss: 0.839923, BCE loss: 0.579111, SB loss: 0.802809
2023-10-29 23:29:55,546 Epoch: [19/484] Iter:[370/495], Time: 0.38, lr: [0.009632034329090003], Loss: 2.222041, Acc:0.781675, Semantic loss: 0.839121, BCE loss: 0.579545, SB loss: 0.803375
2023-10-29 23:29:59,308 Epoch: [19/484] Iter:[380/495], Time: 0.38, lr: [0.009631657102756472], Loss: 2.220621, Acc:0.782479, Semantic loss: 0.838911, BCE loss: 0.578802, SB loss: 0.802907
2023-10-29 23:30:03,053 Epoch: [19/484] Iter:[390/495], Time: 0.38, lr: [0.009631279874781356], Loss: 2.213632, Acc:0.783565, Semantic loss: 0.835200, BCE loss: 0.577352, SB loss: 0.801080
2023-10-29 23:30:06,855 Epoch: [19/484] Iter:[400/495], Time: 0.38, lr: [0.009630902645164582], Loss: 2.212897, Acc:0.783416, Semantic loss: 0.835350, BCE loss: 0.576494, SB loss: 0.801053
2023-10-29 23:30:10,769 Epoch: [19/484] Iter:[410/495], Time: 0.38, lr: [0.00963052541390607], Loss: 2.213265, Acc:0.783498, Semantic loss: 0.834729, BCE loss: 0.577272, SB loss: 0.801265
2023-10-29 23:30:14,543 Epoch: [19/484] Iter:[420/495], Time: 0.38, lr: [0.009630148181005741], Loss: 2.212544, Acc:0.784658, Semantic loss: 0.834275, BCE loss: 0.578230, SB loss: 0.800039
2023-10-29 23:30:18,362 Epoch: [19/484] Iter:[430/495], Time: 0.38, lr: [0.009629770946463515], Loss: 2.207968, Acc:0.784572, Semantic loss: 0.831429, BCE loss: 0.577333, SB loss: 0.799205
2023-10-29 23:30:22,149 Epoch: [19/484] Iter:[440/495], Time: 0.38, lr: [0.009629393710279316], Loss: 2.205479, Acc:0.785342, Semantic loss: 0.830400, BCE loss: 0.577039, SB loss: 0.798040
2023-10-29 23:30:25,864 Epoch: [19/484] Iter:[450/495], Time: 0.38, lr: [0.009629016472453063], Loss: 2.206567, Acc:0.785859, Semantic loss: 0.831763, BCE loss: 0.576928, SB loss: 0.797876
2023-10-29 23:30:29,576 Epoch: [19/484] Iter:[460/495], Time: 0.38, lr: [0.00962863923298468], Loss: 2.203026, Acc:0.785355, Semantic loss: 0.829717, BCE loss: 0.576172, SB loss: 0.797137
2023-10-29 23:30:33,432 Epoch: [19/484] Iter:[470/495], Time: 0.38, lr: [0.009628261991874087], Loss: 2.203401, Acc:0.785485, Semantic loss: 0.829595, BCE loss: 0.575738, SB loss: 0.798068
2023-10-29 23:30:37,317 Epoch: [19/484] Iter:[480/495], Time: 0.38, lr: [0.009627884749121204], Loss: 2.203800, Acc:0.786364, Semantic loss: 0.829567, BCE loss: 0.576631, SB loss: 0.797602
2023-10-29 23:30:40,863 Epoch: [19/484] Iter:[490/495], Time: 0.38, lr: [0.009627507504725954], Loss: 2.202773, Acc:0.786160, Semantic loss: 0.829178, BCE loss: 0.576357, SB loss: 0.797238
2023-10-29 23:30:42,292 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:30:42,536 Loss: 2.056, MeanIU:  0.6427, Best_mIoU:  0.6427
2023-10-29 23:30:42,536 [0.96824618 0.78884627 0.89330019 0.36724713 0.3979413  0.52356105
 0.61518455 0.70520237 0.90535351 0.52109664 0.92008469 0.73468263
 0.50106859 0.91694948 0.44795314 0.58753312 0.23064675 0.50083256
 0.6863868 ]
2023-10-29 23:30:44,699 Epoch: [20/484] Iter:[0/495], Time: 2.13, lr: [0.009627318881912417], Loss: 1.813000, Acc:0.776835, Semantic loss: 0.612009, BCE loss: 0.501324, SB loss: 0.699667
2023-10-29 23:30:48,830 Epoch: [20/484] Iter:[10/495], Time: 0.57, lr: [0.009626941635053468], Loss: 2.183138, Acc:0.787444, Semantic loss: 0.804122, BCE loss: 0.605138, SB loss: 0.773877
2023-10-29 23:30:52,723 Epoch: [20/484] Iter:[20/495], Time: 0.48, lr: [0.009626564386551958], Loss: 2.170075, Acc:0.783302, Semantic loss: 0.824489, BCE loss: 0.578686, SB loss: 0.766900
2023-10-29 23:30:56,561 Epoch: [20/484] Iter:[30/495], Time: 0.45, lr: [0.009626187136407801], Loss: 2.211145, Acc:0.782668, Semantic loss: 0.833756, BCE loss: 0.598660, SB loss: 0.778729
2023-10-29 23:31:00,302 Epoch: [20/484] Iter:[40/495], Time: 0.43, lr: [0.009625809884620926], Loss: 2.242251, Acc:0.787779, Semantic loss: 0.854027, BCE loss: 0.593248, SB loss: 0.794977
2023-10-29 23:31:04,069 Epoch: [20/484] Iter:[50/495], Time: 0.42, lr: [0.00962543263119125], Loss: 2.239010, Acc:0.790811, Semantic loss: 0.845247, BCE loss: 0.598480, SB loss: 0.795282
2023-10-29 23:31:07,806 Epoch: [20/484] Iter:[60/495], Time: 0.41, lr: [0.009625055376118694], Loss: 2.240266, Acc:0.788470, Semantic loss: 0.848275, BCE loss: 0.591552, SB loss: 0.800439
2023-10-29 23:31:11,602 Epoch: [20/484] Iter:[70/495], Time: 0.41, lr: [0.009624678119403181], Loss: 2.241333, Acc:0.786138, Semantic loss: 0.855481, BCE loss: 0.584440, SB loss: 0.801413
2023-10-29 23:31:15,286 Epoch: [20/484] Iter:[80/495], Time: 0.40, lr: [0.009624300861044632], Loss: 2.224047, Acc:0.783755, Semantic loss: 0.848231, BCE loss: 0.576805, SB loss: 0.799010
2023-10-29 23:31:19,083 Epoch: [20/484] Iter:[90/495], Time: 0.40, lr: [0.009623923601042968], Loss: 2.246204, Acc:0.778940, Semantic loss: 0.861720, BCE loss: 0.574835, SB loss: 0.809649
2023-10-29 23:31:22,853 Epoch: [20/484] Iter:[100/495], Time: 0.40, lr: [0.00962354633939811], Loss: 2.247242, Acc:0.779517, Semantic loss: 0.854539, BCE loss: 0.580404, SB loss: 0.812300
2023-10-29 23:31:26,583 Epoch: [20/484] Iter:[110/495], Time: 0.40, lr: [0.00962316907610998], Loss: 2.253773, Acc:0.784564, Semantic loss: 0.856488, BCE loss: 0.582218, SB loss: 0.815067
2023-10-29 23:31:30,351 Epoch: [20/484] Iter:[120/495], Time: 0.39, lr: [0.009622791811178501], Loss: 2.243083, Acc:0.785718, Semantic loss: 0.852107, BCE loss: 0.580953, SB loss: 0.810023
2023-10-29 23:31:34,082 Epoch: [20/484] Iter:[130/495], Time: 0.39, lr: [0.009622414544603589], Loss: 2.229552, Acc:0.787246, Semantic loss: 0.843076, BCE loss: 0.581996, SB loss: 0.804480
2023-10-29 23:31:37,915 Epoch: [20/484] Iter:[140/495], Time: 0.39, lr: [0.00962203727638517], Loss: 2.224168, Acc:0.787917, Semantic loss: 0.839834, BCE loss: 0.579265, SB loss: 0.805069
2023-10-29 23:31:41,750 Epoch: [20/484] Iter:[150/495], Time: 0.39, lr: [0.009621660006523165], Loss: 2.222597, Acc:0.788032, Semantic loss: 0.837200, BCE loss: 0.580678, SB loss: 0.804719
2023-10-29 23:31:45,552 Epoch: [20/484] Iter:[160/495], Time: 0.39, lr: [0.009621282735017491], Loss: 2.226410, Acc:0.789123, Semantic loss: 0.836831, BCE loss: 0.584120, SB loss: 0.805459
2023-10-29 23:31:49,267 Epoch: [20/484] Iter:[170/495], Time: 0.39, lr: [0.009620905461868072], Loss: 2.246562, Acc:0.791133, Semantic loss: 0.852748, BCE loss: 0.584037, SB loss: 0.809777
2023-10-29 23:31:52,989 Epoch: [20/484] Iter:[180/495], Time: 0.39, lr: [0.009620528187074831], Loss: 2.248180, Acc:0.789223, Semantic loss: 0.852141, BCE loss: 0.584860, SB loss: 0.811179
2023-10-29 23:31:56,836 Epoch: [20/484] Iter:[190/495], Time: 0.39, lr: [0.009620150910637688], Loss: 2.249899, Acc:0.789234, Semantic loss: 0.853497, BCE loss: 0.586102, SB loss: 0.810299
2023-10-29 23:32:00,684 Epoch: [20/484] Iter:[200/495], Time: 0.39, lr: [0.009619773632556563], Loss: 2.247044, Acc:0.786615, Semantic loss: 0.850861, BCE loss: 0.585715, SB loss: 0.810467
2023-10-29 23:32:04,438 Epoch: [20/484] Iter:[210/495], Time: 0.39, lr: [0.009619396352831378], Loss: 2.254593, Acc:0.784969, Semantic loss: 0.857716, BCE loss: 0.584134, SB loss: 0.812743
2023-10-29 23:32:08,198 Epoch: [20/484] Iter:[220/495], Time: 0.39, lr: [0.009619019071462055], Loss: 2.254604, Acc:0.784694, Semantic loss: 0.854916, BCE loss: 0.585958, SB loss: 0.813729
2023-10-29 23:32:12,016 Epoch: [20/484] Iter:[230/495], Time: 0.39, lr: [0.009618641788448512], Loss: 2.250659, Acc:0.784328, Semantic loss: 0.854035, BCE loss: 0.584900, SB loss: 0.811724
2023-10-29 23:32:15,797 Epoch: [20/484] Iter:[240/495], Time: 0.39, lr: [0.009618264503790675], Loss: 2.245551, Acc:0.784729, Semantic loss: 0.850109, BCE loss: 0.584126, SB loss: 0.811316
2023-10-29 23:32:19,662 Epoch: [20/484] Iter:[250/495], Time: 0.39, lr: [0.00961788721748846], Loss: 2.241797, Acc:0.784922, Semantic loss: 0.848292, BCE loss: 0.583774, SB loss: 0.809731
2023-10-29 23:32:23,468 Epoch: [20/484] Iter:[260/495], Time: 0.39, lr: [0.009617509929541794], Loss: 2.246568, Acc:0.783624, Semantic loss: 0.850775, BCE loss: 0.585373, SB loss: 0.810420
2023-10-29 23:32:27,228 Epoch: [20/484] Iter:[270/495], Time: 0.39, lr: [0.009617132639950591], Loss: 2.241026, Acc:0.784220, Semantic loss: 0.847578, BCE loss: 0.584866, SB loss: 0.808582
2023-10-29 23:32:31,001 Epoch: [20/484] Iter:[280/495], Time: 0.39, lr: [0.00961675534871478], Loss: 2.233262, Acc:0.783211, Semantic loss: 0.843608, BCE loss: 0.581991, SB loss: 0.807663
2023-10-29 23:32:34,677 Epoch: [20/484] Iter:[290/495], Time: 0.39, lr: [0.009616378055834277], Loss: 2.228501, Acc:0.784309, Semantic loss: 0.840180, BCE loss: 0.582518, SB loss: 0.805803
2023-10-29 23:32:38,461 Epoch: [20/484] Iter:[300/495], Time: 0.39, lr: [0.009616000761309003], Loss: 2.226867, Acc:0.785519, Semantic loss: 0.839878, BCE loss: 0.582453, SB loss: 0.804536
2023-10-29 23:32:42,265 Epoch: [20/484] Iter:[310/495], Time: 0.38, lr: [0.009615623465138882], Loss: 2.227432, Acc:0.785793, Semantic loss: 0.839651, BCE loss: 0.581886, SB loss: 0.805896
2023-10-29 23:32:46,027 Epoch: [20/484] Iter:[320/495], Time: 0.38, lr: [0.009615246167323833], Loss: 2.219250, Acc:0.786251, Semantic loss: 0.835444, BCE loss: 0.580945, SB loss: 0.802861
2023-10-29 23:32:49,771 Epoch: [20/484] Iter:[330/495], Time: 0.38, lr: [0.009614868867863778], Loss: 2.215608, Acc:0.785609, Semantic loss: 0.833963, BCE loss: 0.580144, SB loss: 0.801502
2023-10-29 23:32:53,585 Epoch: [20/484] Iter:[340/495], Time: 0.38, lr: [0.009614491566758638], Loss: 2.214549, Acc:0.785516, Semantic loss: 0.833322, BCE loss: 0.579881, SB loss: 0.801345
2023-10-29 23:32:57,262 Epoch: [20/484] Iter:[350/495], Time: 0.38, lr: [0.009614114264008334], Loss: 2.215180, Acc:0.786625, Semantic loss: 0.833812, BCE loss: 0.579352, SB loss: 0.802016
2023-10-29 23:33:01,032 Epoch: [20/484] Iter:[360/495], Time: 0.38, lr: [0.009613736959612786], Loss: 2.212616, Acc:0.786022, Semantic loss: 0.832269, BCE loss: 0.579221, SB loss: 0.801126
2023-10-29 23:33:04,731 Epoch: [20/484] Iter:[370/495], Time: 0.38, lr: [0.009613359653571915], Loss: 2.215622, Acc:0.785481, Semantic loss: 0.834792, BCE loss: 0.578268, SB loss: 0.802561
2023-10-29 23:33:08,537 Epoch: [20/484] Iter:[380/495], Time: 0.38, lr: [0.009612982345885646], Loss: 2.216868, Acc:0.784841, Semantic loss: 0.834655, BCE loss: 0.579975, SB loss: 0.802238
2023-10-29 23:33:12,337 Epoch: [20/484] Iter:[390/495], Time: 0.38, lr: [0.009612605036553897], Loss: 2.215721, Acc:0.785036, Semantic loss: 0.834888, BCE loss: 0.579408, SB loss: 0.801426
2023-10-29 23:33:16,201 Epoch: [20/484] Iter:[400/495], Time: 0.38, lr: [0.00961222772557659], Loss: 2.216038, Acc:0.785748, Semantic loss: 0.835203, BCE loss: 0.579773, SB loss: 0.801062
2023-10-29 23:33:19,982 Epoch: [20/484] Iter:[410/495], Time: 0.38, lr: [0.009611850412953642], Loss: 2.210675, Acc:0.784804, Semantic loss: 0.832202, BCE loss: 0.578493, SB loss: 0.799980
2023-10-29 23:33:23,687 Epoch: [20/484] Iter:[420/495], Time: 0.38, lr: [0.00961147309868498], Loss: 2.214921, Acc:0.784616, Semantic loss: 0.834627, BCE loss: 0.577530, SB loss: 0.802763
2023-10-29 23:33:27,459 Epoch: [20/484] Iter:[430/495], Time: 0.38, lr: [0.00961109578277052], Loss: 2.221792, Acc:0.784177, Semantic loss: 0.838054, BCE loss: 0.578139, SB loss: 0.805599
2023-10-29 23:33:31,189 Epoch: [20/484] Iter:[440/495], Time: 0.38, lr: [0.009610718465210187], Loss: 2.216041, Acc:0.783775, Semantic loss: 0.834566, BCE loss: 0.576894, SB loss: 0.804581
2023-10-29 23:33:34,961 Epoch: [20/484] Iter:[450/495], Time: 0.38, lr: [0.0096103411460039], Loss: 2.215763, Acc:0.784442, Semantic loss: 0.834529, BCE loss: 0.576791, SB loss: 0.804443
2023-10-29 23:33:38,750 Epoch: [20/484] Iter:[460/495], Time: 0.38, lr: [0.009609963825151582], Loss: 2.215730, Acc:0.784732, Semantic loss: 0.833890, BCE loss: 0.577661, SB loss: 0.804179
2023-10-29 23:33:42,405 Epoch: [20/484] Iter:[470/495], Time: 0.38, lr: [0.009609586502653152], Loss: 2.215810, Acc:0.784194, Semantic loss: 0.835157, BCE loss: 0.576593, SB loss: 0.804060
2023-10-29 23:33:46,216 Epoch: [20/484] Iter:[480/495], Time: 0.38, lr: [0.009609209178508531], Loss: 2.209676, Acc:0.783759, Semantic loss: 0.832064, BCE loss: 0.574836, SB loss: 0.802776
2023-10-29 23:33:49,857 Epoch: [20/484] Iter:[490/495], Time: 0.38, lr: [0.00960883185271764], Loss: 2.213779, Acc:0.784237, Semantic loss: 0.834230, BCE loss: 0.575766, SB loss: 0.803783
2023-10-29 23:36:48,235 0 [9.16756972e-01 5.51889140e-01 8.04996985e-01 1.00367539e-01
 2.14106992e-01 3.46131115e-01 3.94706338e-01 5.46280276e-01
 8.70868608e-01 4.00955812e-01 8.33464035e-01 5.43205553e-01
 3.31600050e-03 7.62941246e-01 8.79744056e-05 4.36177154e-02
 1.09911342e-02 1.33760953e-02 5.49406914e-01] 0.41618244460067916
2023-10-29 23:36:48,236 1 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903] 0.6378614996258416
2023-10-29 23:36:48,239 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:36:48,482 Loss: 2.176, MeanIU:  0.6379, Best_mIoU:  0.6427
2023-10-29 23:36:48,482 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903]
2023-10-29 23:36:50,638 Epoch: [21/484] Iter:[0/495], Time: 2.12, lr: [0.00960864318920482], Loss: 2.590140, Acc:0.849803, Semantic loss: 0.819516, BCE loss: 0.859975, SB loss: 0.910649
2023-10-29 23:36:54,561 Epoch: [21/484] Iter:[10/495], Time: 0.55, lr: [0.009608265860944378], Loss: 2.216524, Acc:0.810310, Semantic loss: 0.793517, BCE loss: 0.632895, SB loss: 0.790112
2023-10-29 23:36:58,200 Epoch: [21/484] Iter:[20/495], Time: 0.46, lr: [0.009607888531037468], Loss: 2.220168, Acc:0.788578, Semantic loss: 0.825432, BCE loss: 0.596777, SB loss: 0.797959
2023-10-29 23:37:01,728 Epoch: [21/484] Iter:[30/495], Time: 0.43, lr: [0.00960751119948401], Loss: 2.154140, Acc:0.789447, Semantic loss: 0.796852, BCE loss: 0.572813, SB loss: 0.784474
2023-10-29 23:37:05,285 Epoch: [21/484] Iter:[40/495], Time: 0.41, lr: [0.00960713386628393], Loss: 2.155504, Acc:0.788418, Semantic loss: 0.800787, BCE loss: 0.568554, SB loss: 0.786162
2023-10-29 23:37:08,878 Epoch: [21/484] Iter:[50/495], Time: 0.40, lr: [0.009606756531437145], Loss: 2.137666, Acc:0.779058, Semantic loss: 0.794347, BCE loss: 0.557364, SB loss: 0.785956
2023-10-29 23:37:12,512 Epoch: [21/484] Iter:[60/495], Time: 0.39, lr: [0.009606379194943577], Loss: 2.147877, Acc:0.782477, Semantic loss: 0.797143, BCE loss: 0.563307, SB loss: 0.787428
2023-10-29 23:37:16,292 Epoch: [21/484] Iter:[70/495], Time: 0.39, lr: [0.009606001856803145], Loss: 2.127412, Acc:0.783321, Semantic loss: 0.788557, BCE loss: 0.555580, SB loss: 0.783275
2023-10-29 23:37:19,949 Epoch: [21/484] Iter:[80/495], Time: 0.39, lr: [0.009605624517015774], Loss: 2.131381, Acc:0.783813, Semantic loss: 0.795326, BCE loss: 0.549623, SB loss: 0.786432
2023-10-29 23:37:23,653 Epoch: [21/484] Iter:[90/495], Time: 0.39, lr: [0.009605247175581382], Loss: 2.188910, Acc:0.783172, Semantic loss: 0.835994, BCE loss: 0.558808, SB loss: 0.794108
2023-10-29 23:37:27,319 Epoch: [21/484] Iter:[100/495], Time: 0.38, lr: [0.009604869832499889], Loss: 2.196617, Acc:0.778464, Semantic loss: 0.837312, BCE loss: 0.561402, SB loss: 0.797903
2023-10-29 23:37:31,002 Epoch: [21/484] Iter:[110/495], Time: 0.38, lr: [0.009604492487771218], Loss: 2.215526, Acc:0.777797, Semantic loss: 0.849095, BCE loss: 0.559876, SB loss: 0.806555
2023-10-29 23:37:34,712 Epoch: [21/484] Iter:[120/495], Time: 0.38, lr: [0.009604115141395291], Loss: 2.227105, Acc:0.776502, Semantic loss: 0.855437, BCE loss: 0.563245, SB loss: 0.808424
2023-10-29 23:37:38,498 Epoch: [21/484] Iter:[130/495], Time: 0.38, lr: [0.009603737793372025], Loss: 2.232285, Acc:0.775114, Semantic loss: 0.865539, BCE loss: 0.560612, SB loss: 0.806134
2023-10-29 23:37:42,219 Epoch: [21/484] Iter:[140/495], Time: 0.38, lr: [0.009603360443701345], Loss: 2.230892, Acc:0.775588, Semantic loss: 0.860762, BCE loss: 0.565244, SB loss: 0.804887
2023-10-29 23:37:45,906 Epoch: [21/484] Iter:[150/495], Time: 0.38, lr: [0.00960298309238317], Loss: 2.230019, Acc:0.776198, Semantic loss: 0.859825, BCE loss: 0.565178, SB loss: 0.805016
2023-10-29 23:37:49,661 Epoch: [21/484] Iter:[160/495], Time: 0.38, lr: [0.00960260573941742], Loss: 2.227873, Acc:0.776234, Semantic loss: 0.854286, BCE loss: 0.568421, SB loss: 0.805166
2023-10-29 23:37:53,354 Epoch: [21/484] Iter:[170/495], Time: 0.38, lr: [0.009602228384804016], Loss: 2.229655, Acc:0.775114, Semantic loss: 0.856256, BCE loss: 0.566425, SB loss: 0.806974
2023-10-29 23:37:57,001 Epoch: [21/484] Iter:[180/495], Time: 0.38, lr: [0.009601851028542881], Loss: 2.233932, Acc:0.775231, Semantic loss: 0.859939, BCE loss: 0.568345, SB loss: 0.805647
2023-10-29 23:38:00,788 Epoch: [21/484] Iter:[190/495], Time: 0.38, lr: [0.009601473670633933], Loss: 2.235172, Acc:0.774577, Semantic loss: 0.861830, BCE loss: 0.564850, SB loss: 0.808491
2023-10-29 23:38:04,540 Epoch: [21/484] Iter:[200/495], Time: 0.38, lr: [0.009601096311077096], Loss: 2.251476, Acc:0.773984, Semantic loss: 0.868720, BCE loss: 0.569534, SB loss: 0.813222
2023-10-29 23:38:08,246 Epoch: [21/484] Iter:[210/495], Time: 0.38, lr: [0.009600718949872288], Loss: 2.268997, Acc:0.774477, Semantic loss: 0.879883, BCE loss: 0.572809, SB loss: 0.816305
2023-10-29 23:38:11,917 Epoch: [21/484] Iter:[220/495], Time: 0.38, lr: [0.009600341587019431], Loss: 2.255138, Acc:0.774918, Semantic loss: 0.869212, BCE loss: 0.571834, SB loss: 0.814092
2023-10-29 23:38:15,590 Epoch: [21/484] Iter:[230/495], Time: 0.38, lr: [0.009599964222518445], Loss: 2.251792, Acc:0.774619, Semantic loss: 0.866283, BCE loss: 0.572151, SB loss: 0.813358
2023-10-29 23:38:19,343 Epoch: [21/484] Iter:[240/495], Time: 0.38, lr: [0.009599586856369254], Loss: 2.249645, Acc:0.774694, Semantic loss: 0.864308, BCE loss: 0.572528, SB loss: 0.812809
2023-10-29 23:38:23,094 Epoch: [21/484] Iter:[250/495], Time: 0.38, lr: [0.009599209488571776], Loss: 2.248162, Acc:0.774673, Semantic loss: 0.862882, BCE loss: 0.573603, SB loss: 0.811677
2023-10-29 23:38:26,863 Epoch: [21/484] Iter:[260/495], Time: 0.38, lr: [0.00959883211912593], Loss: 2.250185, Acc:0.773768, Semantic loss: 0.863863, BCE loss: 0.575058, SB loss: 0.811264
2023-10-29 23:38:30,560 Epoch: [21/484] Iter:[270/495], Time: 0.38, lr: [0.00959845474803164], Loss: 2.254130, Acc:0.776102, Semantic loss: 0.864592, BCE loss: 0.579237, SB loss: 0.810301
2023-10-29 23:38:34,264 Epoch: [21/484] Iter:[280/495], Time: 0.38, lr: [0.009598077375288826], Loss: 2.247036, Acc:0.777312, Semantic loss: 0.859433, BCE loss: 0.579421, SB loss: 0.808182
2023-10-29 23:38:37,983 Epoch: [21/484] Iter:[290/495], Time: 0.38, lr: [0.00959770000089741], Loss: 2.251774, Acc:0.777777, Semantic loss: 0.864094, BCE loss: 0.578740, SB loss: 0.808940
2023-10-29 23:38:41,700 Epoch: [21/484] Iter:[300/495], Time: 0.38, lr: [0.009597322624857308], Loss: 2.241089, Acc:0.777978, Semantic loss: 0.857211, BCE loss: 0.576944, SB loss: 0.806935
2023-10-29 23:38:45,501 Epoch: [21/484] Iter:[310/495], Time: 0.38, lr: [0.009596945247168446], Loss: 2.238252, Acc:0.778090, Semantic loss: 0.855066, BCE loss: 0.577501, SB loss: 0.805686
2023-10-29 23:38:49,285 Epoch: [21/484] Iter:[320/495], Time: 0.38, lr: [0.009596567867830743], Loss: 2.233507, Acc:0.778140, Semantic loss: 0.852910, BCE loss: 0.576142, SB loss: 0.804456
2023-10-29 23:38:53,116 Epoch: [21/484] Iter:[330/495], Time: 0.38, lr: [0.00959619048684412], Loss: 2.235006, Acc:0.778498, Semantic loss: 0.855251, BCE loss: 0.574981, SB loss: 0.804775
2023-10-29 23:38:56,977 Epoch: [21/484] Iter:[340/495], Time: 0.38, lr: [0.009595813104208498], Loss: 2.234008, Acc:0.780190, Semantic loss: 0.853672, BCE loss: 0.576447, SB loss: 0.803889
2023-10-29 23:39:00,718 Epoch: [21/484] Iter:[350/495], Time: 0.38, lr: [0.009595435719923794], Loss: 2.230185, Acc:0.779671, Semantic loss: 0.851705, BCE loss: 0.574990, SB loss: 0.803489
2023-10-29 23:39:04,446 Epoch: [21/484] Iter:[360/495], Time: 0.38, lr: [0.009595058333989935], Loss: 2.229520, Acc:0.780191, Semantic loss: 0.849989, BCE loss: 0.576715, SB loss: 0.802816
2023-10-29 23:39:08,336 Epoch: [21/484] Iter:[370/495], Time: 0.38, lr: [0.009594680946406838], Loss: 2.234916, Acc:0.781153, Semantic loss: 0.855054, BCE loss: 0.576835, SB loss: 0.803027
2023-10-29 23:39:12,150 Epoch: [21/484] Iter:[380/495], Time: 0.38, lr: [0.009594303557174423], Loss: 2.231194, Acc:0.781619, Semantic loss: 0.852013, BCE loss: 0.577498, SB loss: 0.801683
2023-10-29 23:39:15,891 Epoch: [21/484] Iter:[390/495], Time: 0.38, lr: [0.009593926166292613], Loss: 2.227938, Acc:0.781425, Semantic loss: 0.850094, BCE loss: 0.576493, SB loss: 0.801351
2023-10-29 23:39:19,619 Epoch: [21/484] Iter:[400/495], Time: 0.38, lr: [0.009593548773761326], Loss: 2.225643, Acc:0.781664, Semantic loss: 0.848604, BCE loss: 0.575811, SB loss: 0.801227
2023-10-29 23:39:23,372 Epoch: [21/484] Iter:[410/495], Time: 0.38, lr: [0.009593171379580486], Loss: 2.223248, Acc:0.781967, Semantic loss: 0.848007, BCE loss: 0.575104, SB loss: 0.800137
2023-10-29 23:39:27,241 Epoch: [21/484] Iter:[420/495], Time: 0.38, lr: [0.009592793983750013], Loss: 2.221361, Acc:0.782783, Semantic loss: 0.846594, BCE loss: 0.575670, SB loss: 0.799098
2023-10-29 23:39:31,005 Epoch: [21/484] Iter:[430/495], Time: 0.38, lr: [0.009592416586269824], Loss: 2.223692, Acc:0.782128, Semantic loss: 0.847611, BCE loss: 0.576489, SB loss: 0.799593
2023-10-29 23:39:34,893 Epoch: [21/484] Iter:[440/495], Time: 0.38, lr: [0.009592039187139845], Loss: 2.224506, Acc:0.783247, Semantic loss: 0.847775, BCE loss: 0.577139, SB loss: 0.799592
2023-10-29 23:39:38,684 Epoch: [21/484] Iter:[450/495], Time: 0.38, lr: [0.009591661786359992], Loss: 2.222365, Acc:0.783744, Semantic loss: 0.846343, BCE loss: 0.576975, SB loss: 0.799047
2023-10-29 23:39:42,559 Epoch: [21/484] Iter:[460/495], Time: 0.38, lr: [0.009591284383930188], Loss: 2.222004, Acc:0.783783, Semantic loss: 0.845635, BCE loss: 0.576643, SB loss: 0.799726
2023-10-29 23:39:46,326 Epoch: [21/484] Iter:[470/495], Time: 0.38, lr: [0.009590906979850355], Loss: 2.225448, Acc:0.783373, Semantic loss: 0.846780, BCE loss: 0.577857, SB loss: 0.800812
2023-10-29 23:39:50,059 Epoch: [21/484] Iter:[480/495], Time: 0.38, lr: [0.009590529574120411], Loss: 2.223077, Acc:0.782999, Semantic loss: 0.846236, BCE loss: 0.576179, SB loss: 0.800662
2023-10-29 23:39:53,597 Epoch: [21/484] Iter:[490/495], Time: 0.38, lr: [0.009590152166740277], Loss: 2.222649, Acc:0.782665, Semantic loss: 0.846540, BCE loss: 0.575102, SB loss: 0.801008
2023-10-29 23:39:55,038 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:39:55,278 Loss: 2.176, MeanIU:  0.6379, Best_mIoU:  0.6427
2023-10-29 23:39:55,278 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903]
2023-10-29 23:39:57,422 Epoch: [22/484] Iter:[0/495], Time: 2.11, lr: [0.009589963462431366], Loss: 2.242211, Acc:0.630654, Semantic loss: 0.872503, BCE loss: 0.544389, SB loss: 0.825320
2023-10-29 23:40:01,471 Epoch: [22/484] Iter:[10/495], Time: 0.56, lr: [0.009589586052575799], Loss: 2.110484, Acc:0.733077, Semantic loss: 0.769141, BCE loss: 0.537473, SB loss: 0.803870
2023-10-29 23:40:05,270 Epoch: [22/484] Iter:[20/495], Time: 0.47, lr: [0.009589208641069845], Loss: 2.131173, Acc:0.744174, Semantic loss: 0.767311, BCE loss: 0.560878, SB loss: 0.802984
2023-10-29 23:40:08,965 Epoch: [22/484] Iter:[30/495], Time: 0.44, lr: [0.009588831227913423], Loss: 2.192711, Acc:0.765278, Semantic loss: 0.820318, BCE loss: 0.564327, SB loss: 0.808066
2023-10-29 23:40:12,702 Epoch: [22/484] Iter:[40/495], Time: 0.42, lr: [0.009588453813106457], Loss: 2.198235, Acc:0.760817, Semantic loss: 0.831883, BCE loss: 0.563826, SB loss: 0.802525
2023-10-29 23:40:16,543 Epoch: [22/484] Iter:[50/495], Time: 0.42, lr: [0.009588076396648862], Loss: 2.218659, Acc:0.759551, Semantic loss: 0.842068, BCE loss: 0.571307, SB loss: 0.805284
2023-10-29 23:40:20,286 Epoch: [22/484] Iter:[60/495], Time: 0.41, lr: [0.009587698978540563], Loss: 2.203110, Acc:0.767233, Semantic loss: 0.835381, BCE loss: 0.566432, SB loss: 0.801297
2023-10-29 23:40:24,085 Epoch: [22/484] Iter:[70/495], Time: 0.41, lr: [0.00958732155878148], Loss: 2.205136, Acc:0.773061, Semantic loss: 0.831881, BCE loss: 0.575630, SB loss: 0.797624
2023-10-29 23:40:27,837 Epoch: [22/484] Iter:[80/495], Time: 0.40, lr: [0.00958694413737153], Loss: 2.206495, Acc:0.774803, Semantic loss: 0.837644, BCE loss: 0.570026, SB loss: 0.798825
2023-10-29 23:40:31,599 Epoch: [22/484] Iter:[90/495], Time: 0.40, lr: [0.00958656671431064], Loss: 2.191281, Acc:0.779121, Semantic loss: 0.822382, BCE loss: 0.572580, SB loss: 0.796319
2023-10-29 23:40:35,391 Epoch: [22/484] Iter:[100/495], Time: 0.40, lr: [0.009586189289598725], Loss: 2.199617, Acc:0.780472, Semantic loss: 0.831314, BCE loss: 0.572930, SB loss: 0.795372
2023-10-29 23:40:39,157 Epoch: [22/484] Iter:[110/495], Time: 0.39, lr: [0.009585811863235707], Loss: 2.191033, Acc:0.782414, Semantic loss: 0.823006, BCE loss: 0.573606, SB loss: 0.794421
2023-10-29 23:40:42,931 Epoch: [22/484] Iter:[120/495], Time: 0.39, lr: [0.009585434435221508], Loss: 2.176333, Acc:0.784244, Semantic loss: 0.816213, BCE loss: 0.568683, SB loss: 0.791437
2023-10-29 23:40:46,600 Epoch: [22/484] Iter:[130/495], Time: 0.39, lr: [0.009585057005556046], Loss: 2.208151, Acc:0.785467, Semantic loss: 0.832843, BCE loss: 0.577018, SB loss: 0.798289
2023-10-29 23:40:50,371 Epoch: [22/484] Iter:[140/495], Time: 0.39, lr: [0.009584679574239245], Loss: 2.196078, Acc:0.786561, Semantic loss: 0.827296, BCE loss: 0.573951, SB loss: 0.794831
2023-10-29 23:40:54,084 Epoch: [22/484] Iter:[150/495], Time: 0.39, lr: [0.009584302141271022], Loss: 2.194570, Acc:0.785855, Semantic loss: 0.825776, BCE loss: 0.575362, SB loss: 0.793432
2023-10-29 23:40:57,907 Epoch: [22/484] Iter:[160/495], Time: 0.39, lr: [0.0095839247066513], Loss: 2.189377, Acc:0.788539, Semantic loss: 0.820898, BCE loss: 0.578566, SB loss: 0.789913
2023-10-29 23:41:01,654 Epoch: [22/484] Iter:[170/495], Time: 0.39, lr: [0.009583547270379997], Loss: 2.188297, Acc:0.787982, Semantic loss: 0.821339, BCE loss: 0.576442, SB loss: 0.790517
2023-10-29 23:41:05,444 Epoch: [22/484] Iter:[180/495], Time: 0.39, lr: [0.009583169832457036], Loss: 2.183037, Acc:0.789221, Semantic loss: 0.817745, BCE loss: 0.575655, SB loss: 0.789637
2023-10-29 23:41:09,306 Epoch: [22/484] Iter:[190/495], Time: 0.39, lr: [0.009582792392882337], Loss: 2.177261, Acc:0.789898, Semantic loss: 0.814211, BCE loss: 0.575790, SB loss: 0.787260
2023-10-29 23:41:13,153 Epoch: [22/484] Iter:[200/495], Time: 0.39, lr: [0.009582414951655821], Loss: 2.182522, Acc:0.790195, Semantic loss: 0.816150, BCE loss: 0.579411, SB loss: 0.786961
2023-10-29 23:41:16,968 Epoch: [22/484] Iter:[210/495], Time: 0.39, lr: [0.009582037508777405], Loss: 2.192872, Acc:0.787618, Semantic loss: 0.825820, BCE loss: 0.577979, SB loss: 0.789073
2023-10-29 23:41:20,822 Epoch: [22/484] Iter:[220/495], Time: 0.39, lr: [0.009581660064247014], Loss: 2.197619, Acc:0.786977, Semantic loss: 0.830619, BCE loss: 0.577194, SB loss: 0.789806
2023-10-29 23:41:24,582 Epoch: [22/484] Iter:[230/495], Time: 0.39, lr: [0.009581282618064567], Loss: 2.205269, Acc:0.786365, Semantic loss: 0.832250, BCE loss: 0.580144, SB loss: 0.792875
2023-10-29 23:41:28,279 Epoch: [22/484] Iter:[240/495], Time: 0.39, lr: [0.009580905170229982], Loss: 2.207804, Acc:0.785355, Semantic loss: 0.834491, BCE loss: 0.578924, SB loss: 0.794389
2023-10-29 23:41:32,057 Epoch: [22/484] Iter:[250/495], Time: 0.39, lr: [0.009580527720743182], Loss: 2.200453, Acc:0.785576, Semantic loss: 0.830720, BCE loss: 0.577249, SB loss: 0.792485
2023-10-29 23:41:35,905 Epoch: [22/484] Iter:[260/495], Time: 0.39, lr: [0.009580150269604086], Loss: 2.198039, Acc:0.785505, Semantic loss: 0.829387, BCE loss: 0.575238, SB loss: 0.793414
2023-10-29 23:41:39,798 Epoch: [22/484] Iter:[270/495], Time: 0.39, lr: [0.009579772816812618], Loss: 2.205013, Acc:0.785250, Semantic loss: 0.834427, BCE loss: 0.574170, SB loss: 0.796415
2023-10-29 23:41:43,623 Epoch: [22/484] Iter:[280/495], Time: 0.39, lr: [0.009579395362368693], Loss: 2.204907, Acc:0.784747, Semantic loss: 0.833535, BCE loss: 0.574399, SB loss: 0.796973
2023-10-29 23:41:47,424 Epoch: [22/484] Iter:[290/495], Time: 0.39, lr: [0.009579017906272235], Loss: 2.203752, Acc:0.785569, Semantic loss: 0.832091, BCE loss: 0.574976, SB loss: 0.796684
2023-10-29 23:41:51,287 Epoch: [22/484] Iter:[300/495], Time: 0.39, lr: [0.009578640448523164], Loss: 2.205610, Acc:0.784336, Semantic loss: 0.835405, BCE loss: 0.571922, SB loss: 0.798284
2023-10-29 23:41:55,011 Epoch: [22/484] Iter:[310/495], Time: 0.38, lr: [0.009578262989121398], Loss: 2.206792, Acc:0.783774, Semantic loss: 0.836251, BCE loss: 0.571377, SB loss: 0.799164
2023-10-29 23:41:58,879 Epoch: [22/484] Iter:[320/495], Time: 0.38, lr: [0.009577885528066862], Loss: 2.215797, Acc:0.783708, Semantic loss: 0.840814, BCE loss: 0.572550, SB loss: 0.802434
2023-10-29 23:42:02,728 Epoch: [22/484] Iter:[330/495], Time: 0.38, lr: [0.009577508065359472], Loss: 2.212647, Acc:0.784450, Semantic loss: 0.837611, BCE loss: 0.574022, SB loss: 0.801013
2023-10-29 23:42:06,719 Epoch: [22/484] Iter:[340/495], Time: 0.39, lr: [0.00957713060099915], Loss: 2.217694, Acc:0.784045, Semantic loss: 0.841664, BCE loss: 0.573341, SB loss: 0.802689
2023-10-29 23:42:10,498 Epoch: [22/484] Iter:[350/495], Time: 0.39, lr: [0.009576753134985818], Loss: 2.217675, Acc:0.783717, Semantic loss: 0.840814, BCE loss: 0.573248, SB loss: 0.803613
2023-10-29 23:42:14,229 Epoch: [22/484] Iter:[360/495], Time: 0.38, lr: [0.009576375667319392], Loss: 2.220249, Acc:0.783826, Semantic loss: 0.844395, BCE loss: 0.572255, SB loss: 0.803599
2023-10-29 23:42:18,036 Epoch: [22/484] Iter:[370/495], Time: 0.38, lr: [0.009575998197999798], Loss: 2.231514, Acc:0.781294, Semantic loss: 0.853056, BCE loss: 0.572300, SB loss: 0.806157
2023-10-29 23:42:21,904 Epoch: [22/484] Iter:[380/495], Time: 0.38, lr: [0.009575620727026952], Loss: 2.233548, Acc:0.780788, Semantic loss: 0.853738, BCE loss: 0.572633, SB loss: 0.807177
2023-10-29 23:42:25,791 Epoch: [22/484] Iter:[390/495], Time: 0.38, lr: [0.009575243254400775], Loss: 2.234060, Acc:0.781235, Semantic loss: 0.853560, BCE loss: 0.572768, SB loss: 0.807731
2023-10-29 23:42:29,630 Epoch: [22/484] Iter:[400/495], Time: 0.38, lr: [0.009574865780121192], Loss: 2.234986, Acc:0.780998, Semantic loss: 0.854368, BCE loss: 0.573146, SB loss: 0.807471
2023-10-29 23:42:33,474 Epoch: [22/484] Iter:[410/495], Time: 0.38, lr: [0.009574488304188116], Loss: 2.232739, Acc:0.781381, Semantic loss: 0.853751, BCE loss: 0.571270, SB loss: 0.807718
2023-10-29 23:42:37,413 Epoch: [22/484] Iter:[420/495], Time: 0.39, lr: [0.009574110826601472], Loss: 2.231675, Acc:0.782016, Semantic loss: 0.851332, BCE loss: 0.572629, SB loss: 0.807714
2023-10-29 23:42:41,281 Epoch: [22/484] Iter:[430/495], Time: 0.39, lr: [0.00957373334736118], Loss: 2.230108, Acc:0.783053, Semantic loss: 0.849642, BCE loss: 0.573049, SB loss: 0.807416
2023-10-29 23:42:45,133 Epoch: [22/484] Iter:[440/495], Time: 0.39, lr: [0.009573355866467157], Loss: 2.231608, Acc:0.783488, Semantic loss: 0.849967, BCE loss: 0.573918, SB loss: 0.807723
2023-10-29 23:42:48,889 Epoch: [22/484] Iter:[450/495], Time: 0.38, lr: [0.009572978383919328], Loss: 2.230811, Acc:0.783801, Semantic loss: 0.849650, BCE loss: 0.573147, SB loss: 0.808013
2023-10-29 23:42:52,601 Epoch: [22/484] Iter:[460/495], Time: 0.38, lr: [0.00957260089971761], Loss: 2.228250, Acc:0.784150, Semantic loss: 0.848685, BCE loss: 0.571871, SB loss: 0.807694
2023-10-29 23:42:56,336 Epoch: [22/484] Iter:[470/495], Time: 0.38, lr: [0.009572223413861925], Loss: 2.226438, Acc:0.784654, Semantic loss: 0.847665, BCE loss: 0.571831, SB loss: 0.806943
2023-10-29 23:43:00,117 Epoch: [22/484] Iter:[480/495], Time: 0.38, lr: [0.009571845926352194], Loss: 2.225767, Acc:0.784527, Semantic loss: 0.847291, BCE loss: 0.571001, SB loss: 0.807475
2023-10-29 23:43:03,680 Epoch: [22/484] Iter:[490/495], Time: 0.38, lr: [0.009571468437188334], Loss: 2.221382, Acc:0.784441, Semantic loss: 0.844556, BCE loss: 0.569962, SB loss: 0.806863
2023-10-29 23:43:05,129 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:43:05,369 Loss: 2.176, MeanIU:  0.6379, Best_mIoU:  0.6427
2023-10-29 23:43:05,369 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903]
2023-10-29 23:43:07,206 Epoch: [23/484] Iter:[0/495], Time: 1.80, lr: [0.009571279691986082], Loss: 2.996715, Acc:0.722427, Semantic loss: 1.486955, BCE loss: 0.649123, SB loss: 0.860636
2023-10-29 23:43:11,393 Epoch: [23/484] Iter:[10/495], Time: 0.54, lr: [0.009570902200340882], Loss: 2.206135, Acc:0.812536, Semantic loss: 0.872309, BCE loss: 0.560428, SB loss: 0.773398
2023-10-29 23:43:15,142 Epoch: [23/484] Iter:[20/495], Time: 0.46, lr: [0.009570524707041356], Loss: 2.176953, Acc:0.790166, Semantic loss: 0.841214, BCE loss: 0.551990, SB loss: 0.783750
2023-10-29 23:43:18,948 Epoch: [23/484] Iter:[30/495], Time: 0.44, lr: [0.009570147212087423], Loss: 2.200974, Acc:0.788394, Semantic loss: 0.830755, BCE loss: 0.575183, SB loss: 0.795036
2023-10-29 23:43:22,734 Epoch: [23/484] Iter:[40/495], Time: 0.42, lr: [0.009569769715479005], Loss: 2.177094, Acc:0.786993, Semantic loss: 0.822298, BCE loss: 0.567089, SB loss: 0.787708
2023-10-29 23:43:26,567 Epoch: [23/484] Iter:[50/495], Time: 0.41, lr: [0.009569392217216022], Loss: 2.170630, Acc:0.791885, Semantic loss: 0.821703, BCE loss: 0.559181, SB loss: 0.789747
2023-10-29 23:43:30,309 Epoch: [23/484] Iter:[60/495], Time: 0.41, lr: [0.009569014717298393], Loss: 2.209053, Acc:0.792984, Semantic loss: 0.835980, BCE loss: 0.565272, SB loss: 0.807801
2023-10-29 23:43:34,075 Epoch: [23/484] Iter:[70/495], Time: 0.40, lr: [0.009568637215726037], Loss: 2.199777, Acc:0.790962, Semantic loss: 0.830426, BCE loss: 0.562720, SB loss: 0.806631
2023-10-29 23:43:37,814 Epoch: [23/484] Iter:[80/495], Time: 0.40, lr: [0.009568259712498878], Loss: 2.205169, Acc:0.788527, Semantic loss: 0.835317, BCE loss: 0.560549, SB loss: 0.809302
2023-10-29 23:43:41,518 Epoch: [23/484] Iter:[90/495], Time: 0.40, lr: [0.009567882207616835], Loss: 2.198601, Acc:0.784904, Semantic loss: 0.833509, BCE loss: 0.561757, SB loss: 0.803335
2023-10-29 23:43:45,328 Epoch: [23/484] Iter:[100/495], Time: 0.40, lr: [0.009567504701079825], Loss: 2.208591, Acc:0.783252, Semantic loss: 0.845794, BCE loss: 0.555627, SB loss: 0.807169
2023-10-29 23:43:49,109 Epoch: [23/484] Iter:[110/495], Time: 0.39, lr: [0.009567127192887772], Loss: 2.201826, Acc:0.782390, Semantic loss: 0.838442, BCE loss: 0.556925, SB loss: 0.806460
2023-10-29 23:43:52,938 Epoch: [23/484] Iter:[120/495], Time: 0.39, lr: [0.009566749683040594], Loss: 2.200719, Acc:0.782553, Semantic loss: 0.840031, BCE loss: 0.554399, SB loss: 0.806288
2023-10-29 23:43:56,715 Epoch: [23/484] Iter:[130/495], Time: 0.39, lr: [0.009566372171538213], Loss: 2.204534, Acc:0.781969, Semantic loss: 0.840319, BCE loss: 0.559553, SB loss: 0.804662
2023-10-29 23:44:00,522 Epoch: [23/484] Iter:[140/495], Time: 0.39, lr: [0.009565994658380548], Loss: 2.200045, Acc:0.781702, Semantic loss: 0.835447, BCE loss: 0.560621, SB loss: 0.803977
2023-10-29 23:44:04,272 Epoch: [23/484] Iter:[150/495], Time: 0.39, lr: [0.009565617143567516], Loss: 2.205561, Acc:0.782033, Semantic loss: 0.836921, BCE loss: 0.564638, SB loss: 0.804002
2023-10-29 23:44:08,169 Epoch: [23/484] Iter:[160/495], Time: 0.39, lr: [0.009565239627099044], Loss: 2.205922, Acc:0.781839, Semantic loss: 0.837592, BCE loss: 0.564393, SB loss: 0.803937
2023-10-29 23:44:12,016 Epoch: [23/484] Iter:[170/495], Time: 0.39, lr: [0.009564862108975048], Loss: 2.203696, Acc:0.783150, Semantic loss: 0.834606, BCE loss: 0.566935, SB loss: 0.802155
2023-10-29 23:44:15,781 Epoch: [23/484] Iter:[180/495], Time: 0.39, lr: [0.009564484589195447], Loss: 2.208467, Acc:0.783034, Semantic loss: 0.837354, BCE loss: 0.566434, SB loss: 0.804679
2023-10-29 23:44:19,528 Epoch: [23/484] Iter:[190/495], Time: 0.39, lr: [0.009564107067760164], Loss: 2.206080, Acc:0.784070, Semantic loss: 0.832112, BCE loss: 0.568417, SB loss: 0.805550
2023-10-29 23:44:23,295 Epoch: [23/484] Iter:[200/495], Time: 0.39, lr: [0.009563729544669117], Loss: 2.209334, Acc:0.784968, Semantic loss: 0.833481, BCE loss: 0.569274, SB loss: 0.806578
2023-10-29 23:44:27,097 Epoch: [23/484] Iter:[210/495], Time: 0.39, lr: [0.00956335201992223], Loss: 2.207842, Acc:0.783729, Semantic loss: 0.831935, BCE loss: 0.570000, SB loss: 0.805906
2023-10-29 23:44:30,933 Epoch: [23/484] Iter:[220/495], Time: 0.39, lr: [0.009562974493519416], Loss: 2.209179, Acc:0.781058, Semantic loss: 0.833437, BCE loss: 0.569587, SB loss: 0.806155
2023-10-29 23:44:34,730 Epoch: [23/484] Iter:[230/495], Time: 0.39, lr: [0.009562596965460602], Loss: 2.207484, Acc:0.781182, Semantic loss: 0.832632, BCE loss: 0.569837, SB loss: 0.805015
2023-10-29 23:44:38,497 Epoch: [23/484] Iter:[240/495], Time: 0.39, lr: [0.009562219435745704], Loss: 2.208296, Acc:0.782580, Semantic loss: 0.831737, BCE loss: 0.570246, SB loss: 0.806312
2023-10-29 23:44:42,252 Epoch: [23/484] Iter:[250/495], Time: 0.39, lr: [0.009561841904374644], Loss: 2.209459, Acc:0.782586, Semantic loss: 0.833421, BCE loss: 0.570514, SB loss: 0.805524
2023-10-29 23:44:46,018 Epoch: [23/484] Iter:[260/495], Time: 0.39, lr: [0.00956146437134734], Loss: 2.212103, Acc:0.781331, Semantic loss: 0.835232, BCE loss: 0.570748, SB loss: 0.806124
2023-10-29 23:44:49,691 Epoch: [23/484] Iter:[270/495], Time: 0.38, lr: [0.009561086836663716], Loss: 2.204981, Acc:0.781577, Semantic loss: 0.830237, BCE loss: 0.570121, SB loss: 0.804623
2023-10-29 23:44:53,404 Epoch: [23/484] Iter:[280/495], Time: 0.38, lr: [0.009560709300323688], Loss: 2.201881, Acc:0.782325, Semantic loss: 0.827887, BCE loss: 0.571029, SB loss: 0.802965
2023-10-29 23:44:57,123 Epoch: [23/484] Iter:[290/495], Time: 0.38, lr: [0.009560331762327179], Loss: 2.197073, Acc:0.782838, Semantic loss: 0.825176, BCE loss: 0.570040, SB loss: 0.801857
2023-10-29 23:45:00,846 Epoch: [23/484] Iter:[300/495], Time: 0.38, lr: [0.009559954222674106], Loss: 2.192332, Acc:0.782636, Semantic loss: 0.823736, BCE loss: 0.568978, SB loss: 0.799617
2023-10-29 23:45:04,659 Epoch: [23/484] Iter:[310/495], Time: 0.38, lr: [0.009559576681364392], Loss: 2.193023, Acc:0.783093, Semantic loss: 0.823685, BCE loss: 0.570711, SB loss: 0.798626
2023-10-29 23:45:08,365 Epoch: [23/484] Iter:[320/495], Time: 0.38, lr: [0.009559199138397955], Loss: 2.192857, Acc:0.784060, Semantic loss: 0.823161, BCE loss: 0.571399, SB loss: 0.798297
2023-10-29 23:45:12,199 Epoch: [23/484] Iter:[330/495], Time: 0.38, lr: [0.009558821593774717], Loss: 2.195976, Acc:0.784006, Semantic loss: 0.825556, BCE loss: 0.572632, SB loss: 0.797788
2023-10-29 23:45:16,010 Epoch: [23/484] Iter:[340/495], Time: 0.38, lr: [0.009558444047494596], Loss: 2.192195, Acc:0.783745, Semantic loss: 0.824246, BCE loss: 0.571526, SB loss: 0.796424
2023-10-29 23:45:19,773 Epoch: [23/484] Iter:[350/495], Time: 0.38, lr: [0.009558066499557512], Loss: 2.193190, Acc:0.783340, Semantic loss: 0.826607, BCE loss: 0.570012, SB loss: 0.796571
2023-10-29 23:45:23,569 Epoch: [23/484] Iter:[360/495], Time: 0.38, lr: [0.009557688949963387], Loss: 2.189892, Acc:0.784060, Semantic loss: 0.824679, BCE loss: 0.568622, SB loss: 0.796591
2023-10-29 23:45:27,374 Epoch: [23/484] Iter:[370/495], Time: 0.38, lr: [0.00955731139871214], Loss: 2.191497, Acc:0.782460, Semantic loss: 0.825998, BCE loss: 0.567581, SB loss: 0.797917
2023-10-29 23:45:31,112 Epoch: [23/484] Iter:[380/495], Time: 0.38, lr: [0.009556933845803691], Loss: 2.202704, Acc:0.783202, Semantic loss: 0.832613, BCE loss: 0.570272, SB loss: 0.799819
2023-10-29 23:45:34,926 Epoch: [23/484] Iter:[390/495], Time: 0.38, lr: [0.009556556291237958], Loss: 2.206932, Acc:0.783137, Semantic loss: 0.834428, BCE loss: 0.570440, SB loss: 0.802064
2023-10-29 23:45:38,629 Epoch: [23/484] Iter:[400/495], Time: 0.38, lr: [0.009556178735014865], Loss: 2.206298, Acc:0.782838, Semantic loss: 0.833852, BCE loss: 0.570387, SB loss: 0.802059
2023-10-29 23:45:42,402 Epoch: [23/484] Iter:[410/495], Time: 0.38, lr: [0.00955580117713433], Loss: 2.204911, Acc:0.783392, Semantic loss: 0.834111, BCE loss: 0.569970, SB loss: 0.800830
2023-10-29 23:45:46,118 Epoch: [23/484] Iter:[420/495], Time: 0.38, lr: [0.009555423617596271], Loss: 2.204830, Acc:0.783178, Semantic loss: 0.835217, BCE loss: 0.568857, SB loss: 0.800756
2023-10-29 23:45:49,880 Epoch: [23/484] Iter:[430/495], Time: 0.38, lr: [0.009555046056400611], Loss: 2.201597, Acc:0.784075, Semantic loss: 0.832402, BCE loss: 0.568878, SB loss: 0.800317
2023-10-29 23:45:53,636 Epoch: [23/484] Iter:[440/495], Time: 0.38, lr: [0.009554668493547268], Loss: 2.198453, Acc:0.783903, Semantic loss: 0.831674, BCE loss: 0.566261, SB loss: 0.800519
2023-10-29 23:45:57,437 Epoch: [23/484] Iter:[450/495], Time: 0.38, lr: [0.009554290929036164], Loss: 2.198933, Acc:0.783961, Semantic loss: 0.831649, BCE loss: 0.566654, SB loss: 0.800630
2023-10-29 23:46:01,251 Epoch: [23/484] Iter:[460/495], Time: 0.38, lr: [0.009553913362867214], Loss: 2.199534, Acc:0.783507, Semantic loss: 0.831923, BCE loss: 0.566552, SB loss: 0.801059
2023-10-29 23:46:05,099 Epoch: [23/484] Iter:[470/495], Time: 0.38, lr: [0.009553535795040344], Loss: 2.197396, Acc:0.783790, Semantic loss: 0.830093, BCE loss: 0.567412, SB loss: 0.799890
2023-10-29 23:46:08,834 Epoch: [23/484] Iter:[480/495], Time: 0.38, lr: [0.009553158225555471], Loss: 2.204357, Acc:0.783730, Semantic loss: 0.834893, BCE loss: 0.567044, SB loss: 0.802421
2023-10-29 23:46:12,427 Epoch: [23/484] Iter:[490/495], Time: 0.38, lr: [0.009552780654412516], Loss: 2.205195, Acc:0.783060, Semantic loss: 0.835849, BCE loss: 0.566473, SB loss: 0.802873
2023-10-29 23:46:13,869 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:46:14,115 Loss: 2.176, MeanIU:  0.6379, Best_mIoU:  0.6427
2023-10-29 23:46:14,115 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903]
2023-10-29 23:46:16,303 Epoch: [24/484] Iter:[0/495], Time: 2.15, lr: [0.00955259186821923], Loss: 1.979457, Acc:0.858647, Semantic loss: 0.593080, BCE loss: 0.631146, SB loss: 0.755231
2023-10-29 23:46:20,263 Epoch: [24/484] Iter:[10/495], Time: 0.56, lr: [0.009552214294589], Loss: 2.147665, Acc:0.800385, Semantic loss: 0.774498, BCE loss: 0.550366, SB loss: 0.822801
2023-10-29 23:46:23,987 Epoch: [24/484] Iter:[20/495], Time: 0.47, lr: [0.009551836719300488], Loss: 2.291483, Acc:0.770184, Semantic loss: 0.859321, BCE loss: 0.581109, SB loss: 0.851052
2023-10-29 23:46:27,649 Epoch: [24/484] Iter:[30/495], Time: 0.44, lr: [0.009551459142353612], Loss: 2.279097, Acc:0.763218, Semantic loss: 0.877580, BCE loss: 0.564403, SB loss: 0.837114
2023-10-29 23:46:31,334 Epoch: [24/484] Iter:[40/495], Time: 0.42, lr: [0.009551081563748292], Loss: 2.211015, Acc:0.767159, Semantic loss: 0.845816, BCE loss: 0.553991, SB loss: 0.811208
2023-10-29 23:46:35,034 Epoch: [24/484] Iter:[50/495], Time: 0.41, lr: [0.009550703983484449], Loss: 2.173958, Acc:0.768609, Semantic loss: 0.823344, BCE loss: 0.546024, SB loss: 0.804589
2023-10-29 23:46:38,822 Epoch: [24/484] Iter:[60/495], Time: 0.40, lr: [0.009550326401562002], Loss: 2.157494, Acc:0.765642, Semantic loss: 0.812347, BCE loss: 0.543256, SB loss: 0.801892
2023-10-29 23:46:42,621 Epoch: [24/484] Iter:[70/495], Time: 0.40, lr: [0.009549948817980873], Loss: 2.162665, Acc:0.764648, Semantic loss: 0.821592, BCE loss: 0.540843, SB loss: 0.800230
2023-10-29 23:46:46,309 Epoch: [24/484] Iter:[80/495], Time: 0.40, lr: [0.009549571232740977], Loss: 2.171103, Acc:0.771141, Semantic loss: 0.828121, BCE loss: 0.545247, SB loss: 0.797735
2023-10-29 23:46:50,118 Epoch: [24/484] Iter:[90/495], Time: 0.40, lr: [0.00954919364584224], Loss: 2.176660, Acc:0.776365, Semantic loss: 0.825851, BCE loss: 0.553911, SB loss: 0.796898
2023-10-29 23:46:53,878 Epoch: [24/484] Iter:[100/495], Time: 0.39, lr: [0.009548816057284578], Loss: 2.191032, Acc:0.775357, Semantic loss: 0.833416, BCE loss: 0.556347, SB loss: 0.801269
2023-10-29 23:46:57,738 Epoch: [24/484] Iter:[110/495], Time: 0.39, lr: [0.009548438467067911], Loss: 2.186869, Acc:0.776748, Semantic loss: 0.828861, BCE loss: 0.558421, SB loss: 0.799587
2023-10-29 23:47:01,538 Epoch: [24/484] Iter:[120/495], Time: 0.39, lr: [0.00954806087519216], Loss: 2.179117, Acc:0.778418, Semantic loss: 0.823397, BCE loss: 0.558553, SB loss: 0.797167
2023-10-29 23:47:05,257 Epoch: [24/484] Iter:[130/495], Time: 0.39, lr: [0.009547683281657244], Loss: 2.169085, Acc:0.778215, Semantic loss: 0.819382, BCE loss: 0.554646, SB loss: 0.795056
2023-10-29 23:47:09,058 Epoch: [24/484] Iter:[140/495], Time: 0.39, lr: [0.009547305686463085], Loss: 2.172139, Acc:0.776448, Semantic loss: 0.823216, BCE loss: 0.552735, SB loss: 0.796188
2023-10-29 23:47:12,805 Epoch: [24/484] Iter:[150/495], Time: 0.39, lr: [0.009546928089609599], Loss: 2.162017, Acc:0.778939, Semantic loss: 0.816262, BCE loss: 0.550418, SB loss: 0.795336
2023-10-29 23:47:16,526 Epoch: [24/484] Iter:[160/495], Time: 0.39, lr: [0.009546550491096708], Loss: 2.174014, Acc:0.778425, Semantic loss: 0.823047, BCE loss: 0.552459, SB loss: 0.798508
2023-10-29 23:47:20,293 Epoch: [24/484] Iter:[170/495], Time: 0.39, lr: [0.009546172890924331], Loss: 2.179686, Acc:0.778134, Semantic loss: 0.825342, BCE loss: 0.554924, SB loss: 0.799420
2023-10-29 23:47:24,065 Epoch: [24/484] Iter:[180/495], Time: 0.39, lr: [0.009545795289092388], Loss: 2.174627, Acc:0.778727, Semantic loss: 0.821371, BCE loss: 0.554673, SB loss: 0.798583
2023-10-29 23:47:27,836 Epoch: [24/484] Iter:[190/495], Time: 0.39, lr: [0.0095454176856008], Loss: 2.168226, Acc:0.780713, Semantic loss: 0.817919, BCE loss: 0.553179, SB loss: 0.797128
2023-10-29 23:47:31,542 Epoch: [24/484] Iter:[200/495], Time: 0.39, lr: [0.009545040080449483], Loss: 2.178412, Acc:0.781011, Semantic loss: 0.821367, BCE loss: 0.555980, SB loss: 0.801065
2023-10-29 23:47:35,419 Epoch: [24/484] Iter:[210/495], Time: 0.39, lr: [0.009544662473638364], Loss: 2.178913, Acc:0.782731, Semantic loss: 0.820724, BCE loss: 0.558613, SB loss: 0.799575
2023-10-29 23:47:39,304 Epoch: [24/484] Iter:[220/495], Time: 0.39, lr: [0.009544284865167356], Loss: 2.174433, Acc:0.784336, Semantic loss: 0.818751, BCE loss: 0.556826, SB loss: 0.798856
2023-10-29 23:47:43,125 Epoch: [24/484] Iter:[230/495], Time: 0.39, lr: [0.009543907255036382], Loss: 2.176168, Acc:0.785013, Semantic loss: 0.821661, BCE loss: 0.553401, SB loss: 0.801106
2023-10-29 23:47:46,906 Epoch: [24/484] Iter:[240/495], Time: 0.38, lr: [0.009543529643245358], Loss: 2.174842, Acc:0.786382, Semantic loss: 0.820185, BCE loss: 0.555013, SB loss: 0.799644
2023-10-29 23:47:50,623 Epoch: [24/484] Iter:[250/495], Time: 0.38, lr: [0.009543152029794208], Loss: 2.178281, Acc:0.785550, Semantic loss: 0.821705, BCE loss: 0.556869, SB loss: 0.799706
2023-10-29 23:47:54,412 Epoch: [24/484] Iter:[260/495], Time: 0.38, lr: [0.009542774414682851], Loss: 2.173909, Acc:0.785158, Semantic loss: 0.818833, BCE loss: 0.557037, SB loss: 0.798040
2023-10-29 23:47:58,144 Epoch: [24/484] Iter:[270/495], Time: 0.38, lr: [0.009542396797911204], Loss: 2.173067, Acc:0.785137, Semantic loss: 0.820369, BCE loss: 0.554785, SB loss: 0.797913
2023-10-29 23:48:02,010 Epoch: [24/484] Iter:[280/495], Time: 0.38, lr: [0.00954201917947919], Loss: 2.171677, Acc:0.784879, Semantic loss: 0.821016, BCE loss: 0.553071, SB loss: 0.797589
2023-10-29 23:48:05,784 Epoch: [24/484] Iter:[290/495], Time: 0.38, lr: [0.009541641559386726], Loss: 2.171421, Acc:0.784593, Semantic loss: 0.820079, BCE loss: 0.554930, SB loss: 0.796411
2023-10-29 23:48:09,546 Epoch: [24/484] Iter:[300/495], Time: 0.38, lr: [0.009541263937633736], Loss: 2.167302, Acc:0.784274, Semantic loss: 0.818050, BCE loss: 0.554150, SB loss: 0.795101
2023-10-29 23:48:13,323 Epoch: [24/484] Iter:[310/495], Time: 0.38, lr: [0.009540886314220133], Loss: 2.163270, Acc:0.784942, Semantic loss: 0.815358, BCE loss: 0.554673, SB loss: 0.793239
2023-10-29 23:48:17,005 Epoch: [24/484] Iter:[320/495], Time: 0.38, lr: [0.00954050868914584], Loss: 2.163353, Acc:0.785184, Semantic loss: 0.814712, BCE loss: 0.555430, SB loss: 0.793212
2023-10-29 23:48:20,746 Epoch: [24/484] Iter:[330/495], Time: 0.38, lr: [0.00954013106241078], Loss: 2.156822, Acc:0.786052, Semantic loss: 0.812105, BCE loss: 0.553222, SB loss: 0.791495
2023-10-29 23:48:24,607 Epoch: [24/484] Iter:[340/495], Time: 0.38, lr: [0.009539753434014869], Loss: 2.159562, Acc:0.786078, Semantic loss: 0.815354, BCE loss: 0.552077, SB loss: 0.792131
2023-10-29 23:48:28,377 Epoch: [24/484] Iter:[350/495], Time: 0.38, lr: [0.009539375803958026], Loss: 2.156105, Acc:0.786554, Semantic loss: 0.814022, BCE loss: 0.550330, SB loss: 0.791753
2023-10-29 23:48:32,067 Epoch: [24/484] Iter:[360/495], Time: 0.38, lr: [0.009538998172240172], Loss: 2.155108, Acc:0.786858, Semantic loss: 0.812792, BCE loss: 0.550350, SB loss: 0.791966
2023-10-29 23:48:35,790 Epoch: [24/484] Iter:[370/495], Time: 0.38, lr: [0.009538620538861226], Loss: 2.161345, Acc:0.786857, Semantic loss: 0.814476, BCE loss: 0.553262, SB loss: 0.793607
2023-10-29 23:48:39,553 Epoch: [24/484] Iter:[380/495], Time: 0.38, lr: [0.009538242903821109], Loss: 2.163650, Acc:0.786919, Semantic loss: 0.816435, BCE loss: 0.554038, SB loss: 0.793178
2023-10-29 23:48:43,351 Epoch: [24/484] Iter:[390/495], Time: 0.38, lr: [0.009537865267119739], Loss: 2.167775, Acc:0.786606, Semantic loss: 0.817789, BCE loss: 0.556316, SB loss: 0.793670
2023-10-29 23:48:47,168 Epoch: [24/484] Iter:[400/495], Time: 0.38, lr: [0.009537487628757035], Loss: 2.166764, Acc:0.786234, Semantic loss: 0.815665, BCE loss: 0.557375, SB loss: 0.793724
2023-10-29 23:48:50,961 Epoch: [24/484] Iter:[410/495], Time: 0.38, lr: [0.00953710998873292], Loss: 2.173527, Acc:0.786402, Semantic loss: 0.818992, BCE loss: 0.559050, SB loss: 0.795486
2023-10-29 23:48:54,851 Epoch: [24/484] Iter:[420/495], Time: 0.38, lr: [0.009536732347047312], Loss: 2.170887, Acc:0.786434, Semantic loss: 0.817767, BCE loss: 0.558481, SB loss: 0.794640
2023-10-29 23:48:58,540 Epoch: [24/484] Iter:[430/495], Time: 0.38, lr: [0.009536354703700128], Loss: 2.174104, Acc:0.787116, Semantic loss: 0.819706, BCE loss: 0.559176, SB loss: 0.795222
2023-10-29 23:49:02,291 Epoch: [24/484] Iter:[440/495], Time: 0.38, lr: [0.00953597705869129], Loss: 2.171495, Acc:0.787353, Semantic loss: 0.818037, BCE loss: 0.559011, SB loss: 0.794446
2023-10-29 23:49:06,178 Epoch: [24/484] Iter:[450/495], Time: 0.38, lr: [0.009535599412020718], Loss: 2.176785, Acc:0.787439, Semantic loss: 0.820583, BCE loss: 0.560232, SB loss: 0.795970
2023-10-29 23:49:10,073 Epoch: [24/484] Iter:[460/495], Time: 0.38, lr: [0.009535221763688331], Loss: 2.178960, Acc:0.787069, Semantic loss: 0.824446, BCE loss: 0.558707, SB loss: 0.795807
2023-10-29 23:49:13,753 Epoch: [24/484] Iter:[470/495], Time: 0.38, lr: [0.00953484411369405], Loss: 2.181983, Acc:0.786981, Semantic loss: 0.826546, BCE loss: 0.559722, SB loss: 0.795714
2023-10-29 23:49:17,593 Epoch: [24/484] Iter:[480/495], Time: 0.38, lr: [0.00953446646203779], Loss: 2.182104, Acc:0.787104, Semantic loss: 0.825986, BCE loss: 0.561226, SB loss: 0.794891
2023-10-29 23:49:21,160 Epoch: [24/484] Iter:[490/495], Time: 0.38, lr: [0.009534088808719475], Loss: 2.184954, Acc:0.786866, Semantic loss: 0.827464, BCE loss: 0.562015, SB loss: 0.795475
2023-10-29 23:49:22,611 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:49:22,854 Loss: 2.176, MeanIU:  0.6379, Best_mIoU:  0.6427
2023-10-29 23:49:22,854 [0.96188556 0.73171073 0.89304144 0.34090698 0.50431018 0.50656735
 0.59772542 0.70820627 0.89738881 0.51437635 0.92126018 0.7251325
 0.48540365 0.90555458 0.53024266 0.59676579 0.38270536 0.26181565
 0.65436903]
2023-10-29 23:49:24,933 Epoch: [25/484] Iter:[0/495], Time: 2.04, lr: [0.00953389998143702], Loss: 1.629533, Acc:0.789319, Semantic loss: 0.505225, BCE loss: 0.524478, SB loss: 0.599830
2023-10-29 23:49:28,955 Epoch: [25/484] Iter:[10/495], Time: 0.55, lr: [0.00953352232562547], Loss: 2.189153, Acc:0.780237, Semantic loss: 0.840441, BCE loss: 0.557046, SB loss: 0.791666
2023-10-29 23:49:32,828 Epoch: [25/484] Iter:[20/495], Time: 0.47, lr: [0.009533144668151661], Loss: 2.236696, Acc:0.786008, Semantic loss: 0.878673, BCE loss: 0.562576, SB loss: 0.795447
2023-10-29 23:49:36,701 Epoch: [25/484] Iter:[30/495], Time: 0.45, lr: [0.009532767009015513], Loss: 2.217076, Acc:0.791583, Semantic loss: 0.847729, BCE loss: 0.578302, SB loss: 0.791046
2023-10-29 23:49:40,412 Epoch: [25/484] Iter:[40/495], Time: 0.43, lr: [0.009532389348216947], Loss: 2.259394, Acc:0.792815, Semantic loss: 0.864814, BCE loss: 0.584299, SB loss: 0.810281
2023-10-29 23:49:44,339 Epoch: [25/484] Iter:[50/495], Time: 0.42, lr: [0.009532011685755884], Loss: 2.259198, Acc:0.795794, Semantic loss: 0.855907, BCE loss: 0.589064, SB loss: 0.814226
2023-10-29 23:49:48,093 Epoch: [25/484] Iter:[60/495], Time: 0.41, lr: [0.009531634021632238], Loss: 2.300826, Acc:0.796468, Semantic loss: 0.893324, BCE loss: 0.592438, SB loss: 0.815063
2023-10-29 23:49:51,970 Epoch: [25/484] Iter:[70/495], Time: 0.41, lr: [0.009531256355845933], Loss: 2.286882, Acc:0.797023, Semantic loss: 0.880369, BCE loss: 0.593708, SB loss: 0.812805
2023-10-29 23:49:55,739 Epoch: [25/484] Iter:[80/495], Time: 0.41, lr: [0.009530878688396888], Loss: 2.261594, Acc:0.794813, Semantic loss: 0.862935, BCE loss: 0.593737, SB loss: 0.804922
2023-10-29 23:49:59,619 Epoch: [25/484] Iter:[90/495], Time: 0.40, lr: [0.009530501019285022], Loss: 2.250880, Acc:0.792062, Semantic loss: 0.857066, BCE loss: 0.587749, SB loss: 0.806065
2023-10-29 23:50:03,526 Epoch: [25/484] Iter:[100/495], Time: 0.40, lr: [0.009530123348510252], Loss: 2.231780, Acc:0.796592, Semantic loss: 0.842430, BCE loss: 0.587049, SB loss: 0.802301
2023-10-29 23:50:07,264 Epoch: [25/484] Iter:[110/495], Time: 0.40, lr: [0.009529745676072501], Loss: 2.233788, Acc:0.795760, Semantic loss: 0.845951, BCE loss: 0.586074, SB loss: 0.801764
2023-10-29 23:50:11,001 Epoch: [25/484] Iter:[120/495], Time: 0.40, lr: [0.009529368001971688], Loss: 2.230031, Acc:0.795708, Semantic loss: 0.844819, BCE loss: 0.584121, SB loss: 0.801092
2023-10-29 23:50:14,750 Epoch: [25/484] Iter:[130/495], Time: 0.40, lr: [0.00952899032620773], Loss: 2.223860, Acc:0.793487, Semantic loss: 0.841088, BCE loss: 0.583010, SB loss: 0.799762
2023-10-29 23:50:18,548 Epoch: [25/484] Iter:[140/495], Time: 0.39, lr: [0.009528612648780547], Loss: 2.228090, Acc:0.791899, Semantic loss: 0.844898, BCE loss: 0.581656, SB loss: 0.801537
2023-10-29 23:50:22,233 Epoch: [25/484] Iter:[150/495], Time: 0.39, lr: [0.009528234969690063], Loss: 2.221108, Acc:0.792282, Semantic loss: 0.837836, BCE loss: 0.582943, SB loss: 0.800329
2023-10-29 23:50:26,012 Epoch: [25/484] Iter:[160/495], Time: 0.39, lr: [0.009527857288936192], Loss: 2.213891, Acc:0.792144, Semantic loss: 0.837042, BCE loss: 0.577950, SB loss: 0.798899
2023-10-29 23:50:29,805 Epoch: [25/484] Iter:[170/495], Time: 0.39, lr: [0.009527479606518854], Loss: 2.205373, Acc:0.792715, Semantic loss: 0.832494, BCE loss: 0.576416, SB loss: 0.796463
2023-10-29 23:50:33,553 Epoch: [25/484] Iter:[180/495], Time: 0.39, lr: [0.009527101922437971], Loss: 2.200025, Acc:0.791117, Semantic loss: 0.829985, BCE loss: 0.574302, SB loss: 0.795738
2023-10-29 23:50:37,293 Epoch: [25/484] Iter:[190/495], Time: 0.39, lr: [0.009526724236693462], Loss: 2.195215, Acc:0.791777, Semantic loss: 0.826625, BCE loss: 0.575340, SB loss: 0.793249
2023-10-29 23:50:41,046 Epoch: [25/484] Iter:[200/495], Time: 0.39, lr: [0.009526346549285244], Loss: 2.201415, Acc:0.793251, Semantic loss: 0.830434, BCE loss: 0.576563, SB loss: 0.794419
2023-10-29 23:50:44,738 Epoch: [25/484] Iter:[210/495], Time: 0.39, lr: [0.009525968860213238], Loss: 2.202957, Acc:0.793875, Semantic loss: 0.830001, BCE loss: 0.579964, SB loss: 0.792992
2023-10-29 23:50:48,490 Epoch: [25/484] Iter:[220/495], Time: 0.39, lr: [0.009525591169477363], Loss: 2.204390, Acc:0.792973, Semantic loss: 0.831282, BCE loss: 0.578478, SB loss: 0.794629
2023-10-29 23:50:52,219 Epoch: [25/484] Iter:[230/495], Time: 0.39, lr: [0.009525213477077538], Loss: 2.199156, Acc:0.792852, Semantic loss: 0.828378, BCE loss: 0.577114, SB loss: 0.793663
2023-10-29 23:50:56,115 Epoch: [25/484] Iter:[240/495], Time: 0.39, lr: [0.009524835783013684], Loss: 2.195075, Acc:0.792662, Semantic loss: 0.824404, BCE loss: 0.578466, SB loss: 0.792205
2023-10-29 23:50:59,930 Epoch: [25/484] Iter:[250/495], Time: 0.39, lr: [0.009524458087285718], Loss: 2.197405, Acc:0.791183, Semantic loss: 0.825521, BCE loss: 0.577989, SB loss: 0.793896
2023-10-29 23:51:03,648 Epoch: [25/484] Iter:[260/495], Time: 0.39, lr: [0.009524080389893561], Loss: 2.191334, Acc:0.790972, Semantic loss: 0.821729, BCE loss: 0.576572, SB loss: 0.793033
2023-10-29 23:51:07,397 Epoch: [25/484] Iter:[270/495], Time: 0.39, lr: [0.009523702690837133], Loss: 2.187584, Acc:0.790353, Semantic loss: 0.820394, BCE loss: 0.574846, SB loss: 0.792344
2023-10-29 23:51:11,306 Epoch: [25/484] Iter:[280/495], Time: 0.39, lr: [0.009523324990116351], Loss: 2.186618, Acc:0.790659, Semantic loss: 0.820146, BCE loss: 0.575628, SB loss: 0.790844
2023-10-29 23:51:15,081 Epoch: [25/484] Iter:[290/495], Time: 0.39, lr: [0.009522947287731138], Loss: 2.182001, Acc:0.790168, Semantic loss: 0.819210, BCE loss: 0.573045, SB loss: 0.789746
2023-10-29 23:51:18,752 Epoch: [25/484] Iter:[300/495], Time: 0.38, lr: [0.009522569583681407], Loss: 2.182775, Acc:0.789598, Semantic loss: 0.820707, BCE loss: 0.570942, SB loss: 0.791126
2023-10-29 23:51:22,507 Epoch: [25/484] Iter:[310/495], Time: 0.38, lr: [0.009522191877967084], Loss: 2.182128, Acc:0.789978, Semantic loss: 0.820616, BCE loss: 0.571721, SB loss: 0.789791
2023-10-29 23:51:26,389 Epoch: [25/484] Iter:[320/495], Time: 0.38, lr: [0.009521814170588085], Loss: 2.189776, Acc:0.790688, Semantic loss: 0.825224, BCE loss: 0.572333, SB loss: 0.792218
2023-10-29 23:51:30,228 Epoch: [25/484] Iter:[330/495], Time: 0.38, lr: [0.00952143646154433], Loss: 2.192755, Acc:0.790625, Semantic loss: 0.827356, BCE loss: 0.572751, SB loss: 0.792648
2023-10-29 23:51:33,903 Epoch: [25/484] Iter:[340/495], Time: 0.38, lr: [0.009521058750835738], Loss: 2.193683, Acc:0.789608, Semantic loss: 0.827542, BCE loss: 0.572161, SB loss: 0.793980
2023-10-29 23:51:37,684 Epoch: [25/484] Iter:[350/495], Time: 0.38, lr: [0.009520681038462226], Loss: 2.194049, Acc:0.788646, Semantic loss: 0.827549, BCE loss: 0.572510, SB loss: 0.793990
2023-10-29 23:51:41,433 Epoch: [25/484] Iter:[360/495], Time: 0.38, lr: [0.00952030332442372], Loss: 2.194979, Acc:0.788869, Semantic loss: 0.828835, BCE loss: 0.571320, SB loss: 0.794824
2023-10-29 23:51:45,268 Epoch: [25/484] Iter:[370/495], Time: 0.38, lr: [0.009519925608720132], Loss: 2.196130, Acc:0.787698, Semantic loss: 0.828549, BCE loss: 0.572381, SB loss: 0.795200
2023-10-29 23:51:49,029 Epoch: [25/484] Iter:[380/495], Time: 0.38, lr: [0.009519547891351383], Loss: 2.199689, Acc:0.787534, Semantic loss: 0.829140, BCE loss: 0.574400, SB loss: 0.796148
2023-10-29 23:51:52,808 Epoch: [25/484] Iter:[390/495], Time: 0.38, lr: [0.009519170172317397], Loss: 2.195842, Acc:0.788094, Semantic loss: 0.826613, BCE loss: 0.573232, SB loss: 0.795998
2023-10-29 23:51:56,540 Epoch: [25/484] Iter:[400/495], Time: 0.38, lr: [0.009518792451618087], Loss: 2.195124, Acc:0.787683, Semantic loss: 0.827494, BCE loss: 0.571965, SB loss: 0.795666
2023-10-29 23:52:00,223 Epoch: [25/484] Iter:[410/495], Time: 0.38, lr: [0.009518414729253376], Loss: 2.191859, Acc:0.787288, Semantic loss: 0.826375, BCE loss: 0.569807, SB loss: 0.795676
2023-10-29 23:52:03,974 Epoch: [25/484] Iter:[420/495], Time: 0.38, lr: [0.00951803700522318], Loss: 2.192637, Acc:0.786974, Semantic loss: 0.828910, BCE loss: 0.567229, SB loss: 0.796498
2023-10-29 23:52:07,828 Epoch: [25/484] Iter:[430/495], Time: 0.38, lr: [0.009517659279527423], Loss: 2.191288, Acc:0.787074, Semantic loss: 0.828814, BCE loss: 0.566831, SB loss: 0.795643
2023-10-29 23:52:11,604 Epoch: [25/484] Iter:[440/495], Time: 0.38, lr: [0.00951728155216602], Loss: 2.198647, Acc:0.787205, Semantic loss: 0.833748, BCE loss: 0.567974, SB loss: 0.796924
2023-10-29 23:52:15,403 Epoch: [25/484] Iter:[450/495], Time: 0.38, lr: [0.009516903823138892], Loss: 2.202345, Acc:0.786386, Semantic loss: 0.835482, BCE loss: 0.567858, SB loss: 0.799004
2023-10-29 23:52:19,218 Epoch: [25/484] Iter:[460/495], Time: 0.38, lr: [0.009516526092445958], Loss: 2.206445, Acc:0.786184, Semantic loss: 0.836834, BCE loss: 0.568615, SB loss: 0.800997
2023-10-29 23:52:22,973 Epoch: [25/484] Iter:[470/495], Time: 0.38, lr: [0.009516148360087138], Loss: 2.207172, Acc:0.786011, Semantic loss: 0.838536, BCE loss: 0.567374, SB loss: 0.801262
2023-10-29 23:52:26,676 Epoch: [25/484] Iter:[480/495], Time: 0.38, lr: [0.00951577062606235], Loss: 2.207267, Acc:0.785898, Semantic loss: 0.839187, BCE loss: 0.566448, SB loss: 0.801632
2023-10-29 23:52:30,283 Epoch: [25/484] Iter:[490/495], Time: 0.38, lr: [0.009515392890371512], Loss: 2.207233, Acc:0.786653, Semantic loss: 0.837760, BCE loss: 0.567881, SB loss: 0.801592
2023-10-29 23:55:29,012 0 [9.30245541e-01 6.16920575e-01 8.05183363e-01 9.01757266e-02
 1.42682043e-01 4.01957347e-01 3.82881252e-01 5.06395180e-01
 8.68185150e-01 4.16819618e-01 8.11788808e-01 5.44118765e-01
 1.19971917e-02 7.74608722e-01 8.63639445e-04 3.54764130e-02
 1.54780594e-03 2.35888987e-02 5.12931080e-01] 0.4146509011132463
2023-10-29 23:55:29,012 1 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249] 0.610248869732058
2023-10-29 23:55:29,016 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:55:29,258 Loss: 2.199, MeanIU:  0.6102, Best_mIoU:  0.6427
2023-10-29 23:55:29,258 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249]
2023-10-29 23:55:31,321 Epoch: [26/484] Iter:[0/495], Time: 2.03, lr: [0.0095152040219013], Loss: 2.412858, Acc:0.770035, Semantic loss: 0.935856, BCE loss: 0.588644, SB loss: 0.888358
2023-10-29 23:55:35,133 Epoch: [26/484] Iter:[10/495], Time: 0.53, lr: [0.009514826283711239], Loss: 2.117525, Acc:0.770929, Semantic loss: 0.810778, BCE loss: 0.527780, SB loss: 0.778967
2023-10-29 23:55:38,804 Epoch: [26/484] Iter:[20/495], Time: 0.45, lr: [0.009514448543854926], Loss: 2.079059, Acc:0.784421, Semantic loss: 0.791027, BCE loss: 0.520323, SB loss: 0.767710
2023-10-29 23:55:42,489 Epoch: [26/484] Iter:[30/495], Time: 0.43, lr: [0.009514070802332283], Loss: 2.135716, Acc:0.792671, Semantic loss: 0.800024, BCE loss: 0.551879, SB loss: 0.783814
2023-10-29 23:55:46,071 Epoch: [26/484] Iter:[40/495], Time: 0.41, lr: [0.009513693059143225], Loss: 2.134270, Acc:0.796587, Semantic loss: 0.803543, BCE loss: 0.556521, SB loss: 0.774206
2023-10-29 23:55:49,682 Epoch: [26/484] Iter:[50/495], Time: 0.40, lr: [0.009513315314287677], Loss: 2.131078, Acc:0.797397, Semantic loss: 0.803361, BCE loss: 0.550281, SB loss: 0.777437
2023-10-29 23:55:53,375 Epoch: [26/484] Iter:[60/495], Time: 0.39, lr: [0.009512937567765554], Loss: 2.110471, Acc:0.801361, Semantic loss: 0.791926, BCE loss: 0.545275, SB loss: 0.773270
2023-10-29 23:55:57,028 Epoch: [26/484] Iter:[70/495], Time: 0.39, lr: [0.009512559819576777], Loss: 2.110112, Acc:0.799956, Semantic loss: 0.789263, BCE loss: 0.549139, SB loss: 0.771710
2023-10-29 23:56:00,773 Epoch: [26/484] Iter:[80/495], Time: 0.39, lr: [0.009512182069721261], Loss: 2.161702, Acc:0.804377, Semantic loss: 0.820585, BCE loss: 0.551837, SB loss: 0.789280
2023-10-29 23:56:04,564 Epoch: [26/484] Iter:[90/495], Time: 0.39, lr: [0.00951180431819893], Loss: 2.171537, Acc:0.805270, Semantic loss: 0.822469, BCE loss: 0.561240, SB loss: 0.787828
2023-10-29 23:56:08,238 Epoch: [26/484] Iter:[100/495], Time: 0.39, lr: [0.0095114265650097], Loss: 2.177587, Acc:0.805780, Semantic loss: 0.821468, BCE loss: 0.566290, SB loss: 0.789829
2023-10-29 23:56:11,957 Epoch: [26/484] Iter:[110/495], Time: 0.38, lr: [0.009511048810153494], Loss: 2.175008, Acc:0.804672, Semantic loss: 0.816825, BCE loss: 0.569765, SB loss: 0.788417
2023-10-29 23:56:15,638 Epoch: [26/484] Iter:[120/495], Time: 0.38, lr: [0.009510671053630227], Loss: 2.183095, Acc:0.796427, Semantic loss: 0.824852, BCE loss: 0.569213, SB loss: 0.789030
2023-10-29 23:56:19,388 Epoch: [26/484] Iter:[130/495], Time: 0.38, lr: [0.00951029329543982], Loss: 2.164280, Acc:0.796164, Semantic loss: 0.814283, BCE loss: 0.562728, SB loss: 0.787270
2023-10-29 23:56:22,995 Epoch: [26/484] Iter:[140/495], Time: 0.38, lr: [0.00950991553558219], Loss: 2.159612, Acc:0.795499, Semantic loss: 0.813151, BCE loss: 0.562443, SB loss: 0.784018
2023-10-29 23:56:26,651 Epoch: [26/484] Iter:[150/495], Time: 0.38, lr: [0.00950953777405726], Loss: 2.150771, Acc:0.793211, Semantic loss: 0.808517, BCE loss: 0.560716, SB loss: 0.781538
2023-10-29 23:56:30,364 Epoch: [26/484] Iter:[160/495], Time: 0.38, lr: [0.009509160010864945], Loss: 2.148509, Acc:0.795884, Semantic loss: 0.803354, BCE loss: 0.564674, SB loss: 0.780482
2023-10-29 23:56:34,116 Epoch: [26/484] Iter:[170/495], Time: 0.38, lr: [0.009508782246005166], Loss: 2.152450, Acc:0.796844, Semantic loss: 0.805650, BCE loss: 0.563863, SB loss: 0.782936
2023-10-29 23:56:37,819 Epoch: [26/484] Iter:[180/495], Time: 0.38, lr: [0.009508404479477843], Loss: 2.154780, Acc:0.796705, Semantic loss: 0.807920, BCE loss: 0.563782, SB loss: 0.783078
2023-10-29 23:56:41,513 Epoch: [26/484] Iter:[190/495], Time: 0.38, lr: [0.009508026711282893], Loss: 2.152652, Acc:0.796275, Semantic loss: 0.806866, BCE loss: 0.562754, SB loss: 0.783031
2023-10-29 23:56:45,195 Epoch: [26/484] Iter:[200/495], Time: 0.38, lr: [0.009507648941420236], Loss: 2.150072, Acc:0.795927, Semantic loss: 0.804554, BCE loss: 0.563088, SB loss: 0.782430
2023-10-29 23:56:48,885 Epoch: [26/484] Iter:[210/495], Time: 0.38, lr: [0.00950727116988979], Loss: 2.155770, Acc:0.797020, Semantic loss: 0.807320, BCE loss: 0.563299, SB loss: 0.785151
2023-10-29 23:56:52,642 Epoch: [26/484] Iter:[220/495], Time: 0.38, lr: [0.009506893396691475], Loss: 2.159999, Acc:0.797001, Semantic loss: 0.809822, BCE loss: 0.564301, SB loss: 0.785876
2023-10-29 23:56:56,394 Epoch: [26/484] Iter:[230/495], Time: 0.38, lr: [0.009506515621825211], Loss: 2.157216, Acc:0.796832, Semantic loss: 0.807635, BCE loss: 0.565570, SB loss: 0.784011
2023-10-29 23:57:00,184 Epoch: [26/484] Iter:[240/495], Time: 0.38, lr: [0.009506137845290915], Loss: 2.161457, Acc:0.796170, Semantic loss: 0.808919, BCE loss: 0.567106, SB loss: 0.785432
2023-10-29 23:57:03,896 Epoch: [26/484] Iter:[250/495], Time: 0.38, lr: [0.009505760067088507], Loss: 2.157608, Acc:0.794692, Semantic loss: 0.807295, BCE loss: 0.564673, SB loss: 0.785640
2023-10-29 23:57:07,673 Epoch: [26/484] Iter:[260/495], Time: 0.38, lr: [0.009505382287217905], Loss: 2.158657, Acc:0.794717, Semantic loss: 0.808389, BCE loss: 0.564421, SB loss: 0.785847
2023-10-29 23:57:11,452 Epoch: [26/484] Iter:[270/495], Time: 0.38, lr: [0.00950500450567903], Loss: 2.162919, Acc:0.794039, Semantic loss: 0.810577, BCE loss: 0.564761, SB loss: 0.787581
2023-10-29 23:57:15,238 Epoch: [26/484] Iter:[280/495], Time: 0.38, lr: [0.009504626722471798], Loss: 2.162070, Acc:0.792906, Semantic loss: 0.811946, BCE loss: 0.563184, SB loss: 0.786941
2023-10-29 23:57:18,974 Epoch: [26/484] Iter:[290/495], Time: 0.38, lr: [0.00950424893759613], Loss: 2.161532, Acc:0.793134, Semantic loss: 0.811607, BCE loss: 0.562885, SB loss: 0.787040
2023-10-29 23:57:22,785 Epoch: [26/484] Iter:[300/495], Time: 0.38, lr: [0.009503871151051948], Loss: 2.157282, Acc:0.793163, Semantic loss: 0.809728, BCE loss: 0.561749, SB loss: 0.785805
2023-10-29 23:57:26,533 Epoch: [26/484] Iter:[310/495], Time: 0.38, lr: [0.009503493362839165], Loss: 2.154566, Acc:0.793828, Semantic loss: 0.807532, BCE loss: 0.562225, SB loss: 0.784809
2023-10-29 23:57:30,342 Epoch: [26/484] Iter:[320/495], Time: 0.38, lr: [0.009503115572957702], Loss: 2.150581, Acc:0.794117, Semantic loss: 0.805347, BCE loss: 0.561371, SB loss: 0.783863
2023-10-29 23:57:34,088 Epoch: [26/484] Iter:[330/495], Time: 0.38, lr: [0.009502737781407478], Loss: 2.151627, Acc:0.793923, Semantic loss: 0.805724, BCE loss: 0.562068, SB loss: 0.783835
2023-10-29 23:57:37,764 Epoch: [26/484] Iter:[340/495], Time: 0.38, lr: [0.009502359988188413], Loss: 2.155789, Acc:0.793113, Semantic loss: 0.810023, BCE loss: 0.561631, SB loss: 0.784135
2023-10-29 23:57:41,630 Epoch: [26/484] Iter:[350/495], Time: 0.38, lr: [0.009501982193300425], Loss: 2.158985, Acc:0.792494, Semantic loss: 0.813053, BCE loss: 0.561192, SB loss: 0.784740
2023-10-29 23:57:45,427 Epoch: [26/484] Iter:[360/495], Time: 0.38, lr: [0.009501604396743434], Loss: 2.158821, Acc:0.792081, Semantic loss: 0.813281, BCE loss: 0.560480, SB loss: 0.785060
2023-10-29 23:57:49,130 Epoch: [26/484] Iter:[370/495], Time: 0.38, lr: [0.009501226598517357], Loss: 2.157111, Acc:0.792666, Semantic loss: 0.811274, BCE loss: 0.561412, SB loss: 0.784425
2023-10-29 23:57:52,863 Epoch: [26/484] Iter:[380/495], Time: 0.38, lr: [0.009500848798622116], Loss: 2.155854, Acc:0.792340, Semantic loss: 0.811841, BCE loss: 0.559689, SB loss: 0.784324
2023-10-29 23:57:56,618 Epoch: [26/484] Iter:[390/495], Time: 0.38, lr: [0.009500470997057626], Loss: 2.162422, Acc:0.792533, Semantic loss: 0.815019, BCE loss: 0.560514, SB loss: 0.786889
2023-10-29 23:58:00,468 Epoch: [26/484] Iter:[400/495], Time: 0.38, lr: [0.009500093193823805], Loss: 2.165394, Acc:0.792076, Semantic loss: 0.816536, BCE loss: 0.560887, SB loss: 0.787971
2023-10-29 23:58:04,159 Epoch: [26/484] Iter:[410/495], Time: 0.38, lr: [0.009499715388920579], Loss: 2.164264, Acc:0.791265, Semantic loss: 0.815655, BCE loss: 0.561096, SB loss: 0.787513
2023-10-29 23:58:07,868 Epoch: [26/484] Iter:[420/495], Time: 0.38, lr: [0.00949933758234786], Loss: 2.166401, Acc:0.790062, Semantic loss: 0.817567, BCE loss: 0.561163, SB loss: 0.787671
2023-10-29 23:58:11,652 Epoch: [26/484] Iter:[430/495], Time: 0.38, lr: [0.009498959774105569], Loss: 2.162165, Acc:0.790936, Semantic loss: 0.814304, BCE loss: 0.562055, SB loss: 0.785806
2023-10-29 23:58:15,370 Epoch: [26/484] Iter:[440/495], Time: 0.38, lr: [0.009498581964193625], Loss: 2.167722, Acc:0.790125, Semantic loss: 0.817706, BCE loss: 0.562692, SB loss: 0.787323
2023-10-29 23:58:19,152 Epoch: [26/484] Iter:[450/495], Time: 0.38, lr: [0.009498204152611949], Loss: 2.164748, Acc:0.790455, Semantic loss: 0.814956, BCE loss: 0.563179, SB loss: 0.786613
2023-10-29 23:58:22,923 Epoch: [26/484] Iter:[460/495], Time: 0.38, lr: [0.009497826339360456], Loss: 2.171077, Acc:0.790088, Semantic loss: 0.818631, BCE loss: 0.564039, SB loss: 0.788407
2023-10-29 23:58:26,648 Epoch: [26/484] Iter:[470/495], Time: 0.38, lr: [0.009497448524439065], Loss: 2.174294, Acc:0.789979, Semantic loss: 0.819693, BCE loss: 0.565213, SB loss: 0.789389
2023-10-29 23:58:30,410 Epoch: [26/484] Iter:[480/495], Time: 0.38, lr: [0.009497070707847699], Loss: 2.174535, Acc:0.789661, Semantic loss: 0.819404, BCE loss: 0.565260, SB loss: 0.789872
2023-10-29 23:58:34,103 Epoch: [26/484] Iter:[490/495], Time: 0.38, lr: [0.009496692889586274], Loss: 2.174996, Acc:0.790156, Semantic loss: 0.818892, BCE loss: 0.565404, SB loss: 0.790700
2023-10-29 23:58:35,536 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-29 23:58:35,774 Loss: 2.199, MeanIU:  0.6102, Best_mIoU:  0.6427
2023-10-29 23:58:35,774 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249]
2023-10-29 23:58:37,939 Epoch: [27/484] Iter:[0/495], Time: 2.13, lr: [0.009496503979829263], Loss: 2.091877, Acc:0.795236, Semantic loss: 0.688572, BCE loss: 0.626301, SB loss: 0.777004
2023-10-29 23:58:41,993 Epoch: [27/484] Iter:[10/495], Time: 0.56, lr: [0.009496126159062597], Loss: 2.142498, Acc:0.821593, Semantic loss: 0.768743, BCE loss: 0.575686, SB loss: 0.798069
2023-10-29 23:58:45,768 Epoch: [27/484] Iter:[20/495], Time: 0.47, lr: [0.009495748336625667], Loss: 2.182345, Acc:0.794702, Semantic loss: 0.825153, BCE loss: 0.564245, SB loss: 0.792947
2023-10-29 23:58:49,427 Epoch: [27/484] Iter:[30/495], Time: 0.44, lr: [0.009495370512518395], Loss: 2.220151, Acc:0.781693, Semantic loss: 0.866649, BCE loss: 0.557173, SB loss: 0.796329
2023-10-29 23:58:53,117 Epoch: [27/484] Iter:[40/495], Time: 0.42, lr: [0.0094949926867407], Loss: 2.213613, Acc:0.775090, Semantic loss: 0.864045, BCE loss: 0.559353, SB loss: 0.790215
2023-10-29 23:58:56,848 Epoch: [27/484] Iter:[50/495], Time: 0.41, lr: [0.009494614859292498], Loss: 2.236033, Acc:0.779999, Semantic loss: 0.872156, BCE loss: 0.565735, SB loss: 0.798143
2023-10-29 23:59:00,592 Epoch: [27/484] Iter:[60/495], Time: 0.41, lr: [0.00949423703017371], Loss: 2.209148, Acc:0.783917, Semantic loss: 0.855494, BCE loss: 0.562161, SB loss: 0.791493
2023-10-29 23:59:04,224 Epoch: [27/484] Iter:[70/495], Time: 0.40, lr: [0.009493859199384252], Loss: 2.191533, Acc:0.786934, Semantic loss: 0.841298, BCE loss: 0.559526, SB loss: 0.790709
2023-10-29 23:59:07,974 Epoch: [27/484] Iter:[80/495], Time: 0.40, lr: [0.009493481366924046], Loss: 2.189914, Acc:0.787880, Semantic loss: 0.841785, BCE loss: 0.560088, SB loss: 0.788042
2023-10-29 23:59:11,667 Epoch: [27/484] Iter:[90/495], Time: 0.39, lr: [0.009493103532793009], Loss: 2.184166, Acc:0.785200, Semantic loss: 0.840902, BCE loss: 0.559418, SB loss: 0.783846
2023-10-29 23:59:15,352 Epoch: [27/484] Iter:[100/495], Time: 0.39, lr: [0.00949272569699106], Loss: 2.183476, Acc:0.782514, Semantic loss: 0.837756, BCE loss: 0.559937, SB loss: 0.785783
2023-10-29 23:59:19,082 Epoch: [27/484] Iter:[110/495], Time: 0.39, lr: [0.009492347859518118], Loss: 2.181172, Acc:0.784138, Semantic loss: 0.828809, BCE loss: 0.567599, SB loss: 0.784764
2023-10-29 23:59:22,852 Epoch: [27/484] Iter:[120/495], Time: 0.39, lr: [0.009491970020374102], Loss: 2.175377, Acc:0.783446, Semantic loss: 0.826622, BCE loss: 0.566015, SB loss: 0.782740
2023-10-29 23:59:26,639 Epoch: [27/484] Iter:[130/495], Time: 0.39, lr: [0.00949159217955893], Loss: 2.183485, Acc:0.780907, Semantic loss: 0.828861, BCE loss: 0.569197, SB loss: 0.785427
2023-10-29 23:59:30,369 Epoch: [27/484] Iter:[140/495], Time: 0.39, lr: [0.009491214337072519], Loss: 2.186570, Acc:0.780688, Semantic loss: 0.830340, BCE loss: 0.568456, SB loss: 0.787774
2023-10-29 23:59:34,198 Epoch: [27/484] Iter:[150/495], Time: 0.39, lr: [0.009490836492914791], Loss: 2.192817, Acc:0.781587, Semantic loss: 0.832214, BCE loss: 0.573969, SB loss: 0.786634
2023-10-29 23:59:37,932 Epoch: [27/484] Iter:[160/495], Time: 0.39, lr: [0.009490458647085663], Loss: 2.193485, Acc:0.783971, Semantic loss: 0.833997, BCE loss: 0.573164, SB loss: 0.786324
2023-10-29 23:59:41,653 Epoch: [27/484] Iter:[170/495], Time: 0.39, lr: [0.009490080799585054], Loss: 2.218698, Acc:0.782271, Semantic loss: 0.850655, BCE loss: 0.573273, SB loss: 0.794770
2023-10-29 23:59:45,387 Epoch: [27/484] Iter:[180/495], Time: 0.38, lr: [0.009489702950412883], Loss: 2.225492, Acc:0.780944, Semantic loss: 0.854375, BCE loss: 0.571776, SB loss: 0.799340
2023-10-29 23:59:49,191 Epoch: [27/484] Iter:[190/495], Time: 0.38, lr: [0.009489325099569068], Loss: 2.241007, Acc:0.780385, Semantic loss: 0.863068, BCE loss: 0.572156, SB loss: 0.805783
2023-10-29 23:59:52,938 Epoch: [27/484] Iter:[200/495], Time: 0.38, lr: [0.009488947247053528], Loss: 2.249036, Acc:0.778724, Semantic loss: 0.867194, BCE loss: 0.572750, SB loss: 0.809091
2023-10-29 23:59:56,776 Epoch: [27/484] Iter:[210/495], Time: 0.38, lr: [0.009488569392866181], Loss: 2.252924, Acc:0.778808, Semantic loss: 0.866536, BCE loss: 0.576731, SB loss: 0.809656
2023-10-30 00:00:00,595 Epoch: [27/484] Iter:[220/495], Time: 0.38, lr: [0.009488191537006944], Loss: 2.249782, Acc:0.779769, Semantic loss: 0.862494, BCE loss: 0.577757, SB loss: 0.809531
2023-10-30 00:00:04,440 Epoch: [27/484] Iter:[230/495], Time: 0.38, lr: [0.009487813679475742], Loss: 2.246466, Acc:0.780171, Semantic loss: 0.860486, BCE loss: 0.577755, SB loss: 0.808224
2023-10-30 00:00:08,173 Epoch: [27/484] Iter:[240/495], Time: 0.38, lr: [0.009487435820272486], Loss: 2.242069, Acc:0.781745, Semantic loss: 0.856142, BCE loss: 0.578737, SB loss: 0.807191
2023-10-30 00:00:11,736 Epoch: [27/484] Iter:[250/495], Time: 0.38, lr: [0.0094870579593971], Loss: 2.239793, Acc:0.781499, Semantic loss: 0.856298, BCE loss: 0.576806, SB loss: 0.806690
2023-10-30 00:00:57,971 Epoch: [27/484] Iter:[260/495], Time: 0.54, lr: [0.0094866800968495], Loss: 2.237871, Acc:0.782070, Semantic loss: 0.853693, BCE loss: 0.578240, SB loss: 0.805938
2023-10-30 00:01:01,819 Epoch: [27/484] Iter:[270/495], Time: 0.54, lr: [0.009486302232629605], Loss: 2.233431, Acc:0.783152, Semantic loss: 0.849773, BCE loss: 0.579812, SB loss: 0.803846
2023-10-30 00:01:05,527 Epoch: [27/484] Iter:[280/495], Time: 0.53, lr: [0.009485924366737333], Loss: 2.228238, Acc:0.783018, Semantic loss: 0.847376, BCE loss: 0.578341, SB loss: 0.802521
2023-10-30 00:01:09,050 Epoch: [27/484] Iter:[290/495], Time: 0.53, lr: [0.009485546499172604], Loss: 2.228799, Acc:0.784061, Semantic loss: 0.847983, BCE loss: 0.578325, SB loss: 0.802490
2023-10-30 00:01:12,670 Epoch: [27/484] Iter:[300/495], Time: 0.52, lr: [0.009485168629935335], Loss: 2.223410, Acc:0.784323, Semantic loss: 0.845656, BCE loss: 0.576757, SB loss: 0.800997
2023-10-30 00:01:16,253 Epoch: [27/484] Iter:[310/495], Time: 0.52, lr: [0.009484790759025447], Loss: 2.222150, Acc:0.783005, Semantic loss: 0.846233, BCE loss: 0.575758, SB loss: 0.800159
2023-10-30 00:01:19,919 Epoch: [27/484] Iter:[320/495], Time: 0.51, lr: [0.009484412886442858], Loss: 2.222429, Acc:0.782750, Semantic loss: 0.845418, BCE loss: 0.575639, SB loss: 0.801373
2023-10-30 00:01:23,529 Epoch: [27/484] Iter:[330/495], Time: 0.51, lr: [0.009484035012187482], Loss: 2.224408, Acc:0.782127, Semantic loss: 0.846790, BCE loss: 0.573602, SB loss: 0.804016
2023-10-30 00:01:27,116 Epoch: [27/484] Iter:[340/495], Time: 0.50, lr: [0.009483657136259243], Loss: 2.221498, Acc:0.782444, Semantic loss: 0.844513, BCE loss: 0.572561, SB loss: 0.804424
2023-10-30 00:01:30,723 Epoch: [27/484] Iter:[350/495], Time: 0.50, lr: [0.009483279258658057], Loss: 2.217194, Acc:0.782474, Semantic loss: 0.842736, BCE loss: 0.570819, SB loss: 0.803639
2023-10-30 00:01:34,323 Epoch: [27/484] Iter:[360/495], Time: 0.49, lr: [0.009482901379383844], Loss: 2.214584, Acc:0.783096, Semantic loss: 0.841920, BCE loss: 0.569424, SB loss: 0.803240
2023-10-30 00:01:38,004 Epoch: [27/484] Iter:[370/495], Time: 0.49, lr: [0.009482523498436521], Loss: 2.210233, Acc:0.783455, Semantic loss: 0.839424, BCE loss: 0.568750, SB loss: 0.802059
2023-10-30 00:01:41,643 Epoch: [27/484] Iter:[380/495], Time: 0.49, lr: [0.009482145615816007], Loss: 2.219144, Acc:0.781954, Semantic loss: 0.847054, BCE loss: 0.568211, SB loss: 0.803879
2023-10-30 00:01:45,364 Epoch: [27/484] Iter:[390/495], Time: 0.48, lr: [0.009481767731522222], Loss: 2.215145, Acc:0.781865, Semantic loss: 0.844633, BCE loss: 0.566787, SB loss: 0.803725
2023-10-30 00:01:49,191 Epoch: [27/484] Iter:[400/495], Time: 0.48, lr: [0.009481389845555082], Loss: 2.216277, Acc:0.781692, Semantic loss: 0.845245, BCE loss: 0.565908, SB loss: 0.805124
2023-10-30 00:01:52,872 Epoch: [27/484] Iter:[410/495], Time: 0.48, lr: [0.009481011957914506], Loss: 2.211497, Acc:0.782194, Semantic loss: 0.842051, BCE loss: 0.565221, SB loss: 0.804225
2023-10-30 00:01:56,619 Epoch: [27/484] Iter:[420/495], Time: 0.48, lr: [0.009480634068600415], Loss: 2.214018, Acc:0.782294, Semantic loss: 0.844722, BCE loss: 0.564284, SB loss: 0.805012
2023-10-30 00:02:00,344 Epoch: [27/484] Iter:[430/495], Time: 0.47, lr: [0.009480256177612724], Loss: 2.212023, Acc:0.781197, Semantic loss: 0.844187, BCE loss: 0.562042, SB loss: 0.805793
2023-10-30 00:02:04,017 Epoch: [27/484] Iter:[440/495], Time: 0.47, lr: [0.009479878284951355], Loss: 2.215618, Acc:0.780262, Semantic loss: 0.846213, BCE loss: 0.563239, SB loss: 0.806167
2023-10-30 00:02:07,795 Epoch: [27/484] Iter:[450/495], Time: 0.47, lr: [0.009479500390616222], Loss: 2.213593, Acc:0.779645, Semantic loss: 0.844728, BCE loss: 0.562793, SB loss: 0.806072
2023-10-30 00:02:11,513 Epoch: [27/484] Iter:[460/495], Time: 0.47, lr: [0.009479122494607247], Loss: 2.214010, Acc:0.779601, Semantic loss: 0.843736, BCE loss: 0.563645, SB loss: 0.806629
2023-10-30 00:02:15,274 Epoch: [27/484] Iter:[470/495], Time: 0.47, lr: [0.009478744596924348], Loss: 2.210855, Acc:0.780154, Semantic loss: 0.841276, BCE loss: 0.564159, SB loss: 0.805420
2023-10-30 00:02:19,108 Epoch: [27/484] Iter:[480/495], Time: 0.46, lr: [0.009478366697567443], Loss: 2.210047, Acc:0.780539, Semantic loss: 0.840908, BCE loss: 0.564211, SB loss: 0.804929
2023-10-30 00:02:22,616 Epoch: [27/484] Iter:[490/495], Time: 0.46, lr: [0.00947798879653645], Loss: 2.211093, Acc:0.780054, Semantic loss: 0.841478, BCE loss: 0.564313, SB loss: 0.805302
2023-10-30 00:02:24,054 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:02:24,313 Loss: 2.199, MeanIU:  0.6102, Best_mIoU:  0.6427
2023-10-30 00:02:24,314 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249]
2023-10-30 00:02:26,238 Epoch: [28/484] Iter:[0/495], Time: 1.89, lr: [0.009477799845393143], Loss: 2.208590, Acc:0.842884, Semantic loss: 0.830522, BCE loss: 0.514845, SB loss: 0.863223
2023-10-30 00:02:30,224 Epoch: [28/484] Iter:[10/495], Time: 0.53, lr: [0.009477421941850866], Loss: 2.113492, Acc:0.787362, Semantic loss: 0.809852, BCE loss: 0.516801, SB loss: 0.786839
2023-10-30 00:02:34,068 Epoch: [28/484] Iter:[20/495], Time: 0.46, lr: [0.009477044036634297], Loss: 2.178041, Acc:0.781614, Semantic loss: 0.841781, BCE loss: 0.537840, SB loss: 0.798421
2023-10-30 00:02:37,817 Epoch: [28/484] Iter:[30/495], Time: 0.43, lr: [0.009476666129743355], Loss: 2.226999, Acc:0.792577, Semantic loss: 0.838233, BCE loss: 0.580609, SB loss: 0.808157
2023-10-30 00:02:41,584 Epoch: [28/484] Iter:[40/495], Time: 0.42, lr: [0.009476288221177956], Loss: 2.198276, Acc:0.796744, Semantic loss: 0.817909, BCE loss: 0.580828, SB loss: 0.799539
2023-10-30 00:02:45,290 Epoch: [28/484] Iter:[50/495], Time: 0.41, lr: [0.009475910310938022], Loss: 2.174474, Acc:0.796953, Semantic loss: 0.801995, BCE loss: 0.586568, SB loss: 0.785911
2023-10-30 00:02:49,097 Epoch: [28/484] Iter:[60/495], Time: 0.41, lr: [0.00947553239902347], Loss: 2.194818, Acc:0.800124, Semantic loss: 0.810789, BCE loss: 0.593434, SB loss: 0.790595
2023-10-30 00:02:52,758 Epoch: [28/484] Iter:[70/495], Time: 0.40, lr: [0.009475154485434217], Loss: 2.187053, Acc:0.802930, Semantic loss: 0.801768, BCE loss: 0.595159, SB loss: 0.790125
2023-10-30 00:02:56,534 Epoch: [28/484] Iter:[80/495], Time: 0.40, lr: [0.009474776570170184], Loss: 2.165806, Acc:0.804112, Semantic loss: 0.793348, BCE loss: 0.588949, SB loss: 0.783509
2023-10-30 00:03:00,303 Epoch: [28/484] Iter:[90/495], Time: 0.40, lr: [0.009474398653231287], Loss: 2.181733, Acc:0.801829, Semantic loss: 0.805566, BCE loss: 0.590648, SB loss: 0.785519
2023-10-30 00:03:04,035 Epoch: [28/484] Iter:[100/495], Time: 0.39, lr: [0.009474020734617446], Loss: 2.173963, Acc:0.801576, Semantic loss: 0.803973, BCE loss: 0.585905, SB loss: 0.784085
2023-10-30 00:03:07,692 Epoch: [28/484] Iter:[110/495], Time: 0.39, lr: [0.009473642814328578], Loss: 2.159772, Acc:0.800004, Semantic loss: 0.796998, BCE loss: 0.583011, SB loss: 0.779763
2023-10-30 00:03:11,484 Epoch: [28/484] Iter:[120/495], Time: 0.39, lr: [0.009473264892364601], Loss: 2.159713, Acc:0.798045, Semantic loss: 0.797771, BCE loss: 0.583638, SB loss: 0.778305
2023-10-30 00:03:15,224 Epoch: [28/484] Iter:[130/495], Time: 0.39, lr: [0.009472886968725436], Loss: 2.160135, Acc:0.797527, Semantic loss: 0.799959, BCE loss: 0.582727, SB loss: 0.777449
2023-10-30 00:03:18,936 Epoch: [28/484] Iter:[140/495], Time: 0.39, lr: [0.009472509043411], Loss: 2.148378, Acc:0.798560, Semantic loss: 0.794435, BCE loss: 0.581138, SB loss: 0.772805
2023-10-30 00:03:22,723 Epoch: [28/484] Iter:[150/495], Time: 0.39, lr: [0.00947213111642121], Loss: 2.141279, Acc:0.797077, Semantic loss: 0.792115, BCE loss: 0.576142, SB loss: 0.773022
2023-10-30 00:03:26,546 Epoch: [28/484] Iter:[160/495], Time: 0.39, lr: [0.009471753187755984], Loss: 2.144859, Acc:0.796386, Semantic loss: 0.794021, BCE loss: 0.576660, SB loss: 0.774178
2023-10-30 00:03:30,359 Epoch: [28/484] Iter:[170/495], Time: 0.39, lr: [0.009471375257415244], Loss: 2.141874, Acc:0.796430, Semantic loss: 0.793529, BCE loss: 0.574365, SB loss: 0.773980
2023-10-30 00:03:34,139 Epoch: [28/484] Iter:[180/495], Time: 0.39, lr: [0.009470997325398904], Loss: 2.143011, Acc:0.796864, Semantic loss: 0.793298, BCE loss: 0.575629, SB loss: 0.774085
2023-10-30 00:03:37,980 Epoch: [28/484] Iter:[190/495], Time: 0.39, lr: [0.009470619391706884], Loss: 2.148037, Acc:0.796424, Semantic loss: 0.796033, BCE loss: 0.575582, SB loss: 0.776421
2023-10-30 00:03:41,820 Epoch: [28/484] Iter:[200/495], Time: 0.39, lr: [0.009470241456339103], Loss: 2.161656, Acc:0.797018, Semantic loss: 0.803754, BCE loss: 0.577703, SB loss: 0.780199
2023-10-30 00:03:45,621 Epoch: [28/484] Iter:[210/495], Time: 0.39, lr: [0.009469863519295477], Loss: 2.159607, Acc:0.795808, Semantic loss: 0.803423, BCE loss: 0.575567, SB loss: 0.780617
2023-10-30 00:03:49,388 Epoch: [28/484] Iter:[220/495], Time: 0.38, lr: [0.009469485580575929], Loss: 2.157594, Acc:0.795211, Semantic loss: 0.805066, BCE loss: 0.572171, SB loss: 0.780357
2023-10-30 00:03:53,117 Epoch: [28/484] Iter:[230/495], Time: 0.38, lr: [0.009469107640180371], Loss: 2.159559, Acc:0.794970, Semantic loss: 0.807781, BCE loss: 0.571520, SB loss: 0.780258
2023-10-30 00:03:56,934 Epoch: [28/484] Iter:[240/495], Time: 0.38, lr: [0.009468729698108726], Loss: 2.167872, Acc:0.794275, Semantic loss: 0.813321, BCE loss: 0.571321, SB loss: 0.783230
2023-10-30 00:04:00,633 Epoch: [28/484] Iter:[250/495], Time: 0.38, lr: [0.00946835175436091], Loss: 2.169914, Acc:0.793310, Semantic loss: 0.813916, BCE loss: 0.571933, SB loss: 0.784064
2023-10-30 00:04:04,424 Epoch: [28/484] Iter:[260/495], Time: 0.38, lr: [0.009467973808936842], Loss: 2.163095, Acc:0.793334, Semantic loss: 0.810040, BCE loss: 0.570257, SB loss: 0.782798
2023-10-30 00:04:08,113 Epoch: [28/484] Iter:[270/495], Time: 0.38, lr: [0.00946759586183644], Loss: 2.168615, Acc:0.792598, Semantic loss: 0.812433, BCE loss: 0.571390, SB loss: 0.784792
2023-10-30 00:04:11,962 Epoch: [28/484] Iter:[280/495], Time: 0.38, lr: [0.009467217913059623], Loss: 2.172571, Acc:0.792073, Semantic loss: 0.816145, BCE loss: 0.569611, SB loss: 0.786815
2023-10-30 00:04:15,820 Epoch: [28/484] Iter:[290/495], Time: 0.38, lr: [0.009466839962606307], Loss: 2.175742, Acc:0.791784, Semantic loss: 0.818464, BCE loss: 0.569025, SB loss: 0.788253
2023-10-30 00:04:19,602 Epoch: [28/484] Iter:[300/495], Time: 0.38, lr: [0.009466462010476412], Loss: 2.183083, Acc:0.790489, Semantic loss: 0.824029, BCE loss: 0.567822, SB loss: 0.791232
2023-10-30 00:04:23,298 Epoch: [28/484] Iter:[310/495], Time: 0.38, lr: [0.009466084056669856], Loss: 2.185899, Acc:0.790043, Semantic loss: 0.824640, BCE loss: 0.567978, SB loss: 0.793281
2023-10-30 00:04:26,971 Epoch: [28/484] Iter:[320/495], Time: 0.38, lr: [0.009465706101186558], Loss: 2.183156, Acc:0.789366, Semantic loss: 0.823161, BCE loss: 0.566852, SB loss: 0.793143
2023-10-30 00:04:30,825 Epoch: [28/484] Iter:[330/495], Time: 0.38, lr: [0.009465328144026433], Loss: 2.179912, Acc:0.788460, Semantic loss: 0.822626, BCE loss: 0.565436, SB loss: 0.791850
2023-10-30 00:04:34,602 Epoch: [28/484] Iter:[340/495], Time: 0.38, lr: [0.009464950185189403], Loss: 2.178420, Acc:0.787775, Semantic loss: 0.822802, BCE loss: 0.564689, SB loss: 0.790929
2023-10-30 00:04:38,492 Epoch: [28/484] Iter:[350/495], Time: 0.38, lr: [0.009464572224675383], Loss: 2.185808, Acc:0.786988, Semantic loss: 0.826768, BCE loss: 0.566188, SB loss: 0.792852
2023-10-30 00:04:42,235 Epoch: [28/484] Iter:[360/495], Time: 0.38, lr: [0.009464194262484295], Loss: 2.190325, Acc:0.787094, Semantic loss: 0.829755, BCE loss: 0.566719, SB loss: 0.793851
2023-10-30 00:04:46,139 Epoch: [28/484] Iter:[370/495], Time: 0.38, lr: [0.009463816298616052], Loss: 2.186725, Acc:0.787285, Semantic loss: 0.828211, BCE loss: 0.565722, SB loss: 0.792792
2023-10-30 00:04:50,022 Epoch: [28/484] Iter:[380/495], Time: 0.38, lr: [0.009463438333070577], Loss: 2.183346, Acc:0.788237, Semantic loss: 0.826100, BCE loss: 0.565250, SB loss: 0.791996
2023-10-30 00:04:53,743 Epoch: [28/484] Iter:[390/495], Time: 0.38, lr: [0.009463060365847785], Loss: 2.182211, Acc:0.789622, Semantic loss: 0.825797, BCE loss: 0.564715, SB loss: 0.791699
2023-10-30 00:04:57,484 Epoch: [28/484] Iter:[400/495], Time: 0.38, lr: [0.009462682396947595], Loss: 2.181408, Acc:0.790163, Semantic loss: 0.826296, BCE loss: 0.564001, SB loss: 0.791111
2023-10-30 00:05:01,304 Epoch: [28/484] Iter:[410/495], Time: 0.38, lr: [0.009462304426369927], Loss: 2.186104, Acc:0.789240, Semantic loss: 0.829354, BCE loss: 0.565060, SB loss: 0.791689
2023-10-30 00:05:05,088 Epoch: [28/484] Iter:[420/495], Time: 0.38, lr: [0.009461926454114696], Loss: 2.181450, Acc:0.788828, Semantic loss: 0.827406, BCE loss: 0.563144, SB loss: 0.790900
2023-10-30 00:05:08,804 Epoch: [28/484] Iter:[430/495], Time: 0.38, lr: [0.00946154848018182], Loss: 2.180561, Acc:0.788838, Semantic loss: 0.826571, BCE loss: 0.562971, SB loss: 0.791019
2023-10-30 00:05:12,491 Epoch: [28/484] Iter:[440/495], Time: 0.38, lr: [0.009461170504571221], Loss: 2.180038, Acc:0.788475, Semantic loss: 0.825461, BCE loss: 0.563680, SB loss: 0.790897
2023-10-30 00:05:16,266 Epoch: [28/484] Iter:[450/495], Time: 0.38, lr: [0.009460792527282814], Loss: 2.180395, Acc:0.788515, Semantic loss: 0.826349, BCE loss: 0.562870, SB loss: 0.791176
2023-10-30 00:05:20,071 Epoch: [28/484] Iter:[460/495], Time: 0.38, lr: [0.009460414548316516], Loss: 2.184821, Acc:0.788387, Semantic loss: 0.829191, BCE loss: 0.563471, SB loss: 0.792159
2023-10-30 00:05:23,807 Epoch: [28/484] Iter:[470/495], Time: 0.38, lr: [0.009460036567672248], Loss: 2.186939, Acc:0.787717, Semantic loss: 0.830800, BCE loss: 0.562527, SB loss: 0.793611
2023-10-30 00:05:27,669 Epoch: [28/484] Iter:[480/495], Time: 0.38, lr: [0.009459658585349926], Loss: 2.187658, Acc:0.788179, Semantic loss: 0.830706, BCE loss: 0.563108, SB loss: 0.793844
2023-10-30 00:05:31,211 Epoch: [28/484] Iter:[490/495], Time: 0.38, lr: [0.00945928060134947], Loss: 2.184488, Acc:0.788713, Semantic loss: 0.828420, BCE loss: 0.562753, SB loss: 0.793316
2023-10-30 00:05:32,633 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:05:32,878 Loss: 2.199, MeanIU:  0.6102, Best_mIoU:  0.6427
2023-10-30 00:05:32,878 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249]
2023-10-30 00:05:35,186 Epoch: [29/484] Iter:[0/495], Time: 2.27, lr: [0.009459091608719916], Loss: 2.848500, Acc:0.902492, Semantic loss: 0.987091, BCE loss: 0.956009, SB loss: 0.905400
2023-10-30 00:05:39,224 Epoch: [29/484] Iter:[10/495], Time: 0.57, lr: [0.009458713622202101], Loss: 2.094540, Acc:0.794664, Semantic loss: 0.772497, BCE loss: 0.549325, SB loss: 0.772717
2023-10-30 00:05:42,906 Epoch: [29/484] Iter:[20/495], Time: 0.48, lr: [0.00945833563400595], Loss: 2.101162, Acc:0.801673, Semantic loss: 0.759457, BCE loss: 0.576370, SB loss: 0.765335
2023-10-30 00:05:46,637 Epoch: [29/484] Iter:[30/495], Time: 0.44, lr: [0.009457957644131374], Loss: 2.032605, Acc:0.786698, Semantic loss: 0.741836, BCE loss: 0.543230, SB loss: 0.747539
2023-10-30 00:05:50,398 Epoch: [29/484] Iter:[40/495], Time: 0.43, lr: [0.009457579652578296], Loss: 2.072650, Acc:0.789677, Semantic loss: 0.760328, BCE loss: 0.556953, SB loss: 0.755369
2023-10-30 00:05:54,074 Epoch: [29/484] Iter:[50/495], Time: 0.41, lr: [0.00945720165934663], Loss: 2.094434, Acc:0.791171, Semantic loss: 0.771603, BCE loss: 0.561450, SB loss: 0.761380
2023-10-30 00:05:57,814 Epoch: [29/484] Iter:[60/495], Time: 0.41, lr: [0.009456823664436299], Loss: 2.109019, Acc:0.790708, Semantic loss: 0.781811, BCE loss: 0.559166, SB loss: 0.768042
2023-10-30 00:06:01,579 Epoch: [29/484] Iter:[70/495], Time: 0.40, lr: [0.009456445667847216], Loss: 2.121442, Acc:0.790028, Semantic loss: 0.792218, BCE loss: 0.559284, SB loss: 0.769940
2023-10-30 00:06:05,289 Epoch: [29/484] Iter:[80/495], Time: 0.40, lr: [0.0094560676695793], Loss: 2.110375, Acc:0.792438, Semantic loss: 0.782381, BCE loss: 0.557670, SB loss: 0.770324
2023-10-30 00:06:09,016 Epoch: [29/484] Iter:[90/495], Time: 0.40, lr: [0.00945568966963247], Loss: 2.122114, Acc:0.790490, Semantic loss: 0.783479, BCE loss: 0.566261, SB loss: 0.772375
2023-10-30 00:06:12,759 Epoch: [29/484] Iter:[100/495], Time: 0.39, lr: [0.009455311668006646], Loss: 2.123755, Acc:0.794306, Semantic loss: 0.787010, BCE loss: 0.563606, SB loss: 0.773139
2023-10-30 00:06:16,465 Epoch: [29/484] Iter:[110/495], Time: 0.39, lr: [0.009454933664701742], Loss: 2.123970, Acc:0.795593, Semantic loss: 0.785261, BCE loss: 0.563965, SB loss: 0.774743
2023-10-30 00:06:20,236 Epoch: [29/484] Iter:[120/495], Time: 0.39, lr: [0.009454555659717678], Loss: 2.125757, Acc:0.794755, Semantic loss: 0.788259, BCE loss: 0.563212, SB loss: 0.774286
2023-10-30 00:06:23,932 Epoch: [29/484] Iter:[130/495], Time: 0.39, lr: [0.009454177653054372], Loss: 2.128539, Acc:0.797520, Semantic loss: 0.786822, BCE loss: 0.567611, SB loss: 0.774106
2023-10-30 00:06:27,755 Epoch: [29/484] Iter:[140/495], Time: 0.39, lr: [0.009453799644711743], Loss: 2.142455, Acc:0.798890, Semantic loss: 0.795857, BCE loss: 0.570237, SB loss: 0.776361
2023-10-30 00:06:31,566 Epoch: [29/484] Iter:[150/495], Time: 0.39, lr: [0.009453421634689705], Loss: 2.142043, Acc:0.799232, Semantic loss: 0.795051, BCE loss: 0.571330, SB loss: 0.775661
2023-10-30 00:06:35,376 Epoch: [29/484] Iter:[160/495], Time: 0.39, lr: [0.009453043622988181], Loss: 2.141880, Acc:0.800260, Semantic loss: 0.794458, BCE loss: 0.571865, SB loss: 0.775557
2023-10-30 00:06:39,193 Epoch: [29/484] Iter:[170/495], Time: 0.39, lr: [0.009452665609607084], Loss: 2.144510, Acc:0.798060, Semantic loss: 0.798957, BCE loss: 0.569512, SB loss: 0.776041
2023-10-30 00:06:42,838 Epoch: [29/484] Iter:[180/495], Time: 0.39, lr: [0.009452287594546338], Loss: 2.153986, Acc:0.796831, Semantic loss: 0.801687, BCE loss: 0.573337, SB loss: 0.778963
2023-10-30 00:06:46,635 Epoch: [29/484] Iter:[190/495], Time: 0.39, lr: [0.009451909577805855], Loss: 2.151522, Acc:0.795086, Semantic loss: 0.801710, BCE loss: 0.571663, SB loss: 0.778149
2023-10-30 00:06:50,455 Epoch: [29/484] Iter:[200/495], Time: 0.39, lr: [0.009451531559385556], Loss: 2.152187, Acc:0.794881, Semantic loss: 0.801926, BCE loss: 0.571141, SB loss: 0.779120
2023-10-30 00:06:54,129 Epoch: [29/484] Iter:[210/495], Time: 0.38, lr: [0.009451153539285356], Loss: 2.163029, Acc:0.793315, Semantic loss: 0.807587, BCE loss: 0.574665, SB loss: 0.780777
2023-10-30 00:06:57,838 Epoch: [29/484] Iter:[220/495], Time: 0.38, lr: [0.009450775517505177], Loss: 2.161626, Acc:0.791691, Semantic loss: 0.806014, BCE loss: 0.573641, SB loss: 0.781970
2023-10-30 00:07:01,592 Epoch: [29/484] Iter:[230/495], Time: 0.38, lr: [0.009450397494044934], Loss: 2.168651, Acc:0.791168, Semantic loss: 0.808422, BCE loss: 0.576074, SB loss: 0.784155
2023-10-30 00:07:05,386 Epoch: [29/484] Iter:[240/495], Time: 0.38, lr: [0.009450019468904548], Loss: 2.172201, Acc:0.791041, Semantic loss: 0.809262, BCE loss: 0.577646, SB loss: 0.785293
2023-10-30 00:07:09,088 Epoch: [29/484] Iter:[250/495], Time: 0.38, lr: [0.00944964144208393], Loss: 2.166124, Acc:0.790618, Semantic loss: 0.805794, BCE loss: 0.576196, SB loss: 0.784134
2023-10-30 00:07:12,892 Epoch: [29/484] Iter:[260/495], Time: 0.38, lr: [0.009449263413583006], Loss: 2.164230, Acc:0.792748, Semantic loss: 0.804819, BCE loss: 0.576122, SB loss: 0.783289
2023-10-30 00:07:16,721 Epoch: [29/484] Iter:[270/495], Time: 0.38, lr: [0.009448885383401688], Loss: 2.161740, Acc:0.792745, Semantic loss: 0.804662, BCE loss: 0.573722, SB loss: 0.783356
2023-10-30 00:07:20,485 Epoch: [29/484] Iter:[280/495], Time: 0.38, lr: [0.009448507351539898], Loss: 2.163747, Acc:0.794062, Semantic loss: 0.806382, BCE loss: 0.573726, SB loss: 0.783639
2023-10-30 00:07:24,138 Epoch: [29/484] Iter:[290/495], Time: 0.38, lr: [0.00944812931799755], Loss: 2.163031, Acc:0.794813, Semantic loss: 0.805593, BCE loss: 0.573312, SB loss: 0.784126
2023-10-30 00:07:27,899 Epoch: [29/484] Iter:[300/495], Time: 0.38, lr: [0.009447751282774565], Loss: 2.160959, Acc:0.793633, Semantic loss: 0.804239, BCE loss: 0.572909, SB loss: 0.783811
2023-10-30 00:07:31,701 Epoch: [29/484] Iter:[310/495], Time: 0.38, lr: [0.009447373245870859], Loss: 2.154167, Acc:0.794599, Semantic loss: 0.800387, BCE loss: 0.571728, SB loss: 0.782051
2023-10-30 00:07:35,477 Epoch: [29/484] Iter:[320/495], Time: 0.38, lr: [0.00944699520728635], Loss: 2.155032, Acc:0.794126, Semantic loss: 0.802116, BCE loss: 0.570723, SB loss: 0.782193
2023-10-30 00:07:39,242 Epoch: [29/484] Iter:[330/495], Time: 0.38, lr: [0.009446617167020955], Loss: 2.157773, Acc:0.793561, Semantic loss: 0.804034, BCE loss: 0.570451, SB loss: 0.783288
2023-10-30 00:07:42,984 Epoch: [29/484] Iter:[340/495], Time: 0.38, lr: [0.009446239125074595], Loss: 2.168874, Acc:0.791944, Semantic loss: 0.810168, BCE loss: 0.571691, SB loss: 0.787015
2023-10-30 00:07:46,736 Epoch: [29/484] Iter:[350/495], Time: 0.38, lr: [0.009445861081447184], Loss: 2.176647, Acc:0.791239, Semantic loss: 0.815742, BCE loss: 0.571659, SB loss: 0.789246
2023-10-30 00:07:50,492 Epoch: [29/484] Iter:[360/495], Time: 0.38, lr: [0.009445483036138643], Loss: 2.182673, Acc:0.791516, Semantic loss: 0.819320, BCE loss: 0.572601, SB loss: 0.790752
2023-10-30 00:07:54,313 Epoch: [29/484] Iter:[370/495], Time: 0.38, lr: [0.009445104989148887], Loss: 2.185984, Acc:0.790982, Semantic loss: 0.820751, BCE loss: 0.572744, SB loss: 0.792488
2023-10-30 00:07:58,050 Epoch: [29/484] Iter:[380/495], Time: 0.38, lr: [0.009444726940477835], Loss: 2.191742, Acc:0.790418, Semantic loss: 0.823434, BCE loss: 0.574034, SB loss: 0.794274
2023-10-30 00:08:01,775 Epoch: [29/484] Iter:[390/495], Time: 0.38, lr: [0.009444348890125406], Loss: 2.196778, Acc:0.790090, Semantic loss: 0.825617, BCE loss: 0.574849, SB loss: 0.796312
2023-10-30 00:08:05,677 Epoch: [29/484] Iter:[400/495], Time: 0.38, lr: [0.009443970838091516], Loss: 2.195843, Acc:0.788932, Semantic loss: 0.825609, BCE loss: 0.573272, SB loss: 0.796963
2023-10-30 00:08:09,366 Epoch: [29/484] Iter:[410/495], Time: 0.38, lr: [0.009443592784376082], Loss: 2.197181, Acc:0.788849, Semantic loss: 0.826591, BCE loss: 0.573925, SB loss: 0.796665
2023-10-30 00:08:13,132 Epoch: [29/484] Iter:[420/495], Time: 0.38, lr: [0.009443214728979023], Loss: 2.198034, Acc:0.788381, Semantic loss: 0.828015, BCE loss: 0.572319, SB loss: 0.797699
2023-10-30 00:08:16,907 Epoch: [29/484] Iter:[430/495], Time: 0.38, lr: [0.009442836671900257], Loss: 2.198547, Acc:0.788937, Semantic loss: 0.828515, BCE loss: 0.572708, SB loss: 0.797323
2023-10-30 00:08:20,669 Epoch: [29/484] Iter:[440/495], Time: 0.38, lr: [0.009442458613139701], Loss: 2.201647, Acc:0.789050, Semantic loss: 0.829817, BCE loss: 0.573727, SB loss: 0.798103
2023-10-30 00:08:24,394 Epoch: [29/484] Iter:[450/495], Time: 0.38, lr: [0.009442080552697274], Loss: 2.203466, Acc:0.788472, Semantic loss: 0.831338, BCE loss: 0.572533, SB loss: 0.799595
2023-10-30 00:08:28,095 Epoch: [29/484] Iter:[460/495], Time: 0.38, lr: [0.009441702490572891], Loss: 2.204915, Acc:0.787936, Semantic loss: 0.831493, BCE loss: 0.573088, SB loss: 0.800334
2023-10-30 00:08:31,885 Epoch: [29/484] Iter:[470/495], Time: 0.38, lr: [0.009441324426766472], Loss: 2.203921, Acc:0.787957, Semantic loss: 0.831120, BCE loss: 0.572256, SB loss: 0.800544
2023-10-30 00:08:35,673 Epoch: [29/484] Iter:[480/495], Time: 0.38, lr: [0.009440946361277935], Loss: 2.204474, Acc:0.788674, Semantic loss: 0.830155, BCE loss: 0.573927, SB loss: 0.800392
2023-10-30 00:08:39,241 Epoch: [29/484] Iter:[490/495], Time: 0.38, lr: [0.009440568294107195], Loss: 2.202837, Acc:0.788738, Semantic loss: 0.829496, BCE loss: 0.573557, SB loss: 0.799783
2023-10-30 00:08:40,683 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:08:40,926 Loss: 2.199, MeanIU:  0.6102, Best_mIoU:  0.6427
2023-10-30 00:08:40,926 [0.97133626 0.78979157 0.88991853 0.25575272 0.44733719 0.54854708
 0.60825701 0.6773564  0.8985554  0.54736383 0.91550158 0.73902282
 0.49254192 0.9013109  0.45350609 0.4365993  0.09555179 0.24494566
 0.68153249]
2023-10-30 00:08:42,875 Epoch: [30/484] Iter:[0/495], Time: 1.91, lr: [0.009440379259890974], Loss: 2.233600, Acc:0.773782, Semantic loss: 0.811984, BCE loss: 0.562764, SB loss: 0.858852
2023-10-30 00:08:47,175 Epoch: [30/484] Iter:[10/495], Time: 0.56, lr: [0.00944000119019678], Loss: 2.137664, Acc:0.786802, Semantic loss: 0.778401, BCE loss: 0.608200, SB loss: 0.751062
2023-10-30 00:08:51,079 Epoch: [30/484] Iter:[20/495], Time: 0.48, lr: [0.009439623118820177], Loss: 2.229604, Acc:0.780978, Semantic loss: 0.837721, BCE loss: 0.595799, SB loss: 0.796084
2023-10-30 00:08:54,874 Epoch: [30/484] Iter:[30/495], Time: 0.45, lr: [0.009439245045761085], Loss: 2.215279, Acc:0.776696, Semantic loss: 0.828838, BCE loss: 0.586209, SB loss: 0.800232
2023-10-30 00:08:58,596 Epoch: [30/484] Iter:[40/495], Time: 0.43, lr: [0.00943886697101942], Loss: 2.244109, Acc:0.774559, Semantic loss: 0.836480, BCE loss: 0.604118, SB loss: 0.803511
2023-10-30 00:09:02,364 Epoch: [30/484] Iter:[50/495], Time: 0.42, lr: [0.009438488894595103], Loss: 2.219626, Acc:0.773252, Semantic loss: 0.831924, BCE loss: 0.587172, SB loss: 0.800530
2023-10-30 00:09:06,231 Epoch: [30/484] Iter:[60/495], Time: 0.41, lr: [0.009438110816488049], Loss: 2.218672, Acc:0.781760, Semantic loss: 0.817438, BCE loss: 0.590936, SB loss: 0.810297
2023-10-30 00:09:09,956 Epoch: [30/484] Iter:[70/495], Time: 0.41, lr: [0.009437732736698174], Loss: 2.238679, Acc:0.782433, Semantic loss: 0.838220, BCE loss: 0.590676, SB loss: 0.809784
2023-10-30 00:09:13,927 Epoch: [30/484] Iter:[80/495], Time: 0.41, lr: [0.009437354655225398], Loss: 2.200790, Acc:0.783638, Semantic loss: 0.814521, BCE loss: 0.584059, SB loss: 0.802209
2023-10-30 00:09:17,732 Epoch: [30/484] Iter:[90/495], Time: 0.40, lr: [0.00943697657206964], Loss: 2.202757, Acc:0.788286, Semantic loss: 0.813608, BCE loss: 0.586146, SB loss: 0.803004
2023-10-30 00:09:21,492 Epoch: [30/484] Iter:[100/495], Time: 0.40, lr: [0.009436598487230814], Loss: 2.194030, Acc:0.785085, Semantic loss: 0.814487, BCE loss: 0.581811, SB loss: 0.797732
2023-10-30 00:09:25,339 Epoch: [30/484] Iter:[110/495], Time: 0.40, lr: [0.00943622040070884], Loss: 2.184066, Acc:0.785866, Semantic loss: 0.810831, BCE loss: 0.580610, SB loss: 0.792624
2023-10-30 00:09:29,039 Epoch: [30/484] Iter:[120/495], Time: 0.40, lr: [0.009435842312503636], Loss: 2.167212, Acc:0.786402, Semantic loss: 0.805051, BCE loss: 0.573276, SB loss: 0.788884
2023-10-30 00:09:32,929 Epoch: [30/484] Iter:[130/495], Time: 0.40, lr: [0.009435464222615117], Loss: 2.168005, Acc:0.782749, Semantic loss: 0.809866, BCE loss: 0.570153, SB loss: 0.787986
2023-10-30 00:09:36,709 Epoch: [30/484] Iter:[140/495], Time: 0.40, lr: [0.009435086131043203], Loss: 2.173270, Acc:0.783244, Semantic loss: 0.815576, BCE loss: 0.569377, SB loss: 0.788317
2023-10-30 00:09:40,474 Epoch: [30/484] Iter:[150/495], Time: 0.39, lr: [0.00943470803778781], Loss: 2.171821, Acc:0.782684, Semantic loss: 0.815044, BCE loss: 0.569626, SB loss: 0.787151
2023-10-30 00:09:44,192 Epoch: [30/484] Iter:[160/495], Time: 0.39, lr: [0.009434329942848856], Loss: 2.166986, Acc:0.782262, Semantic loss: 0.813855, BCE loss: 0.567299, SB loss: 0.785832
2023-10-30 00:09:47,953 Epoch: [30/484] Iter:[170/495], Time: 0.39, lr: [0.009433951846226259], Loss: 2.172523, Acc:0.782387, Semantic loss: 0.814635, BCE loss: 0.571055, SB loss: 0.786832
2023-10-30 00:09:51,797 Epoch: [30/484] Iter:[180/495], Time: 0.39, lr: [0.009433573747919935], Loss: 2.167745, Acc:0.783854, Semantic loss: 0.809785, BCE loss: 0.570908, SB loss: 0.787053
2023-10-30 00:09:55,584 Epoch: [30/484] Iter:[190/495], Time: 0.39, lr: [0.009433195647929804], Loss: 2.168817, Acc:0.783773, Semantic loss: 0.808362, BCE loss: 0.574686, SB loss: 0.785770
2023-10-30 00:09:59,306 Epoch: [30/484] Iter:[200/495], Time: 0.39, lr: [0.009432817546255783], Loss: 2.166813, Acc:0.785049, Semantic loss: 0.807720, BCE loss: 0.573761, SB loss: 0.785332
2023-10-30 00:10:03,066 Epoch: [30/484] Iter:[210/495], Time: 0.39, lr: [0.009432439442897787], Loss: 2.163087, Acc:0.785928, Semantic loss: 0.807688, BCE loss: 0.569381, SB loss: 0.786018
2023-10-30 00:10:06,871 Epoch: [30/484] Iter:[220/495], Time: 0.39, lr: [0.009432061337855737], Loss: 2.170199, Acc:0.785926, Semantic loss: 0.812990, BCE loss: 0.570288, SB loss: 0.786920
2023-10-30 00:10:10,705 Epoch: [30/484] Iter:[230/495], Time: 0.39, lr: [0.009431683231129548], Loss: 2.171637, Acc:0.785730, Semantic loss: 0.813570, BCE loss: 0.570235, SB loss: 0.787832
2023-10-30 00:10:14,378 Epoch: [30/484] Iter:[240/495], Time: 0.39, lr: [0.009431305122719138], Loss: 2.181106, Acc:0.785752, Semantic loss: 0.817195, BCE loss: 0.573121, SB loss: 0.790789
2023-10-30 00:10:18,178 Epoch: [30/484] Iter:[250/495], Time: 0.39, lr: [0.009430927012624424], Loss: 2.174263, Acc:0.785092, Semantic loss: 0.812886, BCE loss: 0.571839, SB loss: 0.789538
2023-10-30 00:10:22,050 Epoch: [30/484] Iter:[260/495], Time: 0.39, lr: [0.009430548900845324], Loss: 2.177428, Acc:0.785074, Semantic loss: 0.815431, BCE loss: 0.572666, SB loss: 0.789331
2023-10-30 00:10:25,788 Epoch: [30/484] Iter:[270/495], Time: 0.39, lr: [0.009430170787381757], Loss: 2.180166, Acc:0.785673, Semantic loss: 0.817080, BCE loss: 0.571724, SB loss: 0.791362
2023-10-30 00:10:29,539 Epoch: [30/484] Iter:[280/495], Time: 0.39, lr: [0.00942979267223364], Loss: 2.188012, Acc:0.785932, Semantic loss: 0.820805, BCE loss: 0.573106, SB loss: 0.794102
2023-10-30 00:10:33,359 Epoch: [30/484] Iter:[290/495], Time: 0.39, lr: [0.009429414555400887], Loss: 2.186105, Acc:0.786362, Semantic loss: 0.818106, BCE loss: 0.574492, SB loss: 0.793507
2023-10-30 00:10:37,146 Epoch: [30/484] Iter:[300/495], Time: 0.39, lr: [0.009429036436883418], Loss: 2.183495, Acc:0.784920, Semantic loss: 0.818942, BCE loss: 0.570400, SB loss: 0.794153
2023-10-30 00:10:41,012 Epoch: [30/484] Iter:[310/495], Time: 0.39, lr: [0.009428658316681153], Loss: 2.180993, Acc:0.785679, Semantic loss: 0.818035, BCE loss: 0.569385, SB loss: 0.793573
2023-10-30 00:10:44,742 Epoch: [30/484] Iter:[320/495], Time: 0.39, lr: [0.009428280194794005], Loss: 2.188811, Acc:0.786018, Semantic loss: 0.823745, BCE loss: 0.569169, SB loss: 0.795897
2023-10-30 00:10:48,429 Epoch: [30/484] Iter:[330/495], Time: 0.39, lr: [0.009427902071221893], Loss: 2.193744, Acc:0.786309, Semantic loss: 0.826047, BCE loss: 0.571313, SB loss: 0.796384
2023-10-30 00:10:52,200 Epoch: [30/484] Iter:[340/495], Time: 0.38, lr: [0.009427523945964734], Loss: 2.190897, Acc:0.785650, Semantic loss: 0.824505, BCE loss: 0.570757, SB loss: 0.795635
2023-10-30 00:10:55,961 Epoch: [30/484] Iter:[350/495], Time: 0.38, lr: [0.009427145819022447], Loss: 2.187858, Acc:0.785289, Semantic loss: 0.823550, BCE loss: 0.569382, SB loss: 0.794926
2023-10-30 00:10:59,690 Epoch: [30/484] Iter:[360/495], Time: 0.38, lr: [0.009426767690394949], Loss: 2.184707, Acc:0.785728, Semantic loss: 0.821161, BCE loss: 0.569812, SB loss: 0.793734
2023-10-30 00:11:03,456 Epoch: [30/484] Iter:[370/495], Time: 0.38, lr: [0.009426389560082156], Loss: 2.181082, Acc:0.786148, Semantic loss: 0.819684, BCE loss: 0.567768, SB loss: 0.793630
2023-10-30 00:11:07,325 Epoch: [30/484] Iter:[380/495], Time: 0.38, lr: [0.009426011428083986], Loss: 2.182735, Acc:0.785741, Semantic loss: 0.821979, BCE loss: 0.567276, SB loss: 0.793479
2023-10-30 00:11:11,070 Epoch: [30/484] Iter:[390/495], Time: 0.38, lr: [0.009425633294400356], Loss: 2.182145, Acc:0.786506, Semantic loss: 0.821688, BCE loss: 0.567277, SB loss: 0.793180
2023-10-30 00:11:14,929 Epoch: [30/484] Iter:[400/495], Time: 0.38, lr: [0.009425255159031184], Loss: 2.177130, Acc:0.787100, Semantic loss: 0.818864, BCE loss: 0.566769, SB loss: 0.791497
2023-10-30 00:11:18,815 Epoch: [30/484] Iter:[410/495], Time: 0.38, lr: [0.009424877021976388], Loss: 2.184587, Acc:0.787085, Semantic loss: 0.822989, BCE loss: 0.567168, SB loss: 0.794430
2023-10-30 00:11:22,689 Epoch: [30/484] Iter:[420/495], Time: 0.38, lr: [0.009424498883235884], Loss: 2.185893, Acc:0.788177, Semantic loss: 0.822797, BCE loss: 0.568988, SB loss: 0.794107
2023-10-30 00:11:26,350 Epoch: [30/484] Iter:[430/495], Time: 0.38, lr: [0.00942412074280959], Loss: 2.183148, Acc:0.788349, Semantic loss: 0.820365, BCE loss: 0.569208, SB loss: 0.793575
2023-10-30 00:11:30,077 Epoch: [30/484] Iter:[440/495], Time: 0.38, lr: [0.009423742600697423], Loss: 2.184831, Acc:0.787610, Semantic loss: 0.823220, BCE loss: 0.568137, SB loss: 0.793475
2023-10-30 00:11:33,908 Epoch: [30/484] Iter:[450/495], Time: 0.38, lr: [0.009423364456899301], Loss: 2.186961, Acc:0.788183, Semantic loss: 0.824117, BCE loss: 0.568838, SB loss: 0.794006
2023-10-30 00:11:37,763 Epoch: [30/484] Iter:[460/495], Time: 0.38, lr: [0.009422986311415141], Loss: 2.184512, Acc:0.787665, Semantic loss: 0.822797, BCE loss: 0.568346, SB loss: 0.793369
2023-10-30 00:11:41,482 Epoch: [30/484] Iter:[470/495], Time: 0.38, lr: [0.00942260816424486], Loss: 2.185801, Acc:0.788817, Semantic loss: 0.823270, BCE loss: 0.569436, SB loss: 0.793095
2023-10-30 00:11:45,207 Epoch: [30/484] Iter:[480/495], Time: 0.38, lr: [0.009422230015388375], Loss: 2.184963, Acc:0.788100, Semantic loss: 0.822849, BCE loss: 0.569726, SB loss: 0.792388
2023-10-30 00:11:48,779 Epoch: [30/484] Iter:[490/495], Time: 0.38, lr: [0.009421851864845603], Loss: 2.187454, Acc:0.788099, Semantic loss: 0.825010, BCE loss: 0.569773, SB loss: 0.792671
2023-10-30 00:14:47,410 0 [8.80870892e-01 5.31797772e-01 7.92161289e-01 5.83086622e-02
 2.33700441e-01 4.02841682e-01 4.08615426e-01 5.41002544e-01
 8.39036790e-01 3.91239230e-01 8.43870864e-01 5.88327597e-01
 9.01387922e-03 7.54873699e-01 4.55312028e-05 1.75624279e-02
 1.51708425e-02 6.79373390e-03 5.49264743e-01] 0.41392094976800164
2023-10-30 00:14:47,410 1 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271] 0.6210620500069709
2023-10-30 00:14:47,414 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:14:47,662 Loss: 2.148, MeanIU:  0.6211, Best_mIoU:  0.6427
2023-10-30 00:14:47,662 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271]
2023-10-30 00:14:49,621 Epoch: [31/484] Iter:[0/495], Time: 1.93, lr: [0.009421662788941835], Loss: 1.904800, Acc:0.825152, Semantic loss: 0.694788, BCE loss: 0.462756, SB loss: 0.747256
2023-10-30 00:14:53,587 Epoch: [31/484] Iter:[10/495], Time: 0.54, lr: [0.009421284635869479], Loss: 2.118079, Acc:0.759773, Semantic loss: 0.809782, BCE loss: 0.519602, SB loss: 0.788695
2023-10-30 00:14:57,327 Epoch: [31/484] Iter:[20/495], Time: 0.46, lr: [0.00942090648111063], Loss: 2.110035, Acc:0.775025, Semantic loss: 0.817183, BCE loss: 0.511321, SB loss: 0.781531
2023-10-30 00:15:00,935 Epoch: [31/484] Iter:[30/495], Time: 0.43, lr: [0.009420528324665205], Loss: 2.129594, Acc:0.790165, Semantic loss: 0.799438, BCE loss: 0.539867, SB loss: 0.790289
2023-10-30 00:15:04,554 Epoch: [31/484] Iter:[40/495], Time: 0.41, lr: [0.009420150166533123], Loss: 2.134700, Acc:0.790273, Semantic loss: 0.805472, BCE loss: 0.532184, SB loss: 0.797044
2023-10-30 00:15:08,153 Epoch: [31/484] Iter:[50/495], Time: 0.40, lr: [0.009419772006714297], Loss: 2.163726, Acc:0.785103, Semantic loss: 0.823155, BCE loss: 0.530812, SB loss: 0.809760
2023-10-30 00:15:11,827 Epoch: [31/484] Iter:[60/495], Time: 0.40, lr: [0.00941939384520865], Loss: 2.166162, Acc:0.789150, Semantic loss: 0.826170, BCE loss: 0.529827, SB loss: 0.810165
2023-10-30 00:15:15,420 Epoch: [31/484] Iter:[70/495], Time: 0.39, lr: [0.009419015682016094], Loss: 2.156942, Acc:0.783744, Semantic loss: 0.827176, BCE loss: 0.524757, SB loss: 0.805009
2023-10-30 00:15:19,066 Epoch: [31/484] Iter:[80/495], Time: 0.39, lr: [0.009418637517136548], Loss: 2.165732, Acc:0.782566, Semantic loss: 0.832287, BCE loss: 0.530698, SB loss: 0.802747
2023-10-30 00:15:22,856 Epoch: [31/484] Iter:[90/495], Time: 0.39, lr: [0.00941825935056993], Loss: 2.182516, Acc:0.780758, Semantic loss: 0.840853, BCE loss: 0.537802, SB loss: 0.803860
2023-10-30 00:15:26,507 Epoch: [31/484] Iter:[100/495], Time: 0.38, lr: [0.009417881182316156], Loss: 2.177825, Acc:0.778178, Semantic loss: 0.839843, BCE loss: 0.536134, SB loss: 0.801848
2023-10-30 00:15:30,215 Epoch: [31/484] Iter:[110/495], Time: 0.38, lr: [0.009417503012375147], Loss: 2.173997, Acc:0.778954, Semantic loss: 0.832121, BCE loss: 0.538809, SB loss: 0.803067
2023-10-30 00:15:33,928 Epoch: [31/484] Iter:[120/495], Time: 0.38, lr: [0.009417124840746817], Loss: 2.195091, Acc:0.780674, Semantic loss: 0.846056, BCE loss: 0.544361, SB loss: 0.804674
2023-10-30 00:15:37,572 Epoch: [31/484] Iter:[130/495], Time: 0.38, lr: [0.00941674666743108], Loss: 2.197828, Acc:0.782018, Semantic loss: 0.844990, BCE loss: 0.547608, SB loss: 0.805230
2023-10-30 00:15:41,332 Epoch: [31/484] Iter:[140/495], Time: 0.38, lr: [0.009416368492427857], Loss: 2.198599, Acc:0.780553, Semantic loss: 0.847594, BCE loss: 0.547678, SB loss: 0.803327
2023-10-30 00:15:44,968 Epoch: [31/484] Iter:[150/495], Time: 0.38, lr: [0.009415990315737066], Loss: 2.222100, Acc:0.779538, Semantic loss: 0.863469, BCE loss: 0.550211, SB loss: 0.808420
2023-10-30 00:15:48,680 Epoch: [31/484] Iter:[160/495], Time: 0.38, lr: [0.009415612137358623], Loss: 2.215474, Acc:0.778886, Semantic loss: 0.858885, BCE loss: 0.548124, SB loss: 0.808465
2023-10-30 00:15:52,377 Epoch: [31/484] Iter:[170/495], Time: 0.38, lr: [0.009415233957292444], Loss: 2.214212, Acc:0.780379, Semantic loss: 0.856879, BCE loss: 0.548953, SB loss: 0.808380
2023-10-30 00:15:56,033 Epoch: [31/484] Iter:[180/495], Time: 0.38, lr: [0.009414855775538447], Loss: 2.213585, Acc:0.780857, Semantic loss: 0.855829, BCE loss: 0.548788, SB loss: 0.808968
2023-10-30 00:15:59,753 Epoch: [31/484] Iter:[190/495], Time: 0.38, lr: [0.009414477592096552], Loss: 2.209473, Acc:0.781658, Semantic loss: 0.852515, BCE loss: 0.549901, SB loss: 0.807056
2023-10-30 00:16:03,503 Epoch: [31/484] Iter:[200/495], Time: 0.38, lr: [0.00941409940696667], Loss: 2.199211, Acc:0.782995, Semantic loss: 0.845227, BCE loss: 0.550423, SB loss: 0.803562
2023-10-30 00:16:07,236 Epoch: [31/484] Iter:[210/495], Time: 0.38, lr: [0.009413721220148724], Loss: 2.191476, Acc:0.781500, Semantic loss: 0.840118, BCE loss: 0.549773, SB loss: 0.801585
2023-10-30 00:16:11,006 Epoch: [31/484] Iter:[220/495], Time: 0.38, lr: [0.009413343031642627], Loss: 2.192041, Acc:0.781665, Semantic loss: 0.841003, BCE loss: 0.550266, SB loss: 0.800772
2023-10-30 00:16:14,762 Epoch: [31/484] Iter:[230/495], Time: 0.38, lr: [0.009412964841448298], Loss: 2.197948, Acc:0.781418, Semantic loss: 0.842844, BCE loss: 0.553525, SB loss: 0.801579
2023-10-30 00:16:18,489 Epoch: [31/484] Iter:[240/495], Time: 0.38, lr: [0.009412586649565654], Loss: 2.197042, Acc:0.781394, Semantic loss: 0.841768, BCE loss: 0.555189, SB loss: 0.800086
2023-10-30 00:16:22,240 Epoch: [31/484] Iter:[250/495], Time: 0.38, lr: [0.009412208455994612], Loss: 2.196803, Acc:0.781933, Semantic loss: 0.841073, BCE loss: 0.555635, SB loss: 0.800094
2023-10-30 00:16:25,990 Epoch: [31/484] Iter:[260/495], Time: 0.38, lr: [0.00941183026073509], Loss: 2.196334, Acc:0.782655, Semantic loss: 0.839651, BCE loss: 0.556412, SB loss: 0.800272
2023-10-30 00:16:29,747 Epoch: [31/484] Iter:[270/495], Time: 0.38, lr: [0.009411452063787002], Loss: 2.195213, Acc:0.782023, Semantic loss: 0.839669, BCE loss: 0.555639, SB loss: 0.799906
2023-10-30 00:16:33,482 Epoch: [31/484] Iter:[280/495], Time: 0.38, lr: [0.00941107386515027], Loss: 2.190914, Acc:0.783703, Semantic loss: 0.834350, BCE loss: 0.558954, SB loss: 0.797610
2023-10-30 00:16:37,264 Epoch: [31/484] Iter:[290/495], Time: 0.38, lr: [0.009410695664824805], Loss: 2.186613, Acc:0.784754, Semantic loss: 0.832404, BCE loss: 0.557338, SB loss: 0.796871
2023-10-30 00:16:41,056 Epoch: [31/484] Iter:[300/495], Time: 0.38, lr: [0.009410317462810527], Loss: 2.190704, Acc:0.784177, Semantic loss: 0.837421, BCE loss: 0.555390, SB loss: 0.797893
2023-10-30 00:16:44,822 Epoch: [31/484] Iter:[310/495], Time: 0.38, lr: [0.009409939259107358], Loss: 2.190900, Acc:0.783353, Semantic loss: 0.838064, BCE loss: 0.554947, SB loss: 0.797889
2023-10-30 00:16:48,635 Epoch: [31/484] Iter:[320/495], Time: 0.38, lr: [0.009409561053715206], Loss: 2.193209, Acc:0.783726, Semantic loss: 0.839178, BCE loss: 0.556907, SB loss: 0.797123
2023-10-30 00:16:52,340 Epoch: [31/484] Iter:[330/495], Time: 0.38, lr: [0.009409182846633994], Loss: 2.192184, Acc:0.783785, Semantic loss: 0.838216, BCE loss: 0.556629, SB loss: 0.797339
2023-10-30 00:16:56,184 Epoch: [31/484] Iter:[340/495], Time: 0.38, lr: [0.009408804637863637], Loss: 2.192063, Acc:0.782791, Semantic loss: 0.838186, BCE loss: 0.556177, SB loss: 0.797701
2023-10-30 00:16:59,881 Epoch: [31/484] Iter:[350/495], Time: 0.38, lr: [0.009408426427404052], Loss: 2.191195, Acc:0.782352, Semantic loss: 0.835657, BCE loss: 0.557685, SB loss: 0.797853
2023-10-30 00:17:03,633 Epoch: [31/484] Iter:[360/495], Time: 0.38, lr: [0.009408048215255158], Loss: 2.192337, Acc:0.781583, Semantic loss: 0.837001, BCE loss: 0.556757, SB loss: 0.798578
2023-10-30 00:17:07,451 Epoch: [31/484] Iter:[370/495], Time: 0.38, lr: [0.009407670001416868], Loss: 2.193407, Acc:0.782337, Semantic loss: 0.836392, BCE loss: 0.559158, SB loss: 0.797857
2023-10-30 00:17:11,188 Epoch: [31/484] Iter:[380/495], Time: 0.38, lr: [0.009407291785889102], Loss: 2.196912, Acc:0.782254, Semantic loss: 0.838607, BCE loss: 0.559985, SB loss: 0.798320
2023-10-30 00:17:14,895 Epoch: [31/484] Iter:[390/495], Time: 0.38, lr: [0.009406913568671777], Loss: 2.190419, Acc:0.782755, Semantic loss: 0.834773, BCE loss: 0.559061, SB loss: 0.796585
2023-10-30 00:17:18,636 Epoch: [31/484] Iter:[400/495], Time: 0.38, lr: [0.00940653534976481], Loss: 2.184542, Acc:0.782905, Semantic loss: 0.832358, BCE loss: 0.556594, SB loss: 0.795590
2023-10-30 00:17:22,380 Epoch: [31/484] Iter:[410/495], Time: 0.38, lr: [0.009406157129168117], Loss: 2.185110, Acc:0.784037, Semantic loss: 0.832614, BCE loss: 0.557227, SB loss: 0.795269
2023-10-30 00:17:26,124 Epoch: [31/484] Iter:[420/495], Time: 0.38, lr: [0.009405778906881615], Loss: 2.183117, Acc:0.784193, Semantic loss: 0.831851, BCE loss: 0.557293, SB loss: 0.793973
2023-10-30 00:17:29,915 Epoch: [31/484] Iter:[430/495], Time: 0.38, lr: [0.009405400682905221], Loss: 2.180044, Acc:0.784748, Semantic loss: 0.829848, BCE loss: 0.557326, SB loss: 0.792871
2023-10-30 00:17:33,701 Epoch: [31/484] Iter:[440/495], Time: 0.38, lr: [0.009405022457238852], Loss: 2.177016, Acc:0.785815, Semantic loss: 0.827443, BCE loss: 0.557049, SB loss: 0.792525
2023-10-30 00:17:37,405 Epoch: [31/484] Iter:[450/495], Time: 0.38, lr: [0.009404644229882426], Loss: 2.177308, Acc:0.785721, Semantic loss: 0.827728, BCE loss: 0.556737, SB loss: 0.792843
2023-10-30 00:17:41,109 Epoch: [31/484] Iter:[460/495], Time: 0.38, lr: [0.009404266000835859], Loss: 2.179895, Acc:0.785705, Semantic loss: 0.830302, BCE loss: 0.556478, SB loss: 0.793115
2023-10-30 00:17:44,974 Epoch: [31/484] Iter:[470/495], Time: 0.38, lr: [0.009403887770099066], Loss: 2.176091, Acc:0.786378, Semantic loss: 0.827209, BCE loss: 0.556352, SB loss: 0.792530
2023-10-30 00:17:48,745 Epoch: [31/484] Iter:[480/495], Time: 0.38, lr: [0.009403509537671967], Loss: 2.179034, Acc:0.786696, Semantic loss: 0.829164, BCE loss: 0.556243, SB loss: 0.793627
2023-10-30 00:17:52,314 Epoch: [31/484] Iter:[490/495], Time: 0.38, lr: [0.009403131303554479], Loss: 2.178336, Acc:0.786296, Semantic loss: 0.828316, BCE loss: 0.556566, SB loss: 0.793454
2023-10-30 00:17:53,747 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:17:53,993 Loss: 2.148, MeanIU:  0.6211, Best_mIoU:  0.6427
2023-10-30 00:17:53,993 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271]
2023-10-30 00:17:56,382 Epoch: [32/484] Iter:[0/495], Time: 2.35, lr: [0.009402942185861811], Loss: 2.652953, Acc:0.718354, Semantic loss: 1.050090, BCE loss: 0.794597, SB loss: 0.808266
2023-10-30 00:18:00,392 Epoch: [32/484] Iter:[10/495], Time: 0.58, lr: [0.00940256394920858], Loss: 2.271330, Acc:0.809976, Semantic loss: 0.855117, BCE loss: 0.602165, SB loss: 0.814048
2023-10-30 00:18:04,179 Epoch: [32/484] Iter:[20/495], Time: 0.48, lr: [0.009402185710864753], Loss: 2.249000, Acc:0.809137, Semantic loss: 0.853324, BCE loss: 0.590638, SB loss: 0.805038
2023-10-30 00:18:07,901 Epoch: [32/484] Iter:[30/495], Time: 0.45, lr: [0.009401807470830243], Loss: 2.236456, Acc:0.809873, Semantic loss: 0.838578, BCE loss: 0.601339, SB loss: 0.796539
2023-10-30 00:18:11,615 Epoch: [32/484] Iter:[40/495], Time: 0.43, lr: [0.009401429229104969], Loss: 2.226319, Acc:0.786616, Semantic loss: 0.852438, BCE loss: 0.578207, SB loss: 0.795674
2023-10-30 00:18:15,419 Epoch: [32/484] Iter:[50/495], Time: 0.42, lr: [0.009401050985688848], Loss: 2.232847, Acc:0.786066, Semantic loss: 0.845265, BCE loss: 0.589280, SB loss: 0.798302
2023-10-30 00:18:19,180 Epoch: [32/484] Iter:[60/495], Time: 0.41, lr: [0.009400672740581796], Loss: 2.209472, Acc:0.790713, Semantic loss: 0.829633, BCE loss: 0.583573, SB loss: 0.796265
2023-10-30 00:18:22,921 Epoch: [32/484] Iter:[70/495], Time: 0.41, lr: [0.00940029449378373], Loss: 2.194397, Acc:0.786770, Semantic loss: 0.825839, BCE loss: 0.572953, SB loss: 0.795606
2023-10-30 00:18:26,592 Epoch: [32/484] Iter:[80/495], Time: 0.40, lr: [0.009399916245294567], Loss: 2.199519, Acc:0.787597, Semantic loss: 0.825989, BCE loss: 0.577189, SB loss: 0.796341
2023-10-30 00:18:30,404 Epoch: [32/484] Iter:[90/495], Time: 0.40, lr: [0.009399537995114225], Loss: 2.230825, Acc:0.785609, Semantic loss: 0.856334, BCE loss: 0.565872, SB loss: 0.808619
2023-10-30 00:18:34,202 Epoch: [32/484] Iter:[100/495], Time: 0.40, lr: [0.009399159743242621], Loss: 2.220954, Acc:0.785116, Semantic loss: 0.853827, BCE loss: 0.563180, SB loss: 0.803948
2023-10-30 00:18:38,102 Epoch: [32/484] Iter:[110/495], Time: 0.40, lr: [0.009398781489679667], Loss: 2.216110, Acc:0.788685, Semantic loss: 0.846392, BCE loss: 0.566796, SB loss: 0.802923
2023-10-30 00:18:41,771 Epoch: [32/484] Iter:[120/495], Time: 0.39, lr: [0.009398403234425286], Loss: 2.220058, Acc:0.789058, Semantic loss: 0.852921, BCE loss: 0.565658, SB loss: 0.801478
2023-10-30 00:18:45,423 Epoch: [32/484] Iter:[130/495], Time: 0.39, lr: [0.009398024977479392], Loss: 2.220857, Acc:0.788751, Semantic loss: 0.853765, BCE loss: 0.565771, SB loss: 0.801320
2023-10-30 00:18:49,197 Epoch: [32/484] Iter:[140/495], Time: 0.39, lr: [0.009397646718841898], Loss: 2.213626, Acc:0.790367, Semantic loss: 0.854129, BCE loss: 0.562883, SB loss: 0.796614
2023-10-30 00:18:52,997 Epoch: [32/484] Iter:[150/495], Time: 0.39, lr: [0.00939726845851273], Loss: 2.226574, Acc:0.788049, Semantic loss: 0.861630, BCE loss: 0.563973, SB loss: 0.800972
2023-10-30 00:18:56,759 Epoch: [32/484] Iter:[160/495], Time: 0.39, lr: [0.009396890196491798], Loss: 2.217834, Acc:0.788145, Semantic loss: 0.853822, BCE loss: 0.566010, SB loss: 0.798001
2023-10-30 00:19:00,505 Epoch: [32/484] Iter:[170/495], Time: 0.39, lr: [0.009396511932779019], Loss: 2.230772, Acc:0.788152, Semantic loss: 0.859519, BCE loss: 0.568588, SB loss: 0.802666
2023-10-30 00:19:04,320 Epoch: [32/484] Iter:[180/495], Time: 0.39, lr: [0.009396133667374313], Loss: 2.221946, Acc:0.787415, Semantic loss: 0.854208, BCE loss: 0.566615, SB loss: 0.801124
2023-10-30 00:19:08,101 Epoch: [32/484] Iter:[190/495], Time: 0.39, lr: [0.009395755400277593], Loss: 2.219302, Acc:0.788422, Semantic loss: 0.852379, BCE loss: 0.565158, SB loss: 0.801765
2023-10-30 00:19:11,894 Epoch: [32/484] Iter:[200/495], Time: 0.39, lr: [0.009395377131488776], Loss: 2.209782, Acc:0.788495, Semantic loss: 0.845121, BCE loss: 0.565081, SB loss: 0.799580
2023-10-30 00:19:15,796 Epoch: [32/484] Iter:[210/495], Time: 0.39, lr: [0.009394998861007784], Loss: 2.208837, Acc:0.789158, Semantic loss: 0.844915, BCE loss: 0.564685, SB loss: 0.799238
2023-10-30 00:19:19,559 Epoch: [32/484] Iter:[220/495], Time: 0.39, lr: [0.009394620588834527], Loss: 2.209857, Acc:0.789168, Semantic loss: 0.847758, BCE loss: 0.564219, SB loss: 0.797879
2023-10-30 00:19:23,344 Epoch: [32/484] Iter:[230/495], Time: 0.39, lr: [0.009394242314968927], Loss: 2.200925, Acc:0.789216, Semantic loss: 0.843863, BCE loss: 0.561640, SB loss: 0.795421
2023-10-30 00:19:27,185 Epoch: [32/484] Iter:[240/495], Time: 0.39, lr: [0.009393864039410898], Loss: 2.197213, Acc:0.789050, Semantic loss: 0.842425, BCE loss: 0.559686, SB loss: 0.795101
2023-10-30 00:19:30,896 Epoch: [32/484] Iter:[250/495], Time: 0.39, lr: [0.009393485762160356], Loss: 2.191651, Acc:0.788874, Semantic loss: 0.839380, BCE loss: 0.558651, SB loss: 0.793621
2023-10-30 00:19:34,630 Epoch: [32/484] Iter:[260/495], Time: 0.39, lr: [0.00939310748321722], Loss: 2.189692, Acc:0.787848, Semantic loss: 0.838051, BCE loss: 0.559146, SB loss: 0.792495
2023-10-30 00:19:38,457 Epoch: [32/484] Iter:[270/495], Time: 0.39, lr: [0.009392729202581405], Loss: 2.186395, Acc:0.787364, Semantic loss: 0.836131, BCE loss: 0.558303, SB loss: 0.791960
2023-10-30 00:19:42,176 Epoch: [32/484] Iter:[280/495], Time: 0.38, lr: [0.009392350920252828], Loss: 2.182926, Acc:0.787632, Semantic loss: 0.834664, BCE loss: 0.557544, SB loss: 0.790718
2023-10-30 00:19:45,914 Epoch: [32/484] Iter:[290/495], Time: 0.38, lr: [0.009391972636231406], Loss: 2.187468, Acc:0.788533, Semantic loss: 0.837600, BCE loss: 0.559102, SB loss: 0.790766
2023-10-30 00:19:49,699 Epoch: [32/484] Iter:[300/495], Time: 0.38, lr: [0.009391594350517056], Loss: 2.182587, Acc:0.787779, Semantic loss: 0.834008, BCE loss: 0.558239, SB loss: 0.790340
2023-10-30 00:19:53,442 Epoch: [32/484] Iter:[310/495], Time: 0.38, lr: [0.009391216063109694], Loss: 2.185157, Acc:0.788601, Semantic loss: 0.835144, BCE loss: 0.558716, SB loss: 0.791297
2023-10-30 00:19:57,276 Epoch: [32/484] Iter:[320/495], Time: 0.38, lr: [0.009390837774009236], Loss: 2.191095, Acc:0.788654, Semantic loss: 0.838631, BCE loss: 0.559197, SB loss: 0.793267
2023-10-30 00:20:00,984 Epoch: [32/484] Iter:[330/495], Time: 0.38, lr: [0.0093904594832156], Loss: 2.189393, Acc:0.788331, Semantic loss: 0.837553, BCE loss: 0.558532, SB loss: 0.793308
2023-10-30 00:20:04,802 Epoch: [32/484] Iter:[340/495], Time: 0.38, lr: [0.009390081190728702], Loss: 2.187980, Acc:0.788087, Semantic loss: 0.836847, BCE loss: 0.559340, SB loss: 0.791792
2023-10-30 00:20:08,512 Epoch: [32/484] Iter:[350/495], Time: 0.38, lr: [0.009389702896548459], Loss: 2.185968, Acc:0.789125, Semantic loss: 0.835859, BCE loss: 0.558832, SB loss: 0.791276
2023-10-30 00:20:12,241 Epoch: [32/484] Iter:[360/495], Time: 0.38, lr: [0.009389324600674787], Loss: 2.176584, Acc:0.787906, Semantic loss: 0.830736, BCE loss: 0.556122, SB loss: 0.789726
2023-10-30 00:20:15,942 Epoch: [32/484] Iter:[370/495], Time: 0.38, lr: [0.009388946303107602], Loss: 2.177506, Acc:0.787588, Semantic loss: 0.831367, BCE loss: 0.556431, SB loss: 0.789707
2023-10-30 00:20:19,884 Epoch: [32/484] Iter:[380/495], Time: 0.38, lr: [0.009388568003846822], Loss: 2.177556, Acc:0.786625, Semantic loss: 0.832068, BCE loss: 0.555903, SB loss: 0.789584
2023-10-30 00:20:23,710 Epoch: [32/484] Iter:[390/495], Time: 0.38, lr: [0.009388189702892364], Loss: 2.179883, Acc:0.786406, Semantic loss: 0.832252, BCE loss: 0.556971, SB loss: 0.790660
2023-10-30 00:20:27,433 Epoch: [32/484] Iter:[400/495], Time: 0.38, lr: [0.009387811400244144], Loss: 2.183086, Acc:0.785155, Semantic loss: 0.835057, BCE loss: 0.557850, SB loss: 0.790179
2023-10-30 00:20:31,357 Epoch: [32/484] Iter:[410/495], Time: 0.38, lr: [0.009387433095902079], Loss: 2.185604, Acc:0.785115, Semantic loss: 0.835047, BCE loss: 0.558595, SB loss: 0.791962
2023-10-30 00:20:35,207 Epoch: [32/484] Iter:[420/495], Time: 0.38, lr: [0.009387054789866083], Loss: 2.188144, Acc:0.785101, Semantic loss: 0.834770, BCE loss: 0.560801, SB loss: 0.792574
2023-10-30 00:20:38,946 Epoch: [32/484] Iter:[430/495], Time: 0.38, lr: [0.009386676482136076], Loss: 2.192159, Acc:0.785003, Semantic loss: 0.836338, BCE loss: 0.562128, SB loss: 0.793692
2023-10-30 00:20:42,785 Epoch: [32/484] Iter:[440/495], Time: 0.38, lr: [0.009386298172711971], Loss: 2.191630, Acc:0.783898, Semantic loss: 0.836472, BCE loss: 0.560338, SB loss: 0.794820
2023-10-30 00:20:46,517 Epoch: [32/484] Iter:[450/495], Time: 0.38, lr: [0.00938591986159369], Loss: 2.192498, Acc:0.783298, Semantic loss: 0.837723, BCE loss: 0.559486, SB loss: 0.795289
2023-10-30 00:20:50,379 Epoch: [32/484] Iter:[460/495], Time: 0.38, lr: [0.009385541548781141], Loss: 2.189047, Acc:0.783893, Semantic loss: 0.835095, BCE loss: 0.559328, SB loss: 0.794624
2023-10-30 00:20:54,095 Epoch: [32/484] Iter:[470/495], Time: 0.38, lr: [0.00938516323427425], Loss: 2.189084, Acc:0.783490, Semantic loss: 0.834978, BCE loss: 0.559521, SB loss: 0.794585
2023-10-30 00:20:57,990 Epoch: [32/484] Iter:[480/495], Time: 0.38, lr: [0.009384784918072927], Loss: 2.189815, Acc:0.784944, Semantic loss: 0.833704, BCE loss: 0.561806, SB loss: 0.794304
2023-10-30 00:21:01,639 Epoch: [32/484] Iter:[490/495], Time: 0.38, lr: [0.009384406600177092], Loss: 2.189828, Acc:0.785168, Semantic loss: 0.833586, BCE loss: 0.561755, SB loss: 0.794487
2023-10-30 00:21:03,074 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:21:03,320 Loss: 2.148, MeanIU:  0.6211, Best_mIoU:  0.6427
2023-10-30 00:21:03,320 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271]
2023-10-30 00:21:05,424 Epoch: [33/484] Iter:[0/495], Time: 2.07, lr: [0.009384217440593706], Loss: 1.908732, Acc:0.792377, Semantic loss: 0.689608, BCE loss: 0.555313, SB loss: 0.663811
2023-10-30 00:21:09,556 Epoch: [33/484] Iter:[10/495], Time: 0.56, lr: [0.009383839120155942], Loss: 2.202729, Acc:0.795185, Semantic loss: 0.789613, BCE loss: 0.657318, SB loss: 0.755798
2023-10-30 00:21:13,452 Epoch: [33/484] Iter:[20/495], Time: 0.48, lr: [0.00938346079802346], Loss: 2.212886, Acc:0.787144, Semantic loss: 0.807118, BCE loss: 0.613599, SB loss: 0.792169
2023-10-30 00:21:17,164 Epoch: [33/484] Iter:[30/495], Time: 0.45, lr: [0.009383082474196168], Loss: 2.159147, Acc:0.794388, Semantic loss: 0.796560, BCE loss: 0.587214, SB loss: 0.775373
2023-10-30 00:21:21,028 Epoch: [33/484] Iter:[40/495], Time: 0.43, lr: [0.009382704148673988], Loss: 2.189738, Acc:0.793660, Semantic loss: 0.836194, BCE loss: 0.573122, SB loss: 0.780423
2023-10-30 00:21:24,693 Epoch: [33/484] Iter:[50/495], Time: 0.42, lr: [0.009382325821456837], Loss: 2.179606, Acc:0.792139, Semantic loss: 0.828297, BCE loss: 0.572079, SB loss: 0.779231
2023-10-30 00:21:28,449 Epoch: [33/484] Iter:[60/495], Time: 0.41, lr: [0.00938194749254463], Loss: 2.185495, Acc:0.793142, Semantic loss: 0.829033, BCE loss: 0.572032, SB loss: 0.784431
2023-10-30 00:21:32,266 Epoch: [33/484] Iter:[70/495], Time: 0.41, lr: [0.009381569161937282], Loss: 2.183747, Acc:0.794030, Semantic loss: 0.818966, BCE loss: 0.580410, SB loss: 0.784371
2023-10-30 00:21:36,030 Epoch: [33/484] Iter:[80/495], Time: 0.40, lr: [0.009381190829634711], Loss: 2.165549, Acc:0.798764, Semantic loss: 0.806421, BCE loss: 0.577854, SB loss: 0.781274
2023-10-30 00:21:39,761 Epoch: [33/484] Iter:[90/495], Time: 0.40, lr: [0.009380812495636834], Loss: 2.166640, Acc:0.795953, Semantic loss: 0.805989, BCE loss: 0.578805, SB loss: 0.781847
2023-10-30 00:21:43,460 Epoch: [33/484] Iter:[100/495], Time: 0.40, lr: [0.009380434159943565], Loss: 2.174293, Acc:0.797428, Semantic loss: 0.811323, BCE loss: 0.581614, SB loss: 0.781355
2023-10-30 00:21:47,243 Epoch: [33/484] Iter:[110/495], Time: 0.40, lr: [0.009380055822554823], Loss: 2.178030, Acc:0.799366, Semantic loss: 0.817376, BCE loss: 0.579463, SB loss: 0.781191
2023-10-30 00:21:51,008 Epoch: [33/484] Iter:[120/495], Time: 0.39, lr: [0.009379677483470522], Loss: 2.177787, Acc:0.800027, Semantic loss: 0.816151, BCE loss: 0.580842, SB loss: 0.780794
2023-10-30 00:21:54,832 Epoch: [33/484] Iter:[130/495], Time: 0.39, lr: [0.009379299142690582], Loss: 2.170751, Acc:0.799673, Semantic loss: 0.816629, BCE loss: 0.574309, SB loss: 0.779813
2023-10-30 00:21:58,519 Epoch: [33/484] Iter:[140/495], Time: 0.39, lr: [0.009378920800214916], Loss: 2.174624, Acc:0.797839, Semantic loss: 0.822145, BCE loss: 0.569673, SB loss: 0.782807
2023-10-30 00:22:02,481 Epoch: [33/484] Iter:[150/495], Time: 0.39, lr: [0.009378542456043443], Loss: 2.179749, Acc:0.796663, Semantic loss: 0.828067, BCE loss: 0.568480, SB loss: 0.783202
2023-10-30 00:22:06,190 Epoch: [33/484] Iter:[160/495], Time: 0.39, lr: [0.009378164110176076], Loss: 2.199558, Acc:0.796124, Semantic loss: 0.842341, BCE loss: 0.567862, SB loss: 0.789356
2023-10-30 00:22:10,002 Epoch: [33/484] Iter:[170/495], Time: 0.39, lr: [0.009377785762612735], Loss: 2.185445, Acc:0.796467, Semantic loss: 0.833223, BCE loss: 0.565419, SB loss: 0.786803
2023-10-30 00:22:13,777 Epoch: [33/484] Iter:[180/495], Time: 0.39, lr: [0.009377407413353333], Loss: 2.176995, Acc:0.794247, Semantic loss: 0.830223, BCE loss: 0.560431, SB loss: 0.786341
2023-10-30 00:22:17,602 Epoch: [33/484] Iter:[190/495], Time: 0.39, lr: [0.00937702906239779], Loss: 2.171698, Acc:0.795849, Semantic loss: 0.826601, BCE loss: 0.560155, SB loss: 0.784942
2023-10-30 00:22:21,507 Epoch: [33/484] Iter:[200/495], Time: 0.39, lr: [0.00937665070974602], Loss: 2.172017, Acc:0.797214, Semantic loss: 0.824209, BCE loss: 0.563462, SB loss: 0.784346
2023-10-30 00:22:25,213 Epoch: [33/484] Iter:[210/495], Time: 0.39, lr: [0.00937627235539794], Loss: 2.183360, Acc:0.797162, Semantic loss: 0.831461, BCE loss: 0.564869, SB loss: 0.787031
2023-10-30 00:22:29,140 Epoch: [33/484] Iter:[220/495], Time: 0.39, lr: [0.009375893999353466], Loss: 2.180955, Acc:0.797353, Semantic loss: 0.828246, BCE loss: 0.566262, SB loss: 0.786447
2023-10-30 00:22:32,933 Epoch: [33/484] Iter:[230/495], Time: 0.39, lr: [0.009375515641612514], Loss: 2.178049, Acc:0.797963, Semantic loss: 0.826364, BCE loss: 0.565574, SB loss: 0.786110
2023-10-30 00:22:36,810 Epoch: [33/484] Iter:[240/495], Time: 0.39, lr: [0.009375137282175], Loss: 2.173154, Acc:0.797982, Semantic loss: 0.824149, BCE loss: 0.563072, SB loss: 0.785934
2023-10-30 00:22:40,531 Epoch: [33/484] Iter:[250/495], Time: 0.39, lr: [0.009374758921040843], Loss: 2.177912, Acc:0.798661, Semantic loss: 0.826728, BCE loss: 0.565491, SB loss: 0.785694
2023-10-30 00:22:44,330 Epoch: [33/484] Iter:[260/495], Time: 0.39, lr: [0.009374380558209957], Loss: 2.180060, Acc:0.797834, Semantic loss: 0.828585, BCE loss: 0.565664, SB loss: 0.785811
2023-10-30 00:22:47,953 Epoch: [33/484] Iter:[270/495], Time: 0.39, lr: [0.009374002193682259], Loss: 2.189064, Acc:0.796013, Semantic loss: 0.834361, BCE loss: 0.566010, SB loss: 0.788693
2023-10-30 00:22:51,843 Epoch: [33/484] Iter:[280/495], Time: 0.39, lr: [0.009373623827457664], Loss: 2.191705, Acc:0.795297, Semantic loss: 0.836402, BCE loss: 0.565726, SB loss: 0.789577
2023-10-30 00:22:55,611 Epoch: [33/484] Iter:[290/495], Time: 0.39, lr: [0.00937324545953609], Loss: 2.188694, Acc:0.793965, Semantic loss: 0.834151, BCE loss: 0.565324, SB loss: 0.789219
2023-10-30 00:22:59,474 Epoch: [33/484] Iter:[300/495], Time: 0.39, lr: [0.009372867089917454], Loss: 2.189968, Acc:0.794356, Semantic loss: 0.833638, BCE loss: 0.567131, SB loss: 0.789200
2023-10-30 00:23:03,210 Epoch: [33/484] Iter:[310/495], Time: 0.39, lr: [0.00937248871860167], Loss: 2.198584, Acc:0.793312, Semantic loss: 0.838798, BCE loss: 0.565821, SB loss: 0.793965
2023-10-30 00:23:06,905 Epoch: [33/484] Iter:[320/495], Time: 0.38, lr: [0.009372110345588653], Loss: 2.210634, Acc:0.792769, Semantic loss: 0.843930, BCE loss: 0.569054, SB loss: 0.797650
2023-10-30 00:23:10,712 Epoch: [33/484] Iter:[330/495], Time: 0.38, lr: [0.009371731970878323], Loss: 2.208823, Acc:0.791821, Semantic loss: 0.842398, BCE loss: 0.568916, SB loss: 0.797509
2023-10-30 00:23:14,577 Epoch: [33/484] Iter:[340/495], Time: 0.38, lr: [0.009371353594470595], Loss: 2.206552, Acc:0.792105, Semantic loss: 0.840541, BCE loss: 0.568762, SB loss: 0.797249
2023-10-30 00:23:18,484 Epoch: [33/484] Iter:[350/495], Time: 0.38, lr: [0.009370975216365384], Loss: 2.209422, Acc:0.792697, Semantic loss: 0.842832, BCE loss: 0.568953, SB loss: 0.797637
2023-10-30 00:23:22,177 Epoch: [33/484] Iter:[360/495], Time: 0.38, lr: [0.009370596836562608], Loss: 2.210970, Acc:0.793366, Semantic loss: 0.841523, BCE loss: 0.570413, SB loss: 0.799035
2023-10-30 00:23:25,959 Epoch: [33/484] Iter:[370/495], Time: 0.38, lr: [0.00937021845506218], Loss: 2.205029, Acc:0.792157, Semantic loss: 0.838147, BCE loss: 0.568566, SB loss: 0.798316
2023-10-30 00:23:29,802 Epoch: [33/484] Iter:[380/495], Time: 0.38, lr: [0.009369840071864022], Loss: 2.199814, Acc:0.791730, Semantic loss: 0.835379, BCE loss: 0.567395, SB loss: 0.797040
2023-10-30 00:23:33,539 Epoch: [33/484] Iter:[390/495], Time: 0.38, lr: [0.009369461686968046], Loss: 2.202181, Acc:0.792361, Semantic loss: 0.834728, BCE loss: 0.570703, SB loss: 0.796751
2023-10-30 00:23:37,194 Epoch: [33/484] Iter:[400/495], Time: 0.38, lr: [0.009369083300374167], Loss: 2.207579, Acc:0.792367, Semantic loss: 0.837573, BCE loss: 0.570977, SB loss: 0.799028
2023-10-30 00:23:41,067 Epoch: [33/484] Iter:[410/495], Time: 0.38, lr: [0.009368704912082302], Loss: 2.206821, Acc:0.791391, Semantic loss: 0.837232, BCE loss: 0.570746, SB loss: 0.798843
2023-10-30 00:23:44,828 Epoch: [33/484] Iter:[420/495], Time: 0.38, lr: [0.009368326522092373], Loss: 2.208701, Acc:0.790810, Semantic loss: 0.839049, BCE loss: 0.570406, SB loss: 0.799246
2023-10-30 00:23:48,515 Epoch: [33/484] Iter:[430/495], Time: 0.38, lr: [0.009367948130404287], Loss: 2.204788, Acc:0.790529, Semantic loss: 0.836631, BCE loss: 0.570062, SB loss: 0.798095
2023-10-30 00:23:52,263 Epoch: [33/484] Iter:[440/495], Time: 0.38, lr: [0.009367569737017967], Loss: 2.205058, Acc:0.789712, Semantic loss: 0.836668, BCE loss: 0.569868, SB loss: 0.798522
2023-10-30 00:23:56,025 Epoch: [33/484] Iter:[450/495], Time: 0.38, lr: [0.009367191341933326], Loss: 2.205185, Acc:0.789745, Semantic loss: 0.837167, BCE loss: 0.569102, SB loss: 0.798915
2023-10-30 00:23:59,775 Epoch: [33/484] Iter:[460/495], Time: 0.38, lr: [0.009366812945150281], Loss: 2.200068, Acc:0.790319, Semantic loss: 0.834394, BCE loss: 0.567946, SB loss: 0.797728
2023-10-30 00:24:03,669 Epoch: [33/484] Iter:[470/495], Time: 0.38, lr: [0.009366434546668748], Loss: 2.198646, Acc:0.791464, Semantic loss: 0.832942, BCE loss: 0.568217, SB loss: 0.797487
2023-10-30 00:24:07,490 Epoch: [33/484] Iter:[480/495], Time: 0.38, lr: [0.009366056146488643], Loss: 2.196927, Acc:0.792203, Semantic loss: 0.832660, BCE loss: 0.567312, SB loss: 0.796954
2023-10-30 00:24:11,011 Epoch: [33/484] Iter:[490/495], Time: 0.38, lr: [0.009365677744609884], Loss: 2.195617, Acc:0.791465, Semantic loss: 0.833016, BCE loss: 0.565973, SB loss: 0.796628
2023-10-30 00:24:12,457 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:24:12,721 Loss: 2.148, MeanIU:  0.6211, Best_mIoU:  0.6427
2023-10-30 00:24:12,721 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271]
2023-10-30 00:24:14,831 Epoch: [34/484] Iter:[0/495], Time: 2.08, lr: [0.009365488543033481], Loss: 2.152260, Acc:0.731535, Semantic loss: 0.770399, BCE loss: 0.589384, SB loss: 0.792476
2023-10-30 00:24:18,909 Epoch: [34/484] Iter:[10/495], Time: 0.56, lr: [0.00936511013860658], Loss: 2.115497, Acc:0.788487, Semantic loss: 0.777910, BCE loss: 0.572517, SB loss: 0.765070
2023-10-30 00:24:22,590 Epoch: [34/484] Iter:[20/495], Time: 0.47, lr: [0.009364731732480813], Loss: 2.118969, Acc:0.799678, Semantic loss: 0.779974, BCE loss: 0.575004, SB loss: 0.763992
2023-10-30 00:24:26,343 Epoch: [34/484] Iter:[30/495], Time: 0.44, lr: [0.009364353324656098], Loss: 2.106295, Acc:0.794353, Semantic loss: 0.770742, BCE loss: 0.577088, SB loss: 0.758465
2023-10-30 00:24:30,121 Epoch: [34/484] Iter:[40/495], Time: 0.42, lr: [0.009363974915132349], Loss: 2.103940, Acc:0.797700, Semantic loss: 0.768713, BCE loss: 0.577639, SB loss: 0.757587
2023-10-30 00:24:33,999 Epoch: [34/484] Iter:[50/495], Time: 0.42, lr: [0.009363596503909484], Loss: 2.110597, Acc:0.800786, Semantic loss: 0.771706, BCE loss: 0.580736, SB loss: 0.758155
2023-10-30 00:24:37,757 Epoch: [34/484] Iter:[60/495], Time: 0.41, lr: [0.009363218090987415], Loss: 2.116552, Acc:0.804798, Semantic loss: 0.780178, BCE loss: 0.579899, SB loss: 0.756476
2023-10-30 00:24:41,565 Epoch: [34/484] Iter:[70/495], Time: 0.41, lr: [0.009362839676366063], Loss: 2.098968, Acc:0.805331, Semantic loss: 0.772555, BCE loss: 0.573328, SB loss: 0.753085
2023-10-30 00:24:45,316 Epoch: [34/484] Iter:[80/495], Time: 0.40, lr: [0.009362461260045344], Loss: 2.086774, Acc:0.802358, Semantic loss: 0.767328, BCE loss: 0.564899, SB loss: 0.754547
2023-10-30 00:24:49,062 Epoch: [34/484] Iter:[90/495], Time: 0.40, lr: [0.00936208284202517], Loss: 2.107696, Acc:0.800651, Semantic loss: 0.781058, BCE loss: 0.569073, SB loss: 0.757565
2023-10-30 00:24:52,777 Epoch: [34/484] Iter:[100/495], Time: 0.40, lr: [0.009361704422305458], Loss: 2.099754, Acc:0.800141, Semantic loss: 0.778918, BCE loss: 0.563909, SB loss: 0.756927
2023-10-30 00:24:56,581 Epoch: [34/484] Iter:[110/495], Time: 0.39, lr: [0.009361326000886126], Loss: 2.097324, Acc:0.800933, Semantic loss: 0.776779, BCE loss: 0.562126, SB loss: 0.758419
2023-10-30 00:25:00,559 Epoch: [34/484] Iter:[120/495], Time: 0.40, lr: [0.00936094757776709], Loss: 2.086008, Acc:0.803606, Semantic loss: 0.773663, BCE loss: 0.555626, SB loss: 0.756719
2023-10-30 00:25:04,301 Epoch: [34/484] Iter:[130/495], Time: 0.39, lr: [0.009360569152948266], Loss: 2.103477, Acc:0.800424, Semantic loss: 0.785467, BCE loss: 0.557712, SB loss: 0.760298
2023-10-30 00:25:08,175 Epoch: [34/484] Iter:[140/495], Time: 0.39, lr: [0.009360190726429568], Loss: 2.116794, Acc:0.799679, Semantic loss: 0.795894, BCE loss: 0.557014, SB loss: 0.763886
2023-10-30 00:25:11,945 Epoch: [34/484] Iter:[150/495], Time: 0.39, lr: [0.009359812298210913], Loss: 2.108171, Acc:0.801195, Semantic loss: 0.790470, BCE loss: 0.555367, SB loss: 0.762334
2023-10-30 00:25:15,842 Epoch: [34/484] Iter:[160/495], Time: 0.39, lr: [0.009359433868292218], Loss: 2.116159, Acc:0.800828, Semantic loss: 0.795918, BCE loss: 0.555195, SB loss: 0.765045
2023-10-30 00:25:19,691 Epoch: [34/484] Iter:[170/495], Time: 0.39, lr: [0.009359055436673399], Loss: 2.119738, Acc:0.801063, Semantic loss: 0.796449, BCE loss: 0.556074, SB loss: 0.767215
2023-10-30 00:25:23,395 Epoch: [34/484] Iter:[180/495], Time: 0.39, lr: [0.00935867700335437], Loss: 2.133637, Acc:0.802033, Semantic loss: 0.801983, BCE loss: 0.562983, SB loss: 0.768671
2023-10-30 00:25:27,213 Epoch: [34/484] Iter:[190/495], Time: 0.39, lr: [0.009358298568335048], Loss: 2.124413, Acc:0.798780, Semantic loss: 0.797197, BCE loss: 0.560223, SB loss: 0.766993
2023-10-30 00:25:30,994 Epoch: [34/484] Iter:[200/495], Time: 0.39, lr: [0.009357920131615351], Loss: 2.131993, Acc:0.797890, Semantic loss: 0.804073, BCE loss: 0.559452, SB loss: 0.768469
2023-10-30 00:25:34,829 Epoch: [34/484] Iter:[210/495], Time: 0.39, lr: [0.009357541693195191], Loss: 2.133437, Acc:0.797598, Semantic loss: 0.806839, BCE loss: 0.558898, SB loss: 0.767700
2023-10-30 00:25:38,673 Epoch: [34/484] Iter:[220/495], Time: 0.39, lr: [0.009357163253074487], Loss: 2.142246, Acc:0.794675, Semantic loss: 0.810592, BCE loss: 0.560521, SB loss: 0.771133
2023-10-30 00:25:42,400 Epoch: [34/484] Iter:[230/495], Time: 0.39, lr: [0.009356784811253153], Loss: 2.148348, Acc:0.795539, Semantic loss: 0.812254, BCE loss: 0.562779, SB loss: 0.773315
2023-10-30 00:25:46,258 Epoch: [34/484] Iter:[240/495], Time: 0.39, lr: [0.009356406367731107], Loss: 2.149432, Acc:0.796591, Semantic loss: 0.812098, BCE loss: 0.563866, SB loss: 0.773469
2023-10-30 00:25:50,031 Epoch: [34/484] Iter:[250/495], Time: 0.39, lr: [0.009356027922508264], Loss: 2.142093, Acc:0.795032, Semantic loss: 0.806930, BCE loss: 0.562508, SB loss: 0.772655
2023-10-30 00:25:53,784 Epoch: [34/484] Iter:[260/495], Time: 0.39, lr: [0.00935564947558454], Loss: 2.144587, Acc:0.795248, Semantic loss: 0.807516, BCE loss: 0.563604, SB loss: 0.773468
2023-10-30 00:25:57,520 Epoch: [34/484] Iter:[270/495], Time: 0.39, lr: [0.00935527102695985], Loss: 2.145661, Acc:0.796098, Semantic loss: 0.807801, BCE loss: 0.563751, SB loss: 0.774109
2023-10-30 00:26:01,401 Epoch: [34/484] Iter:[280/495], Time: 0.39, lr: [0.00935489257663411], Loss: 2.146930, Acc:0.796575, Semantic loss: 0.809559, BCE loss: 0.563011, SB loss: 0.774360
2023-10-30 00:26:05,066 Epoch: [34/484] Iter:[290/495], Time: 0.39, lr: [0.009354514124607237], Loss: 2.154533, Acc:0.796159, Semantic loss: 0.814498, BCE loss: 0.565035, SB loss: 0.775001
2023-10-30 00:26:08,985 Epoch: [34/484] Iter:[300/495], Time: 0.39, lr: [0.009354135670879145], Loss: 2.152941, Acc:0.796686, Semantic loss: 0.814044, BCE loss: 0.564015, SB loss: 0.774882
2023-10-30 00:26:12,875 Epoch: [34/484] Iter:[310/495], Time: 0.39, lr: [0.009353757215449754], Loss: 2.148505, Acc:0.795916, Semantic loss: 0.811017, BCE loss: 0.563675, SB loss: 0.773813
2023-10-30 00:26:16,652 Epoch: [34/484] Iter:[320/495], Time: 0.39, lr: [0.009353378758318976], Loss: 2.144724, Acc:0.795043, Semantic loss: 0.808373, BCE loss: 0.563254, SB loss: 0.773097
2023-10-30 00:26:20,427 Epoch: [34/484] Iter:[330/495], Time: 0.39, lr: [0.009353000299486727], Loss: 2.149043, Acc:0.795257, Semantic loss: 0.809714, BCE loss: 0.564518, SB loss: 0.774811
2023-10-30 00:26:24,240 Epoch: [34/484] Iter:[340/495], Time: 0.39, lr: [0.009352621838952925], Loss: 2.149051, Acc:0.795374, Semantic loss: 0.810384, BCE loss: 0.563139, SB loss: 0.775527
2023-10-30 00:26:28,141 Epoch: [34/484] Iter:[350/495], Time: 0.39, lr: [0.009352243376717485], Loss: 2.149286, Acc:0.795890, Semantic loss: 0.810135, BCE loss: 0.562674, SB loss: 0.776477
2023-10-30 00:26:32,068 Epoch: [34/484] Iter:[360/495], Time: 0.39, lr: [0.009351864912780321], Loss: 2.152009, Acc:0.796423, Semantic loss: 0.810638, BCE loss: 0.563766, SB loss: 0.777605
2023-10-30 00:26:35,823 Epoch: [34/484] Iter:[370/495], Time: 0.39, lr: [0.009351486447141353], Loss: 2.162659, Acc:0.796294, Semantic loss: 0.815363, BCE loss: 0.566263, SB loss: 0.781033
2023-10-30 00:26:39,597 Epoch: [34/484] Iter:[380/495], Time: 0.39, lr: [0.00935110797980049], Loss: 2.166720, Acc:0.795465, Semantic loss: 0.818393, BCE loss: 0.565965, SB loss: 0.782361
2023-10-30 00:26:43,358 Epoch: [34/484] Iter:[390/495], Time: 0.39, lr: [0.009350729510757654], Loss: 2.164440, Acc:0.795106, Semantic loss: 0.816980, BCE loss: 0.565835, SB loss: 0.781625
2023-10-30 00:26:47,087 Epoch: [34/484] Iter:[400/495], Time: 0.38, lr: [0.009350351040012759], Loss: 2.165387, Acc:0.795008, Semantic loss: 0.817532, BCE loss: 0.566457, SB loss: 0.781398
2023-10-30 00:26:50,939 Epoch: [34/484] Iter:[410/495], Time: 0.38, lr: [0.00934997256756572], Loss: 2.171303, Acc:0.795120, Semantic loss: 0.819599, BCE loss: 0.569297, SB loss: 0.782408
2023-10-30 00:26:54,731 Epoch: [34/484] Iter:[420/495], Time: 0.38, lr: [0.009349594093416454], Loss: 2.170943, Acc:0.795190, Semantic loss: 0.819713, BCE loss: 0.568777, SB loss: 0.782453
2023-10-30 00:26:58,581 Epoch: [34/484] Iter:[430/495], Time: 0.38, lr: [0.009349215617564875], Loss: 2.176762, Acc:0.794961, Semantic loss: 0.822617, BCE loss: 0.569844, SB loss: 0.784301
2023-10-30 00:27:02,329 Epoch: [34/484] Iter:[440/495], Time: 0.38, lr: [0.009348837140010903], Loss: 2.175173, Acc:0.795488, Semantic loss: 0.820731, BCE loss: 0.570992, SB loss: 0.783450
2023-10-30 00:27:06,111 Epoch: [34/484] Iter:[450/495], Time: 0.38, lr: [0.009348458660754448], Loss: 2.178371, Acc:0.795125, Semantic loss: 0.822618, BCE loss: 0.571511, SB loss: 0.784241
2023-10-30 00:27:09,824 Epoch: [34/484] Iter:[460/495], Time: 0.38, lr: [0.009348080179795427], Loss: 2.176948, Acc:0.795377, Semantic loss: 0.821917, BCE loss: 0.570358, SB loss: 0.784673
2023-10-30 00:27:13,509 Epoch: [34/484] Iter:[470/495], Time: 0.38, lr: [0.00934770169713376], Loss: 2.175143, Acc:0.795768, Semantic loss: 0.820177, BCE loss: 0.570866, SB loss: 0.784100
2023-10-30 00:27:17,296 Epoch: [34/484] Iter:[480/495], Time: 0.38, lr: [0.00934732321276936], Loss: 2.172279, Acc:0.796097, Semantic loss: 0.818422, BCE loss: 0.570714, SB loss: 0.783143
2023-10-30 00:27:20,908 Epoch: [34/484] Iter:[490/495], Time: 0.38, lr: [0.00934694472670214], Loss: 2.173920, Acc:0.796378, Semantic loss: 0.819518, BCE loss: 0.571870, SB loss: 0.782533
2023-10-30 00:27:22,358 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:27:22,610 Loss: 2.148, MeanIU:  0.6211, Best_mIoU:  0.6427
2023-10-30 00:27:22,610 [0.96545934 0.76435807 0.88582556 0.35396272 0.4133374  0.54122866
 0.61471042 0.63883974 0.89292373 0.47468361 0.92481453 0.6979561
 0.39314395 0.90627318 0.37555227 0.48118942 0.31408825 0.4480693
 0.71376271]
2023-10-30 00:27:24,577 Epoch: [35/484] Iter:[0/495], Time: 1.93, lr: [0.009346755483029948], Loss: 2.177744, Acc:0.858353, Semantic loss: 1.022580, BCE loss: 0.445480, SB loss: 0.709685
2023-10-30 00:27:28,584 Epoch: [35/484] Iter:[10/495], Time: 0.54, lr: [0.009346376994408346], Loss: 2.173191, Acc:0.746479, Semantic loss: 0.860242, BCE loss: 0.520384, SB loss: 0.792565
2023-10-30 00:27:32,291 Epoch: [35/484] Iter:[20/495], Time: 0.46, lr: [0.009345998504083715], Loss: 2.197027, Acc:0.759498, Semantic loss: 0.843533, BCE loss: 0.543546, SB loss: 0.809948
2023-10-30 00:27:36,040 Epoch: [35/484] Iter:[30/495], Time: 0.43, lr: [0.009345620012055973], Loss: 2.174733, Acc:0.770631, Semantic loss: 0.833473, BCE loss: 0.532322, SB loss: 0.808938
2023-10-30 00:27:39,827 Epoch: [35/484] Iter:[40/495], Time: 0.42, lr: [0.009345241518325033], Loss: 2.174406, Acc:0.773603, Semantic loss: 0.829821, BCE loss: 0.538899, SB loss: 0.805685
2023-10-30 00:27:43,610 Epoch: [35/484] Iter:[50/495], Time: 0.41, lr: [0.009344863022890811], Loss: 2.188107, Acc:0.781166, Semantic loss: 0.831753, BCE loss: 0.551950, SB loss: 0.804404
2023-10-30 00:27:47,369 Epoch: [35/484] Iter:[60/495], Time: 0.41, lr: [0.009344484525753226], Loss: 2.192409, Acc:0.778480, Semantic loss: 0.835004, BCE loss: 0.552393, SB loss: 0.805012
2023-10-30 00:27:51,172 Epoch: [35/484] Iter:[70/495], Time: 0.40, lr: [0.00934410602691219], Loss: 2.201571, Acc:0.784471, Semantic loss: 0.845417, BCE loss: 0.551620, SB loss: 0.804534
2023-10-30 00:27:54,858 Epoch: [35/484] Iter:[80/495], Time: 0.40, lr: [0.009343727526367621], Loss: 2.182173, Acc:0.783482, Semantic loss: 0.831292, BCE loss: 0.550291, SB loss: 0.800591
2023-10-30 00:27:58,582 Epoch: [35/484] Iter:[90/495], Time: 0.39, lr: [0.009343349024119433], Loss: 2.189778, Acc:0.782682, Semantic loss: 0.828222, BCE loss: 0.560100, SB loss: 0.801455
2023-10-30 00:28:02,283 Epoch: [35/484] Iter:[100/495], Time: 0.39, lr: [0.009342970520167544], Loss: 2.171162, Acc:0.780663, Semantic loss: 0.820066, BCE loss: 0.555102, SB loss: 0.795993
2023-10-30 00:28:06,112 Epoch: [35/484] Iter:[110/495], Time: 0.39, lr: [0.009342592014511866], Loss: 2.190365, Acc:0.782064, Semantic loss: 0.840717, BCE loss: 0.553096, SB loss: 0.796552
2023-10-30 00:28:09,811 Epoch: [35/484] Iter:[120/495], Time: 0.39, lr: [0.009342213507152317], Loss: 2.185196, Acc:0.784079, Semantic loss: 0.833997, BCE loss: 0.558399, SB loss: 0.792801
2023-10-30 00:28:13,504 Epoch: [35/484] Iter:[130/495], Time: 0.39, lr: [0.009341834998088812], Loss: 2.182645, Acc:0.783475, Semantic loss: 0.835273, BCE loss: 0.557431, SB loss: 0.789941
2023-10-30 00:28:17,269 Epoch: [35/484] Iter:[140/495], Time: 0.39, lr: [0.009341456487321266], Loss: 2.182076, Acc:0.782737, Semantic loss: 0.835309, BCE loss: 0.553758, SB loss: 0.793008
2023-10-30 00:28:21,141 Epoch: [35/484] Iter:[150/495], Time: 0.39, lr: [0.009341077974849597], Loss: 2.178123, Acc:0.782779, Semantic loss: 0.833964, BCE loss: 0.551779, SB loss: 0.792380
2023-10-30 00:28:25,024 Epoch: [35/484] Iter:[160/495], Time: 0.39, lr: [0.009340699460673719], Loss: 2.181496, Acc:0.783034, Semantic loss: 0.838361, BCE loss: 0.550400, SB loss: 0.792736
2023-10-30 00:28:28,718 Epoch: [35/484] Iter:[170/495], Time: 0.39, lr: [0.009340320944793548], Loss: 2.181610, Acc:0.781390, Semantic loss: 0.839508, BCE loss: 0.548341, SB loss: 0.793760
2023-10-30 00:28:32,514 Epoch: [35/484] Iter:[180/495], Time: 0.39, lr: [0.009339942427208998], Loss: 2.201838, Acc:0.780638, Semantic loss: 0.852228, BCE loss: 0.550805, SB loss: 0.798805
2023-10-30 00:28:36,247 Epoch: [35/484] Iter:[190/495], Time: 0.39, lr: [0.009339563907919988], Loss: 2.188567, Acc:0.782607, Semantic loss: 0.841907, BCE loss: 0.550194, SB loss: 0.796466
2023-10-30 00:28:40,080 Epoch: [35/484] Iter:[200/495], Time: 0.39, lr: [0.009339185386926428], Loss: 2.189618, Acc:0.784627, Semantic loss: 0.839289, BCE loss: 0.554916, SB loss: 0.795412
2023-10-30 00:28:43,881 Epoch: [35/484] Iter:[210/495], Time: 0.38, lr: [0.00933880686422824], Loss: 2.198683, Acc:0.787166, Semantic loss: 0.845775, BCE loss: 0.555793, SB loss: 0.797116
2023-10-30 00:28:47,622 Epoch: [35/484] Iter:[220/495], Time: 0.38, lr: [0.009338428339825336], Loss: 2.198237, Acc:0.787924, Semantic loss: 0.844514, BCE loss: 0.556676, SB loss: 0.797047
2023-10-30 00:28:51,361 Epoch: [35/484] Iter:[230/495], Time: 0.38, lr: [0.00933804981371763], Loss: 2.187322, Acc:0.789504, Semantic loss: 0.837371, BCE loss: 0.555313, SB loss: 0.794638
2023-10-30 00:28:55,153 Epoch: [35/484] Iter:[240/495], Time: 0.38, lr: [0.009337671285905041], Loss: 2.198852, Acc:0.787776, Semantic loss: 0.845185, BCE loss: 0.556244, SB loss: 0.797422
2023-10-30 00:28:58,821 Epoch: [35/484] Iter:[250/495], Time: 0.38, lr: [0.009337292756387484], Loss: 2.196559, Acc:0.787910, Semantic loss: 0.844538, BCE loss: 0.556021, SB loss: 0.795999
2023-10-30 00:29:02,724 Epoch: [35/484] Iter:[260/495], Time: 0.38, lr: [0.009336914225164873], Loss: 2.193870, Acc:0.788864, Semantic loss: 0.841441, BCE loss: 0.557804, SB loss: 0.794624
2023-10-30 00:29:06,627 Epoch: [35/484] Iter:[270/495], Time: 0.38, lr: [0.009336535692237123], Loss: 2.202268, Acc:0.788600, Semantic loss: 0.846989, BCE loss: 0.558290, SB loss: 0.796988
2023-10-30 00:29:10,399 Epoch: [35/484] Iter:[280/495], Time: 0.38, lr: [0.009336157157604151], Loss: 2.198040, Acc:0.788637, Semantic loss: 0.843650, BCE loss: 0.559138, SB loss: 0.795252
2023-10-30 00:29:14,268 Epoch: [35/484] Iter:[290/495], Time: 0.38, lr: [0.009335778621265873], Loss: 2.195295, Acc:0.789442, Semantic loss: 0.842925, BCE loss: 0.558955, SB loss: 0.793415
2023-10-30 00:29:18,097 Epoch: [35/484] Iter:[300/495], Time: 0.38, lr: [0.009335400083222204], Loss: 2.199005, Acc:0.788531, Semantic loss: 0.844372, BCE loss: 0.561035, SB loss: 0.793598
2023-10-30 00:29:21,824 Epoch: [35/484] Iter:[310/495], Time: 0.38, lr: [0.009335021543473059], Loss: 2.201649, Acc:0.789173, Semantic loss: 0.845014, BCE loss: 0.562978, SB loss: 0.793658
2023-10-30 00:29:25,542 Epoch: [35/484] Iter:[320/495], Time: 0.38, lr: [0.009334643002018353], Loss: 2.204504, Acc:0.788933, Semantic loss: 0.844744, BCE loss: 0.566169, SB loss: 0.793591
2023-10-30 00:29:29,302 Epoch: [35/484] Iter:[330/495], Time: 0.38, lr: [0.009334264458858002], Loss: 2.202970, Acc:0.788464, Semantic loss: 0.844340, BCE loss: 0.565631, SB loss: 0.792999
2023-10-30 00:29:33,171 Epoch: [35/484] Iter:[340/495], Time: 0.38, lr: [0.009333885913991922], Loss: 2.200657, Acc:0.789405, Semantic loss: 0.841731, BCE loss: 0.565734, SB loss: 0.793191
2023-10-30 00:29:36,919 Epoch: [35/484] Iter:[350/495], Time: 0.38, lr: [0.009333507367420028], Loss: 2.194593, Acc:0.790129, Semantic loss: 0.838383, BCE loss: 0.564325, SB loss: 0.791886
2023-10-30 00:29:40,653 Epoch: [35/484] Iter:[360/495], Time: 0.38, lr: [0.009333128819142235], Loss: 2.192389, Acc:0.790078, Semantic loss: 0.837365, BCE loss: 0.562722, SB loss: 0.792302
2023-10-30 00:29:44,497 Epoch: [35/484] Iter:[370/495], Time: 0.38, lr: [0.009332750269158458], Loss: 2.191504, Acc:0.790039, Semantic loss: 0.836824, BCE loss: 0.562717, SB loss: 0.791963
2023-10-30 00:29:48,235 Epoch: [35/484] Iter:[380/495], Time: 0.38, lr: [0.009332371717468615], Loss: 2.190165, Acc:0.790909, Semantic loss: 0.835915, BCE loss: 0.562916, SB loss: 0.791334
2023-10-30 00:29:51,986 Epoch: [35/484] Iter:[390/495], Time: 0.38, lr: [0.009331993164072619], Loss: 2.194167, Acc:0.790886, Semantic loss: 0.839012, BCE loss: 0.562325, SB loss: 0.792830
2023-10-30 00:29:55,729 Epoch: [35/484] Iter:[400/495], Time: 0.38, lr: [0.009331614608970386], Loss: 2.189661, Acc:0.791111, Semantic loss: 0.836320, BCE loss: 0.560754, SB loss: 0.792587
2023-10-30 00:29:59,415 Epoch: [35/484] Iter:[410/495], Time: 0.38, lr: [0.009331236052161832], Loss: 2.189309, Acc:0.791476, Semantic loss: 0.835185, BCE loss: 0.562136, SB loss: 0.791988
2023-10-30 00:30:03,190 Epoch: [35/484] Iter:[420/495], Time: 0.38, lr: [0.009330857493646871], Loss: 2.188282, Acc:0.792110, Semantic loss: 0.834252, BCE loss: 0.562508, SB loss: 0.791522
2023-10-30 00:30:06,934 Epoch: [35/484] Iter:[430/495], Time: 0.38, lr: [0.00933047893342542], Loss: 2.186329, Acc:0.791890, Semantic loss: 0.833419, BCE loss: 0.561315, SB loss: 0.791595
2023-10-30 00:30:10,662 Epoch: [35/484] Iter:[440/495], Time: 0.38, lr: [0.009330100371497393], Loss: 2.185802, Acc:0.791943, Semantic loss: 0.832506, BCE loss: 0.561968, SB loss: 0.791328
2023-10-30 00:30:14,403 Epoch: [35/484] Iter:[450/495], Time: 0.38, lr: [0.009329721807862708], Loss: 2.183555, Acc:0.791629, Semantic loss: 0.831494, BCE loss: 0.561353, SB loss: 0.790708
2023-10-30 00:30:18,161 Epoch: [35/484] Iter:[460/495], Time: 0.38, lr: [0.009329343242521276], Loss: 2.184149, Acc:0.791851, Semantic loss: 0.833117, BCE loss: 0.561050, SB loss: 0.789982
2023-10-30 00:30:21,884 Epoch: [35/484] Iter:[470/495], Time: 0.38, lr: [0.009328964675473015], Loss: 2.187760, Acc:0.791837, Semantic loss: 0.833602, BCE loss: 0.563249, SB loss: 0.790909
2023-10-30 00:30:25,604 Epoch: [35/484] Iter:[480/495], Time: 0.38, lr: [0.009328586106717841], Loss: 2.187729, Acc:0.792462, Semantic loss: 0.832031, BCE loss: 0.564652, SB loss: 0.791046
2023-10-30 00:30:29,215 Epoch: [35/484] Iter:[490/495], Time: 0.38, lr: [0.009328207536255668], Loss: 2.190191, Acc:0.791715, Semantic loss: 0.835413, BCE loss: 0.564518, SB loss: 0.790259
2023-10-30 00:33:27,013 0 [8.94129733e-01 4.69937437e-01 7.29610245e-01 7.00909230e-02
 1.75145719e-01 3.42992194e-01 3.69336949e-01 4.93764617e-01
 8.67721067e-01 3.36405813e-01 8.17741388e-01 4.51443572e-01
 1.72548815e-03 7.13253595e-01 1.33017417e-04 1.38762145e-02
 2.55723964e-03 1.77976400e-02 5.01921148e-01] 0.38260968421335434
2023-10-30 00:33:27,014 1 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361] 0.5433203440305946
2023-10-30 00:33:27,017 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:33:27,270 Loss: 2.464, MeanIU:  0.5433, Best_mIoU:  0.6427
2023-10-30 00:33:27,270 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361]
2023-10-30 00:33:29,328 Epoch: [36/484] Iter:[0/495], Time: 2.02, lr: [0.00932801825038443], Loss: 2.823695, Acc:0.684714, Semantic loss: 1.134685, BCE loss: 0.491199, SB loss: 1.197811
2023-10-30 00:33:33,237 Epoch: [36/484] Iter:[10/495], Time: 0.54, lr: [0.009327639677361603], Loss: 2.489540, Acc:0.756081, Semantic loss: 1.024378, BCE loss: 0.544914, SB loss: 0.920249
2023-10-30 00:33:36,977 Epoch: [36/484] Iter:[20/495], Time: 0.46, lr: [0.009327261102631561], Loss: 2.375820, Acc:0.769304, Semantic loss: 0.923547, BCE loss: 0.583406, SB loss: 0.868867
2023-10-30 00:33:40,521 Epoch: [36/484] Iter:[30/495], Time: 0.43, lr: [0.009326882526194227], Loss: 2.412617, Acc:0.771780, Semantic loss: 0.963551, BCE loss: 0.594222, SB loss: 0.854844
2023-10-30 00:33:44,137 Epoch: [36/484] Iter:[40/495], Time: 0.41, lr: [0.009326503948049512], Loss: 2.373914, Acc:0.778083, Semantic loss: 0.936859, BCE loss: 0.589338, SB loss: 0.847717
2023-10-30 00:33:47,830 Epoch: [36/484] Iter:[50/495], Time: 0.40, lr: [0.009326125368197333], Loss: 2.336313, Acc:0.782248, Semantic loss: 0.906298, BCE loss: 0.591432, SB loss: 0.838583
2023-10-30 00:33:51,394 Epoch: [36/484] Iter:[60/495], Time: 0.39, lr: [0.009325746786637605], Loss: 2.321223, Acc:0.780118, Semantic loss: 0.897444, BCE loss: 0.591124, SB loss: 0.832654
2023-10-30 00:33:55,055 Epoch: [36/484] Iter:[70/495], Time: 0.39, lr: [0.009325368203370245], Loss: 2.306982, Acc:0.775409, Semantic loss: 0.887466, BCE loss: 0.589259, SB loss: 0.830256
2023-10-30 00:33:58,659 Epoch: [36/484] Iter:[80/495], Time: 0.39, lr: [0.009324989618395164], Loss: 2.292347, Acc:0.776745, Semantic loss: 0.876881, BCE loss: 0.587926, SB loss: 0.827540
2023-10-30 00:34:02,305 Epoch: [36/484] Iter:[90/495], Time: 0.38, lr: [0.00932461103171228], Loss: 2.265514, Acc:0.780189, Semantic loss: 0.863626, BCE loss: 0.581435, SB loss: 0.820453
2023-10-30 00:34:05,951 Epoch: [36/484] Iter:[100/495], Time: 0.38, lr: [0.009324232443321508], Loss: 2.252949, Acc:0.781636, Semantic loss: 0.855409, BCE loss: 0.582499, SB loss: 0.815041
2023-10-30 00:34:09,692 Epoch: [36/484] Iter:[110/495], Time: 0.38, lr: [0.009323853853222765], Loss: 2.243663, Acc:0.781201, Semantic loss: 0.850998, BCE loss: 0.581187, SB loss: 0.811479
2023-10-30 00:34:13,390 Epoch: [36/484] Iter:[120/495], Time: 0.38, lr: [0.009323475261415963], Loss: 2.239501, Acc:0.780969, Semantic loss: 0.848168, BCE loss: 0.579066, SB loss: 0.812267
2023-10-30 00:34:16,962 Epoch: [36/484] Iter:[130/495], Time: 0.38, lr: [0.009323096667901019], Loss: 2.224161, Acc:0.779837, Semantic loss: 0.842195, BCE loss: 0.572596, SB loss: 0.809369
2023-10-30 00:34:20,669 Epoch: [36/484] Iter:[140/495], Time: 0.38, lr: [0.009322718072677849], Loss: 2.227452, Acc:0.783403, Semantic loss: 0.844166, BCE loss: 0.574599, SB loss: 0.808687
2023-10-30 00:34:24,552 Epoch: [36/484] Iter:[150/495], Time: 0.38, lr: [0.009322339475746365], Loss: 2.229041, Acc:0.783360, Semantic loss: 0.842636, BCE loss: 0.578373, SB loss: 0.808032
2023-10-30 00:34:28,231 Epoch: [36/484] Iter:[160/495], Time: 0.38, lr: [0.009321960877106485], Loss: 2.233367, Acc:0.785185, Semantic loss: 0.845966, BCE loss: 0.579290, SB loss: 0.808111
2023-10-30 00:34:31,921 Epoch: [36/484] Iter:[170/495], Time: 0.38, lr: [0.009321582276758125], Loss: 2.235797, Acc:0.785444, Semantic loss: 0.845809, BCE loss: 0.581656, SB loss: 0.808332
2023-10-30 00:34:35,611 Epoch: [36/484] Iter:[180/495], Time: 0.38, lr: [0.009321203674701196], Loss: 2.222471, Acc:0.787575, Semantic loss: 0.839909, BCE loss: 0.577512, SB loss: 0.805050
2023-10-30 00:34:39,370 Epoch: [36/484] Iter:[190/495], Time: 0.38, lr: [0.009320825070935618], Loss: 2.217064, Acc:0.788190, Semantic loss: 0.837195, BCE loss: 0.577434, SB loss: 0.802436
2023-10-30 00:34:43,066 Epoch: [36/484] Iter:[200/495], Time: 0.38, lr: [0.009320446465461305], Loss: 2.215771, Acc:0.789432, Semantic loss: 0.836442, BCE loss: 0.578858, SB loss: 0.800471
2023-10-30 00:34:46,768 Epoch: [36/484] Iter:[210/495], Time: 0.38, lr: [0.009320067858278167], Loss: 2.208344, Acc:0.789667, Semantic loss: 0.831860, BCE loss: 0.578139, SB loss: 0.798345
2023-10-30 00:34:50,544 Epoch: [36/484] Iter:[220/495], Time: 0.38, lr: [0.009319689249386127], Loss: 2.220656, Acc:0.788980, Semantic loss: 0.839024, BCE loss: 0.579868, SB loss: 0.801764
2023-10-30 00:34:54,323 Epoch: [36/484] Iter:[230/495], Time: 0.38, lr: [0.009319310638785095], Loss: 2.221037, Acc:0.789418, Semantic loss: 0.837475, BCE loss: 0.581646, SB loss: 0.801916
2023-10-30 00:34:58,001 Epoch: [36/484] Iter:[240/495], Time: 0.38, lr: [0.009318932026474989], Loss: 2.222509, Acc:0.789122, Semantic loss: 0.839218, BCE loss: 0.579332, SB loss: 0.803959
2023-10-30 00:35:01,717 Epoch: [36/484] Iter:[250/495], Time: 0.38, lr: [0.009318553412455723], Loss: 2.228749, Acc:0.789515, Semantic loss: 0.842043, BCE loss: 0.582170, SB loss: 0.804536
2023-10-30 00:35:05,527 Epoch: [36/484] Iter:[260/495], Time: 0.38, lr: [0.00931817479672721], Loss: 2.231206, Acc:0.790454, Semantic loss: 0.843481, BCE loss: 0.583062, SB loss: 0.804662
2023-10-30 00:35:09,383 Epoch: [36/484] Iter:[270/495], Time: 0.38, lr: [0.009317796179289368], Loss: 2.228962, Acc:0.790249, Semantic loss: 0.841391, BCE loss: 0.584595, SB loss: 0.802976
2023-10-30 00:35:13,167 Epoch: [36/484] Iter:[280/495], Time: 0.38, lr: [0.009317417560142111], Loss: 2.236134, Acc:0.791023, Semantic loss: 0.845633, BCE loss: 0.585825, SB loss: 0.804676
2023-10-30 00:35:16,892 Epoch: [36/484] Iter:[290/495], Time: 0.38, lr: [0.009317038939285356], Loss: 2.231520, Acc:0.791437, Semantic loss: 0.843082, BCE loss: 0.584401, SB loss: 0.804037
2023-10-30 00:35:20,537 Epoch: [36/484] Iter:[300/495], Time: 0.38, lr: [0.009316660316719015], Loss: 2.225477, Acc:0.791640, Semantic loss: 0.840275, BCE loss: 0.582161, SB loss: 0.803041
2023-10-30 00:35:24,253 Epoch: [36/484] Iter:[310/495], Time: 0.38, lr: [0.009316281692443003], Loss: 2.221131, Acc:0.791248, Semantic loss: 0.839532, BCE loss: 0.579327, SB loss: 0.802272
2023-10-30 00:35:28,012 Epoch: [36/484] Iter:[320/495], Time: 0.38, lr: [0.00931590306645724], Loss: 2.215851, Acc:0.792148, Semantic loss: 0.837171, BCE loss: 0.578086, SB loss: 0.800594
2023-10-30 00:35:31,816 Epoch: [36/484] Iter:[330/495], Time: 0.38, lr: [0.009315524438761633], Loss: 2.215534, Acc:0.792453, Semantic loss: 0.836078, BCE loss: 0.579006, SB loss: 0.800450
2023-10-30 00:35:35,649 Epoch: [36/484] Iter:[340/495], Time: 0.38, lr: [0.009315145809356105], Loss: 2.211506, Acc:0.793097, Semantic loss: 0.833602, BCE loss: 0.578498, SB loss: 0.799406
2023-10-30 00:35:39,355 Epoch: [36/484] Iter:[350/495], Time: 0.38, lr: [0.009314767178240568], Loss: 2.211733, Acc:0.792987, Semantic loss: 0.833536, BCE loss: 0.578324, SB loss: 0.799873
2023-10-30 00:35:43,041 Epoch: [36/484] Iter:[360/495], Time: 0.38, lr: [0.009314388545414935], Loss: 2.206853, Acc:0.792625, Semantic loss: 0.830733, BCE loss: 0.577547, SB loss: 0.798573
2023-10-30 00:35:46,763 Epoch: [36/484] Iter:[370/495], Time: 0.38, lr: [0.009314009910879122], Loss: 2.203151, Acc:0.792687, Semantic loss: 0.829588, BCE loss: 0.576076, SB loss: 0.797487
2023-10-30 00:35:50,542 Epoch: [36/484] Iter:[380/495], Time: 0.38, lr: [0.009313631274633047], Loss: 2.209232, Acc:0.792750, Semantic loss: 0.832452, BCE loss: 0.578715, SB loss: 0.798065
2023-10-30 00:35:54,359 Epoch: [36/484] Iter:[390/495], Time: 0.38, lr: [0.009313252636676622], Loss: 2.211554, Acc:0.791853, Semantic loss: 0.833901, BCE loss: 0.579090, SB loss: 0.798563
2023-10-30 00:35:58,155 Epoch: [36/484] Iter:[400/495], Time: 0.38, lr: [0.009312873997009764], Loss: 2.210835, Acc:0.792371, Semantic loss: 0.832656, BCE loss: 0.579047, SB loss: 0.799132
2023-10-30 00:36:01,948 Epoch: [36/484] Iter:[410/495], Time: 0.38, lr: [0.009312495355632385], Loss: 2.208157, Acc:0.792106, Semantic loss: 0.830845, BCE loss: 0.578929, SB loss: 0.798383
2023-10-30 00:36:05,704 Epoch: [36/484] Iter:[420/495], Time: 0.38, lr: [0.009312116712544402], Loss: 2.208366, Acc:0.791550, Semantic loss: 0.831510, BCE loss: 0.577912, SB loss: 0.798944
2023-10-30 00:36:09,456 Epoch: [36/484] Iter:[430/495], Time: 0.38, lr: [0.009311738067745729], Loss: 2.201699, Acc:0.791337, Semantic loss: 0.828272, BCE loss: 0.576151, SB loss: 0.797275
2023-10-30 00:36:13,201 Epoch: [36/484] Iter:[440/495], Time: 0.38, lr: [0.009311359421236284], Loss: 2.200447, Acc:0.791066, Semantic loss: 0.827452, BCE loss: 0.576353, SB loss: 0.796643
2023-10-30 00:36:16,889 Epoch: [36/484] Iter:[450/495], Time: 0.38, lr: [0.009310980773015978], Loss: 2.199952, Acc:0.791208, Semantic loss: 0.828101, BCE loss: 0.575341, SB loss: 0.796510
2023-10-30 00:36:20,808 Epoch: [36/484] Iter:[460/495], Time: 0.38, lr: [0.00931060212308473], Loss: 2.195783, Acc:0.791215, Semantic loss: 0.826313, BCE loss: 0.574422, SB loss: 0.795047
2023-10-30 00:36:24,655 Epoch: [36/484] Iter:[470/495], Time: 0.38, lr: [0.00931022347144245], Loss: 2.198882, Acc:0.791871, Semantic loss: 0.827945, BCE loss: 0.575757, SB loss: 0.795180
2023-10-30 00:36:28,380 Epoch: [36/484] Iter:[480/495], Time: 0.38, lr: [0.009309844818089058], Loss: 2.195583, Acc:0.791126, Semantic loss: 0.827133, BCE loss: 0.573894, SB loss: 0.794556
2023-10-30 00:36:31,996 Epoch: [36/484] Iter:[490/495], Time: 0.38, lr: [0.009309466163024464], Loss: 2.198000, Acc:0.791404, Semantic loss: 0.828544, BCE loss: 0.574075, SB loss: 0.795382
2023-10-30 00:36:33,413 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:36:33,659 Loss: 2.464, MeanIU:  0.5433, Best_mIoU:  0.6427
2023-10-30 00:36:33,659 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361]
2023-10-30 00:36:35,575 Epoch: [37/484] Iter:[0/495], Time: 1.88, lr: [0.009309276834850442], Loss: 2.212096, Acc:0.743941, Semantic loss: 0.791791, BCE loss: 0.705208, SB loss: 0.715096
2023-10-30 00:36:39,742 Epoch: [37/484] Iter:[10/495], Time: 0.55, lr: [0.00930889817721889], Loss: 2.031029, Acc:0.764707, Semantic loss: 0.729350, BCE loss: 0.561117, SB loss: 0.740561
2023-10-30 00:36:43,523 Epoch: [37/484] Iter:[20/495], Time: 0.47, lr: [0.009308519517875927], Loss: 2.137776, Acc:0.767657, Semantic loss: 0.788489, BCE loss: 0.581083, SB loss: 0.768203
2023-10-30 00:36:47,305 Epoch: [37/484] Iter:[30/495], Time: 0.44, lr: [0.009308140856821466], Loss: 2.132047, Acc:0.780401, Semantic loss: 0.781386, BCE loss: 0.574215, SB loss: 0.776445
2023-10-30 00:36:51,060 Epoch: [37/484] Iter:[40/495], Time: 0.42, lr: [0.009307762194055423], Loss: 2.173299, Acc:0.778832, Semantic loss: 0.812634, BCE loss: 0.576795, SB loss: 0.783870
2023-10-30 00:36:54,806 Epoch: [37/484] Iter:[50/495], Time: 0.41, lr: [0.009307383529577714], Loss: 2.201245, Acc:0.775961, Semantic loss: 0.831199, BCE loss: 0.571485, SB loss: 0.798561
2023-10-30 00:36:58,432 Epoch: [37/484] Iter:[60/495], Time: 0.41, lr: [0.009307004863388252], Loss: 2.210303, Acc:0.778718, Semantic loss: 0.832323, BCE loss: 0.575950, SB loss: 0.802029
2023-10-30 00:37:02,221 Epoch: [37/484] Iter:[70/495], Time: 0.40, lr: [0.00930662619548695], Loss: 2.198712, Acc:0.772696, Semantic loss: 0.832961, BCE loss: 0.566614, SB loss: 0.799136
2023-10-30 00:37:05,922 Epoch: [37/484] Iter:[80/495], Time: 0.40, lr: [0.009306247525873728], Loss: 2.248072, Acc:0.768460, Semantic loss: 0.871512, BCE loss: 0.566786, SB loss: 0.809774
2023-10-30 00:37:09,801 Epoch: [37/484] Iter:[90/495], Time: 0.40, lr: [0.009305868854548496], Loss: 2.224413, Acc:0.772078, Semantic loss: 0.857144, BCE loss: 0.565414, SB loss: 0.801854
2023-10-30 00:37:13,622 Epoch: [37/484] Iter:[100/495], Time: 0.40, lr: [0.009305490181511172], Loss: 2.227286, Acc:0.771233, Semantic loss: 0.865332, BCE loss: 0.562076, SB loss: 0.799879
2023-10-30 00:37:17,399 Epoch: [37/484] Iter:[110/495], Time: 0.39, lr: [0.00930511150676167], Loss: 2.221700, Acc:0.768952, Semantic loss: 0.860759, BCE loss: 0.560108, SB loss: 0.800833
2023-10-30 00:37:21,274 Epoch: [37/484] Iter:[120/495], Time: 0.39, lr: [0.009304732830299905], Loss: 2.225362, Acc:0.770632, Semantic loss: 0.862383, BCE loss: 0.566259, SB loss: 0.796721
2023-10-30 00:37:25,013 Epoch: [37/484] Iter:[130/495], Time: 0.39, lr: [0.00930435415212579], Loss: 2.232290, Acc:0.772762, Semantic loss: 0.864599, BCE loss: 0.571398, SB loss: 0.796293
2023-10-30 00:37:28,795 Epoch: [37/484] Iter:[140/495], Time: 0.39, lr: [0.009303975472239242], Loss: 2.232527, Acc:0.771834, Semantic loss: 0.865542, BCE loss: 0.567104, SB loss: 0.799881
2023-10-30 00:37:32,650 Epoch: [37/484] Iter:[150/495], Time: 0.39, lr: [0.009303596790640176], Loss: 2.230786, Acc:0.772272, Semantic loss: 0.861122, BCE loss: 0.569207, SB loss: 0.800458
2023-10-30 00:37:36,375 Epoch: [37/484] Iter:[160/495], Time: 0.39, lr: [0.009303218107328504], Loss: 2.217506, Acc:0.775631, Semantic loss: 0.848661, BCE loss: 0.570193, SB loss: 0.798652
2023-10-30 00:37:40,244 Epoch: [37/484] Iter:[170/495], Time: 0.39, lr: [0.009302839422304145], Loss: 2.227047, Acc:0.778655, Semantic loss: 0.852636, BCE loss: 0.573622, SB loss: 0.800789
2023-10-30 00:37:43,953 Epoch: [37/484] Iter:[180/495], Time: 0.39, lr: [0.00930246073556701], Loss: 2.236281, Acc:0.778791, Semantic loss: 0.860300, BCE loss: 0.574065, SB loss: 0.801916
2023-10-30 00:37:47,758 Epoch: [37/484] Iter:[190/495], Time: 0.39, lr: [0.009302082047117015], Loss: 2.217468, Acc:0.776895, Semantic loss: 0.850902, BCE loss: 0.568646, SB loss: 0.797920
2023-10-30 00:37:51,520 Epoch: [37/484] Iter:[200/495], Time: 0.39, lr: [0.009301703356954075], Loss: 2.225037, Acc:0.777840, Semantic loss: 0.855547, BCE loss: 0.570572, SB loss: 0.798918
2023-10-30 00:37:55,182 Epoch: [37/484] Iter:[210/495], Time: 0.39, lr: [0.009301324665078105], Loss: 2.221003, Acc:0.778122, Semantic loss: 0.852997, BCE loss: 0.568481, SB loss: 0.799525
2023-10-30 00:37:58,900 Epoch: [37/484] Iter:[220/495], Time: 0.39, lr: [0.009300945971489021], Loss: 2.218262, Acc:0.778764, Semantic loss: 0.849584, BCE loss: 0.569424, SB loss: 0.799254
2023-10-30 00:38:02,628 Epoch: [37/484] Iter:[230/495], Time: 0.38, lr: [0.009300567276186734], Loss: 2.211760, Acc:0.779126, Semantic loss: 0.846141, BCE loss: 0.568903, SB loss: 0.796716
2023-10-30 00:38:06,433 Epoch: [37/484] Iter:[240/495], Time: 0.38, lr: [0.009300188579171163], Loss: 2.210970, Acc:0.779591, Semantic loss: 0.845263, BCE loss: 0.568895, SB loss: 0.796812
2023-10-30 00:38:10,143 Epoch: [37/484] Iter:[250/495], Time: 0.38, lr: [0.00929980988044222], Loss: 2.205648, Acc:0.780202, Semantic loss: 0.842595, BCE loss: 0.567340, SB loss: 0.795712
2023-10-30 00:38:13,936 Epoch: [37/484] Iter:[260/495], Time: 0.38, lr: [0.009299431179999821], Loss: 2.202820, Acc:0.781154, Semantic loss: 0.841621, BCE loss: 0.566444, SB loss: 0.794754
2023-10-30 00:38:17,675 Epoch: [37/484] Iter:[270/495], Time: 0.38, lr: [0.00929905247784388], Loss: 2.200368, Acc:0.781420, Semantic loss: 0.841148, BCE loss: 0.565991, SB loss: 0.793229
2023-10-30 00:38:21,596 Epoch: [37/484] Iter:[280/495], Time: 0.38, lr: [0.00929867377397431], Loss: 2.200483, Acc:0.782127, Semantic loss: 0.840664, BCE loss: 0.565463, SB loss: 0.794356
2023-10-30 00:38:25,395 Epoch: [37/484] Iter:[290/495], Time: 0.38, lr: [0.00929829506839103], Loss: 2.197720, Acc:0.781893, Semantic loss: 0.839963, BCE loss: 0.564846, SB loss: 0.792911
2023-10-30 00:38:29,202 Epoch: [37/484] Iter:[300/495], Time: 0.38, lr: [0.009297916361093951], Loss: 2.195510, Acc:0.782033, Semantic loss: 0.838683, BCE loss: 0.563489, SB loss: 0.793339
2023-10-30 00:38:32,922 Epoch: [37/484] Iter:[310/495], Time: 0.38, lr: [0.00929753765208299], Loss: 2.202352, Acc:0.782096, Semantic loss: 0.842104, BCE loss: 0.565213, SB loss: 0.795035
2023-10-30 00:38:36,689 Epoch: [37/484] Iter:[320/495], Time: 0.38, lr: [0.00929715894135806], Loss: 2.198575, Acc:0.783584, Semantic loss: 0.839468, BCE loss: 0.565529, SB loss: 0.793577
2023-10-30 00:38:40,483 Epoch: [37/484] Iter:[330/495], Time: 0.38, lr: [0.00929678022891908], Loss: 2.200415, Acc:0.782560, Semantic loss: 0.841546, BCE loss: 0.564169, SB loss: 0.794700
2023-10-30 00:38:44,266 Epoch: [37/484] Iter:[340/495], Time: 0.38, lr: [0.009296401514765957], Loss: 2.194297, Acc:0.782831, Semantic loss: 0.837920, BCE loss: 0.562734, SB loss: 0.793644
2023-10-30 00:38:47,967 Epoch: [37/484] Iter:[350/495], Time: 0.38, lr: [0.00929602279889861], Loss: 2.192855, Acc:0.782906, Semantic loss: 0.836338, BCE loss: 0.563571, SB loss: 0.792946
2023-10-30 00:38:51,721 Epoch: [37/484] Iter:[360/495], Time: 0.38, lr: [0.009295644081316954], Loss: 2.192932, Acc:0.781911, Semantic loss: 0.837232, BCE loss: 0.562916, SB loss: 0.792784
2023-10-30 00:38:55,508 Epoch: [37/484] Iter:[370/495], Time: 0.38, lr: [0.009295265362020902], Loss: 2.193473, Acc:0.782724, Semantic loss: 0.836084, BCE loss: 0.564452, SB loss: 0.792936
2023-10-30 00:38:59,268 Epoch: [37/484] Iter:[380/495], Time: 0.38, lr: [0.00929488664101037], Loss: 2.189338, Acc:0.782163, Semantic loss: 0.833393, BCE loss: 0.565172, SB loss: 0.790773
2023-10-30 00:39:03,010 Epoch: [37/484] Iter:[390/495], Time: 0.38, lr: [0.009294507918285273], Loss: 2.186938, Acc:0.781846, Semantic loss: 0.831805, BCE loss: 0.564838, SB loss: 0.790295
2023-10-30 00:39:06,835 Epoch: [37/484] Iter:[400/495], Time: 0.38, lr: [0.009294129193845523], Loss: 2.186360, Acc:0.781915, Semantic loss: 0.831829, BCE loss: 0.564154, SB loss: 0.790376
2023-10-30 00:39:10,594 Epoch: [37/484] Iter:[410/495], Time: 0.38, lr: [0.009293750467691039], Loss: 2.187542, Acc:0.781420, Semantic loss: 0.833108, BCE loss: 0.563622, SB loss: 0.790811
2023-10-30 00:39:14,301 Epoch: [37/484] Iter:[420/495], Time: 0.38, lr: [0.00929337173982173], Loss: 2.190455, Acc:0.781845, Semantic loss: 0.833829, BCE loss: 0.564617, SB loss: 0.792009
2023-10-30 00:39:18,093 Epoch: [37/484] Iter:[430/495], Time: 0.38, lr: [0.009292993010237517], Loss: 2.194971, Acc:0.782409, Semantic loss: 0.836472, BCE loss: 0.565791, SB loss: 0.792708
2023-10-30 00:39:21,856 Epoch: [37/484] Iter:[440/495], Time: 0.38, lr: [0.009292614278938308], Loss: 2.193869, Acc:0.782651, Semantic loss: 0.836109, BCE loss: 0.565421, SB loss: 0.792339
2023-10-30 00:39:25,580 Epoch: [37/484] Iter:[450/495], Time: 0.38, lr: [0.009292235545924022], Loss: 2.193583, Acc:0.782100, Semantic loss: 0.835836, BCE loss: 0.565000, SB loss: 0.792747
2023-10-30 00:39:29,261 Epoch: [37/484] Iter:[460/495], Time: 0.38, lr: [0.009291856811194573], Loss: 2.196283, Acc:0.781522, Semantic loss: 0.838336, BCE loss: 0.564571, SB loss: 0.793376
2023-10-30 00:39:33,010 Epoch: [37/484] Iter:[470/495], Time: 0.38, lr: [0.009291478074749874], Loss: 2.193171, Acc:0.781950, Semantic loss: 0.835568, BCE loss: 0.565072, SB loss: 0.792531
2023-10-30 00:39:36,710 Epoch: [37/484] Iter:[480/495], Time: 0.38, lr: [0.009291099336589842], Loss: 2.190133, Acc:0.782132, Semantic loss: 0.833596, BCE loss: 0.564122, SB loss: 0.792415
2023-10-30 00:39:40,243 Epoch: [37/484] Iter:[490/495], Time: 0.38, lr: [0.009290720596714389], Loss: 2.191101, Acc:0.782802, Semantic loss: 0.834562, BCE loss: 0.563884, SB loss: 0.792655
2023-10-30 00:39:41,676 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:39:41,915 Loss: 2.464, MeanIU:  0.5433, Best_mIoU:  0.6427
2023-10-30 00:39:41,916 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361]
2023-10-30 00:39:44,116 Epoch: [38/484] Iter:[0/495], Time: 2.16, lr: [0.009290531226133351], Loss: 1.855115, Acc:0.855888, Semantic loss: 0.665206, BCE loss: 0.456958, SB loss: 0.732951
2023-10-30 00:39:48,229 Epoch: [38/484] Iter:[10/495], Time: 0.57, lr: [0.009290152483684607], Loss: 1.981951, Acc:0.784867, Semantic loss: 0.724449, BCE loss: 0.494438, SB loss: 0.763064
2023-10-30 00:39:51,932 Epoch: [38/484] Iter:[20/495], Time: 0.48, lr: [0.009289773739520231], Loss: 2.073836, Acc:0.797297, Semantic loss: 0.791077, BCE loss: 0.520547, SB loss: 0.762212
2023-10-30 00:39:55,729 Epoch: [38/484] Iter:[30/495], Time: 0.44, lr: [0.009289394993640135], Loss: 2.138263, Acc:0.795039, Semantic loss: 0.826368, BCE loss: 0.540693, SB loss: 0.771202
2023-10-30 00:39:59,509 Epoch: [38/484] Iter:[40/495], Time: 0.43, lr: [0.009289016246044232], Loss: 2.125573, Acc:0.785481, Semantic loss: 0.816220, BCE loss: 0.534519, SB loss: 0.774834
2023-10-30 00:40:03,278 Epoch: [38/484] Iter:[50/495], Time: 0.42, lr: [0.00928863749673244], Loss: 2.118974, Acc:0.789177, Semantic loss: 0.799828, BCE loss: 0.543134, SB loss: 0.776012
2023-10-30 00:40:07,152 Epoch: [38/484] Iter:[60/495], Time: 0.41, lr: [0.009288258745704674], Loss: 2.100807, Acc:0.792015, Semantic loss: 0.782853, BCE loss: 0.547118, SB loss: 0.770835
2023-10-30 00:40:11,018 Epoch: [38/484] Iter:[70/495], Time: 0.41, lr: [0.009287879992960844], Loss: 2.128754, Acc:0.791625, Semantic loss: 0.798361, BCE loss: 0.549742, SB loss: 0.780651
2023-10-30 00:40:14,760 Epoch: [38/484] Iter:[80/495], Time: 0.41, lr: [0.00928750123850087], Loss: 2.135283, Acc:0.791725, Semantic loss: 0.794845, BCE loss: 0.555865, SB loss: 0.784573
2023-10-30 00:40:18,499 Epoch: [38/484] Iter:[90/495], Time: 0.40, lr: [0.009287122482324661], Loss: 2.130738, Acc:0.793009, Semantic loss: 0.794896, BCE loss: 0.551714, SB loss: 0.784129
2023-10-30 00:40:22,244 Epoch: [38/484] Iter:[100/495], Time: 0.40, lr: [0.009286743724432136], Loss: 2.146726, Acc:0.795164, Semantic loss: 0.806944, BCE loss: 0.553910, SB loss: 0.785872
2023-10-30 00:40:26,137 Epoch: [38/484] Iter:[110/495], Time: 0.40, lr: [0.009286364964823208], Loss: 2.145506, Acc:0.795407, Semantic loss: 0.805428, BCE loss: 0.553660, SB loss: 0.786417
2023-10-30 00:40:29,845 Epoch: [38/484] Iter:[120/495], Time: 0.40, lr: [0.00928598620349779], Loss: 2.150185, Acc:0.796889, Semantic loss: 0.806054, BCE loss: 0.559472, SB loss: 0.784659
2023-10-30 00:40:33,636 Epoch: [38/484] Iter:[130/495], Time: 0.39, lr: [0.009285607440455796], Loss: 2.139026, Acc:0.796313, Semantic loss: 0.799682, BCE loss: 0.558889, SB loss: 0.780455
2023-10-30 00:40:37,347 Epoch: [38/484] Iter:[140/495], Time: 0.39, lr: [0.009285228675697142], Loss: 2.148589, Acc:0.795938, Semantic loss: 0.803380, BCE loss: 0.563117, SB loss: 0.782092
2023-10-30 00:40:41,184 Epoch: [38/484] Iter:[150/495], Time: 0.39, lr: [0.009284849909221744], Loss: 2.146106, Acc:0.795437, Semantic loss: 0.802559, BCE loss: 0.561194, SB loss: 0.782354
2023-10-30 00:40:44,927 Epoch: [38/484] Iter:[160/495], Time: 0.39, lr: [0.009284471141029515], Loss: 2.141894, Acc:0.796146, Semantic loss: 0.801770, BCE loss: 0.559300, SB loss: 0.780824
2023-10-30 00:40:48,828 Epoch: [38/484] Iter:[170/495], Time: 0.39, lr: [0.009284092371120366], Loss: 2.144533, Acc:0.797822, Semantic loss: 0.802391, BCE loss: 0.562089, SB loss: 0.780053
2023-10-30 00:40:52,611 Epoch: [38/484] Iter:[180/495], Time: 0.39, lr: [0.009283713599494217], Loss: 2.147341, Acc:0.797866, Semantic loss: 0.805350, BCE loss: 0.560288, SB loss: 0.781703
2023-10-30 00:40:56,370 Epoch: [38/484] Iter:[190/495], Time: 0.39, lr: [0.00928333482615098], Loss: 2.140508, Acc:0.797032, Semantic loss: 0.802619, BCE loss: 0.558682, SB loss: 0.779206
2023-10-30 00:41:00,161 Epoch: [38/484] Iter:[200/495], Time: 0.39, lr: [0.009282956051090568], Loss: 2.146847, Acc:0.796045, Semantic loss: 0.808835, BCE loss: 0.557414, SB loss: 0.780598
2023-10-30 00:41:03,870 Epoch: [38/484] Iter:[210/495], Time: 0.39, lr: [0.009282577274312896], Loss: 2.146360, Acc:0.796303, Semantic loss: 0.810261, BCE loss: 0.555160, SB loss: 0.780939
2023-10-30 00:41:07,691 Epoch: [38/484] Iter:[220/495], Time: 0.39, lr: [0.00928219849581788], Loss: 2.145082, Acc:0.796615, Semantic loss: 0.809513, BCE loss: 0.554193, SB loss: 0.781376
2023-10-30 00:41:11,493 Epoch: [38/484] Iter:[230/495], Time: 0.39, lr: [0.009281819715605433], Loss: 2.159459, Acc:0.797544, Semantic loss: 0.817604, BCE loss: 0.557873, SB loss: 0.783982
2023-10-30 00:41:15,265 Epoch: [38/484] Iter:[240/495], Time: 0.39, lr: [0.009281440933675469], Loss: 2.158052, Acc:0.796278, Semantic loss: 0.816412, BCE loss: 0.557774, SB loss: 0.783866
2023-10-30 00:41:19,061 Epoch: [38/484] Iter:[250/495], Time: 0.39, lr: [0.009281062150027903], Loss: 2.154456, Acc:0.794984, Semantic loss: 0.815004, BCE loss: 0.555832, SB loss: 0.783621
2023-10-30 00:41:22,972 Epoch: [38/484] Iter:[260/495], Time: 0.39, lr: [0.00928068336466265], Loss: 2.163085, Acc:0.794903, Semantic loss: 0.821021, BCE loss: 0.556687, SB loss: 0.785378
2023-10-30 00:41:26,704 Epoch: [38/484] Iter:[270/495], Time: 0.39, lr: [0.009280304577579624], Loss: 2.165005, Acc:0.794436, Semantic loss: 0.819739, BCE loss: 0.559215, SB loss: 0.786050
2023-10-30 00:41:30,449 Epoch: [38/484] Iter:[280/495], Time: 0.39, lr: [0.00927992578877874], Loss: 2.170937, Acc:0.794055, Semantic loss: 0.822899, BCE loss: 0.561702, SB loss: 0.786336
2023-10-30 00:41:34,197 Epoch: [38/484] Iter:[290/495], Time: 0.39, lr: [0.009279546998259907], Loss: 2.168816, Acc:0.793078, Semantic loss: 0.822672, BCE loss: 0.559676, SB loss: 0.786469
2023-10-30 00:41:38,014 Epoch: [38/484] Iter:[300/495], Time: 0.39, lr: [0.009279168206023047], Loss: 2.163508, Acc:0.792345, Semantic loss: 0.819181, BCE loss: 0.558456, SB loss: 0.785871
2023-10-30 00:41:41,753 Epoch: [38/484] Iter:[310/495], Time: 0.39, lr: [0.00927878941206807], Loss: 2.168080, Acc:0.791574, Semantic loss: 0.820980, BCE loss: 0.559914, SB loss: 0.787186
2023-10-30 00:41:45,683 Epoch: [38/484] Iter:[320/495], Time: 0.39, lr: [0.009278410616394889], Loss: 2.166244, Acc:0.790263, Semantic loss: 0.820699, BCE loss: 0.558952, SB loss: 0.786592
2023-10-30 00:41:49,514 Epoch: [38/484] Iter:[330/495], Time: 0.39, lr: [0.009278031819003421], Loss: 2.171055, Acc:0.790645, Semantic loss: 0.823431, BCE loss: 0.561234, SB loss: 0.786390
2023-10-30 00:41:53,367 Epoch: [38/484] Iter:[340/495], Time: 0.39, lr: [0.00927765301989358], Loss: 2.175643, Acc:0.790529, Semantic loss: 0.825738, BCE loss: 0.562029, SB loss: 0.787877
2023-10-30 00:41:57,208 Epoch: [38/484] Iter:[350/495], Time: 0.39, lr: [0.009277274219065282], Loss: 2.180550, Acc:0.790970, Semantic loss: 0.828164, BCE loss: 0.562265, SB loss: 0.790121
2023-10-30 00:42:01,015 Epoch: [38/484] Iter:[360/495], Time: 0.39, lr: [0.009276895416518436], Loss: 2.182303, Acc:0.790493, Semantic loss: 0.830650, BCE loss: 0.561586, SB loss: 0.790067
2023-10-30 00:42:04,704 Epoch: [38/484] Iter:[370/495], Time: 0.38, lr: [0.00927651661225296], Loss: 2.178498, Acc:0.790285, Semantic loss: 0.826790, BCE loss: 0.562597, SB loss: 0.789111
2023-10-30 00:42:08,398 Epoch: [38/484] Iter:[380/495], Time: 0.38, lr: [0.009276137806268767], Loss: 2.173778, Acc:0.790014, Semantic loss: 0.823920, BCE loss: 0.561910, SB loss: 0.787948
2023-10-30 00:42:12,209 Epoch: [38/484] Iter:[390/495], Time: 0.38, lr: [0.009275758998565774], Loss: 2.173261, Acc:0.789118, Semantic loss: 0.825559, BCE loss: 0.559861, SB loss: 0.787841
2023-10-30 00:42:15,978 Epoch: [38/484] Iter:[400/495], Time: 0.38, lr: [0.00927538018914389], Loss: 2.171284, Acc:0.788763, Semantic loss: 0.824947, BCE loss: 0.558785, SB loss: 0.787553
2023-10-30 00:42:19,716 Epoch: [38/484] Iter:[410/495], Time: 0.38, lr: [0.009275001378003033], Loss: 2.166827, Acc:0.789646, Semantic loss: 0.821440, BCE loss: 0.559366, SB loss: 0.786021
2023-10-30 00:42:23,495 Epoch: [38/484] Iter:[420/495], Time: 0.38, lr: [0.009274622565143118], Loss: 2.164778, Acc:0.790059, Semantic loss: 0.820444, BCE loss: 0.558505, SB loss: 0.785829
2023-10-30 00:42:27,383 Epoch: [38/484] Iter:[430/495], Time: 0.38, lr: [0.009274243750564055], Loss: 2.163225, Acc:0.789824, Semantic loss: 0.819693, BCE loss: 0.558008, SB loss: 0.785524
2023-10-30 00:42:31,324 Epoch: [38/484] Iter:[440/495], Time: 0.38, lr: [0.009273864934265762], Loss: 2.162015, Acc:0.789749, Semantic loss: 0.818953, BCE loss: 0.557480, SB loss: 0.785582
2023-10-30 00:42:35,234 Epoch: [38/484] Iter:[450/495], Time: 0.38, lr: [0.009273486116248151], Loss: 2.165222, Acc:0.789833, Semantic loss: 0.820412, BCE loss: 0.557841, SB loss: 0.786970
2023-10-30 00:42:38,991 Epoch: [38/484] Iter:[460/495], Time: 0.38, lr: [0.009273107296511138], Loss: 2.166883, Acc:0.789765, Semantic loss: 0.821815, BCE loss: 0.557261, SB loss: 0.787807
2023-10-30 00:42:42,760 Epoch: [38/484] Iter:[470/495], Time: 0.38, lr: [0.009272728475054635], Loss: 2.164439, Acc:0.788862, Semantic loss: 0.820804, BCE loss: 0.557043, SB loss: 0.786591
2023-10-30 00:42:46,531 Epoch: [38/484] Iter:[480/495], Time: 0.38, lr: [0.009272349651878557], Loss: 2.162163, Acc:0.788449, Semantic loss: 0.819854, BCE loss: 0.557208, SB loss: 0.785101
2023-10-30 00:42:50,061 Epoch: [38/484] Iter:[490/495], Time: 0.38, lr: [0.00927197082698282], Loss: 2.160673, Acc:0.788222, Semantic loss: 0.818479, BCE loss: 0.557140, SB loss: 0.785055
2023-10-30 00:42:51,494 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:42:51,738 Loss: 2.464, MeanIU:  0.5433, Best_mIoU:  0.6427
2023-10-30 00:42:51,738 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361]
2023-10-30 00:42:53,958 Epoch: [39/484] Iter:[0/495], Time: 2.18, lr: [0.009271781413890052], Loss: 2.484033, Acc:0.783156, Semantic loss: 0.868093, BCE loss: 0.815772, SB loss: 0.800168
2023-10-30 00:42:58,060 Epoch: [39/484] Iter:[10/495], Time: 0.57, lr: [0.009271402586414663], Loss: 2.248514, Acc:0.792425, Semantic loss: 0.838580, BCE loss: 0.625469, SB loss: 0.784465
2023-10-30 00:43:01,988 Epoch: [39/484] Iter:[20/495], Time: 0.49, lr: [0.009271023757219398], Loss: 2.275985, Acc:0.797473, Semantic loss: 0.810851, BCE loss: 0.672399, SB loss: 0.792735
2023-10-30 00:43:05,788 Epoch: [39/484] Iter:[30/495], Time: 0.45, lr: [0.00927064492630417], Loss: 2.246150, Acc:0.801341, Semantic loss: 0.810376, BCE loss: 0.645121, SB loss: 0.790654
2023-10-30 00:43:09,600 Epoch: [39/484] Iter:[40/495], Time: 0.43, lr: [0.009270266093668898], Loss: 2.204312, Acc:0.802999, Semantic loss: 0.792005, BCE loss: 0.626537, SB loss: 0.785770
2023-10-30 00:43:13,255 Epoch: [39/484] Iter:[50/495], Time: 0.42, lr: [0.009269887259313492], Loss: 2.223730, Acc:0.795511, Semantic loss: 0.811957, BCE loss: 0.623509, SB loss: 0.788264
2023-10-30 00:43:16,923 Epoch: [39/484] Iter:[60/495], Time: 0.41, lr: [0.009269508423237866], Loss: 2.185980, Acc:0.792032, Semantic loss: 0.797168, BCE loss: 0.609583, SB loss: 0.779229
2023-10-30 00:43:20,751 Epoch: [39/484] Iter:[70/495], Time: 0.41, lr: [0.009269129585441935], Loss: 2.168125, Acc:0.790537, Semantic loss: 0.799412, BCE loss: 0.594902, SB loss: 0.773811
2023-10-30 00:43:24,438 Epoch: [39/484] Iter:[80/495], Time: 0.40, lr: [0.009268750745925616], Loss: 2.164629, Acc:0.788389, Semantic loss: 0.798875, BCE loss: 0.589673, SB loss: 0.776080
2023-10-30 00:43:28,172 Epoch: [39/484] Iter:[90/495], Time: 0.40, lr: [0.009268371904688818], Loss: 2.155410, Acc:0.784185, Semantic loss: 0.800206, BCE loss: 0.577752, SB loss: 0.777452
2023-10-30 00:43:32,036 Epoch: [39/484] Iter:[100/495], Time: 0.40, lr: [0.009267993061731457], Loss: 2.152316, Acc:0.786171, Semantic loss: 0.797981, BCE loss: 0.582137, SB loss: 0.772198
2023-10-30 00:43:35,772 Epoch: [39/484] Iter:[110/495], Time: 0.40, lr: [0.009267614217053447], Loss: 2.155316, Acc:0.791100, Semantic loss: 0.798641, BCE loss: 0.582654, SB loss: 0.774021
2023-10-30 00:43:39,528 Epoch: [39/484] Iter:[120/495], Time: 0.39, lr: [0.009267235370654704], Loss: 2.170493, Acc:0.790434, Semantic loss: 0.809959, BCE loss: 0.583307, SB loss: 0.777228
2023-10-30 00:43:43,357 Epoch: [39/484] Iter:[130/495], Time: 0.39, lr: [0.00926685652253514], Loss: 2.174347, Acc:0.790847, Semantic loss: 0.811765, BCE loss: 0.584368, SB loss: 0.778214
2023-10-30 00:43:47,131 Epoch: [39/484] Iter:[140/495], Time: 0.39, lr: [0.00926647767269467], Loss: 2.177769, Acc:0.789688, Semantic loss: 0.813130, BCE loss: 0.584727, SB loss: 0.779912
2023-10-30 00:43:50,915 Epoch: [39/484] Iter:[150/495], Time: 0.39, lr: [0.009266098821133205], Loss: 2.180070, Acc:0.789416, Semantic loss: 0.813185, BCE loss: 0.585451, SB loss: 0.781434
2023-10-30 00:43:54,653 Epoch: [39/484] Iter:[160/495], Time: 0.39, lr: [0.009265719967850663], Loss: 2.185102, Acc:0.790870, Semantic loss: 0.812936, BCE loss: 0.588862, SB loss: 0.783304
2023-10-30 00:43:58,488 Epoch: [39/484] Iter:[170/495], Time: 0.39, lr: [0.009265341112846957], Loss: 2.192216, Acc:0.789636, Semantic loss: 0.819570, BCE loss: 0.588279, SB loss: 0.784367
2023-10-30 00:44:02,305 Epoch: [39/484] Iter:[180/495], Time: 0.39, lr: [0.009264962256122], Loss: 2.192938, Acc:0.791530, Semantic loss: 0.820415, BCE loss: 0.586346, SB loss: 0.786177
2023-10-30 00:44:06,094 Epoch: [39/484] Iter:[190/495], Time: 0.39, lr: [0.009264583397675705], Loss: 2.200188, Acc:0.791075, Semantic loss: 0.826014, BCE loss: 0.585151, SB loss: 0.789024
2023-10-30 00:44:09,857 Epoch: [39/484] Iter:[200/495], Time: 0.39, lr: [0.00926420453750799], Loss: 2.195522, Acc:0.790930, Semantic loss: 0.823858, BCE loss: 0.584965, SB loss: 0.786700
2023-10-30 00:44:13,576 Epoch: [39/484] Iter:[210/495], Time: 0.39, lr: [0.009263825675618764], Loss: 2.203832, Acc:0.790686, Semantic loss: 0.828587, BCE loss: 0.585357, SB loss: 0.789889
2023-10-30 00:44:17,465 Epoch: [39/484] Iter:[220/495], Time: 0.39, lr: [0.009263446812007943], Loss: 2.199219, Acc:0.790134, Semantic loss: 0.824674, BCE loss: 0.584776, SB loss: 0.789769
2023-10-30 00:44:21,221 Epoch: [39/484] Iter:[230/495], Time: 0.39, lr: [0.009263067946675443], Loss: 2.200901, Acc:0.790008, Semantic loss: 0.826502, BCE loss: 0.582534, SB loss: 0.791864
2023-10-30 00:44:24,994 Epoch: [39/484] Iter:[240/495], Time: 0.39, lr: [0.009262689079621175], Loss: 2.197698, Acc:0.790010, Semantic loss: 0.826154, BCE loss: 0.580460, SB loss: 0.791084
2023-10-30 00:44:28,742 Epoch: [39/484] Iter:[250/495], Time: 0.39, lr: [0.009262310210845056], Loss: 2.197503, Acc:0.789635, Semantic loss: 0.824700, BCE loss: 0.581555, SB loss: 0.791248
2023-10-30 00:44:32,529 Epoch: [39/484] Iter:[260/495], Time: 0.39, lr: [0.009261931340346995], Loss: 2.199962, Acc:0.788688, Semantic loss: 0.828783, BCE loss: 0.579821, SB loss: 0.791359
2023-10-30 00:44:36,260 Epoch: [39/484] Iter:[270/495], Time: 0.39, lr: [0.00926155246812691], Loss: 2.192239, Acc:0.788132, Semantic loss: 0.825982, BCE loss: 0.577093, SB loss: 0.789164
2023-10-30 00:44:40,064 Epoch: [39/484] Iter:[280/495], Time: 0.39, lr: [0.009261173594184715], Loss: 2.199132, Acc:0.787212, Semantic loss: 0.830518, BCE loss: 0.578184, SB loss: 0.790431
2023-10-30 00:44:43,870 Epoch: [39/484] Iter:[290/495], Time: 0.39, lr: [0.00926079471852032], Loss: 2.200955, Acc:0.787607, Semantic loss: 0.831890, BCE loss: 0.579166, SB loss: 0.789899
2023-10-30 00:44:47,653 Epoch: [39/484] Iter:[300/495], Time: 0.38, lr: [0.009260415841133643], Loss: 2.199565, Acc:0.787237, Semantic loss: 0.829928, BCE loss: 0.580634, SB loss: 0.789003
2023-10-30 00:44:51,338 Epoch: [39/484] Iter:[310/495], Time: 0.38, lr: [0.009260036962024596], Loss: 2.191832, Acc:0.786884, Semantic loss: 0.826391, BCE loss: 0.577739, SB loss: 0.787701
2023-10-30 00:44:55,175 Epoch: [39/484] Iter:[320/495], Time: 0.38, lr: [0.009259658081193096], Loss: 2.189927, Acc:0.787665, Semantic loss: 0.824308, BCE loss: 0.578626, SB loss: 0.786993
2023-10-30 00:44:59,068 Epoch: [39/484] Iter:[330/495], Time: 0.38, lr: [0.009259279198639052], Loss: 2.192926, Acc:0.787909, Semantic loss: 0.827621, BCE loss: 0.578895, SB loss: 0.786410
2023-10-30 00:45:02,794 Epoch: [39/484] Iter:[340/495], Time: 0.38, lr: [0.00925890031436238], Loss: 2.197774, Acc:0.787579, Semantic loss: 0.829781, BCE loss: 0.580123, SB loss: 0.787870
2023-10-30 00:45:06,565 Epoch: [39/484] Iter:[350/495], Time: 0.38, lr: [0.009258521428362993], Loss: 2.193709, Acc:0.787338, Semantic loss: 0.827105, BCE loss: 0.579923, SB loss: 0.786681
2023-10-30 00:45:10,293 Epoch: [39/484] Iter:[360/495], Time: 0.38, lr: [0.009258142540640807], Loss: 2.193183, Acc:0.787771, Semantic loss: 0.825444, BCE loss: 0.581375, SB loss: 0.786365
2023-10-30 00:45:14,092 Epoch: [39/484] Iter:[370/495], Time: 0.38, lr: [0.009257763651195735], Loss: 2.192293, Acc:0.787772, Semantic loss: 0.826136, BCE loss: 0.579537, SB loss: 0.786620
2023-10-30 00:45:17,960 Epoch: [39/484] Iter:[380/495], Time: 0.38, lr: [0.009257384760027689], Loss: 2.190345, Acc:0.788390, Semantic loss: 0.825459, BCE loss: 0.577825, SB loss: 0.787061
2023-10-30 00:45:21,730 Epoch: [39/484] Iter:[390/495], Time: 0.38, lr: [0.009257005867136583], Loss: 2.186443, Acc:0.789034, Semantic loss: 0.823219, BCE loss: 0.576029, SB loss: 0.787195
2023-10-30 00:45:25,592 Epoch: [39/484] Iter:[400/495], Time: 0.38, lr: [0.009256626972522334], Loss: 2.186592, Acc:0.789179, Semantic loss: 0.824098, BCE loss: 0.575453, SB loss: 0.787041
2023-10-30 00:45:29,334 Epoch: [39/484] Iter:[410/495], Time: 0.38, lr: [0.009256248076184853], Loss: 2.187204, Acc:0.788944, Semantic loss: 0.823748, BCE loss: 0.575971, SB loss: 0.787484
2023-10-30 00:45:33,139 Epoch: [39/484] Iter:[420/495], Time: 0.38, lr: [0.009255869178124055], Loss: 2.184567, Acc:0.787867, Semantic loss: 0.823048, BCE loss: 0.574064, SB loss: 0.787455
2023-10-30 00:45:36,934 Epoch: [39/484] Iter:[430/495], Time: 0.38, lr: [0.009255490278339853], Loss: 2.182285, Acc:0.787249, Semantic loss: 0.821856, BCE loss: 0.573158, SB loss: 0.787271
2023-10-30 00:45:40,726 Epoch: [39/484] Iter:[440/495], Time: 0.38, lr: [0.00925511137683216], Loss: 2.184230, Acc:0.787539, Semantic loss: 0.822651, BCE loss: 0.573906, SB loss: 0.787673
2023-10-30 00:45:44,508 Epoch: [39/484] Iter:[450/495], Time: 0.38, lr: [0.009254732473600893], Loss: 2.181946, Acc:0.787750, Semantic loss: 0.821665, BCE loss: 0.573562, SB loss: 0.786720
2023-10-30 00:45:48,283 Epoch: [39/484] Iter:[460/495], Time: 0.38, lr: [0.009254353568645962], Loss: 2.181558, Acc:0.788176, Semantic loss: 0.822075, BCE loss: 0.572765, SB loss: 0.786717
2023-10-30 00:45:52,173 Epoch: [39/484] Iter:[470/495], Time: 0.38, lr: [0.009253974661967283], Loss: 2.184645, Acc:0.788519, Semantic loss: 0.822687, BCE loss: 0.574308, SB loss: 0.787650
2023-10-30 00:45:56,052 Epoch: [39/484] Iter:[480/495], Time: 0.38, lr: [0.009253595753564768], Loss: 2.185656, Acc:0.788468, Semantic loss: 0.823438, BCE loss: 0.574133, SB loss: 0.788085
2023-10-30 00:45:59,645 Epoch: [39/484] Iter:[490/495], Time: 0.38, lr: [0.009253216843438333], Loss: 2.183489, Acc:0.788316, Semantic loss: 0.822952, BCE loss: 0.573333, SB loss: 0.787204
2023-10-30 00:46:01,090 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:46:01,331 Loss: 2.464, MeanIU:  0.5433, Best_mIoU:  0.6427
2023-10-30 00:46:01,331 [0.88953769 0.56632446 0.74206788 0.21810872 0.1228711  0.35635123
 0.55071234 0.62304592 0.88078227 0.32015413 0.8852586  0.61044051
 0.34498101 0.88392612 0.44559824 0.52841732 0.25272221 0.4228432
 0.67894361]
2023-10-30 00:46:03,367 Epoch: [40/484] Iter:[0/495], Time: 2.00, lr: [0.009253027387728619], Loss: 2.108912, Acc:0.786028, Semantic loss: 0.834230, BCE loss: 0.477837, SB loss: 0.796846
2023-10-30 00:46:07,441 Epoch: [40/484] Iter:[10/495], Time: 0.55, lr: [0.009252648475016138], Loss: 2.173934, Acc:0.804276, Semantic loss: 0.807647, BCE loss: 0.577548, SB loss: 0.788738
2023-10-30 00:46:11,216 Epoch: [40/484] Iter:[20/495], Time: 0.47, lr: [0.009252269560579524], Loss: 2.169702, Acc:0.790328, Semantic loss: 0.817038, BCE loss: 0.548984, SB loss: 0.803680
2023-10-30 00:46:14,986 Epoch: [40/484] Iter:[30/495], Time: 0.44, lr: [0.009251890644418684], Loss: 2.168167, Acc:0.791839, Semantic loss: 0.816394, BCE loss: 0.552713, SB loss: 0.799059
2023-10-30 00:46:18,950 Epoch: [40/484] Iter:[40/495], Time: 0.43, lr: [0.009251511726533535], Loss: 2.159864, Acc:0.798581, Semantic loss: 0.815963, BCE loss: 0.545674, SB loss: 0.798226
2023-10-30 00:46:22,650 Epoch: [40/484] Iter:[50/495], Time: 0.42, lr: [0.009251132806923992], Loss: 2.193730, Acc:0.798833, Semantic loss: 0.818900, BCE loss: 0.571457, SB loss: 0.803373
2023-10-30 00:46:26,383 Epoch: [40/484] Iter:[60/495], Time: 0.41, lr: [0.009250753885589965], Loss: 2.213051, Acc:0.799880, Semantic loss: 0.825152, BCE loss: 0.581920, SB loss: 0.805979
2023-10-30 00:46:30,245 Epoch: [40/484] Iter:[70/495], Time: 0.41, lr: [0.00925037496253137], Loss: 2.205003, Acc:0.796771, Semantic loss: 0.832059, BCE loss: 0.574801, SB loss: 0.798143
2023-10-30 00:46:34,016 Epoch: [40/484] Iter:[80/495], Time: 0.40, lr: [0.009249996037748119], Loss: 2.190165, Acc:0.799716, Semantic loss: 0.825452, BCE loss: 0.572933, SB loss: 0.791779
2023-10-30 00:46:37,820 Epoch: [40/484] Iter:[90/495], Time: 0.40, lr: [0.009249617111240126], Loss: 2.168490, Acc:0.801263, Semantic loss: 0.815735, BCE loss: 0.565607, SB loss: 0.787148
2023-10-30 00:46:41,612 Epoch: [40/484] Iter:[100/495], Time: 0.40, lr: [0.009249238183007309], Loss: 2.179795, Acc:0.800142, Semantic loss: 0.819837, BCE loss: 0.571066, SB loss: 0.788892
2023-10-30 00:46:45,465 Epoch: [40/484] Iter:[110/495], Time: 0.40, lr: [0.009248859253049576], Loss: 2.166708, Acc:0.796521, Semantic loss: 0.812120, BCE loss: 0.567224, SB loss: 0.787364
2023-10-30 00:46:49,315 Epoch: [40/484] Iter:[120/495], Time: 0.40, lr: [0.009248480321366841], Loss: 2.176340, Acc:0.797023, Semantic loss: 0.819970, BCE loss: 0.565384, SB loss: 0.790986
2023-10-30 00:46:53,065 Epoch: [40/484] Iter:[130/495], Time: 0.39, lr: [0.00924810138795902], Loss: 2.179325, Acc:0.795101, Semantic loss: 0.816594, BCE loss: 0.569215, SB loss: 0.793517
2023-10-30 00:46:56,874 Epoch: [40/484] Iter:[140/495], Time: 0.39, lr: [0.009247722452826028], Loss: 2.172490, Acc:0.796633, Semantic loss: 0.810435, BCE loss: 0.569821, SB loss: 0.792234
2023-10-30 00:47:00,768 Epoch: [40/484] Iter:[150/495], Time: 0.39, lr: [0.009247343515967777], Loss: 2.178609, Acc:0.796162, Semantic loss: 0.813921, BCE loss: 0.570756, SB loss: 0.793932
2023-10-30 00:47:04,566 Epoch: [40/484] Iter:[160/495], Time: 0.39, lr: [0.009246964577384179], Loss: 2.175778, Acc:0.797993, Semantic loss: 0.811857, BCE loss: 0.569878, SB loss: 0.794043
2023-10-30 00:47:08,322 Epoch: [40/484] Iter:[170/495], Time: 0.39, lr: [0.009246585637075146], Loss: 2.173884, Acc:0.796869, Semantic loss: 0.812087, BCE loss: 0.570002, SB loss: 0.791795
2023-10-30 00:47:12,065 Epoch: [40/484] Iter:[180/495], Time: 0.39, lr: [0.009246206695040598], Loss: 2.171699, Acc:0.796407, Semantic loss: 0.811942, BCE loss: 0.568092, SB loss: 0.791666
2023-10-30 00:47:15,905 Epoch: [40/484] Iter:[190/495], Time: 0.39, lr: [0.009245827751280442], Loss: 2.165307, Acc:0.797360, Semantic loss: 0.808040, BCE loss: 0.567481, SB loss: 0.789785
2023-10-30 00:47:19,643 Epoch: [40/484] Iter:[200/495], Time: 0.39, lr: [0.009245448805794596], Loss: 2.156534, Acc:0.797111, Semantic loss: 0.804130, BCE loss: 0.564152, SB loss: 0.788252
2023-10-30 00:47:23,442 Epoch: [40/484] Iter:[210/495], Time: 0.39, lr: [0.009245069858582972], Loss: 2.161916, Acc:0.796199, Semantic loss: 0.809657, BCE loss: 0.563582, SB loss: 0.788677
2023-10-30 00:47:27,322 Epoch: [40/484] Iter:[220/495], Time: 0.39, lr: [0.009244690909645484], Loss: 2.160348, Acc:0.794971, Semantic loss: 0.809513, BCE loss: 0.562918, SB loss: 0.787917
2023-10-30 00:47:31,040 Epoch: [40/484] Iter:[230/495], Time: 0.39, lr: [0.009244311958982043], Loss: 2.160697, Acc:0.795273, Semantic loss: 0.810820, BCE loss: 0.562890, SB loss: 0.786986
2023-10-30 00:47:34,717 Epoch: [40/484] Iter:[240/495], Time: 0.39, lr: [0.009243933006592566], Loss: 2.165754, Acc:0.796042, Semantic loss: 0.813287, BCE loss: 0.564320, SB loss: 0.788147
2023-10-30 00:47:38,453 Epoch: [40/484] Iter:[250/495], Time: 0.39, lr: [0.009243554052476963], Loss: 2.158732, Acc:0.795074, Semantic loss: 0.810087, BCE loss: 0.561780, SB loss: 0.786865
2023-10-30 00:47:42,261 Epoch: [40/484] Iter:[260/495], Time: 0.39, lr: [0.009243175096635152], Loss: 2.159570, Acc:0.795427, Semantic loss: 0.810741, BCE loss: 0.563135, SB loss: 0.785695
2023-10-30 00:47:46,018 Epoch: [40/484] Iter:[270/495], Time: 0.39, lr: [0.009242796139067044], Loss: 2.158487, Acc:0.794859, Semantic loss: 0.809979, BCE loss: 0.561999, SB loss: 0.786509
2023-10-30 00:47:49,735 Epoch: [40/484] Iter:[280/495], Time: 0.39, lr: [0.00924241717977255], Loss: 2.149801, Acc:0.794225, Semantic loss: 0.805287, BCE loss: 0.559686, SB loss: 0.784829
2023-10-30 00:47:53,538 Epoch: [40/484] Iter:[290/495], Time: 0.39, lr: [0.009242038218751589], Loss: 2.143225, Acc:0.793261, Semantic loss: 0.802884, BCE loss: 0.557217, SB loss: 0.783124
2023-10-30 00:47:57,324 Epoch: [40/484] Iter:[300/495], Time: 0.39, lr: [0.00924165925600407], Loss: 2.144276, Acc:0.792511, Semantic loss: 0.803564, BCE loss: 0.558049, SB loss: 0.782663
2023-10-30 00:48:01,009 Epoch: [40/484] Iter:[310/495], Time: 0.38, lr: [0.009241280291529909], Loss: 2.140957, Acc:0.792309, Semantic loss: 0.802803, BCE loss: 0.556571, SB loss: 0.781582
2023-10-30 00:48:04,803 Epoch: [40/484] Iter:[320/495], Time: 0.38, lr: [0.009240901325329018], Loss: 2.140956, Acc:0.792525, Semantic loss: 0.802665, BCE loss: 0.556322, SB loss: 0.781969
2023-10-30 00:48:08,532 Epoch: [40/484] Iter:[330/495], Time: 0.38, lr: [0.00924052235740131], Loss: 2.138668, Acc:0.792732, Semantic loss: 0.801433, BCE loss: 0.554980, SB loss: 0.782255
2023-10-30 00:48:12,274 Epoch: [40/484] Iter:[340/495], Time: 0.38, lr: [0.0092401433877467], Loss: 2.138174, Acc:0.792947, Semantic loss: 0.801625, BCE loss: 0.554228, SB loss: 0.782321
2023-10-30 00:48:16,051 Epoch: [40/484] Iter:[350/495], Time: 0.38, lr: [0.009239764416365101], Loss: 2.140242, Acc:0.792080, Semantic loss: 0.803309, BCE loss: 0.554476, SB loss: 0.782457
2023-10-30 00:48:19,914 Epoch: [40/484] Iter:[360/495], Time: 0.38, lr: [0.009239385443256426], Loss: 2.140174, Acc:0.791144, Semantic loss: 0.804316, BCE loss: 0.553655, SB loss: 0.782203
2023-10-30 00:48:23,675 Epoch: [40/484] Iter:[370/495], Time: 0.38, lr: [0.009239006468420588], Loss: 2.138119, Acc:0.790629, Semantic loss: 0.802257, BCE loss: 0.554539, SB loss: 0.781324
2023-10-30 00:48:27,559 Epoch: [40/484] Iter:[380/495], Time: 0.38, lr: [0.009238627491857502], Loss: 2.139649, Acc:0.791454, Semantic loss: 0.801924, BCE loss: 0.556216, SB loss: 0.781510
2023-10-30 00:48:31,333 Epoch: [40/484] Iter:[390/495], Time: 0.38, lr: [0.00923824851356708], Loss: 2.138578, Acc:0.790886, Semantic loss: 0.802632, BCE loss: 0.554250, SB loss: 0.781696
2023-10-30 00:48:35,206 Epoch: [40/484] Iter:[400/495], Time: 0.38, lr: [0.009237869533549235], Loss: 2.138301, Acc:0.789769, Semantic loss: 0.803126, BCE loss: 0.552417, SB loss: 0.782758
2023-10-30 00:48:39,010 Epoch: [40/484] Iter:[410/495], Time: 0.38, lr: [0.009237490551803881], Loss: 2.137947, Acc:0.789827, Semantic loss: 0.803197, BCE loss: 0.551432, SB loss: 0.783319
2023-10-30 00:48:42,765 Epoch: [40/484] Iter:[420/495], Time: 0.38, lr: [0.009237111568330934], Loss: 2.138344, Acc:0.789471, Semantic loss: 0.802740, BCE loss: 0.552058, SB loss: 0.783547
2023-10-30 00:48:46,518 Epoch: [40/484] Iter:[430/495], Time: 0.38, lr: [0.009236732583130304], Loss: 2.135393, Acc:0.789425, Semantic loss: 0.801400, BCE loss: 0.551534, SB loss: 0.782459
2023-10-30 00:48:50,271 Epoch: [40/484] Iter:[440/495], Time: 0.38, lr: [0.009236353596201905], Loss: 2.133421, Acc:0.788709, Semantic loss: 0.800781, BCE loss: 0.550500, SB loss: 0.782140
2023-10-30 00:48:54,135 Epoch: [40/484] Iter:[450/495], Time: 0.38, lr: [0.00923597460754565], Loss: 2.138718, Acc:0.788672, Semantic loss: 0.803803, BCE loss: 0.551746, SB loss: 0.783169
2023-10-30 00:48:57,897 Epoch: [40/484] Iter:[460/495], Time: 0.38, lr: [0.009235595617161453], Loss: 2.142749, Acc:0.788662, Semantic loss: 0.806296, BCE loss: 0.551802, SB loss: 0.784650
2023-10-30 00:49:01,737 Epoch: [40/484] Iter:[470/495], Time: 0.38, lr: [0.009235216625049229], Loss: 2.144334, Acc:0.788599, Semantic loss: 0.806124, BCE loss: 0.552658, SB loss: 0.785552
2023-10-30 00:49:05,417 Epoch: [40/484] Iter:[480/495], Time: 0.38, lr: [0.009234837631208886], Loss: 2.144643, Acc:0.788161, Semantic loss: 0.806731, BCE loss: 0.552309, SB loss: 0.785603
2023-10-30 00:49:09,001 Epoch: [40/484] Iter:[490/495], Time: 0.38, lr: [0.009234458635640345], Loss: 2.145035, Acc:0.788200, Semantic loss: 0.807288, BCE loss: 0.552008, SB loss: 0.785740
2023-10-30 00:52:07,248 0 [9.25448208e-01 6.07174699e-01 8.02564905e-01 8.85683284e-02
 1.83592302e-01 3.97723502e-01 3.84095416e-01 5.23684245e-01
 8.67822190e-01 4.44066551e-01 8.58689134e-01 5.55431886e-01
 3.97113061e-03 7.27185791e-01 2.21431464e-04 1.42105673e-02
 1.40880380e-02 5.52995517e-03 5.63581319e-01] 0.41934997889115105
2023-10-30 00:52:07,248 1 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992] 0.63872429328705
2023-10-30 00:52:07,252 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:52:07,491 Loss: 2.125, MeanIU:  0.6387, Best_mIoU:  0.6427
2023-10-30 00:52:07,491 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992]
2023-10-30 00:52:09,358 Epoch: [41/484] Iter:[0/495], Time: 1.83, lr: [0.00923426913720797], Loss: 1.833956, Acc:0.891450, Semantic loss: 0.574618, BCE loss: 0.588481, SB loss: 0.670857
2023-10-30 00:52:13,368 Epoch: [41/484] Iter:[10/495], Time: 0.53, lr: [0.009233890139046961], Loss: 2.237903, Acc:0.798165, Semantic loss: 0.810969, BCE loss: 0.614969, SB loss: 0.811965
2023-10-30 00:52:16,988 Epoch: [41/484] Iter:[20/495], Time: 0.45, lr: [0.009233511139157534], Loss: 2.165133, Acc:0.802544, Semantic loss: 0.779160, BCE loss: 0.603269, SB loss: 0.782704
2023-10-30 00:52:20,591 Epoch: [41/484] Iter:[30/495], Time: 0.42, lr: [0.009233132137539603], Loss: 2.206697, Acc:0.808628, Semantic loss: 0.805548, BCE loss: 0.613958, SB loss: 0.787191
2023-10-30 00:52:24,163 Epoch: [41/484] Iter:[40/495], Time: 0.41, lr: [0.009232753134193078], Loss: 2.189706, Acc:0.807071, Semantic loss: 0.811734, BCE loss: 0.594206, SB loss: 0.783766
2023-10-30 00:52:27,710 Epoch: [41/484] Iter:[50/495], Time: 0.40, lr: [0.009232374129117874], Loss: 2.129898, Acc:0.804242, Semantic loss: 0.782275, BCE loss: 0.576477, SB loss: 0.771147
2023-10-30 00:52:31,388 Epoch: [41/484] Iter:[60/495], Time: 0.39, lr: [0.009231995122313904], Loss: 2.143422, Acc:0.802714, Semantic loss: 0.790015, BCE loss: 0.580594, SB loss: 0.772813
2023-10-30 00:52:34,931 Epoch: [41/484] Iter:[70/495], Time: 0.39, lr: [0.009231616113781083], Loss: 2.132202, Acc:0.801496, Semantic loss: 0.788752, BCE loss: 0.569890, SB loss: 0.773560
2023-10-30 00:52:38,498 Epoch: [41/484] Iter:[80/495], Time: 0.38, lr: [0.009231237103519323], Loss: 2.138707, Acc:0.802580, Semantic loss: 0.791947, BCE loss: 0.571194, SB loss: 0.775566
2023-10-30 00:52:42,318 Epoch: [41/484] Iter:[90/495], Time: 0.38, lr: [0.009230858091528536], Loss: 2.124983, Acc:0.807081, Semantic loss: 0.784624, BCE loss: 0.566303, SB loss: 0.774056
2023-10-30 00:52:46,060 Epoch: [41/484] Iter:[100/495], Time: 0.38, lr: [0.009230479077808636], Loss: 2.141498, Acc:0.805314, Semantic loss: 0.793949, BCE loss: 0.571284, SB loss: 0.776265
2023-10-30 00:52:49,676 Epoch: [41/484] Iter:[110/495], Time: 0.38, lr: [0.009230100062359537], Loss: 2.127924, Acc:0.804167, Semantic loss: 0.789068, BCE loss: 0.568386, SB loss: 0.770471
2023-10-30 00:52:53,423 Epoch: [41/484] Iter:[120/495], Time: 0.38, lr: [0.009229721045181154], Loss: 2.121383, Acc:0.802996, Semantic loss: 0.786574, BCE loss: 0.565827, SB loss: 0.768981
2023-10-30 00:52:57,099 Epoch: [41/484] Iter:[130/495], Time: 0.38, lr: [0.009229342026273395], Loss: 2.119409, Acc:0.802928, Semantic loss: 0.786873, BCE loss: 0.561811, SB loss: 0.770725
2023-10-30 00:53:00,765 Epoch: [41/484] Iter:[140/495], Time: 0.38, lr: [0.009228963005636177], Loss: 2.120630, Acc:0.801940, Semantic loss: 0.789389, BCE loss: 0.562772, SB loss: 0.768469
2023-10-30 00:53:04,441 Epoch: [41/484] Iter:[150/495], Time: 0.38, lr: [0.009228583983269412], Loss: 2.122446, Acc:0.801772, Semantic loss: 0.789363, BCE loss: 0.565724, SB loss: 0.767359
2023-10-30 00:53:08,099 Epoch: [41/484] Iter:[160/495], Time: 0.38, lr: [0.009228204959173014], Loss: 2.125929, Acc:0.800717, Semantic loss: 0.788571, BCE loss: 0.569086, SB loss: 0.768272
2023-10-30 00:53:11,789 Epoch: [41/484] Iter:[170/495], Time: 0.38, lr: [0.009227825933346895], Loss: 2.125762, Acc:0.800049, Semantic loss: 0.790474, BCE loss: 0.568453, SB loss: 0.766834
2023-10-30 00:53:15,526 Epoch: [41/484] Iter:[180/495], Time: 0.38, lr: [0.009227446905790969], Loss: 2.129146, Acc:0.798162, Semantic loss: 0.791916, BCE loss: 0.569618, SB loss: 0.767612
2023-10-30 00:53:19,227 Epoch: [41/484] Iter:[190/495], Time: 0.38, lr: [0.00922706787650515], Loss: 2.131455, Acc:0.796662, Semantic loss: 0.793378, BCE loss: 0.568774, SB loss: 0.769303
2023-10-30 00:53:23,005 Epoch: [41/484] Iter:[200/495], Time: 0.38, lr: [0.009226688845489349], Loss: 2.134697, Acc:0.795708, Semantic loss: 0.795371, BCE loss: 0.569788, SB loss: 0.769538
2023-10-30 00:53:26,757 Epoch: [41/484] Iter:[210/495], Time: 0.38, lr: [0.009226309812743482], Loss: 2.147848, Acc:0.794852, Semantic loss: 0.799727, BCE loss: 0.574947, SB loss: 0.773174
2023-10-30 00:53:30,543 Epoch: [41/484] Iter:[220/495], Time: 0.38, lr: [0.009225930778267458], Loss: 2.154855, Acc:0.794786, Semantic loss: 0.803331, BCE loss: 0.576753, SB loss: 0.774771
2023-10-30 00:53:34,281 Epoch: [41/484] Iter:[230/495], Time: 0.38, lr: [0.009225551742061194], Loss: 2.152120, Acc:0.795662, Semantic loss: 0.802653, BCE loss: 0.575689, SB loss: 0.773778
2023-10-30 00:53:37,934 Epoch: [41/484] Iter:[240/495], Time: 0.38, lr: [0.009225172704124603], Loss: 2.152154, Acc:0.795501, Semantic loss: 0.804044, BCE loss: 0.574770, SB loss: 0.773341
2023-10-30 00:53:41,588 Epoch: [41/484] Iter:[250/495], Time: 0.37, lr: [0.009224793664457595], Loss: 2.150703, Acc:0.794707, Semantic loss: 0.803117, BCE loss: 0.574285, SB loss: 0.773301
2023-10-30 00:53:45,291 Epoch: [41/484] Iter:[260/495], Time: 0.37, lr: [0.009224414623060085], Loss: 2.156018, Acc:0.793672, Semantic loss: 0.806450, BCE loss: 0.573549, SB loss: 0.776020
2023-10-30 00:53:49,044 Epoch: [41/484] Iter:[270/495], Time: 0.37, lr: [0.009224035579931985], Loss: 2.159489, Acc:0.794519, Semantic loss: 0.806658, BCE loss: 0.574918, SB loss: 0.777913
2023-10-30 00:53:52,859 Epoch: [41/484] Iter:[280/495], Time: 0.37, lr: [0.009223656535073212], Loss: 2.159501, Acc:0.795385, Semantic loss: 0.805198, BCE loss: 0.575527, SB loss: 0.778776
2023-10-30 00:53:56,611 Epoch: [41/484] Iter:[290/495], Time: 0.37, lr: [0.009223277488483674], Loss: 2.155348, Acc:0.795401, Semantic loss: 0.802807, BCE loss: 0.574531, SB loss: 0.778010
2023-10-30 00:54:00,365 Epoch: [41/484] Iter:[300/495], Time: 0.37, lr: [0.009222898440163286], Loss: 2.148941, Acc:0.795591, Semantic loss: 0.798775, BCE loss: 0.573150, SB loss: 0.777015
2023-10-30 00:54:04,025 Epoch: [41/484] Iter:[310/495], Time: 0.37, lr: [0.009222519390111962], Loss: 2.154137, Acc:0.794544, Semantic loss: 0.802674, BCE loss: 0.572755, SB loss: 0.778708
2023-10-30 00:54:07,803 Epoch: [41/484] Iter:[320/495], Time: 0.37, lr: [0.009222140338329615], Loss: 2.154025, Acc:0.794536, Semantic loss: 0.802110, BCE loss: 0.572591, SB loss: 0.779325
2023-10-30 00:54:11,480 Epoch: [41/484] Iter:[330/495], Time: 0.37, lr: [0.009221761284816155], Loss: 2.154384, Acc:0.793958, Semantic loss: 0.803021, BCE loss: 0.571575, SB loss: 0.779788
2023-10-30 00:54:15,235 Epoch: [41/484] Iter:[340/495], Time: 0.37, lr: [0.0092213822295715], Loss: 2.157706, Acc:0.794262, Semantic loss: 0.804831, BCE loss: 0.571952, SB loss: 0.780924
2023-10-30 00:54:18,918 Epoch: [41/484] Iter:[350/495], Time: 0.37, lr: [0.009221003172595558], Loss: 2.156926, Acc:0.794482, Semantic loss: 0.803359, BCE loss: 0.572972, SB loss: 0.780595
2023-10-30 00:54:22,630 Epoch: [41/484] Iter:[360/495], Time: 0.37, lr: [0.009220624113888245], Loss: 2.163007, Acc:0.794168, Semantic loss: 0.810634, BCE loss: 0.572280, SB loss: 0.780093
2023-10-30 00:54:26,359 Epoch: [41/484] Iter:[370/495], Time: 0.37, lr: [0.009220245053449476], Loss: 2.162863, Acc:0.794498, Semantic loss: 0.810545, BCE loss: 0.571716, SB loss: 0.780601
2023-10-30 00:54:30,140 Epoch: [41/484] Iter:[380/495], Time: 0.37, lr: [0.009219865991279157], Loss: 2.167780, Acc:0.794371, Semantic loss: 0.813805, BCE loss: 0.572307, SB loss: 0.781668
2023-10-30 00:54:33,902 Epoch: [41/484] Iter:[390/495], Time: 0.37, lr: [0.009219486927377209], Loss: 2.168458, Acc:0.794441, Semantic loss: 0.813335, BCE loss: 0.572489, SB loss: 0.782635
2023-10-30 00:54:37,681 Epoch: [41/484] Iter:[400/495], Time: 0.37, lr: [0.00921910786174354], Loss: 2.169323, Acc:0.793644, Semantic loss: 0.813397, BCE loss: 0.572661, SB loss: 0.783264
2023-10-30 00:54:41,489 Epoch: [41/484] Iter:[410/495], Time: 0.37, lr: [0.009218728794378062], Loss: 2.164888, Acc:0.794029, Semantic loss: 0.810363, BCE loss: 0.573002, SB loss: 0.781523
2023-10-30 00:54:45,220 Epoch: [41/484] Iter:[420/495], Time: 0.37, lr: [0.009218349725280696], Loss: 2.167762, Acc:0.792826, Semantic loss: 0.812436, BCE loss: 0.572462, SB loss: 0.782865
2023-10-30 00:54:48,950 Epoch: [41/484] Iter:[430/495], Time: 0.37, lr: [0.009217970654451344], Loss: 2.168472, Acc:0.792752, Semantic loss: 0.811632, BCE loss: 0.573834, SB loss: 0.783006
2023-10-30 00:54:52,833 Epoch: [41/484] Iter:[440/495], Time: 0.37, lr: [0.009217591581889928], Loss: 2.167700, Acc:0.793032, Semantic loss: 0.811842, BCE loss: 0.573141, SB loss: 0.782717
2023-10-30 00:54:56,696 Epoch: [41/484] Iter:[450/495], Time: 0.38, lr: [0.009217212507596355], Loss: 2.164285, Acc:0.793629, Semantic loss: 0.810404, BCE loss: 0.571997, SB loss: 0.781884
2023-10-30 00:55:00,421 Epoch: [41/484] Iter:[460/495], Time: 0.38, lr: [0.009216833431570539], Loss: 2.164443, Acc:0.793393, Semantic loss: 0.810404, BCE loss: 0.572172, SB loss: 0.781867
2023-10-30 00:55:04,212 Epoch: [41/484] Iter:[470/495], Time: 0.38, lr: [0.009216454353812395], Loss: 2.163592, Acc:0.794054, Semantic loss: 0.810182, BCE loss: 0.571743, SB loss: 0.781667
2023-10-30 00:55:08,001 Epoch: [41/484] Iter:[480/495], Time: 0.38, lr: [0.009216075274321837], Loss: 2.163280, Acc:0.794365, Semantic loss: 0.809689, BCE loss: 0.571182, SB loss: 0.782409
2023-10-30 00:55:11,561 Epoch: [41/484] Iter:[490/495], Time: 0.37, lr: [0.009215696193098774], Loss: 2.161859, Acc:0.794464, Semantic loss: 0.809064, BCE loss: 0.571205, SB loss: 0.781590
2023-10-30 00:55:12,965 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:55:13,204 Loss: 2.125, MeanIU:  0.6387, Best_mIoU:  0.6427
2023-10-30 00:55:13,204 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992]
2023-10-30 00:55:15,325 Epoch: [42/484] Iter:[0/495], Time: 2.09, lr: [0.009215506651837527], Loss: 2.592932, Acc:0.818899, Semantic loss: 1.087342, BCE loss: 0.675760, SB loss: 0.829830
2023-10-30 00:55:19,485 Epoch: [42/484] Iter:[10/495], Time: 0.57, lr: [0.009215127568015546], Loss: 2.269302, Acc:0.790998, Semantic loss: 0.835789, BCE loss: 0.696966, SB loss: 0.736547
2023-10-30 00:55:23,378 Epoch: [42/484] Iter:[20/495], Time: 0.48, lr: [0.009214748482460844], Loss: 2.193509, Acc:0.809228, Semantic loss: 0.804084, BCE loss: 0.642049, SB loss: 0.747376
2023-10-30 00:55:27,238 Epoch: [42/484] Iter:[30/495], Time: 0.45, lr: [0.009214369395173335], Loss: 2.185749, Acc:0.800012, Semantic loss: 0.807302, BCE loss: 0.621990, SB loss: 0.756457
2023-10-30 00:55:31,136 Epoch: [42/484] Iter:[40/495], Time: 0.44, lr: [0.009213990306152928], Loss: 2.203063, Acc:0.798742, Semantic loss: 0.799895, BCE loss: 0.639559, SB loss: 0.763609
2023-10-30 00:55:34,981 Epoch: [42/484] Iter:[50/495], Time: 0.43, lr: [0.00921361121539954], Loss: 2.184611, Acc:0.798561, Semantic loss: 0.804572, BCE loss: 0.615863, SB loss: 0.764177
2023-10-30 00:55:38,707 Epoch: [42/484] Iter:[60/495], Time: 0.42, lr: [0.009213232122913084], Loss: 2.162397, Acc:0.785780, Semantic loss: 0.795001, BCE loss: 0.601428, SB loss: 0.765968
2023-10-30 00:55:42,405 Epoch: [42/484] Iter:[70/495], Time: 0.41, lr: [0.009212853028693471], Loss: 2.158094, Acc:0.792349, Semantic loss: 0.791820, BCE loss: 0.600356, SB loss: 0.765918
2023-10-30 00:55:46,330 Epoch: [42/484] Iter:[80/495], Time: 0.41, lr: [0.009212473932740614], Loss: 2.149340, Acc:0.794240, Semantic loss: 0.789223, BCE loss: 0.594372, SB loss: 0.765745
2023-10-30 00:55:50,080 Epoch: [42/484] Iter:[90/495], Time: 0.40, lr: [0.009212094835054425], Loss: 2.151398, Acc:0.793471, Semantic loss: 0.789958, BCE loss: 0.593978, SB loss: 0.767462
2023-10-30 00:55:53,785 Epoch: [42/484] Iter:[100/495], Time: 0.40, lr: [0.00921171573563482], Loss: 2.154398, Acc:0.796576, Semantic loss: 0.793302, BCE loss: 0.592943, SB loss: 0.768153
2023-10-30 00:55:57,435 Epoch: [42/484] Iter:[110/495], Time: 0.40, lr: [0.009211336634481707], Loss: 2.167728, Acc:0.794806, Semantic loss: 0.803510, BCE loss: 0.593855, SB loss: 0.770363
2023-10-30 00:56:01,153 Epoch: [42/484] Iter:[120/495], Time: 0.40, lr: [0.009210957531595003], Loss: 2.161518, Acc:0.791369, Semantic loss: 0.801613, BCE loss: 0.588710, SB loss: 0.771195
2023-10-30 00:56:04,837 Epoch: [42/484] Iter:[130/495], Time: 0.39, lr: [0.009210578426974618], Loss: 2.152893, Acc:0.792883, Semantic loss: 0.798635, BCE loss: 0.583660, SB loss: 0.770599
2023-10-30 00:56:08,625 Epoch: [42/484] Iter:[140/495], Time: 0.39, lr: [0.009210199320620466], Loss: 2.159986, Acc:0.792291, Semantic loss: 0.801803, BCE loss: 0.585864, SB loss: 0.772319
2023-10-30 00:56:12,450 Epoch: [42/484] Iter:[150/495], Time: 0.39, lr: [0.009209820212532463], Loss: 2.159078, Acc:0.791494, Semantic loss: 0.801291, BCE loss: 0.585751, SB loss: 0.772036
2023-10-30 00:56:16,267 Epoch: [42/484] Iter:[160/495], Time: 0.39, lr: [0.009209441102710516], Loss: 2.155693, Acc:0.791999, Semantic loss: 0.799798, BCE loss: 0.581598, SB loss: 0.774297
2023-10-30 00:56:20,074 Epoch: [42/484] Iter:[170/495], Time: 0.39, lr: [0.00920906199115454], Loss: 2.154941, Acc:0.790253, Semantic loss: 0.800668, BCE loss: 0.578174, SB loss: 0.776099
2023-10-30 00:56:23,776 Epoch: [42/484] Iter:[180/495], Time: 0.39, lr: [0.009208682877864449], Loss: 2.152840, Acc:0.791636, Semantic loss: 0.798571, BCE loss: 0.578377, SB loss: 0.775892
2023-10-30 00:56:27,648 Epoch: [42/484] Iter:[190/495], Time: 0.39, lr: [0.009208303762840155], Loss: 2.161684, Acc:0.791141, Semantic loss: 0.803887, BCE loss: 0.580227, SB loss: 0.777571
2023-10-30 00:56:31,357 Epoch: [42/484] Iter:[200/495], Time: 0.39, lr: [0.009207924646081568], Loss: 2.153655, Acc:0.789830, Semantic loss: 0.802081, BCE loss: 0.575413, SB loss: 0.776161
2023-10-30 00:56:35,173 Epoch: [42/484] Iter:[210/495], Time: 0.39, lr: [0.009207545527588606], Loss: 2.153314, Acc:0.790662, Semantic loss: 0.802614, BCE loss: 0.574452, SB loss: 0.776248
2023-10-30 00:56:38,924 Epoch: [42/484] Iter:[220/495], Time: 0.39, lr: [0.009207166407361179], Loss: 2.155727, Acc:0.790181, Semantic loss: 0.805538, BCE loss: 0.572491, SB loss: 0.777698
2023-10-30 00:56:42,755 Epoch: [42/484] Iter:[230/495], Time: 0.39, lr: [0.009206787285399197], Loss: 2.153062, Acc:0.789056, Semantic loss: 0.803776, BCE loss: 0.571519, SB loss: 0.777767
2023-10-30 00:56:46,512 Epoch: [42/484] Iter:[240/495], Time: 0.39, lr: [0.00920640816170258], Loss: 2.156393, Acc:0.788460, Semantic loss: 0.806082, BCE loss: 0.569817, SB loss: 0.780495
2023-10-30 00:56:50,388 Epoch: [42/484] Iter:[250/495], Time: 0.39, lr: [0.009206029036271232], Loss: 2.158326, Acc:0.789620, Semantic loss: 0.806917, BCE loss: 0.571417, SB loss: 0.779991
2023-10-30 00:56:54,061 Epoch: [42/484] Iter:[260/495], Time: 0.39, lr: [0.009205649909105072], Loss: 2.153660, Acc:0.790485, Semantic loss: 0.805426, BCE loss: 0.568710, SB loss: 0.779524
2023-10-30 00:56:57,878 Epoch: [42/484] Iter:[270/495], Time: 0.39, lr: [0.009205270780204009], Loss: 2.151316, Acc:0.791021, Semantic loss: 0.804420, BCE loss: 0.569142, SB loss: 0.777754
2023-10-30 00:57:01,605 Epoch: [42/484] Iter:[280/495], Time: 0.39, lr: [0.009204891649567956], Loss: 2.157330, Acc:0.790069, Semantic loss: 0.807434, BCE loss: 0.571400, SB loss: 0.778495
2023-10-30 00:57:05,315 Epoch: [42/484] Iter:[290/495], Time: 0.39, lr: [0.00920451251719683], Loss: 2.151951, Acc:0.789880, Semantic loss: 0.803523, BCE loss: 0.571035, SB loss: 0.777393
2023-10-30 00:57:08,989 Epoch: [42/484] Iter:[300/495], Time: 0.38, lr: [0.00920413338309054], Loss: 2.149053, Acc:0.789187, Semantic loss: 0.803169, BCE loss: 0.569207, SB loss: 0.776677
2023-10-30 00:57:12,745 Epoch: [42/484] Iter:[310/495], Time: 0.38, lr: [0.009203754247248997], Loss: 2.150224, Acc:0.790475, Semantic loss: 0.805148, BCE loss: 0.568251, SB loss: 0.776824
2023-10-30 00:57:16,529 Epoch: [42/484] Iter:[320/495], Time: 0.38, lr: [0.009203375109672117], Loss: 2.153106, Acc:0.789687, Semantic loss: 0.807207, BCE loss: 0.567312, SB loss: 0.778587
2023-10-30 00:57:20,284 Epoch: [42/484] Iter:[330/495], Time: 0.38, lr: [0.00920299597035981], Loss: 2.154381, Acc:0.790302, Semantic loss: 0.808570, BCE loss: 0.566777, SB loss: 0.779034
2023-10-30 00:57:23,983 Epoch: [42/484] Iter:[340/495], Time: 0.38, lr: [0.009202616829311993], Loss: 2.151541, Acc:0.790114, Semantic loss: 0.806001, BCE loss: 0.565926, SB loss: 0.779614
2023-10-30 00:57:27,747 Epoch: [42/484] Iter:[350/495], Time: 0.38, lr: [0.009202237686528574], Loss: 2.148397, Acc:0.789945, Semantic loss: 0.806003, BCE loss: 0.563168, SB loss: 0.779226
2023-10-30 00:57:31,532 Epoch: [42/484] Iter:[360/495], Time: 0.38, lr: [0.009201858542009465], Loss: 2.146136, Acc:0.789327, Semantic loss: 0.804483, BCE loss: 0.562130, SB loss: 0.779523
2023-10-30 00:57:35,226 Epoch: [42/484] Iter:[370/495], Time: 0.38, lr: [0.009201479395754584], Loss: 2.148964, Acc:0.788974, Semantic loss: 0.806257, BCE loss: 0.562055, SB loss: 0.780652
2023-10-30 00:57:38,997 Epoch: [42/484] Iter:[380/495], Time: 0.38, lr: [0.00920110024776384], Loss: 2.145018, Acc:0.789008, Semantic loss: 0.804027, BCE loss: 0.561934, SB loss: 0.779058
2023-10-30 00:57:42,826 Epoch: [42/484] Iter:[390/495], Time: 0.38, lr: [0.009200721098037143], Loss: 2.150694, Acc:0.789027, Semantic loss: 0.806948, BCE loss: 0.564190, SB loss: 0.779556
2023-10-30 00:57:46,608 Epoch: [42/484] Iter:[400/495], Time: 0.38, lr: [0.009200341946574412], Loss: 2.149415, Acc:0.789654, Semantic loss: 0.807841, BCE loss: 0.562536, SB loss: 0.779038
2023-10-30 00:57:50,440 Epoch: [42/484] Iter:[410/495], Time: 0.38, lr: [0.009199962793375554], Loss: 2.151251, Acc:0.789587, Semantic loss: 0.808639, BCE loss: 0.562601, SB loss: 0.780011
2023-10-30 00:57:54,190 Epoch: [42/484] Iter:[420/495], Time: 0.38, lr: [0.009199583638440484], Loss: 2.148952, Acc:0.790204, Semantic loss: 0.806997, BCE loss: 0.562844, SB loss: 0.779111
2023-10-30 00:57:58,049 Epoch: [42/484] Iter:[430/495], Time: 0.38, lr: [0.009199204481769113], Loss: 2.149860, Acc:0.789606, Semantic loss: 0.807983, BCE loss: 0.562181, SB loss: 0.779695
2023-10-30 00:58:01,823 Epoch: [42/484] Iter:[440/495], Time: 0.38, lr: [0.009198825323361356], Loss: 2.150004, Acc:0.790240, Semantic loss: 0.807449, BCE loss: 0.562895, SB loss: 0.779660
2023-10-30 00:58:05,707 Epoch: [42/484] Iter:[450/495], Time: 0.38, lr: [0.009198446163217125], Loss: 2.151799, Acc:0.790991, Semantic loss: 0.807542, BCE loss: 0.564395, SB loss: 0.779862
2023-10-30 00:58:09,520 Epoch: [42/484] Iter:[460/495], Time: 0.38, lr: [0.00919806700133633], Loss: 2.148994, Acc:0.792365, Semantic loss: 0.805612, BCE loss: 0.564291, SB loss: 0.779090
2023-10-30 00:58:13,166 Epoch: [42/484] Iter:[470/495], Time: 0.38, lr: [0.009197687837718885], Loss: 2.151985, Acc:0.792866, Semantic loss: 0.806426, BCE loss: 0.566059, SB loss: 0.779500
2023-10-30 00:58:17,027 Epoch: [42/484] Iter:[480/495], Time: 0.38, lr: [0.009197308672364703], Loss: 2.152536, Acc:0.793006, Semantic loss: 0.807632, BCE loss: 0.565908, SB loss: 0.778995
2023-10-30 00:58:20,616 Epoch: [42/484] Iter:[490/495], Time: 0.38, lr: [0.009196929505273697], Loss: 2.152289, Acc:0.793386, Semantic loss: 0.806425, BCE loss: 0.566916, SB loss: 0.778948
2023-10-30 00:58:22,057 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 00:58:22,297 Loss: 2.125, MeanIU:  0.6387, Best_mIoU:  0.6427
2023-10-30 00:58:22,298 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992]
2023-10-30 00:58:24,512 Epoch: [43/484] Iter:[0/495], Time: 2.18, lr: [0.009196739921076858], Loss: 2.115984, Acc:0.720412, Semantic loss: 0.945343, BCE loss: 0.476359, SB loss: 0.694282
2023-10-30 00:58:28,683 Epoch: [43/484] Iter:[10/495], Time: 0.58, lr: [0.00919636075138045], Loss: 2.173205, Acc:0.793182, Semantic loss: 0.784462, BCE loss: 0.635842, SB loss: 0.752901
2023-10-30 00:58:32,473 Epoch: [43/484] Iter:[20/495], Time: 0.48, lr: [0.009195981579946999], Loss: 2.127147, Acc:0.801123, Semantic loss: 0.786496, BCE loss: 0.576773, SB loss: 0.763879
2023-10-30 00:58:36,258 Epoch: [43/484] Iter:[30/495], Time: 0.45, lr: [0.009195602406776417], Loss: 2.172168, Acc:0.817006, Semantic loss: 0.791970, BCE loss: 0.604998, SB loss: 0.775200
2023-10-30 00:58:39,991 Epoch: [43/484] Iter:[40/495], Time: 0.43, lr: [0.009195223231868615], Loss: 2.228252, Acc:0.811486, Semantic loss: 0.821007, BCE loss: 0.627933, SB loss: 0.779312
2023-10-30 00:58:43,780 Epoch: [43/484] Iter:[50/495], Time: 0.42, lr: [0.009194844055223509], Loss: 2.191550, Acc:0.815334, Semantic loss: 0.806630, BCE loss: 0.613446, SB loss: 0.771474
2023-10-30 00:58:47,560 Epoch: [43/484] Iter:[60/495], Time: 0.41, lr: [0.009194464876841007], Loss: 2.219133, Acc:0.808206, Semantic loss: 0.828703, BCE loss: 0.612975, SB loss: 0.777456
2023-10-30 00:58:51,248 Epoch: [43/484] Iter:[70/495], Time: 0.41, lr: [0.009194085696721026], Loss: 2.212703, Acc:0.802640, Semantic loss: 0.822339, BCE loss: 0.614127, SB loss: 0.776236
2023-10-30 00:58:55,008 Epoch: [43/484] Iter:[80/495], Time: 0.40, lr: [0.009193706514863474], Loss: 2.196062, Acc:0.798877, Semantic loss: 0.818653, BCE loss: 0.598490, SB loss: 0.778919
2023-10-30 00:58:58,895 Epoch: [43/484] Iter:[90/495], Time: 0.40, lr: [0.009193327331268266], Loss: 2.211603, Acc:0.802462, Semantic loss: 0.828663, BCE loss: 0.598986, SB loss: 0.783954
2023-10-30 00:59:02,684 Epoch: [43/484] Iter:[100/495], Time: 0.40, lr: [0.009192948145935312], Loss: 2.207778, Acc:0.802225, Semantic loss: 0.824506, BCE loss: 0.600241, SB loss: 0.783031
2023-10-30 00:59:06,443 Epoch: [43/484] Iter:[110/495], Time: 0.40, lr: [0.00919256895886453], Loss: 2.196416, Acc:0.798850, Semantic loss: 0.819843, BCE loss: 0.590177, SB loss: 0.786396
2023-10-30 00:59:10,230 Epoch: [43/484] Iter:[120/495], Time: 0.40, lr: [0.009192189770055826], Loss: 2.193430, Acc:0.798224, Semantic loss: 0.821099, BCE loss: 0.586889, SB loss: 0.785443
2023-10-30 00:59:14,041 Epoch: [43/484] Iter:[130/495], Time: 0.39, lr: [0.009191810579509116], Loss: 2.187176, Acc:0.799456, Semantic loss: 0.821351, BCE loss: 0.582673, SB loss: 0.783152
2023-10-30 00:59:17,834 Epoch: [43/484] Iter:[140/495], Time: 0.39, lr: [0.00919143138722431], Loss: 2.189676, Acc:0.799391, Semantic loss: 0.819815, BCE loss: 0.587063, SB loss: 0.782798
2023-10-30 00:59:21,673 Epoch: [43/484] Iter:[150/495], Time: 0.39, lr: [0.009191052193201323], Loss: 2.185759, Acc:0.799625, Semantic loss: 0.818150, BCE loss: 0.585404, SB loss: 0.782206
2023-10-30 00:59:25,416 Epoch: [43/484] Iter:[160/495], Time: 0.39, lr: [0.009190672997440067], Loss: 2.185532, Acc:0.798120, Semantic loss: 0.818234, BCE loss: 0.585910, SB loss: 0.781388
2023-10-30 00:59:29,199 Epoch: [43/484] Iter:[170/495], Time: 0.39, lr: [0.009190293799940453], Loss: 2.188098, Acc:0.797518, Semantic loss: 0.821798, BCE loss: 0.583801, SB loss: 0.782499
2023-10-30 00:59:32,911 Epoch: [43/484] Iter:[180/495], Time: 0.39, lr: [0.009189914600702391], Loss: 2.186939, Acc:0.795682, Semantic loss: 0.820084, BCE loss: 0.584555, SB loss: 0.782300
2023-10-30 00:59:36,692 Epoch: [43/484] Iter:[190/495], Time: 0.39, lr: [0.0091895353997258], Loss: 2.181701, Acc:0.795278, Semantic loss: 0.817093, BCE loss: 0.584244, SB loss: 0.780365
2023-10-30 00:59:40,469 Epoch: [43/484] Iter:[200/495], Time: 0.39, lr: [0.009189156197010585], Loss: 2.184329, Acc:0.793786, Semantic loss: 0.814982, BCE loss: 0.586657, SB loss: 0.782690
2023-10-30 00:59:44,201 Epoch: [43/484] Iter:[210/495], Time: 0.39, lr: [0.009188776992556663], Loss: 2.187618, Acc:0.791846, Semantic loss: 0.816997, BCE loss: 0.585557, SB loss: 0.785063
2023-10-30 00:59:47,941 Epoch: [43/484] Iter:[220/495], Time: 0.39, lr: [0.009188397786363945], Loss: 2.184670, Acc:0.792111, Semantic loss: 0.813700, BCE loss: 0.586217, SB loss: 0.784754
2023-10-30 00:59:51,655 Epoch: [43/484] Iter:[230/495], Time: 0.39, lr: [0.009188018578432345], Loss: 2.185955, Acc:0.791739, Semantic loss: 0.815497, BCE loss: 0.584920, SB loss: 0.785538
2023-10-30 00:59:55,516 Epoch: [43/484] Iter:[240/495], Time: 0.39, lr: [0.00918763936876177], Loss: 2.181862, Acc:0.791896, Semantic loss: 0.812371, BCE loss: 0.583872, SB loss: 0.785619
2023-10-30 00:59:59,237 Epoch: [43/484] Iter:[250/495], Time: 0.39, lr: [0.00918726015735214], Loss: 2.183052, Acc:0.791259, Semantic loss: 0.815274, BCE loss: 0.582545, SB loss: 0.785233
2023-10-30 01:00:03,096 Epoch: [43/484] Iter:[260/495], Time: 0.39, lr: [0.00918688094420336], Loss: 2.181133, Acc:0.792536, Semantic loss: 0.813021, BCE loss: 0.583351, SB loss: 0.784761
2023-10-30 01:00:06,874 Epoch: [43/484] Iter:[270/495], Time: 0.39, lr: [0.009186501729315346], Loss: 2.177978, Acc:0.791506, Semantic loss: 0.813346, BCE loss: 0.579584, SB loss: 0.785049
2023-10-30 01:00:10,664 Epoch: [43/484] Iter:[280/495], Time: 0.39, lr: [0.009186122512688012], Loss: 2.179322, Acc:0.792279, Semantic loss: 0.814858, BCE loss: 0.579312, SB loss: 0.785151
2023-10-30 01:00:14,360 Epoch: [43/484] Iter:[290/495], Time: 0.38, lr: [0.009185743294321263], Loss: 2.179779, Acc:0.792659, Semantic loss: 0.812977, BCE loss: 0.581228, SB loss: 0.785573
2023-10-30 01:00:18,101 Epoch: [43/484] Iter:[300/495], Time: 0.38, lr: [0.009185364074215021], Loss: 2.174637, Acc:0.791951, Semantic loss: 0.810156, BCE loss: 0.579232, SB loss: 0.785249
2023-10-30 01:00:21,883 Epoch: [43/484] Iter:[310/495], Time: 0.38, lr: [0.009184984852369191], Loss: 2.170336, Acc:0.791201, Semantic loss: 0.808288, BCE loss: 0.577618, SB loss: 0.784431
2023-10-30 01:00:25,594 Epoch: [43/484] Iter:[320/495], Time: 0.38, lr: [0.009184605628783689], Loss: 2.165556, Acc:0.791415, Semantic loss: 0.806339, BCE loss: 0.575979, SB loss: 0.783238
2023-10-30 01:00:29,337 Epoch: [43/484] Iter:[330/495], Time: 0.38, lr: [0.009184226403458425], Loss: 2.165666, Acc:0.791526, Semantic loss: 0.806953, BCE loss: 0.575511, SB loss: 0.783201
2023-10-30 01:00:33,034 Epoch: [43/484] Iter:[340/495], Time: 0.38, lr: [0.00918384717639331], Loss: 2.156717, Acc:0.792264, Semantic loss: 0.802816, BCE loss: 0.572353, SB loss: 0.781548
2023-10-30 01:00:36,856 Epoch: [43/484] Iter:[350/495], Time: 0.38, lr: [0.00918346794758826], Loss: 2.151450, Acc:0.792688, Semantic loss: 0.801130, BCE loss: 0.570099, SB loss: 0.780222
2023-10-30 01:00:40,517 Epoch: [43/484] Iter:[360/495], Time: 0.38, lr: [0.009183088717043186], Loss: 2.150382, Acc:0.792464, Semantic loss: 0.802308, BCE loss: 0.567936, SB loss: 0.780138
2023-10-30 01:00:44,213 Epoch: [43/484] Iter:[370/495], Time: 0.38, lr: [0.009182709484757998], Loss: 2.148436, Acc:0.791778, Semantic loss: 0.802339, BCE loss: 0.566178, SB loss: 0.779919
2023-10-30 01:00:48,010 Epoch: [43/484] Iter:[380/495], Time: 0.38, lr: [0.00918233025073261], Loss: 2.148228, Acc:0.791443, Semantic loss: 0.802142, BCE loss: 0.565870, SB loss: 0.780216
2023-10-30 01:00:51,720 Epoch: [43/484] Iter:[390/495], Time: 0.38, lr: [0.009181951014966935], Loss: 2.149954, Acc:0.790932, Semantic loss: 0.804650, BCE loss: 0.564845, SB loss: 0.780459
2023-10-30 01:00:55,429 Epoch: [43/484] Iter:[400/495], Time: 0.38, lr: [0.009181571777460885], Loss: 2.146507, Acc:0.791199, Semantic loss: 0.802626, BCE loss: 0.563860, SB loss: 0.780021
2023-10-30 01:00:59,110 Epoch: [43/484] Iter:[410/495], Time: 0.38, lr: [0.009181192538214368], Loss: 2.144938, Acc:0.789940, Semantic loss: 0.802599, BCE loss: 0.562632, SB loss: 0.779707
2023-10-30 01:01:02,927 Epoch: [43/484] Iter:[420/495], Time: 0.38, lr: [0.009180813297227301], Loss: 2.149789, Acc:0.789721, Semantic loss: 0.806664, BCE loss: 0.562644, SB loss: 0.780481
2023-10-30 01:01:06,829 Epoch: [43/484] Iter:[430/495], Time: 0.38, lr: [0.009180434054499594], Loss: 2.147167, Acc:0.789829, Semantic loss: 0.804687, BCE loss: 0.563071, SB loss: 0.779409
2023-10-30 01:01:10,525 Epoch: [43/484] Iter:[440/495], Time: 0.38, lr: [0.00918005481003116], Loss: 2.147436, Acc:0.789833, Semantic loss: 0.805267, BCE loss: 0.562967, SB loss: 0.779202
2023-10-30 01:01:14,332 Epoch: [43/484] Iter:[450/495], Time: 0.38, lr: [0.00917967556382191], Loss: 2.148682, Acc:0.790693, Semantic loss: 0.805673, BCE loss: 0.563906, SB loss: 0.779104
2023-10-30 01:01:18,380 Epoch: [43/484] Iter:[460/495], Time: 0.38, lr: [0.009179296315871756], Loss: 2.147499, Acc:0.791228, Semantic loss: 0.804689, BCE loss: 0.563940, SB loss: 0.778870
2023-10-30 01:01:22,159 Epoch: [43/484] Iter:[470/495], Time: 0.38, lr: [0.009178917066180611], Loss: 2.147516, Acc:0.791412, Semantic loss: 0.805220, BCE loss: 0.563132, SB loss: 0.779165
2023-10-30 01:01:26,048 Epoch: [43/484] Iter:[480/495], Time: 0.38, lr: [0.009178537814748387], Loss: 2.147958, Acc:0.791790, Semantic loss: 0.805523, BCE loss: 0.563265, SB loss: 0.779171
2023-10-30 01:01:29,559 Epoch: [43/484] Iter:[490/495], Time: 0.38, lr: [0.009178158561574997], Loss: 2.146146, Acc:0.791533, Semantic loss: 0.804506, BCE loss: 0.562823, SB loss: 0.778817
2023-10-30 01:01:30,996 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:01:31,238 Loss: 2.125, MeanIU:  0.6387, Best_mIoU:  0.6427
2023-10-30 01:01:31,238 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992]
2023-10-30 01:01:33,404 Epoch: [44/484] Iter:[0/495], Time: 2.13, lr: [0.009177968934335336], Loss: 1.671628, Acc:0.787465, Semantic loss: 0.694364, BCE loss: 0.334991, SB loss: 0.642273
2023-10-30 01:01:37,511 Epoch: [44/484] Iter:[10/495], Time: 0.57, lr: [0.00917758967855003], Loss: 2.129290, Acc:0.790772, Semantic loss: 0.834245, BCE loss: 0.502884, SB loss: 0.792162
2023-10-30 01:01:41,314 Epoch: [44/484] Iter:[20/495], Time: 0.48, lr: [0.009177210421023338], Loss: 2.109405, Acc:0.783991, Semantic loss: 0.812318, BCE loss: 0.526630, SB loss: 0.770457
2023-10-30 01:01:44,982 Epoch: [44/484] Iter:[30/495], Time: 0.44, lr: [0.00917683116175517], Loss: 2.136481, Acc:0.782578, Semantic loss: 0.824348, BCE loss: 0.527843, SB loss: 0.784290
2023-10-30 01:01:48,721 Epoch: [44/484] Iter:[40/495], Time: 0.43, lr: [0.009176451900745439], Loss: 2.132394, Acc:0.779857, Semantic loss: 0.816194, BCE loss: 0.532385, SB loss: 0.783814
2023-10-30 01:01:52,373 Epoch: [44/484] Iter:[50/495], Time: 0.41, lr: [0.009176072637994057], Loss: 2.118186, Acc:0.779724, Semantic loss: 0.796222, BCE loss: 0.543183, SB loss: 0.778781
2023-10-30 01:01:55,994 Epoch: [44/484] Iter:[60/495], Time: 0.41, lr: [0.009175693373500937], Loss: 2.105001, Acc:0.783847, Semantic loss: 0.789222, BCE loss: 0.541347, SB loss: 0.774433
2023-10-30 01:01:59,776 Epoch: [44/484] Iter:[70/495], Time: 0.40, lr: [0.00917531410726599], Loss: 2.121762, Acc:0.779046, Semantic loss: 0.799985, BCE loss: 0.538430, SB loss: 0.783346
2023-10-30 01:02:03,604 Epoch: [44/484] Iter:[80/495], Time: 0.40, lr: [0.009174934839289127], Loss: 2.128617, Acc:0.781559, Semantic loss: 0.800859, BCE loss: 0.542542, SB loss: 0.785216
2023-10-30 01:02:07,250 Epoch: [44/484] Iter:[90/495], Time: 0.40, lr: [0.009174555569570263], Loss: 2.129719, Acc:0.781160, Semantic loss: 0.799756, BCE loss: 0.548872, SB loss: 0.781091
2023-10-30 01:02:11,073 Epoch: [44/484] Iter:[100/495], Time: 0.39, lr: [0.009174176298109307], Loss: 2.134083, Acc:0.783723, Semantic loss: 0.801919, BCE loss: 0.551779, SB loss: 0.780385
2023-10-30 01:02:14,752 Epoch: [44/484] Iter:[110/495], Time: 0.39, lr: [0.009173797024906174], Loss: 2.139490, Acc:0.779687, Semantic loss: 0.810658, BCE loss: 0.549812, SB loss: 0.779020
2023-10-30 01:02:18,488 Epoch: [44/484] Iter:[120/495], Time: 0.39, lr: [0.009173417749960772], Loss: 2.147617, Acc:0.780555, Semantic loss: 0.811314, BCE loss: 0.552747, SB loss: 0.783556
2023-10-30 01:02:22,256 Epoch: [44/484] Iter:[130/495], Time: 0.39, lr: [0.009173038473273016], Loss: 2.152907, Acc:0.782325, Semantic loss: 0.812417, BCE loss: 0.557546, SB loss: 0.782944
2023-10-30 01:02:26,075 Epoch: [44/484] Iter:[140/495], Time: 0.39, lr: [0.009172659194842817], Loss: 2.153230, Acc:0.781708, Semantic loss: 0.811211, BCE loss: 0.559846, SB loss: 0.782173
2023-10-30 01:02:29,838 Epoch: [44/484] Iter:[150/495], Time: 0.39, lr: [0.009172279914670088], Loss: 2.160059, Acc:0.779784, Semantic loss: 0.816598, BCE loss: 0.558671, SB loss: 0.784790
2023-10-30 01:02:33,652 Epoch: [44/484] Iter:[160/495], Time: 0.39, lr: [0.009171900632754738], Loss: 2.161121, Acc:0.778147, Semantic loss: 0.815329, BCE loss: 0.559935, SB loss: 0.785857
2023-10-30 01:02:37,435 Epoch: [44/484] Iter:[170/495], Time: 0.39, lr: [0.009171521349096682], Loss: 2.158661, Acc:0.779308, Semantic loss: 0.816052, BCE loss: 0.558173, SB loss: 0.784435
2023-10-30 01:02:41,179 Epoch: [44/484] Iter:[180/495], Time: 0.39, lr: [0.009171142063695832], Loss: 2.165927, Acc:0.780488, Semantic loss: 0.820184, BCE loss: 0.558926, SB loss: 0.786817
2023-10-30 01:02:44,958 Epoch: [44/484] Iter:[190/495], Time: 0.39, lr: [0.009170762776552096], Loss: 2.161437, Acc:0.780244, Semantic loss: 0.821086, BCE loss: 0.555341, SB loss: 0.785011
2023-10-30 01:02:48,644 Epoch: [44/484] Iter:[200/495], Time: 0.38, lr: [0.00917038348766539], Loss: 2.163616, Acc:0.781700, Semantic loss: 0.822244, BCE loss: 0.555502, SB loss: 0.785871
2023-10-30 01:02:52,445 Epoch: [44/484] Iter:[210/495], Time: 0.38, lr: [0.009170004197035623], Loss: 2.168256, Acc:0.781085, Semantic loss: 0.825677, BCE loss: 0.553184, SB loss: 0.789396
2023-10-30 01:02:56,188 Epoch: [44/484] Iter:[220/495], Time: 0.38, lr: [0.00916962490466271], Loss: 2.166848, Acc:0.782375, Semantic loss: 0.823227, BCE loss: 0.553490, SB loss: 0.790131
2023-10-30 01:02:59,945 Epoch: [44/484] Iter:[230/495], Time: 0.38, lr: [0.009169245610546559], Loss: 2.157513, Acc:0.782504, Semantic loss: 0.818874, BCE loss: 0.551527, SB loss: 0.787113
2023-10-30 01:03:03,653 Epoch: [44/484] Iter:[240/495], Time: 0.38, lr: [0.009168866314687087], Loss: 2.161440, Acc:0.782482, Semantic loss: 0.822670, BCE loss: 0.551420, SB loss: 0.787351
2023-10-30 01:03:07,435 Epoch: [44/484] Iter:[250/495], Time: 0.38, lr: [0.009168487017084202], Loss: 2.158483, Acc:0.781509, Semantic loss: 0.819978, BCE loss: 0.550631, SB loss: 0.787874
2023-10-30 01:03:11,202 Epoch: [44/484] Iter:[260/495], Time: 0.38, lr: [0.009168107717737815], Loss: 2.160392, Acc:0.780683, Semantic loss: 0.820652, BCE loss: 0.550706, SB loss: 0.789034
2023-10-30 01:03:14,921 Epoch: [44/484] Iter:[270/495], Time: 0.38, lr: [0.009167728416647841], Loss: 2.154017, Acc:0.781562, Semantic loss: 0.815300, BCE loss: 0.552559, SB loss: 0.786158
2023-10-30 01:03:18,694 Epoch: [44/484] Iter:[280/495], Time: 0.38, lr: [0.00916734911381419], Loss: 2.155175, Acc:0.781468, Semantic loss: 0.816154, BCE loss: 0.551636, SB loss: 0.787385
2023-10-30 01:03:22,466 Epoch: [44/484] Iter:[290/495], Time: 0.38, lr: [0.009166969809236775], Loss: 2.154509, Acc:0.782335, Semantic loss: 0.815592, BCE loss: 0.551638, SB loss: 0.787278
2023-10-30 01:03:26,229 Epoch: [44/484] Iter:[300/495], Time: 0.38, lr: [0.009166590502915508], Loss: 2.153517, Acc:0.782650, Semantic loss: 0.815543, BCE loss: 0.550388, SB loss: 0.787586
2023-10-30 01:03:29,927 Epoch: [44/484] Iter:[310/495], Time: 0.38, lr: [0.009166211194850298], Loss: 2.150560, Acc:0.782662, Semantic loss: 0.815002, BCE loss: 0.549593, SB loss: 0.785965
2023-10-30 01:03:33,654 Epoch: [44/484] Iter:[320/495], Time: 0.38, lr: [0.009165831885041059], Loss: 2.149063, Acc:0.783412, Semantic loss: 0.813561, BCE loss: 0.549846, SB loss: 0.785656
2023-10-30 01:03:37,492 Epoch: [44/484] Iter:[330/495], Time: 0.38, lr: [0.009165452573487705], Loss: 2.144315, Acc:0.783790, Semantic loss: 0.811072, BCE loss: 0.548688, SB loss: 0.784554
2023-10-30 01:03:41,245 Epoch: [44/484] Iter:[340/495], Time: 0.38, lr: [0.009165073260190141], Loss: 2.157182, Acc:0.783465, Semantic loss: 0.821509, BCE loss: 0.549200, SB loss: 0.786473
2023-10-30 01:03:44,956 Epoch: [44/484] Iter:[350/495], Time: 0.38, lr: [0.009164693945148284], Loss: 2.155860, Acc:0.784461, Semantic loss: 0.821246, BCE loss: 0.548827, SB loss: 0.785787
2023-10-30 01:03:48,689 Epoch: [44/484] Iter:[360/495], Time: 0.38, lr: [0.009164314628362048], Loss: 2.157863, Acc:0.784321, Semantic loss: 0.822000, BCE loss: 0.549700, SB loss: 0.786162
2023-10-30 01:03:52,665 Epoch: [44/484] Iter:[370/495], Time: 0.38, lr: [0.009163935309831337], Loss: 2.156679, Acc:0.784308, Semantic loss: 0.821979, BCE loss: 0.548504, SB loss: 0.786196
2023-10-30 01:03:56,335 Epoch: [44/484] Iter:[380/495], Time: 0.38, lr: [0.009163555989556071], Loss: 2.156462, Acc:0.784539, Semantic loss: 0.821635, BCE loss: 0.547771, SB loss: 0.787056
2023-10-30 01:04:00,170 Epoch: [44/484] Iter:[390/495], Time: 0.38, lr: [0.009163176667536157], Loss: 2.158880, Acc:0.784327, Semantic loss: 0.822132, BCE loss: 0.549102, SB loss: 0.787646
2023-10-30 01:04:03,940 Epoch: [44/484] Iter:[400/495], Time: 0.38, lr: [0.009162797343771508], Loss: 2.157115, Acc:0.783346, Semantic loss: 0.821980, BCE loss: 0.548228, SB loss: 0.786907
2023-10-30 01:04:07,787 Epoch: [44/484] Iter:[410/495], Time: 0.38, lr: [0.009162418018262035], Loss: 2.154610, Acc:0.783174, Semantic loss: 0.819678, BCE loss: 0.548399, SB loss: 0.786533
2023-10-30 01:04:11,568 Epoch: [44/484] Iter:[420/495], Time: 0.38, lr: [0.00916203869100765], Loss: 2.157167, Acc:0.782881, Semantic loss: 0.820116, BCE loss: 0.549297, SB loss: 0.787754
2023-10-30 01:04:15,423 Epoch: [44/484] Iter:[430/495], Time: 0.38, lr: [0.009161659362008263], Loss: 2.163509, Acc:0.782544, Semantic loss: 0.822683, BCE loss: 0.551615, SB loss: 0.789211
2023-10-30 01:04:19,240 Epoch: [44/484] Iter:[440/495], Time: 0.38, lr: [0.00916128003126379], Loss: 2.161753, Acc:0.783263, Semantic loss: 0.820514, BCE loss: 0.552421, SB loss: 0.788817
2023-10-30 01:04:22,957 Epoch: [44/484] Iter:[450/495], Time: 0.38, lr: [0.00916090069877414], Loss: 2.161991, Acc:0.784781, Semantic loss: 0.820015, BCE loss: 0.553095, SB loss: 0.788881
2023-10-30 01:04:26,716 Epoch: [44/484] Iter:[460/495], Time: 0.38, lr: [0.009160521364539225], Loss: 2.160746, Acc:0.785216, Semantic loss: 0.818937, BCE loss: 0.553288, SB loss: 0.788521
2023-10-30 01:04:30,402 Epoch: [44/484] Iter:[470/495], Time: 0.38, lr: [0.009160142028558955], Loss: 2.158122, Acc:0.785996, Semantic loss: 0.817345, BCE loss: 0.552879, SB loss: 0.787898
2023-10-30 01:04:34,214 Epoch: [44/484] Iter:[480/495], Time: 0.38, lr: [0.009159762690833245], Loss: 2.157286, Acc:0.785575, Semantic loss: 0.817506, BCE loss: 0.551888, SB loss: 0.787892
2023-10-30 01:04:37,797 Epoch: [44/484] Iter:[490/495], Time: 0.38, lr: [0.009159383351362006], Loss: 2.155527, Acc:0.785366, Semantic loss: 0.816828, BCE loss: 0.550999, SB loss: 0.787700
2023-10-30 01:04:39,228 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:04:39,468 Loss: 2.125, MeanIU:  0.6387, Best_mIoU:  0.6427
2023-10-30 01:04:39,468 [0.96731885 0.76061931 0.88645175 0.34542007 0.44651428 0.54015267
 0.60635965 0.67517676 0.89391428 0.55959175 0.92100656 0.74056947
 0.52742446 0.89482923 0.42177774 0.4849844  0.26090963 0.4960808
 0.70665992]
2023-10-30 01:04:41,678 Epoch: [45/484] Iter:[0/495], Time: 2.17, lr: [0.009159193680971784], Loss: 2.533602, Acc:0.801625, Semantic loss: 0.935132, BCE loss: 0.729524, SB loss: 0.868945
2023-10-30 01:04:45,643 Epoch: [45/484] Iter:[10/495], Time: 0.56, lr: [0.009158814338882082], Loss: 2.281179, Acc:0.789384, Semantic loss: 0.872884, BCE loss: 0.602385, SB loss: 0.805910
2023-10-30 01:04:49,408 Epoch: [45/484] Iter:[20/495], Time: 0.47, lr: [0.00915843499504663], Loss: 2.224273, Acc:0.777419, Semantic loss: 0.838001, BCE loss: 0.585371, SB loss: 0.800901
2023-10-30 01:04:53,253 Epoch: [45/484] Iter:[30/495], Time: 0.44, lr: [0.009158055649465337], Loss: 2.219649, Acc:0.790200, Semantic loss: 0.837100, BCE loss: 0.589999, SB loss: 0.792549
2023-10-30 01:04:56,979 Epoch: [45/484] Iter:[40/495], Time: 0.43, lr: [0.00915767630213812], Loss: 2.182572, Acc:0.791577, Semantic loss: 0.811992, BCE loss: 0.579949, SB loss: 0.790630
2023-10-30 01:05:00,753 Epoch: [45/484] Iter:[50/495], Time: 0.42, lr: [0.009157296953064883], Loss: 2.202696, Acc:0.792359, Semantic loss: 0.837322, BCE loss: 0.576392, SB loss: 0.788982
2023-10-30 01:05:04,511 Epoch: [45/484] Iter:[60/495], Time: 0.41, lr: [0.009156917602245542], Loss: 2.215520, Acc:0.782822, Semantic loss: 0.845499, BCE loss: 0.573343, SB loss: 0.796678
2023-10-30 01:05:08,204 Epoch: [45/484] Iter:[70/495], Time: 0.40, lr: [0.00915653824968001], Loss: 2.192232, Acc:0.784048, Semantic loss: 0.830961, BCE loss: 0.568565, SB loss: 0.792706
2023-10-30 01:05:12,082 Epoch: [45/484] Iter:[80/495], Time: 0.40, lr: [0.009156158895368196], Loss: 2.191260, Acc:0.786784, Semantic loss: 0.829190, BCE loss: 0.567520, SB loss: 0.794550
2023-10-30 01:05:15,756 Epoch: [45/484] Iter:[90/495], Time: 0.40, lr: [0.00915577953931001], Loss: 2.183311, Acc:0.787817, Semantic loss: 0.826996, BCE loss: 0.561556, SB loss: 0.794759
2023-10-30 01:05:19,423 Epoch: [45/484] Iter:[100/495], Time: 0.40, lr: [0.009155400181505367], Loss: 2.170345, Acc:0.787008, Semantic loss: 0.821386, BCE loss: 0.556275, SB loss: 0.792683
2023-10-30 01:05:23,164 Epoch: [45/484] Iter:[110/495], Time: 0.39, lr: [0.009155020821954178], Loss: 2.178609, Acc:0.784337, Semantic loss: 0.832573, BCE loss: 0.551917, SB loss: 0.794120
2023-10-30 01:05:26,919 Epoch: [45/484] Iter:[120/495], Time: 0.39, lr: [0.009154641460656355], Loss: 2.188254, Acc:0.786509, Semantic loss: 0.833239, BCE loss: 0.559244, SB loss: 0.795771
2023-10-30 01:05:30,690 Epoch: [45/484] Iter:[130/495], Time: 0.39, lr: [0.009154262097611806], Loss: 2.165162, Acc:0.786788, Semantic loss: 0.821758, BCE loss: 0.552924, SB loss: 0.790479
2023-10-30 01:05:34,481 Epoch: [45/484] Iter:[140/495], Time: 0.39, lr: [0.009153882732820445], Loss: 2.179130, Acc:0.785605, Semantic loss: 0.829523, BCE loss: 0.553559, SB loss: 0.796047
2023-10-30 01:05:38,189 Epoch: [45/484] Iter:[150/495], Time: 0.39, lr: [0.009153503366282184], Loss: 2.179535, Acc:0.784684, Semantic loss: 0.828789, BCE loss: 0.554848, SB loss: 0.795897
2023-10-30 01:05:42,053 Epoch: [45/484] Iter:[160/495], Time: 0.39, lr: [0.009153123997996934], Loss: 2.171429, Acc:0.787353, Semantic loss: 0.821568, BCE loss: 0.558241, SB loss: 0.791621
2023-10-30 01:05:45,795 Epoch: [45/484] Iter:[170/495], Time: 0.39, lr: [0.009152744627964607], Loss: 2.183543, Acc:0.787391, Semantic loss: 0.829563, BCE loss: 0.560127, SB loss: 0.793854
2023-10-30 01:05:49,582 Epoch: [45/484] Iter:[180/495], Time: 0.39, lr: [0.009152365256185114], Loss: 2.174895, Acc:0.786687, Semantic loss: 0.823400, BCE loss: 0.560364, SB loss: 0.791131
2023-10-30 01:05:53,419 Epoch: [45/484] Iter:[190/495], Time: 0.39, lr: [0.009151985882658366], Loss: 2.182401, Acc:0.788899, Semantic loss: 0.827726, BCE loss: 0.563714, SB loss: 0.790960
2023-10-30 01:05:57,228 Epoch: [45/484] Iter:[200/495], Time: 0.39, lr: [0.009151606507384275], Loss: 2.172589, Acc:0.789454, Semantic loss: 0.822808, BCE loss: 0.562427, SB loss: 0.787354
2023-10-30 01:06:00,943 Epoch: [45/484] Iter:[210/495], Time: 0.39, lr: [0.00915122713036275], Loss: 2.172852, Acc:0.791522, Semantic loss: 0.821736, BCE loss: 0.564020, SB loss: 0.787096
2023-10-30 01:06:04,682 Epoch: [45/484] Iter:[220/495], Time: 0.39, lr: [0.009150847751593708], Loss: 2.170595, Acc:0.791393, Semantic loss: 0.820989, BCE loss: 0.563710, SB loss: 0.785897
2023-10-30 01:06:08,470 Epoch: [45/484] Iter:[230/495], Time: 0.39, lr: [0.009150468371077056], Loss: 2.169980, Acc:0.789948, Semantic loss: 0.823893, BCE loss: 0.561433, SB loss: 0.784653
2023-10-30 01:06:12,200 Epoch: [45/484] Iter:[240/495], Time: 0.38, lr: [0.009150088988812708], Loss: 2.170620, Acc:0.790355, Semantic loss: 0.822949, BCE loss: 0.563485, SB loss: 0.784186
2023-10-30 01:06:15,928 Epoch: [45/484] Iter:[250/495], Time: 0.38, lr: [0.009149709604800571], Loss: 2.169009, Acc:0.790635, Semantic loss: 0.822505, BCE loss: 0.563335, SB loss: 0.783169
2023-10-30 01:06:19,705 Epoch: [45/484] Iter:[260/495], Time: 0.38, lr: [0.009149330219040562], Loss: 2.170377, Acc:0.790085, Semantic loss: 0.824861, BCE loss: 0.562275, SB loss: 0.783241
2023-10-30 01:06:23,356 Epoch: [45/484] Iter:[270/495], Time: 0.38, lr: [0.00914895083153259], Loss: 2.167773, Acc:0.790197, Semantic loss: 0.822946, BCE loss: 0.560758, SB loss: 0.784070
2023-10-30 01:06:27,064 Epoch: [45/484] Iter:[280/495], Time: 0.38, lr: [0.009148571442276567], Loss: 2.173423, Acc:0.788702, Semantic loss: 0.826628, BCE loss: 0.562041, SB loss: 0.784753
2023-10-30 01:06:30,942 Epoch: [45/484] Iter:[290/495], Time: 0.38, lr: [0.0091481920512724], Loss: 2.173117, Acc:0.788207, Semantic loss: 0.827884, BCE loss: 0.560700, SB loss: 0.784532
2023-10-30 01:06:34,708 Epoch: [45/484] Iter:[300/495], Time: 0.38, lr: [0.009147812658520008], Loss: 2.178110, Acc:0.789021, Semantic loss: 0.827696, BCE loss: 0.564839, SB loss: 0.785575
2023-10-30 01:06:38,523 Epoch: [45/484] Iter:[310/495], Time: 0.38, lr: [0.009147433264019298], Loss: 2.182962, Acc:0.787656, Semantic loss: 0.832231, BCE loss: 0.564646, SB loss: 0.786085
2023-10-30 01:06:42,266 Epoch: [45/484] Iter:[320/495], Time: 0.38, lr: [0.009147053867770183], Loss: 2.179414, Acc:0.787305, Semantic loss: 0.831056, BCE loss: 0.562310, SB loss: 0.786048
2023-10-30 01:06:46,052 Epoch: [45/484] Iter:[330/495], Time: 0.38, lr: [0.00914667446977257], Loss: 2.181254, Acc:0.787238, Semantic loss: 0.831345, BCE loss: 0.563136, SB loss: 0.786773
2023-10-30 01:06:49,773 Epoch: [45/484] Iter:[340/495], Time: 0.38, lr: [0.009146295070026374], Loss: 2.181844, Acc:0.786742, Semantic loss: 0.833067, BCE loss: 0.562031, SB loss: 0.786746
2023-10-30 01:06:53,502 Epoch: [45/484] Iter:[350/495], Time: 0.38, lr: [0.009145915668531509], Loss: 2.176407, Acc:0.786815, Semantic loss: 0.829845, BCE loss: 0.560560, SB loss: 0.786002
2023-10-30 01:06:57,244 Epoch: [45/484] Iter:[360/495], Time: 0.38, lr: [0.009145536265287881], Loss: 2.176282, Acc:0.786664, Semantic loss: 0.830392, BCE loss: 0.559060, SB loss: 0.786830
2023-10-30 01:07:01,093 Epoch: [45/484] Iter:[370/495], Time: 0.38, lr: [0.009145156860295404], Loss: 2.174866, Acc:0.786017, Semantic loss: 0.830248, BCE loss: 0.558622, SB loss: 0.785995
2023-10-30 01:07:04,788 Epoch: [45/484] Iter:[380/495], Time: 0.38, lr: [0.00914477745355399], Loss: 2.171526, Acc:0.786934, Semantic loss: 0.828540, BCE loss: 0.557400, SB loss: 0.785586
2023-10-30 01:07:08,510 Epoch: [45/484] Iter:[390/495], Time: 0.38, lr: [0.009144398045063548], Loss: 2.174597, Acc:0.786809, Semantic loss: 0.830350, BCE loss: 0.558239, SB loss: 0.786008
2023-10-30 01:07:12,386 Epoch: [45/484] Iter:[400/495], Time: 0.38, lr: [0.00914401863482399], Loss: 2.172717, Acc:0.786775, Semantic loss: 0.829781, BCE loss: 0.557080, SB loss: 0.785856
2023-10-30 01:07:16,252 Epoch: [45/484] Iter:[410/495], Time: 0.38, lr: [0.00914363922283523], Loss: 2.174483, Acc:0.787050, Semantic loss: 0.830457, BCE loss: 0.557875, SB loss: 0.786151
2023-10-30 01:07:19,962 Epoch: [45/484] Iter:[420/495], Time: 0.38, lr: [0.009143259809097177], Loss: 2.174650, Acc:0.786686, Semantic loss: 0.830797, BCE loss: 0.557562, SB loss: 0.786291
2023-10-30 01:07:23,776 Epoch: [45/484] Iter:[430/495], Time: 0.38, lr: [0.009142880393609741], Loss: 2.176781, Acc:0.787464, Semantic loss: 0.831339, BCE loss: 0.559933, SB loss: 0.785508
2023-10-30 01:07:27,621 Epoch: [45/484] Iter:[440/495], Time: 0.38, lr: [0.009142500976372838], Loss: 2.177757, Acc:0.787280, Semantic loss: 0.832628, BCE loss: 0.559642, SB loss: 0.785486
2023-10-30 01:07:31,417 Epoch: [45/484] Iter:[450/495], Time: 0.38, lr: [0.009142121557386371], Loss: 2.180139, Acc:0.787831, Semantic loss: 0.833252, BCE loss: 0.561135, SB loss: 0.785752
2023-10-30 01:07:35,277 Epoch: [45/484] Iter:[460/495], Time: 0.38, lr: [0.00914174213665026], Loss: 2.180268, Acc:0.788069, Semantic loss: 0.832897, BCE loss: 0.561089, SB loss: 0.786282
2023-10-30 01:07:39,117 Epoch: [45/484] Iter:[470/495], Time: 0.38, lr: [0.00914136271416441], Loss: 2.180862, Acc:0.787913, Semantic loss: 0.833011, BCE loss: 0.561358, SB loss: 0.786492
2023-10-30 01:07:43,009 Epoch: [45/484] Iter:[480/495], Time: 0.38, lr: [0.009140983289928736], Loss: 2.183265, Acc:0.788191, Semantic loss: 0.834526, BCE loss: 0.561606, SB loss: 0.787133
2023-10-30 01:07:46,556 Epoch: [45/484] Iter:[490/495], Time: 0.38, lr: [0.009140603863943149], Loss: 2.178088, Acc:0.788078, Semantic loss: 0.832032, BCE loss: 0.559793, SB loss: 0.786263
2023-10-30 01:10:46,033 0 [9.21164612e-01 5.91282569e-01 7.96393307e-01 9.96441549e-02
 1.95562606e-01 3.91860720e-01 3.63059174e-01 5.27909602e-01
 8.40628802e-01 3.42449672e-01 8.54482759e-01 5.56721442e-01
 1.54498401e-03 7.86279400e-01 1.23178989e-05 5.41475527e-03
 1.43492320e-03 6.24274436e-03 4.84421202e-01] 0.40876367098508765
2023-10-30 01:10:46,034 1 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321] 0.6438499318101266
2023-10-30 01:10:46,037 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:10:46,401 Loss: 2.228, MeanIU:  0.6438, Best_mIoU:  0.6438
2023-10-30 01:10:46,401 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321]
2023-10-30 01:10:48,573 Epoch: [46/484] Iter:[0/495], Time: 2.14, lr: [0.00914041415029411], Loss: 2.009424, Acc:0.779351, Semantic loss: 0.709036, BCE loss: 0.590540, SB loss: 0.709848
2023-10-30 01:10:52,562 Epoch: [46/484] Iter:[10/495], Time: 0.56, lr: [0.009140034721683484], Loss: 2.133947, Acc:0.776008, Semantic loss: 0.798211, BCE loss: 0.564312, SB loss: 0.771424
2023-10-30 01:10:56,231 Epoch: [46/484] Iter:[20/495], Time: 0.47, lr: [0.009139655291322723], Loss: 2.156873, Acc:0.763346, Semantic loss: 0.797456, BCE loss: 0.581057, SB loss: 0.778360
2023-10-30 01:10:59,910 Epoch: [46/484] Iter:[30/495], Time: 0.43, lr: [0.009139275859211735], Loss: 2.122950, Acc:0.769680, Semantic loss: 0.785163, BCE loss: 0.565934, SB loss: 0.771854
2023-10-30 01:11:03,523 Epoch: [46/484] Iter:[40/495], Time: 0.42, lr: [0.009138896425350436], Loss: 2.125055, Acc:0.778928, Semantic loss: 0.794911, BCE loss: 0.562048, SB loss: 0.768096
2023-10-30 01:11:07,048 Epoch: [46/484] Iter:[50/495], Time: 0.40, lr: [0.009138516989738733], Loss: 2.131741, Acc:0.778592, Semantic loss: 0.794260, BCE loss: 0.567291, SB loss: 0.770190
2023-10-30 01:11:10,759 Epoch: [46/484] Iter:[60/495], Time: 0.40, lr: [0.00913813755237654], Loss: 2.141702, Acc:0.779976, Semantic loss: 0.809223, BCE loss: 0.557753, SB loss: 0.774726
2023-10-30 01:11:14,314 Epoch: [46/484] Iter:[70/495], Time: 0.39, lr: [0.009137758113263766], Loss: 2.180705, Acc:0.781352, Semantic loss: 0.830903, BCE loss: 0.567151, SB loss: 0.782652
2023-10-30 01:11:17,930 Epoch: [46/484] Iter:[80/495], Time: 0.39, lr: [0.009137378672400324], Loss: 2.168807, Acc:0.780575, Semantic loss: 0.823732, BCE loss: 0.565664, SB loss: 0.779410
2023-10-30 01:11:21,538 Epoch: [46/484] Iter:[90/495], Time: 0.39, lr: [0.009136999229786122], Loss: 2.181046, Acc:0.786912, Semantic loss: 0.828402, BCE loss: 0.574292, SB loss: 0.778352
2023-10-30 01:11:25,229 Epoch: [46/484] Iter:[100/495], Time: 0.38, lr: [0.009136619785421076], Loss: 2.179224, Acc:0.789689, Semantic loss: 0.826862, BCE loss: 0.571922, SB loss: 0.780440
2023-10-30 01:11:28,887 Epoch: [46/484] Iter:[110/495], Time: 0.38, lr: [0.009136240339305093], Loss: 2.166025, Acc:0.790828, Semantic loss: 0.820300, BCE loss: 0.566561, SB loss: 0.779164
2023-10-30 01:11:32,616 Epoch: [46/484] Iter:[120/495], Time: 0.38, lr: [0.009135860891438086], Loss: 2.180428, Acc:0.791463, Semantic loss: 0.824359, BCE loss: 0.572262, SB loss: 0.783806
2023-10-30 01:11:36,275 Epoch: [46/484] Iter:[130/495], Time: 0.38, lr: [0.009135481441819965], Loss: 2.179493, Acc:0.792090, Semantic loss: 0.825675, BCE loss: 0.569586, SB loss: 0.784233
2023-10-30 01:11:39,930 Epoch: [46/484] Iter:[140/495], Time: 0.38, lr: [0.009135101990450643], Loss: 2.178832, Acc:0.791841, Semantic loss: 0.823662, BCE loss: 0.567454, SB loss: 0.787716
2023-10-30 01:11:43,692 Epoch: [46/484] Iter:[150/495], Time: 0.38, lr: [0.009134722537330027], Loss: 2.183449, Acc:0.792765, Semantic loss: 0.824271, BCE loss: 0.571865, SB loss: 0.787313
2023-10-30 01:11:47,461 Epoch: [46/484] Iter:[160/495], Time: 0.38, lr: [0.009134343082458035], Loss: 2.182228, Acc:0.790846, Semantic loss: 0.822620, BCE loss: 0.572544, SB loss: 0.787065
2023-10-30 01:11:51,213 Epoch: [46/484] Iter:[170/495], Time: 0.38, lr: [0.009133963625834572], Loss: 2.186908, Acc:0.790345, Semantic loss: 0.824845, BCE loss: 0.573301, SB loss: 0.788762
2023-10-30 01:11:54,943 Epoch: [46/484] Iter:[180/495], Time: 0.38, lr: [0.009133584167459552], Loss: 2.181562, Acc:0.791132, Semantic loss: 0.821354, BCE loss: 0.573464, SB loss: 0.786745
2023-10-30 01:11:58,600 Epoch: [46/484] Iter:[190/495], Time: 0.38, lr: [0.009133204707332884], Loss: 2.182916, Acc:0.791371, Semantic loss: 0.819916, BCE loss: 0.575702, SB loss: 0.787298
2023-10-30 01:12:02,265 Epoch: [46/484] Iter:[200/495], Time: 0.38, lr: [0.009132825245454482], Loss: 2.179986, Acc:0.790961, Semantic loss: 0.819199, BCE loss: 0.575262, SB loss: 0.785524
2023-10-30 01:12:06,014 Epoch: [46/484] Iter:[210/495], Time: 0.38, lr: [0.009132445781824254], Loss: 2.174625, Acc:0.790002, Semantic loss: 0.818930, BCE loss: 0.571242, SB loss: 0.784453
2023-10-30 01:12:09,752 Epoch: [46/484] Iter:[220/495], Time: 0.38, lr: [0.009132066316442112], Loss: 2.178751, Acc:0.791654, Semantic loss: 0.822142, BCE loss: 0.570792, SB loss: 0.785817
2023-10-30 01:12:13,531 Epoch: [46/484] Iter:[230/495], Time: 0.38, lr: [0.009131686849307966], Loss: 2.180363, Acc:0.790541, Semantic loss: 0.823197, BCE loss: 0.571245, SB loss: 0.785921
2023-10-30 01:12:17,289 Epoch: [46/484] Iter:[240/495], Time: 0.38, lr: [0.00913130738042173], Loss: 2.196085, Acc:0.790210, Semantic loss: 0.833992, BCE loss: 0.574158, SB loss: 0.787935
2023-10-30 01:12:20,995 Epoch: [46/484] Iter:[250/495], Time: 0.38, lr: [0.009130927909783313], Loss: 2.202615, Acc:0.789521, Semantic loss: 0.837002, BCE loss: 0.575190, SB loss: 0.790423
2023-10-30 01:12:24,780 Epoch: [46/484] Iter:[260/495], Time: 0.38, lr: [0.009130548437392628], Loss: 2.195092, Acc:0.788465, Semantic loss: 0.832294, BCE loss: 0.573430, SB loss: 0.789368
2023-10-30 01:12:28,570 Epoch: [46/484] Iter:[270/495], Time: 0.38, lr: [0.009130168963249584], Loss: 2.194216, Acc:0.790050, Semantic loss: 0.832183, BCE loss: 0.573935, SB loss: 0.788097
2023-10-30 01:12:32,301 Epoch: [46/484] Iter:[280/495], Time: 0.38, lr: [0.00912978948735409], Loss: 2.193740, Acc:0.790954, Semantic loss: 0.830085, BCE loss: 0.575080, SB loss: 0.788575
2023-10-30 01:12:36,009 Epoch: [46/484] Iter:[290/495], Time: 0.38, lr: [0.009129410009706062], Loss: 2.187056, Acc:0.790456, Semantic loss: 0.826560, BCE loss: 0.573675, SB loss: 0.786822
2023-10-30 01:12:39,805 Epoch: [46/484] Iter:[300/495], Time: 0.38, lr: [0.009129030530305405], Loss: 2.181163, Acc:0.790974, Semantic loss: 0.823613, BCE loss: 0.572140, SB loss: 0.785410
2023-10-30 01:12:43,580 Epoch: [46/484] Iter:[310/495], Time: 0.38, lr: [0.009128651049152036], Loss: 2.179201, Acc:0.790897, Semantic loss: 0.824003, BCE loss: 0.570382, SB loss: 0.784816
2023-10-30 01:12:47,499 Epoch: [46/484] Iter:[320/495], Time: 0.38, lr: [0.009128271566245863], Loss: 2.175125, Acc:0.789776, Semantic loss: 0.823258, BCE loss: 0.567037, SB loss: 0.784830
2023-10-30 01:12:51,345 Epoch: [46/484] Iter:[330/495], Time: 0.38, lr: [0.009127892081586797], Loss: 2.177875, Acc:0.790602, Semantic loss: 0.823818, BCE loss: 0.565814, SB loss: 0.788244
2023-10-30 01:12:55,011 Epoch: [46/484] Iter:[340/495], Time: 0.38, lr: [0.009127512595174749], Loss: 2.182051, Acc:0.789372, Semantic loss: 0.823859, BCE loss: 0.566311, SB loss: 0.791882
2023-10-30 01:12:58,717 Epoch: [46/484] Iter:[350/495], Time: 0.38, lr: [0.009127133107009628], Loss: 2.180027, Acc:0.788752, Semantic loss: 0.823172, BCE loss: 0.564203, SB loss: 0.792652
2023-10-30 01:13:02,406 Epoch: [46/484] Iter:[360/495], Time: 0.38, lr: [0.009126753617091348], Loss: 2.178719, Acc:0.789158, Semantic loss: 0.822732, BCE loss: 0.563974, SB loss: 0.792013
2023-10-30 01:13:06,151 Epoch: [46/484] Iter:[370/495], Time: 0.38, lr: [0.00912637412541982], Loss: 2.180288, Acc:0.789932, Semantic loss: 0.822765, BCE loss: 0.566020, SB loss: 0.791503
2023-10-30 01:13:09,935 Epoch: [46/484] Iter:[380/495], Time: 0.38, lr: [0.009125994631994951], Loss: 2.174581, Acc:0.788893, Semantic loss: 0.820785, BCE loss: 0.563624, SB loss: 0.790172
2023-10-30 01:13:13,666 Epoch: [46/484] Iter:[390/495], Time: 0.38, lr: [0.009125615136816657], Loss: 2.174748, Acc:0.789038, Semantic loss: 0.822182, BCE loss: 0.562255, SB loss: 0.790311
2023-10-30 01:13:17,381 Epoch: [46/484] Iter:[400/495], Time: 0.38, lr: [0.009125235639884847], Loss: 2.175141, Acc:0.788902, Semantic loss: 0.822757, BCE loss: 0.561355, SB loss: 0.791029
2023-10-30 01:13:21,267 Epoch: [46/484] Iter:[410/495], Time: 0.38, lr: [0.00912485614119943], Loss: 2.173131, Acc:0.788974, Semantic loss: 0.820825, BCE loss: 0.561650, SB loss: 0.790656
2023-10-30 01:13:25,012 Epoch: [46/484] Iter:[420/495], Time: 0.38, lr: [0.00912447664076032], Loss: 2.173676, Acc:0.790468, Semantic loss: 0.821096, BCE loss: 0.562275, SB loss: 0.790305
2023-10-30 01:13:28,906 Epoch: [46/484] Iter:[430/495], Time: 0.38, lr: [0.009124097138567423], Loss: 2.171938, Acc:0.789616, Semantic loss: 0.821153, BCE loss: 0.560333, SB loss: 0.790452
2023-10-30 01:13:32,698 Epoch: [46/484] Iter:[440/495], Time: 0.38, lr: [0.009123717634620653], Loss: 2.175830, Acc:0.789700, Semantic loss: 0.823188, BCE loss: 0.560451, SB loss: 0.792190
2023-10-30 01:13:36,390 Epoch: [46/484] Iter:[450/495], Time: 0.38, lr: [0.009123338128919923], Loss: 2.176989, Acc:0.789008, Semantic loss: 0.822941, BCE loss: 0.561308, SB loss: 0.792739
2023-10-30 01:13:40,140 Epoch: [46/484] Iter:[460/495], Time: 0.38, lr: [0.009122958621465138], Loss: 2.175705, Acc:0.789308, Semantic loss: 0.821629, BCE loss: 0.561539, SB loss: 0.792537
2023-10-30 01:13:43,844 Epoch: [46/484] Iter:[470/495], Time: 0.38, lr: [0.009122579112256215], Loss: 2.175292, Acc:0.789442, Semantic loss: 0.821242, BCE loss: 0.561190, SB loss: 0.792860
2023-10-30 01:13:47,547 Epoch: [46/484] Iter:[480/495], Time: 0.38, lr: [0.009122199601293061], Loss: 2.181376, Acc:0.788088, Semantic loss: 0.825036, BCE loss: 0.561095, SB loss: 0.795246
2023-10-30 01:13:51,087 Epoch: [46/484] Iter:[490/495], Time: 0.38, lr: [0.00912182008857559], Loss: 2.179132, Acc:0.787469, Semantic loss: 0.824421, BCE loss: 0.560441, SB loss: 0.794270
2023-10-30 01:13:52,520 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:13:52,759 Loss: 2.228, MeanIU:  0.6438, Best_mIoU:  0.6438
2023-10-30 01:13:52,759 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321]
2023-10-30 01:13:54,899 Epoch: [47/484] Iter:[0/495], Time: 2.11, lr: [0.009121630331558956], Loss: 2.462700, Acc:0.892462, Semantic loss: 1.055460, BCE loss: 0.595707, SB loss: 0.811533
2023-10-30 01:13:58,943 Epoch: [47/484] Iter:[10/495], Time: 0.56, lr: [0.009121250816209838], Loss: 2.182368, Acc:0.832258, Semantic loss: 0.813041, BCE loss: 0.576206, SB loss: 0.793121
2023-10-30 01:14:02,800 Epoch: [47/484] Iter:[20/495], Time: 0.48, lr: [0.009120871299106178], Loss: 2.176573, Acc:0.815935, Semantic loss: 0.812885, BCE loss: 0.571896, SB loss: 0.791792
2023-10-30 01:14:06,625 Epoch: [47/484] Iter:[30/495], Time: 0.45, lr: [0.009120491780247887], Loss: 2.147937, Acc:0.798626, Semantic loss: 0.809911, BCE loss: 0.549368, SB loss: 0.788658
2023-10-30 01:14:10,340 Epoch: [47/484] Iter:[40/495], Time: 0.43, lr: [0.009120112259634876], Loss: 2.122228, Acc:0.795264, Semantic loss: 0.801822, BCE loss: 0.541936, SB loss: 0.778470
2023-10-30 01:14:14,016 Epoch: [47/484] Iter:[50/495], Time: 0.42, lr: [0.009119732737267053], Loss: 2.110240, Acc:0.794020, Semantic loss: 0.787594, BCE loss: 0.548396, SB loss: 0.774250
2023-10-30 01:14:17,716 Epoch: [47/484] Iter:[60/495], Time: 0.41, lr: [0.00911935321314433], Loss: 2.109662, Acc:0.798159, Semantic loss: 0.785906, BCE loss: 0.554662, SB loss: 0.769094
2023-10-30 01:14:21,471 Epoch: [47/484] Iter:[70/495], Time: 0.40, lr: [0.009118973687266623], Loss: 2.133665, Acc:0.788221, Semantic loss: 0.800439, BCE loss: 0.556777, SB loss: 0.776449
2023-10-30 01:14:25,201 Epoch: [47/484] Iter:[80/495], Time: 0.40, lr: [0.009118594159633836], Loss: 2.134694, Acc:0.789412, Semantic loss: 0.799705, BCE loss: 0.557646, SB loss: 0.777343
2023-10-30 01:14:28,943 Epoch: [47/484] Iter:[90/495], Time: 0.40, lr: [0.009118214630245881], Loss: 2.136303, Acc:0.785763, Semantic loss: 0.805722, BCE loss: 0.551816, SB loss: 0.778765
2023-10-30 01:14:32,773 Epoch: [47/484] Iter:[100/495], Time: 0.40, lr: [0.009117835099102672], Loss: 2.148782, Acc:0.788765, Semantic loss: 0.814668, BCE loss: 0.554143, SB loss: 0.779972
2023-10-30 01:14:36,542 Epoch: [47/484] Iter:[110/495], Time: 0.39, lr: [0.009117455566204117], Loss: 2.142406, Acc:0.789378, Semantic loss: 0.809034, BCE loss: 0.555490, SB loss: 0.777882
2023-10-30 01:14:40,383 Epoch: [47/484] Iter:[120/495], Time: 0.39, lr: [0.009117076031550125], Loss: 2.143527, Acc:0.787713, Semantic loss: 0.815616, BCE loss: 0.550579, SB loss: 0.777332
2023-10-30 01:14:44,104 Epoch: [47/484] Iter:[130/495], Time: 0.39, lr: [0.009116696495140611], Loss: 2.142621, Acc:0.786108, Semantic loss: 0.812764, BCE loss: 0.551779, SB loss: 0.778077
2023-10-30 01:14:47,961 Epoch: [47/484] Iter:[140/495], Time: 0.39, lr: [0.009116316956975484], Loss: 2.142725, Acc:0.785615, Semantic loss: 0.809177, BCE loss: 0.555144, SB loss: 0.778405
2023-10-30 01:14:51,763 Epoch: [47/484] Iter:[150/495], Time: 0.39, lr: [0.009115937417054654], Loss: 2.137667, Acc:0.785698, Semantic loss: 0.805762, BCE loss: 0.554759, SB loss: 0.777147
2023-10-30 01:14:55,588 Epoch: [47/484] Iter:[160/495], Time: 0.39, lr: [0.009115557875378032], Loss: 2.138997, Acc:0.784579, Semantic loss: 0.806263, BCE loss: 0.553079, SB loss: 0.779654
2023-10-30 01:14:59,256 Epoch: [47/484] Iter:[170/495], Time: 0.39, lr: [0.009115178331945526], Loss: 2.134525, Acc:0.786385, Semantic loss: 0.801975, BCE loss: 0.554889, SB loss: 0.777661
2023-10-30 01:15:02,959 Epoch: [47/484] Iter:[180/495], Time: 0.39, lr: [0.009114798786757052], Loss: 2.135655, Acc:0.785212, Semantic loss: 0.803756, BCE loss: 0.553638, SB loss: 0.778261
2023-10-30 01:15:06,582 Epoch: [47/484] Iter:[190/495], Time: 0.39, lr: [0.009114419239812517], Loss: 2.133623, Acc:0.785791, Semantic loss: 0.803059, BCE loss: 0.553264, SB loss: 0.777299
2023-10-30 01:15:10,330 Epoch: [47/484] Iter:[200/495], Time: 0.39, lr: [0.009114039691111834], Loss: 2.133890, Acc:0.784388, Semantic loss: 0.803531, BCE loss: 0.552055, SB loss: 0.778304
2023-10-30 01:15:14,041 Epoch: [47/484] Iter:[210/495], Time: 0.39, lr: [0.009113660140654909], Loss: 2.129753, Acc:0.785251, Semantic loss: 0.802123, BCE loss: 0.549776, SB loss: 0.777854
2023-10-30 01:15:17,727 Epoch: [47/484] Iter:[220/495], Time: 0.38, lr: [0.009113280588441658], Loss: 2.126429, Acc:0.782774, Semantic loss: 0.802172, BCE loss: 0.547913, SB loss: 0.776344
2023-10-30 01:15:21,541 Epoch: [47/484] Iter:[230/495], Time: 0.38, lr: [0.00911290103447199], Loss: 2.136762, Acc:0.785274, Semantic loss: 0.807175, BCE loss: 0.550922, SB loss: 0.778665
2023-10-30 01:15:25,336 Epoch: [47/484] Iter:[240/495], Time: 0.38, lr: [0.009112521478745812], Loss: 2.143897, Acc:0.784692, Semantic loss: 0.808917, BCE loss: 0.552703, SB loss: 0.782277
2023-10-30 01:15:29,244 Epoch: [47/484] Iter:[250/495], Time: 0.38, lr: [0.009112141921263039], Loss: 2.138894, Acc:0.783686, Semantic loss: 0.806329, BCE loss: 0.550353, SB loss: 0.782212
2023-10-30 01:15:33,051 Epoch: [47/484] Iter:[260/495], Time: 0.38, lr: [0.009111762362023578], Loss: 2.143985, Acc:0.784380, Semantic loss: 0.810013, BCE loss: 0.550814, SB loss: 0.783158
2023-10-30 01:15:36,766 Epoch: [47/484] Iter:[270/495], Time: 0.38, lr: [0.009111382801027345], Loss: 2.141764, Acc:0.784634, Semantic loss: 0.809963, BCE loss: 0.548835, SB loss: 0.782965
2023-10-30 01:15:40,512 Epoch: [47/484] Iter:[280/495], Time: 0.38, lr: [0.009111003238274245], Loss: 2.135107, Acc:0.785204, Semantic loss: 0.806325, BCE loss: 0.547917, SB loss: 0.780866
2023-10-30 01:15:44,373 Epoch: [47/484] Iter:[290/495], Time: 0.38, lr: [0.009110623673764192], Loss: 2.135797, Acc:0.784783, Semantic loss: 0.807219, BCE loss: 0.547377, SB loss: 0.781201
2023-10-30 01:15:48,108 Epoch: [47/484] Iter:[300/495], Time: 0.38, lr: [0.009110244107497093], Loss: 2.135470, Acc:0.786859, Semantic loss: 0.807168, BCE loss: 0.546521, SB loss: 0.781780
2023-10-30 01:15:51,961 Epoch: [47/484] Iter:[310/495], Time: 0.38, lr: [0.009109864539472863], Loss: 2.139567, Acc:0.787056, Semantic loss: 0.808646, BCE loss: 0.548418, SB loss: 0.782504
2023-10-30 01:15:55,734 Epoch: [47/484] Iter:[320/495], Time: 0.38, lr: [0.009109484969691408], Loss: 2.136313, Acc:0.787948, Semantic loss: 0.807639, BCE loss: 0.547946, SB loss: 0.780728
2023-10-30 01:15:59,532 Epoch: [47/484] Iter:[330/495], Time: 0.38, lr: [0.009109105398152642], Loss: 2.137504, Acc:0.788226, Semantic loss: 0.806818, BCE loss: 0.549979, SB loss: 0.780707
2023-10-30 01:16:03,324 Epoch: [47/484] Iter:[340/495], Time: 0.38, lr: [0.009108725824856475], Loss: 2.137335, Acc:0.788615, Semantic loss: 0.805197, BCE loss: 0.551434, SB loss: 0.780703
2023-10-30 01:16:07,015 Epoch: [47/484] Iter:[350/495], Time: 0.38, lr: [0.009108346249802815], Loss: 2.131290, Acc:0.788238, Semantic loss: 0.802419, BCE loss: 0.550161, SB loss: 0.778711
2023-10-30 01:16:10,754 Epoch: [47/484] Iter:[360/495], Time: 0.38, lr: [0.009107966672991576], Loss: 2.131548, Acc:0.788470, Semantic loss: 0.801894, BCE loss: 0.550228, SB loss: 0.779426
2023-10-30 01:16:14,575 Epoch: [47/484] Iter:[370/495], Time: 0.38, lr: [0.009107587094422664], Loss: 2.137213, Acc:0.788947, Semantic loss: 0.804395, BCE loss: 0.552822, SB loss: 0.779995
2023-10-30 01:16:18,319 Epoch: [47/484] Iter:[380/495], Time: 0.38, lr: [0.009107207514095996], Loss: 2.134751, Acc:0.788785, Semantic loss: 0.803278, BCE loss: 0.552327, SB loss: 0.779147
2023-10-30 01:16:22,033 Epoch: [47/484] Iter:[390/495], Time: 0.38, lr: [0.009106827932011476], Loss: 2.134075, Acc:0.788389, Semantic loss: 0.803096, BCE loss: 0.551924, SB loss: 0.779054
2023-10-30 01:16:25,770 Epoch: [47/484] Iter:[400/495], Time: 0.38, lr: [0.009106448348169018], Loss: 2.134841, Acc:0.788742, Semantic loss: 0.803119, BCE loss: 0.552087, SB loss: 0.779635
2023-10-30 01:16:29,589 Epoch: [47/484] Iter:[410/495], Time: 0.38, lr: [0.009106068762568531], Loss: 2.132381, Acc:0.789306, Semantic loss: 0.801464, BCE loss: 0.552051, SB loss: 0.778866
2023-10-30 01:16:33,314 Epoch: [47/484] Iter:[420/495], Time: 0.38, lr: [0.009105689175209927], Loss: 2.132545, Acc:0.788703, Semantic loss: 0.802865, BCE loss: 0.551189, SB loss: 0.778490
2023-10-30 01:16:37,092 Epoch: [47/484] Iter:[430/495], Time: 0.38, lr: [0.009105309586093114], Loss: 2.137149, Acc:0.789024, Semantic loss: 0.804922, BCE loss: 0.553142, SB loss: 0.779085
2023-10-30 01:16:40,848 Epoch: [47/484] Iter:[440/495], Time: 0.38, lr: [0.009104929995218003], Loss: 2.133326, Acc:0.787942, Semantic loss: 0.804216, BCE loss: 0.550908, SB loss: 0.778203
2023-10-30 01:16:44,536 Epoch: [47/484] Iter:[450/495], Time: 0.38, lr: [0.009104550402584507], Loss: 2.133842, Acc:0.787795, Semantic loss: 0.804163, BCE loss: 0.551115, SB loss: 0.778564
2023-10-30 01:16:48,367 Epoch: [47/484] Iter:[460/495], Time: 0.38, lr: [0.009104170808192534], Loss: 2.131949, Acc:0.787680, Semantic loss: 0.803075, BCE loss: 0.550948, SB loss: 0.777925
2023-10-30 01:16:52,176 Epoch: [47/484] Iter:[470/495], Time: 0.38, lr: [0.009103791212041995], Loss: 2.134241, Acc:0.788081, Semantic loss: 0.803958, BCE loss: 0.551988, SB loss: 0.778295
2023-10-30 01:16:55,904 Epoch: [47/484] Iter:[480/495], Time: 0.38, lr: [0.0091034116141328], Loss: 2.135111, Acc:0.788259, Semantic loss: 0.804310, BCE loss: 0.552825, SB loss: 0.777976
2023-10-30 01:16:59,464 Epoch: [47/484] Iter:[490/495], Time: 0.38, lr: [0.00910303201446486], Loss: 2.135560, Acc:0.788853, Semantic loss: 0.804864, BCE loss: 0.552682, SB loss: 0.778013
2023-10-30 01:17:00,897 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:17:01,140 Loss: 2.228, MeanIU:  0.6438, Best_mIoU:  0.6438
2023-10-30 01:17:01,140 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321]
2023-10-30 01:17:03,394 Epoch: [48/484] Iter:[0/495], Time: 2.21, lr: [0.009102842213971334], Loss: 1.827482, Acc:0.651790, Semantic loss: 0.746743, BCE loss: 0.331568, SB loss: 0.749171
2023-10-30 01:17:07,532 Epoch: [48/484] Iter:[10/495], Time: 0.58, lr: [0.009102462611665108], Loss: 2.055320, Acc:0.809085, Semantic loss: 0.732389, BCE loss: 0.563551, SB loss: 0.759379
2023-10-30 01:17:11,388 Epoch: [48/484] Iter:[20/495], Time: 0.49, lr: [0.009102083007599912], Loss: 2.017444, Acc:0.791426, Semantic loss: 0.732699, BCE loss: 0.542091, SB loss: 0.742653
2023-10-30 01:17:15,192 Epoch: [48/484] Iter:[30/495], Time: 0.45, lr: [0.009101703401775657], Loss: 2.064867, Acc:0.793965, Semantic loss: 0.753858, BCE loss: 0.558912, SB loss: 0.752097
2023-10-30 01:17:18,972 Epoch: [48/484] Iter:[40/495], Time: 0.43, lr: [0.009101323794192255], Loss: 2.065275, Acc:0.791718, Semantic loss: 0.748602, BCE loss: 0.563914, SB loss: 0.752758
2023-10-30 01:17:22,703 Epoch: [48/484] Iter:[50/495], Time: 0.42, lr: [0.009100944184849613], Loss: 2.075146, Acc:0.788245, Semantic loss: 0.757257, BCE loss: 0.562829, SB loss: 0.755060
2023-10-30 01:17:26,398 Epoch: [48/484] Iter:[60/495], Time: 0.41, lr: [0.009100564573747643], Loss: 2.070178, Acc:0.788156, Semantic loss: 0.763642, BCE loss: 0.551046, SB loss: 0.755490
2023-10-30 01:17:30,204 Epoch: [48/484] Iter:[70/495], Time: 0.41, lr: [0.009100184960886257], Loss: 2.061960, Acc:0.788168, Semantic loss: 0.766237, BCE loss: 0.545150, SB loss: 0.750573
2023-10-30 01:17:33,968 Epoch: [48/484] Iter:[80/495], Time: 0.40, lr: [0.009099805346265361], Loss: 2.059663, Acc:0.789648, Semantic loss: 0.770033, BCE loss: 0.538409, SB loss: 0.751221
2023-10-30 01:17:37,805 Epoch: [48/484] Iter:[90/495], Time: 0.40, lr: [0.009099425729884869], Loss: 2.059330, Acc:0.790634, Semantic loss: 0.769912, BCE loss: 0.540531, SB loss: 0.748887
2023-10-30 01:17:41,553 Epoch: [48/484] Iter:[100/495], Time: 0.40, lr: [0.00909904611174469], Loss: 2.046486, Acc:0.792736, Semantic loss: 0.761821, BCE loss: 0.538649, SB loss: 0.746016
2023-10-30 01:17:45,349 Epoch: [48/484] Iter:[110/495], Time: 0.40, lr: [0.009098666491844733], Loss: 2.066597, Acc:0.785354, Semantic loss: 0.775828, BCE loss: 0.536822, SB loss: 0.753947
2023-10-30 01:17:49,124 Epoch: [48/484] Iter:[120/495], Time: 0.40, lr: [0.009098286870184913], Loss: 2.059268, Acc:0.786167, Semantic loss: 0.772696, BCE loss: 0.533142, SB loss: 0.753431
2023-10-30 01:17:52,935 Epoch: [48/484] Iter:[130/495], Time: 0.40, lr: [0.009097907246765135], Loss: 2.070223, Acc:0.786628, Semantic loss: 0.778526, BCE loss: 0.535847, SB loss: 0.755850
2023-10-30 01:17:56,691 Epoch: [48/484] Iter:[140/495], Time: 0.39, lr: [0.00909752762158531], Loss: 2.069600, Acc:0.785514, Semantic loss: 0.778221, BCE loss: 0.536909, SB loss: 0.754470
2023-10-30 01:18:00,463 Epoch: [48/484] Iter:[150/495], Time: 0.39, lr: [0.00909714799464535], Loss: 2.091245, Acc:0.785485, Semantic loss: 0.786886, BCE loss: 0.542364, SB loss: 0.761994
2023-10-30 01:18:04,231 Epoch: [48/484] Iter:[160/495], Time: 0.39, lr: [0.009096768365945165], Loss: 2.091628, Acc:0.785328, Semantic loss: 0.785951, BCE loss: 0.543202, SB loss: 0.762475
2023-10-30 01:18:07,970 Epoch: [48/484] Iter:[170/495], Time: 0.39, lr: [0.009096388735484665], Loss: 2.094903, Acc:0.785809, Semantic loss: 0.787377, BCE loss: 0.545005, SB loss: 0.762521
2023-10-30 01:18:11,665 Epoch: [48/484] Iter:[180/495], Time: 0.39, lr: [0.009096009103263759], Loss: 2.085075, Acc:0.783428, Semantic loss: 0.781428, BCE loss: 0.543199, SB loss: 0.760448
2023-10-30 01:18:15,479 Epoch: [48/484] Iter:[190/495], Time: 0.39, lr: [0.009095629469282359], Loss: 2.086809, Acc:0.782298, Semantic loss: 0.782392, BCE loss: 0.542642, SB loss: 0.761775
2023-10-30 01:18:19,240 Epoch: [48/484] Iter:[200/495], Time: 0.39, lr: [0.009095249833540374], Loss: 2.083691, Acc:0.783199, Semantic loss: 0.780953, BCE loss: 0.540478, SB loss: 0.762261
2023-10-30 01:18:23,130 Epoch: [48/484] Iter:[210/495], Time: 0.39, lr: [0.009094870196037715], Loss: 2.091391, Acc:0.784550, Semantic loss: 0.783697, BCE loss: 0.544623, SB loss: 0.763071
2023-10-30 01:18:26,980 Epoch: [48/484] Iter:[220/495], Time: 0.39, lr: [0.009094490556774292], Loss: 2.096947, Acc:0.786559, Semantic loss: 0.787971, BCE loss: 0.546567, SB loss: 0.762408
2023-10-30 01:18:30,767 Epoch: [48/484] Iter:[230/495], Time: 0.39, lr: [0.009094110915750013], Loss: 2.097738, Acc:0.786883, Semantic loss: 0.789522, BCE loss: 0.545269, SB loss: 0.762947
2023-10-30 01:18:34,517 Epoch: [48/484] Iter:[240/495], Time: 0.39, lr: [0.009093731272964792], Loss: 2.111708, Acc:0.786301, Semantic loss: 0.799175, BCE loss: 0.545320, SB loss: 0.767213
2023-10-30 01:18:38,437 Epoch: [48/484] Iter:[250/495], Time: 0.39, lr: [0.009093351628418537], Loss: 2.114807, Acc:0.785625, Semantic loss: 0.798828, BCE loss: 0.545385, SB loss: 0.770594
2023-10-30 01:18:42,320 Epoch: [48/484] Iter:[260/495], Time: 0.39, lr: [0.009092971982111156], Loss: 2.126261, Acc:0.784058, Semantic loss: 0.807634, BCE loss: 0.544660, SB loss: 0.773967
2023-10-30 01:18:46,087 Epoch: [48/484] Iter:[270/495], Time: 0.39, lr: [0.009092592334042564], Loss: 2.128244, Acc:0.784529, Semantic loss: 0.808356, BCE loss: 0.544282, SB loss: 0.775606
2023-10-30 01:18:49,919 Epoch: [48/484] Iter:[280/495], Time: 0.39, lr: [0.009092212684212668], Loss: 2.130093, Acc:0.785430, Semantic loss: 0.808897, BCE loss: 0.544928, SB loss: 0.776267
2023-10-30 01:18:53,680 Epoch: [48/484] Iter:[290/495], Time: 0.39, lr: [0.00909183303262138], Loss: 2.131077, Acc:0.785038, Semantic loss: 0.809348, BCE loss: 0.544899, SB loss: 0.776830
2023-10-30 01:18:57,426 Epoch: [48/484] Iter:[300/495], Time: 0.39, lr: [0.009091453379268605], Loss: 2.124235, Acc:0.785292, Semantic loss: 0.804540, BCE loss: 0.544936, SB loss: 0.774759
2023-10-30 01:19:01,200 Epoch: [48/484] Iter:[310/495], Time: 0.39, lr: [0.00909107372415426], Loss: 2.121558, Acc:0.785086, Semantic loss: 0.802996, BCE loss: 0.544870, SB loss: 0.773693
2023-10-30 01:19:04,989 Epoch: [48/484] Iter:[320/495], Time: 0.39, lr: [0.009090694067278252], Loss: 2.119343, Acc:0.785405, Semantic loss: 0.801107, BCE loss: 0.545154, SB loss: 0.773082
2023-10-30 01:19:08,818 Epoch: [48/484] Iter:[330/495], Time: 0.39, lr: [0.009090314408640492], Loss: 2.129389, Acc:0.785329, Semantic loss: 0.806348, BCE loss: 0.548342, SB loss: 0.774699
2023-10-30 01:19:12,653 Epoch: [48/484] Iter:[340/495], Time: 0.39, lr: [0.009089934748240887], Loss: 2.129150, Acc:0.785422, Semantic loss: 0.805097, BCE loss: 0.548975, SB loss: 0.775078
2023-10-30 01:19:16,490 Epoch: [48/484] Iter:[350/495], Time: 0.39, lr: [0.00908955508607935], Loss: 2.126426, Acc:0.785086, Semantic loss: 0.802175, BCE loss: 0.550062, SB loss: 0.774189
2023-10-30 01:19:20,254 Epoch: [48/484] Iter:[360/495], Time: 0.39, lr: [0.00908917542215579], Loss: 2.125495, Acc:0.785269, Semantic loss: 0.800877, BCE loss: 0.550269, SB loss: 0.774349
2023-10-30 01:19:24,022 Epoch: [48/484] Iter:[370/495], Time: 0.39, lr: [0.009088795756470118], Loss: 2.126935, Acc:0.784402, Semantic loss: 0.802024, BCE loss: 0.551188, SB loss: 0.773723
2023-10-30 01:19:27,831 Epoch: [48/484] Iter:[380/495], Time: 0.38, lr: [0.009088416089022241], Loss: 2.124908, Acc:0.784629, Semantic loss: 0.800948, BCE loss: 0.550498, SB loss: 0.773462
2023-10-30 01:19:31,664 Epoch: [48/484] Iter:[390/495], Time: 0.38, lr: [0.009088036419812073], Loss: 2.128274, Acc:0.785548, Semantic loss: 0.802487, BCE loss: 0.552444, SB loss: 0.773343
2023-10-30 01:19:35,450 Epoch: [48/484] Iter:[400/495], Time: 0.38, lr: [0.009087656748839523], Loss: 2.128238, Acc:0.785571, Semantic loss: 0.803058, BCE loss: 0.552456, SB loss: 0.772724
2023-10-30 01:19:39,302 Epoch: [48/484] Iter:[410/495], Time: 0.38, lr: [0.0090872770761045], Loss: 2.127967, Acc:0.784856, Semantic loss: 0.803896, BCE loss: 0.551002, SB loss: 0.773070
2023-10-30 01:19:43,179 Epoch: [48/484] Iter:[420/495], Time: 0.38, lr: [0.009086897401606913], Loss: 2.127743, Acc:0.785587, Semantic loss: 0.802066, BCE loss: 0.552812, SB loss: 0.772865
2023-10-30 01:19:47,005 Epoch: [48/484] Iter:[430/495], Time: 0.38, lr: [0.009086517725346674], Loss: 2.131336, Acc:0.785608, Semantic loss: 0.804569, BCE loss: 0.552748, SB loss: 0.774020
2023-10-30 01:19:50,789 Epoch: [48/484] Iter:[440/495], Time: 0.38, lr: [0.009086138047323694], Loss: 2.129094, Acc:0.786350, Semantic loss: 0.802684, BCE loss: 0.552750, SB loss: 0.773660
2023-10-30 01:19:54,580 Epoch: [48/484] Iter:[450/495], Time: 0.38, lr: [0.009085758367537881], Loss: 2.136143, Acc:0.785905, Semantic loss: 0.804434, BCE loss: 0.556437, SB loss: 0.775271
2023-10-30 01:19:58,293 Epoch: [48/484] Iter:[460/495], Time: 0.38, lr: [0.009085378685989144], Loss: 2.139370, Acc:0.785275, Semantic loss: 0.807027, BCE loss: 0.556474, SB loss: 0.775869
2023-10-30 01:20:02,064 Epoch: [48/484] Iter:[470/495], Time: 0.38, lr: [0.009084999002677395], Loss: 2.140202, Acc:0.785551, Semantic loss: 0.807065, BCE loss: 0.557422, SB loss: 0.775715
2023-10-30 01:20:05,992 Epoch: [48/484] Iter:[480/495], Time: 0.38, lr: [0.009084619317602542], Loss: 2.139106, Acc:0.785733, Semantic loss: 0.807503, BCE loss: 0.555750, SB loss: 0.775853
2023-10-30 01:20:09,519 Epoch: [48/484] Iter:[490/495], Time: 0.38, lr: [0.009084239630764497], Loss: 2.139732, Acc:0.785957, Semantic loss: 0.808194, BCE loss: 0.555463, SB loss: 0.776075
2023-10-30 01:20:10,946 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:20:11,187 Loss: 2.228, MeanIU:  0.6438, Best_mIoU:  0.6438
2023-10-30 01:20:11,187 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321]
2023-10-30 01:20:13,269 Epoch: [49/484] Iter:[0/495], Time: 2.05, lr: [0.00908404978668425], Loss: 1.802720, Acc:0.808261, Semantic loss: 0.671078, BCE loss: 0.477120, SB loss: 0.654522
2023-10-30 01:20:17,260 Epoch: [49/484] Iter:[10/495], Time: 0.55, lr: [0.009083670097201246], Loss: 2.048215, Acc:0.793439, Semantic loss: 0.751168, BCE loss: 0.532215, SB loss: 0.764832
2023-10-30 01:20:21,075 Epoch: [49/484] Iter:[20/495], Time: 0.47, lr: [0.009083290405954824], Loss: 2.104821, Acc:0.804946, Semantic loss: 0.774128, BCE loss: 0.561905, SB loss: 0.768788
2023-10-30 01:20:24,810 Epoch: [49/484] Iter:[30/495], Time: 0.44, lr: [0.009082910712944894], Loss: 2.087134, Acc:0.798434, Semantic loss: 0.771220, BCE loss: 0.556115, SB loss: 0.759800
2023-10-30 01:20:28,462 Epoch: [49/484] Iter:[40/495], Time: 0.42, lr: [0.009082531018171367], Loss: 2.110588, Acc:0.805684, Semantic loss: 0.779398, BCE loss: 0.562047, SB loss: 0.769143
2023-10-30 01:20:32,225 Epoch: [49/484] Iter:[50/495], Time: 0.41, lr: [0.00908215132163415], Loss: 2.108023, Acc:0.793589, Semantic loss: 0.786980, BCE loss: 0.554373, SB loss: 0.766669
2023-10-30 01:20:35,979 Epoch: [49/484] Iter:[60/495], Time: 0.41, lr: [0.009081771623333155], Loss: 2.084338, Acc:0.796971, Semantic loss: 0.776571, BCE loss: 0.546105, SB loss: 0.761662
2023-10-30 01:20:39,797 Epoch: [49/484] Iter:[70/495], Time: 0.40, lr: [0.009081391923268291], Loss: 2.108293, Acc:0.796673, Semantic loss: 0.783888, BCE loss: 0.557931, SB loss: 0.766473
2023-10-30 01:20:43,492 Epoch: [49/484] Iter:[80/495], Time: 0.40, lr: [0.00908101222143947], Loss: 2.106623, Acc:0.792981, Semantic loss: 0.790110, BCE loss: 0.545426, SB loss: 0.771087
2023-10-30 01:20:47,206 Epoch: [49/484] Iter:[90/495], Time: 0.40, lr: [0.009080632517846599], Loss: 2.139023, Acc:0.793365, Semantic loss: 0.807258, BCE loss: 0.556780, SB loss: 0.774986
2023-10-30 01:20:50,899 Epoch: [49/484] Iter:[100/495], Time: 0.39, lr: [0.009080252812489588], Loss: 2.130814, Acc:0.786247, Semantic loss: 0.805143, BCE loss: 0.550098, SB loss: 0.775574
2023-10-30 01:20:54,649 Epoch: [49/484] Iter:[110/495], Time: 0.39, lr: [0.00907987310536835], Loss: 2.129641, Acc:0.784244, Semantic loss: 0.802521, BCE loss: 0.551589, SB loss: 0.775530
2023-10-30 01:20:58,361 Epoch: [49/484] Iter:[120/495], Time: 0.39, lr: [0.00907949339648279], Loss: 2.149277, Acc:0.784454, Semantic loss: 0.817000, BCE loss: 0.552694, SB loss: 0.779583
2023-10-30 01:21:02,124 Epoch: [49/484] Iter:[130/495], Time: 0.39, lr: [0.00907911368583282], Loss: 2.154110, Acc:0.782948, Semantic loss: 0.821447, BCE loss: 0.552165, SB loss: 0.780498
2023-10-30 01:21:05,952 Epoch: [49/484] Iter:[140/495], Time: 0.39, lr: [0.009078733973418353], Loss: 2.176045, Acc:0.782418, Semantic loss: 0.827653, BCE loss: 0.561525, SB loss: 0.786867
2023-10-30 01:21:09,733 Epoch: [49/484] Iter:[150/495], Time: 0.39, lr: [0.009078354259239295], Loss: 2.170816, Acc:0.781158, Semantic loss: 0.825853, BCE loss: 0.558534, SB loss: 0.786428
2023-10-30 01:21:13,531 Epoch: [49/484] Iter:[160/495], Time: 0.39, lr: [0.009077974543295557], Loss: 2.164682, Acc:0.780063, Semantic loss: 0.825542, BCE loss: 0.554306, SB loss: 0.784834
2023-10-30 01:21:17,286 Epoch: [49/484] Iter:[170/495], Time: 0.39, lr: [0.009077594825587048], Loss: 2.159410, Acc:0.781881, Semantic loss: 0.820467, BCE loss: 0.553673, SB loss: 0.785270
2023-10-30 01:21:20,981 Epoch: [49/484] Iter:[180/495], Time: 0.39, lr: [0.009077215106113678], Loss: 2.159934, Acc:0.781205, Semantic loss: 0.820712, BCE loss: 0.552444, SB loss: 0.786778
2023-10-30 01:21:24,750 Epoch: [49/484] Iter:[190/495], Time: 0.38, lr: [0.009076835384875357], Loss: 2.160772, Acc:0.783423, Semantic loss: 0.819585, BCE loss: 0.553213, SB loss: 0.787974
2023-10-30 01:21:28,561 Epoch: [49/484] Iter:[200/495], Time: 0.38, lr: [0.009076455661871997], Loss: 2.153590, Acc:0.784815, Semantic loss: 0.816864, BCE loss: 0.552360, SB loss: 0.784366
2023-10-30 01:21:32,253 Epoch: [49/484] Iter:[210/495], Time: 0.38, lr: [0.009076075937103504], Loss: 2.155169, Acc:0.782367, Semantic loss: 0.819336, BCE loss: 0.548507, SB loss: 0.787325
2023-10-30 01:21:36,003 Epoch: [49/484] Iter:[220/495], Time: 0.38, lr: [0.00907569621056979], Loss: 2.154787, Acc:0.784619, Semantic loss: 0.818605, BCE loss: 0.549320, SB loss: 0.786862
2023-10-30 01:21:39,932 Epoch: [49/484] Iter:[230/495], Time: 0.38, lr: [0.009075316482270763], Loss: 2.153053, Acc:0.784038, Semantic loss: 0.818094, BCE loss: 0.547888, SB loss: 0.787071
2023-10-30 01:21:43,730 Epoch: [49/484] Iter:[240/495], Time: 0.38, lr: [0.009074936752206334], Loss: 2.157122, Acc:0.784267, Semantic loss: 0.819527, BCE loss: 0.548585, SB loss: 0.789010
2023-10-30 01:21:47,416 Epoch: [49/484] Iter:[250/495], Time: 0.38, lr: [0.009074557020376413], Loss: 2.156008, Acc:0.783625, Semantic loss: 0.819494, BCE loss: 0.547826, SB loss: 0.788688
2023-10-30 01:21:51,139 Epoch: [49/484] Iter:[260/495], Time: 0.38, lr: [0.009074177286780909], Loss: 2.152826, Acc:0.782966, Semantic loss: 0.817473, BCE loss: 0.547758, SB loss: 0.787594
2023-10-30 01:21:54,962 Epoch: [49/484] Iter:[270/495], Time: 0.38, lr: [0.009073797551419733], Loss: 2.152401, Acc:0.784377, Semantic loss: 0.816572, BCE loss: 0.549083, SB loss: 0.786746
2023-10-30 01:21:58,741 Epoch: [49/484] Iter:[280/495], Time: 0.38, lr: [0.009073417814292791], Loss: 2.155058, Acc:0.785587, Semantic loss: 0.816631, BCE loss: 0.550338, SB loss: 0.788090
2023-10-30 01:22:02,463 Epoch: [49/484] Iter:[290/495], Time: 0.38, lr: [0.009073038075399999], Loss: 2.154895, Acc:0.785880, Semantic loss: 0.817346, BCE loss: 0.549605, SB loss: 0.787944
2023-10-30 01:22:06,130 Epoch: [49/484] Iter:[300/495], Time: 0.38, lr: [0.00907265833474126], Loss: 2.151097, Acc:0.785169, Semantic loss: 0.814943, BCE loss: 0.550268, SB loss: 0.785886
2023-10-30 01:22:09,828 Epoch: [49/484] Iter:[310/495], Time: 0.38, lr: [0.009072278592316489], Loss: 2.153888, Acc:0.785090, Semantic loss: 0.815794, BCE loss: 0.551258, SB loss: 0.786836
2023-10-30 01:22:13,619 Epoch: [49/484] Iter:[320/495], Time: 0.38, lr: [0.00907189884812559], Loss: 2.151681, Acc:0.785876, Semantic loss: 0.814806, BCE loss: 0.550253, SB loss: 0.786622
2023-10-30 01:22:17,517 Epoch: [49/484] Iter:[330/495], Time: 0.38, lr: [0.009071519102168479], Loss: 2.152647, Acc:0.785093, Semantic loss: 0.814425, BCE loss: 0.551593, SB loss: 0.786629
2023-10-30 01:22:21,318 Epoch: [49/484] Iter:[340/495], Time: 0.38, lr: [0.00907113935444506], Loss: 2.152022, Acc:0.785456, Semantic loss: 0.813786, BCE loss: 0.552320, SB loss: 0.785916
2023-10-30 01:22:25,045 Epoch: [49/484] Iter:[350/495], Time: 0.38, lr: [0.009070759604955249], Loss: 2.152787, Acc:0.785566, Semantic loss: 0.815809, BCE loss: 0.550753, SB loss: 0.786225
2023-10-30 01:22:28,780 Epoch: [49/484] Iter:[360/495], Time: 0.38, lr: [0.009070379853698948], Loss: 2.153604, Acc:0.785581, Semantic loss: 0.816553, BCE loss: 0.550813, SB loss: 0.786239
2023-10-30 01:22:32,539 Epoch: [49/484] Iter:[370/495], Time: 0.38, lr: [0.009070000100676072], Loss: 2.153268, Acc:0.785744, Semantic loss: 0.817348, BCE loss: 0.549921, SB loss: 0.785999
2023-10-30 01:22:36,257 Epoch: [49/484] Iter:[380/495], Time: 0.38, lr: [0.009069620345886528], Loss: 2.150900, Acc:0.786532, Semantic loss: 0.814264, BCE loss: 0.551255, SB loss: 0.785381
2023-10-30 01:22:40,073 Epoch: [49/484] Iter:[390/495], Time: 0.38, lr: [0.009069240589330228], Loss: 2.156036, Acc:0.786559, Semantic loss: 0.816899, BCE loss: 0.552607, SB loss: 0.786530
2023-10-30 01:22:43,789 Epoch: [49/484] Iter:[400/495], Time: 0.38, lr: [0.009068860831007079], Loss: 2.156673, Acc:0.786582, Semantic loss: 0.816336, BCE loss: 0.553076, SB loss: 0.787261
2023-10-30 01:22:47,622 Epoch: [49/484] Iter:[410/495], Time: 0.38, lr: [0.009068481070916993], Loss: 2.153623, Acc:0.786546, Semantic loss: 0.814757, BCE loss: 0.552598, SB loss: 0.786268
2023-10-30 01:22:51,375 Epoch: [49/484] Iter:[420/495], Time: 0.38, lr: [0.009068101309059877], Loss: 2.153462, Acc:0.786558, Semantic loss: 0.814984, BCE loss: 0.551368, SB loss: 0.787110
2023-10-30 01:22:55,110 Epoch: [49/484] Iter:[430/495], Time: 0.38, lr: [0.009067721545435642], Loss: 2.153781, Acc:0.785947, Semantic loss: 0.815811, BCE loss: 0.551065, SB loss: 0.786905
2023-10-30 01:22:58,879 Epoch: [49/484] Iter:[440/495], Time: 0.38, lr: [0.009067341780044197], Loss: 2.152747, Acc:0.786069, Semantic loss: 0.815015, BCE loss: 0.551141, SB loss: 0.786591
2023-10-30 01:23:02,830 Epoch: [49/484] Iter:[450/495], Time: 0.38, lr: [0.009066962012885453], Loss: 2.152032, Acc:0.786328, Semantic loss: 0.813781, BCE loss: 0.551911, SB loss: 0.786340
2023-10-30 01:23:06,533 Epoch: [49/484] Iter:[460/495], Time: 0.38, lr: [0.009066582243959318], Loss: 2.152696, Acc:0.786746, Semantic loss: 0.813529, BCE loss: 0.552875, SB loss: 0.786292
2023-10-30 01:23:10,237 Epoch: [49/484] Iter:[470/495], Time: 0.38, lr: [0.009066202473265702], Loss: 2.152506, Acc:0.786938, Semantic loss: 0.813436, BCE loss: 0.552514, SB loss: 0.786557
2023-10-30 01:23:13,946 Epoch: [49/484] Iter:[480/495], Time: 0.38, lr: [0.009065822700804515], Loss: 2.160852, Acc:0.786882, Semantic loss: 0.818605, BCE loss: 0.553337, SB loss: 0.788910
2023-10-30 01:23:17,495 Epoch: [49/484] Iter:[490/495], Time: 0.38, lr: [0.009065442926575665], Loss: 2.162759, Acc:0.787099, Semantic loss: 0.819542, BCE loss: 0.554081, SB loss: 0.789136
2023-10-30 01:23:18,925 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:23:19,161 Loss: 2.228, MeanIU:  0.6438, Best_mIoU:  0.6438
2023-10-30 01:23:19,161 [0.96507497 0.77469284 0.88612804 0.35143659 0.50394176 0.52258947
 0.56774131 0.67735487 0.87926389 0.53546872 0.93126511 0.71788404
 0.53318284 0.91089331 0.42054195 0.59430857 0.30575794 0.47613927
 0.67948321]
2023-10-30 01:23:21,120 Epoch: [50/484] Iter:[0/495], Time: 1.92, lr: [0.00906525303879834], Loss: 1.590590, Acc:0.666687, Semantic loss: 0.629153, BCE loss: 0.339916, SB loss: 0.621521
2023-10-30 01:23:25,207 Epoch: [50/484] Iter:[10/495], Time: 0.55, lr: [0.009064873261917827], Loss: 2.078365, Acc:0.786999, Semantic loss: 0.749410, BCE loss: 0.572097, SB loss: 0.756858
2023-10-30 01:23:28,937 Epoch: [50/484] Iter:[20/495], Time: 0.46, lr: [0.009064493483269428], Loss: 2.142301, Acc:0.792600, Semantic loss: 0.793531, BCE loss: 0.576807, SB loss: 0.771963
2023-10-30 01:23:32,757 Epoch: [50/484] Iter:[30/495], Time: 0.44, lr: [0.009064113702853047], Loss: 2.105120, Acc:0.787596, Semantic loss: 0.780865, BCE loss: 0.563736, SB loss: 0.760519
2023-10-30 01:23:36,471 Epoch: [50/484] Iter:[40/495], Time: 0.42, lr: [0.0090637339206686], Loss: 2.092241, Acc:0.788835, Semantic loss: 0.781231, BCE loss: 0.558654, SB loss: 0.752356
2023-10-30 01:23:40,091 Epoch: [50/484] Iter:[50/495], Time: 0.41, lr: [0.009063354136715992], Loss: 2.133361, Acc:0.784455, Semantic loss: 0.816949, BCE loss: 0.551077, SB loss: 0.765335
2023-10-30 01:23:43,878 Epoch: [50/484] Iter:[60/495], Time: 0.40, lr: [0.009062974350995132], Loss: 2.108226, Acc:0.781915, Semantic loss: 0.814566, BCE loss: 0.529582, SB loss: 0.764077
2023-10-30 01:23:47,591 Epoch: [50/484] Iter:[70/495], Time: 0.40, lr: [0.009062594563505931], Loss: 2.107043, Acc:0.783306, Semantic loss: 0.806519, BCE loss: 0.536983, SB loss: 0.763541
2023-10-30 01:23:51,377 Epoch: [50/484] Iter:[80/495], Time: 0.40, lr: [0.0090622147742483], Loss: 2.107157, Acc:0.785556, Semantic loss: 0.799096, BCE loss: 0.543307, SB loss: 0.764754
2023-10-30 01:23:55,295 Epoch: [50/484] Iter:[90/495], Time: 0.40, lr: [0.009061834983222146], Loss: 2.100686, Acc:0.790568, Semantic loss: 0.792365, BCE loss: 0.547174, SB loss: 0.761146
2023-10-30 01:23:59,056 Epoch: [50/484] Iter:[100/495], Time: 0.39, lr: [0.009061455190427378], Loss: 2.106185, Acc:0.792155, Semantic loss: 0.796292, BCE loss: 0.549220, SB loss: 0.760673
2023-10-30 01:24:02,815 Epoch: [50/484] Iter:[110/495], Time: 0.39, lr: [0.00906107539586391], Loss: 2.122411, Acc:0.796491, Semantic loss: 0.802343, BCE loss: 0.557462, SB loss: 0.762606
2023-10-30 01:24:06,730 Epoch: [50/484] Iter:[120/495], Time: 0.39, lr: [0.009060695599531645], Loss: 2.126741, Acc:0.797082, Semantic loss: 0.801093, BCE loss: 0.562498, SB loss: 0.763150
2023-10-30 01:24:10,465 Epoch: [50/484] Iter:[130/495], Time: 0.39, lr: [0.009060315801430496], Loss: 2.145359, Acc:0.796752, Semantic loss: 0.810610, BCE loss: 0.565650, SB loss: 0.769100
2023-10-30 01:24:14,220 Epoch: [50/484] Iter:[140/495], Time: 0.39, lr: [0.009059936001560371], Loss: 2.141217, Acc:0.796573, Semantic loss: 0.805056, BCE loss: 0.565315, SB loss: 0.770846
2023-10-30 01:24:18,064 Epoch: [50/484] Iter:[150/495], Time: 0.39, lr: [0.009059556199921184], Loss: 2.136819, Acc:0.793742, Semantic loss: 0.804784, BCE loss: 0.562010, SB loss: 0.770024
2023-10-30 01:24:21,818 Epoch: [50/484] Iter:[160/495], Time: 0.39, lr: [0.009059176396512837], Loss: 2.142710, Acc:0.792101, Semantic loss: 0.810797, BCE loss: 0.560285, SB loss: 0.771628
2023-10-30 01:24:25,468 Epoch: [50/484] Iter:[170/495], Time: 0.39, lr: [0.009058796591335244], Loss: 2.138020, Acc:0.790637, Semantic loss: 0.810948, BCE loss: 0.556692, SB loss: 0.770381
2023-10-30 01:24:29,317 Epoch: [50/484] Iter:[180/495], Time: 0.39, lr: [0.009058416784388311], Loss: 2.141555, Acc:0.790598, Semantic loss: 0.815445, BCE loss: 0.554723, SB loss: 0.771387
2023-10-30 01:24:33,114 Epoch: [50/484] Iter:[190/495], Time: 0.39, lr: [0.009058036975671951], Loss: 2.148253, Acc:0.792579, Semantic loss: 0.816316, BCE loss: 0.556287, SB loss: 0.775651
2023-10-30 01:24:36,951 Epoch: [50/484] Iter:[200/495], Time: 0.39, lr: [0.009057657165186073], Loss: 2.146645, Acc:0.793246, Semantic loss: 0.814100, BCE loss: 0.558220, SB loss: 0.774325
2023-10-30 01:24:40,734 Epoch: [50/484] Iter:[210/495], Time: 0.39, lr: [0.009057277352930585], Loss: 2.149049, Acc:0.794266, Semantic loss: 0.813505, BCE loss: 0.560289, SB loss: 0.775256
2023-10-30 01:24:44,524 Epoch: [50/484] Iter:[220/495], Time: 0.39, lr: [0.009056897538905394], Loss: 2.151957, Acc:0.792709, Semantic loss: 0.815813, BCE loss: 0.560866, SB loss: 0.775278
2023-10-30 01:24:48,328 Epoch: [50/484] Iter:[230/495], Time: 0.39, lr: [0.009056517723110412], Loss: 2.157555, Acc:0.792640, Semantic loss: 0.817248, BCE loss: 0.564745, SB loss: 0.775562
2023-10-30 01:24:52,215 Epoch: [50/484] Iter:[240/495], Time: 0.39, lr: [0.009056137905545549], Loss: 2.163060, Acc:0.793334, Semantic loss: 0.817876, BCE loss: 0.568397, SB loss: 0.776787
2023-10-30 01:24:56,026 Epoch: [50/484] Iter:[250/495], Time: 0.39, lr: [0.009055758086210714], Loss: 2.161076, Acc:0.792536, Semantic loss: 0.816011, BCE loss: 0.568646, SB loss: 0.776418
2023-10-30 01:24:59,823 Epoch: [50/484] Iter:[260/495], Time: 0.39, lr: [0.009055378265105815], Loss: 2.165580, Acc:0.793899, Semantic loss: 0.816297, BCE loss: 0.571625, SB loss: 0.777658
2023-10-30 01:25:03,583 Epoch: [50/484] Iter:[270/495], Time: 0.39, lr: [0.009054998442230762], Loss: 2.165888, Acc:0.794029, Semantic loss: 0.815399, BCE loss: 0.572686, SB loss: 0.777803
2023-10-30 01:25:07,423 Epoch: [50/484] Iter:[280/495], Time: 0.39, lr: [0.009054618617585464], Loss: 2.169100, Acc:0.794763, Semantic loss: 0.817125, BCE loss: 0.573909, SB loss: 0.778067
2023-10-30 01:25:11,102 Epoch: [50/484] Iter:[290/495], Time: 0.38, lr: [0.009054238791169828], Loss: 2.170201, Acc:0.795286, Semantic loss: 0.816642, BCE loss: 0.575382, SB loss: 0.778177
2023-10-30 01:25:14,938 Epoch: [50/484] Iter:[300/495], Time: 0.38, lr: [0.009053858962983769], Loss: 2.169069, Acc:0.795930, Semantic loss: 0.815365, BCE loss: 0.575162, SB loss: 0.778542
2023-10-30 01:25:18,854 Epoch: [50/484] Iter:[310/495], Time: 0.38, lr: [0.009053479133027191], Loss: 2.167938, Acc:0.796812, Semantic loss: 0.813102, BCE loss: 0.576217, SB loss: 0.778619
2023-10-30 01:25:22,566 Epoch: [50/484] Iter:[320/495], Time: 0.38, lr: [0.009053099301300006], Loss: 2.172987, Acc:0.797413, Semantic loss: 0.814928, BCE loss: 0.578327, SB loss: 0.779732
2023-10-30 01:25:26,355 Epoch: [50/484] Iter:[330/495], Time: 0.38, lr: [0.00905271946780212], Loss: 2.170687, Acc:0.798206, Semantic loss: 0.813530, BCE loss: 0.577387, SB loss: 0.779769
2023-10-30 01:25:30,098 Epoch: [50/484] Iter:[340/495], Time: 0.38, lr: [0.009052339632533447], Loss: 2.166752, Acc:0.798133, Semantic loss: 0.811003, BCE loss: 0.577170, SB loss: 0.778579
2023-10-30 01:25:33,993 Epoch: [50/484] Iter:[350/495], Time: 0.38, lr: [0.009051959795493891], Loss: 2.161004, Acc:0.797947, Semantic loss: 0.808787, BCE loss: 0.574827, SB loss: 0.777390
2023-10-30 01:25:37,729 Epoch: [50/484] Iter:[360/495], Time: 0.38, lr: [0.009051579956683365], Loss: 2.161469, Acc:0.797817, Semantic loss: 0.808806, BCE loss: 0.574091, SB loss: 0.778573
2023-10-30 01:25:41,534 Epoch: [50/484] Iter:[370/495], Time: 0.38, lr: [0.009051200116101776], Loss: 2.162389, Acc:0.798416, Semantic loss: 0.809044, BCE loss: 0.574179, SB loss: 0.779166
2023-10-30 01:25:45,409 Epoch: [50/484] Iter:[380/495], Time: 0.38, lr: [0.009050820273749035], Loss: 2.163467, Acc:0.798432, Semantic loss: 0.809224, BCE loss: 0.575468, SB loss: 0.778775
2023-10-30 01:25:49,239 Epoch: [50/484] Iter:[390/495], Time: 0.38, lr: [0.009050440429625049], Loss: 2.165473, Acc:0.798026, Semantic loss: 0.809427, BCE loss: 0.576811, SB loss: 0.779235
2023-10-30 01:25:53,046 Epoch: [50/484] Iter:[400/495], Time: 0.38, lr: [0.009050060583729732], Loss: 2.161602, Acc:0.796971, Semantic loss: 0.808191, BCE loss: 0.575394, SB loss: 0.778017
2023-10-30 01:25:56,806 Epoch: [50/484] Iter:[410/495], Time: 0.38, lr: [0.009049680736062986], Loss: 2.159419, Acc:0.797096, Semantic loss: 0.807183, BCE loss: 0.574551, SB loss: 0.777685
2023-10-30 01:26:00,625 Epoch: [50/484] Iter:[420/495], Time: 0.38, lr: [0.009049300886624723], Loss: 2.157866, Acc:0.796471, Semantic loss: 0.807103, BCE loss: 0.573158, SB loss: 0.777604
2023-10-30 01:26:04,423 Epoch: [50/484] Iter:[430/495], Time: 0.38, lr: [0.009048921035414855], Loss: 2.158140, Acc:0.797393, Semantic loss: 0.806983, BCE loss: 0.573582, SB loss: 0.777574
2023-10-30 01:26:08,281 Epoch: [50/484] Iter:[440/495], Time: 0.38, lr: [0.009048541182433287], Loss: 2.157570, Acc:0.798639, Semantic loss: 0.805856, BCE loss: 0.574159, SB loss: 0.777555
2023-10-30 01:26:11,965 Epoch: [50/484] Iter:[450/495], Time: 0.38, lr: [0.00904816132767993], Loss: 2.154543, Acc:0.798692, Semantic loss: 0.805080, BCE loss: 0.572496, SB loss: 0.776967
2023-10-30 01:26:15,701 Epoch: [50/484] Iter:[460/495], Time: 0.38, lr: [0.009047781471154693], Loss: 2.153825, Acc:0.798267, Semantic loss: 0.804482, BCE loss: 0.572940, SB loss: 0.776403
2023-10-30 01:26:19,502 Epoch: [50/484] Iter:[470/495], Time: 0.38, lr: [0.009047401612857487], Loss: 2.152600, Acc:0.797841, Semantic loss: 0.804312, BCE loss: 0.571551, SB loss: 0.776737
2023-10-30 01:26:23,309 Epoch: [50/484] Iter:[480/495], Time: 0.38, lr: [0.009047021752788218], Loss: 2.152925, Acc:0.797695, Semantic loss: 0.804564, BCE loss: 0.571516, SB loss: 0.776845
2023-10-30 01:26:26,875 Epoch: [50/484] Iter:[490/495], Time: 0.38, lr: [0.009046641890946797], Loss: 2.146744, Acc:0.797301, Semantic loss: 0.801407, BCE loss: 0.569862, SB loss: 0.775475
2023-10-30 01:29:25,456 0 [9.33105122e-01 5.98663174e-01 8.12238582e-01 1.10076026e-01
 2.56593043e-01 3.89556399e-01 3.70648419e-01 5.53576063e-01
 8.71804656e-01 4.16520199e-01 8.65004334e-01 5.74774626e-01
 3.53371141e-03 7.88115842e-01 2.86098371e-05 3.79801731e-02
 1.76692485e-02 4.36370781e-03 5.75432203e-01] 0.43050969149785806
2023-10-30 01:29:25,457 1 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ] 0.6736067258225994
2023-10-30 01:29:25,460 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:29:25,828 Loss: 2.149, MeanIU:  0.6736, Best_mIoU:  0.6736
2023-10-30 01:29:25,828 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ]
2023-10-30 01:29:27,965 Epoch: [51/484] Iter:[0/495], Time: 2.10, lr: [0.009046451959361499], Loss: 2.569686, Acc:0.787414, Semantic loss: 1.107808, BCE loss: 0.682318, SB loss: 0.779560
2023-10-30 01:29:32,016 Epoch: [51/484] Iter:[10/495], Time: 0.56, lr: [0.009046072094861676], Loss: 2.284318, Acc:0.821354, Semantic loss: 0.935366, BCE loss: 0.575191, SB loss: 0.773761
2023-10-30 01:29:35,693 Epoch: [51/484] Iter:[20/495], Time: 0.47, lr: [0.009045692228589475], Loss: 2.186951, Acc:0.818413, Semantic loss: 0.842417, BCE loss: 0.578383, SB loss: 0.766151
2023-10-30 01:29:39,333 Epoch: [51/484] Iter:[30/495], Time: 0.43, lr: [0.009045312360544802], Loss: 2.195504, Acc:0.814570, Semantic loss: 0.869790, BCE loss: 0.558438, SB loss: 0.767276
2023-10-30 01:29:42,936 Epoch: [51/484] Iter:[40/495], Time: 0.42, lr: [0.009044932490727565], Loss: 2.160891, Acc:0.810398, Semantic loss: 0.840517, BCE loss: 0.549277, SB loss: 0.771098
2023-10-30 01:29:46,528 Epoch: [51/484] Iter:[50/495], Time: 0.41, lr: [0.009044552619137678], Loss: 2.150457, Acc:0.813840, Semantic loss: 0.828083, BCE loss: 0.550264, SB loss: 0.772110
2023-10-30 01:29:50,197 Epoch: [51/484] Iter:[60/495], Time: 0.40, lr: [0.009044172745775046], Loss: 2.174096, Acc:0.812996, Semantic loss: 0.834997, BCE loss: 0.555327, SB loss: 0.783772
2023-10-30 01:29:53,850 Epoch: [51/484] Iter:[70/495], Time: 0.39, lr: [0.009043792870639578], Loss: 2.151416, Acc:0.815083, Semantic loss: 0.821807, BCE loss: 0.545792, SB loss: 0.783818
2023-10-30 01:29:57,522 Epoch: [51/484] Iter:[80/495], Time: 0.39, lr: [0.009043412993731183], Loss: 2.145973, Acc:0.817524, Semantic loss: 0.815093, BCE loss: 0.550140, SB loss: 0.780739
2023-10-30 01:30:01,217 Epoch: [51/484] Iter:[90/495], Time: 0.39, lr: [0.009043033115049772], Loss: 2.151575, Acc:0.813171, Semantic loss: 0.814490, BCE loss: 0.553634, SB loss: 0.783451
2023-10-30 01:30:04,874 Epoch: [51/484] Iter:[100/495], Time: 0.39, lr: [0.009042653234595254], Loss: 2.149981, Acc:0.807740, Semantic loss: 0.815032, BCE loss: 0.555817, SB loss: 0.779132
2023-10-30 01:30:08,685 Epoch: [51/484] Iter:[110/495], Time: 0.39, lr: [0.009042273352367534], Loss: 2.145786, Acc:0.810455, Semantic loss: 0.809166, BCE loss: 0.558132, SB loss: 0.778488
2023-10-30 01:30:12,460 Epoch: [51/484] Iter:[120/495], Time: 0.39, lr: [0.009041893468366525], Loss: 2.140819, Acc:0.807632, Semantic loss: 0.807156, BCE loss: 0.557094, SB loss: 0.776569
2023-10-30 01:30:16,152 Epoch: [51/484] Iter:[130/495], Time: 0.38, lr: [0.009041513582592135], Loss: 2.128836, Acc:0.805161, Semantic loss: 0.796936, BCE loss: 0.559349, SB loss: 0.772551
2023-10-30 01:30:19,812 Epoch: [51/484] Iter:[140/495], Time: 0.38, lr: [0.009041133695044274], Loss: 2.133932, Acc:0.799391, Semantic loss: 0.803189, BCE loss: 0.559188, SB loss: 0.771554
2023-10-30 01:30:23,631 Epoch: [51/484] Iter:[150/495], Time: 0.38, lr: [0.009040753805722848], Loss: 2.130545, Acc:0.798799, Semantic loss: 0.799034, BCE loss: 0.560560, SB loss: 0.770951
2023-10-30 01:30:27,402 Epoch: [51/484] Iter:[160/495], Time: 0.38, lr: [0.009040373914627767], Loss: 2.144554, Acc:0.797806, Semantic loss: 0.804246, BCE loss: 0.567887, SB loss: 0.772421
2023-10-30 01:30:31,093 Epoch: [51/484] Iter:[170/495], Time: 0.38, lr: [0.00903999402175894], Loss: 2.148097, Acc:0.797309, Semantic loss: 0.803643, BCE loss: 0.571703, SB loss: 0.772751
2023-10-30 01:30:34,861 Epoch: [51/484] Iter:[180/495], Time: 0.38, lr: [0.009039614127116277], Loss: 2.142467, Acc:0.796942, Semantic loss: 0.799838, BCE loss: 0.569835, SB loss: 0.772794
2023-10-30 01:30:38,525 Epoch: [51/484] Iter:[190/495], Time: 0.38, lr: [0.009039234230699685], Loss: 2.146598, Acc:0.795911, Semantic loss: 0.800631, BCE loss: 0.569951, SB loss: 0.776016
2023-10-30 01:30:42,305 Epoch: [51/484] Iter:[200/495], Time: 0.38, lr: [0.009038854332509075], Loss: 2.143245, Acc:0.794738, Semantic loss: 0.799785, BCE loss: 0.567750, SB loss: 0.775710
2023-10-30 01:30:45,965 Epoch: [51/484] Iter:[210/495], Time: 0.38, lr: [0.009038474432544356], Loss: 2.155163, Acc:0.796080, Semantic loss: 0.804957, BCE loss: 0.574435, SB loss: 0.775771
2023-10-30 01:30:49,699 Epoch: [51/484] Iter:[220/495], Time: 0.38, lr: [0.009038094530805434], Loss: 2.149492, Acc:0.795440, Semantic loss: 0.804073, BCE loss: 0.571579, SB loss: 0.773840
2023-10-30 01:30:53,433 Epoch: [51/484] Iter:[230/495], Time: 0.38, lr: [0.00903771462729222], Loss: 2.151732, Acc:0.794943, Semantic loss: 0.805883, BCE loss: 0.570913, SB loss: 0.774935
2023-10-30 01:30:57,075 Epoch: [51/484] Iter:[240/495], Time: 0.38, lr: [0.009037334722004622], Loss: 2.155563, Acc:0.795643, Semantic loss: 0.806336, BCE loss: 0.572387, SB loss: 0.776840
2023-10-30 01:31:00,914 Epoch: [51/484] Iter:[250/495], Time: 0.38, lr: [0.009036954814942549], Loss: 2.153410, Acc:0.795035, Semantic loss: 0.804993, BCE loss: 0.570703, SB loss: 0.777713
2023-10-30 01:31:04,575 Epoch: [51/484] Iter:[260/495], Time: 0.38, lr: [0.009036574906105913], Loss: 2.165088, Acc:0.795173, Semantic loss: 0.813232, BCE loss: 0.571552, SB loss: 0.780304
2023-10-30 01:31:08,270 Epoch: [51/484] Iter:[270/495], Time: 0.38, lr: [0.009036194995494615], Loss: 2.162613, Acc:0.795002, Semantic loss: 0.811547, BCE loss: 0.570076, SB loss: 0.780989
2023-10-30 01:31:12,125 Epoch: [51/484] Iter:[280/495], Time: 0.38, lr: [0.009035815083108571], Loss: 2.159361, Acc:0.792546, Semantic loss: 0.811202, BCE loss: 0.566040, SB loss: 0.782119
2023-10-30 01:31:15,818 Epoch: [51/484] Iter:[290/495], Time: 0.38, lr: [0.009035435168947689], Loss: 2.159084, Acc:0.793210, Semantic loss: 0.811043, BCE loss: 0.566894, SB loss: 0.781147
2023-10-30 01:31:19,620 Epoch: [51/484] Iter:[300/495], Time: 0.38, lr: [0.009035055253011876], Loss: 2.155611, Acc:0.792738, Semantic loss: 0.808447, BCE loss: 0.566746, SB loss: 0.780418
2023-10-30 01:31:23,410 Epoch: [51/484] Iter:[310/495], Time: 0.38, lr: [0.00903467533530104], Loss: 2.175917, Acc:0.792137, Semantic loss: 0.824062, BCE loss: 0.567017, SB loss: 0.784837
2023-10-30 01:31:27,207 Epoch: [51/484] Iter:[320/495], Time: 0.38, lr: [0.009034295415815088], Loss: 2.188657, Acc:0.790474, Semantic loss: 0.830472, BCE loss: 0.568971, SB loss: 0.789214
2023-10-30 01:31:30,961 Epoch: [51/484] Iter:[330/495], Time: 0.38, lr: [0.009033915494553936], Loss: 2.203171, Acc:0.789293, Semantic loss: 0.837710, BCE loss: 0.571634, SB loss: 0.793827
2023-10-30 01:31:34,812 Epoch: [51/484] Iter:[340/495], Time: 0.38, lr: [0.009033535571517487], Loss: 2.208589, Acc:0.788436, Semantic loss: 0.840042, BCE loss: 0.571809, SB loss: 0.796738
2023-10-30 01:31:38,639 Epoch: [51/484] Iter:[350/495], Time: 0.38, lr: [0.00903315564670565], Loss: 2.211715, Acc:0.789468, Semantic loss: 0.840371, BCE loss: 0.572286, SB loss: 0.799058
2023-10-30 01:31:42,442 Epoch: [51/484] Iter:[360/495], Time: 0.38, lr: [0.009032775720118336], Loss: 2.217675, Acc:0.788403, Semantic loss: 0.843458, BCE loss: 0.572894, SB loss: 0.801323
2023-10-30 01:31:46,128 Epoch: [51/484] Iter:[370/495], Time: 0.38, lr: [0.009032395791755453], Loss: 2.212325, Acc:0.788558, Semantic loss: 0.840806, BCE loss: 0.571346, SB loss: 0.800173
2023-10-30 01:31:49,908 Epoch: [51/484] Iter:[380/495], Time: 0.38, lr: [0.009032015861616909], Loss: 2.211469, Acc:0.789550, Semantic loss: 0.839990, BCE loss: 0.571515, SB loss: 0.799964
2023-10-30 01:31:53,642 Epoch: [51/484] Iter:[390/495], Time: 0.38, lr: [0.009031635929702611], Loss: 2.206775, Acc:0.788554, Semantic loss: 0.837805, BCE loss: 0.569064, SB loss: 0.799906
2023-10-30 01:31:57,351 Epoch: [51/484] Iter:[400/495], Time: 0.38, lr: [0.009031255996012472], Loss: 2.207414, Acc:0.788256, Semantic loss: 0.840649, BCE loss: 0.566667, SB loss: 0.800098
2023-10-30 01:32:01,092 Epoch: [51/484] Iter:[410/495], Time: 0.38, lr: [0.009030876060546396], Loss: 2.205324, Acc:0.786684, Semantic loss: 0.840182, BCE loss: 0.564943, SB loss: 0.800199
2023-10-30 01:32:04,881 Epoch: [51/484] Iter:[420/495], Time: 0.38, lr: [0.009030496123304296], Loss: 2.201133, Acc:0.786561, Semantic loss: 0.838162, BCE loss: 0.563830, SB loss: 0.799141
2023-10-30 01:32:08,663 Epoch: [51/484] Iter:[430/495], Time: 0.38, lr: [0.009030116184286079], Loss: 2.205308, Acc:0.786276, Semantic loss: 0.841694, BCE loss: 0.563756, SB loss: 0.799858
2023-10-30 01:32:12,332 Epoch: [51/484] Iter:[440/495], Time: 0.38, lr: [0.009029736243491652], Loss: 2.206876, Acc:0.785782, Semantic loss: 0.841990, BCE loss: 0.564237, SB loss: 0.800649
2023-10-30 01:32:16,150 Epoch: [51/484] Iter:[450/495], Time: 0.38, lr: [0.009029356300920928], Loss: 2.206258, Acc:0.786241, Semantic loss: 0.840419, BCE loss: 0.565634, SB loss: 0.800204
2023-10-30 01:32:19,933 Epoch: [51/484] Iter:[460/495], Time: 0.38, lr: [0.00902897635657381], Loss: 2.207434, Acc:0.786032, Semantic loss: 0.841799, BCE loss: 0.565073, SB loss: 0.800563
2023-10-30 01:32:23,630 Epoch: [51/484] Iter:[470/495], Time: 0.38, lr: [0.009028596410450207], Loss: 2.207552, Acc:0.785506, Semantic loss: 0.842531, BCE loss: 0.564302, SB loss: 0.800719
2023-10-30 01:32:27,320 Epoch: [51/484] Iter:[480/495], Time: 0.38, lr: [0.009028216462550033], Loss: 2.205774, Acc:0.785137, Semantic loss: 0.841917, BCE loss: 0.563939, SB loss: 0.799919
2023-10-30 01:32:30,929 Epoch: [51/484] Iter:[490/495], Time: 0.38, lr: [0.009027836512873194], Loss: 2.205362, Acc:0.784043, Semantic loss: 0.841728, BCE loss: 0.563568, SB loss: 0.800065
2023-10-30 01:32:32,344 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:32:32,588 Loss: 2.149, MeanIU:  0.6736, Best_mIoU:  0.6736
2023-10-30 01:32:32,588 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ]
2023-10-30 01:32:34,695 Epoch: [52/484] Iter:[0/495], Time: 2.07, lr: [0.009027646537368495], Loss: 2.191739, Acc:0.647118, Semantic loss: 0.818571, BCE loss: 0.487202, SB loss: 0.885966
2023-10-30 01:32:38,776 Epoch: [52/484] Iter:[10/495], Time: 0.56, lr: [0.009027266585026486], Loss: 2.193512, Acc:0.793448, Semantic loss: 0.782207, BCE loss: 0.611351, SB loss: 0.799954
2023-10-30 01:32:42,594 Epoch: [52/484] Iter:[20/495], Time: 0.47, lr: [0.009026886630907583], Loss: 2.215400, Acc:0.792198, Semantic loss: 0.820974, BCE loss: 0.595155, SB loss: 0.799271
2023-10-30 01:32:46,505 Epoch: [52/484] Iter:[30/495], Time: 0.45, lr: [0.009026506675011694], Loss: 2.178390, Acc:0.785876, Semantic loss: 0.803939, BCE loss: 0.585310, SB loss: 0.789141
2023-10-30 01:32:50,215 Epoch: [52/484] Iter:[40/495], Time: 0.43, lr: [0.009026126717338729], Loss: 2.191948, Acc:0.788734, Semantic loss: 0.801193, BCE loss: 0.594780, SB loss: 0.795975
2023-10-30 01:32:53,955 Epoch: [52/484] Iter:[50/495], Time: 0.42, lr: [0.009025746757888595], Loss: 2.204599, Acc:0.790135, Semantic loss: 0.814675, BCE loss: 0.596134, SB loss: 0.793790
2023-10-30 01:32:57,855 Epoch: [52/484] Iter:[60/495], Time: 0.41, lr: [0.0090253667966612], Loss: 2.183378, Acc:0.786870, Semantic loss: 0.808345, BCE loss: 0.586638, SB loss: 0.788396
2023-10-30 01:33:01,641 Epoch: [52/484] Iter:[70/495], Time: 0.41, lr: [0.009024986833656457], Loss: 2.202205, Acc:0.788456, Semantic loss: 0.824370, BCE loss: 0.585914, SB loss: 0.791921
2023-10-30 01:33:05,296 Epoch: [52/484] Iter:[80/495], Time: 0.40, lr: [0.00902460686887427], Loss: 2.190499, Acc:0.790377, Semantic loss: 0.822282, BCE loss: 0.576471, SB loss: 0.791746
2023-10-30 01:33:09,050 Epoch: [52/484] Iter:[90/495], Time: 0.40, lr: [0.00902422690231455], Loss: 2.185470, Acc:0.788803, Semantic loss: 0.825127, BCE loss: 0.569511, SB loss: 0.790832
2023-10-30 01:33:12,774 Epoch: [52/484] Iter:[100/495], Time: 0.40, lr: [0.009023846933977201], Loss: 2.169947, Acc:0.789452, Semantic loss: 0.817640, BCE loss: 0.565205, SB loss: 0.787102
2023-10-30 01:33:16,521 Epoch: [52/484] Iter:[110/495], Time: 0.40, lr: [0.009023466963862138], Loss: 2.177849, Acc:0.791715, Semantic loss: 0.821644, BCE loss: 0.567236, SB loss: 0.788969
2023-10-30 01:33:20,303 Epoch: [52/484] Iter:[120/495], Time: 0.39, lr: [0.009023086991969267], Loss: 2.169880, Acc:0.789708, Semantic loss: 0.817700, BCE loss: 0.563016, SB loss: 0.789164
2023-10-30 01:33:24,007 Epoch: [52/484] Iter:[130/495], Time: 0.39, lr: [0.009022707018298496], Loss: 2.171294, Acc:0.789415, Semantic loss: 0.819102, BCE loss: 0.562787, SB loss: 0.789406
2023-10-30 01:33:27,782 Epoch: [52/484] Iter:[140/495], Time: 0.39, lr: [0.009022327042849733], Loss: 2.165130, Acc:0.788373, Semantic loss: 0.819834, BCE loss: 0.557103, SB loss: 0.788193
2023-10-30 01:33:31,560 Epoch: [52/484] Iter:[150/495], Time: 0.39, lr: [0.009021947065622885], Loss: 2.159212, Acc:0.787505, Semantic loss: 0.814486, BCE loss: 0.556605, SB loss: 0.788121
2023-10-30 01:33:35,459 Epoch: [52/484] Iter:[160/495], Time: 0.39, lr: [0.009021567086617865], Loss: 2.162452, Acc:0.789201, Semantic loss: 0.814756, BCE loss: 0.559568, SB loss: 0.788128
2023-10-30 01:33:39,185 Epoch: [52/484] Iter:[170/495], Time: 0.39, lr: [0.009021187105834577], Loss: 2.165591, Acc:0.789651, Semantic loss: 0.816524, BCE loss: 0.560550, SB loss: 0.788517
2023-10-30 01:33:42,908 Epoch: [52/484] Iter:[180/495], Time: 0.39, lr: [0.009020807123272932], Loss: 2.160260, Acc:0.789545, Semantic loss: 0.815036, BCE loss: 0.558931, SB loss: 0.786293
2023-10-30 01:33:46,817 Epoch: [52/484] Iter:[190/495], Time: 0.39, lr: [0.009020427138932838], Loss: 2.155721, Acc:0.790362, Semantic loss: 0.812071, BCE loss: 0.559339, SB loss: 0.784311
2023-10-30 01:33:50,637 Epoch: [52/484] Iter:[200/495], Time: 0.39, lr: [0.009020047152814206], Loss: 2.160053, Acc:0.791210, Semantic loss: 0.814433, BCE loss: 0.560144, SB loss: 0.785477
2023-10-30 01:33:54,475 Epoch: [52/484] Iter:[210/495], Time: 0.39, lr: [0.009019667164916938], Loss: 2.165552, Acc:0.792013, Semantic loss: 0.817745, BCE loss: 0.561054, SB loss: 0.786753
2023-10-30 01:33:58,224 Epoch: [52/484] Iter:[220/495], Time: 0.39, lr: [0.009019287175240946], Loss: 2.165105, Acc:0.793495, Semantic loss: 0.819175, BCE loss: 0.560254, SB loss: 0.785675
2023-10-30 01:34:01,930 Epoch: [52/484] Iter:[230/495], Time: 0.39, lr: [0.00901890718378614], Loss: 2.175525, Acc:0.792458, Semantic loss: 0.825181, BCE loss: 0.562644, SB loss: 0.787700
2023-10-30 01:34:05,722 Epoch: [52/484] Iter:[240/495], Time: 0.39, lr: [0.009018527190552428], Loss: 2.177263, Acc:0.792426, Semantic loss: 0.825552, BCE loss: 0.564624, SB loss: 0.787088
2023-10-30 01:34:09,446 Epoch: [52/484] Iter:[250/495], Time: 0.39, lr: [0.009018147195539714], Loss: 2.178838, Acc:0.793190, Semantic loss: 0.825104, BCE loss: 0.565468, SB loss: 0.788266
2023-10-30 01:34:13,286 Epoch: [52/484] Iter:[260/495], Time: 0.39, lr: [0.009017767198747913], Loss: 2.177158, Acc:0.793349, Semantic loss: 0.823512, BCE loss: 0.565040, SB loss: 0.788606
2023-10-30 01:34:17,033 Epoch: [52/484] Iter:[270/495], Time: 0.39, lr: [0.009017387200176929], Loss: 2.180021, Acc:0.791421, Semantic loss: 0.825989, BCE loss: 0.564583, SB loss: 0.789449
2023-10-30 01:34:20,908 Epoch: [52/484] Iter:[280/495], Time: 0.39, lr: [0.009017007199826671], Loss: 2.177441, Acc:0.791559, Semantic loss: 0.823513, BCE loss: 0.565471, SB loss: 0.788457
2023-10-30 01:34:24,764 Epoch: [52/484] Iter:[290/495], Time: 0.39, lr: [0.009016627197697047], Loss: 2.169839, Acc:0.792252, Semantic loss: 0.819633, BCE loss: 0.563544, SB loss: 0.786662
2023-10-30 01:34:28,485 Epoch: [52/484] Iter:[300/495], Time: 0.38, lr: [0.009016247193787968], Loss: 2.169036, Acc:0.792700, Semantic loss: 0.818498, BCE loss: 0.565168, SB loss: 0.785370
2023-10-30 01:34:32,226 Epoch: [52/484] Iter:[310/495], Time: 0.38, lr: [0.009015867188099339], Loss: 2.167649, Acc:0.793120, Semantic loss: 0.816963, BCE loss: 0.565172, SB loss: 0.785514
2023-10-30 01:34:36,053 Epoch: [52/484] Iter:[320/495], Time: 0.38, lr: [0.00901548718063107], Loss: 2.167382, Acc:0.793342, Semantic loss: 0.817760, BCE loss: 0.564836, SB loss: 0.784786
2023-10-30 01:34:39,784 Epoch: [52/484] Iter:[330/495], Time: 0.38, lr: [0.009015107171383069], Loss: 2.166340, Acc:0.795129, Semantic loss: 0.817073, BCE loss: 0.565400, SB loss: 0.783868
2023-10-30 01:34:43,522 Epoch: [52/484] Iter:[340/495], Time: 0.38, lr: [0.009014727160355245], Loss: 2.163688, Acc:0.793949, Semantic loss: 0.816194, BCE loss: 0.563809, SB loss: 0.783685
2023-10-30 01:34:47,241 Epoch: [52/484] Iter:[350/495], Time: 0.38, lr: [0.009014347147547504], Loss: 2.160498, Acc:0.794952, Semantic loss: 0.814781, BCE loss: 0.562753, SB loss: 0.782963
2023-10-30 01:34:50,988 Epoch: [52/484] Iter:[360/495], Time: 0.38, lr: [0.009013967132959759], Loss: 2.160216, Acc:0.794317, Semantic loss: 0.814076, BCE loss: 0.562687, SB loss: 0.783453
2023-10-30 01:34:54,791 Epoch: [52/484] Iter:[370/495], Time: 0.38, lr: [0.009013587116591913], Loss: 2.158384, Acc:0.793919, Semantic loss: 0.812580, BCE loss: 0.563556, SB loss: 0.782248
2023-10-30 01:34:58,625 Epoch: [52/484] Iter:[380/495], Time: 0.38, lr: [0.009013207098443877], Loss: 2.165601, Acc:0.795047, Semantic loss: 0.816199, BCE loss: 0.566214, SB loss: 0.783189
2023-10-30 01:35:02,410 Epoch: [52/484] Iter:[390/495], Time: 0.38, lr: [0.009012827078515558], Loss: 2.163547, Acc:0.795048, Semantic loss: 0.815238, BCE loss: 0.565718, SB loss: 0.782590
2023-10-30 01:35:06,163 Epoch: [52/484] Iter:[400/495], Time: 0.38, lr: [0.009012447056806868], Loss: 2.161457, Acc:0.796366, Semantic loss: 0.814291, BCE loss: 0.566119, SB loss: 0.781047
2023-10-30 01:35:09,847 Epoch: [52/484] Iter:[410/495], Time: 0.38, lr: [0.009012067033317708], Loss: 2.166024, Acc:0.795423, Semantic loss: 0.819772, BCE loss: 0.565178, SB loss: 0.781074
2023-10-30 01:35:13,586 Epoch: [52/484] Iter:[420/495], Time: 0.38, lr: [0.009011687008047994], Loss: 2.163483, Acc:0.795327, Semantic loss: 0.818184, BCE loss: 0.564392, SB loss: 0.780907
2023-10-30 01:35:17,328 Epoch: [52/484] Iter:[430/495], Time: 0.38, lr: [0.00901130698099763], Loss: 2.165638, Acc:0.795181, Semantic loss: 0.818891, BCE loss: 0.564885, SB loss: 0.781862
2023-10-30 01:35:21,146 Epoch: [52/484] Iter:[440/495], Time: 0.38, lr: [0.009010926952166525], Loss: 2.165039, Acc:0.796900, Semantic loss: 0.819231, BCE loss: 0.564546, SB loss: 0.781262
2023-10-30 01:35:24,882 Epoch: [52/484] Iter:[450/495], Time: 0.38, lr: [0.009010546921554586], Loss: 2.164462, Acc:0.796809, Semantic loss: 0.818079, BCE loss: 0.565004, SB loss: 0.781378
2023-10-30 01:35:28,755 Epoch: [52/484] Iter:[460/495], Time: 0.38, lr: [0.009010166889161723], Loss: 2.162443, Acc:0.797058, Semantic loss: 0.816059, BCE loss: 0.565388, SB loss: 0.780996
2023-10-30 01:35:32,571 Epoch: [52/484] Iter:[470/495], Time: 0.38, lr: [0.009009786854987843], Loss: 2.167903, Acc:0.796267, Semantic loss: 0.819675, BCE loss: 0.565382, SB loss: 0.782846
2023-10-30 01:35:36,565 Epoch: [52/484] Iter:[480/495], Time: 0.38, lr: [0.009009406819032856], Loss: 2.168666, Acc:0.796258, Semantic loss: 0.818699, BCE loss: 0.567240, SB loss: 0.782727
2023-10-30 01:35:40,196 Epoch: [52/484] Iter:[490/495], Time: 0.38, lr: [0.009009026781296668], Loss: 2.174177, Acc:0.796347, Semantic loss: 0.822749, BCE loss: 0.567094, SB loss: 0.784334
2023-10-30 01:35:41,624 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:35:41,889 Loss: 2.149, MeanIU:  0.6736, Best_mIoU:  0.6736
2023-10-30 01:35:41,889 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ]
2023-10-30 01:35:44,196 Epoch: [53/484] Iter:[0/495], Time: 2.27, lr: [0.009008836761760597], Loss: 2.108572, Acc:0.864848, Semantic loss: 0.720370, BCE loss: 0.660047, SB loss: 0.728155
2023-10-30 01:35:48,336 Epoch: [53/484] Iter:[10/495], Time: 0.58, lr: [0.009008456721352436], Loss: 2.073767, Acc:0.831113, Semantic loss: 0.770381, BCE loss: 0.521183, SB loss: 0.782202
2023-10-30 01:35:52,015 Epoch: [53/484] Iter:[20/495], Time: 0.48, lr: [0.009008076679162846], Loss: 2.113761, Acc:0.808252, Semantic loss: 0.795726, BCE loss: 0.531500, SB loss: 0.786535
2023-10-30 01:35:55,812 Epoch: [53/484] Iter:[30/495], Time: 0.45, lr: [0.009007696635191737], Loss: 2.168522, Acc:0.797386, Semantic loss: 0.813962, BCE loss: 0.558936, SB loss: 0.795624
2023-10-30 01:35:59,521 Epoch: [53/484] Iter:[40/495], Time: 0.43, lr: [0.009007316589439011], Loss: 2.191308, Acc:0.800131, Semantic loss: 0.823846, BCE loss: 0.571709, SB loss: 0.795752
2023-10-30 01:36:03,178 Epoch: [53/484] Iter:[50/495], Time: 0.42, lr: [0.009006936541904582], Loss: 2.180792, Acc:0.803633, Semantic loss: 0.819446, BCE loss: 0.565009, SB loss: 0.796337
2023-10-30 01:36:06,908 Epoch: [53/484] Iter:[60/495], Time: 0.41, lr: [0.009006556492588354], Loss: 2.171581, Acc:0.802462, Semantic loss: 0.807845, BCE loss: 0.570598, SB loss: 0.793139
2023-10-30 01:36:10,663 Epoch: [53/484] Iter:[70/495], Time: 0.40, lr: [0.009006176441490238], Loss: 2.180784, Acc:0.807059, Semantic loss: 0.806788, BCE loss: 0.579067, SB loss: 0.794929
2023-10-30 01:36:14,493 Epoch: [53/484] Iter:[80/495], Time: 0.40, lr: [0.00900579638861014], Loss: 2.186012, Acc:0.807635, Semantic loss: 0.808290, BCE loss: 0.583887, SB loss: 0.793836
2023-10-30 01:36:18,238 Epoch: [53/484] Iter:[90/495], Time: 0.40, lr: [0.009005416333947972], Loss: 2.195920, Acc:0.804930, Semantic loss: 0.818454, BCE loss: 0.584238, SB loss: 0.793228
2023-10-30 01:36:22,001 Epoch: [53/484] Iter:[100/495], Time: 0.40, lr: [0.009005036277503637], Loss: 2.169127, Acc:0.803745, Semantic loss: 0.802286, BCE loss: 0.577177, SB loss: 0.789665
2023-10-30 01:36:25,686 Epoch: [53/484] Iter:[110/495], Time: 0.39, lr: [0.009004656219277046], Loss: 2.165139, Acc:0.800227, Semantic loss: 0.802943, BCE loss: 0.574551, SB loss: 0.787644
2023-10-30 01:36:29,499 Epoch: [53/484] Iter:[120/495], Time: 0.39, lr: [0.009004276159268106], Loss: 2.173274, Acc:0.801754, Semantic loss: 0.804163, BCE loss: 0.583854, SB loss: 0.785257
2023-10-30 01:36:33,357 Epoch: [53/484] Iter:[130/495], Time: 0.39, lr: [0.009003896097476725], Loss: 2.178995, Acc:0.801399, Semantic loss: 0.806896, BCE loss: 0.587426, SB loss: 0.784672
2023-10-30 01:36:37,155 Epoch: [53/484] Iter:[140/495], Time: 0.39, lr: [0.009003516033902812], Loss: 2.161829, Acc:0.798832, Semantic loss: 0.800267, BCE loss: 0.580377, SB loss: 0.781185
2023-10-30 01:36:40,937 Epoch: [53/484] Iter:[150/495], Time: 0.39, lr: [0.009003135968546275], Loss: 2.162811, Acc:0.801227, Semantic loss: 0.799944, BCE loss: 0.581942, SB loss: 0.780925
2023-10-30 01:36:44,722 Epoch: [53/484] Iter:[160/495], Time: 0.39, lr: [0.00900275590140702], Loss: 2.153726, Acc:0.800424, Semantic loss: 0.797123, BCE loss: 0.577888, SB loss: 0.778715
2023-10-30 01:36:48,420 Epoch: [53/484] Iter:[170/495], Time: 0.39, lr: [0.009002375832484958], Loss: 2.147014, Acc:0.801026, Semantic loss: 0.794879, BCE loss: 0.575723, SB loss: 0.776412
2023-10-30 01:36:52,157 Epoch: [53/484] Iter:[180/495], Time: 0.39, lr: [0.009001995761779994], Loss: 2.143986, Acc:0.800093, Semantic loss: 0.792894, BCE loss: 0.575114, SB loss: 0.775978
2023-10-30 01:36:55,972 Epoch: [53/484] Iter:[190/495], Time: 0.39, lr: [0.009001615689292038], Loss: 2.152610, Acc:0.800489, Semantic loss: 0.797306, BCE loss: 0.576428, SB loss: 0.778877
2023-10-30 01:36:59,734 Epoch: [53/484] Iter:[200/495], Time: 0.39, lr: [0.009001235615021], Loss: 2.158209, Acc:0.799841, Semantic loss: 0.803222, BCE loss: 0.575680, SB loss: 0.779307
2023-10-30 01:37:03,512 Epoch: [53/484] Iter:[210/495], Time: 0.39, lr: [0.009000855538966781], Loss: 2.151416, Acc:0.797716, Semantic loss: 0.799665, BCE loss: 0.574479, SB loss: 0.777272
2023-10-30 01:37:07,262 Epoch: [53/484] Iter:[220/495], Time: 0.39, lr: [0.009000475461129295], Loss: 2.148877, Acc:0.798408, Semantic loss: 0.798353, BCE loss: 0.572968, SB loss: 0.777555
2023-10-30 01:37:11,066 Epoch: [53/484] Iter:[230/495], Time: 0.39, lr: [0.00900009538150845], Loss: 2.146769, Acc:0.796053, Semantic loss: 0.798437, BCE loss: 0.571250, SB loss: 0.777083
2023-10-30 01:37:14,816 Epoch: [53/484] Iter:[240/495], Time: 0.39, lr: [0.008999715300104152], Loss: 2.149308, Acc:0.795397, Semantic loss: 0.798421, BCE loss: 0.573041, SB loss: 0.777845
2023-10-30 01:37:18,697 Epoch: [53/484] Iter:[250/495], Time: 0.39, lr: [0.008999335216916308], Loss: 2.146829, Acc:0.796638, Semantic loss: 0.796148, BCE loss: 0.573077, SB loss: 0.777604
2023-10-30 01:37:22,375 Epoch: [53/484] Iter:[260/495], Time: 0.38, lr: [0.008998955131944828], Loss: 2.149099, Acc:0.796034, Semantic loss: 0.798547, BCE loss: 0.572191, SB loss: 0.778361
2023-10-30 01:37:26,182 Epoch: [53/484] Iter:[270/495], Time: 0.38, lr: [0.00899857504518962], Loss: 2.147214, Acc:0.796812, Semantic loss: 0.797215, BCE loss: 0.571390, SB loss: 0.778609
2023-10-30 01:37:29,926 Epoch: [53/484] Iter:[280/495], Time: 0.38, lr: [0.008998194956650588], Loss: 2.147387, Acc:0.795297, Semantic loss: 0.798011, BCE loss: 0.570512, SB loss: 0.778864
2023-10-30 01:37:33,647 Epoch: [53/484] Iter:[290/495], Time: 0.38, lr: [0.008997814866327647], Loss: 2.150232, Acc:0.795736, Semantic loss: 0.798948, BCE loss: 0.571675, SB loss: 0.779609
2023-10-30 01:37:37,351 Epoch: [53/484] Iter:[300/495], Time: 0.38, lr: [0.008997434774220698], Loss: 2.152084, Acc:0.795857, Semantic loss: 0.800755, BCE loss: 0.570013, SB loss: 0.781316
2023-10-30 01:37:41,145 Epoch: [53/484] Iter:[310/495], Time: 0.38, lr: [0.008997054680329651], Loss: 2.148297, Acc:0.796027, Semantic loss: 0.798885, BCE loss: 0.567850, SB loss: 0.781562
2023-10-30 01:37:44,876 Epoch: [53/484] Iter:[320/495], Time: 0.38, lr: [0.008996674584654417], Loss: 2.151368, Acc:0.796411, Semantic loss: 0.800995, BCE loss: 0.567227, SB loss: 0.783146
2023-10-30 01:37:48,586 Epoch: [53/484] Iter:[330/495], Time: 0.38, lr: [0.008996294487194901], Loss: 2.148014, Acc:0.795625, Semantic loss: 0.799465, BCE loss: 0.565128, SB loss: 0.783421
2023-10-30 01:37:52,333 Epoch: [53/484] Iter:[340/495], Time: 0.38, lr: [0.008995914387951012], Loss: 2.148070, Acc:0.794269, Semantic loss: 0.801953, BCE loss: 0.563283, SB loss: 0.782834
2023-10-30 01:37:56,141 Epoch: [53/484] Iter:[350/495], Time: 0.38, lr: [0.008995534286922655], Loss: 2.146317, Acc:0.793469, Semantic loss: 0.802354, BCE loss: 0.560108, SB loss: 0.783855
2023-10-30 01:37:59,880 Epoch: [53/484] Iter:[360/495], Time: 0.38, lr: [0.008995154184109743], Loss: 2.150586, Acc:0.793128, Semantic loss: 0.805411, BCE loss: 0.559920, SB loss: 0.785255
2023-10-30 01:38:03,662 Epoch: [53/484] Iter:[370/495], Time: 0.38, lr: [0.008994774079512179], Loss: 2.148563, Acc:0.792483, Semantic loss: 0.805721, BCE loss: 0.558104, SB loss: 0.784738
2023-10-30 01:38:07,441 Epoch: [53/484] Iter:[380/495], Time: 0.38, lr: [0.008994393973129873], Loss: 2.147186, Acc:0.791574, Semantic loss: 0.805296, BCE loss: 0.557156, SB loss: 0.784734
2023-10-30 01:38:11,248 Epoch: [53/484] Iter:[390/495], Time: 0.38, lr: [0.008994013864962732], Loss: 2.144035, Acc:0.791050, Semantic loss: 0.804230, BCE loss: 0.555304, SB loss: 0.784501
2023-10-30 01:38:14,930 Epoch: [53/484] Iter:[400/495], Time: 0.38, lr: [0.008993633755010664], Loss: 2.144247, Acc:0.791295, Semantic loss: 0.804488, BCE loss: 0.554555, SB loss: 0.785204
2023-10-30 01:38:18,682 Epoch: [53/484] Iter:[410/495], Time: 0.38, lr: [0.008993253643273578], Loss: 2.141142, Acc:0.790305, Semantic loss: 0.803527, BCE loss: 0.553063, SB loss: 0.784552
2023-10-30 01:38:22,482 Epoch: [53/484] Iter:[420/495], Time: 0.38, lr: [0.008992873529751382], Loss: 2.141061, Acc:0.790770, Semantic loss: 0.803932, BCE loss: 0.552925, SB loss: 0.784203
2023-10-30 01:38:26,205 Epoch: [53/484] Iter:[430/495], Time: 0.38, lr: [0.008992493414443982], Loss: 2.144216, Acc:0.790930, Semantic loss: 0.808282, BCE loss: 0.550984, SB loss: 0.784950
2023-10-30 01:38:29,897 Epoch: [53/484] Iter:[440/495], Time: 0.38, lr: [0.008992113297351285], Loss: 2.144209, Acc:0.791892, Semantic loss: 0.807946, BCE loss: 0.552001, SB loss: 0.784263
2023-10-30 01:38:33,685 Epoch: [53/484] Iter:[450/495], Time: 0.38, lr: [0.008991733178473202], Loss: 2.146248, Acc:0.792324, Semantic loss: 0.808861, BCE loss: 0.553383, SB loss: 0.784003
2023-10-30 01:38:37,384 Epoch: [53/484] Iter:[460/495], Time: 0.38, lr: [0.008991353057809638], Loss: 2.149097, Acc:0.792184, Semantic loss: 0.809971, BCE loss: 0.554753, SB loss: 0.784373
2023-10-30 01:38:41,216 Epoch: [53/484] Iter:[470/495], Time: 0.38, lr: [0.0089909729353605], Loss: 2.142403, Acc:0.791943, Semantic loss: 0.807355, BCE loss: 0.552611, SB loss: 0.782438
2023-10-30 01:38:44,924 Epoch: [53/484] Iter:[480/495], Time: 0.38, lr: [0.0089905928111257], Loss: 2.147819, Acc:0.791260, Semantic loss: 0.811826, BCE loss: 0.552515, SB loss: 0.783478
2023-10-30 01:38:48,476 Epoch: [53/484] Iter:[490/495], Time: 0.38, lr: [0.008990212685105144], Loss: 2.146107, Acc:0.791064, Semantic loss: 0.810012, BCE loss: 0.553358, SB loss: 0.782738
2023-10-30 01:38:49,908 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:38:50,152 Loss: 2.149, MeanIU:  0.6736, Best_mIoU:  0.6736
2023-10-30 01:38:50,153 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ]
2023-10-30 01:38:52,283 Epoch: [54/484] Iter:[0/495], Time: 2.09, lr: [0.008990022621425177], Loss: 2.236296, Acc:0.820414, Semantic loss: 0.758486, BCE loss: 0.685651, SB loss: 0.792158
2023-10-30 01:38:56,344 Epoch: [54/484] Iter:[10/495], Time: 0.56, lr: [0.00898964249272581], Loss: 2.074890, Acc:0.789331, Semantic loss: 0.770901, BCE loss: 0.542620, SB loss: 0.761369
2023-10-30 01:39:00,121 Epoch: [54/484] Iter:[20/495], Time: 0.47, lr: [0.008989262362240458], Loss: 2.111588, Acc:0.770293, Semantic loss: 0.799371, BCE loss: 0.543724, SB loss: 0.768493
2023-10-30 01:39:03,791 Epoch: [54/484] Iter:[30/495], Time: 0.44, lr: [0.008988882229969025], Loss: 2.158544, Acc:0.770736, Semantic loss: 0.829313, BCE loss: 0.544873, SB loss: 0.784358
2023-10-30 01:39:07,581 Epoch: [54/484] Iter:[40/495], Time: 0.42, lr: [0.00898850209591142], Loss: 2.180434, Acc:0.777683, Semantic loss: 0.829241, BCE loss: 0.564298, SB loss: 0.786895
2023-10-30 01:39:11,288 Epoch: [54/484] Iter:[50/495], Time: 0.41, lr: [0.00898812196006755], Loss: 2.210934, Acc:0.786742, Semantic loss: 0.847469, BCE loss: 0.584086, SB loss: 0.779378
2023-10-30 01:39:15,089 Epoch: [54/484] Iter:[60/495], Time: 0.41, lr: [0.008987741822437324], Loss: 2.194332, Acc:0.789417, Semantic loss: 0.833427, BCE loss: 0.580903, SB loss: 0.780002
2023-10-30 01:39:19,018 Epoch: [54/484] Iter:[70/495], Time: 0.41, lr: [0.008987361683020648], Loss: 2.189125, Acc:0.792421, Semantic loss: 0.831501, BCE loss: 0.579486, SB loss: 0.778139
2023-10-30 01:39:22,741 Epoch: [54/484] Iter:[80/495], Time: 0.40, lr: [0.00898698154181743], Loss: 2.182002, Acc:0.795029, Semantic loss: 0.821046, BCE loss: 0.584804, SB loss: 0.776152
2023-10-30 01:39:26,515 Epoch: [54/484] Iter:[90/495], Time: 0.40, lr: [0.008986601398827577], Loss: 2.166403, Acc:0.796152, Semantic loss: 0.814484, BCE loss: 0.577034, SB loss: 0.774886
2023-10-30 01:39:30,233 Epoch: [54/484] Iter:[100/495], Time: 0.40, lr: [0.008986221254051], Loss: 2.157395, Acc:0.796625, Semantic loss: 0.810268, BCE loss: 0.573815, SB loss: 0.773312
2023-10-30 01:39:33,967 Epoch: [54/484] Iter:[110/495], Time: 0.39, lr: [0.008985841107487605], Loss: 2.167994, Acc:0.793209, Semantic loss: 0.819220, BCE loss: 0.572786, SB loss: 0.775988
2023-10-30 01:39:37,706 Epoch: [54/484] Iter:[120/495], Time: 0.39, lr: [0.008985460959137296], Loss: 2.155297, Acc:0.792693, Semantic loss: 0.811749, BCE loss: 0.569998, SB loss: 0.773550
2023-10-30 01:39:41,443 Epoch: [54/484] Iter:[130/495], Time: 0.39, lr: [0.008985080808999986], Loss: 2.157376, Acc:0.789854, Semantic loss: 0.811660, BCE loss: 0.570014, SB loss: 0.775702
2023-10-30 01:39:45,148 Epoch: [54/484] Iter:[140/495], Time: 0.39, lr: [0.008984700657075578], Loss: 2.171181, Acc:0.788719, Semantic loss: 0.820926, BCE loss: 0.569145, SB loss: 0.781110
2023-10-30 01:39:48,873 Epoch: [54/484] Iter:[150/495], Time: 0.39, lr: [0.008984320503363985], Loss: 2.169676, Acc:0.787085, Semantic loss: 0.821379, BCE loss: 0.565662, SB loss: 0.782635
2023-10-30 01:39:52,662 Epoch: [54/484] Iter:[160/495], Time: 0.39, lr: [0.008983940347865108], Loss: 2.175381, Acc:0.785680, Semantic loss: 0.825980, BCE loss: 0.565019, SB loss: 0.784382
2023-10-30 01:39:56,459 Epoch: [54/484] Iter:[170/495], Time: 0.39, lr: [0.008983560190578858], Loss: 2.180669, Acc:0.785071, Semantic loss: 0.829989, BCE loss: 0.565543, SB loss: 0.785137
2023-10-30 01:40:00,306 Epoch: [54/484] Iter:[180/495], Time: 0.39, lr: [0.008983180031505144], Loss: 2.176164, Acc:0.788704, Semantic loss: 0.825906, BCE loss: 0.567622, SB loss: 0.782636
2023-10-30 01:40:04,085 Epoch: [54/484] Iter:[190/495], Time: 0.39, lr: [0.008982799870643873], Loss: 2.164630, Acc:0.788064, Semantic loss: 0.819452, BCE loss: 0.562210, SB loss: 0.782968
2023-10-30 01:40:07,827 Epoch: [54/484] Iter:[200/495], Time: 0.39, lr: [0.00898241970799495], Loss: 2.159740, Acc:0.788609, Semantic loss: 0.816780, BCE loss: 0.560780, SB loss: 0.782179
2023-10-30 01:40:11,572 Epoch: [54/484] Iter:[210/495], Time: 0.39, lr: [0.008982039543558284], Loss: 2.158951, Acc:0.788082, Semantic loss: 0.817420, BCE loss: 0.560545, SB loss: 0.780987
2023-10-30 01:40:15,331 Epoch: [54/484] Iter:[220/495], Time: 0.39, lr: [0.008981659377333783], Loss: 2.173507, Acc:0.789746, Semantic loss: 0.827194, BCE loss: 0.563264, SB loss: 0.783049
2023-10-30 01:40:19,120 Epoch: [54/484] Iter:[230/495], Time: 0.38, lr: [0.008981279209321354], Loss: 2.178853, Acc:0.788870, Semantic loss: 0.830515, BCE loss: 0.563564, SB loss: 0.784774
2023-10-30 01:40:22,937 Epoch: [54/484] Iter:[240/495], Time: 0.38, lr: [0.008980899039520903], Loss: 2.175585, Acc:0.789134, Semantic loss: 0.828537, BCE loss: 0.562708, SB loss: 0.784340
2023-10-30 01:40:26,677 Epoch: [54/484] Iter:[250/495], Time: 0.38, lr: [0.00898051886793234], Loss: 2.178284, Acc:0.790295, Semantic loss: 0.828542, BCE loss: 0.563768, SB loss: 0.785973
2023-10-30 01:40:30,417 Epoch: [54/484] Iter:[260/495], Time: 0.38, lr: [0.008980138694555573], Loss: 2.178836, Acc:0.789628, Semantic loss: 0.830030, BCE loss: 0.561701, SB loss: 0.787106
2023-10-30 01:40:34,246 Epoch: [54/484] Iter:[270/495], Time: 0.38, lr: [0.008979758519390505], Loss: 2.172551, Acc:0.789546, Semantic loss: 0.826528, BCE loss: 0.560010, SB loss: 0.786013
2023-10-30 01:40:37,966 Epoch: [54/484] Iter:[280/495], Time: 0.38, lr: [0.008979378342437049], Loss: 2.168900, Acc:0.789815, Semantic loss: 0.824758, BCE loss: 0.560131, SB loss: 0.784011
2023-10-30 01:40:41,832 Epoch: [54/484] Iter:[290/495], Time: 0.38, lr: [0.00897899816369511], Loss: 2.165606, Acc:0.789662, Semantic loss: 0.822432, BCE loss: 0.559296, SB loss: 0.783878
2023-10-30 01:40:45,617 Epoch: [54/484] Iter:[300/495], Time: 0.38, lr: [0.008978617983164594], Loss: 2.161246, Acc:0.789542, Semantic loss: 0.820825, BCE loss: 0.557541, SB loss: 0.782879
2023-10-30 01:40:49,359 Epoch: [54/484] Iter:[310/495], Time: 0.38, lr: [0.00897823780084541], Loss: 2.155758, Acc:0.789037, Semantic loss: 0.818587, BCE loss: 0.555736, SB loss: 0.781435
2023-10-30 01:40:53,150 Epoch: [54/484] Iter:[320/495], Time: 0.38, lr: [0.008977857616737467], Loss: 2.155437, Acc:0.789485, Semantic loss: 0.818929, BCE loss: 0.554949, SB loss: 0.781559
2023-10-30 01:40:56,952 Epoch: [54/484] Iter:[330/495], Time: 0.38, lr: [0.008977477430840668], Loss: 2.154565, Acc:0.789960, Semantic loss: 0.818618, BCE loss: 0.554120, SB loss: 0.781827
2023-10-30 01:41:00,698 Epoch: [54/484] Iter:[340/495], Time: 0.38, lr: [0.008977097243154925], Loss: 2.155480, Acc:0.790685, Semantic loss: 0.817482, BCE loss: 0.555715, SB loss: 0.782283
2023-10-30 01:41:04,484 Epoch: [54/484] Iter:[350/495], Time: 0.38, lr: [0.008976717053680144], Loss: 2.157686, Acc:0.791402, Semantic loss: 0.818035, BCE loss: 0.557880, SB loss: 0.781770
2023-10-30 01:41:08,200 Epoch: [54/484] Iter:[360/495], Time: 0.38, lr: [0.008976336862416228], Loss: 2.161992, Acc:0.790795, Semantic loss: 0.818825, BCE loss: 0.559843, SB loss: 0.783325
2023-10-30 01:41:11,929 Epoch: [54/484] Iter:[370/495], Time: 0.38, lr: [0.008975956669363093], Loss: 2.167821, Acc:0.790144, Semantic loss: 0.823402, BCE loss: 0.560829, SB loss: 0.783589
2023-10-30 01:41:15,755 Epoch: [54/484] Iter:[380/495], Time: 0.38, lr: [0.008975576474520639], Loss: 2.165580, Acc:0.789555, Semantic loss: 0.822140, BCE loss: 0.560874, SB loss: 0.782566
2023-10-30 01:41:19,549 Epoch: [54/484] Iter:[390/495], Time: 0.38, lr: [0.008975196277888776], Loss: 2.160556, Acc:0.790775, Semantic loss: 0.819229, BCE loss: 0.559172, SB loss: 0.782155
2023-10-30 01:41:23,458 Epoch: [54/484] Iter:[400/495], Time: 0.38, lr: [0.008974816079467414], Loss: 2.167794, Acc:0.791298, Semantic loss: 0.824986, BCE loss: 0.559213, SB loss: 0.783595
2023-10-30 01:41:27,225 Epoch: [54/484] Iter:[410/495], Time: 0.38, lr: [0.008974435879256453], Loss: 2.165308, Acc:0.791262, Semantic loss: 0.823572, BCE loss: 0.558990, SB loss: 0.782746
2023-10-30 01:41:30,986 Epoch: [54/484] Iter:[420/495], Time: 0.38, lr: [0.008974055677255809], Loss: 2.163134, Acc:0.791615, Semantic loss: 0.822557, BCE loss: 0.558474, SB loss: 0.782103
2023-10-30 01:41:34,730 Epoch: [54/484] Iter:[430/495], Time: 0.38, lr: [0.008973675473465384], Loss: 2.164811, Acc:0.792367, Semantic loss: 0.824653, BCE loss: 0.557839, SB loss: 0.782320
2023-10-30 01:41:38,497 Epoch: [54/484] Iter:[440/495], Time: 0.38, lr: [0.008973295267885085], Loss: 2.163412, Acc:0.792698, Semantic loss: 0.822447, BCE loss: 0.559162, SB loss: 0.781804
2023-10-30 01:41:42,419 Epoch: [54/484] Iter:[450/495], Time: 0.38, lr: [0.008972915060514822], Loss: 2.162943, Acc:0.793764, Semantic loss: 0.821393, BCE loss: 0.560210, SB loss: 0.781341
2023-10-30 01:41:46,177 Epoch: [54/484] Iter:[460/495], Time: 0.38, lr: [0.008972534851354503], Loss: 2.163473, Acc:0.794165, Semantic loss: 0.821558, BCE loss: 0.560222, SB loss: 0.781694
2023-10-30 01:41:49,929 Epoch: [54/484] Iter:[470/495], Time: 0.38, lr: [0.008972154640404031], Loss: 2.164010, Acc:0.793927, Semantic loss: 0.822201, BCE loss: 0.559576, SB loss: 0.782233
2023-10-30 01:41:53,647 Epoch: [54/484] Iter:[480/495], Time: 0.38, lr: [0.008971774427663318], Loss: 2.164536, Acc:0.793669, Semantic loss: 0.823307, BCE loss: 0.558965, SB loss: 0.782264
2023-10-30 01:41:57,307 Epoch: [54/484] Iter:[490/495], Time: 0.38, lr: [0.008971394213132268], Loss: 2.161484, Acc:0.793182, Semantic loss: 0.821094, BCE loss: 0.558831, SB loss: 0.781559
2023-10-30 01:41:58,726 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:41:58,966 Loss: 2.149, MeanIU:  0.6736, Best_mIoU:  0.6736
2023-10-30 01:41:58,966 [0.97046146 0.77893953 0.89828839 0.39487381 0.55362286 0.53789529
 0.63701756 0.70055646 0.90264679 0.5319903  0.91553551 0.7304744
 0.53649322 0.92089668 0.51591853 0.57888387 0.50260551 0.4706102
 0.7208174 ]
2023-10-30 01:42:01,044 Epoch: [55/484] Iter:[0/495], Time: 2.04, lr: [0.008971204105195337], Loss: 2.384511, Acc:0.806139, Semantic loss: 0.846941, BCE loss: 0.640588, SB loss: 0.896981
2023-10-30 01:42:05,211 Epoch: [55/484] Iter:[10/495], Time: 0.56, lr: [0.00897082388797861], Loss: 2.224733, Acc:0.799837, Semantic loss: 0.888525, BCE loss: 0.542220, SB loss: 0.793989
2023-10-30 01:42:09,096 Epoch: [55/484] Iter:[20/495], Time: 0.48, lr: [0.008970443668971316], Loss: 2.160473, Acc:0.813033, Semantic loss: 0.839045, BCE loss: 0.546678, SB loss: 0.774750
2023-10-30 01:42:12,834 Epoch: [55/484] Iter:[30/495], Time: 0.45, lr: [0.008970063448173358], Loss: 2.202599, Acc:0.807906, Semantic loss: 0.860848, BCE loss: 0.550453, SB loss: 0.791298
2023-10-30 01:42:16,637 Epoch: [55/484] Iter:[40/495], Time: 0.43, lr: [0.008969683225584649], Loss: 2.174374, Acc:0.806054, Semantic loss: 0.843669, BCE loss: 0.546578, SB loss: 0.784127
2023-10-30 01:42:20,387 Epoch: [55/484] Iter:[50/495], Time: 0.42, lr: [0.008969303001205095], Loss: 2.183021, Acc:0.805715, Semantic loss: 0.860078, BCE loss: 0.536545, SB loss: 0.786398
2023-10-30 01:42:24,242 Epoch: [55/484] Iter:[60/495], Time: 0.41, lr: [0.0089689227750346], Loss: 2.185453, Acc:0.809107, Semantic loss: 0.846719, BCE loss: 0.552981, SB loss: 0.785754
2023-10-30 01:42:28,027 Epoch: [55/484] Iter:[70/495], Time: 0.41, lr: [0.008968542547073074], Loss: 2.184101, Acc:0.809539, Semantic loss: 0.841998, BCE loss: 0.556223, SB loss: 0.785880
2023-10-30 01:42:31,901 Epoch: [55/484] Iter:[80/495], Time: 0.41, lr: [0.008968162317320423], Loss: 2.164671, Acc:0.807261, Semantic loss: 0.829021, BCE loss: 0.555802, SB loss: 0.779847
2023-10-30 01:42:35,668 Epoch: [55/484] Iter:[90/495], Time: 0.40, lr: [0.008967782085776557], Loss: 2.180744, Acc:0.807499, Semantic loss: 0.834858, BCE loss: 0.565335, SB loss: 0.780551
2023-10-30 01:42:39,457 Epoch: [55/484] Iter:[100/495], Time: 0.40, lr: [0.008967401852441378], Loss: 2.174646, Acc:0.806449, Semantic loss: 0.832154, BCE loss: 0.563636, SB loss: 0.778857
2023-10-30 01:42:43,246 Epoch: [55/484] Iter:[110/495], Time: 0.40, lr: [0.008967021617314799], Loss: 2.162244, Acc:0.805362, Semantic loss: 0.824642, BCE loss: 0.562307, SB loss: 0.775295
2023-10-30 01:42:46,971 Epoch: [55/484] Iter:[120/495], Time: 0.40, lr: [0.008966641380396722], Loss: 2.161885, Acc:0.802376, Semantic loss: 0.827496, BCE loss: 0.559617, SB loss: 0.774772
2023-10-30 01:42:50,688 Epoch: [55/484] Iter:[130/495], Time: 0.39, lr: [0.008966261141687056], Loss: 2.174498, Acc:0.801457, Semantic loss: 0.833096, BCE loss: 0.563234, SB loss: 0.778168
2023-10-30 01:42:54,413 Epoch: [55/484] Iter:[140/495], Time: 0.39, lr: [0.00896588090118571], Loss: 2.182432, Acc:0.801273, Semantic loss: 0.836726, BCE loss: 0.566061, SB loss: 0.779646
2023-10-30 01:42:58,217 Epoch: [55/484] Iter:[150/495], Time: 0.39, lr: [0.00896550065889259], Loss: 2.172333, Acc:0.800351, Semantic loss: 0.828974, BCE loss: 0.565843, SB loss: 0.777516
2023-10-30 01:43:01,985 Epoch: [55/484] Iter:[160/495], Time: 0.39, lr: [0.0089651204148076], Loss: 2.173100, Acc:0.799642, Semantic loss: 0.826791, BCE loss: 0.568100, SB loss: 0.778209
2023-10-30 01:43:05,832 Epoch: [55/484] Iter:[170/495], Time: 0.39, lr: [0.008964740168930653], Loss: 2.172366, Acc:0.800546, Semantic loss: 0.827510, BCE loss: 0.568027, SB loss: 0.776829
2023-10-30 01:43:09,606 Epoch: [55/484] Iter:[180/495], Time: 0.39, lr: [0.008964359921261652], Loss: 2.167262, Acc:0.797637, Semantic loss: 0.823829, BCE loss: 0.564422, SB loss: 0.779012
2023-10-30 01:43:13,356 Epoch: [55/484] Iter:[190/495], Time: 0.39, lr: [0.008963979671800505], Loss: 2.163712, Acc:0.797045, Semantic loss: 0.821106, BCE loss: 0.565009, SB loss: 0.777597
2023-10-30 01:43:17,056 Epoch: [55/484] Iter:[200/495], Time: 0.39, lr: [0.008963599420547119], Loss: 2.162373, Acc:0.795620, Semantic loss: 0.819953, BCE loss: 0.564585, SB loss: 0.777835
2023-10-30 01:43:20,819 Epoch: [55/484] Iter:[210/495], Time: 0.39, lr: [0.0089632191675014], Loss: 2.164151, Acc:0.795745, Semantic loss: 0.821105, BCE loss: 0.564874, SB loss: 0.778173
2023-10-30 01:43:24,578 Epoch: [55/484] Iter:[220/495], Time: 0.39, lr: [0.008962838912663258], Loss: 2.160978, Acc:0.795479, Semantic loss: 0.817387, BCE loss: 0.565186, SB loss: 0.778405
2023-10-30 01:43:28,319 Epoch: [55/484] Iter:[230/495], Time: 0.39, lr: [0.008962458656032598], Loss: 2.157247, Acc:0.795389, Semantic loss: 0.815516, BCE loss: 0.563754, SB loss: 0.777976
2023-10-30 01:43:32,065 Epoch: [55/484] Iter:[240/495], Time: 0.39, lr: [0.008962078397609326], Loss: 2.158201, Acc:0.794938, Semantic loss: 0.815737, BCE loss: 0.564196, SB loss: 0.778268
2023-10-30 01:43:35,918 Epoch: [55/484] Iter:[250/495], Time: 0.39, lr: [0.00896169813739335], Loss: 2.154603, Acc:0.793834, Semantic loss: 0.814446, BCE loss: 0.563518, SB loss: 0.776638
2023-10-30 01:43:39,644 Epoch: [55/484] Iter:[260/495], Time: 0.39, lr: [0.00896131787538458], Loss: 2.158074, Acc:0.793232, Semantic loss: 0.816653, BCE loss: 0.563625, SB loss: 0.777796
2023-10-30 01:43:43,520 Epoch: [55/484] Iter:[270/495], Time: 0.39, lr: [0.00896093761158292], Loss: 2.157825, Acc:0.792717, Semantic loss: 0.816411, BCE loss: 0.563490, SB loss: 0.777925
2023-10-30 01:43:47,310 Epoch: [55/484] Iter:[280/495], Time: 0.39, lr: [0.008960557345988277], Loss: 2.158419, Acc:0.794308, Semantic loss: 0.815666, BCE loss: 0.564717, SB loss: 0.778037
2023-10-30 01:43:51,047 Epoch: [55/484] Iter:[290/495], Time: 0.39, lr: [0.008960177078600558], Loss: 2.161099, Acc:0.794176, Semantic loss: 0.818242, BCE loss: 0.563981, SB loss: 0.778876
2023-10-30 01:43:54,865 Epoch: [55/484] Iter:[300/495], Time: 0.38, lr: [0.008959796809419671], Loss: 2.162733, Acc:0.794880, Semantic loss: 0.819514, BCE loss: 0.563395, SB loss: 0.779824
2023-10-30 01:43:58,656 Epoch: [55/484] Iter:[310/495], Time: 0.38, lr: [0.008959416538445522], Loss: 2.157614, Acc:0.795193, Semantic loss: 0.815818, BCE loss: 0.563240, SB loss: 0.778556
2023-10-30 01:44:02,366 Epoch: [55/484] Iter:[320/495], Time: 0.38, lr: [0.00895903626567802], Loss: 2.160522, Acc:0.794889, Semantic loss: 0.818248, BCE loss: 0.562443, SB loss: 0.779831
2023-10-30 01:44:06,287 Epoch: [55/484] Iter:[330/495], Time: 0.38, lr: [0.008958655991117068], Loss: 2.156525, Acc:0.794285, Semantic loss: 0.816386, BCE loss: 0.561122, SB loss: 0.779018
2023-10-30 01:44:10,019 Epoch: [55/484] Iter:[340/495], Time: 0.38, lr: [0.008958275714762575], Loss: 2.155647, Acc:0.794242, Semantic loss: 0.815283, BCE loss: 0.561156, SB loss: 0.779207
2023-10-30 01:44:13,703 Epoch: [55/484] Iter:[350/495], Time: 0.38, lr: [0.008957895436614452], Loss: 2.152623, Acc:0.793936, Semantic loss: 0.813480, BCE loss: 0.560036, SB loss: 0.779108
2023-10-30 01:44:17,457 Epoch: [55/484] Iter:[360/495], Time: 0.38, lr: [0.0089575151566726], Loss: 2.150521, Acc:0.794280, Semantic loss: 0.812884, BCE loss: 0.559391, SB loss: 0.778246
2023-10-30 01:44:21,239 Epoch: [55/484] Iter:[370/495], Time: 0.38, lr: [0.008957134874936927], Loss: 2.148294, Acc:0.793466, Semantic loss: 0.811683, BCE loss: 0.558040, SB loss: 0.778570
2023-10-30 01:44:25,040 Epoch: [55/484] Iter:[380/495], Time: 0.38, lr: [0.008956754591407344], Loss: 2.149265, Acc:0.793697, Semantic loss: 0.811417, BCE loss: 0.559408, SB loss: 0.778440
2023-10-30 01:44:28,876 Epoch: [55/484] Iter:[390/495], Time: 0.38, lr: [0.008956374306083752], Loss: 2.147697, Acc:0.793671, Semantic loss: 0.810075, BCE loss: 0.560269, SB loss: 0.777354
2023-10-30 01:44:32,538 Epoch: [55/484] Iter:[400/495], Time: 0.38, lr: [0.008955994018966061], Loss: 2.148941, Acc:0.794001, Semantic loss: 0.809576, BCE loss: 0.561701, SB loss: 0.777665
2023-10-30 01:44:36,341 Epoch: [55/484] Iter:[410/495], Time: 0.38, lr: [0.00895561373005418], Loss: 2.147350, Acc:0.793346, Semantic loss: 0.809833, BCE loss: 0.560732, SB loss: 0.776785
2023-10-30 01:44:40,156 Epoch: [55/484] Iter:[420/495], Time: 0.38, lr: [0.008955233439348011], Loss: 2.143933, Acc:0.793368, Semantic loss: 0.807932, BCE loss: 0.559677, SB loss: 0.776325
2023-10-30 01:44:43,961 Epoch: [55/484] Iter:[430/495], Time: 0.38, lr: [0.008954853146847465], Loss: 2.149277, Acc:0.792843, Semantic loss: 0.811722, BCE loss: 0.560916, SB loss: 0.776639
2023-10-30 01:44:47,851 Epoch: [55/484] Iter:[440/495], Time: 0.38, lr: [0.008954472852552449], Loss: 2.149586, Acc:0.792209, Semantic loss: 0.811384, BCE loss: 0.561089, SB loss: 0.777112
2023-10-30 01:44:51,562 Epoch: [55/484] Iter:[450/495], Time: 0.38, lr: [0.008954092556462866], Loss: 2.145630, Acc:0.791992, Semantic loss: 0.808987, BCE loss: 0.560637, SB loss: 0.776006
2023-10-30 01:44:55,372 Epoch: [55/484] Iter:[460/495], Time: 0.38, lr: [0.008953712258578626], Loss: 2.147672, Acc:0.791852, Semantic loss: 0.810344, BCE loss: 0.560368, SB loss: 0.776960
2023-10-30 01:44:59,069 Epoch: [55/484] Iter:[470/495], Time: 0.38, lr: [0.008953331958899633], Loss: 2.146862, Acc:0.791298, Semantic loss: 0.809813, BCE loss: 0.560764, SB loss: 0.776286
2023-10-30 01:45:02,762 Epoch: [55/484] Iter:[480/495], Time: 0.38, lr: [0.008952951657425798], Loss: 2.148167, Acc:0.791706, Semantic loss: 0.811277, BCE loss: 0.560096, SB loss: 0.776794
2023-10-30 01:45:06,388 Epoch: [55/484] Iter:[490/495], Time: 0.38, lr: [0.008952571354157026], Loss: 2.145960, Acc:0.791708, Semantic loss: 0.810552, BCE loss: 0.558848, SB loss: 0.776559
2023-10-30 01:48:04,088 0 [9.21149506e-01 6.05633395e-01 8.04429456e-01 8.46632978e-02
 2.07733789e-01 3.99469117e-01 4.20816852e-01 5.59465570e-01
 8.65073586e-01 3.80142270e-01 8.27062537e-01 5.83361087e-01
 1.29950325e-02 7.25115882e-01 1.52284172e-04 9.73524024e-02
 3.31582380e-02 3.64052780e-02 5.21566342e-01] 0.4255655748204936
2023-10-30 01:48:04,089 1 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886] 0.6495780169057594
2023-10-30 01:48:04,092 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:48:04,331 Loss: 2.244, MeanIU:  0.6496, Best_mIoU:  0.6736
2023-10-30 01:48:04,331 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886]
2023-10-30 01:48:06,743 Epoch: [56/484] Iter:[0/495], Time: 2.38, lr: [0.008952381201849508], Loss: 2.249714, Acc:0.820202, Semantic loss: 0.883739, BCE loss: 0.524967, SB loss: 0.841007
2023-10-30 01:48:10,510 Epoch: [56/484] Iter:[10/495], Time: 0.56, lr: [0.008952000895888153], Loss: 2.184800, Acc:0.795485, Semantic loss: 0.888626, BCE loss: 0.549500, SB loss: 0.746674
2023-10-30 01:48:14,028 Epoch: [56/484] Iter:[20/495], Time: 0.46, lr: [0.008951620588131629], Loss: 2.202595, Acc:0.785299, Semantic loss: 0.844491, BCE loss: 0.576124, SB loss: 0.781980
2023-10-30 01:48:17,619 Epoch: [56/484] Iter:[30/495], Time: 0.43, lr: [0.008951240278579842], Loss: 2.212402, Acc:0.781374, Semantic loss: 0.860589, BCE loss: 0.564881, SB loss: 0.786931
2023-10-30 01:48:21,117 Epoch: [56/484] Iter:[40/495], Time: 0.41, lr: [0.008950859967232697], Loss: 2.139573, Acc:0.774177, Semantic loss: 0.813138, BCE loss: 0.542600, SB loss: 0.783835
2023-10-30 01:48:24,720 Epoch: [56/484] Iter:[50/495], Time: 0.40, lr: [0.0089504796540901], Loss: 2.135940, Acc:0.775722, Semantic loss: 0.806341, BCE loss: 0.547735, SB loss: 0.781864
2023-10-30 01:48:28,252 Epoch: [56/484] Iter:[60/495], Time: 0.39, lr: [0.008950099339151963], Loss: 2.126803, Acc:0.780744, Semantic loss: 0.797791, BCE loss: 0.551529, SB loss: 0.777484
2023-10-30 01:48:31,813 Epoch: [56/484] Iter:[70/495], Time: 0.39, lr: [0.008949719022418187], Loss: 2.107927, Acc:0.784856, Semantic loss: 0.790895, BCE loss: 0.546381, SB loss: 0.770650
2023-10-30 01:48:35,408 Epoch: [56/484] Iter:[80/495], Time: 0.38, lr: [0.008949338703888683], Loss: 2.128732, Acc:0.781402, Semantic loss: 0.800924, BCE loss: 0.549229, SB loss: 0.778578
2023-10-30 01:48:38,994 Epoch: [56/484] Iter:[90/495], Time: 0.38, lr: [0.008948958383563353], Loss: 2.142274, Acc:0.779287, Semantic loss: 0.807395, BCE loss: 0.554243, SB loss: 0.780636
2023-10-30 01:48:42,620 Epoch: [56/484] Iter:[100/495], Time: 0.38, lr: [0.00894857806144211], Loss: 2.143672, Acc:0.779037, Semantic loss: 0.807828, BCE loss: 0.553816, SB loss: 0.782027
2023-10-30 01:48:46,336 Epoch: [56/484] Iter:[110/495], Time: 0.38, lr: [0.008948197737524855], Loss: 2.134787, Acc:0.778390, Semantic loss: 0.804323, BCE loss: 0.549842, SB loss: 0.780621
2023-10-30 01:48:49,963 Epoch: [56/484] Iter:[120/495], Time: 0.38, lr: [0.008947817411811498], Loss: 2.139056, Acc:0.781688, Semantic loss: 0.801801, BCE loss: 0.555721, SB loss: 0.781533
2023-10-30 01:48:53,574 Epoch: [56/484] Iter:[130/495], Time: 0.38, lr: [0.008947437084301943], Loss: 2.144055, Acc:0.778839, Semantic loss: 0.804537, BCE loss: 0.556261, SB loss: 0.783257
2023-10-30 01:48:57,252 Epoch: [56/484] Iter:[140/495], Time: 0.38, lr: [0.0089470567549961], Loss: 2.143302, Acc:0.780007, Semantic loss: 0.807478, BCE loss: 0.553684, SB loss: 0.782140
2023-10-30 01:49:00,956 Epoch: [56/484] Iter:[150/495], Time: 0.37, lr: [0.008946676423893875], Loss: 2.143781, Acc:0.780135, Semantic loss: 0.804886, BCE loss: 0.556841, SB loss: 0.782054
2023-10-30 01:49:04,626 Epoch: [56/484] Iter:[160/495], Time: 0.37, lr: [0.008946296090995173], Loss: 2.142161, Acc:0.780903, Semantic loss: 0.806209, BCE loss: 0.555632, SB loss: 0.780320
2023-10-30 01:49:08,326 Epoch: [56/484] Iter:[170/495], Time: 0.37, lr: [0.0089459157562999], Loss: 2.150773, Acc:0.780478, Semantic loss: 0.810693, BCE loss: 0.558751, SB loss: 0.781328
2023-10-30 01:49:12,041 Epoch: [56/484] Iter:[180/495], Time: 0.37, lr: [0.008945535419807964], Loss: 2.145743, Acc:0.782289, Semantic loss: 0.805727, BCE loss: 0.560152, SB loss: 0.779864
2023-10-30 01:49:15,754 Epoch: [56/484] Iter:[190/495], Time: 0.37, lr: [0.008945155081519272], Loss: 2.133061, Acc:0.783621, Semantic loss: 0.798720, BCE loss: 0.558151, SB loss: 0.776189
2023-10-30 01:49:19,488 Epoch: [56/484] Iter:[200/495], Time: 0.37, lr: [0.008944774741433731], Loss: 2.145078, Acc:0.784110, Semantic loss: 0.803502, BCE loss: 0.563691, SB loss: 0.777885
2023-10-30 01:49:23,157 Epoch: [56/484] Iter:[210/495], Time: 0.37, lr: [0.008944394399551246], Loss: 2.148540, Acc:0.785761, Semantic loss: 0.805658, BCE loss: 0.564720, SB loss: 0.778162
2023-10-30 01:49:26,864 Epoch: [56/484] Iter:[220/495], Time: 0.37, lr: [0.008944014055871726], Loss: 2.148726, Acc:0.786359, Semantic loss: 0.804595, BCE loss: 0.565573, SB loss: 0.778559
2023-10-30 01:49:30,532 Epoch: [56/484] Iter:[230/495], Time: 0.37, lr: [0.008943633710395076], Loss: 2.147695, Acc:0.788175, Semantic loss: 0.804650, BCE loss: 0.565255, SB loss: 0.777791
2023-10-30 01:49:34,278 Epoch: [56/484] Iter:[240/495], Time: 0.37, lr: [0.0089432533631212], Loss: 2.142219, Acc:0.787644, Semantic loss: 0.804191, BCE loss: 0.562785, SB loss: 0.775242
2023-10-30 01:49:37,969 Epoch: [56/484] Iter:[250/495], Time: 0.37, lr: [0.008942873014050008], Loss: 2.145490, Acc:0.787937, Semantic loss: 0.804524, BCE loss: 0.564174, SB loss: 0.776791
2023-10-30 01:49:41,752 Epoch: [56/484] Iter:[260/495], Time: 0.37, lr: [0.008942492663181407], Loss: 2.145680, Acc:0.789174, Semantic loss: 0.805218, BCE loss: 0.563032, SB loss: 0.777430
2023-10-30 01:49:45,505 Epoch: [56/484] Iter:[270/495], Time: 0.37, lr: [0.008942112310515303], Loss: 2.144918, Acc:0.788995, Semantic loss: 0.805754, BCE loss: 0.562584, SB loss: 0.776580
2023-10-30 01:49:49,242 Epoch: [56/484] Iter:[280/495], Time: 0.37, lr: [0.0089417319560516], Loss: 2.152461, Acc:0.787569, Semantic loss: 0.811101, BCE loss: 0.562798, SB loss: 0.778562
2023-10-30 01:49:52,988 Epoch: [56/484] Iter:[290/495], Time: 0.37, lr: [0.008941351599790207], Loss: 2.151574, Acc:0.787709, Semantic loss: 0.811289, BCE loss: 0.561790, SB loss: 0.778494
2023-10-30 01:49:56,880 Epoch: [56/484] Iter:[300/495], Time: 0.37, lr: [0.008940971241731032], Loss: 2.147803, Acc:0.787702, Semantic loss: 0.808080, BCE loss: 0.561531, SB loss: 0.778192
2023-10-30 01:50:00,645 Epoch: [56/484] Iter:[310/495], Time: 0.37, lr: [0.008940590881873978], Loss: 2.150189, Acc:0.788703, Semantic loss: 0.809163, BCE loss: 0.563178, SB loss: 0.777848
2023-10-30 01:50:04,469 Epoch: [56/484] Iter:[320/495], Time: 0.37, lr: [0.008940210520218952], Loss: 2.148557, Acc:0.789735, Semantic loss: 0.808147, BCE loss: 0.562846, SB loss: 0.777564
2023-10-30 01:50:08,202 Epoch: [56/484] Iter:[330/495], Time: 0.37, lr: [0.008939830156765862], Loss: 2.141903, Acc:0.788200, Semantic loss: 0.804826, BCE loss: 0.560621, SB loss: 0.776457
2023-10-30 01:50:12,008 Epoch: [56/484] Iter:[340/495], Time: 0.37, lr: [0.008939449791514616], Loss: 2.143945, Acc:0.787618, Semantic loss: 0.806859, BCE loss: 0.559730, SB loss: 0.777355
2023-10-30 01:50:15,742 Epoch: [56/484] Iter:[350/495], Time: 0.37, lr: [0.008939069424465117], Loss: 2.144454, Acc:0.788396, Semantic loss: 0.807053, BCE loss: 0.559462, SB loss: 0.777939
2023-10-30 01:50:19,486 Epoch: [56/484] Iter:[360/495], Time: 0.37, lr: [0.008938689055617273], Loss: 2.141667, Acc:0.788069, Semantic loss: 0.805490, BCE loss: 0.558798, SB loss: 0.777379
2023-10-30 01:50:23,264 Epoch: [56/484] Iter:[370/495], Time: 0.37, lr: [0.00893830868497099], Loss: 2.138014, Acc:0.787899, Semantic loss: 0.804720, BCE loss: 0.556769, SB loss: 0.776525
2023-10-30 01:50:27,088 Epoch: [56/484] Iter:[380/495], Time: 0.37, lr: [0.008937928312526176], Loss: 2.135554, Acc:0.787684, Semantic loss: 0.803933, BCE loss: 0.555568, SB loss: 0.776053
2023-10-30 01:50:30,853 Epoch: [56/484] Iter:[390/495], Time: 0.37, lr: [0.008937547938282737], Loss: 2.134079, Acc:0.788055, Semantic loss: 0.802179, BCE loss: 0.555872, SB loss: 0.776028
2023-10-30 01:50:34,641 Epoch: [56/484] Iter:[400/495], Time: 0.37, lr: [0.008937167562240576], Loss: 2.134779, Acc:0.788890, Semantic loss: 0.802844, BCE loss: 0.555123, SB loss: 0.776812
2023-10-30 01:50:38,411 Epoch: [56/484] Iter:[410/495], Time: 0.37, lr: [0.008936787184399605], Loss: 2.133986, Acc:0.788394, Semantic loss: 0.802390, BCE loss: 0.555091, SB loss: 0.776505
2023-10-30 01:50:42,198 Epoch: [56/484] Iter:[420/495], Time: 0.37, lr: [0.008936406804759725], Loss: 2.134648, Acc:0.788362, Semantic loss: 0.802977, BCE loss: 0.554741, SB loss: 0.776931
2023-10-30 01:50:45,941 Epoch: [56/484] Iter:[430/495], Time: 0.37, lr: [0.008936026423320849], Loss: 2.139707, Acc:0.788972, Semantic loss: 0.804035, BCE loss: 0.557098, SB loss: 0.778574
2023-10-30 01:50:49,604 Epoch: [56/484] Iter:[440/495], Time: 0.37, lr: [0.008935646040082875], Loss: 2.151387, Acc:0.788350, Semantic loss: 0.812650, BCE loss: 0.557395, SB loss: 0.781341
2023-10-30 01:50:53,329 Epoch: [56/484] Iter:[450/495], Time: 0.37, lr: [0.008935265655045717], Loss: 2.154309, Acc:0.787855, Semantic loss: 0.813887, BCE loss: 0.558319, SB loss: 0.782103
2023-10-30 01:50:57,166 Epoch: [56/484] Iter:[460/495], Time: 0.37, lr: [0.008934885268209278], Loss: 2.151141, Acc:0.788262, Semantic loss: 0.811281, BCE loss: 0.557821, SB loss: 0.782039
2023-10-30 01:51:00,883 Epoch: [56/484] Iter:[470/495], Time: 0.37, lr: [0.008934504879573464], Loss: 2.150525, Acc:0.788196, Semantic loss: 0.810687, BCE loss: 0.557904, SB loss: 0.781934
2023-10-30 01:51:04,639 Epoch: [56/484] Iter:[480/495], Time: 0.37, lr: [0.008934124489138183], Loss: 2.147465, Acc:0.788656, Semantic loss: 0.808875, BCE loss: 0.556951, SB loss: 0.781639
2023-10-30 01:51:08,218 Epoch: [56/484] Iter:[490/495], Time: 0.37, lr: [0.008933744096903338], Loss: 2.149019, Acc:0.788141, Semantic loss: 0.810190, BCE loss: 0.556761, SB loss: 0.782067
2023-10-30 01:51:09,666 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:51:09,908 Loss: 2.244, MeanIU:  0.6496, Best_mIoU:  0.6736
2023-10-30 01:51:09,908 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886]
2023-10-30 01:51:12,065 Epoch: [57/484] Iter:[0/495], Time: 2.12, lr: [0.008933553900111052], Loss: 1.945483, Acc:0.740266, Semantic loss: 0.702761, BCE loss: 0.520053, SB loss: 0.722670
2023-10-30 01:51:16,030 Epoch: [57/484] Iter:[10/495], Time: 0.55, lr: [0.008933173505176691], Loss: 2.083613, Acc:0.781482, Semantic loss: 0.787671, BCE loss: 0.546830, SB loss: 0.749112
2023-10-30 01:51:19,729 Epoch: [57/484] Iter:[20/495], Time: 0.47, lr: [0.008932793108442534], Loss: 2.170472, Acc:0.784115, Semantic loss: 0.865584, BCE loss: 0.527170, SB loss: 0.777718
2023-10-30 01:51:23,627 Epoch: [57/484] Iter:[30/495], Time: 0.44, lr: [0.008932412709908487], Loss: 2.172028, Acc:0.780160, Semantic loss: 0.847629, BCE loss: 0.535470, SB loss: 0.788930
2023-10-30 01:51:27,554 Epoch: [57/484] Iter:[40/495], Time: 0.43, lr: [0.008932032309574458], Loss: 2.159438, Acc:0.788764, Semantic loss: 0.839017, BCE loss: 0.531019, SB loss: 0.789402
2023-10-30 01:51:31,378 Epoch: [57/484] Iter:[50/495], Time: 0.42, lr: [0.00893165190744035], Loss: 2.182407, Acc:0.786499, Semantic loss: 0.856125, BCE loss: 0.535542, SB loss: 0.790740
2023-10-30 01:51:35,240 Epoch: [57/484] Iter:[60/495], Time: 0.41, lr: [0.008931271503506073], Loss: 2.179992, Acc:0.786612, Semantic loss: 0.846910, BCE loss: 0.541249, SB loss: 0.791833
2023-10-30 01:51:39,224 Epoch: [57/484] Iter:[70/495], Time: 0.41, lr: [0.008930891097771532], Loss: 2.191965, Acc:0.786489, Semantic loss: 0.853553, BCE loss: 0.548328, SB loss: 0.790084
2023-10-30 01:51:43,096 Epoch: [57/484] Iter:[80/495], Time: 0.41, lr: [0.008930510690236633], Loss: 2.173564, Acc:0.790792, Semantic loss: 0.836919, BCE loss: 0.549905, SB loss: 0.786741
2023-10-30 01:51:46,786 Epoch: [57/484] Iter:[90/495], Time: 0.40, lr: [0.008930130280901281], Loss: 2.191573, Acc:0.787819, Semantic loss: 0.846438, BCE loss: 0.554491, SB loss: 0.790643
2023-10-30 01:51:50,467 Epoch: [57/484] Iter:[100/495], Time: 0.40, lr: [0.008929749869765384], Loss: 2.171445, Acc:0.789719, Semantic loss: 0.833088, BCE loss: 0.550844, SB loss: 0.787513
2023-10-30 01:51:54,118 Epoch: [57/484] Iter:[110/495], Time: 0.40, lr: [0.008929369456828849], Loss: 2.182112, Acc:0.790067, Semantic loss: 0.838263, BCE loss: 0.554965, SB loss: 0.788884
2023-10-30 01:51:57,706 Epoch: [57/484] Iter:[120/495], Time: 0.39, lr: [0.00892898904209158], Loss: 2.179371, Acc:0.788918, Semantic loss: 0.833156, BCE loss: 0.557471, SB loss: 0.788744
2023-10-30 01:52:01,316 Epoch: [57/484] Iter:[130/495], Time: 0.39, lr: [0.008928608625553487], Loss: 2.183263, Acc:0.789495, Semantic loss: 0.838971, BCE loss: 0.555596, SB loss: 0.788696
2023-10-30 01:52:04,981 Epoch: [57/484] Iter:[140/495], Time: 0.39, lr: [0.00892822820721447], Loss: 2.181828, Acc:0.789837, Semantic loss: 0.836416, BCE loss: 0.555151, SB loss: 0.790261
2023-10-30 01:52:08,629 Epoch: [57/484] Iter:[150/495], Time: 0.39, lr: [0.00892784778707444], Loss: 2.188792, Acc:0.792250, Semantic loss: 0.837781, BCE loss: 0.560082, SB loss: 0.790929
2023-10-30 01:52:12,320 Epoch: [57/484] Iter:[160/495], Time: 0.39, lr: [0.008927467365133302], Loss: 2.199436, Acc:0.792460, Semantic loss: 0.845833, BCE loss: 0.560272, SB loss: 0.793330
2023-10-30 01:52:15,972 Epoch: [57/484] Iter:[170/495], Time: 0.39, lr: [0.008927086941390962], Loss: 2.194778, Acc:0.792325, Semantic loss: 0.843351, BCE loss: 0.560435, SB loss: 0.790992
2023-10-30 01:52:19,740 Epoch: [57/484] Iter:[180/495], Time: 0.39, lr: [0.008926706515847324], Loss: 2.191318, Acc:0.792708, Semantic loss: 0.839796, BCE loss: 0.558919, SB loss: 0.792603
2023-10-30 01:52:23,448 Epoch: [57/484] Iter:[190/495], Time: 0.38, lr: [0.0089263260885023], Loss: 2.203215, Acc:0.791945, Semantic loss: 0.845809, BCE loss: 0.561209, SB loss: 0.796198
2023-10-30 01:52:27,123 Epoch: [57/484] Iter:[200/495], Time: 0.38, lr: [0.008925945659355792], Loss: 2.209579, Acc:0.792042, Semantic loss: 0.850201, BCE loss: 0.561701, SB loss: 0.797677
2023-10-30 01:52:30,877 Epoch: [57/484] Iter:[210/495], Time: 0.38, lr: [0.008925565228407706], Loss: 2.209414, Acc:0.792148, Semantic loss: 0.848559, BCE loss: 0.563444, SB loss: 0.797411
2023-10-30 01:52:34,597 Epoch: [57/484] Iter:[220/495], Time: 0.38, lr: [0.008925184795657948], Loss: 2.207480, Acc:0.792347, Semantic loss: 0.843693, BCE loss: 0.567746, SB loss: 0.796041
2023-10-30 01:52:38,276 Epoch: [57/484] Iter:[230/495], Time: 0.38, lr: [0.008924804361106427], Loss: 2.201578, Acc:0.792843, Semantic loss: 0.841346, BCE loss: 0.564512, SB loss: 0.795719
2023-10-30 01:52:41,942 Epoch: [57/484] Iter:[240/495], Time: 0.38, lr: [0.008924423924753047], Loss: 2.204512, Acc:0.792170, Semantic loss: 0.841716, BCE loss: 0.567152, SB loss: 0.795645
2023-10-30 01:52:45,629 Epoch: [57/484] Iter:[250/495], Time: 0.38, lr: [0.008924043486597713], Loss: 2.212403, Acc:0.791316, Semantic loss: 0.848424, BCE loss: 0.566141, SB loss: 0.797838
2023-10-30 01:52:49,286 Epoch: [57/484] Iter:[260/495], Time: 0.38, lr: [0.008923663046640334], Loss: 2.216746, Acc:0.789607, Semantic loss: 0.850441, BCE loss: 0.565837, SB loss: 0.800468
2023-10-30 01:52:52,936 Epoch: [57/484] Iter:[270/495], Time: 0.38, lr: [0.008923282604880813], Loss: 2.210301, Acc:0.788262, Semantic loss: 0.844953, BCE loss: 0.566769, SB loss: 0.798580
2023-10-30 01:52:56,706 Epoch: [57/484] Iter:[280/495], Time: 0.38, lr: [0.00892290216131906], Loss: 2.209905, Acc:0.788390, Semantic loss: 0.846089, BCE loss: 0.564325, SB loss: 0.799491
2023-10-30 01:53:00,446 Epoch: [57/484] Iter:[290/495], Time: 0.38, lr: [0.008922521715954977], Loss: 2.217713, Acc:0.788308, Semantic loss: 0.851224, BCE loss: 0.563574, SB loss: 0.802915
2023-10-30 01:53:04,072 Epoch: [57/484] Iter:[300/495], Time: 0.38, lr: [0.008922141268788472], Loss: 2.222584, Acc:0.787520, Semantic loss: 0.853795, BCE loss: 0.564382, SB loss: 0.804407
2023-10-30 01:53:07,834 Epoch: [57/484] Iter:[310/495], Time: 0.38, lr: [0.008921760819819451], Loss: 2.221708, Acc:0.787608, Semantic loss: 0.853842, BCE loss: 0.564959, SB loss: 0.802907
2023-10-30 01:53:11,449 Epoch: [57/484] Iter:[320/495], Time: 0.38, lr: [0.00892138036904782], Loss: 2.220825, Acc:0.788248, Semantic loss: 0.851830, BCE loss: 0.565900, SB loss: 0.803095
2023-10-30 01:53:15,219 Epoch: [57/484] Iter:[330/495], Time: 0.38, lr: [0.008920999916473485], Loss: 2.218159, Acc:0.787943, Semantic loss: 0.850459, BCE loss: 0.564750, SB loss: 0.802949
2023-10-30 01:53:18,922 Epoch: [57/484] Iter:[340/495], Time: 0.38, lr: [0.00892061946209635], Loss: 2.217844, Acc:0.788757, Semantic loss: 0.848417, BCE loss: 0.566964, SB loss: 0.802462
2023-10-30 01:53:22,783 Epoch: [57/484] Iter:[350/495], Time: 0.38, lr: [0.008920239005916326], Loss: 2.225861, Acc:0.787887, Semantic loss: 0.853391, BCE loss: 0.567609, SB loss: 0.804861
2023-10-30 01:53:26,440 Epoch: [57/484] Iter:[360/495], Time: 0.38, lr: [0.008919858547933314], Loss: 2.229533, Acc:0.787711, Semantic loss: 0.854779, BCE loss: 0.569389, SB loss: 0.805365
2023-10-30 01:53:30,056 Epoch: [57/484] Iter:[370/495], Time: 0.38, lr: [0.008919478088147224], Loss: 2.226844, Acc:0.788125, Semantic loss: 0.853445, BCE loss: 0.568472, SB loss: 0.804927
2023-10-30 01:53:33,756 Epoch: [57/484] Iter:[380/495], Time: 0.38, lr: [0.008919097626557957], Loss: 2.223111, Acc:0.787334, Semantic loss: 0.850640, BCE loss: 0.569260, SB loss: 0.803211
2023-10-30 01:53:37,454 Epoch: [57/484] Iter:[390/495], Time: 0.38, lr: [0.008918717163165425], Loss: 2.217345, Acc:0.788043, Semantic loss: 0.847361, BCE loss: 0.568301, SB loss: 0.801683
2023-10-30 01:53:41,213 Epoch: [57/484] Iter:[400/495], Time: 0.38, lr: [0.008918336697969532], Loss: 2.216241, Acc:0.789044, Semantic loss: 0.846907, BCE loss: 0.568680, SB loss: 0.800654
2023-10-30 01:53:44,842 Epoch: [57/484] Iter:[410/495], Time: 0.38, lr: [0.00891795623097018], Loss: 2.214724, Acc:0.788885, Semantic loss: 0.846542, BCE loss: 0.568033, SB loss: 0.800149
2023-10-30 01:53:48,534 Epoch: [57/484] Iter:[420/495], Time: 0.38, lr: [0.008917575762167278], Loss: 2.211592, Acc:0.788805, Semantic loss: 0.844429, BCE loss: 0.567232, SB loss: 0.799931
2023-10-30 01:53:52,283 Epoch: [57/484] Iter:[430/495], Time: 0.38, lr: [0.008917195291560733], Loss: 2.210969, Acc:0.788595, Semantic loss: 0.844084, BCE loss: 0.566885, SB loss: 0.800000
2023-10-30 01:53:56,006 Epoch: [57/484] Iter:[440/495], Time: 0.38, lr: [0.008916814819150451], Loss: 2.207336, Acc:0.788705, Semantic loss: 0.842806, BCE loss: 0.565360, SB loss: 0.799170
2023-10-30 01:53:59,664 Epoch: [57/484] Iter:[450/495], Time: 0.38, lr: [0.008916434344936334], Loss: 2.203238, Acc:0.789806, Semantic loss: 0.840351, BCE loss: 0.565179, SB loss: 0.797709
2023-10-30 01:54:03,263 Epoch: [57/484] Iter:[460/495], Time: 0.38, lr: [0.008916053868918292], Loss: 2.200205, Acc:0.790239, Semantic loss: 0.839231, BCE loss: 0.564177, SB loss: 0.796798
2023-10-30 01:54:06,927 Epoch: [57/484] Iter:[470/495], Time: 0.38, lr: [0.00891567339109623], Loss: 2.199669, Acc:0.789361, Semantic loss: 0.839009, BCE loss: 0.563593, SB loss: 0.797066
2023-10-30 01:54:10,680 Epoch: [57/484] Iter:[480/495], Time: 0.38, lr: [0.008915292911470054], Loss: 2.201124, Acc:0.790007, Semantic loss: 0.838954, BCE loss: 0.565179, SB loss: 0.796992
2023-10-30 01:54:14,185 Epoch: [57/484] Iter:[490/495], Time: 0.38, lr: [0.00891491243003967], Loss: 2.196459, Acc:0.790168, Semantic loss: 0.836407, BCE loss: 0.564105, SB loss: 0.795946
2023-10-30 01:54:15,571 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:54:15,842 Loss: 2.244, MeanIU:  0.6496, Best_mIoU:  0.6736
2023-10-30 01:54:15,842 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886]
2023-10-30 01:54:18,223 Epoch: [58/484] Iter:[0/495], Time: 2.34, lr: [0.008914722188647868], Loss: 2.669430, Acc:0.834370, Semantic loss: 0.942081, BCE loss: 0.824624, SB loss: 0.902724
2023-10-30 01:54:22,193 Epoch: [58/484] Iter:[10/495], Time: 0.57, lr: [0.008914341704510994], Loss: 2.110829, Acc:0.764737, Semantic loss: 0.801728, BCE loss: 0.541364, SB loss: 0.767736
2023-10-30 01:54:25,928 Epoch: [58/484] Iter:[20/495], Time: 0.48, lr: [0.008913961218569674], Loss: 2.098178, Acc:0.795047, Semantic loss: 0.799009, BCE loss: 0.510330, SB loss: 0.788839
2023-10-30 01:54:29,675 Epoch: [58/484] Iter:[30/495], Time: 0.45, lr: [0.008913580730823819], Loss: 2.115618, Acc:0.797713, Semantic loss: 0.816043, BCE loss: 0.524888, SB loss: 0.774687
2023-10-30 01:54:33,300 Epoch: [58/484] Iter:[40/495], Time: 0.42, lr: [0.008913200241273329], Loss: 2.138136, Acc:0.787800, Semantic loss: 0.829756, BCE loss: 0.534763, SB loss: 0.773617
2023-10-30 01:54:36,942 Epoch: [58/484] Iter:[50/495], Time: 0.41, lr: [0.008912819749918114], Loss: 2.146239, Acc:0.787699, Semantic loss: 0.829356, BCE loss: 0.546679, SB loss: 0.770205
2023-10-30 01:54:40,733 Epoch: [58/484] Iter:[60/495], Time: 0.41, lr: [0.00891243925675808], Loss: 2.153976, Acc:0.793291, Semantic loss: 0.827348, BCE loss: 0.558313, SB loss: 0.768315
2023-10-30 01:54:44,396 Epoch: [58/484] Iter:[70/495], Time: 0.40, lr: [0.008912058761793129], Loss: 2.142514, Acc:0.792365, Semantic loss: 0.827130, BCE loss: 0.549608, SB loss: 0.765775
2023-10-30 01:54:48,059 Epoch: [58/484] Iter:[80/495], Time: 0.40, lr: [0.00891167826502317], Loss: 2.127430, Acc:0.796315, Semantic loss: 0.817330, BCE loss: 0.542541, SB loss: 0.767558
2023-10-30 01:54:51,799 Epoch: [58/484] Iter:[90/495], Time: 0.39, lr: [0.008911297766448108], Loss: 2.140111, Acc:0.791581, Semantic loss: 0.827379, BCE loss: 0.541808, SB loss: 0.770925
2023-10-30 01:54:55,581 Epoch: [58/484] Iter:[100/495], Time: 0.39, lr: [0.00891091726606785], Loss: 2.127583, Acc:0.791364, Semantic loss: 0.821432, BCE loss: 0.538650, SB loss: 0.767501
2023-10-30 01:54:59,138 Epoch: [58/484] Iter:[110/495], Time: 0.39, lr: [0.008910536763882298], Loss: 2.124004, Acc:0.791655, Semantic loss: 0.816892, BCE loss: 0.539328, SB loss: 0.767785
2023-10-30 01:55:02,795 Epoch: [58/484] Iter:[120/495], Time: 0.39, lr: [0.008910156259891359], Loss: 2.140402, Acc:0.790444, Semantic loss: 0.824323, BCE loss: 0.546651, SB loss: 0.769428
2023-10-30 01:55:06,461 Epoch: [58/484] Iter:[130/495], Time: 0.39, lr: [0.008909775754094944], Loss: 2.136983, Acc:0.791635, Semantic loss: 0.818667, BCE loss: 0.548200, SB loss: 0.770117
2023-10-30 01:55:10,081 Epoch: [58/484] Iter:[140/495], Time: 0.38, lr: [0.008909395246492953], Loss: 2.145106, Acc:0.791452, Semantic loss: 0.822144, BCE loss: 0.547154, SB loss: 0.775808
2023-10-30 01:55:13,695 Epoch: [58/484] Iter:[150/495], Time: 0.38, lr: [0.008909014737085295], Loss: 2.136931, Acc:0.791694, Semantic loss: 0.819124, BCE loss: 0.545279, SB loss: 0.772528
2023-10-30 01:55:17,459 Epoch: [58/484] Iter:[160/495], Time: 0.38, lr: [0.008908634225871872], Loss: 2.138467, Acc:0.791542, Semantic loss: 0.822020, BCE loss: 0.542012, SB loss: 0.774434
2023-10-30 01:55:21,158 Epoch: [58/484] Iter:[170/495], Time: 0.38, lr: [0.008908253712852594], Loss: 2.140784, Acc:0.787604, Semantic loss: 0.821020, BCE loss: 0.545461, SB loss: 0.774302
2023-10-30 01:55:24,835 Epoch: [58/484] Iter:[180/495], Time: 0.38, lr: [0.008907873198027364], Loss: 2.136105, Acc:0.787352, Semantic loss: 0.817218, BCE loss: 0.546381, SB loss: 0.772506
2023-10-30 01:55:28,550 Epoch: [58/484] Iter:[190/495], Time: 0.38, lr: [0.008907492681396088], Loss: 2.128390, Acc:0.786781, Semantic loss: 0.812651, BCE loss: 0.545954, SB loss: 0.769785
2023-10-30 01:55:32,343 Epoch: [58/484] Iter:[200/495], Time: 0.38, lr: [0.008907112162958673], Loss: 2.138376, Acc:0.787295, Semantic loss: 0.817815, BCE loss: 0.547610, SB loss: 0.772951
2023-10-30 01:55:36,034 Epoch: [58/484] Iter:[210/495], Time: 0.38, lr: [0.008906731642715023], Loss: 2.135868, Acc:0.788481, Semantic loss: 0.816861, BCE loss: 0.547864, SB loss: 0.771143
2023-10-30 01:55:39,650 Epoch: [58/484] Iter:[220/495], Time: 0.38, lr: [0.008906351120665046], Loss: 2.136976, Acc:0.788406, Semantic loss: 0.816306, BCE loss: 0.547898, SB loss: 0.772772
2023-10-30 01:55:43,300 Epoch: [58/484] Iter:[230/495], Time: 0.38, lr: [0.008905970596808645], Loss: 2.144220, Acc:0.786108, Semantic loss: 0.820592, BCE loss: 0.547011, SB loss: 0.776617
2023-10-30 01:55:46,981 Epoch: [58/484] Iter:[240/495], Time: 0.38, lr: [0.008905590071145728], Loss: 2.138426, Acc:0.786989, Semantic loss: 0.816781, BCE loss: 0.546082, SB loss: 0.775564
2023-10-30 01:55:50,629 Epoch: [58/484] Iter:[250/495], Time: 0.38, lr: [0.008905209543676199], Loss: 2.140415, Acc:0.787092, Semantic loss: 0.816321, BCE loss: 0.547245, SB loss: 0.776849
2023-10-30 01:55:54,372 Epoch: [58/484] Iter:[260/495], Time: 0.38, lr: [0.008904829014399965], Loss: 2.140834, Acc:0.786134, Semantic loss: 0.816746, BCE loss: 0.545623, SB loss: 0.778465
2023-10-30 01:55:58,005 Epoch: [58/484] Iter:[270/495], Time: 0.38, lr: [0.008904448483316929], Loss: 2.134739, Acc:0.785036, Semantic loss: 0.813838, BCE loss: 0.543207, SB loss: 0.777695
2023-10-30 01:56:01,674 Epoch: [58/484] Iter:[280/495], Time: 0.38, lr: [0.008904067950427], Loss: 2.135962, Acc:0.785714, Semantic loss: 0.814130, BCE loss: 0.544637, SB loss: 0.777195
2023-10-30 01:56:05,298 Epoch: [58/484] Iter:[290/495], Time: 0.38, lr: [0.008903687415730081], Loss: 2.145064, Acc:0.784309, Semantic loss: 0.819884, BCE loss: 0.546457, SB loss: 0.778723
2023-10-30 01:56:09,029 Epoch: [58/484] Iter:[300/495], Time: 0.38, lr: [0.008903306879226079], Loss: 2.141981, Acc:0.784806, Semantic loss: 0.816258, BCE loss: 0.546715, SB loss: 0.779007
2023-10-30 01:56:12,757 Epoch: [58/484] Iter:[310/495], Time: 0.38, lr: [0.0089029263409149], Loss: 2.140713, Acc:0.786014, Semantic loss: 0.813919, BCE loss: 0.547850, SB loss: 0.778944
2023-10-30 01:56:16,447 Epoch: [58/484] Iter:[320/495], Time: 0.38, lr: [0.00890254580079645], Loss: 2.139530, Acc:0.785312, Semantic loss: 0.813317, BCE loss: 0.547917, SB loss: 0.778296
2023-10-30 01:56:20,049 Epoch: [58/484] Iter:[330/495], Time: 0.38, lr: [0.00890216525887063], Loss: 2.139660, Acc:0.784333, Semantic loss: 0.814390, BCE loss: 0.547712, SB loss: 0.777558
2023-10-30 01:56:23,759 Epoch: [58/484] Iter:[340/495], Time: 0.38, lr: [0.008901784715137352], Loss: 2.139818, Acc:0.783892, Semantic loss: 0.814782, BCE loss: 0.547741, SB loss: 0.777295
2023-10-30 01:56:27,462 Epoch: [58/484] Iter:[350/495], Time: 0.37, lr: [0.008901404169596517], Loss: 2.141506, Acc:0.783687, Semantic loss: 0.815951, BCE loss: 0.547537, SB loss: 0.778018
2023-10-30 01:56:31,121 Epoch: [58/484] Iter:[360/495], Time: 0.37, lr: [0.008901023622248032], Loss: 2.138438, Acc:0.784410, Semantic loss: 0.811926, BCE loss: 0.549001, SB loss: 0.777512
2023-10-30 01:56:34,845 Epoch: [58/484] Iter:[370/495], Time: 0.37, lr: [0.008900643073091805], Loss: 2.134850, Acc:0.784299, Semantic loss: 0.809832, BCE loss: 0.547826, SB loss: 0.777192
2023-10-30 01:56:38,654 Epoch: [58/484] Iter:[380/495], Time: 0.37, lr: [0.008900262522127738], Loss: 2.134402, Acc:0.784705, Semantic loss: 0.810985, BCE loss: 0.545971, SB loss: 0.777445
2023-10-30 01:56:42,300 Epoch: [58/484] Iter:[390/495], Time: 0.37, lr: [0.008899881969355736], Loss: 2.130375, Acc:0.785346, Semantic loss: 0.807585, BCE loss: 0.546161, SB loss: 0.776629
2023-10-30 01:56:46,047 Epoch: [58/484] Iter:[400/495], Time: 0.37, lr: [0.008899501414775707], Loss: 2.129605, Acc:0.786038, Semantic loss: 0.807611, BCE loss: 0.545702, SB loss: 0.776292
2023-10-30 01:56:49,765 Epoch: [58/484] Iter:[410/495], Time: 0.37, lr: [0.008899120858387557], Loss: 2.129099, Acc:0.787144, Semantic loss: 0.806549, BCE loss: 0.547197, SB loss: 0.775353
2023-10-30 01:56:53,439 Epoch: [58/484] Iter:[420/495], Time: 0.37, lr: [0.00889874030019119], Loss: 2.124300, Acc:0.786820, Semantic loss: 0.803773, BCE loss: 0.545640, SB loss: 0.774887
2023-10-30 01:56:57,130 Epoch: [58/484] Iter:[430/495], Time: 0.37, lr: [0.00889835974018651], Loss: 2.121825, Acc:0.787795, Semantic loss: 0.802666, BCE loss: 0.545092, SB loss: 0.774067
2023-10-30 01:57:00,836 Epoch: [58/484] Iter:[440/495], Time: 0.37, lr: [0.008897979178373427], Loss: 2.118207, Acc:0.788450, Semantic loss: 0.800662, BCE loss: 0.544853, SB loss: 0.772693
2023-10-30 01:57:04,473 Epoch: [58/484] Iter:[450/495], Time: 0.37, lr: [0.008897598614751843], Loss: 2.120783, Acc:0.788457, Semantic loss: 0.801840, BCE loss: 0.546615, SB loss: 0.772329
2023-10-30 01:57:08,181 Epoch: [58/484] Iter:[460/495], Time: 0.37, lr: [0.008897218049321663], Loss: 2.119543, Acc:0.788802, Semantic loss: 0.800399, BCE loss: 0.547389, SB loss: 0.771755
2023-10-30 01:57:11,787 Epoch: [58/484] Iter:[470/495], Time: 0.37, lr: [0.008896837482082795], Loss: 2.119747, Acc:0.788100, Semantic loss: 0.800526, BCE loss: 0.547566, SB loss: 0.771655
2023-10-30 01:57:15,434 Epoch: [58/484] Iter:[480/495], Time: 0.37, lr: [0.008896456913035143], Loss: 2.120249, Acc:0.789211, Semantic loss: 0.800687, BCE loss: 0.548158, SB loss: 0.771405
2023-10-30 01:57:18,977 Epoch: [58/484] Iter:[490/495], Time: 0.37, lr: [0.008896076342178611], Loss: 2.119710, Acc:0.789752, Semantic loss: 0.800363, BCE loss: 0.548774, SB loss: 0.770573
2023-10-30 01:57:20,384 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 01:57:20,625 Loss: 2.244, MeanIU:  0.6496, Best_mIoU:  0.6736
2023-10-30 01:57:20,625 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886]
2023-10-30 01:57:22,556 Epoch: [59/484] Iter:[0/495], Time: 1.90, lr: [0.008895886056071986], Loss: 2.001398, Acc:0.902700, Semantic loss: 0.698080, BCE loss: 0.528879, SB loss: 0.774440
2023-10-30 01:57:26,438 Epoch: [59/484] Iter:[10/495], Time: 0.53, lr: [0.00889550548250196], Loss: 2.006132, Acc:0.798041, Semantic loss: 0.743330, BCE loss: 0.523950, SB loss: 0.738853
2023-10-30 01:57:30,297 Epoch: [59/484] Iter:[20/495], Time: 0.46, lr: [0.008895124907122819], Loss: 2.101127, Acc:0.787036, Semantic loss: 0.798654, BCE loss: 0.537391, SB loss: 0.765083
2023-10-30 01:57:33,872 Epoch: [59/484] Iter:[30/495], Time: 0.43, lr: [0.008894744329934468], Loss: 2.094512, Acc:0.793472, Semantic loss: 0.785769, BCE loss: 0.542447, SB loss: 0.766296
2023-10-30 01:57:37,442 Epoch: [59/484] Iter:[40/495], Time: 0.41, lr: [0.008894363750936813], Loss: 2.080958, Acc:0.790435, Semantic loss: 0.787561, BCE loss: 0.520011, SB loss: 0.773387
2023-10-30 01:57:41,277 Epoch: [59/484] Iter:[50/495], Time: 0.40, lr: [0.008893983170129759], Loss: 2.100167, Acc:0.789012, Semantic loss: 0.788204, BCE loss: 0.538883, SB loss: 0.773080
2023-10-30 01:57:44,932 Epoch: [59/484] Iter:[60/495], Time: 0.40, lr: [0.00889360258751321], Loss: 2.122619, Acc:0.791921, Semantic loss: 0.801384, BCE loss: 0.549014, SB loss: 0.772222
2023-10-30 01:57:48,634 Epoch: [59/484] Iter:[70/495], Time: 0.39, lr: [0.008893222003087077], Loss: 2.103083, Acc:0.793834, Semantic loss: 0.787099, BCE loss: 0.547695, SB loss: 0.768289
2023-10-30 01:57:52,311 Epoch: [59/484] Iter:[80/495], Time: 0.39, lr: [0.008892841416851257], Loss: 2.100572, Acc:0.794799, Semantic loss: 0.787191, BCE loss: 0.547513, SB loss: 0.765868
2023-10-30 01:57:55,909 Epoch: [59/484] Iter:[90/495], Time: 0.39, lr: [0.00889246082880566], Loss: 2.110882, Acc:0.791396, Semantic loss: 0.792979, BCE loss: 0.551742, SB loss: 0.766161
2023-10-30 01:57:59,675 Epoch: [59/484] Iter:[100/495], Time: 0.39, lr: [0.008892080238950193], Loss: 2.107440, Acc:0.790985, Semantic loss: 0.789837, BCE loss: 0.552924, SB loss: 0.764679
2023-10-30 01:58:03,295 Epoch: [59/484] Iter:[110/495], Time: 0.38, lr: [0.008891699647284758], Loss: 2.114427, Acc:0.792359, Semantic loss: 0.791826, BCE loss: 0.558846, SB loss: 0.763754
2023-10-30 01:58:06,970 Epoch: [59/484] Iter:[120/495], Time: 0.38, lr: [0.008891319053809264], Loss: 2.121745, Acc:0.793988, Semantic loss: 0.800160, BCE loss: 0.557641, SB loss: 0.763944
2023-10-30 01:58:10,603 Epoch: [59/484] Iter:[130/495], Time: 0.38, lr: [0.008890938458523612], Loss: 2.124497, Acc:0.793858, Semantic loss: 0.804305, BCE loss: 0.556072, SB loss: 0.764121
2023-10-30 01:58:14,324 Epoch: [59/484] Iter:[140/495], Time: 0.38, lr: [0.008890557861427709], Loss: 2.124115, Acc:0.795331, Semantic loss: 0.803512, BCE loss: 0.556711, SB loss: 0.763893
2023-10-30 01:58:18,035 Epoch: [59/484] Iter:[150/495], Time: 0.38, lr: [0.00889017726252146], Loss: 2.122994, Acc:0.792007, Semantic loss: 0.802507, BCE loss: 0.557024, SB loss: 0.763463
2023-10-30 01:58:21,811 Epoch: [59/484] Iter:[160/495], Time: 0.38, lr: [0.00888979666180477], Loss: 2.122842, Acc:0.789252, Semantic loss: 0.802621, BCE loss: 0.555905, SB loss: 0.764317
2023-10-30 01:58:25,498 Epoch: [59/484] Iter:[170/495], Time: 0.38, lr: [0.008889416059277547], Loss: 2.166513, Acc:0.785926, Semantic loss: 0.835949, BCE loss: 0.556893, SB loss: 0.773671
2023-10-30 01:58:29,261 Epoch: [59/484] Iter:[180/495], Time: 0.38, lr: [0.008889035454939692], Loss: 2.167890, Acc:0.784844, Semantic loss: 0.833398, BCE loss: 0.558892, SB loss: 0.775601
2023-10-30 01:58:32,926 Epoch: [59/484] Iter:[190/495], Time: 0.38, lr: [0.008888654848791115], Loss: 2.165583, Acc:0.783095, Semantic loss: 0.829684, BCE loss: 0.560484, SB loss: 0.775415
2023-10-30 01:58:36,732 Epoch: [59/484] Iter:[200/495], Time: 0.38, lr: [0.008888274240831717], Loss: 2.167946, Acc:0.782996, Semantic loss: 0.830993, BCE loss: 0.558893, SB loss: 0.778060
2023-10-30 01:58:40,380 Epoch: [59/484] Iter:[210/495], Time: 0.38, lr: [0.008887893631061407], Loss: 2.168558, Acc:0.783209, Semantic loss: 0.830480, BCE loss: 0.558865, SB loss: 0.779213
2023-10-30 01:58:44,042 Epoch: [59/484] Iter:[220/495], Time: 0.38, lr: [0.008887513019480084], Loss: 2.172124, Acc:0.785024, Semantic loss: 0.829937, BCE loss: 0.560599, SB loss: 0.781587
2023-10-30 01:58:47,673 Epoch: [59/484] Iter:[230/495], Time: 0.38, lr: [0.00888713240608766], Loss: 2.178763, Acc:0.785785, Semantic loss: 0.833317, BCE loss: 0.561362, SB loss: 0.784084
2023-10-30 01:58:51,317 Epoch: [59/484] Iter:[240/495], Time: 0.38, lr: [0.008886751790884039], Loss: 2.174358, Acc:0.784641, Semantic loss: 0.831659, BCE loss: 0.558727, SB loss: 0.783973
2023-10-30 01:58:54,998 Epoch: [59/484] Iter:[250/495], Time: 0.38, lr: [0.008886371173869123], Loss: 2.167589, Acc:0.783852, Semantic loss: 0.828697, BCE loss: 0.555209, SB loss: 0.783684
2023-10-30 01:58:58,739 Epoch: [59/484] Iter:[260/495], Time: 0.38, lr: [0.008885990555042819], Loss: 2.160821, Acc:0.783819, Semantic loss: 0.827899, BCE loss: 0.549606, SB loss: 0.783316
2023-10-30 01:59:02,431 Epoch: [59/484] Iter:[270/495], Time: 0.38, lr: [0.008885609934405032], Loss: 2.170177, Acc:0.782756, Semantic loss: 0.835067, BCE loss: 0.549235, SB loss: 0.785874
2023-10-30 01:59:06,180 Epoch: [59/484] Iter:[280/495], Time: 0.38, lr: [0.008885229311955668], Loss: 2.171422, Acc:0.783100, Semantic loss: 0.834859, BCE loss: 0.550233, SB loss: 0.786330
2023-10-30 01:59:09,816 Epoch: [59/484] Iter:[290/495], Time: 0.38, lr: [0.008884848687694631], Loss: 2.166250, Acc:0.783443, Semantic loss: 0.832215, BCE loss: 0.548562, SB loss: 0.785473
2023-10-30 01:59:13,460 Epoch: [59/484] Iter:[300/495], Time: 0.37, lr: [0.008884468061621825], Loss: 2.170911, Acc:0.782808, Semantic loss: 0.836047, BCE loss: 0.549684, SB loss: 0.785180
2023-10-30 01:59:17,106 Epoch: [59/484] Iter:[310/495], Time: 0.37, lr: [0.00888408743373716], Loss: 2.168466, Acc:0.781542, Semantic loss: 0.833554, BCE loss: 0.549432, SB loss: 0.785480
2023-10-30 01:59:20,775 Epoch: [59/484] Iter:[320/495], Time: 0.37, lr: [0.008883706804040535], Loss: 2.169363, Acc:0.780977, Semantic loss: 0.833181, BCE loss: 0.550282, SB loss: 0.785900
2023-10-30 01:59:24,485 Epoch: [59/484] Iter:[330/495], Time: 0.37, lr: [0.008883326172531859], Loss: 2.164878, Acc:0.780914, Semantic loss: 0.830516, BCE loss: 0.549563, SB loss: 0.784799
2023-10-30 01:59:28,138 Epoch: [59/484] Iter:[340/495], Time: 0.37, lr: [0.008882945539211035], Loss: 2.158867, Acc:0.780871, Semantic loss: 0.827078, BCE loss: 0.548750, SB loss: 0.783039
2023-10-30 01:59:31,835 Epoch: [59/484] Iter:[350/495], Time: 0.37, lr: [0.00888256490407797], Loss: 2.161903, Acc:0.781682, Semantic loss: 0.828467, BCE loss: 0.550828, SB loss: 0.782607
2023-10-30 01:59:35,571 Epoch: [59/484] Iter:[360/495], Time: 0.37, lr: [0.008882184267132567], Loss: 2.164105, Acc:0.781989, Semantic loss: 0.829062, BCE loss: 0.550517, SB loss: 0.784526
2023-10-30 01:59:39,259 Epoch: [59/484] Iter:[370/495], Time: 0.37, lr: [0.008881803628374735], Loss: 2.169218, Acc:0.783337, Semantic loss: 0.831034, BCE loss: 0.552490, SB loss: 0.785694
2023-10-30 01:59:43,008 Epoch: [59/484] Iter:[380/495], Time: 0.37, lr: [0.008881422987804375], Loss: 2.168054, Acc:0.783493, Semantic loss: 0.829306, BCE loss: 0.553391, SB loss: 0.785358
2023-10-30 01:59:46,701 Epoch: [59/484] Iter:[390/495], Time: 0.37, lr: [0.008881042345421392], Loss: 2.168869, Acc:0.784165, Semantic loss: 0.829248, BCE loss: 0.554222, SB loss: 0.785400
2023-10-30 01:59:50,359 Epoch: [59/484] Iter:[400/495], Time: 0.37, lr: [0.008880661701225694], Loss: 2.166560, Acc:0.783744, Semantic loss: 0.826753, BCE loss: 0.555251, SB loss: 0.784556
2023-10-30 01:59:54,144 Epoch: [59/484] Iter:[410/495], Time: 0.37, lr: [0.008880281055217184], Loss: 2.165367, Acc:0.784070, Semantic loss: 0.826545, BCE loss: 0.553898, SB loss: 0.784924
2023-10-30 01:59:57,838 Epoch: [59/484] Iter:[420/495], Time: 0.37, lr: [0.008879900407395766], Loss: 2.163319, Acc:0.783390, Semantic loss: 0.825596, BCE loss: 0.553502, SB loss: 0.784221
2023-10-30 02:00:01,529 Epoch: [59/484] Iter:[430/495], Time: 0.37, lr: [0.008879519757761349], Loss: 2.162676, Acc:0.782392, Semantic loss: 0.825750, BCE loss: 0.552301, SB loss: 0.784626
2023-10-30 02:00:05,155 Epoch: [59/484] Iter:[440/495], Time: 0.37, lr: [0.008879139106313836], Loss: 2.162219, Acc:0.781851, Semantic loss: 0.825163, BCE loss: 0.552296, SB loss: 0.784760
2023-10-30 02:00:08,829 Epoch: [59/484] Iter:[450/495], Time: 0.37, lr: [0.008878758453053127], Loss: 2.158861, Acc:0.781823, Semantic loss: 0.822957, BCE loss: 0.552668, SB loss: 0.783236
2023-10-30 02:00:12,657 Epoch: [59/484] Iter:[460/495], Time: 0.37, lr: [0.008878377797979136], Loss: 2.159801, Acc:0.782061, Semantic loss: 0.823763, BCE loss: 0.552990, SB loss: 0.783048
2023-10-30 02:00:16,339 Epoch: [59/484] Iter:[470/495], Time: 0.37, lr: [0.008877997141091762], Loss: 2.162220, Acc:0.782375, Semantic loss: 0.823959, BCE loss: 0.553622, SB loss: 0.784639
2023-10-30 02:00:20,133 Epoch: [59/484] Iter:[480/495], Time: 0.37, lr: [0.008877616482390912], Loss: 2.159221, Acc:0.782861, Semantic loss: 0.822378, BCE loss: 0.553318, SB loss: 0.783525
2023-10-30 02:00:23,694 Epoch: [59/484] Iter:[490/495], Time: 0.37, lr: [0.008877235821876488], Loss: 2.161442, Acc:0.783645, Semantic loss: 0.822978, BCE loss: 0.554439, SB loss: 0.784025
2023-10-30 02:00:25,106 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:00:25,342 Loss: 2.244, MeanIU:  0.6496, Best_mIoU:  0.6736
2023-10-30 02:00:25,342 [0.95484224 0.73728951 0.89210659 0.20016941 0.45386878 0.55463643
 0.62451767 0.70834266 0.89948582 0.52721548 0.92328246 0.74991684
 0.51621657 0.90020833 0.47121705 0.62494331 0.55562607 0.36466825
 0.68342886]
2023-10-30 02:00:27,475 Epoch: [60/484] Iter:[0/495], Time: 2.10, lr: [0.00887704549093916], Loss: 2.069448, Acc:0.826194, Semantic loss: 0.714349, BCE loss: 0.569940, SB loss: 0.785159
2023-10-30 02:00:31,492 Epoch: [60/484] Iter:[10/495], Time: 0.56, lr: [0.008876664827704201], Loss: 2.270788, Acc:0.821016, Semantic loss: 0.822912, BCE loss: 0.665830, SB loss: 0.782046
2023-10-30 02:00:35,253 Epoch: [60/484] Iter:[20/495], Time: 0.47, lr: [0.008876284162655434], Loss: 2.320205, Acc:0.796348, Semantic loss: 0.882651, BCE loss: 0.611643, SB loss: 0.825910
2023-10-30 02:00:38,929 Epoch: [60/484] Iter:[30/495], Time: 0.44, lr: [0.008875903495792764], Loss: 2.244219, Acc:0.783539, Semantic loss: 0.835493, BCE loss: 0.599379, SB loss: 0.809347
2023-10-30 02:00:42,669 Epoch: [60/484] Iter:[40/495], Time: 0.42, lr: [0.008875522827116091], Loss: 2.211897, Acc:0.784950, Semantic loss: 0.819336, BCE loss: 0.594409, SB loss: 0.798151
2023-10-30 02:00:46,392 Epoch: [60/484] Iter:[50/495], Time: 0.41, lr: [0.008875142156625326], Loss: 2.199933, Acc:0.788098, Semantic loss: 0.812284, BCE loss: 0.598560, SB loss: 0.789089
2023-10-30 02:00:50,199 Epoch: [60/484] Iter:[60/495], Time: 0.41, lr: [0.008874761484320372], Loss: 2.160126, Acc:0.791212, Semantic loss: 0.800403, BCE loss: 0.583361, SB loss: 0.776363
2023-10-30 02:00:53,863 Epoch: [60/484] Iter:[70/495], Time: 0.40, lr: [0.008874380810201133], Loss: 2.144041, Acc:0.795904, Semantic loss: 0.791816, BCE loss: 0.581687, SB loss: 0.770538
2023-10-30 02:00:57,576 Epoch: [60/484] Iter:[80/495], Time: 0.40, lr: [0.008874000134267512], Loss: 2.137258, Acc:0.797955, Semantic loss: 0.797427, BCE loss: 0.570419, SB loss: 0.769412
2023-10-30 02:01:01,250 Epoch: [60/484] Iter:[90/495], Time: 0.39, lr: [0.008873619456519419], Loss: 2.141920, Acc:0.800476, Semantic loss: 0.796035, BCE loss: 0.574594, SB loss: 0.771290
2023-10-30 02:01:05,058 Epoch: [60/484] Iter:[100/495], Time: 0.39, lr: [0.008873238776956754], Loss: 2.168790, Acc:0.801049, Semantic loss: 0.814950, BCE loss: 0.575937, SB loss: 0.777903
2023-10-30 02:01:08,789 Epoch: [60/484] Iter:[110/495], Time: 0.39, lr: [0.008872858095579425], Loss: 2.164882, Acc:0.801951, Semantic loss: 0.815314, BCE loss: 0.574685, SB loss: 0.774883
2023-10-30 02:01:12,428 Epoch: [60/484] Iter:[120/495], Time: 0.39, lr: [0.008872477412387334], Loss: 2.163509, Acc:0.802687, Semantic loss: 0.814747, BCE loss: 0.576326, SB loss: 0.772436
2023-10-30 02:01:16,252 Epoch: [60/484] Iter:[130/495], Time: 0.39, lr: [0.00887209672738039], Loss: 2.157619, Acc:0.802186, Semantic loss: 0.812488, BCE loss: 0.573072, SB loss: 0.772059
2023-10-30 02:01:19,888 Epoch: [60/484] Iter:[140/495], Time: 0.39, lr: [0.008871716040558494], Loss: 2.150604, Acc:0.801020, Semantic loss: 0.806291, BCE loss: 0.573540, SB loss: 0.770773
2023-10-30 02:01:23,578 Epoch: [60/484] Iter:[150/495], Time: 0.39, lr: [0.008871335351921552], Loss: 2.133714, Acc:0.802958, Semantic loss: 0.797357, BCE loss: 0.569271, SB loss: 0.767085
2023-10-30 02:01:27,343 Epoch: [60/484] Iter:[160/495], Time: 0.38, lr: [0.00887095466146947], Loss: 2.125189, Acc:0.803951, Semantic loss: 0.793391, BCE loss: 0.565686, SB loss: 0.766111
2023-10-30 02:01:30,971 Epoch: [60/484] Iter:[170/495], Time: 0.38, lr: [0.008870573969202149], Loss: 2.135533, Acc:0.804613, Semantic loss: 0.798966, BCE loss: 0.568263, SB loss: 0.768304
2023-10-30 02:01:34,646 Epoch: [60/484] Iter:[180/495], Time: 0.38, lr: [0.008870193275119499], Loss: 2.126425, Acc:0.804250, Semantic loss: 0.794177, BCE loss: 0.565833, SB loss: 0.766416
2023-10-30 02:01:38,339 Epoch: [60/484] Iter:[190/495], Time: 0.38, lr: [0.008869812579221422], Loss: 2.124226, Acc:0.805095, Semantic loss: 0.793582, BCE loss: 0.563846, SB loss: 0.766799
2023-10-30 02:01:42,065 Epoch: [60/484] Iter:[200/495], Time: 0.38, lr: [0.00886943188150782], Loss: 2.125879, Acc:0.804511, Semantic loss: 0.794787, BCE loss: 0.563701, SB loss: 0.767391
2023-10-30 02:01:45,797 Epoch: [60/484] Iter:[210/495], Time: 0.38, lr: [0.008869051181978605], Loss: 2.117905, Acc:0.804209, Semantic loss: 0.790553, BCE loss: 0.562341, SB loss: 0.765011
2023-10-30 02:01:49,499 Epoch: [60/484] Iter:[220/495], Time: 0.38, lr: [0.008868670480633676], Loss: 2.123111, Acc:0.802725, Semantic loss: 0.793149, BCE loss: 0.563278, SB loss: 0.766684
2023-10-30 02:01:53,147 Epoch: [60/484] Iter:[230/495], Time: 0.38, lr: [0.008868289777472938], Loss: 2.122768, Acc:0.804446, Semantic loss: 0.794161, BCE loss: 0.561059, SB loss: 0.767549
2023-10-30 02:01:56,851 Epoch: [60/484] Iter:[240/495], Time: 0.38, lr: [0.008867909072496297], Loss: 2.123736, Acc:0.804353, Semantic loss: 0.793623, BCE loss: 0.562067, SB loss: 0.768046
2023-10-30 02:02:00,466 Epoch: [60/484] Iter:[250/495], Time: 0.38, lr: [0.00886752836570366], Loss: 2.128418, Acc:0.804071, Semantic loss: 0.795781, BCE loss: 0.564261, SB loss: 0.768377
2023-10-30 02:02:04,145 Epoch: [60/484] Iter:[260/495], Time: 0.38, lr: [0.008867147657094928], Loss: 2.131088, Acc:0.802532, Semantic loss: 0.799030, BCE loss: 0.563543, SB loss: 0.768515
2023-10-30 02:02:07,864 Epoch: [60/484] Iter:[270/495], Time: 0.38, lr: [0.008866766946670006], Loss: 2.128989, Acc:0.803699, Semantic loss: 0.795826, BCE loss: 0.566066, SB loss: 0.767098
2023-10-30 02:02:11,429 Epoch: [60/484] Iter:[280/495], Time: 0.38, lr: [0.0088663862344288], Loss: 2.125506, Acc:0.802769, Semantic loss: 0.793960, BCE loss: 0.565019, SB loss: 0.766527
2023-10-30 02:02:15,117 Epoch: [60/484] Iter:[290/495], Time: 0.38, lr: [0.008866005520371215], Loss: 2.122446, Acc:0.801048, Semantic loss: 0.792705, BCE loss: 0.562336, SB loss: 0.767405
2023-10-30 02:02:18,804 Epoch: [60/484] Iter:[300/495], Time: 0.38, lr: [0.008865624804497157], Loss: 2.119107, Acc:0.801783, Semantic loss: 0.790502, BCE loss: 0.562063, SB loss: 0.766542
2023-10-30 02:02:22,486 Epoch: [60/484] Iter:[310/495], Time: 0.38, lr: [0.008865244086806525], Loss: 2.117993, Acc:0.801888, Semantic loss: 0.790449, BCE loss: 0.561852, SB loss: 0.765692
2023-10-30 02:02:26,238 Epoch: [60/484] Iter:[320/495], Time: 0.38, lr: [0.008864863367299232], Loss: 2.118330, Acc:0.801922, Semantic loss: 0.790287, BCE loss: 0.562452, SB loss: 0.765591
2023-10-30 02:02:29,943 Epoch: [60/484] Iter:[330/495], Time: 0.38, lr: [0.008864482645975174], Loss: 2.120063, Acc:0.802488, Semantic loss: 0.790696, BCE loss: 0.563323, SB loss: 0.766044
2023-10-30 02:02:33,674 Epoch: [60/484] Iter:[340/495], Time: 0.38, lr: [0.008864101922834263], Loss: 2.123995, Acc:0.802474, Semantic loss: 0.790693, BCE loss: 0.566484, SB loss: 0.766818
2023-10-30 02:02:37,370 Epoch: [60/484] Iter:[350/495], Time: 0.38, lr: [0.008863721197876399], Loss: 2.121502, Acc:0.802627, Semantic loss: 0.790018, BCE loss: 0.565536, SB loss: 0.765949
2023-10-30 02:02:41,140 Epoch: [60/484] Iter:[360/495], Time: 0.38, lr: [0.008863340471101487], Loss: 2.120352, Acc:0.801202, Semantic loss: 0.790121, BCE loss: 0.564324, SB loss: 0.765908
2023-10-30 02:02:44,802 Epoch: [60/484] Iter:[370/495], Time: 0.38, lr: [0.008862959742509433], Loss: 2.117875, Acc:0.801522, Semantic loss: 0.789380, BCE loss: 0.563730, SB loss: 0.764765
2023-10-30 02:02:48,468 Epoch: [60/484] Iter:[380/495], Time: 0.38, lr: [0.008862579012100141], Loss: 2.119041, Acc:0.800769, Semantic loss: 0.789695, BCE loss: 0.563959, SB loss: 0.765388
2023-10-30 02:02:52,269 Epoch: [60/484] Iter:[390/495], Time: 0.38, lr: [0.008862198279873517], Loss: 2.118670, Acc:0.799788, Semantic loss: 0.790396, BCE loss: 0.562934, SB loss: 0.765340
2023-10-30 02:02:55,934 Epoch: [60/484] Iter:[400/495], Time: 0.38, lr: [0.008861817545829464], Loss: 2.116857, Acc:0.800049, Semantic loss: 0.790650, BCE loss: 0.560706, SB loss: 0.765501
2023-10-30 02:02:59,562 Epoch: [60/484] Iter:[410/495], Time: 0.38, lr: [0.008861436809967885], Loss: 2.115954, Acc:0.799657, Semantic loss: 0.790405, BCE loss: 0.559909, SB loss: 0.765640
2023-10-30 02:03:03,282 Epoch: [60/484] Iter:[420/495], Time: 0.38, lr: [0.00886105607228869], Loss: 2.118909, Acc:0.798841, Semantic loss: 0.791686, BCE loss: 0.560139, SB loss: 0.767084
2023-10-30 02:03:06,981 Epoch: [60/484] Iter:[430/495], Time: 0.37, lr: [0.008860675332791775], Loss: 2.119555, Acc:0.799235, Semantic loss: 0.792060, BCE loss: 0.560315, SB loss: 0.767180
2023-10-30 02:03:10,646 Epoch: [60/484] Iter:[440/495], Time: 0.37, lr: [0.008860294591477054], Loss: 2.115328, Acc:0.798950, Semantic loss: 0.790020, BCE loss: 0.558862, SB loss: 0.766447
2023-10-30 02:03:14,345 Epoch: [60/484] Iter:[450/495], Time: 0.37, lr: [0.008859913848344425], Loss: 2.112260, Acc:0.799060, Semantic loss: 0.788912, BCE loss: 0.557230, SB loss: 0.766118
2023-10-30 02:03:18,110 Epoch: [60/484] Iter:[460/495], Time: 0.37, lr: [0.008859533103393795], Loss: 2.114374, Acc:0.798377, Semantic loss: 0.790559, BCE loss: 0.557284, SB loss: 0.766531
2023-10-30 02:03:21,805 Epoch: [60/484] Iter:[470/495], Time: 0.37, lr: [0.008859152356625068], Loss: 2.114744, Acc:0.798145, Semantic loss: 0.789873, BCE loss: 0.558082, SB loss: 0.766788
2023-10-30 02:03:25,530 Epoch: [60/484] Iter:[480/495], Time: 0.37, lr: [0.008858771608038149], Loss: 2.110923, Acc:0.797366, Semantic loss: 0.788422, BCE loss: 0.556156, SB loss: 0.766345
2023-10-30 02:03:29,050 Epoch: [60/484] Iter:[490/495], Time: 0.37, lr: [0.008858390857632941], Loss: 2.112001, Acc:0.797872, Semantic loss: 0.789600, BCE loss: 0.556200, SB loss: 0.766202
2023-10-30 02:06:24,754 0 [9.35936715e-01 6.48045421e-01 8.14825695e-01 1.35675773e-01
 2.31391897e-01 3.83132939e-01 4.39768219e-01 5.09810366e-01
 8.83704649e-01 4.24515205e-01 8.44311607e-01 5.74234690e-01
 7.14234074e-03 7.81469006e-01 2.39062354e-05 4.62382672e-02
 4.89177369e-02 2.48069988e-02 5.09952415e-01] 0.4338896761304089
2023-10-30 02:06:24,755 1 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879] 0.6599628838817991
2023-10-30 02:06:24,758 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:06:24,997 Loss: 2.169, MeanIU:  0.6600, Best_mIoU:  0.6736
2023-10-30 02:06:24,997 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879]
2023-10-30 02:06:26,881 Epoch: [61/484] Iter:[0/495], Time: 1.85, lr: [0.00885820048174845], Loss: 2.324609, Acc:0.749229, Semantic loss: 1.046504, BCE loss: 0.456127, SB loss: 0.821978
2023-10-30 02:06:30,705 Epoch: [61/484] Iter:[10/495], Time: 0.52, lr: [0.00885781972861563], Loss: 2.282888, Acc:0.741035, Semantic loss: 0.898340, BCE loss: 0.521305, SB loss: 0.863242
2023-10-30 02:06:34,195 Epoch: [61/484] Iter:[20/495], Time: 0.44, lr: [0.008857438973664285], Loss: 2.266806, Acc:0.753648, Semantic loss: 0.866322, BCE loss: 0.531755, SB loss: 0.868729
2023-10-30 02:06:37,623 Epoch: [61/484] Iter:[30/495], Time: 0.41, lr: [0.008857058216894318], Loss: 2.187135, Acc:0.773832, Semantic loss: 0.836270, BCE loss: 0.513304, SB loss: 0.837561
2023-10-30 02:06:41,067 Epoch: [61/484] Iter:[40/495], Time: 0.39, lr: [0.008856677458305633], Loss: 2.148203, Acc:0.774733, Semantic loss: 0.820222, BCE loss: 0.507847, SB loss: 0.820134
2023-10-30 02:06:44,664 Epoch: [61/484] Iter:[50/495], Time: 0.38, lr: [0.008856296697898135], Loss: 2.182814, Acc:0.779063, Semantic loss: 0.836222, BCE loss: 0.529337, SB loss: 0.817255
2023-10-30 02:06:48,208 Epoch: [61/484] Iter:[60/495], Time: 0.38, lr: [0.008855915935671727], Loss: 2.154646, Acc:0.784421, Semantic loss: 0.816617, BCE loss: 0.530163, SB loss: 0.807865
2023-10-30 02:06:51,786 Epoch: [61/484] Iter:[70/495], Time: 0.38, lr: [0.008855535171626315], Loss: 2.145156, Acc:0.784945, Semantic loss: 0.808829, BCE loss: 0.537043, SB loss: 0.799284
2023-10-30 02:06:55,338 Epoch: [61/484] Iter:[80/495], Time: 0.37, lr: [0.008855154405761801], Loss: 2.169180, Acc:0.784908, Semantic loss: 0.824240, BCE loss: 0.547038, SB loss: 0.797902
2023-10-30 02:06:58,886 Epoch: [61/484] Iter:[90/495], Time: 0.37, lr: [0.008854773638078094], Loss: 2.175136, Acc:0.784440, Semantic loss: 0.825910, BCE loss: 0.553632, SB loss: 0.795594
2023-10-30 02:07:02,466 Epoch: [61/484] Iter:[100/495], Time: 0.37, lr: [0.008854392868575093], Loss: 2.183871, Acc:0.785424, Semantic loss: 0.830896, BCE loss: 0.558611, SB loss: 0.794364
2023-10-30 02:07:06,153 Epoch: [61/484] Iter:[110/495], Time: 0.37, lr: [0.008854012097252707], Loss: 2.183904, Acc:0.782497, Semantic loss: 0.830216, BCE loss: 0.560508, SB loss: 0.793180
2023-10-30 02:07:09,772 Epoch: [61/484] Iter:[120/495], Time: 0.37, lr: [0.008853631324110838], Loss: 2.187119, Acc:0.779539, Semantic loss: 0.835060, BCE loss: 0.559247, SB loss: 0.792812
2023-10-30 02:07:13,494 Epoch: [61/484] Iter:[130/495], Time: 0.37, lr: [0.00885325054914939], Loss: 2.198090, Acc:0.778887, Semantic loss: 0.842543, BCE loss: 0.559592, SB loss: 0.795955
2023-10-30 02:07:17,161 Epoch: [61/484] Iter:[140/495], Time: 0.37, lr: [0.008852869772368268], Loss: 2.192443, Acc:0.779804, Semantic loss: 0.837942, BCE loss: 0.559235, SB loss: 0.795266
2023-10-30 02:07:20,893 Epoch: [61/484] Iter:[150/495], Time: 0.37, lr: [0.008852488993767378], Loss: 2.190172, Acc:0.778956, Semantic loss: 0.836784, BCE loss: 0.560163, SB loss: 0.793225
2023-10-30 02:07:24,556 Epoch: [61/484] Iter:[160/495], Time: 0.37, lr: [0.00885210821334662], Loss: 2.195088, Acc:0.778869, Semantic loss: 0.840273, BCE loss: 0.560163, SB loss: 0.794651
2023-10-30 02:07:28,208 Epoch: [61/484] Iter:[170/495], Time: 0.37, lr: [0.008851727431105903], Loss: 2.192637, Acc:0.779577, Semantic loss: 0.839128, BCE loss: 0.558119, SB loss: 0.795389
2023-10-30 02:07:31,803 Epoch: [61/484] Iter:[180/495], Time: 0.37, lr: [0.008851346647045129], Loss: 2.185790, Acc:0.778952, Semantic loss: 0.835358, BCE loss: 0.557574, SB loss: 0.792858
2023-10-30 02:07:35,453 Epoch: [61/484] Iter:[190/495], Time: 0.37, lr: [0.008850965861164201], Loss: 2.183976, Acc:0.778539, Semantic loss: 0.830843, BCE loss: 0.561135, SB loss: 0.791999
2023-10-30 02:07:39,155 Epoch: [61/484] Iter:[200/495], Time: 0.37, lr: [0.008850585073463028], Loss: 2.185571, Acc:0.779026, Semantic loss: 0.835621, BCE loss: 0.558906, SB loss: 0.791045
2023-10-30 02:07:42,896 Epoch: [61/484] Iter:[210/495], Time: 0.37, lr: [0.008850204283941508], Loss: 2.177953, Acc:0.780149, Semantic loss: 0.831067, BCE loss: 0.558024, SB loss: 0.788863
2023-10-30 02:07:46,583 Epoch: [61/484] Iter:[220/495], Time: 0.37, lr: [0.008849823492599551], Loss: 2.174343, Acc:0.781877, Semantic loss: 0.829322, BCE loss: 0.556789, SB loss: 0.788232
2023-10-30 02:07:50,239 Epoch: [61/484] Iter:[230/495], Time: 0.37, lr: [0.008849442699437058], Loss: 2.174263, Acc:0.782492, Semantic loss: 0.827804, BCE loss: 0.557796, SB loss: 0.788663
2023-10-30 02:07:53,855 Epoch: [61/484] Iter:[240/495], Time: 0.37, lr: [0.008849061904453934], Loss: 2.178026, Acc:0.782731, Semantic loss: 0.828442, BCE loss: 0.559814, SB loss: 0.789770
2023-10-30 02:07:57,573 Epoch: [61/484] Iter:[250/495], Time: 0.37, lr: [0.008848681107650082], Loss: 2.182226, Acc:0.783137, Semantic loss: 0.830342, BCE loss: 0.562643, SB loss: 0.789241
2023-10-30 02:08:01,217 Epoch: [61/484] Iter:[260/495], Time: 0.37, lr: [0.00884830030902541], Loss: 2.173897, Acc:0.783124, Semantic loss: 0.825331, BCE loss: 0.560642, SB loss: 0.787924
2023-10-30 02:08:04,872 Epoch: [61/484] Iter:[270/495], Time: 0.37, lr: [0.008847919508579818], Loss: 2.172485, Acc:0.782439, Semantic loss: 0.824831, BCE loss: 0.560730, SB loss: 0.786924
2023-10-30 02:08:08,532 Epoch: [61/484] Iter:[280/495], Time: 0.37, lr: [0.008847538706313211], Loss: 2.173328, Acc:0.781854, Semantic loss: 0.826089, BCE loss: 0.560865, SB loss: 0.786375
2023-10-30 02:08:12,172 Epoch: [61/484] Iter:[290/495], Time: 0.37, lr: [0.008847157902225497], Loss: 2.175841, Acc:0.782171, Semantic loss: 0.826995, BCE loss: 0.562021, SB loss: 0.786824
2023-10-30 02:08:15,821 Epoch: [61/484] Iter:[300/495], Time: 0.37, lr: [0.008846777096316576], Loss: 2.175895, Acc:0.782150, Semantic loss: 0.826117, BCE loss: 0.562664, SB loss: 0.787114
2023-10-30 02:08:19,440 Epoch: [61/484] Iter:[310/495], Time: 0.37, lr: [0.008846396288586354], Loss: 2.169742, Acc:0.781988, Semantic loss: 0.822680, BCE loss: 0.561968, SB loss: 0.785094
2023-10-30 02:08:23,011 Epoch: [61/484] Iter:[320/495], Time: 0.37, lr: [0.008846015479034734], Loss: 2.169213, Acc:0.782920, Semantic loss: 0.822129, BCE loss: 0.562615, SB loss: 0.784469
2023-10-30 02:08:26,687 Epoch: [61/484] Iter:[330/495], Time: 0.37, lr: [0.00884563466766162], Loss: 2.168882, Acc:0.783760, Semantic loss: 0.822837, BCE loss: 0.561229, SB loss: 0.784815
2023-10-30 02:08:30,477 Epoch: [61/484] Iter:[340/495], Time: 0.37, lr: [0.008845253854466918], Loss: 2.166202, Acc:0.784692, Semantic loss: 0.821369, BCE loss: 0.560790, SB loss: 0.784042
2023-10-30 02:08:34,127 Epoch: [61/484] Iter:[350/495], Time: 0.37, lr: [0.008844873039450531], Loss: 2.165253, Acc:0.785393, Semantic loss: 0.819702, BCE loss: 0.562176, SB loss: 0.783374
2023-10-30 02:08:37,809 Epoch: [61/484] Iter:[360/495], Time: 0.37, lr: [0.008844492222612363], Loss: 2.162437, Acc:0.785441, Semantic loss: 0.817994, BCE loss: 0.561786, SB loss: 0.782657
2023-10-30 02:08:41,517 Epoch: [61/484] Iter:[370/495], Time: 0.37, lr: [0.00884411140395232], Loss: 2.162513, Acc:0.786097, Semantic loss: 0.817701, BCE loss: 0.562487, SB loss: 0.782324
2023-10-30 02:08:45,149 Epoch: [61/484] Iter:[380/495], Time: 0.37, lr: [0.008843730583470303], Loss: 2.160431, Acc:0.786683, Semantic loss: 0.816601, BCE loss: 0.561689, SB loss: 0.782141
2023-10-30 02:08:48,883 Epoch: [61/484] Iter:[390/495], Time: 0.37, lr: [0.008843349761166219], Loss: 2.158364, Acc:0.787198, Semantic loss: 0.816255, BCE loss: 0.560712, SB loss: 0.781397
2023-10-30 02:08:52,513 Epoch: [61/484] Iter:[400/495], Time: 0.37, lr: [0.00884296893703997], Loss: 2.156119, Acc:0.787291, Semantic loss: 0.814589, BCE loss: 0.561500, SB loss: 0.780030
2023-10-30 02:08:56,184 Epoch: [61/484] Iter:[410/495], Time: 0.37, lr: [0.00884258811109146], Loss: 2.159101, Acc:0.788010, Semantic loss: 0.816138, BCE loss: 0.562282, SB loss: 0.780681
2023-10-30 02:08:59,931 Epoch: [61/484] Iter:[420/495], Time: 0.37, lr: [0.008842207283320594], Loss: 2.159912, Acc:0.788536, Semantic loss: 0.815573, BCE loss: 0.563654, SB loss: 0.780685
2023-10-30 02:09:03,715 Epoch: [61/484] Iter:[430/495], Time: 0.37, lr: [0.008841826453727277], Loss: 2.153573, Acc:0.787665, Semantic loss: 0.812842, BCE loss: 0.561618, SB loss: 0.779113
2023-10-30 02:09:07,427 Epoch: [61/484] Iter:[440/495], Time: 0.37, lr: [0.008841445622311412], Loss: 2.151439, Acc:0.787881, Semantic loss: 0.811574, BCE loss: 0.561083, SB loss: 0.778782
2023-10-30 02:09:11,143 Epoch: [61/484] Iter:[450/495], Time: 0.37, lr: [0.008841064789072902], Loss: 2.150225, Acc:0.788230, Semantic loss: 0.810324, BCE loss: 0.561728, SB loss: 0.778174
2023-10-30 02:09:14,918 Epoch: [61/484] Iter:[460/495], Time: 0.37, lr: [0.008840683954011653], Loss: 2.147379, Acc:0.788383, Semantic loss: 0.809734, BCE loss: 0.560086, SB loss: 0.777558
2023-10-30 02:09:18,559 Epoch: [61/484] Iter:[470/495], Time: 0.37, lr: [0.008840303117127569], Loss: 2.150084, Acc:0.789210, Semantic loss: 0.810931, BCE loss: 0.561147, SB loss: 0.778006
2023-10-30 02:09:22,191 Epoch: [61/484] Iter:[480/495], Time: 0.37, lr: [0.008839922278420552], Loss: 2.151813, Acc:0.789193, Semantic loss: 0.811458, BCE loss: 0.561640, SB loss: 0.778715
2023-10-30 02:09:25,664 Epoch: [61/484] Iter:[490/495], Time: 0.37, lr: [0.008839541437890506], Loss: 2.150842, Acc:0.788148, Semantic loss: 0.811168, BCE loss: 0.560865, SB loss: 0.778809
2023-10-30 02:09:27,064 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:09:27,301 Loss: 2.169, MeanIU:  0.6600, Best_mIoU:  0.6736
2023-10-30 02:09:27,301 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879]
2023-10-30 02:09:29,399 Epoch: [62/484] Iter:[0/495], Time: 2.06, lr: [0.00883935101694182], Loss: 1.778351, Acc:0.812684, Semantic loss: 0.652610, BCE loss: 0.348091, SB loss: 0.777649
2023-10-30 02:09:33,419 Epoch: [62/484] Iter:[10/495], Time: 0.55, lr: [0.008838970173677055], Loss: 2.032951, Acc:0.774722, Semantic loss: 0.719457, BCE loss: 0.554304, SB loss: 0.759190
2023-10-30 02:09:37,082 Epoch: [62/484] Iter:[20/495], Time: 0.46, lr: [0.008838589328589021], Loss: 2.083547, Acc:0.780137, Semantic loss: 0.769044, BCE loss: 0.541168, SB loss: 0.773336
2023-10-30 02:09:40,760 Epoch: [62/484] Iter:[30/495], Time: 0.43, lr: [0.008838208481677622], Loss: 2.077902, Acc:0.793132, Semantic loss: 0.755854, BCE loss: 0.552084, SB loss: 0.769964
2023-10-30 02:09:44,441 Epoch: [62/484] Iter:[40/495], Time: 0.42, lr: [0.008837827632942764], Loss: 2.115404, Acc:0.798891, Semantic loss: 0.786225, BCE loss: 0.564719, SB loss: 0.764461
2023-10-30 02:09:48,009 Epoch: [62/484] Iter:[50/495], Time: 0.41, lr: [0.00883744678238435], Loss: 2.083647, Acc:0.798942, Semantic loss: 0.774068, BCE loss: 0.554454, SB loss: 0.755126
2023-10-30 02:09:51,720 Epoch: [62/484] Iter:[60/495], Time: 0.40, lr: [0.008837065930002287], Loss: 2.074716, Acc:0.796852, Semantic loss: 0.772839, BCE loss: 0.546636, SB loss: 0.755241
2023-10-30 02:09:55,381 Epoch: [62/484] Iter:[70/495], Time: 0.39, lr: [0.008836685075796474], Loss: 2.065077, Acc:0.799325, Semantic loss: 0.773171, BCE loss: 0.538347, SB loss: 0.753559
2023-10-30 02:09:59,345 Epoch: [62/484] Iter:[80/495], Time: 0.40, lr: [0.008836304219766816], Loss: 2.060959, Acc:0.796833, Semantic loss: 0.775923, BCE loss: 0.536585, SB loss: 0.748451
2023-10-30 02:10:03,092 Epoch: [62/484] Iter:[90/495], Time: 0.39, lr: [0.008835923361913217], Loss: 2.084655, Acc:0.798987, Semantic loss: 0.790725, BCE loss: 0.540075, SB loss: 0.753855
2023-10-30 02:10:06,748 Epoch: [62/484] Iter:[100/495], Time: 0.39, lr: [0.008835542502235583], Loss: 2.094294, Acc:0.791455, Semantic loss: 0.795981, BCE loss: 0.539559, SB loss: 0.758754
2023-10-30 02:10:10,374 Epoch: [62/484] Iter:[110/495], Time: 0.39, lr: [0.008835161640733816], Loss: 2.115747, Acc:0.789788, Semantic loss: 0.808550, BCE loss: 0.540340, SB loss: 0.766858
2023-10-30 02:10:14,013 Epoch: [62/484] Iter:[120/495], Time: 0.39, lr: [0.008834780777407823], Loss: 2.113059, Acc:0.786766, Semantic loss: 0.803430, BCE loss: 0.543320, SB loss: 0.766309
2023-10-30 02:10:17,629 Epoch: [62/484] Iter:[130/495], Time: 0.38, lr: [0.008834399912257504], Loss: 2.122647, Acc:0.786415, Semantic loss: 0.804273, BCE loss: 0.546046, SB loss: 0.772327
2023-10-30 02:10:21,242 Epoch: [62/484] Iter:[140/495], Time: 0.38, lr: [0.008834019045282764], Loss: 2.105948, Acc:0.782805, Semantic loss: 0.796595, BCE loss: 0.540534, SB loss: 0.768818
2023-10-30 02:10:24,962 Epoch: [62/484] Iter:[150/495], Time: 0.38, lr: [0.008833638176483506], Loss: 2.111156, Acc:0.783949, Semantic loss: 0.799422, BCE loss: 0.543081, SB loss: 0.768653
2023-10-30 02:10:28,692 Epoch: [62/484] Iter:[160/495], Time: 0.38, lr: [0.008833257305859639], Loss: 2.112558, Acc:0.784089, Semantic loss: 0.798970, BCE loss: 0.542372, SB loss: 0.771216
2023-10-30 02:10:32,368 Epoch: [62/484] Iter:[170/495], Time: 0.38, lr: [0.008832876433411059], Loss: 2.111360, Acc:0.784601, Semantic loss: 0.794715, BCE loss: 0.546549, SB loss: 0.770096
2023-10-30 02:10:35,915 Epoch: [62/484] Iter:[180/495], Time: 0.38, lr: [0.008832495559137675], Loss: 2.102269, Acc:0.783814, Semantic loss: 0.794534, BCE loss: 0.539943, SB loss: 0.767792
2023-10-30 02:10:39,604 Epoch: [62/484] Iter:[190/495], Time: 0.38, lr: [0.00883211468303939], Loss: 2.102880, Acc:0.783570, Semantic loss: 0.794109, BCE loss: 0.541286, SB loss: 0.767485
2023-10-30 02:10:43,263 Epoch: [62/484] Iter:[200/495], Time: 0.38, lr: [0.008831733805116105], Loss: 2.100870, Acc:0.783381, Semantic loss: 0.793444, BCE loss: 0.540454, SB loss: 0.766972
2023-10-30 02:10:46,942 Epoch: [62/484] Iter:[210/495], Time: 0.38, lr: [0.008831352925367728], Loss: 2.104175, Acc:0.781583, Semantic loss: 0.796192, BCE loss: 0.539679, SB loss: 0.768304
2023-10-30 02:10:50,652 Epoch: [62/484] Iter:[220/495], Time: 0.38, lr: [0.008830972043794162], Loss: 2.098666, Acc:0.782013, Semantic loss: 0.792168, BCE loss: 0.538520, SB loss: 0.767978
2023-10-30 02:10:54,303 Epoch: [62/484] Iter:[230/495], Time: 0.38, lr: [0.008830591160395309], Loss: 2.099241, Acc:0.783314, Semantic loss: 0.790786, BCE loss: 0.540433, SB loss: 0.768022
2023-10-30 02:10:57,966 Epoch: [62/484] Iter:[240/495], Time: 0.38, lr: [0.008830210275171071], Loss: 2.099983, Acc:0.782092, Semantic loss: 0.791895, BCE loss: 0.538574, SB loss: 0.769514
2023-10-30 02:11:01,623 Epoch: [62/484] Iter:[250/495], Time: 0.38, lr: [0.008829829388121357], Loss: 2.102163, Acc:0.784469, Semantic loss: 0.790359, BCE loss: 0.542403, SB loss: 0.769401
2023-10-30 02:11:05,286 Epoch: [62/484] Iter:[260/495], Time: 0.38, lr: [0.008829448499246068], Loss: 2.093004, Acc:0.783410, Semantic loss: 0.787147, BCE loss: 0.538788, SB loss: 0.767069
2023-10-30 02:11:09,016 Epoch: [62/484] Iter:[270/495], Time: 0.38, lr: [0.008829067608545108], Loss: 2.099526, Acc:0.783570, Semantic loss: 0.790079, BCE loss: 0.541499, SB loss: 0.767947
2023-10-30 02:11:12,761 Epoch: [62/484] Iter:[280/495], Time: 0.38, lr: [0.008828686716018379], Loss: 2.099734, Acc:0.783696, Semantic loss: 0.790071, BCE loss: 0.542134, SB loss: 0.767529
2023-10-30 02:11:16,467 Epoch: [62/484] Iter:[290/495], Time: 0.38, lr: [0.008828305821665787], Loss: 2.110436, Acc:0.783144, Semantic loss: 0.795669, BCE loss: 0.544465, SB loss: 0.770302
2023-10-30 02:11:20,157 Epoch: [62/484] Iter:[300/495], Time: 0.37, lr: [0.008827924925487235], Loss: 2.112461, Acc:0.782927, Semantic loss: 0.796578, BCE loss: 0.543929, SB loss: 0.771954
2023-10-30 02:11:23,730 Epoch: [62/484] Iter:[310/495], Time: 0.37, lr: [0.008827544027482625], Loss: 2.117998, Acc:0.781729, Semantic loss: 0.799278, BCE loss: 0.544921, SB loss: 0.773798
2023-10-30 02:11:27,434 Epoch: [62/484] Iter:[320/495], Time: 0.37, lr: [0.008827163127651865], Loss: 2.116712, Acc:0.781096, Semantic loss: 0.797385, BCE loss: 0.545482, SB loss: 0.773845
2023-10-30 02:11:31,075 Epoch: [62/484] Iter:[330/495], Time: 0.37, lr: [0.008826782225994855], Loss: 2.117574, Acc:0.781463, Semantic loss: 0.798295, BCE loss: 0.544728, SB loss: 0.774550
2023-10-30 02:11:34,792 Epoch: [62/484] Iter:[340/495], Time: 0.37, lr: [0.0088264013225115], Loss: 2.111182, Acc:0.781718, Semantic loss: 0.794608, BCE loss: 0.543554, SB loss: 0.773020
2023-10-30 02:11:38,476 Epoch: [62/484] Iter:[350/495], Time: 0.37, lr: [0.008826020417201702], Loss: 2.113082, Acc:0.781789, Semantic loss: 0.794931, BCE loss: 0.544017, SB loss: 0.774134
2023-10-30 02:11:42,125 Epoch: [62/484] Iter:[360/495], Time: 0.37, lr: [0.008825639510065368], Loss: 2.114175, Acc:0.782747, Semantic loss: 0.795197, BCE loss: 0.545374, SB loss: 0.773603
2023-10-30 02:11:45,832 Epoch: [62/484] Iter:[370/495], Time: 0.37, lr: [0.0088252586011024], Loss: 2.113142, Acc:0.783341, Semantic loss: 0.794359, BCE loss: 0.546001, SB loss: 0.772781
2023-10-30 02:11:49,534 Epoch: [62/484] Iter:[380/495], Time: 0.37, lr: [0.0088248776903127], Loss: 2.115042, Acc:0.783454, Semantic loss: 0.795207, BCE loss: 0.546098, SB loss: 0.773737
2023-10-30 02:11:53,226 Epoch: [62/484] Iter:[390/495], Time: 0.37, lr: [0.00882449677769617], Loss: 2.116891, Acc:0.783438, Semantic loss: 0.795753, BCE loss: 0.547643, SB loss: 0.773495
2023-10-30 02:11:56,964 Epoch: [62/484] Iter:[400/495], Time: 0.37, lr: [0.008824115863252721], Loss: 2.120658, Acc:0.783581, Semantic loss: 0.798358, BCE loss: 0.549072, SB loss: 0.773228
2023-10-30 02:12:00,632 Epoch: [62/484] Iter:[410/495], Time: 0.37, lr: [0.008823734946982251], Loss: 2.118693, Acc:0.784856, Semantic loss: 0.797235, BCE loss: 0.548998, SB loss: 0.772460
2023-10-30 02:12:04,326 Epoch: [62/484] Iter:[420/495], Time: 0.37, lr: [0.008823354028884664], Loss: 2.118312, Acc:0.785147, Semantic loss: 0.796555, BCE loss: 0.549331, SB loss: 0.772426
2023-10-30 02:12:08,030 Epoch: [62/484] Iter:[430/495], Time: 0.37, lr: [0.008822973108959867], Loss: 2.116166, Acc:0.786243, Semantic loss: 0.795162, BCE loss: 0.549452, SB loss: 0.771552
2023-10-30 02:12:11,690 Epoch: [62/484] Iter:[440/495], Time: 0.37, lr: [0.008822592187207759], Loss: 2.114925, Acc:0.786496, Semantic loss: 0.795153, BCE loss: 0.549052, SB loss: 0.770720
2023-10-30 02:12:15,342 Epoch: [62/484] Iter:[450/495], Time: 0.37, lr: [0.008822211263628246], Loss: 2.117850, Acc:0.786812, Semantic loss: 0.796532, BCE loss: 0.549699, SB loss: 0.771618
2023-10-30 02:12:18,971 Epoch: [62/484] Iter:[460/495], Time: 0.37, lr: [0.00882183033822123], Loss: 2.119427, Acc:0.787250, Semantic loss: 0.798639, BCE loss: 0.548370, SB loss: 0.772419
2023-10-30 02:12:22,535 Epoch: [62/484] Iter:[470/495], Time: 0.37, lr: [0.008821449410986617], Loss: 2.117523, Acc:0.786823, Semantic loss: 0.797330, BCE loss: 0.547971, SB loss: 0.772222
2023-10-30 02:12:26,255 Epoch: [62/484] Iter:[480/495], Time: 0.37, lr: [0.008821068481924307], Loss: 2.121735, Acc:0.785882, Semantic loss: 0.801041, BCE loss: 0.547207, SB loss: 0.773487
2023-10-30 02:12:29,780 Epoch: [62/484] Iter:[490/495], Time: 0.37, lr: [0.008820687551034209], Loss: 2.124959, Acc:0.785700, Semantic loss: 0.802189, BCE loss: 0.548137, SB loss: 0.774632
2023-10-30 02:12:31,186 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:12:31,419 Loss: 2.169, MeanIU:  0.6600, Best_mIoU:  0.6736
2023-10-30 02:12:31,419 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879]
2023-10-30 02:12:33,416 Epoch: [63/484] Iter:[0/495], Time: 1.96, lr: [0.008820497084903707], Loss: 1.711719, Acc:0.803616, Semantic loss: 0.644658, BCE loss: 0.396641, SB loss: 0.670419
2023-10-30 02:12:37,326 Epoch: [63/484] Iter:[10/495], Time: 0.53, lr: [0.00882011615127174], Loss: 2.224593, Acc:0.790543, Semantic loss: 0.870426, BCE loss: 0.559619, SB loss: 0.794548
2023-10-30 02:12:40,969 Epoch: [63/484] Iter:[20/495], Time: 0.45, lr: [0.008819735215811739], Loss: 2.180278, Acc:0.777609, Semantic loss: 0.835137, BCE loss: 0.539963, SB loss: 0.805178
2023-10-30 02:12:44,576 Epoch: [63/484] Iter:[30/495], Time: 0.42, lr: [0.008819354278523612], Loss: 2.147480, Acc:0.779133, Semantic loss: 0.816835, BCE loss: 0.532809, SB loss: 0.797836
2023-10-30 02:12:48,278 Epoch: [63/484] Iter:[40/495], Time: 0.41, lr: [0.008818973339407257], Loss: 2.103138, Acc:0.783633, Semantic loss: 0.781530, BCE loss: 0.542160, SB loss: 0.779448
2023-10-30 02:12:51,857 Epoch: [63/484] Iter:[50/495], Time: 0.40, lr: [0.00881859239846258], Loss: 2.083690, Acc:0.786154, Semantic loss: 0.776068, BCE loss: 0.535074, SB loss: 0.772549
2023-10-30 02:12:55,567 Epoch: [63/484] Iter:[60/495], Time: 0.40, lr: [0.008818211455689486], Loss: 2.082155, Acc:0.794622, Semantic loss: 0.772292, BCE loss: 0.544726, SB loss: 0.765137
2023-10-30 02:12:59,108 Epoch: [63/484] Iter:[70/495], Time: 0.39, lr: [0.008817830511087876], Loss: 2.095117, Acc:0.784770, Semantic loss: 0.786240, BCE loss: 0.540069, SB loss: 0.768809
2023-10-30 02:13:02,784 Epoch: [63/484] Iter:[80/495], Time: 0.39, lr: [0.008817449564657654], Loss: 2.102772, Acc:0.787310, Semantic loss: 0.790167, BCE loss: 0.546914, SB loss: 0.765691
2023-10-30 02:13:06,463 Epoch: [63/484] Iter:[90/495], Time: 0.38, lr: [0.008817068616398723], Loss: 2.122790, Acc:0.789580, Semantic loss: 0.796991, BCE loss: 0.552668, SB loss: 0.773131
2023-10-30 02:13:10,153 Epoch: [63/484] Iter:[100/495], Time: 0.38, lr: [0.00881668766631099], Loss: 2.120263, Acc:0.789257, Semantic loss: 0.795222, BCE loss: 0.553647, SB loss: 0.771394
2023-10-30 02:13:13,765 Epoch: [63/484] Iter:[110/495], Time: 0.38, lr: [0.008816306714394354], Loss: 2.109491, Acc:0.790480, Semantic loss: 0.787765, BCE loss: 0.552998, SB loss: 0.768729
2023-10-30 02:13:17,500 Epoch: [63/484] Iter:[120/495], Time: 0.38, lr: [0.008815925760648722], Loss: 2.104295, Acc:0.792199, Semantic loss: 0.787233, BCE loss: 0.550178, SB loss: 0.766884
2023-10-30 02:13:21,285 Epoch: [63/484] Iter:[130/495], Time: 0.38, lr: [0.008815544805073992], Loss: 2.119592, Acc:0.792620, Semantic loss: 0.796244, BCE loss: 0.552651, SB loss: 0.770697
2023-10-30 02:13:24,933 Epoch: [63/484] Iter:[140/495], Time: 0.38, lr: [0.008815163847670072], Loss: 2.128027, Acc:0.792109, Semantic loss: 0.798865, BCE loss: 0.557993, SB loss: 0.771169
2023-10-30 02:13:28,628 Epoch: [63/484] Iter:[150/495], Time: 0.38, lr: [0.008814782888436866], Loss: 2.122414, Acc:0.792109, Semantic loss: 0.794125, BCE loss: 0.559193, SB loss: 0.769096
2023-10-30 02:13:32,353 Epoch: [63/484] Iter:[160/495], Time: 0.38, lr: [0.008814401927374274], Loss: 2.124917, Acc:0.791012, Semantic loss: 0.798697, BCE loss: 0.554373, SB loss: 0.771847
2023-10-30 02:13:36,151 Epoch: [63/484] Iter:[170/495], Time: 0.38, lr: [0.008814020964482201], Loss: 2.133631, Acc:0.791676, Semantic loss: 0.799247, BCE loss: 0.562120, SB loss: 0.772265
2023-10-30 02:13:39,896 Epoch: [63/484] Iter:[180/495], Time: 0.38, lr: [0.008813639999760552], Loss: 2.138928, Acc:0.793333, Semantic loss: 0.800182, BCE loss: 0.565702, SB loss: 0.773043
2023-10-30 02:13:43,487 Epoch: [63/484] Iter:[190/495], Time: 0.38, lr: [0.008813259033209227], Loss: 2.128730, Acc:0.793029, Semantic loss: 0.796189, BCE loss: 0.561275, SB loss: 0.771266
2023-10-30 02:13:47,216 Epoch: [63/484] Iter:[200/495], Time: 0.38, lr: [0.008812878064828132], Loss: 2.129922, Acc:0.793484, Semantic loss: 0.795583, BCE loss: 0.562810, SB loss: 0.771529
2023-10-30 02:13:50,852 Epoch: [63/484] Iter:[210/495], Time: 0.38, lr: [0.008812497094617169], Loss: 2.132922, Acc:0.792889, Semantic loss: 0.796875, BCE loss: 0.562627, SB loss: 0.773420
2023-10-30 02:13:54,544 Epoch: [63/484] Iter:[220/495], Time: 0.38, lr: [0.008812116122576241], Loss: 2.130899, Acc:0.792453, Semantic loss: 0.795145, BCE loss: 0.563334, SB loss: 0.772419
2023-10-30 02:13:58,165 Epoch: [63/484] Iter:[230/495], Time: 0.38, lr: [0.008811735148705254], Loss: 2.133033, Acc:0.792707, Semantic loss: 0.796226, BCE loss: 0.565669, SB loss: 0.771138
2023-10-30 02:14:01,822 Epoch: [63/484] Iter:[240/495], Time: 0.37, lr: [0.008811354173004106], Loss: 2.132221, Acc:0.792406, Semantic loss: 0.797694, BCE loss: 0.561633, SB loss: 0.772894
2023-10-30 02:14:05,608 Epoch: [63/484] Iter:[250/495], Time: 0.38, lr: [0.008810973195472705], Loss: 2.134863, Acc:0.793416, Semantic loss: 0.799789, BCE loss: 0.560656, SB loss: 0.774418
2023-10-30 02:14:09,370 Epoch: [63/484] Iter:[260/495], Time: 0.38, lr: [0.008810592216110955], Loss: 2.133716, Acc:0.793724, Semantic loss: 0.799216, BCE loss: 0.560859, SB loss: 0.773640
2023-10-30 02:14:13,104 Epoch: [63/484] Iter:[270/495], Time: 0.38, lr: [0.008810211234918755], Loss: 2.140062, Acc:0.793433, Semantic loss: 0.801910, BCE loss: 0.563815, SB loss: 0.774337
2023-10-30 02:14:16,870 Epoch: [63/484] Iter:[280/495], Time: 0.38, lr: [0.00880983025189601], Loss: 2.144480, Acc:0.794581, Semantic loss: 0.803053, BCE loss: 0.565439, SB loss: 0.775988
2023-10-30 02:14:20,559 Epoch: [63/484] Iter:[290/495], Time: 0.37, lr: [0.008809449267042625], Loss: 2.139330, Acc:0.794647, Semantic loss: 0.800778, BCE loss: 0.564331, SB loss: 0.774221
2023-10-30 02:14:24,244 Epoch: [63/484] Iter:[300/495], Time: 0.37, lr: [0.0088090682803585], Loss: 2.140554, Acc:0.794990, Semantic loss: 0.800619, BCE loss: 0.564998, SB loss: 0.774936
2023-10-30 02:14:27,937 Epoch: [63/484] Iter:[310/495], Time: 0.37, lr: [0.008808687291843541], Loss: 2.139253, Acc:0.794363, Semantic loss: 0.801883, BCE loss: 0.562871, SB loss: 0.774500
2023-10-30 02:14:31,606 Epoch: [63/484] Iter:[320/495], Time: 0.37, lr: [0.00880830630149765], Loss: 2.135638, Acc:0.793615, Semantic loss: 0.801340, BCE loss: 0.559939, SB loss: 0.774358
2023-10-30 02:14:35,301 Epoch: [63/484] Iter:[330/495], Time: 0.37, lr: [0.008807925309320732], Loss: 2.135339, Acc:0.793342, Semantic loss: 0.800959, BCE loss: 0.560066, SB loss: 0.774314
2023-10-30 02:14:38,897 Epoch: [63/484] Iter:[340/495], Time: 0.37, lr: [0.008807544315312686], Loss: 2.137971, Acc:0.793209, Semantic loss: 0.802812, BCE loss: 0.560281, SB loss: 0.774879
2023-10-30 02:14:42,649 Epoch: [63/484] Iter:[350/495], Time: 0.37, lr: [0.00880716331947342], Loss: 2.137105, Acc:0.792526, Semantic loss: 0.803379, BCE loss: 0.559160, SB loss: 0.774567
2023-10-30 02:14:46,337 Epoch: [63/484] Iter:[360/495], Time: 0.37, lr: [0.008806782321802835], Loss: 2.134430, Acc:0.792827, Semantic loss: 0.802013, BCE loss: 0.558953, SB loss: 0.773463
2023-10-30 02:14:50,032 Epoch: [63/484] Iter:[370/495], Time: 0.37, lr: [0.008806401322300834], Loss: 2.134875, Acc:0.793195, Semantic loss: 0.801782, BCE loss: 0.559605, SB loss: 0.773489
2023-10-30 02:14:53,758 Epoch: [63/484] Iter:[380/495], Time: 0.37, lr: [0.008806020320967318], Loss: 2.136706, Acc:0.792379, Semantic loss: 0.803162, BCE loss: 0.557946, SB loss: 0.775598
2023-10-30 02:14:57,561 Epoch: [63/484] Iter:[390/495], Time: 0.37, lr: [0.008805639317802195], Loss: 2.146567, Acc:0.791710, Semantic loss: 0.807624, BCE loss: 0.561293, SB loss: 0.777650
2023-10-30 02:15:01,135 Epoch: [63/484] Iter:[400/495], Time: 0.37, lr: [0.008805258312805365], Loss: 2.147050, Acc:0.792137, Semantic loss: 0.807158, BCE loss: 0.561621, SB loss: 0.778271
2023-10-30 02:15:04,878 Epoch: [63/484] Iter:[410/495], Time: 0.37, lr: [0.008804877305976731], Loss: 2.145134, Acc:0.791826, Semantic loss: 0.807069, BCE loss: 0.560669, SB loss: 0.777396
2023-10-30 02:15:08,597 Epoch: [63/484] Iter:[420/495], Time: 0.37, lr: [0.0088044962973162], Loss: 2.143306, Acc:0.791991, Semantic loss: 0.805034, BCE loss: 0.560998, SB loss: 0.777274
2023-10-30 02:15:12,248 Epoch: [63/484] Iter:[430/495], Time: 0.37, lr: [0.008804115286823668], Loss: 2.146128, Acc:0.792404, Semantic loss: 0.808601, BCE loss: 0.560576, SB loss: 0.776951
2023-10-30 02:15:15,940 Epoch: [63/484] Iter:[440/495], Time: 0.37, lr: [0.008803734274499044], Loss: 2.145149, Acc:0.792697, Semantic loss: 0.808094, BCE loss: 0.560115, SB loss: 0.776940
2023-10-30 02:15:19,687 Epoch: [63/484] Iter:[450/495], Time: 0.37, lr: [0.00880335326034223], Loss: 2.143915, Acc:0.792690, Semantic loss: 0.807349, BCE loss: 0.559547, SB loss: 0.777019
2023-10-30 02:15:23,289 Epoch: [63/484] Iter:[460/495], Time: 0.37, lr: [0.008802972244353127], Loss: 2.142616, Acc:0.792459, Semantic loss: 0.807871, BCE loss: 0.556916, SB loss: 0.777829
2023-10-30 02:15:26,960 Epoch: [63/484] Iter:[470/495], Time: 0.37, lr: [0.00880259122653164], Loss: 2.142088, Acc:0.791662, Semantic loss: 0.808075, BCE loss: 0.556792, SB loss: 0.777222
2023-10-30 02:15:30,672 Epoch: [63/484] Iter:[480/495], Time: 0.37, lr: [0.00880221020687767], Loss: 2.139312, Acc:0.791552, Semantic loss: 0.805735, BCE loss: 0.556863, SB loss: 0.776714
2023-10-30 02:15:34,232 Epoch: [63/484] Iter:[490/495], Time: 0.37, lr: [0.008801829185391123], Loss: 2.141849, Acc:0.791446, Semantic loss: 0.807888, BCE loss: 0.556485, SB loss: 0.777477
2023-10-30 02:15:35,651 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:15:35,889 Loss: 2.169, MeanIU:  0.6600, Best_mIoU:  0.6736
2023-10-30 02:15:35,889 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879]
2023-10-30 02:15:37,921 Epoch: [64/484] Iter:[0/495], Time: 2.00, lr: [0.008801638673960601], Loss: 1.945149, Acc:0.782231, Semantic loss: 0.636334, BCE loss: 0.636956, SB loss: 0.671859
2023-10-30 02:15:41,882 Epoch: [64/484] Iter:[10/495], Time: 0.54, lr: [0.008801257649725005], Loss: 2.229274, Acc:0.802932, Semantic loss: 0.814609, BCE loss: 0.605276, SB loss: 0.809388
2023-10-30 02:15:45,577 Epoch: [64/484] Iter:[20/495], Time: 0.46, lr: [0.008800876623656586], Loss: 2.155087, Acc:0.789108, Semantic loss: 0.815125, BCE loss: 0.551572, SB loss: 0.788389
2023-10-30 02:15:49,206 Epoch: [64/484] Iter:[30/495], Time: 0.43, lr: [0.00880049559575525], Loss: 2.102570, Acc:0.791652, Semantic loss: 0.783308, BCE loss: 0.538338, SB loss: 0.780924
2023-10-30 02:15:52,824 Epoch: [64/484] Iter:[40/495], Time: 0.41, lr: [0.008800114566020898], Loss: 2.076324, Acc:0.800536, Semantic loss: 0.773462, BCE loss: 0.527777, SB loss: 0.775086
2023-10-30 02:15:56,430 Epoch: [64/484] Iter:[50/495], Time: 0.40, lr: [0.008799733534453435], Loss: 2.102496, Acc:0.794149, Semantic loss: 0.792321, BCE loss: 0.526146, SB loss: 0.784029
2023-10-30 02:16:00,109 Epoch: [64/484] Iter:[60/495], Time: 0.40, lr: [0.008799352501052763], Loss: 2.106310, Acc:0.790621, Semantic loss: 0.786486, BCE loss: 0.535589, SB loss: 0.784235
2023-10-30 02:16:03,723 Epoch: [64/484] Iter:[70/495], Time: 0.39, lr: [0.008798971465818786], Loss: 2.094530, Acc:0.787020, Semantic loss: 0.785561, BCE loss: 0.523253, SB loss: 0.785716
2023-10-30 02:16:07,425 Epoch: [64/484] Iter:[80/495], Time: 0.39, lr: [0.008798590428751404], Loss: 2.117036, Acc:0.786334, Semantic loss: 0.797349, BCE loss: 0.533688, SB loss: 0.785999
2023-10-30 02:16:11,102 Epoch: [64/484] Iter:[90/495], Time: 0.39, lr: [0.008798209389850523], Loss: 2.088561, Acc:0.789817, Semantic loss: 0.784538, BCE loss: 0.527646, SB loss: 0.776377
2023-10-30 02:16:14,801 Epoch: [64/484] Iter:[100/495], Time: 0.38, lr: [0.008797828349116046], Loss: 2.088859, Acc:0.788190, Semantic loss: 0.788332, BCE loss: 0.526010, SB loss: 0.774517
2023-10-30 02:16:18,565 Epoch: [64/484] Iter:[110/495], Time: 0.38, lr: [0.008797447306547872], Loss: 2.112927, Acc:0.788419, Semantic loss: 0.798519, BCE loss: 0.535816, SB loss: 0.778592
2023-10-30 02:16:22,222 Epoch: [64/484] Iter:[120/495], Time: 0.38, lr: [0.008797066262145908], Loss: 2.114360, Acc:0.790591, Semantic loss: 0.798279, BCE loss: 0.539047, SB loss: 0.777033
2023-10-30 02:16:25,891 Epoch: [64/484] Iter:[130/495], Time: 0.38, lr: [0.008796685215910057], Loss: 2.112504, Acc:0.790619, Semantic loss: 0.794854, BCE loss: 0.541224, SB loss: 0.776426
2023-10-30 02:16:29,516 Epoch: [64/484] Iter:[140/495], Time: 0.38, lr: [0.008796304167840219], Loss: 2.108352, Acc:0.788071, Semantic loss: 0.794534, BCE loss: 0.537992, SB loss: 0.775826
2023-10-30 02:16:33,233 Epoch: [64/484] Iter:[150/495], Time: 0.38, lr: [0.008795923117936299], Loss: 2.105843, Acc:0.787626, Semantic loss: 0.795151, BCE loss: 0.536058, SB loss: 0.774635
2023-10-30 02:16:36,831 Epoch: [64/484] Iter:[160/495], Time: 0.38, lr: [0.0087955420661982], Loss: 2.100864, Acc:0.787711, Semantic loss: 0.790839, BCE loss: 0.537734, SB loss: 0.772291
2023-10-30 02:16:40,480 Epoch: [64/484] Iter:[170/495], Time: 0.38, lr: [0.008795161012625825], Loss: 2.106199, Acc:0.788843, Semantic loss: 0.793335, BCE loss: 0.540253, SB loss: 0.772610
2023-10-30 02:16:44,164 Epoch: [64/484] Iter:[180/495], Time: 0.38, lr: [0.008794779957219074], Loss: 2.112434, Acc:0.789032, Semantic loss: 0.797346, BCE loss: 0.539930, SB loss: 0.775158
2023-10-30 02:16:47,904 Epoch: [64/484] Iter:[190/495], Time: 0.38, lr: [0.008794398899977851], Loss: 2.109477, Acc:0.790144, Semantic loss: 0.794725, BCE loss: 0.540946, SB loss: 0.773805
2023-10-30 02:16:51,532 Epoch: [64/484] Iter:[200/495], Time: 0.38, lr: [0.008794017840902063], Loss: 2.105735, Acc:0.788884, Semantic loss: 0.791954, BCE loss: 0.542369, SB loss: 0.771411
2023-10-30 02:16:55,140 Epoch: [64/484] Iter:[210/495], Time: 0.38, lr: [0.008793636779991607], Loss: 2.104225, Acc:0.790302, Semantic loss: 0.792072, BCE loss: 0.542024, SB loss: 0.770128
2023-10-30 02:16:58,804 Epoch: [64/484] Iter:[220/495], Time: 0.38, lr: [0.008793255717246389], Loss: 2.109428, Acc:0.791097, Semantic loss: 0.793143, BCE loss: 0.544913, SB loss: 0.771372
2023-10-30 02:17:02,560 Epoch: [64/484] Iter:[230/495], Time: 0.38, lr: [0.008792874652666312], Loss: 2.101338, Acc:0.791044, Semantic loss: 0.789371, BCE loss: 0.542232, SB loss: 0.769735
2023-10-30 02:17:06,208 Epoch: [64/484] Iter:[240/495], Time: 0.37, lr: [0.008792493586251279], Loss: 2.100089, Acc:0.791202, Semantic loss: 0.789423, BCE loss: 0.540965, SB loss: 0.769700
2023-10-30 02:17:09,899 Epoch: [64/484] Iter:[250/495], Time: 0.37, lr: [0.00879211251800119], Loss: 2.100811, Acc:0.791000, Semantic loss: 0.789658, BCE loss: 0.540353, SB loss: 0.770800
2023-10-30 02:17:13,647 Epoch: [64/484] Iter:[260/495], Time: 0.37, lr: [0.008791731447915951], Loss: 2.103087, Acc:0.791403, Semantic loss: 0.792425, BCE loss: 0.539252, SB loss: 0.771410
2023-10-30 02:17:17,323 Epoch: [64/484] Iter:[270/495], Time: 0.37, lr: [0.008791350375995462], Loss: 2.102854, Acc:0.790276, Semantic loss: 0.791083, BCE loss: 0.540209, SB loss: 0.771562
2023-10-30 02:17:21,016 Epoch: [64/484] Iter:[280/495], Time: 0.37, lr: [0.00879096930223963], Loss: 2.111715, Acc:0.790486, Semantic loss: 0.795696, BCE loss: 0.543134, SB loss: 0.772885
2023-10-30 02:17:24,835 Epoch: [64/484] Iter:[290/495], Time: 0.37, lr: [0.008790588226648353], Loss: 2.106922, Acc:0.789227, Semantic loss: 0.795141, BCE loss: 0.538919, SB loss: 0.772862
2023-10-30 02:17:28,522 Epoch: [64/484] Iter:[300/495], Time: 0.37, lr: [0.008790207149221536], Loss: 2.108079, Acc:0.789704, Semantic loss: 0.795413, BCE loss: 0.539860, SB loss: 0.772806
2023-10-30 02:17:32,178 Epoch: [64/484] Iter:[310/495], Time: 0.37, lr: [0.00878982606995908], Loss: 2.108665, Acc:0.789795, Semantic loss: 0.795047, BCE loss: 0.540450, SB loss: 0.773169
2023-10-30 02:17:35,999 Epoch: [64/484] Iter:[320/495], Time: 0.37, lr: [0.008789444988860893], Loss: 2.110031, Acc:0.790608, Semantic loss: 0.796716, BCE loss: 0.539600, SB loss: 0.773715
2023-10-30 02:17:39,741 Epoch: [64/484] Iter:[330/495], Time: 0.37, lr: [0.008789063905926871], Loss: 2.115910, Acc:0.790706, Semantic loss: 0.799250, BCE loss: 0.542294, SB loss: 0.774365
2023-10-30 02:17:43,348 Epoch: [64/484] Iter:[340/495], Time: 0.37, lr: [0.008788682821156921], Loss: 2.124830, Acc:0.791923, Semantic loss: 0.802985, BCE loss: 0.545205, SB loss: 0.776639
2023-10-30 02:17:47,095 Epoch: [64/484] Iter:[350/495], Time: 0.37, lr: [0.008788301734550943], Loss: 2.127059, Acc:0.791907, Semantic loss: 0.802765, BCE loss: 0.546992, SB loss: 0.777302
2023-10-30 02:17:50,823 Epoch: [64/484] Iter:[360/495], Time: 0.37, lr: [0.008787920646108843], Loss: 2.131058, Acc:0.792355, Semantic loss: 0.803885, BCE loss: 0.549754, SB loss: 0.777418
2023-10-30 02:17:54,454 Epoch: [64/484] Iter:[370/495], Time: 0.37, lr: [0.008787539555830521], Loss: 2.131436, Acc:0.792801, Semantic loss: 0.802768, BCE loss: 0.550557, SB loss: 0.778111
2023-10-30 02:17:58,090 Epoch: [64/484] Iter:[380/495], Time: 0.37, lr: [0.008787158463715878], Loss: 2.130779, Acc:0.793045, Semantic loss: 0.802403, BCE loss: 0.550835, SB loss: 0.777540
2023-10-30 02:18:01,767 Epoch: [64/484] Iter:[390/495], Time: 0.37, lr: [0.008786777369764822], Loss: 2.131192, Acc:0.793352, Semantic loss: 0.802870, BCE loss: 0.550098, SB loss: 0.778225
2023-10-30 02:18:05,579 Epoch: [64/484] Iter:[400/495], Time: 0.37, lr: [0.008786396273977252], Loss: 2.132304, Acc:0.793072, Semantic loss: 0.802704, BCE loss: 0.551782, SB loss: 0.777818
2023-10-30 02:18:09,249 Epoch: [64/484] Iter:[410/495], Time: 0.37, lr: [0.008786015176353072], Loss: 2.132248, Acc:0.792979, Semantic loss: 0.802021, BCE loss: 0.552132, SB loss: 0.778095
2023-10-30 02:18:12,961 Epoch: [64/484] Iter:[420/495], Time: 0.37, lr: [0.008785634076892182], Loss: 2.137163, Acc:0.792187, Semantic loss: 0.806672, BCE loss: 0.551895, SB loss: 0.778595
2023-10-30 02:18:16,624 Epoch: [64/484] Iter:[430/495], Time: 0.37, lr: [0.00878525297559449], Loss: 2.137123, Acc:0.791348, Semantic loss: 0.807062, BCE loss: 0.550292, SB loss: 0.779770
2023-10-30 02:18:20,322 Epoch: [64/484] Iter:[440/495], Time: 0.37, lr: [0.008784871872459892], Loss: 2.140790, Acc:0.791578, Semantic loss: 0.808075, BCE loss: 0.551990, SB loss: 0.780726
2023-10-30 02:18:23,916 Epoch: [64/484] Iter:[450/495], Time: 0.37, lr: [0.008784490767488294], Loss: 2.145160, Acc:0.791391, Semantic loss: 0.810486, BCE loss: 0.552370, SB loss: 0.782304
2023-10-30 02:18:27,648 Epoch: [64/484] Iter:[460/495], Time: 0.37, lr: [0.0087841096606796], Loss: 2.148638, Acc:0.790529, Semantic loss: 0.812676, BCE loss: 0.552655, SB loss: 0.783307
2023-10-30 02:18:31,333 Epoch: [64/484] Iter:[470/495], Time: 0.37, lr: [0.00878372855203371], Loss: 2.147538, Acc:0.791399, Semantic loss: 0.811424, BCE loss: 0.552008, SB loss: 0.784106
2023-10-30 02:18:35,044 Epoch: [64/484] Iter:[480/495], Time: 0.37, lr: [0.008783347441550527], Loss: 2.144187, Acc:0.790852, Semantic loss: 0.809696, BCE loss: 0.550750, SB loss: 0.783741
2023-10-30 02:18:38,558 Epoch: [64/484] Iter:[490/495], Time: 0.37, lr: [0.008782966329229957], Loss: 2.148621, Acc:0.790889, Semantic loss: 0.811833, BCE loss: 0.551974, SB loss: 0.784815
2023-10-30 02:18:39,969 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:18:40,207 Loss: 2.169, MeanIU:  0.6600, Best_mIoU:  0.6736
2023-10-30 02:18:40,208 [0.97008741 0.78176203 0.89263915 0.35742881 0.50160669 0.50875421
 0.6413941  0.62808583 0.90497595 0.57535403 0.9220389  0.76473525
 0.53128071 0.91110149 0.45546283 0.72614953 0.3407531  0.42366601
 0.70201879]
2023-10-30 02:18:42,283 Epoch: [65/484] Iter:[0/495], Time: 2.04, lr: [0.00878277577238062], Loss: 1.849911, Acc:0.743938, Semantic loss: 0.702269, BCE loss: 0.427627, SB loss: 0.720015
2023-10-30 02:18:46,219 Epoch: [65/484] Iter:[10/495], Time: 0.54, lr: [0.00878239465730378], Loss: 2.215978, Acc:0.796812, Semantic loss: 0.781828, BCE loss: 0.641887, SB loss: 0.792263
2023-10-30 02:18:49,909 Epoch: [65/484] Iter:[20/495], Time: 0.46, lr: [0.008782013540389306], Loss: 2.181006, Acc:0.792861, Semantic loss: 0.794049, BCE loss: 0.593268, SB loss: 0.793689
2023-10-30 02:18:53,549 Epoch: [65/484] Iter:[30/495], Time: 0.43, lr: [0.008781632421637103], Loss: 2.140294, Acc:0.794781, Semantic loss: 0.794651, BCE loss: 0.571200, SB loss: 0.774443
2023-10-30 02:18:57,261 Epoch: [65/484] Iter:[40/495], Time: 0.42, lr: [0.00878125130104707], Loss: 2.142615, Acc:0.797273, Semantic loss: 0.797444, BCE loss: 0.569402, SB loss: 0.775769
2023-10-30 02:19:00,955 Epoch: [65/484] Iter:[50/495], Time: 0.41, lr: [0.008780870178619112], Loss: 2.143112, Acc:0.782948, Semantic loss: 0.803670, BCE loss: 0.556013, SB loss: 0.783429
2023-10-30 02:19:04,718 Epoch: [65/484] Iter:[60/495], Time: 0.40, lr: [0.00878048905435313], Loss: 2.132689, Acc:0.788650, Semantic loss: 0.798521, BCE loss: 0.555718, SB loss: 0.778450
2023-10-30 02:19:08,335 Epoch: [65/484] Iter:[70/495], Time: 0.40, lr: [0.008780107928249029], Loss: 2.122756, Acc:0.784603, Semantic loss: 0.781072, BCE loss: 0.559038, SB loss: 0.782646
2023-10-30 02:19:12,013 Epoch: [65/484] Iter:[80/495], Time: 0.39, lr: [0.008779726800306708], Loss: 2.123536, Acc:0.780109, Semantic loss: 0.781237, BCE loss: 0.561459, SB loss: 0.780839
2023-10-30 02:19:15,678 Epoch: [65/484] Iter:[90/495], Time: 0.39, lr: [0.00877934567052607], Loss: 2.133170, Acc:0.781988, Semantic loss: 0.792323, BCE loss: 0.558822, SB loss: 0.782025
2023-10-30 02:19:19,570 Epoch: [65/484] Iter:[100/495], Time: 0.39, lr: [0.00877896453890702], Loss: 2.145237, Acc:0.778088, Semantic loss: 0.803134, BCE loss: 0.555388, SB loss: 0.786716
2023-10-30 02:19:23,313 Epoch: [65/484] Iter:[110/495], Time: 0.39, lr: [0.008778583405449458], Loss: 2.157327, Acc:0.778269, Semantic loss: 0.807214, BCE loss: 0.563259, SB loss: 0.786853
2023-10-30 02:19:26,908 Epoch: [65/484] Iter:[120/495], Time: 0.39, lr: [0.008778202270153287], Loss: 2.153672, Acc:0.779360, Semantic loss: 0.804808, BCE loss: 0.561148, SB loss: 0.787716
2023-10-30 02:19:30,652 Epoch: [65/484] Iter:[130/495], Time: 0.38, lr: [0.00877782113301841], Loss: 2.157837, Acc:0.779359, Semantic loss: 0.811702, BCE loss: 0.557824, SB loss: 0.788312
2023-10-30 02:19:34,428 Epoch: [65/484] Iter:[140/495], Time: 0.38, lr: [0.008777439994044732], Loss: 2.153245, Acc:0.779839, Semantic loss: 0.809425, BCE loss: 0.556528, SB loss: 0.787292
2023-10-30 02:19:38,171 Epoch: [65/484] Iter:[150/495], Time: 0.38, lr: [0.008777058853232149], Loss: 2.147651, Acc:0.778927, Semantic loss: 0.804245, BCE loss: 0.558175, SB loss: 0.785231
2023-10-30 02:19:41,804 Epoch: [65/484] Iter:[160/495], Time: 0.38, lr: [0.00877667771058057], Loss: 2.155789, Acc:0.780085, Semantic loss: 0.807539, BCE loss: 0.560930, SB loss: 0.787320
2023-10-30 02:19:45,609 Epoch: [65/484] Iter:[170/495], Time: 0.38, lr: [0.008776296566089891], Loss: 2.144518, Acc:0.781163, Semantic loss: 0.800671, BCE loss: 0.559501, SB loss: 0.784346
2023-10-30 02:19:49,225 Epoch: [65/484] Iter:[180/495], Time: 0.38, lr: [0.00877591541976002], Loss: 2.149601, Acc:0.779558, Semantic loss: 0.803935, BCE loss: 0.561713, SB loss: 0.783952
2023-10-30 02:19:52,924 Epoch: [65/484] Iter:[190/495], Time: 0.38, lr: [0.008775534271590857], Loss: 2.145390, Acc:0.778912, Semantic loss: 0.802860, BCE loss: 0.560615, SB loss: 0.781915
2023-10-30 02:19:56,599 Epoch: [65/484] Iter:[200/495], Time: 0.38, lr: [0.008775153121582304], Loss: 2.151900, Acc:0.778323, Semantic loss: 0.806019, BCE loss: 0.559334, SB loss: 0.786547
2023-10-30 02:20:00,266 Epoch: [65/484] Iter:[210/495], Time: 0.38, lr: [0.008774771969734264], Loss: 2.152241, Acc:0.779554, Semantic loss: 0.805650, BCE loss: 0.559137, SB loss: 0.787454
2023-10-30 02:20:03,974 Epoch: [65/484] Iter:[220/495], Time: 0.38, lr: [0.00877439081604664], Loss: 2.155916, Acc:0.780100, Semantic loss: 0.807964, BCE loss: 0.560964, SB loss: 0.786988
2023-10-30 02:20:07,625 Epoch: [65/484] Iter:[230/495], Time: 0.38, lr: [0.008774009660519333], Loss: 2.150924, Acc:0.780376, Semantic loss: 0.804972, BCE loss: 0.560125, SB loss: 0.785827
2023-10-30 02:20:11,300 Epoch: [65/484] Iter:[240/495], Time: 0.38, lr: [0.008773628503152246], Loss: 2.149901, Acc:0.782125, Semantic loss: 0.804656, BCE loss: 0.559231, SB loss: 0.786014
2023-10-30 02:20:14,996 Epoch: [65/484] Iter:[250/495], Time: 0.38, lr: [0.008773247343945282], Loss: 2.154143, Acc:0.782894, Semantic loss: 0.806341, BCE loss: 0.561545, SB loss: 0.786257
2023-10-30 02:20:18,732 Epoch: [65/484] Iter:[260/495], Time: 0.38, lr: [0.008772866182898341], Loss: 2.157351, Acc:0.783689, Semantic loss: 0.806762, BCE loss: 0.563223, SB loss: 0.787366
2023-10-30 02:20:22,485 Epoch: [65/484] Iter:[270/495], Time: 0.38, lr: [0.008772485020011328], Loss: 2.154848, Acc:0.785256, Semantic loss: 0.805599, BCE loss: 0.563555, SB loss: 0.785694
2023-10-30 02:20:26,278 Epoch: [65/484] Iter:[280/495], Time: 0.38, lr: [0.008772103855284142], Loss: 2.158250, Acc:0.786591, Semantic loss: 0.805982, BCE loss: 0.565663, SB loss: 0.786605
2023-10-30 02:20:29,970 Epoch: [65/484] Iter:[290/495], Time: 0.38, lr: [0.008771722688716689], Loss: 2.160474, Acc:0.787343, Semantic loss: 0.809259, BCE loss: 0.564973, SB loss: 0.786242
2023-10-30 02:20:33,647 Epoch: [65/484] Iter:[300/495], Time: 0.38, lr: [0.008771341520308869], Loss: 2.158796, Acc:0.788125, Semantic loss: 0.809230, BCE loss: 0.564438, SB loss: 0.785128
2023-10-30 02:20:37,384 Epoch: [65/484] Iter:[310/495], Time: 0.38, lr: [0.008770960350060586], Loss: 2.164593, Acc:0.787340, Semantic loss: 0.811813, BCE loss: 0.566787, SB loss: 0.785993
2023-10-30 02:20:41,148 Epoch: [65/484] Iter:[320/495], Time: 0.38, lr: [0.00877057917797174], Loss: 2.166414, Acc:0.787284, Semantic loss: 0.811369, BCE loss: 0.568735, SB loss: 0.786310
2023-10-30 02:20:44,865 Epoch: [65/484] Iter:[330/495], Time: 0.38, lr: [0.008770198004042235], Loss: 2.168910, Acc:0.786728, Semantic loss: 0.812573, BCE loss: 0.569505, SB loss: 0.786832
2023-10-30 02:20:48,527 Epoch: [65/484] Iter:[340/495], Time: 0.38, lr: [0.008769816828271973], Loss: 2.166819, Acc:0.786918, Semantic loss: 0.811699, BCE loss: 0.568422, SB loss: 0.786698
2023-10-30 02:20:52,240 Epoch: [65/484] Iter:[350/495], Time: 0.38, lr: [0.008769435650660852], Loss: 2.168127, Acc:0.786477, Semantic loss: 0.813402, BCE loss: 0.567176, SB loss: 0.787550
2023-10-30 02:20:55,898 Epoch: [65/484] Iter:[360/495], Time: 0.38, lr: [0.008769054471208782], Loss: 2.167411, Acc:0.786791, Semantic loss: 0.813146, BCE loss: 0.566658, SB loss: 0.787607
2023-10-30 02:20:59,566 Epoch: [65/484] Iter:[370/495], Time: 0.38, lr: [0.00876867328991566], Loss: 2.163155, Acc:0.786045, Semantic loss: 0.811240, BCE loss: 0.565423, SB loss: 0.786492
2023-10-30 02:21:03,348 Epoch: [65/484] Iter:[380/495], Time: 0.38, lr: [0.00876829210678139], Loss: 2.160314, Acc:0.787787, Semantic loss: 0.808857, BCE loss: 0.566675, SB loss: 0.784782
2023-10-30 02:21:07,083 Epoch: [65/484] Iter:[390/495], Time: 0.38, lr: [0.008767910921805873], Loss: 2.156394, Acc:0.788665, Semantic loss: 0.807177, BCE loss: 0.564948, SB loss: 0.784270
2023-10-30 02:21:10,756 Epoch: [65/484] Iter:[400/495], Time: 0.38, lr: [0.008767529734989012], Loss: 2.158368, Acc:0.788690, Semantic loss: 0.808926, BCE loss: 0.565566, SB loss: 0.783877
2023-10-30 02:21:14,393 Epoch: [65/484] Iter:[410/495], Time: 0.38, lr: [0.008767148546330707], Loss: 2.163215, Acc:0.788750, Semantic loss: 0.810789, BCE loss: 0.567650, SB loss: 0.784776
2023-10-30 02:21:18,090 Epoch: [65/484] Iter:[420/495], Time: 0.37, lr: [0.008766767355830865], Loss: 2.162126, Acc:0.788030, Semantic loss: 0.809783, BCE loss: 0.567217, SB loss: 0.785125
2023-10-30 02:21:21,841 Epoch: [65/484] Iter:[430/495], Time: 0.37, lr: [0.008766386163489381], Loss: 2.160995, Acc:0.788355, Semantic loss: 0.809339, BCE loss: 0.567109, SB loss: 0.784547
2023-10-30 02:21:25,637 Epoch: [65/484] Iter:[440/495], Time: 0.38, lr: [0.008766004969306166], Loss: 2.158177, Acc:0.788517, Semantic loss: 0.808744, BCE loss: 0.566245, SB loss: 0.783189
2023-10-30 02:21:29,335 Epoch: [65/484] Iter:[450/495], Time: 0.37, lr: [0.008765623773281115], Loss: 2.157221, Acc:0.789035, Semantic loss: 0.807861, BCE loss: 0.566166, SB loss: 0.783195
2023-10-30 02:21:33,080 Epoch: [65/484] Iter:[460/495], Time: 0.37, lr: [0.008765242575414132], Loss: 2.158904, Acc:0.789427, Semantic loss: 0.808324, BCE loss: 0.566870, SB loss: 0.783710
2023-10-30 02:21:36,740 Epoch: [65/484] Iter:[470/495], Time: 0.37, lr: [0.00876486137570512], Loss: 2.160530, Acc:0.789574, Semantic loss: 0.809685, BCE loss: 0.566019, SB loss: 0.784826
2023-10-30 02:21:40,360 Epoch: [65/484] Iter:[480/495], Time: 0.37, lr: [0.008764480174153981], Loss: 2.159728, Acc:0.789800, Semantic loss: 0.808883, BCE loss: 0.565433, SB loss: 0.785411
2023-10-30 02:21:43,960 Epoch: [65/484] Iter:[490/495], Time: 0.37, lr: [0.008764098970760616], Loss: 2.157260, Acc:0.790131, Semantic loss: 0.807783, BCE loss: 0.564832, SB loss: 0.784644
2023-10-30 02:24:40,337 0 [9.35592802e-01 6.37289314e-01 8.10317709e-01 1.25242953e-01
 2.21841266e-01 4.08250292e-01 4.48250471e-01 5.63835917e-01
 8.79951297e-01 4.16958110e-01 8.05279575e-01 6.06582101e-01
 2.01058575e-03 8.02393119e-01 1.08574293e-06 5.31558187e-02
 3.21756481e-02 1.49071508e-02 5.73070560e-01] 0.43879504087008764
2023-10-30 02:24:40,337 1 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603] 0.6680557233808051
2023-10-30 02:24:40,341 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:24:40,578 Loss: 2.073, MeanIU:  0.6681, Best_mIoU:  0.6736
2023-10-30 02:24:40,578 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603]
2023-10-30 02:24:42,786 Epoch: [66/484] Iter:[0/495], Time: 2.17, lr: [0.008763908368373067], Loss: 2.114048, Acc:0.785929, Semantic loss: 0.867105, BCE loss: 0.370348, SB loss: 0.876596
2023-10-30 02:24:46,642 Epoch: [66/484] Iter:[10/495], Time: 0.55, lr: [0.008763527162216182], Loss: 2.085699, Acc:0.769813, Semantic loss: 0.796505, BCE loss: 0.497541, SB loss: 0.791653
2023-10-30 02:24:50,196 Epoch: [66/484] Iter:[20/495], Time: 0.46, lr: [0.008763145954216825], Loss: 2.069805, Acc:0.778570, Semantic loss: 0.782733, BCE loss: 0.518940, SB loss: 0.768132
2023-10-30 02:24:53,712 Epoch: [66/484] Iter:[30/495], Time: 0.42, lr: [0.0087627647443749], Loss: 2.116315, Acc:0.785682, Semantic loss: 0.808670, BCE loss: 0.528565, SB loss: 0.779080
2023-10-30 02:24:57,199 Epoch: [66/484] Iter:[40/495], Time: 0.40, lr: [0.00876238353269031], Loss: 2.093013, Acc:0.777511, Semantic loss: 0.792657, BCE loss: 0.527364, SB loss: 0.772992
2023-10-30 02:25:00,730 Epoch: [66/484] Iter:[50/495], Time: 0.39, lr: [0.008762002319162954], Loss: 2.083705, Acc:0.780598, Semantic loss: 0.785245, BCE loss: 0.527709, SB loss: 0.770752
2023-10-30 02:25:04,298 Epoch: [66/484] Iter:[60/495], Time: 0.39, lr: [0.008761621103792739], Loss: 2.103783, Acc:0.781880, Semantic loss: 0.786746, BCE loss: 0.546426, SB loss: 0.770611
2023-10-30 02:25:07,821 Epoch: [66/484] Iter:[70/495], Time: 0.38, lr: [0.00876123988657956], Loss: 2.114587, Acc:0.782317, Semantic loss: 0.789797, BCE loss: 0.553636, SB loss: 0.771153
2023-10-30 02:25:11,434 Epoch: [66/484] Iter:[80/495], Time: 0.38, lr: [0.008760858667523326], Loss: 2.112400, Acc:0.781545, Semantic loss: 0.789982, BCE loss: 0.553068, SB loss: 0.769350
2023-10-30 02:25:15,146 Epoch: [66/484] Iter:[90/495], Time: 0.38, lr: [0.008760477446623935], Loss: 2.129624, Acc:0.783421, Semantic loss: 0.799033, BCE loss: 0.561177, SB loss: 0.769414
2023-10-30 02:25:18,852 Epoch: [66/484] Iter:[100/495], Time: 0.38, lr: [0.008760096223881289], Loss: 2.119308, Acc:0.789946, Semantic loss: 0.786563, BCE loss: 0.562898, SB loss: 0.769848
2023-10-30 02:25:22,439 Epoch: [66/484] Iter:[110/495], Time: 0.38, lr: [0.008759714999295292], Loss: 2.123233, Acc:0.789754, Semantic loss: 0.789780, BCE loss: 0.562769, SB loss: 0.770684
2023-10-30 02:25:26,092 Epoch: [66/484] Iter:[120/495], Time: 0.38, lr: [0.008759333772865844], Loss: 2.131804, Acc:0.790514, Semantic loss: 0.802571, BCE loss: 0.555646, SB loss: 0.773587
2023-10-30 02:25:29,805 Epoch: [66/484] Iter:[130/495], Time: 0.38, lr: [0.008758952544592849], Loss: 2.128616, Acc:0.791981, Semantic loss: 0.799646, BCE loss: 0.556844, SB loss: 0.772126
2023-10-30 02:25:33,398 Epoch: [66/484] Iter:[140/495], Time: 0.37, lr: [0.008758571314476205], Loss: 2.133478, Acc:0.792897, Semantic loss: 0.800852, BCE loss: 0.558773, SB loss: 0.773853
2023-10-30 02:25:36,992 Epoch: [66/484] Iter:[150/495], Time: 0.37, lr: [0.00875819008251582], Loss: 2.117439, Acc:0.793408, Semantic loss: 0.792342, BCE loss: 0.554703, SB loss: 0.770394
2023-10-30 02:25:40,504 Epoch: [66/484] Iter:[160/495], Time: 0.37, lr: [0.00875780884871159], Loss: 2.111355, Acc:0.796075, Semantic loss: 0.790581, BCE loss: 0.551696, SB loss: 0.769079
2023-10-30 02:25:44,120 Epoch: [66/484] Iter:[170/495], Time: 0.37, lr: [0.00875742761306342], Loss: 2.113916, Acc:0.796008, Semantic loss: 0.795402, BCE loss: 0.551118, SB loss: 0.767395
2023-10-30 02:25:47,824 Epoch: [66/484] Iter:[180/495], Time: 0.37, lr: [0.00875704637557121], Loss: 2.104555, Acc:0.794821, Semantic loss: 0.789968, BCE loss: 0.548454, SB loss: 0.766134
2023-10-30 02:25:51,458 Epoch: [66/484] Iter:[190/495], Time: 0.37, lr: [0.008756665136234866], Loss: 2.107172, Acc:0.797264, Semantic loss: 0.789652, BCE loss: 0.551960, SB loss: 0.765559
2023-10-30 02:25:55,086 Epoch: [66/484] Iter:[200/495], Time: 0.37, lr: [0.008756283895054284], Loss: 2.107184, Acc:0.795991, Semantic loss: 0.790855, BCE loss: 0.550450, SB loss: 0.765879
2023-10-30 02:25:58,763 Epoch: [66/484] Iter:[210/495], Time: 0.37, lr: [0.008755902652029371], Loss: 2.108692, Acc:0.795431, Semantic loss: 0.792562, BCE loss: 0.552507, SB loss: 0.763623
2023-10-30 02:26:02,324 Epoch: [66/484] Iter:[220/495], Time: 0.37, lr: [0.008755521407160025], Loss: 2.105211, Acc:0.795739, Semantic loss: 0.789550, BCE loss: 0.552301, SB loss: 0.763360
2023-10-30 02:26:05,976 Epoch: [66/484] Iter:[230/495], Time: 0.37, lr: [0.008755140160446151], Loss: 2.105160, Acc:0.793819, Semantic loss: 0.792282, BCE loss: 0.549593, SB loss: 0.763286
2023-10-30 02:26:09,593 Epoch: [66/484] Iter:[240/495], Time: 0.37, lr: [0.008754758911887648], Loss: 2.116918, Acc:0.791761, Semantic loss: 0.798322, BCE loss: 0.550492, SB loss: 0.768104
2023-10-30 02:26:13,250 Epoch: [66/484] Iter:[250/495], Time: 0.37, lr: [0.00875437766148442], Loss: 2.124862, Acc:0.791851, Semantic loss: 0.802358, BCE loss: 0.552884, SB loss: 0.769619
2023-10-30 02:26:16,906 Epoch: [66/484] Iter:[260/495], Time: 0.37, lr: [0.008753996409236369], Loss: 2.123019, Acc:0.791352, Semantic loss: 0.799213, BCE loss: 0.555083, SB loss: 0.768724
2023-10-30 02:26:20,549 Epoch: [66/484] Iter:[270/495], Time: 0.37, lr: [0.008753615155143396], Loss: 2.123996, Acc:0.791975, Semantic loss: 0.798145, BCE loss: 0.556549, SB loss: 0.769302
2023-10-30 02:26:24,330 Epoch: [66/484] Iter:[280/495], Time: 0.37, lr: [0.0087532338992054], Loss: 2.126468, Acc:0.790908, Semantic loss: 0.798523, BCE loss: 0.558219, SB loss: 0.769726
2023-10-30 02:26:28,024 Epoch: [66/484] Iter:[290/495], Time: 0.37, lr: [0.008752852641422289], Loss: 2.130590, Acc:0.791279, Semantic loss: 0.799621, BCE loss: 0.559189, SB loss: 0.771780
2023-10-30 02:26:31,689 Epoch: [66/484] Iter:[300/495], Time: 0.37, lr: [0.008752471381793957], Loss: 2.131648, Acc:0.790785, Semantic loss: 0.801251, BCE loss: 0.557829, SB loss: 0.772568
2023-10-30 02:26:35,374 Epoch: [66/484] Iter:[310/495], Time: 0.37, lr: [0.008752090120320313], Loss: 2.130956, Acc:0.789521, Semantic loss: 0.800617, BCE loss: 0.557501, SB loss: 0.772839
2023-10-30 02:26:39,049 Epoch: [66/484] Iter:[320/495], Time: 0.37, lr: [0.008751708857001255], Loss: 2.126923, Acc:0.788992, Semantic loss: 0.799396, BCE loss: 0.555084, SB loss: 0.772443
2023-10-30 02:26:42,746 Epoch: [66/484] Iter:[330/495], Time: 0.37, lr: [0.008751327591836684], Loss: 2.125114, Acc:0.789590, Semantic loss: 0.797580, BCE loss: 0.555493, SB loss: 0.772042
2023-10-30 02:26:46,445 Epoch: [66/484] Iter:[340/495], Time: 0.37, lr: [0.008750946324826505], Loss: 2.128268, Acc:0.789244, Semantic loss: 0.798602, BCE loss: 0.556960, SB loss: 0.772706
2023-10-30 02:26:50,077 Epoch: [66/484] Iter:[350/495], Time: 0.37, lr: [0.008750565055970617], Loss: 2.128742, Acc:0.789326, Semantic loss: 0.800249, BCE loss: 0.555435, SB loss: 0.773058
2023-10-30 02:26:53,787 Epoch: [66/484] Iter:[360/495], Time: 0.37, lr: [0.008750183785268923], Loss: 2.129448, Acc:0.789387, Semantic loss: 0.799179, BCE loss: 0.556275, SB loss: 0.773994
2023-10-30 02:26:57,421 Epoch: [66/484] Iter:[370/495], Time: 0.37, lr: [0.008749802512721323], Loss: 2.128567, Acc:0.789860, Semantic loss: 0.798386, BCE loss: 0.556554, SB loss: 0.773628
2023-10-30 02:27:01,173 Epoch: [66/484] Iter:[380/495], Time: 0.37, lr: [0.00874942123832772], Loss: 2.131240, Acc:0.790207, Semantic loss: 0.798861, BCE loss: 0.558822, SB loss: 0.773557
2023-10-30 02:27:04,810 Epoch: [66/484] Iter:[390/495], Time: 0.37, lr: [0.008749039962088017], Loss: 2.135671, Acc:0.789350, Semantic loss: 0.801259, BCE loss: 0.560187, SB loss: 0.774225
2023-10-30 02:27:08,505 Epoch: [66/484] Iter:[400/495], Time: 0.37, lr: [0.008748658684002113], Loss: 2.138426, Acc:0.789764, Semantic loss: 0.802184, BCE loss: 0.561353, SB loss: 0.774889
2023-10-30 02:27:12,150 Epoch: [66/484] Iter:[410/495], Time: 0.37, lr: [0.008748277404069912], Loss: 2.140597, Acc:0.789827, Semantic loss: 0.803124, BCE loss: 0.561522, SB loss: 0.775950
2023-10-30 02:27:15,858 Epoch: [66/484] Iter:[420/495], Time: 0.37, lr: [0.008747896122291314], Loss: 2.140687, Acc:0.788947, Semantic loss: 0.804475, BCE loss: 0.559418, SB loss: 0.776794
2023-10-30 02:27:19,570 Epoch: [66/484] Iter:[430/495], Time: 0.37, lr: [0.008747514838666221], Loss: 2.142210, Acc:0.788724, Semantic loss: 0.805246, BCE loss: 0.560278, SB loss: 0.776686
2023-10-30 02:27:23,282 Epoch: [66/484] Iter:[440/495], Time: 0.37, lr: [0.008747133553194536], Loss: 2.143393, Acc:0.787842, Semantic loss: 0.805997, BCE loss: 0.560527, SB loss: 0.776869
2023-10-30 02:27:26,950 Epoch: [66/484] Iter:[450/495], Time: 0.37, lr: [0.00874675226587616], Loss: 2.141569, Acc:0.788246, Semantic loss: 0.805154, BCE loss: 0.560210, SB loss: 0.776206
2023-10-30 02:27:30,687 Epoch: [66/484] Iter:[460/495], Time: 0.37, lr: [0.008746370976710991], Loss: 2.139952, Acc:0.788811, Semantic loss: 0.804872, BCE loss: 0.559261, SB loss: 0.775819
2023-10-30 02:27:34,343 Epoch: [66/484] Iter:[470/495], Time: 0.37, lr: [0.008745989685698936], Loss: 2.138155, Acc:0.789134, Semantic loss: 0.803753, BCE loss: 0.558200, SB loss: 0.776202
2023-10-30 02:27:38,084 Epoch: [66/484] Iter:[480/495], Time: 0.37, lr: [0.008745608392839894], Loss: 2.136794, Acc:0.789040, Semantic loss: 0.802889, BCE loss: 0.558249, SB loss: 0.775655
2023-10-30 02:27:41,682 Epoch: [66/484] Iter:[490/495], Time: 0.37, lr: [0.008745227098133766], Loss: 2.139918, Acc:0.789510, Semantic loss: 0.804856, BCE loss: 0.559601, SB loss: 0.775461
2023-10-30 02:27:43,083 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:27:43,325 Loss: 2.073, MeanIU:  0.6681, Best_mIoU:  0.6736
2023-10-30 02:27:43,325 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603]
2023-10-30 02:27:45,378 Epoch: [67/484] Iter:[0/495], Time: 2.02, lr: [0.008745036450088015], Loss: 2.096799, Acc:0.619313, Semantic loss: 0.694650, BCE loss: 0.605363, SB loss: 0.796786
2023-10-30 02:27:49,385 Epoch: [67/484] Iter:[10/495], Time: 0.55, lr: [0.008744655152611077], Loss: 2.288409, Acc:0.747019, Semantic loss: 0.903434, BCE loss: 0.598953, SB loss: 0.786023
2023-10-30 02:27:53,087 Epoch: [67/484] Iter:[20/495], Time: 0.46, lr: [0.008744273853286806], Loss: 2.189076, Acc:0.765901, Semantic loss: 0.818048, BCE loss: 0.585652, SB loss: 0.785376
2023-10-30 02:27:56,645 Epoch: [67/484] Iter:[30/495], Time: 0.43, lr: [0.008743892552115105], Loss: 2.198263, Acc:0.773892, Semantic loss: 0.830155, BCE loss: 0.576201, SB loss: 0.791907
2023-10-30 02:28:00,321 Epoch: [67/484] Iter:[40/495], Time: 0.41, lr: [0.008743511249095877], Loss: 2.146594, Acc:0.780572, Semantic loss: 0.796962, BCE loss: 0.570198, SB loss: 0.779434
2023-10-30 02:28:03,882 Epoch: [67/484] Iter:[50/495], Time: 0.40, lr: [0.008743129944229022], Loss: 2.163229, Acc:0.784160, Semantic loss: 0.810229, BCE loss: 0.570331, SB loss: 0.782670
2023-10-30 02:28:07,583 Epoch: [67/484] Iter:[60/495], Time: 0.40, lr: [0.008742748637514442], Loss: 2.164412, Acc:0.790528, Semantic loss: 0.806160, BCE loss: 0.576738, SB loss: 0.781514
2023-10-30 02:28:11,221 Epoch: [67/484] Iter:[70/495], Time: 0.39, lr: [0.008742367328952038], Loss: 2.141826, Acc:0.794777, Semantic loss: 0.788709, BCE loss: 0.580897, SB loss: 0.772220
2023-10-30 02:28:14,869 Epoch: [67/484] Iter:[80/495], Time: 0.39, lr: [0.008741986018541712], Loss: 2.154402, Acc:0.793187, Semantic loss: 0.793366, BCE loss: 0.584354, SB loss: 0.776683
2023-10-30 02:28:18,508 Epoch: [67/484] Iter:[90/495], Time: 0.39, lr: [0.008741604706283365], Loss: 2.159638, Acc:0.792370, Semantic loss: 0.802368, BCE loss: 0.580957, SB loss: 0.776313
2023-10-30 02:28:22,115 Epoch: [67/484] Iter:[100/495], Time: 0.38, lr: [0.0087412233921769], Loss: 2.151823, Acc:0.792034, Semantic loss: 0.794076, BCE loss: 0.583911, SB loss: 0.773836
2023-10-30 02:28:25,832 Epoch: [67/484] Iter:[110/495], Time: 0.38, lr: [0.008740842076222218], Loss: 2.141318, Acc:0.790120, Semantic loss: 0.791541, BCE loss: 0.575132, SB loss: 0.774645
2023-10-30 02:28:29,484 Epoch: [67/484] Iter:[120/495], Time: 0.38, lr: [0.008740460758419217], Loss: 2.157820, Acc:0.791637, Semantic loss: 0.799228, BCE loss: 0.577097, SB loss: 0.781495
2023-10-30 02:28:33,088 Epoch: [67/484] Iter:[130/495], Time: 0.38, lr: [0.008740079438767803], Loss: 2.147346, Acc:0.792095, Semantic loss: 0.796224, BCE loss: 0.572811, SB loss: 0.778312
2023-10-30 02:28:36,627 Epoch: [67/484] Iter:[140/495], Time: 0.38, lr: [0.008739698117267875], Loss: 2.136451, Acc:0.791782, Semantic loss: 0.792741, BCE loss: 0.567727, SB loss: 0.775983
2023-10-30 02:28:40,407 Epoch: [67/484] Iter:[150/495], Time: 0.38, lr: [0.008739316793919333], Loss: 2.141688, Acc:0.792780, Semantic loss: 0.795629, BCE loss: 0.570928, SB loss: 0.775132
2023-10-30 02:28:44,003 Epoch: [67/484] Iter:[160/495], Time: 0.38, lr: [0.008738935468722085], Loss: 2.145992, Acc:0.793345, Semantic loss: 0.798529, BCE loss: 0.572004, SB loss: 0.775459
2023-10-30 02:28:47,668 Epoch: [67/484] Iter:[170/495], Time: 0.38, lr: [0.008738554141676026], Loss: 2.145538, Acc:0.792942, Semantic loss: 0.799582, BCE loss: 0.570336, SB loss: 0.775620
2023-10-30 02:28:51,382 Epoch: [67/484] Iter:[180/495], Time: 0.38, lr: [0.008738172812781058], Loss: 2.137244, Acc:0.791038, Semantic loss: 0.794765, BCE loss: 0.569409, SB loss: 0.773071
2023-10-30 02:28:55,041 Epoch: [67/484] Iter:[190/495], Time: 0.38, lr: [0.008737791482037086], Loss: 2.130637, Acc:0.790824, Semantic loss: 0.790271, BCE loss: 0.568857, SB loss: 0.771509
2023-10-30 02:28:58,698 Epoch: [67/484] Iter:[200/495], Time: 0.37, lr: [0.008737410149444007], Loss: 2.125240, Acc:0.791177, Semantic loss: 0.789107, BCE loss: 0.565965, SB loss: 0.770168
2023-10-30 02:29:02,282 Epoch: [67/484] Iter:[210/495], Time: 0.37, lr: [0.008737028815001725], Loss: 2.125246, Acc:0.792136, Semantic loss: 0.788499, BCE loss: 0.566535, SB loss: 0.770212
2023-10-30 02:29:05,949 Epoch: [67/484] Iter:[220/495], Time: 0.37, lr: [0.008736647478710141], Loss: 2.131564, Acc:0.791410, Semantic loss: 0.794609, BCE loss: 0.565430, SB loss: 0.771525
2023-10-30 02:29:09,695 Epoch: [67/484] Iter:[230/495], Time: 0.37, lr: [0.008736266140569156], Loss: 2.137234, Acc:0.791308, Semantic loss: 0.796116, BCE loss: 0.567335, SB loss: 0.773783
2023-10-30 02:29:13,336 Epoch: [67/484] Iter:[240/495], Time: 0.37, lr: [0.008735884800578672], Loss: 2.128583, Acc:0.792515, Semantic loss: 0.791233, BCE loss: 0.565484, SB loss: 0.771866
2023-10-30 02:29:17,001 Epoch: [67/484] Iter:[250/495], Time: 0.37, lr: [0.00873550345873859], Loss: 2.133368, Acc:0.792323, Semantic loss: 0.793614, BCE loss: 0.566985, SB loss: 0.772769
2023-10-30 02:29:20,729 Epoch: [67/484] Iter:[260/495], Time: 0.37, lr: [0.00873512211504881], Loss: 2.132580, Acc:0.792208, Semantic loss: 0.792836, BCE loss: 0.567216, SB loss: 0.772527
2023-10-30 02:29:24,331 Epoch: [67/484] Iter:[270/495], Time: 0.37, lr: [0.008734740769509235], Loss: 2.127768, Acc:0.792748, Semantic loss: 0.791639, BCE loss: 0.565098, SB loss: 0.771031
2023-10-30 02:29:28,008 Epoch: [67/484] Iter:[280/495], Time: 0.37, lr: [0.008734359422119765], Loss: 2.125704, Acc:0.791528, Semantic loss: 0.792841, BCE loss: 0.562664, SB loss: 0.770199
2023-10-30 02:29:31,707 Epoch: [67/484] Iter:[290/495], Time: 0.37, lr: [0.008733978072880302], Loss: 2.120794, Acc:0.790874, Semantic loss: 0.790919, BCE loss: 0.561661, SB loss: 0.768214
2023-10-30 02:29:35,390 Epoch: [67/484] Iter:[300/495], Time: 0.37, lr: [0.008733596721790748], Loss: 2.120371, Acc:0.791221, Semantic loss: 0.790547, BCE loss: 0.561661, SB loss: 0.768164
2023-10-30 02:29:39,062 Epoch: [67/484] Iter:[310/495], Time: 0.37, lr: [0.008733215368851003], Loss: 2.121698, Acc:0.791298, Semantic loss: 0.791920, BCE loss: 0.561577, SB loss: 0.768201
2023-10-30 02:29:42,641 Epoch: [67/484] Iter:[320/495], Time: 0.37, lr: [0.008732834014060968], Loss: 2.120771, Acc:0.791327, Semantic loss: 0.790733, BCE loss: 0.561427, SB loss: 0.768611
2023-10-30 02:29:46,291 Epoch: [67/484] Iter:[330/495], Time: 0.37, lr: [0.008732452657420547], Loss: 2.120141, Acc:0.791178, Semantic loss: 0.789694, BCE loss: 0.561520, SB loss: 0.768927
2023-10-30 02:29:49,936 Epoch: [67/484] Iter:[340/495], Time: 0.37, lr: [0.008732071298929637], Loss: 2.121359, Acc:0.790834, Semantic loss: 0.792518, BCE loss: 0.560815, SB loss: 0.768027
2023-10-30 02:29:53,639 Epoch: [67/484] Iter:[350/495], Time: 0.37, lr: [0.008731689938588144], Loss: 2.125710, Acc:0.791427, Semantic loss: 0.795062, BCE loss: 0.561062, SB loss: 0.769587
2023-10-30 02:29:57,301 Epoch: [67/484] Iter:[360/495], Time: 0.37, lr: [0.008731308576395964], Loss: 2.125789, Acc:0.791336, Semantic loss: 0.794287, BCE loss: 0.561912, SB loss: 0.769589
2023-10-30 02:30:00,989 Epoch: [67/484] Iter:[370/495], Time: 0.37, lr: [0.008730927212353003], Loss: 2.128918, Acc:0.791732, Semantic loss: 0.795107, BCE loss: 0.563330, SB loss: 0.770481
2023-10-30 02:30:04,618 Epoch: [67/484] Iter:[380/495], Time: 0.37, lr: [0.008730545846459159], Loss: 2.127991, Acc:0.791968, Semantic loss: 0.794242, BCE loss: 0.563483, SB loss: 0.770267
2023-10-30 02:30:08,325 Epoch: [67/484] Iter:[390/495], Time: 0.37, lr: [0.008730164478714334], Loss: 2.123167, Acc:0.792085, Semantic loss: 0.792273, BCE loss: 0.562037, SB loss: 0.768857
2023-10-30 02:30:11,905 Epoch: [67/484] Iter:[400/495], Time: 0.37, lr: [0.00872978310911843], Loss: 2.122931, Acc:0.791847, Semantic loss: 0.792729, BCE loss: 0.560854, SB loss: 0.769348
2023-10-30 02:30:15,616 Epoch: [67/484] Iter:[410/495], Time: 0.37, lr: [0.008729401737671347], Loss: 2.120082, Acc:0.792456, Semantic loss: 0.791743, BCE loss: 0.560025, SB loss: 0.768314
2023-10-30 02:30:19,240 Epoch: [67/484] Iter:[420/495], Time: 0.37, lr: [0.008729020364372989], Loss: 2.122139, Acc:0.793022, Semantic loss: 0.791942, BCE loss: 0.560244, SB loss: 0.769953
2023-10-30 02:30:22,837 Epoch: [67/484] Iter:[430/495], Time: 0.37, lr: [0.008728638989223252], Loss: 2.122505, Acc:0.792098, Semantic loss: 0.793305, BCE loss: 0.558379, SB loss: 0.770821
2023-10-30 02:30:26,483 Epoch: [67/484] Iter:[440/495], Time: 0.37, lr: [0.00872825761222204], Loss: 2.119355, Acc:0.792760, Semantic loss: 0.792100, BCE loss: 0.556943, SB loss: 0.770313
2023-10-30 02:30:30,170 Epoch: [67/484] Iter:[450/495], Time: 0.37, lr: [0.008727876233369257], Loss: 2.125045, Acc:0.792305, Semantic loss: 0.796028, BCE loss: 0.556930, SB loss: 0.772087
2023-10-30 02:30:33,836 Epoch: [67/484] Iter:[460/495], Time: 0.37, lr: [0.008727494852664799], Loss: 2.125342, Acc:0.793217, Semantic loss: 0.796182, BCE loss: 0.556860, SB loss: 0.772300
2023-10-30 02:30:37,592 Epoch: [67/484] Iter:[470/495], Time: 0.37, lr: [0.008727113470108568], Loss: 2.125076, Acc:0.793269, Semantic loss: 0.794968, BCE loss: 0.558412, SB loss: 0.771697
2023-10-30 02:30:41,263 Epoch: [67/484] Iter:[480/495], Time: 0.37, lr: [0.00872673208570047], Loss: 2.124962, Acc:0.793845, Semantic loss: 0.794560, BCE loss: 0.559075, SB loss: 0.771327
2023-10-30 02:30:44,777 Epoch: [67/484] Iter:[490/495], Time: 0.37, lr: [0.0087263506994404], Loss: 2.123596, Acc:0.793598, Semantic loss: 0.794304, BCE loss: 0.557975, SB loss: 0.771317
2023-10-30 02:30:46,187 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:30:46,420 Loss: 2.073, MeanIU:  0.6681, Best_mIoU:  0.6736
2023-10-30 02:30:46,420 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603]
2023-10-30 02:30:48,324 Epoch: [68/484] Iter:[0/495], Time: 1.87, lr: [0.008726160005615846], Loss: 2.252235, Acc:0.792932, Semantic loss: 0.942664, BCE loss: 0.563166, SB loss: 0.746406
2023-10-30 02:30:52,269 Epoch: [68/484] Iter:[10/495], Time: 0.53, lr: [0.008725778616577638], Loss: 2.378217, Acc:0.814798, Semantic loss: 0.991268, BCE loss: 0.553787, SB loss: 0.833163
2023-10-30 02:30:55,834 Epoch: [68/484] Iter:[20/495], Time: 0.45, lr: [0.008725397225687211], Loss: 2.180673, Acc:0.787273, Semantic loss: 0.874460, BCE loss: 0.520394, SB loss: 0.785819
2023-10-30 02:30:59,438 Epoch: [68/484] Iter:[30/495], Time: 0.42, lr: [0.00872501583294447], Loss: 2.178814, Acc:0.789855, Semantic loss: 0.866248, BCE loss: 0.532149, SB loss: 0.780418
2023-10-30 02:31:03,129 Epoch: [68/484] Iter:[40/495], Time: 0.41, lr: [0.008724634438349314], Loss: 2.249887, Acc:0.782644, Semantic loss: 0.914172, BCE loss: 0.531047, SB loss: 0.804668
2023-10-30 02:31:06,875 Epoch: [68/484] Iter:[50/495], Time: 0.40, lr: [0.008724253041901643], Loss: 2.252931, Acc:0.779199, Semantic loss: 0.903923, BCE loss: 0.537075, SB loss: 0.811933
2023-10-30 02:31:10,510 Epoch: [68/484] Iter:[60/495], Time: 0.39, lr: [0.008723871643601359], Loss: 2.269181, Acc:0.773814, Semantic loss: 0.898014, BCE loss: 0.550780, SB loss: 0.820387
2023-10-30 02:31:14,234 Epoch: [68/484] Iter:[70/495], Time: 0.39, lr: [0.008723490243448366], Loss: 2.240147, Acc:0.776921, Semantic loss: 0.872846, BCE loss: 0.551099, SB loss: 0.816202
2023-10-30 02:31:17,878 Epoch: [68/484] Iter:[80/495], Time: 0.39, lr: [0.00872310884144256], Loss: 2.244301, Acc:0.781022, Semantic loss: 0.870792, BCE loss: 0.558040, SB loss: 0.815469
2023-10-30 02:31:21,558 Epoch: [68/484] Iter:[90/495], Time: 0.39, lr: [0.008722727437583847], Loss: 2.213116, Acc:0.780280, Semantic loss: 0.851777, BCE loss: 0.556903, SB loss: 0.804436
2023-10-30 02:31:25,121 Epoch: [68/484] Iter:[100/495], Time: 0.38, lr: [0.008722346031872122], Loss: 2.207672, Acc:0.779376, Semantic loss: 0.847208, BCE loss: 0.557369, SB loss: 0.803096
2023-10-30 02:31:28,753 Epoch: [68/484] Iter:[110/495], Time: 0.38, lr: [0.008721964624307292], Loss: 2.204250, Acc:0.784270, Semantic loss: 0.842948, BCE loss: 0.562243, SB loss: 0.799059
2023-10-30 02:31:32,432 Epoch: [68/484] Iter:[120/495], Time: 0.38, lr: [0.008721583214889254], Loss: 2.193677, Acc:0.786340, Semantic loss: 0.834794, BCE loss: 0.560477, SB loss: 0.798406
2023-10-30 02:31:36,117 Epoch: [68/484] Iter:[130/495], Time: 0.38, lr: [0.008721201803617908], Loss: 2.191718, Acc:0.786611, Semantic loss: 0.834487, BCE loss: 0.561639, SB loss: 0.795593
2023-10-30 02:31:39,820 Epoch: [68/484] Iter:[140/495], Time: 0.38, lr: [0.008720820390493161], Loss: 2.193774, Acc:0.789777, Semantic loss: 0.834124, BCE loss: 0.565309, SB loss: 0.794341
2023-10-30 02:31:43,570 Epoch: [68/484] Iter:[150/495], Time: 0.38, lr: [0.008720438975514909], Loss: 2.190879, Acc:0.791664, Semantic loss: 0.832110, BCE loss: 0.565685, SB loss: 0.793085
2023-10-30 02:31:47,232 Epoch: [68/484] Iter:[160/495], Time: 0.38, lr: [0.008720057558683053], Loss: 2.179886, Acc:0.790734, Semantic loss: 0.827674, BCE loss: 0.561984, SB loss: 0.790228
2023-10-30 02:31:50,930 Epoch: [68/484] Iter:[170/495], Time: 0.38, lr: [0.008719676139997494], Loss: 2.171302, Acc:0.793017, Semantic loss: 0.820652, BCE loss: 0.564237, SB loss: 0.786412
2023-10-30 02:31:54,561 Epoch: [68/484] Iter:[180/495], Time: 0.38, lr: [0.008719294719458134], Loss: 2.170145, Acc:0.792261, Semantic loss: 0.819719, BCE loss: 0.563781, SB loss: 0.786645
2023-10-30 02:31:58,124 Epoch: [68/484] Iter:[190/495], Time: 0.38, lr: [0.008718913297064876], Loss: 2.165188, Acc:0.793091, Semantic loss: 0.816746, BCE loss: 0.562465, SB loss: 0.785977
2023-10-30 02:32:01,729 Epoch: [68/484] Iter:[200/495], Time: 0.37, lr: [0.008718531872817615], Loss: 2.170311, Acc:0.793902, Semantic loss: 0.819943, BCE loss: 0.565076, SB loss: 0.785291
2023-10-30 02:32:05,450 Epoch: [68/484] Iter:[210/495], Time: 0.37, lr: [0.008718150446716257], Loss: 2.171641, Acc:0.792656, Semantic loss: 0.822542, BCE loss: 0.564357, SB loss: 0.784742
2023-10-30 02:32:09,157 Epoch: [68/484] Iter:[220/495], Time: 0.37, lr: [0.008717769018760702], Loss: 2.167763, Acc:0.792672, Semantic loss: 0.820470, BCE loss: 0.562914, SB loss: 0.784380
2023-10-30 02:32:12,901 Epoch: [68/484] Iter:[230/495], Time: 0.37, lr: [0.00871738758895085], Loss: 2.167557, Acc:0.791973, Semantic loss: 0.821716, BCE loss: 0.562431, SB loss: 0.783410
2023-10-30 02:32:16,610 Epoch: [68/484] Iter:[240/495], Time: 0.37, lr: [0.008717006157286602], Loss: 2.165646, Acc:0.792184, Semantic loss: 0.819854, BCE loss: 0.563181, SB loss: 0.782611
2023-10-30 02:32:20,232 Epoch: [68/484] Iter:[250/495], Time: 0.37, lr: [0.008716624723767857], Loss: 2.170457, Acc:0.791077, Semantic loss: 0.823247, BCE loss: 0.563641, SB loss: 0.783568
2023-10-30 02:32:23,827 Epoch: [68/484] Iter:[260/495], Time: 0.37, lr: [0.008716243288394517], Loss: 2.174957, Acc:0.790107, Semantic loss: 0.826155, BCE loss: 0.564137, SB loss: 0.784664
2023-10-30 02:32:27,557 Epoch: [68/484] Iter:[270/495], Time: 0.37, lr: [0.008715861851166486], Loss: 2.177336, Acc:0.790785, Semantic loss: 0.826418, BCE loss: 0.565951, SB loss: 0.784967
2023-10-30 02:32:31,278 Epoch: [68/484] Iter:[280/495], Time: 0.37, lr: [0.008715480412083662], Loss: 2.177218, Acc:0.790321, Semantic loss: 0.827320, BCE loss: 0.564644, SB loss: 0.785255
2023-10-30 02:32:34,976 Epoch: [68/484] Iter:[290/495], Time: 0.37, lr: [0.008715098971145944], Loss: 2.174548, Acc:0.789598, Semantic loss: 0.825449, BCE loss: 0.564668, SB loss: 0.784431
2023-10-30 02:32:38,704 Epoch: [68/484] Iter:[300/495], Time: 0.37, lr: [0.008714717528353235], Loss: 2.176140, Acc:0.788748, Semantic loss: 0.827245, BCE loss: 0.563291, SB loss: 0.785604
2023-10-30 02:32:42,308 Epoch: [68/484] Iter:[310/495], Time: 0.37, lr: [0.008714336083705436], Loss: 2.169744, Acc:0.789241, Semantic loss: 0.824189, BCE loss: 0.561879, SB loss: 0.783675
2023-10-30 02:32:45,915 Epoch: [68/484] Iter:[320/495], Time: 0.37, lr: [0.008713954637202448], Loss: 2.166578, Acc:0.787328, Semantic loss: 0.823547, BCE loss: 0.559705, SB loss: 0.783326
2023-10-30 02:32:49,568 Epoch: [68/484] Iter:[330/495], Time: 0.37, lr: [0.00871357318884417], Loss: 2.165715, Acc:0.787616, Semantic loss: 0.823289, BCE loss: 0.559627, SB loss: 0.782799
2023-10-30 02:32:53,226 Epoch: [68/484] Iter:[340/495], Time: 0.37, lr: [0.008713191738630503], Loss: 2.164937, Acc:0.787549, Semantic loss: 0.822763, BCE loss: 0.559984, SB loss: 0.782191
2023-10-30 02:32:56,940 Epoch: [68/484] Iter:[350/495], Time: 0.37, lr: [0.008712810286561349], Loss: 2.161322, Acc:0.787363, Semantic loss: 0.820906, BCE loss: 0.559364, SB loss: 0.781053
2023-10-30 02:33:00,630 Epoch: [68/484] Iter:[360/495], Time: 0.37, lr: [0.008712428832636608], Loss: 2.159742, Acc:0.787857, Semantic loss: 0.819042, BCE loss: 0.560047, SB loss: 0.780653
2023-10-30 02:33:04,314 Epoch: [68/484] Iter:[370/495], Time: 0.37, lr: [0.008712047376856182], Loss: 2.158658, Acc:0.787901, Semantic loss: 0.819080, BCE loss: 0.558809, SB loss: 0.780769
2023-10-30 02:33:08,031 Epoch: [68/484] Iter:[380/495], Time: 0.37, lr: [0.00871166591921997], Loss: 2.153983, Acc:0.788492, Semantic loss: 0.816461, BCE loss: 0.557768, SB loss: 0.779754
2023-10-30 02:33:11,680 Epoch: [68/484] Iter:[390/495], Time: 0.37, lr: [0.008711284459727872], Loss: 2.153021, Acc:0.789619, Semantic loss: 0.816387, BCE loss: 0.558077, SB loss: 0.778556
2023-10-30 02:33:15,332 Epoch: [68/484] Iter:[400/495], Time: 0.37, lr: [0.008710902998379792], Loss: 2.156579, Acc:0.789390, Semantic loss: 0.819697, BCE loss: 0.558579, SB loss: 0.778303
2023-10-30 02:33:19,007 Epoch: [68/484] Iter:[410/495], Time: 0.37, lr: [0.008710521535175627], Loss: 2.151825, Acc:0.789783, Semantic loss: 0.816656, BCE loss: 0.557776, SB loss: 0.777393
2023-10-30 02:33:22,721 Epoch: [68/484] Iter:[420/495], Time: 0.37, lr: [0.008710140070115278], Loss: 2.152513, Acc:0.790293, Semantic loss: 0.816128, BCE loss: 0.558388, SB loss: 0.777997
2023-10-30 02:33:26,445 Epoch: [68/484] Iter:[430/495], Time: 0.37, lr: [0.008709758603198649], Loss: 2.154220, Acc:0.790627, Semantic loss: 0.816363, BCE loss: 0.559587, SB loss: 0.778270
2023-10-30 02:33:30,262 Epoch: [68/484] Iter:[440/495], Time: 0.37, lr: [0.008709377134425636], Loss: 2.155596, Acc:0.791021, Semantic loss: 0.818033, BCE loss: 0.558411, SB loss: 0.779152
2023-10-30 02:33:33,918 Epoch: [68/484] Iter:[450/495], Time: 0.37, lr: [0.008708995663796144], Loss: 2.154568, Acc:0.791847, Semantic loss: 0.816612, BCE loss: 0.558627, SB loss: 0.779329
2023-10-30 02:33:37,580 Epoch: [68/484] Iter:[460/495], Time: 0.37, lr: [0.008708614191310072], Loss: 2.155211, Acc:0.791563, Semantic loss: 0.816405, BCE loss: 0.559499, SB loss: 0.779307
2023-10-30 02:33:41,280 Epoch: [68/484] Iter:[470/495], Time: 0.37, lr: [0.008708232716967319], Loss: 2.154254, Acc:0.791680, Semantic loss: 0.814739, BCE loss: 0.560996, SB loss: 0.778519
2023-10-30 02:33:44,977 Epoch: [68/484] Iter:[480/495], Time: 0.37, lr: [0.008707851240767788], Loss: 2.151426, Acc:0.791270, Semantic loss: 0.812743, BCE loss: 0.560701, SB loss: 0.777982
2023-10-30 02:33:48,475 Epoch: [68/484] Iter:[490/495], Time: 0.37, lr: [0.008707469762711377], Loss: 2.150897, Acc:0.791233, Semantic loss: 0.813403, BCE loss: 0.559460, SB loss: 0.778034
2023-10-30 02:33:49,881 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:33:50,119 Loss: 2.073, MeanIU:  0.6681, Best_mIoU:  0.6736
2023-10-30 02:33:50,119 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603]
2023-10-30 02:33:52,108 Epoch: [69/484] Iter:[0/495], Time: 1.95, lr: [0.008707279022986812], Loss: 2.227663, Acc:0.838411, Semantic loss: 0.781497, BCE loss: 0.647397, SB loss: 0.798769
2023-10-30 02:33:56,037 Epoch: [69/484] Iter:[10/495], Time: 0.53, lr: [0.008706897542144898], Loss: 2.017766, Acc:0.804054, Semantic loss: 0.723910, BCE loss: 0.538235, SB loss: 0.755621
2023-10-30 02:33:59,743 Epoch: [69/484] Iter:[20/495], Time: 0.46, lr: [0.008706516059445857], Loss: 2.173859, Acc:0.799374, Semantic loss: 0.824437, BCE loss: 0.551014, SB loss: 0.798408
2023-10-30 02:34:03,373 Epoch: [69/484] Iter:[30/495], Time: 0.43, lr: [0.008706134574889588], Loss: 2.179315, Acc:0.804992, Semantic loss: 0.832542, BCE loss: 0.556180, SB loss: 0.790593
2023-10-30 02:34:07,068 Epoch: [69/484] Iter:[40/495], Time: 0.41, lr: [0.008705753088475996], Loss: 2.165286, Acc:0.798215, Semantic loss: 0.812134, BCE loss: 0.563814, SB loss: 0.789338
2023-10-30 02:34:10,664 Epoch: [69/484] Iter:[50/495], Time: 0.40, lr: [0.008705371600204976], Loss: 2.134833, Acc:0.798814, Semantic loss: 0.797817, BCE loss: 0.554695, SB loss: 0.782321
2023-10-30 02:34:14,313 Epoch: [69/484] Iter:[60/495], Time: 0.40, lr: [0.00870499011007643], Loss: 2.138907, Acc:0.796138, Semantic loss: 0.799507, BCE loss: 0.560847, SB loss: 0.778553
2023-10-30 02:34:18,039 Epoch: [69/484] Iter:[70/495], Time: 0.39, lr: [0.008704608618090262], Loss: 2.140580, Acc:0.795176, Semantic loss: 0.805844, BCE loss: 0.553659, SB loss: 0.781078
2023-10-30 02:34:21,932 Epoch: [69/484] Iter:[80/495], Time: 0.39, lr: [0.008704227124246369], Loss: 2.136938, Acc:0.794670, Semantic loss: 0.806340, BCE loss: 0.549988, SB loss: 0.780610
2023-10-30 02:34:25,596 Epoch: [69/484] Iter:[90/495], Time: 0.39, lr: [0.008703845628544652], Loss: 2.177988, Acc:0.794164, Semantic loss: 0.833009, BCE loss: 0.555831, SB loss: 0.789148
2023-10-30 02:34:29,231 Epoch: [69/484] Iter:[100/495], Time: 0.39, lr: [0.008703464130985012], Loss: 2.202848, Acc:0.786406, Semantic loss: 0.845122, BCE loss: 0.557208, SB loss: 0.800519
2023-10-30 02:34:32,857 Epoch: [69/484] Iter:[110/495], Time: 0.38, lr: [0.00870308263156735], Loss: 2.201268, Acc:0.788984, Semantic loss: 0.840735, BCE loss: 0.560351, SB loss: 0.800182
2023-10-30 02:34:36,599 Epoch: [69/484] Iter:[120/495], Time: 0.38, lr: [0.008702701130291564], Loss: 2.200544, Acc:0.794218, Semantic loss: 0.837461, BCE loss: 0.566908, SB loss: 0.796174
2023-10-30 02:34:40,371 Epoch: [69/484] Iter:[130/495], Time: 0.38, lr: [0.008702319627157559], Loss: 2.188749, Acc:0.796248, Semantic loss: 0.833950, BCE loss: 0.563115, SB loss: 0.791684
2023-10-30 02:34:44,132 Epoch: [69/484] Iter:[140/495], Time: 0.38, lr: [0.008701938122165232], Loss: 2.196706, Acc:0.796669, Semantic loss: 0.837359, BCE loss: 0.566663, SB loss: 0.792684
2023-10-30 02:34:47,836 Epoch: [69/484] Iter:[150/495], Time: 0.38, lr: [0.008701556615314484], Loss: 2.198746, Acc:0.795387, Semantic loss: 0.837576, BCE loss: 0.566942, SB loss: 0.794228
2023-10-30 02:34:51,582 Epoch: [69/484] Iter:[160/495], Time: 0.38, lr: [0.008701175106605214], Loss: 2.201411, Acc:0.791304, Semantic loss: 0.841837, BCE loss: 0.562019, SB loss: 0.797555
2023-10-30 02:34:55,228 Epoch: [69/484] Iter:[170/495], Time: 0.38, lr: [0.008700793596037327], Loss: 2.201649, Acc:0.793393, Semantic loss: 0.841248, BCE loss: 0.565168, SB loss: 0.795234
2023-10-30 02:34:58,830 Epoch: [69/484] Iter:[180/495], Time: 0.38, lr: [0.008700412083610718], Loss: 2.197956, Acc:0.793027, Semantic loss: 0.838214, BCE loss: 0.566753, SB loss: 0.792990
2023-10-30 02:35:02,484 Epoch: [69/484] Iter:[190/495], Time: 0.38, lr: [0.00870003056932529], Loss: 2.192667, Acc:0.793493, Semantic loss: 0.834287, BCE loss: 0.565334, SB loss: 0.793046
2023-10-30 02:35:06,128 Epoch: [69/484] Iter:[200/495], Time: 0.38, lr: [0.008699649053180944], Loss: 2.192462, Acc:0.792825, Semantic loss: 0.833207, BCE loss: 0.565254, SB loss: 0.794001
2023-10-30 02:35:09,839 Epoch: [69/484] Iter:[210/495], Time: 0.38, lr: [0.008699267535177578], Loss: 2.184693, Acc:0.793781, Semantic loss: 0.829261, BCE loss: 0.564100, SB loss: 0.791333
2023-10-30 02:35:13,474 Epoch: [69/484] Iter:[220/495], Time: 0.38, lr: [0.008698886015315096], Loss: 2.179288, Acc:0.792570, Semantic loss: 0.827020, BCE loss: 0.562898, SB loss: 0.789370
2023-10-30 02:35:17,284 Epoch: [69/484] Iter:[230/495], Time: 0.38, lr: [0.008698504493593396], Loss: 2.170215, Acc:0.792414, Semantic loss: 0.823251, BCE loss: 0.559144, SB loss: 0.787819
2023-10-30 02:35:20,972 Epoch: [69/484] Iter:[240/495], Time: 0.38, lr: [0.008698122970012375], Loss: 2.175748, Acc:0.793520, Semantic loss: 0.825750, BCE loss: 0.561762, SB loss: 0.788237
2023-10-30 02:35:24,601 Epoch: [69/484] Iter:[250/495], Time: 0.38, lr: [0.00869774144457194], Loss: 2.170333, Acc:0.792722, Semantic loss: 0.823025, BCE loss: 0.561006, SB loss: 0.786302
2023-10-30 02:35:28,355 Epoch: [69/484] Iter:[260/495], Time: 0.38, lr: [0.008697359917271988], Loss: 2.167376, Acc:0.793267, Semantic loss: 0.822638, BCE loss: 0.559495, SB loss: 0.785243
2023-10-30 02:35:31,971 Epoch: [69/484] Iter:[270/495], Time: 0.38, lr: [0.008696978388112418], Loss: 2.158266, Acc:0.792839, Semantic loss: 0.819391, BCE loss: 0.555822, SB loss: 0.783053
2023-10-30 02:35:35,701 Epoch: [69/484] Iter:[280/495], Time: 0.38, lr: [0.008696596857093133], Loss: 2.155651, Acc:0.792314, Semantic loss: 0.819641, BCE loss: 0.552356, SB loss: 0.783655
2023-10-30 02:35:39,530 Epoch: [69/484] Iter:[290/495], Time: 0.38, lr: [0.008696215324214033], Loss: 2.160363, Acc:0.791169, Semantic loss: 0.823453, BCE loss: 0.551910, SB loss: 0.785001
2023-10-30 02:35:43,184 Epoch: [69/484] Iter:[300/495], Time: 0.38, lr: [0.008695833789475017], Loss: 2.161890, Acc:0.790681, Semantic loss: 0.823361, BCE loss: 0.551102, SB loss: 0.787426
2023-10-30 02:35:46,916 Epoch: [69/484] Iter:[310/495], Time: 0.38, lr: [0.008695452252875983], Loss: 2.162302, Acc:0.790999, Semantic loss: 0.822827, BCE loss: 0.550688, SB loss: 0.788787
2023-10-30 02:35:50,627 Epoch: [69/484] Iter:[320/495], Time: 0.38, lr: [0.008695070714416836], Loss: 2.160611, Acc:0.791157, Semantic loss: 0.821684, BCE loss: 0.549509, SB loss: 0.789417
2023-10-30 02:35:54,312 Epoch: [69/484] Iter:[330/495], Time: 0.38, lr: [0.008694689174097473], Loss: 2.161882, Acc:0.791460, Semantic loss: 0.822324, BCE loss: 0.550391, SB loss: 0.789168
2023-10-30 02:35:57,986 Epoch: [69/484] Iter:[340/495], Time: 0.37, lr: [0.008694307631917794], Loss: 2.164629, Acc:0.791626, Semantic loss: 0.823988, BCE loss: 0.550926, SB loss: 0.789715
2023-10-30 02:36:01,792 Epoch: [69/484] Iter:[350/495], Time: 0.38, lr: [0.008693926087877705], Loss: 2.160468, Acc:0.791602, Semantic loss: 0.821549, BCE loss: 0.550117, SB loss: 0.788802
2023-10-30 02:36:05,352 Epoch: [69/484] Iter:[360/495], Time: 0.37, lr: [0.008693544541977098], Loss: 2.161114, Acc:0.790095, Semantic loss: 0.822600, BCE loss: 0.550012, SB loss: 0.788501
2023-10-30 02:36:09,043 Epoch: [69/484] Iter:[370/495], Time: 0.37, lr: [0.008693162994215877], Loss: 2.158677, Acc:0.790389, Semantic loss: 0.820180, BCE loss: 0.551051, SB loss: 0.787446
2023-10-30 02:36:12,786 Epoch: [69/484] Iter:[380/495], Time: 0.37, lr: [0.008692781444593943], Loss: 2.158076, Acc:0.790062, Semantic loss: 0.819901, BCE loss: 0.551514, SB loss: 0.786661
2023-10-30 02:36:16,529 Epoch: [69/484] Iter:[390/495], Time: 0.37, lr: [0.008692399893111196], Loss: 2.155868, Acc:0.790510, Semantic loss: 0.818355, BCE loss: 0.551872, SB loss: 0.785641
2023-10-30 02:36:20,166 Epoch: [69/484] Iter:[400/495], Time: 0.37, lr: [0.008692018339767535], Loss: 2.156785, Acc:0.789890, Semantic loss: 0.818908, BCE loss: 0.551856, SB loss: 0.786020
2023-10-30 02:36:23,871 Epoch: [69/484] Iter:[410/495], Time: 0.37, lr: [0.00869163678456286], Loss: 2.160450, Acc:0.790834, Semantic loss: 0.819337, BCE loss: 0.555573, SB loss: 0.785540
2023-10-30 02:36:27,606 Epoch: [69/484] Iter:[420/495], Time: 0.37, lr: [0.008691255227497072], Loss: 2.163504, Acc:0.791569, Semantic loss: 0.820238, BCE loss: 0.557533, SB loss: 0.785733
2023-10-30 02:36:31,235 Epoch: [69/484] Iter:[430/495], Time: 0.37, lr: [0.008690873668570069], Loss: 2.162508, Acc:0.791357, Semantic loss: 0.818227, BCE loss: 0.559203, SB loss: 0.785078
2023-10-30 02:36:34,972 Epoch: [69/484] Iter:[440/495], Time: 0.37, lr: [0.008690492107781755], Loss: 2.165814, Acc:0.792073, Semantic loss: 0.818215, BCE loss: 0.561758, SB loss: 0.785841
2023-10-30 02:36:38,662 Epoch: [69/484] Iter:[450/495], Time: 0.37, lr: [0.008690110545132029], Loss: 2.171037, Acc:0.791830, Semantic loss: 0.822671, BCE loss: 0.561882, SB loss: 0.786484
2023-10-30 02:36:42,363 Epoch: [69/484] Iter:[460/495], Time: 0.37, lr: [0.008689728980620788], Loss: 2.172585, Acc:0.791569, Semantic loss: 0.823362, BCE loss: 0.562502, SB loss: 0.786721
2023-10-30 02:36:46,054 Epoch: [69/484] Iter:[470/495], Time: 0.37, lr: [0.008689347414247936], Loss: 2.167729, Acc:0.791725, Semantic loss: 0.821361, BCE loss: 0.560987, SB loss: 0.785381
2023-10-30 02:36:49,811 Epoch: [69/484] Iter:[480/495], Time: 0.37, lr: [0.008688965846013372], Loss: 2.167742, Acc:0.791424, Semantic loss: 0.821699, BCE loss: 0.560617, SB loss: 0.785425
2023-10-30 02:36:53,350 Epoch: [69/484] Iter:[490/495], Time: 0.37, lr: [0.008688584275916995], Loss: 2.168984, Acc:0.791910, Semantic loss: 0.822146, BCE loss: 0.561569, SB loss: 0.785270
2023-10-30 02:36:54,754 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:36:54,987 Loss: 2.073, MeanIU:  0.6681, Best_mIoU:  0.6736
2023-10-30 02:36:54,987 [0.9737005  0.8009796  0.89735757 0.42285625 0.43728604 0.5733715
 0.65495614 0.72813624 0.90706096 0.50159349 0.91913244 0.75736999
 0.42457691 0.9230632  0.52581793 0.59441959 0.55004352 0.40825086
 0.69308603]
2023-10-30 02:36:56,962 Epoch: [70/484] Iter:[0/495], Time: 1.94, lr: [0.008688393490170594], Loss: 1.684643, Acc:0.852546, Semantic loss: 0.562066, BCE loss: 0.430986, SB loss: 0.691592
2023-10-30 02:37:01,023 Epoch: [70/484] Iter:[10/495], Time: 0.55, lr: [0.00868801191728131], Loss: 2.162812, Acc:0.805989, Semantic loss: 0.834701, BCE loss: 0.558620, SB loss: 0.769490
2023-10-30 02:37:04,749 Epoch: [70/484] Iter:[20/495], Time: 0.46, lr: [0.008687630342529964], Loss: 2.170096, Acc:0.801693, Semantic loss: 0.824475, BCE loss: 0.570869, SB loss: 0.774752
2023-10-30 02:37:08,438 Epoch: [70/484] Iter:[30/495], Time: 0.43, lr: [0.008687248765916455], Loss: 2.156738, Acc:0.789295, Semantic loss: 0.823094, BCE loss: 0.560708, SB loss: 0.772935
2023-10-30 02:37:12,024 Epoch: [70/484] Iter:[40/495], Time: 0.41, lr: [0.008686867187440685], Loss: 2.149603, Acc:0.796145, Semantic loss: 0.802302, BCE loss: 0.572462, SB loss: 0.774839
2023-10-30 02:37:15,585 Epoch: [70/484] Iter:[50/495], Time: 0.40, lr: [0.008686485607102553], Loss: 2.158754, Acc:0.783368, Semantic loss: 0.802479, BCE loss: 0.572764, SB loss: 0.783511
2023-10-30 02:37:19,219 Epoch: [70/484] Iter:[60/495], Time: 0.40, lr: [0.008686104024901956], Loss: 2.154878, Acc:0.787421, Semantic loss: 0.797518, BCE loss: 0.574641, SB loss: 0.782719
2023-10-30 02:37:22,770 Epoch: [70/484] Iter:[70/495], Time: 0.39, lr: [0.0086857224408388], Loss: 2.134499, Acc:0.787345, Semantic loss: 0.791035, BCE loss: 0.566388, SB loss: 0.777076
2023-10-30 02:37:26,348 Epoch: [70/484] Iter:[80/495], Time: 0.39, lr: [0.008685340854912979], Loss: 2.128505, Acc:0.788210, Semantic loss: 0.793122, BCE loss: 0.559991, SB loss: 0.775392
2023-10-30 02:37:30,007 Epoch: [70/484] Iter:[90/495], Time: 0.38, lr: [0.008684959267124396], Loss: 2.137212, Acc:0.787805, Semantic loss: 0.801521, BCE loss: 0.560281, SB loss: 0.775410
2023-10-30 02:37:33,673 Epoch: [70/484] Iter:[100/495], Time: 0.38, lr: [0.008684577677472952], Loss: 2.147648, Acc:0.782196, Semantic loss: 0.811454, BCE loss: 0.557501, SB loss: 0.778693
2023-10-30 02:37:37,338 Epoch: [70/484] Iter:[110/495], Time: 0.38, lr: [0.008684196085958546], Loss: 2.206447, Acc:0.781181, Semantic loss: 0.843047, BCE loss: 0.566736, SB loss: 0.796664
2023-10-30 02:37:40,998 Epoch: [70/484] Iter:[120/495], Time: 0.38, lr: [0.008683814492581076], Loss: 2.212868, Acc:0.779750, Semantic loss: 0.842365, BCE loss: 0.572371, SB loss: 0.798132
2023-10-30 02:37:44,689 Epoch: [70/484] Iter:[130/495], Time: 0.38, lr: [0.008683432897340445], Loss: 2.211379, Acc:0.780609, Semantic loss: 0.840620, BCE loss: 0.573875, SB loss: 0.796884
2023-10-30 02:37:48,371 Epoch: [70/484] Iter:[140/495], Time: 0.38, lr: [0.00868305130023655], Loss: 2.205810, Acc:0.780360, Semantic loss: 0.837134, BCE loss: 0.574748, SB loss: 0.793928
2023-10-30 02:37:51,993 Epoch: [70/484] Iter:[150/495], Time: 0.38, lr: [0.008682669701269293], Loss: 2.206136, Acc:0.782468, Semantic loss: 0.835724, BCE loss: 0.576842, SB loss: 0.793570
2023-10-30 02:37:55,675 Epoch: [70/484] Iter:[160/495], Time: 0.38, lr: [0.008682288100438572], Loss: 2.208261, Acc:0.778523, Semantic loss: 0.840562, BCE loss: 0.570958, SB loss: 0.796741
2023-10-30 02:37:59,285 Epoch: [70/484] Iter:[170/495], Time: 0.38, lr: [0.00868190649774429], Loss: 2.231008, Acc:0.776248, Semantic loss: 0.851306, BCE loss: 0.576654, SB loss: 0.803049
2023-10-30 02:38:03,111 Epoch: [70/484] Iter:[180/495], Time: 0.38, lr: [0.008681524893186344], Loss: 2.244909, Acc:0.775511, Semantic loss: 0.859324, BCE loss: 0.578308, SB loss: 0.807277
2023-10-30 02:38:06,831 Epoch: [70/484] Iter:[190/495], Time: 0.38, lr: [0.008681143286764637], Loss: 2.245051, Acc:0.776778, Semantic loss: 0.860002, BCE loss: 0.577255, SB loss: 0.807795
2023-10-30 02:38:10,487 Epoch: [70/484] Iter:[200/495], Time: 0.38, lr: [0.008680761678479065], Loss: 2.243825, Acc:0.777149, Semantic loss: 0.858857, BCE loss: 0.577927, SB loss: 0.807041
2023-10-30 02:38:14,188 Epoch: [70/484] Iter:[210/495], Time: 0.38, lr: [0.00868038006832953], Loss: 2.235359, Acc:0.778339, Semantic loss: 0.854143, BCE loss: 0.576904, SB loss: 0.804313
2023-10-30 02:38:17,855 Epoch: [70/484] Iter:[220/495], Time: 0.37, lr: [0.00867999845631593], Loss: 2.235088, Acc:0.778754, Semantic loss: 0.853966, BCE loss: 0.576107, SB loss: 0.805014
2023-10-30 02:38:21,546 Epoch: [70/484] Iter:[230/495], Time: 0.37, lr: [0.008679616842438169], Loss: 2.232071, Acc:0.778213, Semantic loss: 0.851178, BCE loss: 0.574257, SB loss: 0.806636
2023-10-30 02:38:25,304 Epoch: [70/484] Iter:[240/495], Time: 0.37, lr: [0.008679235226696141], Loss: 2.225805, Acc:0.778719, Semantic loss: 0.847018, BCE loss: 0.573641, SB loss: 0.805146
2023-10-30 02:38:29,017 Epoch: [70/484] Iter:[250/495], Time: 0.37, lr: [0.008678853609089751], Loss: 2.225631, Acc:0.780592, Semantic loss: 0.845972, BCE loss: 0.575364, SB loss: 0.804295
2023-10-30 02:38:32,749 Epoch: [70/484] Iter:[260/495], Time: 0.37, lr: [0.008678471989618897], Loss: 2.219677, Acc:0.781153, Semantic loss: 0.844013, BCE loss: 0.573572, SB loss: 0.802092
2023-10-30 02:38:36,381 Epoch: [70/484] Iter:[270/495], Time: 0.37, lr: [0.00867809036828348], Loss: 2.220433, Acc:0.782689, Semantic loss: 0.844923, BCE loss: 0.574058, SB loss: 0.801452
2023-10-30 02:38:39,981 Epoch: [70/484] Iter:[280/495], Time: 0.37, lr: [0.008677708745083395], Loss: 2.222905, Acc:0.781756, Semantic loss: 0.846406, BCE loss: 0.574241, SB loss: 0.802258
2023-10-30 02:38:43,674 Epoch: [70/484] Iter:[290/495], Time: 0.37, lr: [0.008677327120018546], Loss: 2.215735, Acc:0.782316, Semantic loss: 0.842633, BCE loss: 0.571450, SB loss: 0.801651
2023-10-30 02:38:47,262 Epoch: [70/484] Iter:[300/495], Time: 0.37, lr: [0.008676945493088832], Loss: 2.209066, Acc:0.782887, Semantic loss: 0.839473, BCE loss: 0.570127, SB loss: 0.799466
2023-10-30 02:38:50,921 Epoch: [70/484] Iter:[310/495], Time: 0.37, lr: [0.008676563864294154], Loss: 2.205836, Acc:0.782922, Semantic loss: 0.839301, BCE loss: 0.567884, SB loss: 0.798651
2023-10-30 02:38:54,593 Epoch: [70/484] Iter:[320/495], Time: 0.37, lr: [0.008676182233634408], Loss: 2.205190, Acc:0.783645, Semantic loss: 0.838345, BCE loss: 0.568350, SB loss: 0.798496
2023-10-30 02:38:58,312 Epoch: [70/484] Iter:[330/495], Time: 0.37, lr: [0.008675800601109498], Loss: 2.204860, Acc:0.783135, Semantic loss: 0.839723, BCE loss: 0.566744, SB loss: 0.798392
2023-10-30 02:39:01,992 Epoch: [70/484] Iter:[340/495], Time: 0.37, lr: [0.008675418966719322], Loss: 2.205462, Acc:0.783760, Semantic loss: 0.839599, BCE loss: 0.567165, SB loss: 0.798699
2023-10-30 02:39:05,592 Epoch: [70/484] Iter:[350/495], Time: 0.37, lr: [0.00867503733046378], Loss: 2.203839, Acc:0.783984, Semantic loss: 0.837908, BCE loss: 0.567716, SB loss: 0.798215
2023-10-30 02:39:09,258 Epoch: [70/484] Iter:[360/495], Time: 0.37, lr: [0.00867465569234277], Loss: 2.203127, Acc:0.783376, Semantic loss: 0.837426, BCE loss: 0.567827, SB loss: 0.797874
2023-10-30 02:39:13,010 Epoch: [70/484] Iter:[370/495], Time: 0.37, lr: [0.008674274052356193], Loss: 2.206083, Acc:0.782775, Semantic loss: 0.840787, BCE loss: 0.566550, SB loss: 0.798747
2023-10-30 02:39:16,718 Epoch: [70/484] Iter:[380/495], Time: 0.37, lr: [0.00867389241050395], Loss: 2.205180, Acc:0.783058, Semantic loss: 0.840846, BCE loss: 0.565614, SB loss: 0.798720
2023-10-30 02:39:20,397 Epoch: [70/484] Iter:[390/495], Time: 0.37, lr: [0.008673510766785936], Loss: 2.202556, Acc:0.784080, Semantic loss: 0.838882, BCE loss: 0.566646, SB loss: 0.797028
2023-10-30 02:39:24,045 Epoch: [70/484] Iter:[400/495], Time: 0.37, lr: [0.008673129121202055], Loss: 2.202043, Acc:0.783849, Semantic loss: 0.838899, BCE loss: 0.566138, SB loss: 0.797005
2023-10-30 02:39:27,786 Epoch: [70/484] Iter:[410/495], Time: 0.37, lr: [0.008672747473752207], Loss: 2.200266, Acc:0.784591, Semantic loss: 0.837734, BCE loss: 0.565632, SB loss: 0.796901
2023-10-30 02:39:31,495 Epoch: [70/484] Iter:[420/495], Time: 0.37, lr: [0.00867236582443629], Loss: 2.195723, Acc:0.784372, Semantic loss: 0.835631, BCE loss: 0.563850, SB loss: 0.796242
2023-10-30 02:39:35,097 Epoch: [70/484] Iter:[430/495], Time: 0.37, lr: [0.008671984173254205], Loss: 2.192156, Acc:0.783974, Semantic loss: 0.834652, BCE loss: 0.562084, SB loss: 0.795420
2023-10-30 02:39:38,740 Epoch: [70/484] Iter:[440/495], Time: 0.37, lr: [0.00867160252020585], Loss: 2.190024, Acc:0.784478, Semantic loss: 0.832905, BCE loss: 0.562267, SB loss: 0.794852
2023-10-30 02:39:42,521 Epoch: [70/484] Iter:[450/495], Time: 0.37, lr: [0.008671220865291122], Loss: 2.186645, Acc:0.784908, Semantic loss: 0.831560, BCE loss: 0.561487, SB loss: 0.793598
2023-10-30 02:39:46,259 Epoch: [70/484] Iter:[460/495], Time: 0.37, lr: [0.008670839208509926], Loss: 2.186053, Acc:0.785843, Semantic loss: 0.831130, BCE loss: 0.561566, SB loss: 0.793357
2023-10-30 02:39:49,929 Epoch: [70/484] Iter:[470/495], Time: 0.37, lr: [0.00867045754986216], Loss: 2.182872, Acc:0.786645, Semantic loss: 0.829636, BCE loss: 0.560269, SB loss: 0.792968
2023-10-30 02:39:53,538 Epoch: [70/484] Iter:[480/495], Time: 0.37, lr: [0.008670075889347722], Loss: 2.183989, Acc:0.787005, Semantic loss: 0.830174, BCE loss: 0.561161, SB loss: 0.792654
2023-10-30 02:39:57,051 Epoch: [70/484] Iter:[490/495], Time: 0.37, lr: [0.008669694226966512], Loss: 2.181861, Acc:0.787040, Semantic loss: 0.829852, BCE loss: 0.560318, SB loss: 0.791691
2023-10-30 02:42:52,908 0 [9.18612099e-01 5.70134534e-01 8.02283094e-01 1.00718479e-01
 2.02625108e-01 3.93177162e-01 4.28851991e-01 5.44507427e-01
 8.76243547e-01 3.92188608e-01 7.28258582e-01 5.81667339e-01
 2.83678906e-04 7.94282280e-01 3.21104338e-04 4.69397013e-02
 2.54934971e-03 6.17087185e-03 5.63949314e-01] 0.41861917203056115
2023-10-30 02:42:52,909 1 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215] 0.6400085109922465
2023-10-30 02:42:52,912 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:42:53,138 Loss: 2.134, MeanIU:  0.6400, Best_mIoU:  0.6736
2023-10-30 02:42:53,138 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215]
2023-10-30 02:42:55,247 Epoch: [71/484] Iter:[0/495], Time: 2.08, lr: [0.008669503395075837], Loss: 3.070248, Acc:0.858558, Semantic loss: 1.389951, BCE loss: 0.730350, SB loss: 0.949947
2023-10-30 02:42:59,027 Epoch: [71/484] Iter:[10/495], Time: 0.53, lr: [0.008669121729894282], Loss: 2.189262, Acc:0.760548, Semantic loss: 0.835967, BCE loss: 0.577305, SB loss: 0.775990
2023-10-30 02:43:02,688 Epoch: [71/484] Iter:[20/495], Time: 0.45, lr: [0.008668740062845706], Loss: 2.101501, Acc:0.756929, Semantic loss: 0.788695, BCE loss: 0.544176, SB loss: 0.768631
2023-10-30 02:43:06,259 Epoch: [71/484] Iter:[30/495], Time: 0.42, lr: [0.008668358393930002], Loss: 2.175278, Acc:0.756161, Semantic loss: 0.850232, BCE loss: 0.540634, SB loss: 0.784411
2023-10-30 02:43:09,783 Epoch: [71/484] Iter:[40/495], Time: 0.41, lr: [0.008667976723147078], Loss: 2.143940, Acc:0.771554, Semantic loss: 0.823883, BCE loss: 0.544250, SB loss: 0.775807
2023-10-30 02:43:13,249 Epoch: [71/484] Iter:[50/495], Time: 0.39, lr: [0.008667595050496829], Loss: 2.157403, Acc:0.782064, Semantic loss: 0.818518, BCE loss: 0.563477, SB loss: 0.775407
2023-10-30 02:43:16,788 Epoch: [71/484] Iter:[60/495], Time: 0.39, lr: [0.008667213375979156], Loss: 2.161326, Acc:0.782082, Semantic loss: 0.818690, BCE loss: 0.563348, SB loss: 0.779288
2023-10-30 02:43:20,313 Epoch: [71/484] Iter:[70/495], Time: 0.38, lr: [0.008666831699593957], Loss: 2.158453, Acc:0.781325, Semantic loss: 0.821992, BCE loss: 0.557022, SB loss: 0.779439
2023-10-30 02:43:23,867 Epoch: [71/484] Iter:[80/495], Time: 0.38, lr: [0.008666450021341133], Loss: 2.158387, Acc:0.781959, Semantic loss: 0.823737, BCE loss: 0.552934, SB loss: 0.781716
2023-10-30 02:43:27,433 Epoch: [71/484] Iter:[90/495], Time: 0.38, lr: [0.008666068341220584], Loss: 2.148020, Acc:0.783221, Semantic loss: 0.815298, BCE loss: 0.552586, SB loss: 0.780136
2023-10-30 02:43:31,007 Epoch: [71/484] Iter:[100/495], Time: 0.37, lr: [0.008665686659232206], Loss: 2.147906, Acc:0.780348, Semantic loss: 0.816752, BCE loss: 0.546444, SB loss: 0.784709
2023-10-30 02:43:34,637 Epoch: [71/484] Iter:[110/495], Time: 0.37, lr: [0.0086653049753759], Loss: 2.133769, Acc:0.780285, Semantic loss: 0.809613, BCE loss: 0.542467, SB loss: 0.781689
2023-10-30 02:43:38,156 Epoch: [71/484] Iter:[120/495], Time: 0.37, lr: [0.008664923289651568], Loss: 2.127982, Acc:0.784977, Semantic loss: 0.804854, BCE loss: 0.542999, SB loss: 0.780130
2023-10-30 02:43:41,833 Epoch: [71/484] Iter:[130/495], Time: 0.37, lr: [0.008664541602059109], Loss: 2.126573, Acc:0.783170, Semantic loss: 0.807158, BCE loss: 0.539304, SB loss: 0.780111
2023-10-30 02:43:45,426 Epoch: [71/484] Iter:[140/495], Time: 0.37, lr: [0.008664159912598416], Loss: 2.128638, Acc:0.783098, Semantic loss: 0.807168, BCE loss: 0.537793, SB loss: 0.783677
2023-10-30 02:43:49,108 Epoch: [71/484] Iter:[150/495], Time: 0.37, lr: [0.008663778221269399], Loss: 2.124254, Acc:0.782494, Semantic loss: 0.806004, BCE loss: 0.536266, SB loss: 0.781984
2023-10-30 02:43:52,783 Epoch: [71/484] Iter:[160/495], Time: 0.37, lr: [0.00866339652807195], Loss: 2.123092, Acc:0.781921, Semantic loss: 0.804269, BCE loss: 0.537600, SB loss: 0.781223
2023-10-30 02:43:56,399 Epoch: [71/484] Iter:[170/495], Time: 0.37, lr: [0.008663014833005968], Loss: 2.122658, Acc:0.782757, Semantic loss: 0.804770, BCE loss: 0.538108, SB loss: 0.779780
2023-10-30 02:44:00,024 Epoch: [71/484] Iter:[180/495], Time: 0.37, lr: [0.008662633136071357], Loss: 2.125218, Acc:0.786489, Semantic loss: 0.807165, BCE loss: 0.538389, SB loss: 0.779664
2023-10-30 02:44:03,746 Epoch: [71/484] Iter:[190/495], Time: 0.37, lr: [0.008662251437268013], Loss: 2.122707, Acc:0.786919, Semantic loss: 0.805084, BCE loss: 0.538992, SB loss: 0.778631
2023-10-30 02:44:07,397 Epoch: [71/484] Iter:[200/495], Time: 0.37, lr: [0.008661869736595837], Loss: 2.122536, Acc:0.788803, Semantic loss: 0.805434, BCE loss: 0.537200, SB loss: 0.779902
2023-10-30 02:44:11,095 Epoch: [71/484] Iter:[210/495], Time: 0.37, lr: [0.008661488034054728], Loss: 2.122433, Acc:0.789959, Semantic loss: 0.805561, BCE loss: 0.537661, SB loss: 0.779212
2023-10-30 02:44:14,722 Epoch: [71/484] Iter:[220/495], Time: 0.37, lr: [0.008661106329644582], Loss: 2.120984, Acc:0.792194, Semantic loss: 0.804660, BCE loss: 0.537590, SB loss: 0.778734
2023-10-30 02:44:18,355 Epoch: [71/484] Iter:[230/495], Time: 0.37, lr: [0.008660724623365304], Loss: 2.112361, Acc:0.790746, Semantic loss: 0.800447, BCE loss: 0.536290, SB loss: 0.775623
2023-10-30 02:44:21,943 Epoch: [71/484] Iter:[240/495], Time: 0.37, lr: [0.008660342915216791], Loss: 2.104161, Acc:0.790260, Semantic loss: 0.796932, BCE loss: 0.534282, SB loss: 0.772947
2023-10-30 02:44:25,593 Epoch: [71/484] Iter:[250/495], Time: 0.37, lr: [0.00865996120519894], Loss: 2.103286, Acc:0.789930, Semantic loss: 0.796463, BCE loss: 0.534178, SB loss: 0.772645
2023-10-30 02:44:29,384 Epoch: [71/484] Iter:[260/495], Time: 0.37, lr: [0.008659579493311654], Loss: 2.105873, Acc:0.790786, Semantic loss: 0.798527, BCE loss: 0.534673, SB loss: 0.772673
2023-10-30 02:44:33,136 Epoch: [71/484] Iter:[270/495], Time: 0.37, lr: [0.008659197779554829], Loss: 2.108574, Acc:0.790390, Semantic loss: 0.798951, BCE loss: 0.537008, SB loss: 0.772616
2023-10-30 02:44:36,807 Epoch: [71/484] Iter:[280/495], Time: 0.37, lr: [0.008658816063928366], Loss: 2.111071, Acc:0.790053, Semantic loss: 0.800637, BCE loss: 0.537170, SB loss: 0.773265
2023-10-30 02:44:40,587 Epoch: [71/484] Iter:[290/495], Time: 0.37, lr: [0.008658434346432164], Loss: 2.109866, Acc:0.791101, Semantic loss: 0.799830, BCE loss: 0.537672, SB loss: 0.772364
2023-10-30 02:44:44,198 Epoch: [71/484] Iter:[300/495], Time: 0.37, lr: [0.008658052627066122], Loss: 2.105985, Acc:0.791373, Semantic loss: 0.797311, BCE loss: 0.536773, SB loss: 0.771900
2023-10-30 02:44:47,802 Epoch: [71/484] Iter:[310/495], Time: 0.37, lr: [0.008657670905830141], Loss: 2.100584, Acc:0.790296, Semantic loss: 0.793656, BCE loss: 0.536303, SB loss: 0.770624
2023-10-30 02:44:51,422 Epoch: [71/484] Iter:[320/495], Time: 0.37, lr: [0.008657289182724117], Loss: 2.100093, Acc:0.790139, Semantic loss: 0.793587, BCE loss: 0.536109, SB loss: 0.770397
2023-10-30 02:44:55,138 Epoch: [71/484] Iter:[330/495], Time: 0.37, lr: [0.008656907457747953], Loss: 2.103579, Acc:0.789382, Semantic loss: 0.796083, BCE loss: 0.535683, SB loss: 0.771813
2023-10-30 02:44:58,855 Epoch: [71/484] Iter:[340/495], Time: 0.37, lr: [0.008656525730901544], Loss: 2.104446, Acc:0.789256, Semantic loss: 0.795749, BCE loss: 0.536750, SB loss: 0.771947
2023-10-30 02:45:02,551 Epoch: [71/484] Iter:[350/495], Time: 0.37, lr: [0.008656144002184792], Loss: 2.101285, Acc:0.788703, Semantic loss: 0.794131, BCE loss: 0.535610, SB loss: 0.771545
2023-10-30 02:45:06,230 Epoch: [71/484] Iter:[360/495], Time: 0.37, lr: [0.008655762271597596], Loss: 2.100856, Acc:0.788803, Semantic loss: 0.794364, BCE loss: 0.535965, SB loss: 0.770527
2023-10-30 02:45:09,959 Epoch: [71/484] Iter:[370/495], Time: 0.37, lr: [0.008655380539139855], Loss: 2.098662, Acc:0.788839, Semantic loss: 0.792700, BCE loss: 0.535391, SB loss: 0.770571
2023-10-30 02:45:13,636 Epoch: [71/484] Iter:[380/495], Time: 0.37, lr: [0.008654998804811466], Loss: 2.097506, Acc:0.788422, Semantic loss: 0.792025, BCE loss: 0.534502, SB loss: 0.770978
2023-10-30 02:45:17,246 Epoch: [71/484] Iter:[390/495], Time: 0.37, lr: [0.008654617068612333], Loss: 2.095154, Acc:0.788631, Semantic loss: 0.790493, BCE loss: 0.534439, SB loss: 0.770222
2023-10-30 02:45:20,895 Epoch: [71/484] Iter:[400/495], Time: 0.37, lr: [0.00865423533054235], Loss: 2.098625, Acc:0.788267, Semantic loss: 0.793062, BCE loss: 0.534248, SB loss: 0.771315
2023-10-30 02:45:24,607 Epoch: [71/484] Iter:[410/495], Time: 0.37, lr: [0.00865385359060142], Loss: 2.096564, Acc:0.788769, Semantic loss: 0.791650, BCE loss: 0.534048, SB loss: 0.770866
2023-10-30 02:45:28,326 Epoch: [71/484] Iter:[420/495], Time: 0.37, lr: [0.008653471848789441], Loss: 2.097541, Acc:0.787902, Semantic loss: 0.793208, BCE loss: 0.533003, SB loss: 0.771330
2023-10-30 02:45:31,880 Epoch: [71/484] Iter:[430/495], Time: 0.37, lr: [0.00865309010510631], Loss: 2.096881, Acc:0.787786, Semantic loss: 0.792316, BCE loss: 0.533795, SB loss: 0.770771
2023-10-30 02:45:35,663 Epoch: [71/484] Iter:[440/495], Time: 0.37, lr: [0.008652708359551927], Loss: 2.097294, Acc:0.788805, Semantic loss: 0.792647, BCE loss: 0.533658, SB loss: 0.770989
2023-10-30 02:45:39,389 Epoch: [71/484] Iter:[450/495], Time: 0.37, lr: [0.008652326612126194], Loss: 2.100389, Acc:0.789184, Semantic loss: 0.793740, BCE loss: 0.534692, SB loss: 0.771957
2023-10-30 02:45:43,077 Epoch: [71/484] Iter:[460/495], Time: 0.37, lr: [0.008651944862829006], Loss: 2.101161, Acc:0.789605, Semantic loss: 0.793196, BCE loss: 0.536041, SB loss: 0.771923
2023-10-30 02:45:46,702 Epoch: [71/484] Iter:[470/495], Time: 0.37, lr: [0.008651563111660264], Loss: 2.101964, Acc:0.789539, Semantic loss: 0.793050, BCE loss: 0.536939, SB loss: 0.771975
2023-10-30 02:45:50,338 Epoch: [71/484] Iter:[480/495], Time: 0.37, lr: [0.008651181358619869], Loss: 2.104326, Acc:0.789787, Semantic loss: 0.794146, BCE loss: 0.537714, SB loss: 0.772467
2023-10-30 02:45:53,834 Epoch: [71/484] Iter:[490/495], Time: 0.37, lr: [0.008650799603707716], Loss: 2.104821, Acc:0.790004, Semantic loss: 0.794802, BCE loss: 0.537869, SB loss: 0.772150
2023-10-30 02:45:55,220 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:45:55,459 Loss: 2.134, MeanIU:  0.6400, Best_mIoU:  0.6736
2023-10-30 02:45:55,459 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215]
2023-10-30 02:45:57,335 Epoch: [72/484] Iter:[0/495], Time: 1.84, lr: [0.0086506087255497], Loss: 2.146299, Acc:0.828259, Semantic loss: 0.733366, BCE loss: 0.660578, SB loss: 0.752355
2023-10-30 02:46:01,275 Epoch: [72/484] Iter:[10/495], Time: 0.53, lr: [0.008650226967829725], Loss: 2.171008, Acc:0.762664, Semantic loss: 0.894025, BCE loss: 0.517096, SB loss: 0.759887
2023-10-30 02:46:04,938 Epoch: [72/484] Iter:[20/495], Time: 0.45, lr: [0.008649845208237741], Loss: 2.262645, Acc:0.770174, Semantic loss: 0.899774, BCE loss: 0.539884, SB loss: 0.822987
2023-10-30 02:46:08,632 Epoch: [72/484] Iter:[30/495], Time: 0.42, lr: [0.008649463446773647], Loss: 2.163351, Acc:0.785570, Semantic loss: 0.838854, BCE loss: 0.530349, SB loss: 0.794147
2023-10-30 02:46:12,284 Epoch: [72/484] Iter:[40/495], Time: 0.41, lr: [0.008649081683437344], Loss: 2.174340, Acc:0.788290, Semantic loss: 0.836967, BCE loss: 0.543500, SB loss: 0.793872
2023-10-30 02:46:16,131 Epoch: [72/484] Iter:[50/495], Time: 0.40, lr: [0.00864869991822873], Loss: 2.176212, Acc:0.789952, Semantic loss: 0.832176, BCE loss: 0.551920, SB loss: 0.792116
2023-10-30 02:46:19,760 Epoch: [72/484] Iter:[60/495], Time: 0.40, lr: [0.008648318151147702], Loss: 2.163866, Acc:0.795065, Semantic loss: 0.825808, BCE loss: 0.554100, SB loss: 0.783957
2023-10-30 02:46:23,363 Epoch: [72/484] Iter:[70/495], Time: 0.39, lr: [0.008647936382194164], Loss: 2.138994, Acc:0.792044, Semantic loss: 0.815004, BCE loss: 0.545919, SB loss: 0.778071
2023-10-30 02:46:27,028 Epoch: [72/484] Iter:[80/495], Time: 0.39, lr: [0.00864755461136801], Loss: 2.136471, Acc:0.792537, Semantic loss: 0.816058, BCE loss: 0.544622, SB loss: 0.775791
2023-10-30 02:46:30,661 Epoch: [72/484] Iter:[90/495], Time: 0.39, lr: [0.00864717283866914], Loss: 2.118287, Acc:0.788097, Semantic loss: 0.809673, BCE loss: 0.540265, SB loss: 0.768350
2023-10-30 02:46:34,359 Epoch: [72/484] Iter:[100/495], Time: 0.38, lr: [0.008646791064097452], Loss: 2.122785, Acc:0.788980, Semantic loss: 0.813728, BCE loss: 0.540080, SB loss: 0.768977
2023-10-30 02:46:37,977 Epoch: [72/484] Iter:[110/495], Time: 0.38, lr: [0.008646409287652848], Loss: 2.146349, Acc:0.790842, Semantic loss: 0.826780, BCE loss: 0.547495, SB loss: 0.772074
2023-10-30 02:46:41,670 Epoch: [72/484] Iter:[120/495], Time: 0.38, lr: [0.008646027509335226], Loss: 2.161318, Acc:0.787897, Semantic loss: 0.834284, BCE loss: 0.550256, SB loss: 0.776777
2023-10-30 02:46:45,470 Epoch: [72/484] Iter:[130/495], Time: 0.38, lr: [0.008645645729144483], Loss: 2.159514, Acc:0.789027, Semantic loss: 0.828327, BCE loss: 0.554098, SB loss: 0.777089
2023-10-30 02:46:49,098 Epoch: [72/484] Iter:[140/495], Time: 0.38, lr: [0.00864526394708052], Loss: 2.165116, Acc:0.790747, Semantic loss: 0.828778, BCE loss: 0.558399, SB loss: 0.777939
2023-10-30 02:46:52,873 Epoch: [72/484] Iter:[150/495], Time: 0.38, lr: [0.008644882163143236], Loss: 2.167462, Acc:0.792302, Semantic loss: 0.829393, BCE loss: 0.558455, SB loss: 0.779613
2023-10-30 02:46:56,477 Epoch: [72/484] Iter:[160/495], Time: 0.38, lr: [0.008644500377332527], Loss: 2.170427, Acc:0.792720, Semantic loss: 0.829632, BCE loss: 0.559116, SB loss: 0.781680
2023-10-30 02:47:00,177 Epoch: [72/484] Iter:[170/495], Time: 0.38, lr: [0.008644118589648295], Loss: 2.169312, Acc:0.791052, Semantic loss: 0.826822, BCE loss: 0.558996, SB loss: 0.783495
2023-10-30 02:47:03,887 Epoch: [72/484] Iter:[180/495], Time: 0.38, lr: [0.008643736800090437], Loss: 2.167267, Acc:0.788282, Semantic loss: 0.826663, BCE loss: 0.557461, SB loss: 0.783143
2023-10-30 02:47:07,580 Epoch: [72/484] Iter:[190/495], Time: 0.38, lr: [0.008643355008658855], Loss: 2.160496, Acc:0.789260, Semantic loss: 0.822456, BCE loss: 0.556953, SB loss: 0.781086
2023-10-30 02:47:11,278 Epoch: [72/484] Iter:[200/495], Time: 0.38, lr: [0.008642973215353442], Loss: 2.152892, Acc:0.788149, Semantic loss: 0.820248, BCE loss: 0.553755, SB loss: 0.778889
2023-10-30 02:47:14,962 Epoch: [72/484] Iter:[210/495], Time: 0.38, lr: [0.008642591420174104], Loss: 2.149743, Acc:0.787108, Semantic loss: 0.817820, BCE loss: 0.553655, SB loss: 0.778268
2023-10-30 02:47:18,688 Epoch: [72/484] Iter:[220/495], Time: 0.38, lr: [0.008642209623120733], Loss: 2.152280, Acc:0.785831, Semantic loss: 0.819788, BCE loss: 0.551904, SB loss: 0.780589
2023-10-30 02:47:22,340 Epoch: [72/484] Iter:[230/495], Time: 0.38, lr: [0.008641827824193232], Loss: 2.147738, Acc:0.787488, Semantic loss: 0.816213, BCE loss: 0.551533, SB loss: 0.779992
2023-10-30 02:47:26,132 Epoch: [72/484] Iter:[240/495], Time: 0.38, lr: [0.0086414460233915], Loss: 2.149502, Acc:0.786475, Semantic loss: 0.819181, BCE loss: 0.551267, SB loss: 0.779053
2023-10-30 02:47:29,766 Epoch: [72/484] Iter:[250/495], Time: 0.38, lr: [0.008641064220715432], Loss: 2.151746, Acc:0.788680, Semantic loss: 0.820822, BCE loss: 0.551854, SB loss: 0.779069
2023-10-30 02:47:33,483 Epoch: [72/484] Iter:[260/495], Time: 0.38, lr: [0.00864068241616493], Loss: 2.148010, Acc:0.789102, Semantic loss: 0.817420, BCE loss: 0.551320, SB loss: 0.779270
2023-10-30 02:47:37,141 Epoch: [72/484] Iter:[270/495], Time: 0.38, lr: [0.008640300609739892], Loss: 2.150756, Acc:0.788584, Semantic loss: 0.820098, BCE loss: 0.550609, SB loss: 0.780049
2023-10-30 02:47:40,785 Epoch: [72/484] Iter:[280/495], Time: 0.37, lr: [0.008639918801440218], Loss: 2.149929, Acc:0.787822, Semantic loss: 0.820429, BCE loss: 0.549675, SB loss: 0.779825
2023-10-30 02:47:44,492 Epoch: [72/484] Iter:[290/495], Time: 0.37, lr: [0.008639536991265804], Loss: 2.150364, Acc:0.787989, Semantic loss: 0.819616, BCE loss: 0.550192, SB loss: 0.780556
2023-10-30 02:47:48,180 Epoch: [72/484] Iter:[300/495], Time: 0.37, lr: [0.008639155179216552], Loss: 2.145611, Acc:0.788560, Semantic loss: 0.816058, BCE loss: 0.550535, SB loss: 0.779018
2023-10-30 02:47:51,832 Epoch: [72/484] Iter:[310/495], Time: 0.37, lr: [0.008638773365292358], Loss: 2.146134, Acc:0.790058, Semantic loss: 0.815543, BCE loss: 0.550330, SB loss: 0.780261
2023-10-30 02:47:55,605 Epoch: [72/484] Iter:[320/495], Time: 0.37, lr: [0.008638391549493122], Loss: 2.142767, Acc:0.789186, Semantic loss: 0.814165, BCE loss: 0.549610, SB loss: 0.778992
2023-10-30 02:47:59,260 Epoch: [72/484] Iter:[330/495], Time: 0.37, lr: [0.008638009731818741], Loss: 2.144908, Acc:0.789521, Semantic loss: 0.813385, BCE loss: 0.552981, SB loss: 0.778541
2023-10-30 02:48:02,967 Epoch: [72/484] Iter:[340/495], Time: 0.37, lr: [0.008637627912269116], Loss: 2.145834, Acc:0.789365, Semantic loss: 0.813208, BCE loss: 0.554077, SB loss: 0.778549
2023-10-30 02:48:06,624 Epoch: [72/484] Iter:[350/495], Time: 0.37, lr: [0.008637246090844146], Loss: 2.142303, Acc:0.789678, Semantic loss: 0.812893, BCE loss: 0.551947, SB loss: 0.777463
2023-10-30 02:48:10,227 Epoch: [72/484] Iter:[360/495], Time: 0.37, lr: [0.008636864267543726], Loss: 2.144075, Acc:0.790282, Semantic loss: 0.814023, BCE loss: 0.552641, SB loss: 0.777411
2023-10-30 02:48:13,865 Epoch: [72/484] Iter:[370/495], Time: 0.37, lr: [0.00863648244236776], Loss: 2.147097, Acc:0.789220, Semantic loss: 0.816694, BCE loss: 0.552653, SB loss: 0.777751
2023-10-30 02:48:17,513 Epoch: [72/484] Iter:[380/495], Time: 0.37, lr: [0.00863610061531614], Loss: 2.142377, Acc:0.787884, Semantic loss: 0.814009, BCE loss: 0.552183, SB loss: 0.776185
2023-10-30 02:48:21,312 Epoch: [72/484] Iter:[390/495], Time: 0.37, lr: [0.008635718786388772], Loss: 2.142407, Acc:0.788175, Semantic loss: 0.813708, BCE loss: 0.552535, SB loss: 0.776164
2023-10-30 02:48:25,092 Epoch: [72/484] Iter:[400/495], Time: 0.37, lr: [0.00863533695558555], Loss: 2.143917, Acc:0.788283, Semantic loss: 0.812897, BCE loss: 0.554694, SB loss: 0.776325
2023-10-30 02:48:28,747 Epoch: [72/484] Iter:[410/495], Time: 0.37, lr: [0.008634955122906374], Loss: 2.145770, Acc:0.788761, Semantic loss: 0.814034, BCE loss: 0.554154, SB loss: 0.777582
2023-10-30 02:48:32,583 Epoch: [72/484] Iter:[420/495], Time: 0.37, lr: [0.008634573288351141], Loss: 2.146429, Acc:0.789309, Semantic loss: 0.813740, BCE loss: 0.554101, SB loss: 0.778588
2023-10-30 02:48:36,311 Epoch: [72/484] Iter:[430/495], Time: 0.37, lr: [0.008634191451919751], Loss: 2.147716, Acc:0.789624, Semantic loss: 0.813882, BCE loss: 0.554621, SB loss: 0.779213
2023-10-30 02:48:40,023 Epoch: [72/484] Iter:[440/495], Time: 0.37, lr: [0.008633809613612103], Loss: 2.145371, Acc:0.790548, Semantic loss: 0.813020, BCE loss: 0.553850, SB loss: 0.778501
2023-10-30 02:48:43,606 Epoch: [72/484] Iter:[450/495], Time: 0.37, lr: [0.008633427773428097], Loss: 2.143867, Acc:0.790845, Semantic loss: 0.812321, BCE loss: 0.553342, SB loss: 0.778204
2023-10-30 02:48:47,282 Epoch: [72/484] Iter:[460/495], Time: 0.37, lr: [0.008633045931367628], Loss: 2.141951, Acc:0.790351, Semantic loss: 0.812116, BCE loss: 0.551958, SB loss: 0.777877
2023-10-30 02:48:51,023 Epoch: [72/484] Iter:[470/495], Time: 0.37, lr: [0.008632664087430596], Loss: 2.135688, Acc:0.790554, Semantic loss: 0.809076, BCE loss: 0.550078, SB loss: 0.776534
2023-10-30 02:48:54,704 Epoch: [72/484] Iter:[480/495], Time: 0.37, lr: [0.008632282241616898], Loss: 2.136632, Acc:0.790043, Semantic loss: 0.809911, BCE loss: 0.550212, SB loss: 0.776509
2023-10-30 02:48:58,202 Epoch: [72/484] Iter:[490/495], Time: 0.37, lr: [0.008631900393926438], Loss: 2.134118, Acc:0.789559, Semantic loss: 0.807883, BCE loss: 0.550487, SB loss: 0.775748
2023-10-30 02:48:59,601 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:48:59,840 Loss: 2.134, MeanIU:  0.6400, Best_mIoU:  0.6736
2023-10-30 02:48:59,840 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215]
2023-10-30 02:49:02,060 Epoch: [73/484] Iter:[0/495], Time: 2.19, lr: [0.008631709469377387], Loss: 1.952199, Acc:0.847324, Semantic loss: 0.663728, BCE loss: 0.650300, SB loss: 0.638171
2023-10-30 02:49:06,034 Epoch: [73/484] Iter:[10/495], Time: 0.56, lr: [0.008631327618871587], Loss: 2.033199, Acc:0.837199, Semantic loss: 0.761679, BCE loss: 0.547882, SB loss: 0.723639
2023-10-30 02:49:09,735 Epoch: [73/484] Iter:[20/495], Time: 0.47, lr: [0.008630945766488768], Loss: 2.058627, Acc:0.824677, Semantic loss: 0.762004, BCE loss: 0.553233, SB loss: 0.743389
2023-10-30 02:49:13,395 Epoch: [73/484] Iter:[30/495], Time: 0.44, lr: [0.008630563912228826], Loss: 2.060703, Acc:0.823799, Semantic loss: 0.758456, BCE loss: 0.557024, SB loss: 0.745223
2023-10-30 02:49:17,030 Epoch: [73/484] Iter:[40/495], Time: 0.42, lr: [0.008630182056091663], Loss: 2.054998, Acc:0.817300, Semantic loss: 0.756590, BCE loss: 0.551966, SB loss: 0.746442
2023-10-30 02:49:20,726 Epoch: [73/484] Iter:[50/495], Time: 0.41, lr: [0.008629800198077176], Loss: 2.068369, Acc:0.812242, Semantic loss: 0.766185, BCE loss: 0.548832, SB loss: 0.753353
2023-10-30 02:49:24,361 Epoch: [73/484] Iter:[60/495], Time: 0.40, lr: [0.008629418338185263], Loss: 2.054591, Acc:0.808740, Semantic loss: 0.758616, BCE loss: 0.546558, SB loss: 0.749416
2023-10-30 02:49:28,096 Epoch: [73/484] Iter:[70/495], Time: 0.40, lr: [0.008629036476415823], Loss: 2.075665, Acc:0.811110, Semantic loss: 0.772453, BCE loss: 0.553710, SB loss: 0.749502
2023-10-30 02:49:31,798 Epoch: [73/484] Iter:[80/495], Time: 0.39, lr: [0.008628654612768754], Loss: 2.069780, Acc:0.810003, Semantic loss: 0.771629, BCE loss: 0.550263, SB loss: 0.747889
2023-10-30 02:49:35,511 Epoch: [73/484] Iter:[90/495], Time: 0.39, lr: [0.008628272747243955], Loss: 2.078110, Acc:0.807895, Semantic loss: 0.775439, BCE loss: 0.552633, SB loss: 0.750038
2023-10-30 02:49:39,155 Epoch: [73/484] Iter:[100/495], Time: 0.39, lr: [0.008627890879841324], Loss: 2.076926, Acc:0.805918, Semantic loss: 0.776775, BCE loss: 0.551997, SB loss: 0.748153
2023-10-30 02:49:42,811 Epoch: [73/484] Iter:[110/495], Time: 0.39, lr: [0.00862750901056076], Loss: 2.070580, Acc:0.801429, Semantic loss: 0.777561, BCE loss: 0.545318, SB loss: 0.747701
2023-10-30 02:49:46,459 Epoch: [73/484] Iter:[120/495], Time: 0.38, lr: [0.008627127139402163], Loss: 2.083337, Acc:0.801165, Semantic loss: 0.781229, BCE loss: 0.553376, SB loss: 0.748732
2023-10-30 02:49:50,098 Epoch: [73/484] Iter:[130/495], Time: 0.38, lr: [0.00862674526636543], Loss: 2.087591, Acc:0.801956, Semantic loss: 0.782009, BCE loss: 0.556429, SB loss: 0.749153
2023-10-30 02:49:53,915 Epoch: [73/484] Iter:[140/495], Time: 0.38, lr: [0.008626363391450457], Loss: 2.084897, Acc:0.799701, Semantic loss: 0.782676, BCE loss: 0.553244, SB loss: 0.748976
2023-10-30 02:49:57,515 Epoch: [73/484] Iter:[150/495], Time: 0.38, lr: [0.008625981514657143], Loss: 2.093174, Acc:0.798529, Semantic loss: 0.788124, BCE loss: 0.554175, SB loss: 0.750875
2023-10-30 02:50:01,158 Epoch: [73/484] Iter:[160/495], Time: 0.38, lr: [0.008625599635985389], Loss: 2.105257, Acc:0.798094, Semantic loss: 0.793278, BCE loss: 0.557889, SB loss: 0.754090
2023-10-30 02:50:04,811 Epoch: [73/484] Iter:[170/495], Time: 0.38, lr: [0.008625217755435092], Loss: 2.108083, Acc:0.798847, Semantic loss: 0.791479, BCE loss: 0.559137, SB loss: 0.757467
2023-10-30 02:50:08,473 Epoch: [73/484] Iter:[180/495], Time: 0.38, lr: [0.00862483587300615], Loss: 2.103268, Acc:0.798157, Semantic loss: 0.789139, BCE loss: 0.557677, SB loss: 0.756452
2023-10-30 02:50:12,151 Epoch: [73/484] Iter:[190/495], Time: 0.38, lr: [0.008624453988698462], Loss: 2.109370, Acc:0.796652, Semantic loss: 0.797811, BCE loss: 0.553879, SB loss: 0.757679
2023-10-30 02:50:15,938 Epoch: [73/484] Iter:[200/495], Time: 0.38, lr: [0.008624072102511928], Loss: 2.108007, Acc:0.797790, Semantic loss: 0.795636, BCE loss: 0.555608, SB loss: 0.756763
2023-10-30 02:50:19,636 Epoch: [73/484] Iter:[210/495], Time: 0.38, lr: [0.008623690214446441], Loss: 2.105260, Acc:0.801131, Semantic loss: 0.791719, BCE loss: 0.557898, SB loss: 0.755643
2023-10-30 02:50:23,317 Epoch: [73/484] Iter:[220/495], Time: 0.38, lr: [0.008623308324501906], Loss: 2.105866, Acc:0.800790, Semantic loss: 0.793297, BCE loss: 0.555191, SB loss: 0.757378
2023-10-30 02:50:27,004 Epoch: [73/484] Iter:[230/495], Time: 0.38, lr: [0.008622926432678214], Loss: 2.105541, Acc:0.797705, Semantic loss: 0.794317, BCE loss: 0.552921, SB loss: 0.758303
2023-10-30 02:50:30,694 Epoch: [73/484] Iter:[240/495], Time: 0.38, lr: [0.00862254453897527], Loss: 2.103297, Acc:0.797818, Semantic loss: 0.794328, BCE loss: 0.551155, SB loss: 0.757814
2023-10-30 02:50:34,284 Epoch: [73/484] Iter:[250/495], Time: 0.38, lr: [0.008622162643392968], Loss: 2.100153, Acc:0.797963, Semantic loss: 0.793020, BCE loss: 0.550704, SB loss: 0.756430
2023-10-30 02:50:37,973 Epoch: [73/484] Iter:[260/495], Time: 0.38, lr: [0.008621780745931208], Loss: 2.099741, Acc:0.795515, Semantic loss: 0.795317, BCE loss: 0.546735, SB loss: 0.757689
2023-10-30 02:50:41,621 Epoch: [73/484] Iter:[270/495], Time: 0.38, lr: [0.008621398846589889], Loss: 2.100096, Acc:0.795189, Semantic loss: 0.796179, BCE loss: 0.545705, SB loss: 0.758212
2023-10-30 02:50:45,267 Epoch: [73/484] Iter:[280/495], Time: 0.38, lr: [0.008621016945368909], Loss: 2.104365, Acc:0.795214, Semantic loss: 0.797440, BCE loss: 0.546937, SB loss: 0.759987
2023-10-30 02:50:48,927 Epoch: [73/484] Iter:[290/495], Time: 0.37, lr: [0.008620635042268163], Loss: 2.101070, Acc:0.794727, Semantic loss: 0.796158, BCE loss: 0.545306, SB loss: 0.759606
2023-10-30 02:50:52,706 Epoch: [73/484] Iter:[300/495], Time: 0.37, lr: [0.00862025313728755], Loss: 2.097511, Acc:0.794836, Semantic loss: 0.794918, BCE loss: 0.543115, SB loss: 0.759478
2023-10-30 02:50:56,360 Epoch: [73/484] Iter:[310/495], Time: 0.37, lr: [0.008619871230426974], Loss: 2.100722, Acc:0.795143, Semantic loss: 0.794483, BCE loss: 0.544981, SB loss: 0.761258
2023-10-30 02:51:00,068 Epoch: [73/484] Iter:[320/495], Time: 0.37, lr: [0.00861948932168633], Loss: 2.106183, Acc:0.795344, Semantic loss: 0.797232, BCE loss: 0.547711, SB loss: 0.761240
2023-10-30 02:51:03,728 Epoch: [73/484] Iter:[330/495], Time: 0.37, lr: [0.00861910741106551], Loss: 2.108511, Acc:0.795793, Semantic loss: 0.798626, BCE loss: 0.547512, SB loss: 0.762373
2023-10-30 02:51:07,311 Epoch: [73/484] Iter:[340/495], Time: 0.37, lr: [0.008618725498564421], Loss: 2.108144, Acc:0.795551, Semantic loss: 0.798564, BCE loss: 0.546391, SB loss: 0.763188
2023-10-30 02:51:11,175 Epoch: [73/484] Iter:[350/495], Time: 0.37, lr: [0.008618343584182958], Loss: 2.109799, Acc:0.795261, Semantic loss: 0.799506, BCE loss: 0.547018, SB loss: 0.763275
2023-10-30 02:51:14,949 Epoch: [73/484] Iter:[360/495], Time: 0.37, lr: [0.008617961667921017], Loss: 2.110370, Acc:0.795792, Semantic loss: 0.799430, BCE loss: 0.546864, SB loss: 0.764076
2023-10-30 02:51:18,633 Epoch: [73/484] Iter:[370/495], Time: 0.37, lr: [0.0086175797497785], Loss: 2.112466, Acc:0.796020, Semantic loss: 0.801328, BCE loss: 0.546065, SB loss: 0.765074
2023-10-30 02:51:22,312 Epoch: [73/484] Iter:[380/495], Time: 0.37, lr: [0.008617197829755301], Loss: 2.117059, Acc:0.796307, Semantic loss: 0.804235, BCE loss: 0.546804, SB loss: 0.766019
2023-10-30 02:51:26,099 Epoch: [73/484] Iter:[390/495], Time: 0.37, lr: [0.00861681590785132], Loss: 2.112318, Acc:0.794720, Semantic loss: 0.801185, BCE loss: 0.546168, SB loss: 0.764965
2023-10-30 02:51:29,765 Epoch: [73/484] Iter:[400/495], Time: 0.37, lr: [0.008616433984066458], Loss: 2.112241, Acc:0.795109, Semantic loss: 0.801021, BCE loss: 0.545933, SB loss: 0.765288
2023-10-30 02:51:33,455 Epoch: [73/484] Iter:[410/495], Time: 0.37, lr: [0.008616052058400606], Loss: 2.108275, Acc:0.793876, Semantic loss: 0.799738, BCE loss: 0.543625, SB loss: 0.764912
2023-10-30 02:51:37,066 Epoch: [73/484] Iter:[420/495], Time: 0.37, lr: [0.00861567013085367], Loss: 2.107621, Acc:0.794034, Semantic loss: 0.800424, BCE loss: 0.542399, SB loss: 0.764797
2023-10-30 02:51:40,759 Epoch: [73/484] Iter:[430/495], Time: 0.37, lr: [0.008615288201425543], Loss: 2.109791, Acc:0.792628, Semantic loss: 0.801657, BCE loss: 0.542192, SB loss: 0.765942
2023-10-30 02:51:44,406 Epoch: [73/484] Iter:[440/495], Time: 0.37, lr: [0.008614906270116126], Loss: 2.108236, Acc:0.792722, Semantic loss: 0.800298, BCE loss: 0.542118, SB loss: 0.765819
2023-10-30 02:51:48,041 Epoch: [73/484] Iter:[450/495], Time: 0.37, lr: [0.008614524336925316], Loss: 2.107603, Acc:0.792155, Semantic loss: 0.800451, BCE loss: 0.541308, SB loss: 0.765844
2023-10-30 02:51:51,651 Epoch: [73/484] Iter:[460/495], Time: 0.37, lr: [0.008614142401853007], Loss: 2.105065, Acc:0.792610, Semantic loss: 0.799845, BCE loss: 0.539661, SB loss: 0.765559
2023-10-30 02:51:55,375 Epoch: [73/484] Iter:[470/495], Time: 0.37, lr: [0.008613760464899105], Loss: 2.104836, Acc:0.792352, Semantic loss: 0.799264, BCE loss: 0.540056, SB loss: 0.765516
2023-10-30 02:51:59,210 Epoch: [73/484] Iter:[480/495], Time: 0.37, lr: [0.008613378526063501], Loss: 2.106949, Acc:0.792487, Semantic loss: 0.799841, BCE loss: 0.541491, SB loss: 0.765617
2023-10-30 02:52:02,710 Epoch: [73/484] Iter:[490/495], Time: 0.37, lr: [0.008612996585346097], Loss: 2.108170, Acc:0.792420, Semantic loss: 0.800306, BCE loss: 0.542497, SB loss: 0.765367
2023-10-30 02:52:04,106 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:52:04,340 Loss: 2.134, MeanIU:  0.6400, Best_mIoU:  0.6736
2023-10-30 02:52:04,340 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215]
2023-10-30 02:52:06,384 Epoch: [74/484] Iter:[0/495], Time: 2.01, lr: [0.008612805614281687], Loss: 2.401498, Acc:0.813580, Semantic loss: 0.929882, BCE loss: 0.519940, SB loss: 0.951676
2023-10-30 02:52:10,334 Epoch: [74/484] Iter:[10/495], Time: 0.54, lr: [0.008612423670741392], Loss: 2.036724, Acc:0.802531, Semantic loss: 0.717823, BCE loss: 0.565565, SB loss: 0.753335
2023-10-30 02:52:14,050 Epoch: [74/484] Iter:[20/495], Time: 0.46, lr: [0.008612041725319038], Loss: 2.081269, Acc:0.806391, Semantic loss: 0.754829, BCE loss: 0.576308, SB loss: 0.750132
2023-10-30 02:52:17,688 Epoch: [74/484] Iter:[30/495], Time: 0.43, lr: [0.008611659778014528], Loss: 2.102697, Acc:0.803545, Semantic loss: 0.768914, BCE loss: 0.579523, SB loss: 0.754261
2023-10-30 02:52:21,411 Epoch: [74/484] Iter:[40/495], Time: 0.42, lr: [0.008611277828827755], Loss: 2.128423, Acc:0.806082, Semantic loss: 0.790636, BCE loss: 0.577547, SB loss: 0.760240
2023-10-30 02:52:25,038 Epoch: [74/484] Iter:[50/495], Time: 0.41, lr: [0.008610895877758621], Loss: 2.134252, Acc:0.801120, Semantic loss: 0.800582, BCE loss: 0.572564, SB loss: 0.761106
2023-10-30 02:52:28,746 Epoch: [74/484] Iter:[60/495], Time: 0.40, lr: [0.008610513924807023], Loss: 2.123973, Acc:0.796256, Semantic loss: 0.797989, BCE loss: 0.562217, SB loss: 0.763767
2023-10-30 02:52:32,373 Epoch: [74/484] Iter:[70/495], Time: 0.39, lr: [0.008610131969972859], Loss: 2.128127, Acc:0.793837, Semantic loss: 0.803571, BCE loss: 0.557757, SB loss: 0.766799
2023-10-30 02:52:36,122 Epoch: [74/484] Iter:[80/495], Time: 0.39, lr: [0.008609750013256024], Loss: 2.155250, Acc:0.795524, Semantic loss: 0.819283, BCE loss: 0.567969, SB loss: 0.767998
2023-10-30 02:52:39,903 Epoch: [74/484] Iter:[90/495], Time: 0.39, lr: [0.008609368054656421], Loss: 2.164396, Acc:0.797282, Semantic loss: 0.819689, BCE loss: 0.570630, SB loss: 0.774077
2023-10-30 02:52:43,687 Epoch: [74/484] Iter:[100/495], Time: 0.39, lr: [0.008608986094173945], Loss: 2.176503, Acc:0.799107, Semantic loss: 0.830280, BCE loss: 0.568791, SB loss: 0.777432
2023-10-30 02:52:47,313 Epoch: [74/484] Iter:[110/495], Time: 0.39, lr: [0.008608604131808495], Loss: 2.187793, Acc:0.797791, Semantic loss: 0.836476, BCE loss: 0.571613, SB loss: 0.779704
2023-10-30 02:52:51,022 Epoch: [74/484] Iter:[120/495], Time: 0.39, lr: [0.008608222167559966], Loss: 2.184313, Acc:0.793153, Semantic loss: 0.838101, BCE loss: 0.566078, SB loss: 0.780134
2023-10-30 02:52:54,746 Epoch: [74/484] Iter:[130/495], Time: 0.38, lr: [0.00860784020142826], Loss: 2.183211, Acc:0.793346, Semantic loss: 0.835583, BCE loss: 0.567573, SB loss: 0.780056
2023-10-30 02:52:58,418 Epoch: [74/484] Iter:[140/495], Time: 0.38, lr: [0.008607458233413271], Loss: 2.172155, Acc:0.792453, Semantic loss: 0.829965, BCE loss: 0.562574, SB loss: 0.779616
2023-10-30 02:53:02,153 Epoch: [74/484] Iter:[150/495], Time: 0.38, lr: [0.0086070762635149], Loss: 2.167682, Acc:0.794729, Semantic loss: 0.822993, BCE loss: 0.567349, SB loss: 0.777341
2023-10-30 02:53:05,766 Epoch: [74/484] Iter:[160/495], Time: 0.38, lr: [0.008606694291733044], Loss: 2.156378, Acc:0.794500, Semantic loss: 0.816767, BCE loss: 0.564064, SB loss: 0.775547
2023-10-30 02:53:09,491 Epoch: [74/484] Iter:[170/495], Time: 0.38, lr: [0.008606312318067601], Loss: 2.158165, Acc:0.794469, Semantic loss: 0.818449, BCE loss: 0.562360, SB loss: 0.777356
2023-10-30 02:53:13,185 Epoch: [74/484] Iter:[180/495], Time: 0.38, lr: [0.008605930342518466], Loss: 2.172740, Acc:0.794556, Semantic loss: 0.826112, BCE loss: 0.565389, SB loss: 0.781240
2023-10-30 02:53:16,879 Epoch: [74/484] Iter:[190/495], Time: 0.38, lr: [0.008605548365085541], Loss: 2.162524, Acc:0.793965, Semantic loss: 0.822545, BCE loss: 0.561570, SB loss: 0.778408
2023-10-30 02:53:20,564 Epoch: [74/484] Iter:[200/495], Time: 0.38, lr: [0.00860516638576872], Loss: 2.154987, Acc:0.795432, Semantic loss: 0.816097, BCE loss: 0.562299, SB loss: 0.776591
2023-10-30 02:53:24,299 Epoch: [74/484] Iter:[210/495], Time: 0.38, lr: [0.008604784404567904], Loss: 2.163244, Acc:0.794350, Semantic loss: 0.820935, BCE loss: 0.563398, SB loss: 0.778910
2023-10-30 02:53:27,996 Epoch: [74/484] Iter:[220/495], Time: 0.38, lr: [0.00860440242148299], Loss: 2.162999, Acc:0.794426, Semantic loss: 0.820469, BCE loss: 0.562844, SB loss: 0.779687
2023-10-30 02:53:31,648 Epoch: [74/484] Iter:[230/495], Time: 0.38, lr: [0.008604020436513872], Loss: 2.167685, Acc:0.795218, Semantic loss: 0.821903, BCE loss: 0.563122, SB loss: 0.782660
2023-10-30 02:53:35,331 Epoch: [74/484] Iter:[240/495], Time: 0.38, lr: [0.008603638449660455], Loss: 2.162337, Acc:0.794498, Semantic loss: 0.819831, BCE loss: 0.559666, SB loss: 0.782840
2023-10-30 02:53:39,079 Epoch: [74/484] Iter:[250/495], Time: 0.38, lr: [0.008603256460922632], Loss: 2.162165, Acc:0.794198, Semantic loss: 0.818987, BCE loss: 0.560626, SB loss: 0.782552
2023-10-30 02:53:42,753 Epoch: [74/484] Iter:[260/495], Time: 0.38, lr: [0.0086028744703003], Loss: 2.163469, Acc:0.793972, Semantic loss: 0.819637, BCE loss: 0.562559, SB loss: 0.781272
2023-10-30 02:53:46,424 Epoch: [74/484] Iter:[270/495], Time: 0.38, lr: [0.008602492477793358], Loss: 2.157104, Acc:0.792787, Semantic loss: 0.816529, BCE loss: 0.560559, SB loss: 0.780016
2023-10-30 02:53:50,191 Epoch: [74/484] Iter:[280/495], Time: 0.38, lr: [0.008602110483401705], Loss: 2.154880, Acc:0.791652, Semantic loss: 0.815649, BCE loss: 0.558738, SB loss: 0.780494
2023-10-30 02:53:53,828 Epoch: [74/484] Iter:[290/495], Time: 0.38, lr: [0.008601728487125237], Loss: 2.153031, Acc:0.790759, Semantic loss: 0.813768, BCE loss: 0.559238, SB loss: 0.780025
2023-10-30 02:53:57,551 Epoch: [74/484] Iter:[300/495], Time: 0.38, lr: [0.008601346488963853], Loss: 2.156158, Acc:0.790613, Semantic loss: 0.814855, BCE loss: 0.560841, SB loss: 0.780462
2023-10-30 02:54:01,166 Epoch: [74/484] Iter:[310/495], Time: 0.38, lr: [0.008600964488917449], Loss: 2.152488, Acc:0.790905, Semantic loss: 0.813370, BCE loss: 0.559403, SB loss: 0.779716
2023-10-30 02:54:04,835 Epoch: [74/484] Iter:[320/495], Time: 0.38, lr: [0.008600582486985925], Loss: 2.160209, Acc:0.790889, Semantic loss: 0.818963, BCE loss: 0.560137, SB loss: 0.781109
2023-10-30 02:54:08,516 Epoch: [74/484] Iter:[330/495], Time: 0.38, lr: [0.008600200483169175], Loss: 2.159947, Acc:0.790534, Semantic loss: 0.818563, BCE loss: 0.559559, SB loss: 0.781826
2023-10-30 02:54:12,228 Epoch: [74/484] Iter:[340/495], Time: 0.37, lr: [0.008599818477467101], Loss: 2.160716, Acc:0.790862, Semantic loss: 0.818066, BCE loss: 0.560804, SB loss: 0.781846
2023-10-30 02:54:15,869 Epoch: [74/484] Iter:[350/495], Time: 0.37, lr: [0.008599436469879597], Loss: 2.164854, Acc:0.789505, Semantic loss: 0.819989, BCE loss: 0.561568, SB loss: 0.783298
2023-10-30 02:54:19,521 Epoch: [74/484] Iter:[360/495], Time: 0.37, lr: [0.008599054460406564], Loss: 2.162230, Acc:0.788221, Semantic loss: 0.819885, BCE loss: 0.559904, SB loss: 0.782442
2023-10-30 02:54:23,136 Epoch: [74/484] Iter:[370/495], Time: 0.37, lr: [0.008598672449047898], Loss: 2.159890, Acc:0.787057, Semantic loss: 0.819021, BCE loss: 0.558483, SB loss: 0.782386
2023-10-30 02:54:26,850 Epoch: [74/484] Iter:[380/495], Time: 0.37, lr: [0.008598290435803495], Loss: 2.158154, Acc:0.787078, Semantic loss: 0.817460, BCE loss: 0.558725, SB loss: 0.781969
2023-10-30 02:54:30,514 Epoch: [74/484] Iter:[390/495], Time: 0.37, lr: [0.008597908420673255], Loss: 2.157879, Acc:0.786779, Semantic loss: 0.818194, BCE loss: 0.558118, SB loss: 0.781567
2023-10-30 02:54:34,193 Epoch: [74/484] Iter:[400/495], Time: 0.37, lr: [0.008597526403657072], Loss: 2.156925, Acc:0.787769, Semantic loss: 0.816225, BCE loss: 0.559111, SB loss: 0.781589
2023-10-30 02:54:37,899 Epoch: [74/484] Iter:[410/495], Time: 0.37, lr: [0.00859714438475485], Loss: 2.158733, Acc:0.787454, Semantic loss: 0.817052, BCE loss: 0.560289, SB loss: 0.781392
2023-10-30 02:54:41,488 Epoch: [74/484] Iter:[420/495], Time: 0.37, lr: [0.008596762363966481], Loss: 2.157818, Acc:0.787451, Semantic loss: 0.816514, BCE loss: 0.561424, SB loss: 0.779880
2023-10-30 02:54:45,255 Epoch: [74/484] Iter:[430/495], Time: 0.37, lr: [0.008596380341291867], Loss: 2.157288, Acc:0.787498, Semantic loss: 0.815238, BCE loss: 0.562150, SB loss: 0.779900
2023-10-30 02:54:48,976 Epoch: [74/484] Iter:[440/495], Time: 0.37, lr: [0.008595998316730899], Loss: 2.157079, Acc:0.787247, Semantic loss: 0.814939, BCE loss: 0.561877, SB loss: 0.780263
2023-10-30 02:54:52,664 Epoch: [74/484] Iter:[450/495], Time: 0.37, lr: [0.00859561629028348], Loss: 2.155015, Acc:0.787397, Semantic loss: 0.814076, BCE loss: 0.560657, SB loss: 0.780282
2023-10-30 02:54:56,431 Epoch: [74/484] Iter:[460/495], Time: 0.37, lr: [0.008595234261949507], Loss: 2.158204, Acc:0.787910, Semantic loss: 0.815390, BCE loss: 0.561796, SB loss: 0.781018
2023-10-30 02:55:00,092 Epoch: [74/484] Iter:[470/495], Time: 0.37, lr: [0.008594852231728874], Loss: 2.155575, Acc:0.788733, Semantic loss: 0.813946, BCE loss: 0.561208, SB loss: 0.780421
2023-10-30 02:55:03,729 Epoch: [74/484] Iter:[480/495], Time: 0.37, lr: [0.008594470199621484], Loss: 2.159611, Acc:0.788852, Semantic loss: 0.816196, BCE loss: 0.561933, SB loss: 0.781482
2023-10-30 02:55:07,260 Epoch: [74/484] Iter:[490/495], Time: 0.37, lr: [0.00859408816562723], Loss: 2.156061, Acc:0.788950, Semantic loss: 0.814199, BCE loss: 0.561732, SB loss: 0.780131
2023-10-30 02:55:08,664 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 02:55:08,902 Loss: 2.134, MeanIU:  0.6400, Best_mIoU:  0.6736
2023-10-30 02:55:08,902 [0.96841716 0.77885078 0.86731487 0.33781784 0.46617414 0.52538595
 0.62015869 0.70212179 0.90421951 0.51883627 0.90433891 0.75107643
 0.52236655 0.89440226 0.18173306 0.61200441 0.48515709 0.40795387
 0.71183215]
2023-10-30 02:55:10,728 Epoch: [75/484] Iter:[0/495], Time: 1.79, lr: [0.008593897147922499], Loss: 2.300007, Acc:0.825892, Semantic loss: 1.164985, BCE loss: 0.376529, SB loss: 0.758493
2023-10-30 02:55:14,796 Epoch: [75/484] Iter:[10/495], Time: 0.53, lr: [0.008593515111097759], Loss: 2.143864, Acc:0.795829, Semantic loss: 0.826117, BCE loss: 0.557339, SB loss: 0.760409
2023-10-30 02:55:18,511 Epoch: [75/484] Iter:[20/495], Time: 0.46, lr: [0.008593133072385899], Loss: 2.125508, Acc:0.795058, Semantic loss: 0.805865, BCE loss: 0.555067, SB loss: 0.764577
2023-10-30 02:55:22,170 Epoch: [75/484] Iter:[30/495], Time: 0.43, lr: [0.008592751031786819], Loss: 2.109745, Acc:0.787421, Semantic loss: 0.792282, BCE loss: 0.557158, SB loss: 0.760305
2023-10-30 02:55:25,817 Epoch: [75/484] Iter:[40/495], Time: 0.41, lr: [0.008592368989300415], Loss: 2.082994, Acc:0.787446, Semantic loss: 0.781895, BCE loss: 0.543298, SB loss: 0.757801
2023-10-30 02:55:29,426 Epoch: [75/484] Iter:[50/495], Time: 0.40, lr: [0.008591986944926584], Loss: 2.070571, Acc:0.787595, Semantic loss: 0.773645, BCE loss: 0.546870, SB loss: 0.750057
2023-10-30 02:55:33,045 Epoch: [75/484] Iter:[60/495], Time: 0.40, lr: [0.008591604898665225], Loss: 2.073694, Acc:0.791128, Semantic loss: 0.768653, BCE loss: 0.549925, SB loss: 0.755117
2023-10-30 02:55:36,866 Epoch: [75/484] Iter:[70/495], Time: 0.39, lr: [0.008591222850516235], Loss: 2.091322, Acc:0.791231, Semantic loss: 0.777467, BCE loss: 0.550831, SB loss: 0.763023
2023-10-30 02:55:40,600 Epoch: [75/484] Iter:[80/495], Time: 0.39, lr: [0.00859084080047951], Loss: 2.107469, Acc:0.792847, Semantic loss: 0.782278, BCE loss: 0.559890, SB loss: 0.765301
2023-10-30 02:55:44,186 Epoch: [75/484] Iter:[90/495], Time: 0.39, lr: [0.008590458748554948], Loss: 2.091364, Acc:0.793538, Semantic loss: 0.774769, BCE loss: 0.558692, SB loss: 0.757904
2023-10-30 02:55:47,846 Epoch: [75/484] Iter:[100/495], Time: 0.39, lr: [0.008590076694742444], Loss: 2.098267, Acc:0.790540, Semantic loss: 0.783333, BCE loss: 0.555455, SB loss: 0.759479
2023-10-30 02:55:51,462 Epoch: [75/484] Iter:[110/495], Time: 0.38, lr: [0.008589694639041901], Loss: 2.116430, Acc:0.793945, Semantic loss: 0.791833, BCE loss: 0.561412, SB loss: 0.763184
2023-10-30 02:55:55,114 Epoch: [75/484] Iter:[120/495], Time: 0.38, lr: [0.008589312581453214], Loss: 2.115716, Acc:0.793511, Semantic loss: 0.795753, BCE loss: 0.560864, SB loss: 0.759100
2023-10-30 02:55:58,846 Epoch: [75/484] Iter:[130/495], Time: 0.38, lr: [0.008588930521976276], Loss: 2.123769, Acc:0.794922, Semantic loss: 0.798121, BCE loss: 0.564637, SB loss: 0.761012
2023-10-30 02:56:02,501 Epoch: [75/484] Iter:[140/495], Time: 0.38, lr: [0.008588548460610992], Loss: 2.126197, Acc:0.796036, Semantic loss: 0.799262, BCE loss: 0.565696, SB loss: 0.761239
2023-10-30 02:56:06,239 Epoch: [75/484] Iter:[150/495], Time: 0.38, lr: [0.008588166397357253], Loss: 2.128576, Acc:0.798271, Semantic loss: 0.797540, BCE loss: 0.569852, SB loss: 0.761185
2023-10-30 02:56:09,957 Epoch: [75/484] Iter:[160/495], Time: 0.38, lr: [0.00858778433221496], Loss: 2.122285, Acc:0.801801, Semantic loss: 0.793370, BCE loss: 0.569477, SB loss: 0.759438
2023-10-30 02:56:13,576 Epoch: [75/484] Iter:[170/495], Time: 0.38, lr: [0.008587402265184008], Loss: 2.116875, Acc:0.803719, Semantic loss: 0.790368, BCE loss: 0.568345, SB loss: 0.758162
2023-10-30 02:56:17,197 Epoch: [75/484] Iter:[180/495], Time: 0.38, lr: [0.008587020196264294], Loss: 2.136468, Acc:0.800157, Semantic loss: 0.803858, BCE loss: 0.567830, SB loss: 0.764779
2023-10-30 02:56:20,856 Epoch: [75/484] Iter:[190/495], Time: 0.38, lr: [0.008586638125455718], Loss: 2.138024, Acc:0.798263, Semantic loss: 0.806629, BCE loss: 0.565705, SB loss: 0.765689
2023-10-30 02:56:24,621 Epoch: [75/484] Iter:[200/495], Time: 0.38, lr: [0.008586256052758175], Loss: 2.142462, Acc:0.797791, Semantic loss: 0.808739, BCE loss: 0.566525, SB loss: 0.767198
2023-10-30 02:56:28,341 Epoch: [75/484] Iter:[210/495], Time: 0.38, lr: [0.008585873978171564], Loss: 2.136691, Acc:0.796754, Semantic loss: 0.806886, BCE loss: 0.563535, SB loss: 0.766270
2023-10-30 02:56:32,043 Epoch: [75/484] Iter:[220/495], Time: 0.38, lr: [0.00858549190169578], Loss: 2.132294, Acc:0.794733, Semantic loss: 0.804997, BCE loss: 0.560938, SB loss: 0.766359
2023-10-30 02:56:35,739 Epoch: [75/484] Iter:[230/495], Time: 0.38, lr: [0.008585109823330724], Loss: 2.129104, Acc:0.794359, Semantic loss: 0.803844, BCE loss: 0.558731, SB loss: 0.766528
2023-10-30 02:56:39,463 Epoch: [75/484] Iter:[240/495], Time: 0.38, lr: [0.008584727743076288], Loss: 2.133488, Acc:0.794145, Semantic loss: 0.807869, BCE loss: 0.558584, SB loss: 0.767035
2023-10-30 02:56:43,154 Epoch: [75/484] Iter:[250/495], Time: 0.38, lr: [0.008584345660932373], Loss: 2.129932, Acc:0.793695, Semantic loss: 0.805831, BCE loss: 0.558565, SB loss: 0.765537
2023-10-30 02:56:47,043 Epoch: [75/484] Iter:[260/495], Time: 0.38, lr: [0.008583963576898876], Loss: 2.129275, Acc:0.795819, Semantic loss: 0.804180, BCE loss: 0.559431, SB loss: 0.765664
2023-10-30 02:56:50,828 Epoch: [75/484] Iter:[270/495], Time: 0.38, lr: [0.008583581490975692], Loss: 2.130122, Acc:0.796599, Semantic loss: 0.803631, BCE loss: 0.559721, SB loss: 0.766770
2023-10-30 02:56:54,574 Epoch: [75/484] Iter:[280/495], Time: 0.38, lr: [0.00858319940316272], Loss: 2.127439, Acc:0.796450, Semantic loss: 0.801963, BCE loss: 0.559219, SB loss: 0.766257
2023-10-30 02:56:58,258 Epoch: [75/484] Iter:[290/495], Time: 0.38, lr: [0.008582817313459858], Loss: 2.130984, Acc:0.796444, Semantic loss: 0.804369, BCE loss: 0.558398, SB loss: 0.768218
2023-10-30 02:57:01,989 Epoch: [75/484] Iter:[300/495], Time: 0.38, lr: [0.008582435221867], Loss: 2.123794, Acc:0.796418, Semantic loss: 0.801340, BCE loss: 0.555986, SB loss: 0.766467
2023-10-30 02:57:05,687 Epoch: [75/484] Iter:[310/495], Time: 0.38, lr: [0.008582053128384046], Loss: 2.124306, Acc:0.796995, Semantic loss: 0.802306, BCE loss: 0.555826, SB loss: 0.766174
2023-10-30 02:57:09,446 Epoch: [75/484] Iter:[320/495], Time: 0.38, lr: [0.008581671033010893], Loss: 2.129030, Acc:0.797519, Semantic loss: 0.804265, BCE loss: 0.557862, SB loss: 0.766903
2023-10-30 02:57:13,174 Epoch: [75/484] Iter:[330/495], Time: 0.38, lr: [0.008581288935747437], Loss: 2.134815, Acc:0.797439, Semantic loss: 0.807239, BCE loss: 0.558275, SB loss: 0.769301
2023-10-30 02:57:16,847 Epoch: [75/484] Iter:[340/495], Time: 0.38, lr: [0.008580906836593575], Loss: 2.133864, Acc:0.797684, Semantic loss: 0.806279, BCE loss: 0.557962, SB loss: 0.769623
2023-10-30 02:57:20,467 Epoch: [75/484] Iter:[350/495], Time: 0.37, lr: [0.008580524735549206], Loss: 2.133855, Acc:0.798085, Semantic loss: 0.806071, BCE loss: 0.558250, SB loss: 0.769534
2023-10-30 02:57:24,176 Epoch: [75/484] Iter:[360/495], Time: 0.37, lr: [0.008580142632614224], Loss: 2.133858, Acc:0.797876, Semantic loss: 0.805804, BCE loss: 0.557999, SB loss: 0.770055
2023-10-30 02:57:27,824 Epoch: [75/484] Iter:[370/495], Time: 0.37, lr: [0.008579760527788529], Loss: 2.132150, Acc:0.798441, Semantic loss: 0.804727, BCE loss: 0.557958, SB loss: 0.769466
2023-10-30 02:57:31,427 Epoch: [75/484] Iter:[380/495], Time: 0.37, lr: [0.008579378421072014], Loss: 2.130375, Acc:0.798016, Semantic loss: 0.804597, BCE loss: 0.556526, SB loss: 0.769253
2023-10-30 02:57:35,134 Epoch: [75/484] Iter:[390/495], Time: 0.37, lr: [0.008578996312464584], Loss: 2.133580, Acc:0.797825, Semantic loss: 0.807138, BCE loss: 0.556355, SB loss: 0.770088
2023-10-30 02:57:38,794 Epoch: [75/484] Iter:[400/495], Time: 0.37, lr: [0.008578614201966128], Loss: 2.139187, Acc:0.797083, Semantic loss: 0.810560, BCE loss: 0.557650, SB loss: 0.770976
2023-10-30 02:57:42,550 Epoch: [75/484] Iter:[410/495], Time: 0.37, lr: [0.008578232089576546], Loss: 2.139499, Acc:0.796511, Semantic loss: 0.811110, BCE loss: 0.557088, SB loss: 0.771301
2023-10-30 02:57:46,206 Epoch: [75/484] Iter:[420/495], Time: 0.37, lr: [0.008577849975295735], Loss: 2.144613, Acc:0.796643, Semantic loss: 0.814125, BCE loss: 0.558336, SB loss: 0.772152
2023-10-30 02:57:49,865 Epoch: [75/484] Iter:[430/495], Time: 0.37, lr: [0.008577467859123594], Loss: 2.145365, Acc:0.796034, Semantic loss: 0.813994, BCE loss: 0.558422, SB loss: 0.772950
2023-10-30 02:57:53,522 Epoch: [75/484] Iter:[440/495], Time: 0.37, lr: [0.008577085741060017], Loss: 2.146177, Acc:0.796218, Semantic loss: 0.812880, BCE loss: 0.559479, SB loss: 0.773818
2023-10-30 02:57:57,265 Epoch: [75/484] Iter:[450/495], Time: 0.37, lr: [0.008576703621104902], Loss: 2.146008, Acc:0.795589, Semantic loss: 0.812543, BCE loss: 0.559374, SB loss: 0.774091
2023-10-30 02:58:01,025 Epoch: [75/484] Iter:[460/495], Time: 0.37, lr: [0.008576321499258147], Loss: 2.144229, Acc:0.794967, Semantic loss: 0.811493, BCE loss: 0.558591, SB loss: 0.774145
2023-10-30 02:58:04,803 Epoch: [75/484] Iter:[470/495], Time: 0.37, lr: [0.008575939375519646], Loss: 2.145372, Acc:0.794846, Semantic loss: 0.812328, BCE loss: 0.559215, SB loss: 0.773829
2023-10-30 02:58:08,518 Epoch: [75/484] Iter:[480/495], Time: 0.37, lr: [0.008575557249889301], Loss: 2.153395, Acc:0.795236, Semantic loss: 0.817177, BCE loss: 0.560058, SB loss: 0.776159
2023-10-30 02:58:12,050 Epoch: [75/484] Iter:[490/495], Time: 0.37, lr: [0.008575175122367005], Loss: 2.153633, Acc:0.796139, Semantic loss: 0.816337, BCE loss: 0.560345, SB loss: 0.776951
2023-10-30 03:01:08,698 0 [0.93153892 0.59873378 0.79651289 0.10882473 0.24615669 0.39835719
 0.41305801 0.56869913 0.85801064 0.4194861  0.81753342 0.50503399
 0.00251519 0.73784576 0.         0.04997667 0.02212274 0.00720647
 0.53869485] 0.4221214295250104
2023-10-30 03:01:08,698 1 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593] 0.6045160818514066
2023-10-30 03:01:08,702 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:01:08,944 Loss: 2.135, MeanIU:  0.6045, Best_mIoU:  0.6736
2023-10-30 03:01:08,945 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593]
2023-10-30 03:01:11,123 Epoch: [76/484] Iter:[0/495], Time: 2.15, lr: [0.008574984057896343], Loss: 2.049381, Acc:0.756338, Semantic loss: 0.648363, BCE loss: 0.653326, SB loss: 0.747692
2023-10-30 03:01:14,809 Epoch: [76/484] Iter:[10/495], Time: 0.53, lr: [0.00857460192753593], Loss: 2.122185, Acc:0.784333, Semantic loss: 0.770036, BCE loss: 0.604205, SB loss: 0.747944
2023-10-30 03:01:18,277 Epoch: [76/484] Iter:[20/495], Time: 0.44, lr: [0.008574219795283307], Loss: 2.022061, Acc:0.791149, Semantic loss: 0.731930, BCE loss: 0.545979, SB loss: 0.744152
2023-10-30 03:01:21,767 Epoch: [76/484] Iter:[30/495], Time: 0.41, lr: [0.008573837661138374], Loss: 2.058481, Acc:0.781042, Semantic loss: 0.767152, BCE loss: 0.537676, SB loss: 0.753653
2023-10-30 03:01:25,170 Epoch: [76/484] Iter:[40/495], Time: 0.39, lr: [0.008573455525101028], Loss: 2.171881, Acc:0.780202, Semantic loss: 0.834264, BCE loss: 0.557455, SB loss: 0.780162
2023-10-30 03:01:28,632 Epoch: [76/484] Iter:[50/495], Time: 0.39, lr: [0.008573073387171167], Loss: 2.145588, Acc:0.779365, Semantic loss: 0.822806, BCE loss: 0.547692, SB loss: 0.775090
2023-10-30 03:01:32,222 Epoch: [76/484] Iter:[60/495], Time: 0.38, lr: [0.008572691247348684], Loss: 2.170292, Acc:0.780533, Semantic loss: 0.837596, BCE loss: 0.551555, SB loss: 0.781141
2023-10-30 03:01:35,778 Epoch: [76/484] Iter:[70/495], Time: 0.38, lr: [0.00857230910563348], Loss: 2.179764, Acc:0.781314, Semantic loss: 0.836530, BCE loss: 0.557199, SB loss: 0.786036
2023-10-30 03:01:39,293 Epoch: [76/484] Iter:[80/495], Time: 0.37, lr: [0.008571926962025446], Loss: 2.178783, Acc:0.778220, Semantic loss: 0.839862, BCE loss: 0.551364, SB loss: 0.787557
2023-10-30 03:01:42,795 Epoch: [76/484] Iter:[90/495], Time: 0.37, lr: [0.008571544816524486], Loss: 2.169610, Acc:0.778293, Semantic loss: 0.830850, BCE loss: 0.553978, SB loss: 0.784782
2023-10-30 03:01:46,467 Epoch: [76/484] Iter:[100/495], Time: 0.37, lr: [0.008571162669130493], Loss: 2.167349, Acc:0.780572, Semantic loss: 0.828287, BCE loss: 0.553042, SB loss: 0.786021
2023-10-30 03:01:50,082 Epoch: [76/484] Iter:[110/495], Time: 0.37, lr: [0.008570780519843363], Loss: 2.152679, Acc:0.785116, Semantic loss: 0.818404, BCE loss: 0.551890, SB loss: 0.782386
2023-10-30 03:01:53,730 Epoch: [76/484] Iter:[120/495], Time: 0.37, lr: [0.008570398368662996], Loss: 2.162658, Acc:0.782997, Semantic loss: 0.823485, BCE loss: 0.552966, SB loss: 0.786208
2023-10-30 03:01:57,428 Epoch: [76/484] Iter:[130/495], Time: 0.37, lr: [0.008570016215589287], Loss: 2.176545, Acc:0.783873, Semantic loss: 0.831064, BCE loss: 0.552778, SB loss: 0.792702
2023-10-30 03:02:00,975 Epoch: [76/484] Iter:[140/495], Time: 0.37, lr: [0.008569634060622132], Loss: 2.181398, Acc:0.782739, Semantic loss: 0.829066, BCE loss: 0.557892, SB loss: 0.794440
2023-10-30 03:02:04,654 Epoch: [76/484] Iter:[150/495], Time: 0.37, lr: [0.00856925190376143], Loss: 2.188128, Acc:0.784099, Semantic loss: 0.832339, BCE loss: 0.559035, SB loss: 0.796754
2023-10-30 03:02:08,285 Epoch: [76/484] Iter:[160/495], Time: 0.37, lr: [0.008568869745007075], Loss: 2.178765, Acc:0.786202, Semantic loss: 0.825288, BCE loss: 0.560192, SB loss: 0.793285
2023-10-30 03:02:11,974 Epoch: [76/484] Iter:[170/495], Time: 0.37, lr: [0.008568487584358965], Loss: 2.188472, Acc:0.786815, Semantic loss: 0.829573, BCE loss: 0.562930, SB loss: 0.795968
2023-10-30 03:02:15,523 Epoch: [76/484] Iter:[180/495], Time: 0.37, lr: [0.008568105421817], Loss: 2.174859, Acc:0.789199, Semantic loss: 0.821724, BCE loss: 0.561905, SB loss: 0.791229
2023-10-30 03:02:19,072 Epoch: [76/484] Iter:[190/495], Time: 0.37, lr: [0.008567723257381072], Loss: 2.170566, Acc:0.790069, Semantic loss: 0.822128, BCE loss: 0.559597, SB loss: 0.788841
2023-10-30 03:02:22,804 Epoch: [76/484] Iter:[200/495], Time: 0.37, lr: [0.008567341091051079], Loss: 2.167286, Acc:0.789393, Semantic loss: 0.818407, BCE loss: 0.560173, SB loss: 0.788706
2023-10-30 03:02:26,506 Epoch: [76/484] Iter:[210/495], Time: 0.37, lr: [0.008566958922826919], Loss: 2.171750, Acc:0.789125, Semantic loss: 0.821792, BCE loss: 0.559002, SB loss: 0.790956
2023-10-30 03:02:30,207 Epoch: [76/484] Iter:[220/495], Time: 0.37, lr: [0.008566576752708489], Loss: 2.169354, Acc:0.790240, Semantic loss: 0.820822, BCE loss: 0.558615, SB loss: 0.789917
2023-10-30 03:02:33,755 Epoch: [76/484] Iter:[230/495], Time: 0.37, lr: [0.008566194580695682], Loss: 2.169291, Acc:0.791535, Semantic loss: 0.819179, BCE loss: 0.560946, SB loss: 0.789166
2023-10-30 03:02:37,395 Epoch: [76/484] Iter:[240/495], Time: 0.37, lr: [0.008565812406788399], Loss: 2.167849, Acc:0.791762, Semantic loss: 0.818345, BCE loss: 0.560832, SB loss: 0.788672
2023-10-30 03:02:40,961 Epoch: [76/484] Iter:[250/495], Time: 0.37, lr: [0.008565430230986534], Loss: 2.164580, Acc:0.791635, Semantic loss: 0.818012, BCE loss: 0.557744, SB loss: 0.788824
2023-10-30 03:02:44,603 Epoch: [76/484] Iter:[260/495], Time: 0.37, lr: [0.008565048053289987], Loss: 2.162117, Acc:0.793159, Semantic loss: 0.818459, BCE loss: 0.555592, SB loss: 0.788067
2023-10-30 03:02:48,413 Epoch: [76/484] Iter:[270/495], Time: 0.37, lr: [0.00856466587369865], Loss: 2.155595, Acc:0.792888, Semantic loss: 0.816752, BCE loss: 0.552538, SB loss: 0.786305
2023-10-30 03:02:52,002 Epoch: [76/484] Iter:[280/495], Time: 0.37, lr: [0.008564283692212425], Loss: 2.152408, Acc:0.793550, Semantic loss: 0.813838, BCE loss: 0.554225, SB loss: 0.784346
2023-10-30 03:02:55,628 Epoch: [76/484] Iter:[290/495], Time: 0.37, lr: [0.008563901508831205], Loss: 2.147492, Acc:0.792040, Semantic loss: 0.812415, BCE loss: 0.550904, SB loss: 0.784172
2023-10-30 03:02:59,267 Epoch: [76/484] Iter:[300/495], Time: 0.37, lr: [0.008563519323554886], Loss: 2.157492, Acc:0.792251, Semantic loss: 0.818396, BCE loss: 0.552507, SB loss: 0.786589
2023-10-30 03:03:02,947 Epoch: [76/484] Iter:[310/495], Time: 0.37, lr: [0.008563137136383367], Loss: 2.169556, Acc:0.791889, Semantic loss: 0.825458, BCE loss: 0.555253, SB loss: 0.788846
2023-10-30 03:03:06,616 Epoch: [76/484] Iter:[320/495], Time: 0.37, lr: [0.008562754947316542], Loss: 2.166118, Acc:0.791713, Semantic loss: 0.823222, BCE loss: 0.554492, SB loss: 0.788404
2023-10-30 03:03:10,330 Epoch: [76/484] Iter:[330/495], Time: 0.37, lr: [0.008562372756354311], Loss: 2.161961, Acc:0.791116, Semantic loss: 0.822786, BCE loss: 0.552388, SB loss: 0.786787
2023-10-30 03:03:14,097 Epoch: [76/484] Iter:[340/495], Time: 0.37, lr: [0.008561990563496569], Loss: 2.163867, Acc:0.791436, Semantic loss: 0.823576, BCE loss: 0.553090, SB loss: 0.787201
2023-10-30 03:03:17,714 Epoch: [76/484] Iter:[350/495], Time: 0.37, lr: [0.008561608368743211], Loss: 2.168163, Acc:0.792014, Semantic loss: 0.826906, BCE loss: 0.554006, SB loss: 0.787251
2023-10-30 03:03:21,299 Epoch: [76/484] Iter:[360/495], Time: 0.37, lr: [0.008561226172094136], Loss: 2.167230, Acc:0.792758, Semantic loss: 0.826634, BCE loss: 0.553736, SB loss: 0.786860
2023-10-30 03:03:25,035 Epoch: [76/484] Iter:[370/495], Time: 0.37, lr: [0.00856084397354924], Loss: 2.160527, Acc:0.792349, Semantic loss: 0.822948, BCE loss: 0.551970, SB loss: 0.785609
2023-10-30 03:03:28,604 Epoch: [76/484] Iter:[380/495], Time: 0.37, lr: [0.00856046177310842], Loss: 2.158901, Acc:0.792076, Semantic loss: 0.822442, BCE loss: 0.551743, SB loss: 0.784716
2023-10-30 03:03:32,255 Epoch: [76/484] Iter:[390/495], Time: 0.37, lr: [0.008560079570771569], Loss: 2.155786, Acc:0.792294, Semantic loss: 0.819996, BCE loss: 0.552254, SB loss: 0.783536
2023-10-30 03:03:35,972 Epoch: [76/484] Iter:[400/495], Time: 0.37, lr: [0.008559697366538587], Loss: 2.161519, Acc:0.791061, Semantic loss: 0.824391, BCE loss: 0.551940, SB loss: 0.785188
2023-10-30 03:03:39,628 Epoch: [76/484] Iter:[410/495], Time: 0.37, lr: [0.008559315160409371], Loss: 2.160425, Acc:0.790324, Semantic loss: 0.823213, BCE loss: 0.552107, SB loss: 0.785105
2023-10-30 03:03:43,340 Epoch: [76/484] Iter:[420/495], Time: 0.37, lr: [0.008558932952383816], Loss: 2.159298, Acc:0.790590, Semantic loss: 0.822740, BCE loss: 0.552046, SB loss: 0.784513
2023-10-30 03:03:46,884 Epoch: [76/484] Iter:[430/495], Time: 0.37, lr: [0.008558550742461818], Loss: 2.159661, Acc:0.789480, Semantic loss: 0.823874, BCE loss: 0.550524, SB loss: 0.785263
2023-10-30 03:03:50,638 Epoch: [76/484] Iter:[440/495], Time: 0.37, lr: [0.008558168530643274], Loss: 2.158098, Acc:0.789481, Semantic loss: 0.821581, BCE loss: 0.551953, SB loss: 0.784564
2023-10-30 03:03:54,377 Epoch: [76/484] Iter:[450/495], Time: 0.37, lr: [0.008557786316928082], Loss: 2.157556, Acc:0.790122, Semantic loss: 0.820442, BCE loss: 0.552621, SB loss: 0.784492
2023-10-30 03:03:58,054 Epoch: [76/484] Iter:[460/495], Time: 0.37, lr: [0.008557404101316137], Loss: 2.158966, Acc:0.789231, Semantic loss: 0.821746, BCE loss: 0.552200, SB loss: 0.785020
2023-10-30 03:04:01,722 Epoch: [76/484] Iter:[470/495], Time: 0.37, lr: [0.008557021883807333], Loss: 2.158919, Acc:0.788813, Semantic loss: 0.820334, BCE loss: 0.553243, SB loss: 0.785343
2023-10-30 03:04:05,550 Epoch: [76/484] Iter:[480/495], Time: 0.37, lr: [0.008556639664401572], Loss: 2.158708, Acc:0.788743, Semantic loss: 0.821197, BCE loss: 0.552392, SB loss: 0.785119
2023-10-30 03:04:09,024 Epoch: [76/484] Iter:[490/495], Time: 0.37, lr: [0.008556257443098748], Loss: 2.161756, Acc:0.788895, Semantic loss: 0.823804, BCE loss: 0.552697, SB loss: 0.785256
2023-10-30 03:04:10,409 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:04:10,651 Loss: 2.135, MeanIU:  0.6045, Best_mIoU:  0.6736
2023-10-30 03:04:10,651 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593]
2023-10-30 03:04:12,447 Epoch: [77/484] Iter:[0/495], Time: 1.76, lr: [0.008556066331735904], Loss: 1.636022, Acc:0.706198, Semantic loss: 0.605253, BCE loss: 0.349567, SB loss: 0.681202
2023-10-30 03:04:16,584 Epoch: [77/484] Iter:[10/495], Time: 0.54, lr: [0.008555684107587287], Loss: 1.946128, Acc:0.787382, Semantic loss: 0.737372, BCE loss: 0.468409, SB loss: 0.740347
2023-10-30 03:04:20,275 Epoch: [77/484] Iter:[20/495], Time: 0.46, lr: [0.008555301881541352], Loss: 2.019880, Acc:0.804213, Semantic loss: 0.766020, BCE loss: 0.503856, SB loss: 0.750004
2023-10-30 03:04:24,061 Epoch: [77/484] Iter:[30/495], Time: 0.43, lr: [0.008554919653597988], Loss: 2.049064, Acc:0.807820, Semantic loss: 0.761083, BCE loss: 0.522645, SB loss: 0.765335
2023-10-30 03:04:27,734 Epoch: [77/484] Iter:[40/495], Time: 0.42, lr: [0.008554537423757095], Loss: 2.064326, Acc:0.811957, Semantic loss: 0.763065, BCE loss: 0.536124, SB loss: 0.765137
2023-10-30 03:04:31,425 Epoch: [77/484] Iter:[50/495], Time: 0.41, lr: [0.008554155192018568], Loss: 2.069909, Acc:0.810828, Semantic loss: 0.769109, BCE loss: 0.539453, SB loss: 0.761347
2023-10-30 03:04:35,168 Epoch: [77/484] Iter:[60/495], Time: 0.40, lr: [0.008553772958382303], Loss: 2.062126, Acc:0.811013, Semantic loss: 0.762463, BCE loss: 0.544523, SB loss: 0.755139
2023-10-30 03:04:38,895 Epoch: [77/484] Iter:[70/495], Time: 0.40, lr: [0.0085533907228482], Loss: 2.050653, Acc:0.807882, Semantic loss: 0.759255, BCE loss: 0.537803, SB loss: 0.753595
2023-10-30 03:04:42,589 Epoch: [77/484] Iter:[80/495], Time: 0.39, lr: [0.008553008485416153], Loss: 2.048096, Acc:0.802558, Semantic loss: 0.762484, BCE loss: 0.526593, SB loss: 0.759019
2023-10-30 03:04:46,294 Epoch: [77/484] Iter:[90/495], Time: 0.39, lr: [0.008552626246086055], Loss: 2.032203, Acc:0.801588, Semantic loss: 0.756976, BCE loss: 0.518495, SB loss: 0.756732
2023-10-30 03:04:49,923 Epoch: [77/484] Iter:[100/495], Time: 0.39, lr: [0.008552244004857807], Loss: 2.043687, Acc:0.798310, Semantic loss: 0.764500, BCE loss: 0.521817, SB loss: 0.757370
2023-10-30 03:04:53,639 Epoch: [77/484] Iter:[110/495], Time: 0.39, lr: [0.008551861761731306], Loss: 2.045101, Acc:0.795264, Semantic loss: 0.763109, BCE loss: 0.523722, SB loss: 0.758270
2023-10-30 03:04:57,381 Epoch: [77/484] Iter:[120/495], Time: 0.39, lr: [0.008551479516706442], Loss: 2.061885, Acc:0.793807, Semantic loss: 0.769323, BCE loss: 0.532890, SB loss: 0.759671
2023-10-30 03:05:01,073 Epoch: [77/484] Iter:[130/495], Time: 0.38, lr: [0.008551097269783118], Loss: 2.060686, Acc:0.797184, Semantic loss: 0.767601, BCE loss: 0.532927, SB loss: 0.760159
2023-10-30 03:05:04,638 Epoch: [77/484] Iter:[140/495], Time: 0.38, lr: [0.008550715020961228], Loss: 2.068164, Acc:0.794770, Semantic loss: 0.778160, BCE loss: 0.529010, SB loss: 0.760994
2023-10-30 03:05:08,379 Epoch: [77/484] Iter:[150/495], Time: 0.38, lr: [0.008550332770240665], Loss: 2.080646, Acc:0.793638, Semantic loss: 0.785506, BCE loss: 0.532634, SB loss: 0.762507
2023-10-30 03:05:12,074 Epoch: [77/484] Iter:[160/495], Time: 0.38, lr: [0.008549950517621332], Loss: 2.089341, Acc:0.793417, Semantic loss: 0.789406, BCE loss: 0.536896, SB loss: 0.763039
2023-10-30 03:05:15,752 Epoch: [77/484] Iter:[170/495], Time: 0.38, lr: [0.008549568263103116], Loss: 2.093655, Acc:0.790642, Semantic loss: 0.790341, BCE loss: 0.538848, SB loss: 0.764466
2023-10-30 03:05:19,436 Epoch: [77/484] Iter:[180/495], Time: 0.38, lr: [0.008549186006685923], Loss: 2.096581, Acc:0.789817, Semantic loss: 0.793897, BCE loss: 0.537527, SB loss: 0.765157
2023-10-30 03:05:23,143 Epoch: [77/484] Iter:[190/495], Time: 0.38, lr: [0.008548803748369643], Loss: 2.096094, Acc:0.791481, Semantic loss: 0.791547, BCE loss: 0.538945, SB loss: 0.765602
2023-10-30 03:05:26,771 Epoch: [77/484] Iter:[200/495], Time: 0.38, lr: [0.008548421488154176], Loss: 2.104244, Acc:0.792112, Semantic loss: 0.793726, BCE loss: 0.544043, SB loss: 0.766476
2023-10-30 03:05:30,419 Epoch: [77/484] Iter:[210/495], Time: 0.38, lr: [0.008548039226039413], Loss: 2.106097, Acc:0.790801, Semantic loss: 0.794764, BCE loss: 0.544262, SB loss: 0.767070
2023-10-30 03:05:34,167 Epoch: [77/484] Iter:[220/495], Time: 0.38, lr: [0.008547656962025255], Loss: 2.103280, Acc:0.790158, Semantic loss: 0.792206, BCE loss: 0.544990, SB loss: 0.766084
2023-10-30 03:05:37,814 Epoch: [77/484] Iter:[230/495], Time: 0.38, lr: [0.008547274696111596], Loss: 2.101989, Acc:0.790565, Semantic loss: 0.790778, BCE loss: 0.544739, SB loss: 0.766472
2023-10-30 03:05:41,453 Epoch: [77/484] Iter:[240/495], Time: 0.38, lr: [0.008546892428298335], Loss: 2.103368, Acc:0.791330, Semantic loss: 0.792567, BCE loss: 0.544201, SB loss: 0.766601
2023-10-30 03:05:45,063 Epoch: [77/484] Iter:[250/495], Time: 0.38, lr: [0.008546510158585364], Loss: 2.095570, Acc:0.791541, Semantic loss: 0.788552, BCE loss: 0.542671, SB loss: 0.764347
2023-10-30 03:05:48,811 Epoch: [77/484] Iter:[260/495], Time: 0.38, lr: [0.00854612788697258], Loss: 2.099395, Acc:0.791816, Semantic loss: 0.790764, BCE loss: 0.543336, SB loss: 0.765295
2023-10-30 03:05:52,372 Epoch: [77/484] Iter:[270/495], Time: 0.38, lr: [0.008545745613459882], Loss: 2.095902, Acc:0.792872, Semantic loss: 0.787184, BCE loss: 0.544763, SB loss: 0.763954
2023-10-30 03:05:56,087 Epoch: [77/484] Iter:[280/495], Time: 0.38, lr: [0.008545363338047163], Loss: 2.094316, Acc:0.791858, Semantic loss: 0.786651, BCE loss: 0.543680, SB loss: 0.763985
2023-10-30 03:05:59,834 Epoch: [77/484] Iter:[290/495], Time: 0.38, lr: [0.008544981060734322], Loss: 2.100953, Acc:0.792840, Semantic loss: 0.787977, BCE loss: 0.547549, SB loss: 0.765427
2023-10-30 03:06:03,710 Epoch: [77/484] Iter:[300/495], Time: 0.38, lr: [0.008544598781521253], Loss: 2.101635, Acc:0.793256, Semantic loss: 0.787163, BCE loss: 0.549932, SB loss: 0.764540
2023-10-30 03:06:07,512 Epoch: [77/484] Iter:[310/495], Time: 0.38, lr: [0.008544216500407853], Loss: 2.099874, Acc:0.794626, Semantic loss: 0.785005, BCE loss: 0.551074, SB loss: 0.763795
2023-10-30 03:06:11,089 Epoch: [77/484] Iter:[320/495], Time: 0.38, lr: [0.008543834217394016], Loss: 2.100097, Acc:0.794092, Semantic loss: 0.786576, BCE loss: 0.549792, SB loss: 0.763730
2023-10-30 03:06:14,781 Epoch: [77/484] Iter:[330/495], Time: 0.37, lr: [0.008543451932479641], Loss: 2.098273, Acc:0.793806, Semantic loss: 0.786078, BCE loss: 0.549705, SB loss: 0.762490
2023-10-30 03:06:18,578 Epoch: [77/484] Iter:[340/495], Time: 0.38, lr: [0.008543069645664621], Loss: 2.099667, Acc:0.792624, Semantic loss: 0.787630, BCE loss: 0.548903, SB loss: 0.763134
2023-10-30 03:06:22,265 Epoch: [77/484] Iter:[350/495], Time: 0.37, lr: [0.008542687356948858], Loss: 2.098344, Acc:0.792993, Semantic loss: 0.786825, BCE loss: 0.548377, SB loss: 0.763143
2023-10-30 03:06:25,895 Epoch: [77/484] Iter:[360/495], Time: 0.37, lr: [0.00854230506633224], Loss: 2.097085, Acc:0.792481, Semantic loss: 0.787124, BCE loss: 0.546843, SB loss: 0.763118
2023-10-30 03:06:29,620 Epoch: [77/484] Iter:[370/495], Time: 0.37, lr: [0.008541922773814667], Loss: 2.093580, Acc:0.792250, Semantic loss: 0.785594, BCE loss: 0.545324, SB loss: 0.762661
2023-10-30 03:06:33,406 Epoch: [77/484] Iter:[380/495], Time: 0.37, lr: [0.008541540479396037], Loss: 2.097206, Acc:0.791889, Semantic loss: 0.787237, BCE loss: 0.546859, SB loss: 0.763110
2023-10-30 03:06:37,112 Epoch: [77/484] Iter:[390/495], Time: 0.37, lr: [0.008541158183076243], Loss: 2.094615, Acc:0.790753, Semantic loss: 0.785285, BCE loss: 0.546514, SB loss: 0.762815
2023-10-30 03:06:40,946 Epoch: [77/484] Iter:[400/495], Time: 0.37, lr: [0.008540775884855183], Loss: 2.097550, Acc:0.790909, Semantic loss: 0.786714, BCE loss: 0.547256, SB loss: 0.763580
2023-10-30 03:06:44,680 Epoch: [77/484] Iter:[410/495], Time: 0.37, lr: [0.00854039358473275], Loss: 2.104331, Acc:0.791232, Semantic loss: 0.791558, BCE loss: 0.547738, SB loss: 0.765035
2023-10-30 03:06:48,260 Epoch: [77/484] Iter:[420/495], Time: 0.37, lr: [0.008540011282708844], Loss: 2.109421, Acc:0.790851, Semantic loss: 0.794198, BCE loss: 0.549534, SB loss: 0.765689
2023-10-30 03:06:51,960 Epoch: [77/484] Iter:[430/495], Time: 0.37, lr: [0.008539628978783359], Loss: 2.104759, Acc:0.790286, Semantic loss: 0.790960, BCE loss: 0.548885, SB loss: 0.764913
2023-10-30 03:06:55,506 Epoch: [77/484] Iter:[440/495], Time: 0.37, lr: [0.00853924667295619], Loss: 2.107698, Acc:0.789470, Semantic loss: 0.793140, BCE loss: 0.548206, SB loss: 0.766352
2023-10-30 03:06:59,285 Epoch: [77/484] Iter:[450/495], Time: 0.37, lr: [0.00853886436522723], Loss: 2.104761, Acc:0.789521, Semantic loss: 0.791300, BCE loss: 0.547582, SB loss: 0.765879
2023-10-30 03:07:03,020 Epoch: [77/484] Iter:[460/495], Time: 0.37, lr: [0.008538482055596383], Loss: 2.101562, Acc:0.789804, Semantic loss: 0.790277, BCE loss: 0.546621, SB loss: 0.764665
2023-10-30 03:07:06,684 Epoch: [77/484] Iter:[470/495], Time: 0.37, lr: [0.00853809974406354], Loss: 2.100054, Acc:0.789845, Semantic loss: 0.789351, BCE loss: 0.546029, SB loss: 0.764674
2023-10-30 03:07:10,341 Epoch: [77/484] Iter:[480/495], Time: 0.37, lr: [0.008537717430628597], Loss: 2.103087, Acc:0.789858, Semantic loss: 0.792726, BCE loss: 0.544905, SB loss: 0.765456
2023-10-30 03:07:13,810 Epoch: [77/484] Iter:[490/495], Time: 0.37, lr: [0.008537335115291452], Loss: 2.103721, Acc:0.790820, Semantic loss: 0.793034, BCE loss: 0.545323, SB loss: 0.765364
2023-10-30 03:07:15,210 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:07:15,449 Loss: 2.135, MeanIU:  0.6045, Best_mIoU:  0.6736
2023-10-30 03:07:15,449 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593]
2023-10-30 03:07:17,330 Epoch: [78/484] Iter:[0/495], Time: 1.84, lr: [0.00853714395690952], Loss: 2.046112, Acc:0.797891, Semantic loss: 0.768567, BCE loss: 0.557829, SB loss: 0.719716
2023-10-30 03:07:21,306 Epoch: [78/484] Iter:[10/495], Time: 0.53, lr: [0.008536761638718873], Loss: 2.156515, Acc:0.754516, Semantic loss: 0.835640, BCE loss: 0.534152, SB loss: 0.786723
2023-10-30 03:07:24,996 Epoch: [78/484] Iter:[20/495], Time: 0.45, lr: [0.008536379318625763], Loss: 2.133058, Acc:0.758044, Semantic loss: 0.819310, BCE loss: 0.526979, SB loss: 0.786769
2023-10-30 03:07:28,685 Epoch: [78/484] Iter:[30/495], Time: 0.43, lr: [0.008535996996630085], Loss: 2.135348, Acc:0.776380, Semantic loss: 0.814110, BCE loss: 0.540340, SB loss: 0.780897
2023-10-30 03:07:32,377 Epoch: [78/484] Iter:[40/495], Time: 0.41, lr: [0.008535614672731734], Loss: 2.103998, Acc:0.775054, Semantic loss: 0.803098, BCE loss: 0.527938, SB loss: 0.772962
2023-10-30 03:07:36,008 Epoch: [78/484] Iter:[50/495], Time: 0.40, lr: [0.008535232346930606], Loss: 2.076762, Acc:0.779917, Semantic loss: 0.789519, BCE loss: 0.519269, SB loss: 0.767974
2023-10-30 03:07:39,689 Epoch: [78/484] Iter:[60/495], Time: 0.40, lr: [0.0085348500192266], Loss: 2.108592, Acc:0.779441, Semantic loss: 0.809696, BCE loss: 0.518672, SB loss: 0.780225
2023-10-30 03:07:43,372 Epoch: [78/484] Iter:[70/495], Time: 0.39, lr: [0.008534467689619605], Loss: 2.102926, Acc:0.779523, Semantic loss: 0.806005, BCE loss: 0.521217, SB loss: 0.775703
2023-10-30 03:07:46,975 Epoch: [78/484] Iter:[80/495], Time: 0.39, lr: [0.008534085358109525], Loss: 2.110879, Acc:0.782799, Semantic loss: 0.807148, BCE loss: 0.527115, SB loss: 0.776616
2023-10-30 03:07:50,780 Epoch: [78/484] Iter:[90/495], Time: 0.39, lr: [0.00853370302469625], Loss: 2.145338, Acc:0.785477, Semantic loss: 0.822991, BCE loss: 0.536291, SB loss: 0.786056
2023-10-30 03:07:54,479 Epoch: [78/484] Iter:[100/495], Time: 0.39, lr: [0.008533320689379679], Loss: 2.150428, Acc:0.785110, Semantic loss: 0.822285, BCE loss: 0.543200, SB loss: 0.784944
2023-10-30 03:07:58,130 Epoch: [78/484] Iter:[110/495], Time: 0.38, lr: [0.008532938352159705], Loss: 2.180984, Acc:0.784790, Semantic loss: 0.842523, BCE loss: 0.548510, SB loss: 0.789950
2023-10-30 03:08:01,842 Epoch: [78/484] Iter:[120/495], Time: 0.38, lr: [0.008532556013036225], Loss: 2.166600, Acc:0.784682, Semantic loss: 0.835547, BCE loss: 0.546199, SB loss: 0.784855
2023-10-30 03:08:05,537 Epoch: [78/484] Iter:[130/495], Time: 0.38, lr: [0.008532173672009136], Loss: 2.167147, Acc:0.785352, Semantic loss: 0.832167, BCE loss: 0.548222, SB loss: 0.786758
2023-10-30 03:08:09,234 Epoch: [78/484] Iter:[140/495], Time: 0.38, lr: [0.008531791329078333], Loss: 2.168299, Acc:0.786342, Semantic loss: 0.831439, BCE loss: 0.549570, SB loss: 0.787290
2023-10-30 03:08:12,901 Epoch: [78/484] Iter:[150/495], Time: 0.38, lr: [0.00853140898424371], Loss: 2.159725, Acc:0.788460, Semantic loss: 0.824038, BCE loss: 0.550831, SB loss: 0.784856
2023-10-30 03:08:16,715 Epoch: [78/484] Iter:[160/495], Time: 0.38, lr: [0.008531026637505166], Loss: 2.149936, Acc:0.788963, Semantic loss: 0.817902, BCE loss: 0.550591, SB loss: 0.781443
2023-10-30 03:08:20,518 Epoch: [78/484] Iter:[170/495], Time: 0.38, lr: [0.008530644288862594], Loss: 2.150672, Acc:0.790689, Semantic loss: 0.817620, BCE loss: 0.553478, SB loss: 0.779574
2023-10-30 03:08:24,080 Epoch: [78/484] Iter:[180/495], Time: 0.38, lr: [0.008530261938315891], Loss: 2.145837, Acc:0.790371, Semantic loss: 0.815695, BCE loss: 0.552196, SB loss: 0.777945
2023-10-30 03:08:27,753 Epoch: [78/484] Iter:[190/495], Time: 0.38, lr: [0.008529879585864951], Loss: 2.150588, Acc:0.790454, Semantic loss: 0.824564, BCE loss: 0.551975, SB loss: 0.774049
2023-10-30 03:08:31,557 Epoch: [78/484] Iter:[200/495], Time: 0.38, lr: [0.008529497231509671], Loss: 2.143009, Acc:0.789870, Semantic loss: 0.818476, BCE loss: 0.551463, SB loss: 0.773070
2023-10-30 03:08:35,234 Epoch: [78/484] Iter:[210/495], Time: 0.38, lr: [0.008529114875249948], Loss: 2.147016, Acc:0.791705, Semantic loss: 0.818949, BCE loss: 0.553954, SB loss: 0.774113
2023-10-30 03:08:38,938 Epoch: [78/484] Iter:[220/495], Time: 0.38, lr: [0.008528732517085675], Loss: 2.146804, Acc:0.791793, Semantic loss: 0.817750, BCE loss: 0.554592, SB loss: 0.774462
2023-10-30 03:08:42,622 Epoch: [78/484] Iter:[230/495], Time: 0.38, lr: [0.008528350157016749], Loss: 2.146261, Acc:0.792293, Semantic loss: 0.816874, BCE loss: 0.553849, SB loss: 0.775538
2023-10-30 03:08:46,233 Epoch: [78/484] Iter:[240/495], Time: 0.38, lr: [0.008527967795043067], Loss: 2.142523, Acc:0.792695, Semantic loss: 0.815694, BCE loss: 0.551607, SB loss: 0.775221
2023-10-30 03:08:49,892 Epoch: [78/484] Iter:[250/495], Time: 0.38, lr: [0.008527585431164521], Loss: 2.142058, Acc:0.792501, Semantic loss: 0.815917, BCE loss: 0.550791, SB loss: 0.775350
2023-10-30 03:08:53,650 Epoch: [78/484] Iter:[260/495], Time: 0.38, lr: [0.008527203065381012], Loss: 2.142545, Acc:0.791967, Semantic loss: 0.816459, BCE loss: 0.549824, SB loss: 0.776262
2023-10-30 03:08:57,341 Epoch: [78/484] Iter:[270/495], Time: 0.38, lr: [0.008526820697692429], Loss: 2.141399, Acc:0.792442, Semantic loss: 0.814041, BCE loss: 0.551471, SB loss: 0.775886
2023-10-30 03:09:00,962 Epoch: [78/484] Iter:[280/495], Time: 0.38, lr: [0.00852643832809867], Loss: 2.139402, Acc:0.790980, Semantic loss: 0.812897, BCE loss: 0.549373, SB loss: 0.777132
2023-10-30 03:09:04,692 Epoch: [78/484] Iter:[290/495], Time: 0.38, lr: [0.008526055956599636], Loss: 2.138275, Acc:0.791891, Semantic loss: 0.811979, BCE loss: 0.548894, SB loss: 0.777402
2023-10-30 03:09:08,488 Epoch: [78/484] Iter:[300/495], Time: 0.38, lr: [0.008525673583195214], Loss: 2.134934, Acc:0.792205, Semantic loss: 0.809768, BCE loss: 0.548908, SB loss: 0.776257
2023-10-30 03:09:12,206 Epoch: [78/484] Iter:[310/495], Time: 0.38, lr: [0.008525291207885305], Loss: 2.130563, Acc:0.793285, Semantic loss: 0.808239, BCE loss: 0.547191, SB loss: 0.775133
2023-10-30 03:09:15,811 Epoch: [78/484] Iter:[320/495], Time: 0.37, lr: [0.008524908830669805], Loss: 2.132590, Acc:0.793708, Semantic loss: 0.810599, BCE loss: 0.546912, SB loss: 0.775079
2023-10-30 03:09:19,565 Epoch: [78/484] Iter:[330/495], Time: 0.37, lr: [0.008524526451548605], Loss: 2.132019, Acc:0.792892, Semantic loss: 0.811259, BCE loss: 0.545613, SB loss: 0.775147
2023-10-30 03:09:23,234 Epoch: [78/484] Iter:[340/495], Time: 0.37, lr: [0.008524144070521605], Loss: 2.137953, Acc:0.792852, Semantic loss: 0.815002, BCE loss: 0.545627, SB loss: 0.777324
2023-10-30 03:09:26,974 Epoch: [78/484] Iter:[350/495], Time: 0.37, lr: [0.008523761687588696], Loss: 2.136986, Acc:0.792304, Semantic loss: 0.814973, BCE loss: 0.545310, SB loss: 0.776703
2023-10-30 03:09:30,692 Epoch: [78/484] Iter:[360/495], Time: 0.37, lr: [0.00852337930274978], Loss: 2.135831, Acc:0.791357, Semantic loss: 0.815111, BCE loss: 0.544543, SB loss: 0.776176
2023-10-30 03:09:34,380 Epoch: [78/484] Iter:[370/495], Time: 0.37, lr: [0.008522996916004746], Loss: 2.139813, Acc:0.792089, Semantic loss: 0.815680, BCE loss: 0.547642, SB loss: 0.776491
2023-10-30 03:09:38,049 Epoch: [78/484] Iter:[380/495], Time: 0.37, lr: [0.008522614527353492], Loss: 2.138878, Acc:0.791934, Semantic loss: 0.813979, BCE loss: 0.547658, SB loss: 0.777242
2023-10-30 03:09:41,769 Epoch: [78/484] Iter:[390/495], Time: 0.37, lr: [0.008522232136795914], Loss: 2.136506, Acc:0.791214, Semantic loss: 0.812613, BCE loss: 0.547109, SB loss: 0.776784
2023-10-30 03:09:45,428 Epoch: [78/484] Iter:[400/495], Time: 0.37, lr: [0.008521849744331908], Loss: 2.137910, Acc:0.790934, Semantic loss: 0.812508, BCE loss: 0.549165, SB loss: 0.776237
2023-10-30 03:09:49,119 Epoch: [78/484] Iter:[410/495], Time: 0.37, lr: [0.008521467349961368], Loss: 2.137042, Acc:0.791372, Semantic loss: 0.811673, BCE loss: 0.549736, SB loss: 0.775633
2023-10-30 03:09:52,792 Epoch: [78/484] Iter:[420/495], Time: 0.37, lr: [0.00852108495368419], Loss: 2.137630, Acc:0.791138, Semantic loss: 0.811387, BCE loss: 0.549879, SB loss: 0.776364
2023-10-30 03:09:56,370 Epoch: [78/484] Iter:[430/495], Time: 0.37, lr: [0.008520702555500269], Loss: 2.143113, Acc:0.791598, Semantic loss: 0.814581, BCE loss: 0.551167, SB loss: 0.777364
2023-10-30 03:10:00,023 Epoch: [78/484] Iter:[440/495], Time: 0.37, lr: [0.008520320155409503], Loss: 2.140199, Acc:0.790786, Semantic loss: 0.813397, BCE loss: 0.550344, SB loss: 0.776459
2023-10-30 03:10:03,723 Epoch: [78/484] Iter:[450/495], Time: 0.37, lr: [0.008519937753411783], Loss: 2.137061, Acc:0.791627, Semantic loss: 0.811122, BCE loss: 0.550277, SB loss: 0.775663
2023-10-30 03:10:07,419 Epoch: [78/484] Iter:[460/495], Time: 0.37, lr: [0.008519555349507005], Loss: 2.136056, Acc:0.792225, Semantic loss: 0.810241, BCE loss: 0.550104, SB loss: 0.775711
2023-10-30 03:10:11,093 Epoch: [78/484] Iter:[470/495], Time: 0.37, lr: [0.00851917294369507], Loss: 2.139123, Acc:0.792271, Semantic loss: 0.811627, BCE loss: 0.551938, SB loss: 0.775558
2023-10-30 03:10:14,755 Epoch: [78/484] Iter:[480/495], Time: 0.37, lr: [0.008518790535975866], Loss: 2.138035, Acc:0.792302, Semantic loss: 0.810701, BCE loss: 0.551479, SB loss: 0.775854
2023-10-30 03:10:18,247 Epoch: [78/484] Iter:[490/495], Time: 0.37, lr: [0.008518408126349294], Loss: 2.139053, Acc:0.792519, Semantic loss: 0.811197, BCE loss: 0.551477, SB loss: 0.776379
2023-10-30 03:10:19,650 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:10:19,891 Loss: 2.135, MeanIU:  0.6045, Best_mIoU:  0.6736
2023-10-30 03:10:19,891 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593]
2023-10-30 03:10:22,130 Epoch: [79/484] Iter:[0/495], Time: 2.21, lr: [0.00851821692082071], Loss: 2.385592, Acc:0.818011, Semantic loss: 0.914719, BCE loss: 0.511037, SB loss: 0.959836
2023-10-30 03:10:26,017 Epoch: [79/484] Iter:[10/495], Time: 0.55, lr: [0.008517834508332886], Loss: 2.140904, Acc:0.770342, Semantic loss: 0.764757, BCE loss: 0.594312, SB loss: 0.781836
2023-10-30 03:10:29,655 Epoch: [79/484] Iter:[20/495], Time: 0.46, lr: [0.008517452093937429], Loss: 2.026035, Acc:0.791541, Semantic loss: 0.729294, BCE loss: 0.554682, SB loss: 0.742059
2023-10-30 03:10:33,410 Epoch: [79/484] Iter:[30/495], Time: 0.43, lr: [0.008517069677634236], Loss: 2.059782, Acc:0.786211, Semantic loss: 0.770279, BCE loss: 0.534489, SB loss: 0.755014
2023-10-30 03:10:37,103 Epoch: [79/484] Iter:[40/495], Time: 0.42, lr: [0.0085166872594232], Loss: 2.102591, Acc:0.782578, Semantic loss: 0.798356, BCE loss: 0.533979, SB loss: 0.770256
2023-10-30 03:10:40,758 Epoch: [79/484] Iter:[50/495], Time: 0.41, lr: [0.00851630483930422], Loss: 2.093203, Acc:0.783966, Semantic loss: 0.790383, BCE loss: 0.531734, SB loss: 0.771085
2023-10-30 03:10:44,388 Epoch: [79/484] Iter:[60/495], Time: 0.40, lr: [0.008515922417277189], Loss: 2.122979, Acc:0.781134, Semantic loss: 0.807809, BCE loss: 0.536336, SB loss: 0.778833
2023-10-30 03:10:48,000 Epoch: [79/484] Iter:[70/495], Time: 0.40, lr: [0.008515539993342003], Loss: 2.130929, Acc:0.783271, Semantic loss: 0.805084, BCE loss: 0.548728, SB loss: 0.777117
2023-10-30 03:10:51,524 Epoch: [79/484] Iter:[80/495], Time: 0.39, lr: [0.008515157567498556], Loss: 2.129239, Acc:0.784498, Semantic loss: 0.800346, BCE loss: 0.552094, SB loss: 0.776800
2023-10-30 03:10:55,203 Epoch: [79/484] Iter:[90/495], Time: 0.39, lr: [0.008514775139746742], Loss: 2.103785, Acc:0.785305, Semantic loss: 0.790630, BCE loss: 0.542382, SB loss: 0.770773
2023-10-30 03:10:58,914 Epoch: [79/484] Iter:[100/495], Time: 0.39, lr: [0.008514392710086461], Loss: 2.116341, Acc:0.784088, Semantic loss: 0.800504, BCE loss: 0.541556, SB loss: 0.774281
2023-10-30 03:11:02,564 Epoch: [79/484] Iter:[110/495], Time: 0.38, lr: [0.008514010278517605], Loss: 2.112871, Acc:0.781554, Semantic loss: 0.796887, BCE loss: 0.543178, SB loss: 0.772807
2023-10-30 03:11:06,149 Epoch: [79/484] Iter:[120/495], Time: 0.38, lr: [0.008513627845040068], Loss: 2.119603, Acc:0.781824, Semantic loss: 0.800811, BCE loss: 0.547094, SB loss: 0.771699
2023-10-30 03:11:09,798 Epoch: [79/484] Iter:[130/495], Time: 0.38, lr: [0.00851324540965375], Loss: 2.110263, Acc:0.782636, Semantic loss: 0.795003, BCE loss: 0.547350, SB loss: 0.767911
2023-10-30 03:11:13,551 Epoch: [79/484] Iter:[140/495], Time: 0.38, lr: [0.008512862972358542], Loss: 2.103135, Acc:0.783310, Semantic loss: 0.789650, BCE loss: 0.548123, SB loss: 0.765363
2023-10-30 03:11:17,242 Epoch: [79/484] Iter:[150/495], Time: 0.38, lr: [0.00851248053315434], Loss: 2.093864, Acc:0.783049, Semantic loss: 0.784839, BCE loss: 0.544908, SB loss: 0.764116
2023-10-30 03:11:20,921 Epoch: [79/484] Iter:[160/495], Time: 0.38, lr: [0.008512098092041039], Loss: 2.091147, Acc:0.783785, Semantic loss: 0.781569, BCE loss: 0.545985, SB loss: 0.763592
2023-10-30 03:11:24,732 Epoch: [79/484] Iter:[170/495], Time: 0.38, lr: [0.008511715649018535], Loss: 2.106258, Acc:0.785213, Semantic loss: 0.789514, BCE loss: 0.549293, SB loss: 0.767451
2023-10-30 03:11:28,325 Epoch: [79/484] Iter:[180/495], Time: 0.38, lr: [0.008511333204086723], Loss: 2.111202, Acc:0.784949, Semantic loss: 0.794855, BCE loss: 0.546844, SB loss: 0.769503
2023-10-30 03:11:32,051 Epoch: [79/484] Iter:[190/495], Time: 0.38, lr: [0.008510950757245497], Loss: 2.102193, Acc:0.786955, Semantic loss: 0.788658, BCE loss: 0.545742, SB loss: 0.767793
2023-10-30 03:11:35,878 Epoch: [79/484] Iter:[200/495], Time: 0.38, lr: [0.008510568308494752], Loss: 2.105900, Acc:0.788675, Semantic loss: 0.790821, BCE loss: 0.545355, SB loss: 0.769724
2023-10-30 03:11:39,585 Epoch: [79/484] Iter:[210/495], Time: 0.38, lr: [0.008510185857834387], Loss: 2.119058, Acc:0.787417, Semantic loss: 0.796952, BCE loss: 0.551592, SB loss: 0.770514
2023-10-30 03:11:43,219 Epoch: [79/484] Iter:[220/495], Time: 0.38, lr: [0.008509803405264294], Loss: 2.119678, Acc:0.789531, Semantic loss: 0.796354, BCE loss: 0.552875, SB loss: 0.770449
2023-10-30 03:11:46,825 Epoch: [79/484] Iter:[230/495], Time: 0.38, lr: [0.008509420950784368], Loss: 2.120035, Acc:0.787407, Semantic loss: 0.798870, BCE loss: 0.549195, SB loss: 0.771970
2023-10-30 03:11:50,561 Epoch: [79/484] Iter:[240/495], Time: 0.38, lr: [0.008509038494394505], Loss: 2.123341, Acc:0.786763, Semantic loss: 0.800762, BCE loss: 0.549896, SB loss: 0.772683
2023-10-30 03:11:54,218 Epoch: [79/484] Iter:[250/495], Time: 0.38, lr: [0.008508656036094598], Loss: 2.121376, Acc:0.785530, Semantic loss: 0.803449, BCE loss: 0.544913, SB loss: 0.773014
2023-10-30 03:11:57,865 Epoch: [79/484] Iter:[260/495], Time: 0.38, lr: [0.008508273575884543], Loss: 2.115369, Acc:0.787374, Semantic loss: 0.798974, BCE loss: 0.545751, SB loss: 0.770644
2023-10-30 03:12:01,646 Epoch: [79/484] Iter:[270/495], Time: 0.38, lr: [0.008507891113764238], Loss: 2.112389, Acc:0.788622, Semantic loss: 0.796539, BCE loss: 0.545107, SB loss: 0.770742
2023-10-30 03:12:05,389 Epoch: [79/484] Iter:[280/495], Time: 0.38, lr: [0.008507508649733575], Loss: 2.113057, Acc:0.789096, Semantic loss: 0.795531, BCE loss: 0.546008, SB loss: 0.771519
2023-10-30 03:12:09,071 Epoch: [79/484] Iter:[290/495], Time: 0.38, lr: [0.008507126183792449], Loss: 2.112013, Acc:0.788771, Semantic loss: 0.794958, BCE loss: 0.546206, SB loss: 0.770848
2023-10-30 03:12:12,750 Epoch: [79/484] Iter:[300/495], Time: 0.37, lr: [0.008506743715940757], Loss: 2.118421, Acc:0.789960, Semantic loss: 0.797695, BCE loss: 0.549047, SB loss: 0.771680
2023-10-30 03:12:16,394 Epoch: [79/484] Iter:[310/495], Time: 0.37, lr: [0.008506361246178392], Loss: 2.117072, Acc:0.790821, Semantic loss: 0.796891, BCE loss: 0.548970, SB loss: 0.771211
2023-10-30 03:12:20,164 Epoch: [79/484] Iter:[320/495], Time: 0.37, lr: [0.00850597877450525], Loss: 2.116260, Acc:0.790230, Semantic loss: 0.795678, BCE loss: 0.549494, SB loss: 0.771088
2023-10-30 03:12:23,798 Epoch: [79/484] Iter:[330/495], Time: 0.37, lr: [0.008505596300921226], Loss: 2.125340, Acc:0.790592, Semantic loss: 0.801490, BCE loss: 0.551307, SB loss: 0.772543
2023-10-30 03:12:27,497 Epoch: [79/484] Iter:[340/495], Time: 0.37, lr: [0.008505213825426215], Loss: 2.126340, Acc:0.790367, Semantic loss: 0.803337, BCE loss: 0.550887, SB loss: 0.772116
2023-10-30 03:12:31,199 Epoch: [79/484] Iter:[350/495], Time: 0.37, lr: [0.008504831348020112], Loss: 2.124606, Acc:0.791493, Semantic loss: 0.802428, BCE loss: 0.550977, SB loss: 0.771201
2023-10-30 03:12:34,852 Epoch: [79/484] Iter:[360/495], Time: 0.37, lr: [0.008504448868702809], Loss: 2.119819, Acc:0.791441, Semantic loss: 0.799687, BCE loss: 0.549254, SB loss: 0.770878
2023-10-30 03:12:38,553 Epoch: [79/484] Iter:[370/495], Time: 0.37, lr: [0.008504066387474207], Loss: 2.120695, Acc:0.791500, Semantic loss: 0.800056, BCE loss: 0.550377, SB loss: 0.770262
2023-10-30 03:12:42,300 Epoch: [79/484] Iter:[380/495], Time: 0.37, lr: [0.008503683904334196], Loss: 2.126605, Acc:0.791418, Semantic loss: 0.802681, BCE loss: 0.551706, SB loss: 0.772217
2023-10-30 03:12:46,093 Epoch: [79/484] Iter:[390/495], Time: 0.37, lr: [0.008503301419282672], Loss: 2.123534, Acc:0.791848, Semantic loss: 0.799518, BCE loss: 0.552179, SB loss: 0.771836
2023-10-30 03:12:49,984 Epoch: [79/484] Iter:[400/495], Time: 0.37, lr: [0.00850291893231953], Loss: 2.127141, Acc:0.792006, Semantic loss: 0.801165, BCE loss: 0.554593, SB loss: 0.771383
2023-10-30 03:12:53,593 Epoch: [79/484] Iter:[410/495], Time: 0.37, lr: [0.008502536443444668], Loss: 2.125852, Acc:0.791256, Semantic loss: 0.800461, BCE loss: 0.554250, SB loss: 0.771140
2023-10-30 03:12:57,323 Epoch: [79/484] Iter:[420/495], Time: 0.37, lr: [0.008502153952657977], Loss: 2.126728, Acc:0.791403, Semantic loss: 0.801693, BCE loss: 0.553997, SB loss: 0.771038
2023-10-30 03:13:01,045 Epoch: [79/484] Iter:[430/495], Time: 0.37, lr: [0.008501771459959352], Loss: 2.123730, Acc:0.791592, Semantic loss: 0.799532, BCE loss: 0.553491, SB loss: 0.770707
2023-10-30 03:13:04,710 Epoch: [79/484] Iter:[440/495], Time: 0.37, lr: [0.008501388965348688], Loss: 2.123606, Acc:0.792648, Semantic loss: 0.798884, BCE loss: 0.553922, SB loss: 0.770801
2023-10-30 03:13:08,483 Epoch: [79/484] Iter:[450/495], Time: 0.37, lr: [0.008501006468825885], Loss: 2.121355, Acc:0.792987, Semantic loss: 0.796883, BCE loss: 0.553464, SB loss: 0.771008
2023-10-30 03:13:12,204 Epoch: [79/484] Iter:[460/495], Time: 0.37, lr: [0.008500623970390829], Loss: 2.119805, Acc:0.792398, Semantic loss: 0.796182, BCE loss: 0.552872, SB loss: 0.770751
2023-10-30 03:13:15,936 Epoch: [79/484] Iter:[470/495], Time: 0.37, lr: [0.008500241470043423], Loss: 2.124686, Acc:0.792909, Semantic loss: 0.798901, BCE loss: 0.553604, SB loss: 0.772181
2023-10-30 03:13:19,651 Epoch: [79/484] Iter:[480/495], Time: 0.37, lr: [0.008499858967783555], Loss: 2.124707, Acc:0.792965, Semantic loss: 0.798651, BCE loss: 0.553569, SB loss: 0.772487
2023-10-30 03:13:23,200 Epoch: [79/484] Iter:[490/495], Time: 0.37, lr: [0.008499476463611126], Loss: 2.122649, Acc:0.793042, Semantic loss: 0.797961, BCE loss: 0.552834, SB loss: 0.771854
2023-10-30 03:13:24,596 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:13:24,834 Loss: 2.135, MeanIU:  0.6045, Best_mIoU:  0.6736
2023-10-30 03:13:24,834 [0.9624972  0.79024753 0.87258724 0.31141375 0.47275219 0.54274555
 0.61621116 0.70637072 0.8931848  0.54211559 0.8925333  0.68840626
 0.50160059 0.87934671 0.28345601 0.48542047 0.23272635 0.12323417
 0.68895593]
2023-10-30 03:13:26,908 Epoch: [80/484] Iter:[0/495], Time: 2.04, lr: [0.008499285210807665], Loss: 1.855873, Acc:0.782438, Semantic loss: 0.683782, BCE loss: 0.449382, SB loss: 0.722709
2023-10-30 03:13:30,974 Epoch: [80/484] Iter:[10/495], Time: 0.55, lr: [0.008498902703766194], Loss: 2.055916, Acc:0.803862, Semantic loss: 0.760312, BCE loss: 0.520655, SB loss: 0.774949
2023-10-30 03:13:34,658 Epoch: [80/484] Iter:[20/495], Time: 0.47, lr: [0.008498520194811891], Loss: 2.169750, Acc:0.811914, Semantic loss: 0.802158, BCE loss: 0.575689, SB loss: 0.791903
2023-10-30 03:13:38,312 Epoch: [80/484] Iter:[30/495], Time: 0.43, lr: [0.00849813768394466], Loss: 2.143353, Acc:0.795408, Semantic loss: 0.805788, BCE loss: 0.551334, SB loss: 0.786231
2023-10-30 03:13:42,159 Epoch: [80/484] Iter:[40/495], Time: 0.42, lr: [0.008497755171164391], Loss: 2.147565, Acc:0.794548, Semantic loss: 0.808532, BCE loss: 0.554035, SB loss: 0.784998
2023-10-30 03:13:45,704 Epoch: [80/484] Iter:[50/495], Time: 0.41, lr: [0.008497372656470978], Loss: 2.154756, Acc:0.803390, Semantic loss: 0.809376, BCE loss: 0.566034, SB loss: 0.779347
2023-10-30 03:13:49,399 Epoch: [80/484] Iter:[60/495], Time: 0.40, lr: [0.00849699013986432], Loss: 2.134707, Acc:0.809052, Semantic loss: 0.799500, BCE loss: 0.560281, SB loss: 0.774927
2023-10-30 03:13:53,110 Epoch: [80/484] Iter:[70/495], Time: 0.40, lr: [0.008496607621344304], Loss: 2.169428, Acc:0.805497, Semantic loss: 0.831773, BCE loss: 0.556702, SB loss: 0.780953
2023-10-30 03:13:56,793 Epoch: [80/484] Iter:[80/495], Time: 0.39, lr: [0.008496225100910833], Loss: 2.176485, Acc:0.803941, Semantic loss: 0.836734, BCE loss: 0.551890, SB loss: 0.787861
2023-10-30 03:14:00,509 Epoch: [80/484] Iter:[90/495], Time: 0.39, lr: [0.008495842578563798], Loss: 2.172273, Acc:0.805279, Semantic loss: 0.834634, BCE loss: 0.550949, SB loss: 0.786690
2023-10-30 03:14:04,231 Epoch: [80/484] Iter:[100/495], Time: 0.39, lr: [0.008495460054303093], Loss: 2.181828, Acc:0.805579, Semantic loss: 0.839925, BCE loss: 0.550901, SB loss: 0.791002
2023-10-30 03:14:08,026 Epoch: [80/484] Iter:[110/495], Time: 0.39, lr: [0.008495077528128614], Loss: 2.203390, Acc:0.804676, Semantic loss: 0.840517, BCE loss: 0.569627, SB loss: 0.793245
2023-10-30 03:14:11,705 Epoch: [80/484] Iter:[120/495], Time: 0.39, lr: [0.008494695000040256], Loss: 2.187236, Acc:0.804970, Semantic loss: 0.828689, BCE loss: 0.568632, SB loss: 0.789915
2023-10-30 03:14:15,392 Epoch: [80/484] Iter:[130/495], Time: 0.39, lr: [0.008494312470037913], Loss: 2.192322, Acc:0.805023, Semantic loss: 0.832167, BCE loss: 0.570076, SB loss: 0.790080
2023-10-30 03:14:19,061 Epoch: [80/484] Iter:[140/495], Time: 0.38, lr: [0.008493929938121479], Loss: 2.196617, Acc:0.804450, Semantic loss: 0.834093, BCE loss: 0.571126, SB loss: 0.791398
2023-10-30 03:14:22,705 Epoch: [80/484] Iter:[150/495], Time: 0.38, lr: [0.008493547404290848], Loss: 2.188507, Acc:0.802482, Semantic loss: 0.828801, BCE loss: 0.568300, SB loss: 0.791406
2023-10-30 03:14:26,455 Epoch: [80/484] Iter:[160/495], Time: 0.38, lr: [0.008493164868545917], Loss: 2.182844, Acc:0.801888, Semantic loss: 0.825737, BCE loss: 0.568960, SB loss: 0.788146
2023-10-30 03:14:30,109 Epoch: [80/484] Iter:[170/495], Time: 0.38, lr: [0.008492782330886581], Loss: 2.187857, Acc:0.801888, Semantic loss: 0.828292, BCE loss: 0.572855, SB loss: 0.786710
2023-10-30 03:14:33,859 Epoch: [80/484] Iter:[180/495], Time: 0.38, lr: [0.00849239979131273], Loss: 2.189184, Acc:0.801112, Semantic loss: 0.828298, BCE loss: 0.573930, SB loss: 0.786955
2023-10-30 03:14:37,495 Epoch: [80/484] Iter:[190/495], Time: 0.38, lr: [0.008492017249824265], Loss: 2.186215, Acc:0.800259, Semantic loss: 0.827144, BCE loss: 0.573791, SB loss: 0.785281
2023-10-30 03:14:41,120 Epoch: [80/484] Iter:[200/495], Time: 0.38, lr: [0.008491634706421076], Loss: 2.181050, Acc:0.798941, Semantic loss: 0.824801, BCE loss: 0.571980, SB loss: 0.784268
2023-10-30 03:14:44,816 Epoch: [80/484] Iter:[210/495], Time: 0.38, lr: [0.00849125216110306], Loss: 2.177230, Acc:0.800019, Semantic loss: 0.821960, BCE loss: 0.572804, SB loss: 0.782467
2023-10-30 03:14:48,453 Epoch: [80/484] Iter:[220/495], Time: 0.38, lr: [0.008490869613870107], Loss: 2.180842, Acc:0.797924, Semantic loss: 0.825469, BCE loss: 0.571271, SB loss: 0.784102
2023-10-30 03:14:52,177 Epoch: [80/484] Iter:[230/495], Time: 0.38, lr: [0.008490487064722118], Loss: 2.177467, Acc:0.796952, Semantic loss: 0.824347, BCE loss: 0.568751, SB loss: 0.784369
2023-10-30 03:14:55,900 Epoch: [80/484] Iter:[240/495], Time: 0.38, lr: [0.008490104513658983], Loss: 2.172316, Acc:0.796560, Semantic loss: 0.821709, BCE loss: 0.566525, SB loss: 0.784082
2023-10-30 03:14:59,627 Epoch: [80/484] Iter:[250/495], Time: 0.38, lr: [0.0084897219606806], Loss: 2.170023, Acc:0.797848, Semantic loss: 0.818164, BCE loss: 0.568124, SB loss: 0.783734
2023-10-30 03:15:03,278 Epoch: [80/484] Iter:[260/495], Time: 0.38, lr: [0.00848933940578686], Loss: 2.171314, Acc:0.798200, Semantic loss: 0.818425, BCE loss: 0.569242, SB loss: 0.783647
2023-10-30 03:15:07,011 Epoch: [80/484] Iter:[270/495], Time: 0.38, lr: [0.00848895684897766], Loss: 2.166859, Acc:0.796855, Semantic loss: 0.816971, BCE loss: 0.567767, SB loss: 0.782120
2023-10-30 03:15:10,787 Epoch: [80/484] Iter:[280/495], Time: 0.38, lr: [0.008488574290252893], Loss: 2.167100, Acc:0.797829, Semantic loss: 0.817779, BCE loss: 0.566991, SB loss: 0.782330
2023-10-30 03:15:14,479 Epoch: [80/484] Iter:[290/495], Time: 0.38, lr: [0.008488191729612455], Loss: 2.165529, Acc:0.798900, Semantic loss: 0.816864, BCE loss: 0.567725, SB loss: 0.780940
2023-10-30 03:15:18,159 Epoch: [80/484] Iter:[300/495], Time: 0.38, lr: [0.00848780916705624], Loss: 2.159199, Acc:0.798700, Semantic loss: 0.812295, BCE loss: 0.565654, SB loss: 0.781251
2023-10-30 03:15:21,835 Epoch: [80/484] Iter:[310/495], Time: 0.38, lr: [0.008487426602584138], Loss: 2.157906, Acc:0.797871, Semantic loss: 0.812897, BCE loss: 0.564514, SB loss: 0.780494
2023-10-30 03:15:25,538 Epoch: [80/484] Iter:[320/495], Time: 0.38, lr: [0.00848704403619605], Loss: 2.158261, Acc:0.797162, Semantic loss: 0.812517, BCE loss: 0.564522, SB loss: 0.781221
2023-10-30 03:15:29,231 Epoch: [80/484] Iter:[330/495], Time: 0.38, lr: [0.008486661467891869], Loss: 2.159132, Acc:0.797860, Semantic loss: 0.812039, BCE loss: 0.565190, SB loss: 0.781903
2023-10-30 03:15:32,839 Epoch: [80/484] Iter:[340/495], Time: 0.38, lr: [0.008486278897671487], Loss: 2.153903, Acc:0.799184, Semantic loss: 0.809384, BCE loss: 0.564311, SB loss: 0.780208
2023-10-30 03:15:36,481 Epoch: [80/484] Iter:[350/495], Time: 0.37, lr: [0.0084858963255348], Loss: 2.150717, Acc:0.799319, Semantic loss: 0.807684, BCE loss: 0.563183, SB loss: 0.779850
2023-10-30 03:15:40,112 Epoch: [80/484] Iter:[360/495], Time: 0.37, lr: [0.008485513751481703], Loss: 2.146996, Acc:0.798647, Semantic loss: 0.807489, BCE loss: 0.561860, SB loss: 0.777647
2023-10-30 03:15:43,750 Epoch: [80/484] Iter:[370/495], Time: 0.37, lr: [0.00848513117551209], Loss: 2.144500, Acc:0.799286, Semantic loss: 0.805766, BCE loss: 0.560853, SB loss: 0.777881
2023-10-30 03:15:47,422 Epoch: [80/484] Iter:[380/495], Time: 0.37, lr: [0.008484748597625854], Loss: 2.146467, Acc:0.798626, Semantic loss: 0.807878, BCE loss: 0.560771, SB loss: 0.777818
2023-10-30 03:15:51,112 Epoch: [80/484] Iter:[390/495], Time: 0.37, lr: [0.008484366017822889], Loss: 2.145499, Acc:0.799200, Semantic loss: 0.806442, BCE loss: 0.561527, SB loss: 0.777529
2023-10-30 03:15:54,792 Epoch: [80/484] Iter:[400/495], Time: 0.37, lr: [0.008483983436103092], Loss: 2.147050, Acc:0.799461, Semantic loss: 0.807323, BCE loss: 0.561901, SB loss: 0.777826
2023-10-30 03:15:58,388 Epoch: [80/484] Iter:[410/495], Time: 0.37, lr: [0.008483600852466355], Loss: 2.144257, Acc:0.800060, Semantic loss: 0.807615, BCE loss: 0.560347, SB loss: 0.776295
2023-10-30 03:16:02,076 Epoch: [80/484] Iter:[420/495], Time: 0.37, lr: [0.008483218266912574], Loss: 2.143031, Acc:0.799131, Semantic loss: 0.807853, BCE loss: 0.558878, SB loss: 0.776300
2023-10-30 03:16:05,786 Epoch: [80/484] Iter:[430/495], Time: 0.37, lr: [0.008482835679441645], Loss: 2.143646, Acc:0.798812, Semantic loss: 0.806416, BCE loss: 0.561189, SB loss: 0.776041
2023-10-30 03:16:09,487 Epoch: [80/484] Iter:[440/495], Time: 0.37, lr: [0.008482453090053457], Loss: 2.144449, Acc:0.798756, Semantic loss: 0.806242, BCE loss: 0.561690, SB loss: 0.776516
2023-10-30 03:16:13,114 Epoch: [80/484] Iter:[450/495], Time: 0.37, lr: [0.008482070498747909], Loss: 2.139759, Acc:0.798369, Semantic loss: 0.803858, BCE loss: 0.560132, SB loss: 0.775769
2023-10-30 03:16:16,745 Epoch: [80/484] Iter:[460/495], Time: 0.37, lr: [0.008481687905524891], Loss: 2.139179, Acc:0.798090, Semantic loss: 0.803892, BCE loss: 0.559977, SB loss: 0.775310
2023-10-30 03:16:20,496 Epoch: [80/484] Iter:[470/495], Time: 0.37, lr: [0.008481305310384303], Loss: 2.135907, Acc:0.797475, Semantic loss: 0.801825, BCE loss: 0.559510, SB loss: 0.774572
2023-10-30 03:16:24,220 Epoch: [80/484] Iter:[480/495], Time: 0.37, lr: [0.008480922713326036], Loss: 2.132227, Acc:0.796877, Semantic loss: 0.800965, BCE loss: 0.557599, SB loss: 0.773664
2023-10-30 03:16:27,716 Epoch: [80/484] Iter:[490/495], Time: 0.37, lr: [0.008480540114349983], Loss: 2.133745, Acc:0.797159, Semantic loss: 0.801978, BCE loss: 0.557674, SB loss: 0.774093
2023-10-30 03:19:24,052 0 [9.25505206e-01 5.80261206e-01 8.09375060e-01 1.15006870e-01
 2.28322129e-01 3.96712691e-01 3.98054776e-01 5.61397140e-01
 8.70914207e-01 4.47289910e-01 8.49368968e-01 5.89178496e-01
 8.00605166e-03 7.81383653e-01 7.39615292e-04 2.79417762e-02
 7.11086608e-02 1.19853446e-02 5.68052017e-01] 0.43371598823560614
2023-10-30 03:19:24,052 1 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169] 0.6834800492274153
2023-10-30 03:19:24,056 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:19:24,417 Loss: 2.103, MeanIU:  0.6835, Best_mIoU:  0.6835
2023-10-30 03:19:24,417 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169]
2023-10-30 03:19:26,676 Epoch: [81/484] Iter:[0/495], Time: 2.23, lr: [0.008480348814142754], Loss: 1.980956, Acc:0.815354, Semantic loss: 0.725609, BCE loss: 0.533622, SB loss: 0.721725
2023-10-30 03:19:30,408 Epoch: [81/484] Iter:[10/495], Time: 0.54, lr: [0.008479966212289827], Loss: 2.181413, Acc:0.816384, Semantic loss: 0.782538, BCE loss: 0.642559, SB loss: 0.756315
2023-10-30 03:19:33,828 Epoch: [81/484] Iter:[20/495], Time: 0.45, lr: [0.00847958360851885], Loss: 2.178825, Acc:0.798790, Semantic loss: 0.792499, BCE loss: 0.617016, SB loss: 0.769310
2023-10-30 03:19:37,235 Epoch: [81/484] Iter:[30/495], Time: 0.41, lr: [0.00847920100282972], Loss: 2.118312, Acc:0.789977, Semantic loss: 0.777079, BCE loss: 0.579644, SB loss: 0.761589
2023-10-30 03:19:40,723 Epoch: [81/484] Iter:[40/495], Time: 0.40, lr: [0.008478818395222328], Loss: 2.136413, Acc:0.779231, Semantic loss: 0.794542, BCE loss: 0.575142, SB loss: 0.766729
2023-10-30 03:19:44,198 Epoch: [81/484] Iter:[50/495], Time: 0.39, lr: [0.00847843578569657], Loss: 2.173514, Acc:0.779784, Semantic loss: 0.806495, BCE loss: 0.576203, SB loss: 0.790816
2023-10-30 03:19:47,788 Epoch: [81/484] Iter:[60/495], Time: 0.38, lr: [0.00847805317425234], Loss: 2.143706, Acc:0.783942, Semantic loss: 0.793015, BCE loss: 0.570303, SB loss: 0.780388
2023-10-30 03:19:51,217 Epoch: [81/484] Iter:[70/495], Time: 0.38, lr: [0.008477670560889532], Loss: 2.134153, Acc:0.788110, Semantic loss: 0.790625, BCE loss: 0.565834, SB loss: 0.777694
2023-10-30 03:19:54,663 Epoch: [81/484] Iter:[80/495], Time: 0.37, lr: [0.00847728794560804], Loss: 2.127446, Acc:0.787919, Semantic loss: 0.788645, BCE loss: 0.566157, SB loss: 0.772644
2023-10-30 03:19:58,123 Epoch: [81/484] Iter:[90/495], Time: 0.37, lr: [0.008476905328407757], Loss: 2.126609, Acc:0.785763, Semantic loss: 0.792967, BCE loss: 0.560939, SB loss: 0.772703
2023-10-30 03:20:01,705 Epoch: [81/484] Iter:[100/495], Time: 0.37, lr: [0.008476522709288583], Loss: 2.114310, Acc:0.784953, Semantic loss: 0.787417, BCE loss: 0.557148, SB loss: 0.769745
2023-10-30 03:20:05,389 Epoch: [81/484] Iter:[110/495], Time: 0.37, lr: [0.008476140088250404], Loss: 2.103968, Acc:0.785561, Semantic loss: 0.782877, BCE loss: 0.554393, SB loss: 0.766697
2023-10-30 03:20:09,016 Epoch: [81/484] Iter:[120/495], Time: 0.37, lr: [0.008475757465293119], Loss: 2.105377, Acc:0.787157, Semantic loss: 0.783423, BCE loss: 0.557457, SB loss: 0.764496
2023-10-30 03:20:12,592 Epoch: [81/484] Iter:[130/495], Time: 0.37, lr: [0.008475374840416619], Loss: 2.108846, Acc:0.786236, Semantic loss: 0.786972, BCE loss: 0.555405, SB loss: 0.766469
2023-10-30 03:20:16,208 Epoch: [81/484] Iter:[140/495], Time: 0.37, lr: [0.008474992213620802], Loss: 2.109616, Acc:0.789377, Semantic loss: 0.790379, BCE loss: 0.553514, SB loss: 0.765722
2023-10-30 03:20:19,693 Epoch: [81/484] Iter:[150/495], Time: 0.37, lr: [0.00847460958490556], Loss: 2.096597, Acc:0.789469, Semantic loss: 0.784960, BCE loss: 0.550267, SB loss: 0.761370
2023-10-30 03:20:23,296 Epoch: [81/484] Iter:[160/495], Time: 0.37, lr: [0.008474226954270787], Loss: 2.098271, Acc:0.790119, Semantic loss: 0.787401, BCE loss: 0.549494, SB loss: 0.761375
2023-10-30 03:20:26,945 Epoch: [81/484] Iter:[170/495], Time: 0.37, lr: [0.008473844321716377], Loss: 2.108261, Acc:0.792210, Semantic loss: 0.789821, BCE loss: 0.553598, SB loss: 0.764842
2023-10-30 03:20:30,550 Epoch: [81/484] Iter:[180/495], Time: 0.37, lr: [0.008473461687242225], Loss: 2.105841, Acc:0.792991, Semantic loss: 0.787360, BCE loss: 0.555538, SB loss: 0.762943
2023-10-30 03:20:34,210 Epoch: [81/484] Iter:[190/495], Time: 0.37, lr: [0.008473079050848223], Loss: 2.096747, Acc:0.793712, Semantic loss: 0.784166, BCE loss: 0.551493, SB loss: 0.761088
2023-10-30 03:20:37,870 Epoch: [81/484] Iter:[200/495], Time: 0.37, lr: [0.008472696412534267], Loss: 2.095375, Acc:0.794655, Semantic loss: 0.783482, BCE loss: 0.552163, SB loss: 0.759731
2023-10-30 03:20:41,544 Epoch: [81/484] Iter:[210/495], Time: 0.37, lr: [0.00847231377230025], Loss: 2.097417, Acc:0.795167, Semantic loss: 0.785415, BCE loss: 0.553271, SB loss: 0.758731
2023-10-30 03:20:45,218 Epoch: [81/484] Iter:[220/495], Time: 0.37, lr: [0.008471931130146068], Loss: 2.103673, Acc:0.796365, Semantic loss: 0.787093, BCE loss: 0.557849, SB loss: 0.758731
2023-10-30 03:20:48,823 Epoch: [81/484] Iter:[230/495], Time: 0.37, lr: [0.008471548486071612], Loss: 2.101383, Acc:0.795483, Semantic loss: 0.784488, BCE loss: 0.559772, SB loss: 0.757122
2023-10-30 03:20:52,434 Epoch: [81/484] Iter:[240/495], Time: 0.37, lr: [0.008471165840076778], Loss: 2.100487, Acc:0.795860, Semantic loss: 0.784016, BCE loss: 0.559432, SB loss: 0.757039
2023-10-30 03:20:56,086 Epoch: [81/484] Iter:[250/495], Time: 0.37, lr: [0.00847078319216146], Loss: 2.099925, Acc:0.795405, Semantic loss: 0.785051, BCE loss: 0.557428, SB loss: 0.757446
2023-10-30 03:20:59,751 Epoch: [81/484] Iter:[260/495], Time: 0.37, lr: [0.00847040054232555], Loss: 2.094796, Acc:0.794091, Semantic loss: 0.783014, BCE loss: 0.555330, SB loss: 0.756452
2023-10-30 03:21:03,423 Epoch: [81/484] Iter:[270/495], Time: 0.37, lr: [0.008470017890568945], Loss: 2.096059, Acc:0.792965, Semantic loss: 0.782916, BCE loss: 0.556435, SB loss: 0.756707
2023-10-30 03:21:07,130 Epoch: [81/484] Iter:[280/495], Time: 0.37, lr: [0.008469635236891534], Loss: 2.096127, Acc:0.793161, Semantic loss: 0.783211, BCE loss: 0.555436, SB loss: 0.757480
2023-10-30 03:21:10,750 Epoch: [81/484] Iter:[290/495], Time: 0.37, lr: [0.008469252581293217], Loss: 2.096140, Acc:0.794343, Semantic loss: 0.782517, BCE loss: 0.555973, SB loss: 0.757651
2023-10-30 03:21:14,303 Epoch: [81/484] Iter:[300/495], Time: 0.36, lr: [0.008468869923773884], Loss: 2.097730, Acc:0.795164, Semantic loss: 0.782850, BCE loss: 0.556702, SB loss: 0.758178
2023-10-30 03:21:17,932 Epoch: [81/484] Iter:[310/495], Time: 0.36, lr: [0.00846848726433343], Loss: 2.092783, Acc:0.794329, Semantic loss: 0.780276, BCE loss: 0.555138, SB loss: 0.757369
2023-10-30 03:21:21,611 Epoch: [81/484] Iter:[320/495], Time: 0.36, lr: [0.00846810460297175], Loss: 2.099392, Acc:0.795320, Semantic loss: 0.782988, BCE loss: 0.557553, SB loss: 0.758851
2023-10-30 03:21:25,309 Epoch: [81/484] Iter:[330/495], Time: 0.37, lr: [0.008467721939688738], Loss: 2.100846, Acc:0.794309, Semantic loss: 0.785262, BCE loss: 0.557173, SB loss: 0.758411
2023-10-30 03:21:28,946 Epoch: [81/484] Iter:[340/495], Time: 0.37, lr: [0.008467339274484283], Loss: 2.100356, Acc:0.793699, Semantic loss: 0.784968, BCE loss: 0.557118, SB loss: 0.758270
2023-10-30 03:21:32,568 Epoch: [81/484] Iter:[350/495], Time: 0.36, lr: [0.008466956607358286], Loss: 2.100971, Acc:0.794150, Semantic loss: 0.784778, BCE loss: 0.557123, SB loss: 0.759070
2023-10-30 03:21:36,296 Epoch: [81/484] Iter:[360/495], Time: 0.37, lr: [0.008466573938310636], Loss: 2.099106, Acc:0.794676, Semantic loss: 0.783487, BCE loss: 0.557184, SB loss: 0.758435
2023-10-30 03:21:40,007 Epoch: [81/484] Iter:[370/495], Time: 0.37, lr: [0.008466191267341229], Loss: 2.098164, Acc:0.794827, Semantic loss: 0.783739, BCE loss: 0.556229, SB loss: 0.758195
2023-10-30 03:21:43,773 Epoch: [81/484] Iter:[380/495], Time: 0.37, lr: [0.008465808594449956], Loss: 2.097057, Acc:0.794875, Semantic loss: 0.783621, BCE loss: 0.555475, SB loss: 0.757961
2023-10-30 03:21:47,529 Epoch: [81/484] Iter:[390/495], Time: 0.37, lr: [0.008465425919636713], Loss: 2.095711, Acc:0.795138, Semantic loss: 0.783749, BCE loss: 0.553865, SB loss: 0.758097
2023-10-30 03:21:51,099 Epoch: [81/484] Iter:[400/495], Time: 0.37, lr: [0.008465043242901395], Loss: 2.096213, Acc:0.795926, Semantic loss: 0.783683, BCE loss: 0.553757, SB loss: 0.758773
2023-10-30 03:21:54,771 Epoch: [81/484] Iter:[410/495], Time: 0.37, lr: [0.008464660564243895], Loss: 2.096743, Acc:0.795911, Semantic loss: 0.783518, BCE loss: 0.554589, SB loss: 0.758636
2023-10-30 03:21:58,449 Epoch: [81/484] Iter:[420/495], Time: 0.37, lr: [0.008464277883664106], Loss: 2.095448, Acc:0.795674, Semantic loss: 0.784502, BCE loss: 0.552174, SB loss: 0.758772
2023-10-30 03:22:02,021 Epoch: [81/484] Iter:[430/495], Time: 0.37, lr: [0.008463895201161923], Loss: 2.093772, Acc:0.794885, Semantic loss: 0.783767, BCE loss: 0.552064, SB loss: 0.757942
2023-10-30 03:22:05,705 Epoch: [81/484] Iter:[440/495], Time: 0.37, lr: [0.008463512516737237], Loss: 2.094079, Acc:0.794925, Semantic loss: 0.783966, BCE loss: 0.552208, SB loss: 0.757904
2023-10-30 03:22:09,495 Epoch: [81/484] Iter:[450/495], Time: 0.37, lr: [0.008463129830389944], Loss: 2.096594, Acc:0.795131, Semantic loss: 0.784323, BCE loss: 0.554420, SB loss: 0.757851
2023-10-30 03:22:13,153 Epoch: [81/484] Iter:[460/495], Time: 0.37, lr: [0.008462747142119939], Loss: 2.095114, Acc:0.796022, Semantic loss: 0.784164, BCE loss: 0.553838, SB loss: 0.757113
2023-10-30 03:22:16,835 Epoch: [81/484] Iter:[470/495], Time: 0.37, lr: [0.008462364451927112], Loss: 2.093021, Acc:0.795163, Semantic loss: 0.783403, BCE loss: 0.553102, SB loss: 0.756515
2023-10-30 03:22:20,525 Epoch: [81/484] Iter:[480/495], Time: 0.37, lr: [0.008461981759811358], Loss: 2.094162, Acc:0.795188, Semantic loss: 0.785107, BCE loss: 0.552571, SB loss: 0.756484
2023-10-30 03:22:24,008 Epoch: [81/484] Iter:[490/495], Time: 0.37, lr: [0.008461599065772575], Loss: 2.094488, Acc:0.795464, Semantic loss: 0.785328, BCE loss: 0.551869, SB loss: 0.757291
2023-10-30 03:22:25,405 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:22:25,653 Loss: 2.103, MeanIU:  0.6835, Best_mIoU:  0.6835
2023-10-30 03:22:25,653 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169]
2023-10-30 03:22:27,871 Epoch: [82/484] Iter:[0/495], Time: 2.18, lr: [0.008461407718032013], Loss: 2.078018, Acc:0.840221, Semantic loss: 0.653860, BCE loss: 0.721669, SB loss: 0.702489
2023-10-30 03:22:31,897 Epoch: [82/484] Iter:[10/495], Time: 0.57, lr: [0.00846102502110848], Loss: 2.020831, Acc:0.818898, Semantic loss: 0.746841, BCE loss: 0.548389, SB loss: 0.725601
2023-10-30 03:22:35,623 Epoch: [82/484] Iter:[20/495], Time: 0.47, lr: [0.008460642322261649], Loss: 2.055950, Acc:0.820008, Semantic loss: 0.743303, BCE loss: 0.590632, SB loss: 0.722015
2023-10-30 03:22:39,253 Epoch: [82/484] Iter:[30/495], Time: 0.44, lr: [0.008460259621491413], Loss: 2.072052, Acc:0.813768, Semantic loss: 0.764379, BCE loss: 0.563177, SB loss: 0.744496
2023-10-30 03:22:43,008 Epoch: [82/484] Iter:[40/495], Time: 0.42, lr: [0.008459876918797666], Loss: 2.115705, Acc:0.817320, Semantic loss: 0.786007, BCE loss: 0.575091, SB loss: 0.754607
2023-10-30 03:22:46,711 Epoch: [82/484] Iter:[50/495], Time: 0.41, lr: [0.008459494214180303], Loss: 2.128724, Acc:0.815159, Semantic loss: 0.798217, BCE loss: 0.571977, SB loss: 0.758529
2023-10-30 03:22:50,349 Epoch: [82/484] Iter:[60/495], Time: 0.40, lr: [0.008459111507639214], Loss: 2.110518, Acc:0.808226, Semantic loss: 0.782025, BCE loss: 0.573141, SB loss: 0.755352
2023-10-30 03:22:54,051 Epoch: [82/484] Iter:[70/495], Time: 0.40, lr: [0.008458728799174298], Loss: 2.085566, Acc:0.802248, Semantic loss: 0.769101, BCE loss: 0.562817, SB loss: 0.753648
2023-10-30 03:22:57,685 Epoch: [82/484] Iter:[80/495], Time: 0.40, lr: [0.008458346088785443], Loss: 2.107670, Acc:0.803861, Semantic loss: 0.776419, BCE loss: 0.571316, SB loss: 0.759935
2023-10-30 03:23:01,398 Epoch: [82/484] Iter:[90/495], Time: 0.39, lr: [0.008457963376472546], Loss: 2.109384, Acc:0.804651, Semantic loss: 0.779990, BCE loss: 0.568106, SB loss: 0.761289
2023-10-30 03:23:05,022 Epoch: [82/484] Iter:[100/495], Time: 0.39, lr: [0.008457580662235502], Loss: 2.106622, Acc:0.803424, Semantic loss: 0.779983, BCE loss: 0.565795, SB loss: 0.760845
2023-10-30 03:23:08,630 Epoch: [82/484] Iter:[110/495], Time: 0.39, lr: [0.0084571979460742], Loss: 2.106900, Acc:0.805562, Semantic loss: 0.778703, BCE loss: 0.569062, SB loss: 0.759134
2023-10-30 03:23:12,377 Epoch: [82/484] Iter:[120/495], Time: 0.39, lr: [0.008456815227988536], Loss: 2.117579, Acc:0.803796, Semantic loss: 0.789685, BCE loss: 0.566869, SB loss: 0.761025
2023-10-30 03:23:16,088 Epoch: [82/484] Iter:[130/495], Time: 0.38, lr: [0.008456432507978404], Loss: 2.119134, Acc:0.805375, Semantic loss: 0.790329, BCE loss: 0.562608, SB loss: 0.766197
2023-10-30 03:23:19,855 Epoch: [82/484] Iter:[140/495], Time: 0.38, lr: [0.008456049786043697], Loss: 2.114586, Acc:0.807364, Semantic loss: 0.787005, BCE loss: 0.562673, SB loss: 0.764908
2023-10-30 03:23:23,585 Epoch: [82/484] Iter:[150/495], Time: 0.38, lr: [0.00845566706218431], Loss: 2.128863, Acc:0.805568, Semantic loss: 0.796309, BCE loss: 0.564379, SB loss: 0.768175
2023-10-30 03:23:27,239 Epoch: [82/484] Iter:[160/495], Time: 0.38, lr: [0.008455284336400134], Loss: 2.126791, Acc:0.805901, Semantic loss: 0.796008, BCE loss: 0.565296, SB loss: 0.765487
2023-10-30 03:23:30,982 Epoch: [82/484] Iter:[170/495], Time: 0.38, lr: [0.008454901608691062], Loss: 2.112607, Acc:0.804501, Semantic loss: 0.789224, BCE loss: 0.559356, SB loss: 0.764026
2023-10-30 03:23:34,687 Epoch: [82/484] Iter:[180/495], Time: 0.38, lr: [0.00845451887905699], Loss: 2.116695, Acc:0.803329, Semantic loss: 0.792143, BCE loss: 0.559415, SB loss: 0.765137
2023-10-30 03:23:38,374 Epoch: [82/484] Iter:[190/495], Time: 0.38, lr: [0.008454136147497812], Loss: 2.116512, Acc:0.803292, Semantic loss: 0.793635, BCE loss: 0.555820, SB loss: 0.767057
2023-10-30 03:23:42,037 Epoch: [82/484] Iter:[200/495], Time: 0.38, lr: [0.00845375341401342], Loss: 2.115289, Acc:0.803179, Semantic loss: 0.794256, BCE loss: 0.555297, SB loss: 0.765736
2023-10-30 03:23:45,674 Epoch: [82/484] Iter:[210/495], Time: 0.38, lr: [0.008453370678603706], Loss: 2.113498, Acc:0.802564, Semantic loss: 0.790380, BCE loss: 0.556316, SB loss: 0.766802
2023-10-30 03:23:49,401 Epoch: [82/484] Iter:[220/495], Time: 0.38, lr: [0.008452987941268565], Loss: 2.121922, Acc:0.803769, Semantic loss: 0.794789, BCE loss: 0.557786, SB loss: 0.769347
2023-10-30 03:23:53,131 Epoch: [82/484] Iter:[230/495], Time: 0.38, lr: [0.008452605202007893], Loss: 2.127786, Acc:0.803578, Semantic loss: 0.796919, BCE loss: 0.559195, SB loss: 0.771672
2023-10-30 03:23:56,931 Epoch: [82/484] Iter:[240/495], Time: 0.38, lr: [0.00845222246082158], Loss: 2.125660, Acc:0.803128, Semantic loss: 0.795273, BCE loss: 0.559261, SB loss: 0.771126
2023-10-30 03:24:00,509 Epoch: [82/484] Iter:[250/495], Time: 0.38, lr: [0.008451839717709518], Loss: 2.139807, Acc:0.800563, Semantic loss: 0.806253, BCE loss: 0.557358, SB loss: 0.776196
2023-10-30 03:24:04,230 Epoch: [82/484] Iter:[260/495], Time: 0.38, lr: [0.008451456972671604], Loss: 2.141468, Acc:0.799621, Semantic loss: 0.806462, BCE loss: 0.558011, SB loss: 0.776996
2023-10-30 03:24:07,892 Epoch: [82/484] Iter:[270/495], Time: 0.38, lr: [0.008451074225707731], Loss: 2.134780, Acc:0.800983, Semantic loss: 0.803679, BCE loss: 0.555185, SB loss: 0.775916
2023-10-30 03:24:11,529 Epoch: [82/484] Iter:[280/495], Time: 0.38, lr: [0.008450691476817792], Loss: 2.139572, Acc:0.800097, Semantic loss: 0.807249, BCE loss: 0.554380, SB loss: 0.777944
2023-10-30 03:24:15,253 Epoch: [82/484] Iter:[290/495], Time: 0.38, lr: [0.008450308726001677], Loss: 2.137984, Acc:0.799799, Semantic loss: 0.806078, BCE loss: 0.554149, SB loss: 0.777758
2023-10-30 03:24:18,873 Epoch: [82/484] Iter:[300/495], Time: 0.38, lr: [0.008449925973259284], Loss: 2.136571, Acc:0.800225, Semantic loss: 0.804130, BCE loss: 0.554606, SB loss: 0.777835
2023-10-30 03:24:22,603 Epoch: [82/484] Iter:[310/495], Time: 0.38, lr: [0.008449543218590507], Loss: 2.131920, Acc:0.800256, Semantic loss: 0.801508, BCE loss: 0.554122, SB loss: 0.776289
2023-10-30 03:24:26,355 Epoch: [82/484] Iter:[320/495], Time: 0.38, lr: [0.008449160461995234], Loss: 2.140272, Acc:0.799479, Semantic loss: 0.807090, BCE loss: 0.555670, SB loss: 0.777512
2023-10-30 03:24:30,028 Epoch: [82/484] Iter:[330/495], Time: 0.38, lr: [0.008448777703473362], Loss: 2.144051, Acc:0.798450, Semantic loss: 0.811676, BCE loss: 0.553636, SB loss: 0.778739
2023-10-30 03:24:33,865 Epoch: [82/484] Iter:[340/495], Time: 0.38, lr: [0.008448394943024785], Loss: 2.151801, Acc:0.797958, Semantic loss: 0.814878, BCE loss: 0.556509, SB loss: 0.780413
2023-10-30 03:24:37,464 Epoch: [82/484] Iter:[350/495], Time: 0.38, lr: [0.008448012180649393], Loss: 2.156331, Acc:0.798323, Semantic loss: 0.818003, BCE loss: 0.556248, SB loss: 0.782080
2023-10-30 03:24:41,109 Epoch: [82/484] Iter:[360/495], Time: 0.38, lr: [0.008447629416347082], Loss: 2.164241, Acc:0.798391, Semantic loss: 0.820564, BCE loss: 0.557979, SB loss: 0.785698
2023-10-30 03:24:44,851 Epoch: [82/484] Iter:[370/495], Time: 0.38, lr: [0.008447246650117743], Loss: 2.169523, Acc:0.799476, Semantic loss: 0.821359, BCE loss: 0.560372, SB loss: 0.787792
2023-10-30 03:24:48,656 Epoch: [82/484] Iter:[380/495], Time: 0.38, lr: [0.008446863881961274], Loss: 2.176557, Acc:0.798999, Semantic loss: 0.826411, BCE loss: 0.560368, SB loss: 0.789778
2023-10-30 03:24:52,303 Epoch: [82/484] Iter:[390/495], Time: 0.37, lr: [0.008446481111877563], Loss: 2.175101, Acc:0.798774, Semantic loss: 0.825286, BCE loss: 0.560770, SB loss: 0.789046
2023-10-30 03:24:55,904 Epoch: [82/484] Iter:[400/495], Time: 0.37, lr: [0.008446098339866507], Loss: 2.171292, Acc:0.799419, Semantic loss: 0.823451, BCE loss: 0.560644, SB loss: 0.787196
2023-10-30 03:24:59,541 Epoch: [82/484] Iter:[410/495], Time: 0.37, lr: [0.008445715565927997], Loss: 2.171557, Acc:0.799191, Semantic loss: 0.823387, BCE loss: 0.560473, SB loss: 0.787698
2023-10-30 03:25:03,227 Epoch: [82/484] Iter:[420/495], Time: 0.37, lr: [0.008445332790061925], Loss: 2.170184, Acc:0.799535, Semantic loss: 0.823251, BCE loss: 0.559647, SB loss: 0.787285
2023-10-30 03:25:06,890 Epoch: [82/484] Iter:[430/495], Time: 0.37, lr: [0.008444950012268188], Loss: 2.171541, Acc:0.799528, Semantic loss: 0.824059, BCE loss: 0.559197, SB loss: 0.788285
2023-10-30 03:25:10,593 Epoch: [82/484] Iter:[440/495], Time: 0.37, lr: [0.008444567232546676], Loss: 2.172896, Acc:0.798756, Semantic loss: 0.824432, BCE loss: 0.559483, SB loss: 0.788981
2023-10-30 03:25:14,291 Epoch: [82/484] Iter:[450/495], Time: 0.37, lr: [0.008444184450897283], Loss: 2.171649, Acc:0.798389, Semantic loss: 0.823974, BCE loss: 0.558297, SB loss: 0.789378
2023-10-30 03:25:17,956 Epoch: [82/484] Iter:[460/495], Time: 0.37, lr: [0.008443801667319903], Loss: 2.170431, Acc:0.797931, Semantic loss: 0.824069, BCE loss: 0.557815, SB loss: 0.788547
2023-10-30 03:25:21,615 Epoch: [82/484] Iter:[470/495], Time: 0.37, lr: [0.008443418881814432], Loss: 2.168021, Acc:0.798145, Semantic loss: 0.822265, BCE loss: 0.557403, SB loss: 0.788353
2023-10-30 03:25:25,204 Epoch: [82/484] Iter:[480/495], Time: 0.37, lr: [0.008443036094380756], Loss: 2.165172, Acc:0.798135, Semantic loss: 0.820805, BCE loss: 0.556833, SB loss: 0.787534
2023-10-30 03:25:28,668 Epoch: [82/484] Iter:[490/495], Time: 0.37, lr: [0.008442653305018774], Loss: 2.165750, Acc:0.797567, Semantic loss: 0.821514, BCE loss: 0.556541, SB loss: 0.787695
2023-10-30 03:25:30,070 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:25:30,326 Loss: 2.103, MeanIU:  0.6835, Best_mIoU:  0.6835
2023-10-30 03:25:30,326 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169]
2023-10-30 03:25:32,569 Epoch: [83/484] Iter:[0/495], Time: 2.21, lr: [0.008442461909614632], Loss: 2.029892, Acc:0.928038, Semantic loss: 0.689405, BCE loss: 0.669464, SB loss: 0.671023
2023-10-30 03:25:36,435 Epoch: [83/484] Iter:[10/495], Time: 0.55, lr: [0.008442079117359988], Loss: 2.112466, Acc:0.808582, Semantic loss: 0.749585, BCE loss: 0.606033, SB loss: 0.756848
2023-10-30 03:25:40,023 Epoch: [83/484] Iter:[20/495], Time: 0.46, lr: [0.008441696323176769], Loss: 2.146996, Acc:0.813216, Semantic loss: 0.784602, BCE loss: 0.593547, SB loss: 0.768847
2023-10-30 03:25:43,722 Epoch: [83/484] Iter:[30/495], Time: 0.43, lr: [0.008441313527064866], Loss: 2.151772, Acc:0.808897, Semantic loss: 0.823017, BCE loss: 0.563341, SB loss: 0.765415
2023-10-30 03:25:47,358 Epoch: [83/484] Iter:[40/495], Time: 0.41, lr: [0.008440930729024175], Loss: 2.173149, Acc:0.792274, Semantic loss: 0.843553, BCE loss: 0.555611, SB loss: 0.773986
2023-10-30 03:25:50,948 Epoch: [83/484] Iter:[50/495], Time: 0.40, lr: [0.00844054792905459], Loss: 2.172704, Acc:0.787828, Semantic loss: 0.845336, BCE loss: 0.543076, SB loss: 0.784292
2023-10-30 03:25:54,610 Epoch: [83/484] Iter:[60/495], Time: 0.40, lr: [0.008440165127156], Loss: 2.145980, Acc:0.786310, Semantic loss: 0.818101, BCE loss: 0.553827, SB loss: 0.774052
2023-10-30 03:25:58,170 Epoch: [83/484] Iter:[70/495], Time: 0.39, lr: [0.008439782323328301], Loss: 2.128195, Acc:0.786040, Semantic loss: 0.811417, BCE loss: 0.546426, SB loss: 0.770352
2023-10-30 03:26:01,772 Epoch: [83/484] Iter:[80/495], Time: 0.39, lr: [0.008439399517571387], Loss: 2.139862, Acc:0.787568, Semantic loss: 0.815294, BCE loss: 0.554080, SB loss: 0.770488
2023-10-30 03:26:05,462 Epoch: [83/484] Iter:[90/495], Time: 0.39, lr: [0.00843901670988515], Loss: 2.150448, Acc:0.789540, Semantic loss: 0.817511, BCE loss: 0.557757, SB loss: 0.775181
2023-10-30 03:26:09,145 Epoch: [83/484] Iter:[100/495], Time: 0.38, lr: [0.00843863390026948], Loss: 2.139624, Acc:0.790841, Semantic loss: 0.809777, BCE loss: 0.557623, SB loss: 0.772224
2023-10-30 03:26:12,817 Epoch: [83/484] Iter:[110/495], Time: 0.38, lr: [0.008438251088724272], Loss: 2.127959, Acc:0.792716, Semantic loss: 0.802680, BCE loss: 0.557937, SB loss: 0.767341
2023-10-30 03:26:16,461 Epoch: [83/484] Iter:[120/495], Time: 0.38, lr: [0.008437868275249422], Loss: 2.130947, Acc:0.795485, Semantic loss: 0.800000, BCE loss: 0.561342, SB loss: 0.769605
2023-10-30 03:26:20,121 Epoch: [83/484] Iter:[130/495], Time: 0.38, lr: [0.00843748545984482], Loss: 2.139272, Acc:0.793256, Semantic loss: 0.804333, BCE loss: 0.564239, SB loss: 0.770701
2023-10-30 03:26:23,806 Epoch: [83/484] Iter:[140/495], Time: 0.38, lr: [0.00843710264251036], Loss: 2.134901, Acc:0.791880, Semantic loss: 0.807070, BCE loss: 0.558121, SB loss: 0.769710
2023-10-30 03:26:27,530 Epoch: [83/484] Iter:[150/495], Time: 0.38, lr: [0.008436719823245934], Loss: 2.135307, Acc:0.790807, Semantic loss: 0.806214, BCE loss: 0.558231, SB loss: 0.770862
2023-10-30 03:26:31,263 Epoch: [83/484] Iter:[160/495], Time: 0.38, lr: [0.008436337002051432], Loss: 2.136861, Acc:0.789984, Semantic loss: 0.807801, BCE loss: 0.558326, SB loss: 0.770734
2023-10-30 03:26:34,916 Epoch: [83/484] Iter:[170/495], Time: 0.38, lr: [0.008435954178926754], Loss: 2.146069, Acc:0.790259, Semantic loss: 0.813706, BCE loss: 0.560113, SB loss: 0.772251
2023-10-30 03:26:38,614 Epoch: [83/484] Iter:[180/495], Time: 0.38, lr: [0.00843557135387179], Loss: 2.149956, Acc:0.788681, Semantic loss: 0.817589, BCE loss: 0.560189, SB loss: 0.772178
2023-10-30 03:26:42,274 Epoch: [83/484] Iter:[190/495], Time: 0.38, lr: [0.008435188526886432], Loss: 2.141952, Acc:0.787911, Semantic loss: 0.812050, BCE loss: 0.559299, SB loss: 0.770603
2023-10-30 03:26:45,989 Epoch: [83/484] Iter:[200/495], Time: 0.38, lr: [0.008434805697970572], Loss: 2.136522, Acc:0.787372, Semantic loss: 0.808608, BCE loss: 0.557468, SB loss: 0.770446
2023-10-30 03:26:49,611 Epoch: [83/484] Iter:[210/495], Time: 0.38, lr: [0.008434422867124106], Loss: 2.139702, Acc:0.787965, Semantic loss: 0.811180, BCE loss: 0.558753, SB loss: 0.769769
2023-10-30 03:26:53,269 Epoch: [83/484] Iter:[220/495], Time: 0.38, lr: [0.008434040034346923], Loss: 2.133276, Acc:0.787413, Semantic loss: 0.806769, BCE loss: 0.557372, SB loss: 0.769135
2023-10-30 03:26:56,963 Epoch: [83/484] Iter:[230/495], Time: 0.37, lr: [0.008433657199638919], Loss: 2.131563, Acc:0.789166, Semantic loss: 0.806874, BCE loss: 0.554756, SB loss: 0.769933
2023-10-30 03:27:00,566 Epoch: [83/484] Iter:[240/495], Time: 0.37, lr: [0.008433274362999985], Loss: 2.132551, Acc:0.789928, Semantic loss: 0.805899, BCE loss: 0.555596, SB loss: 0.771056
2023-10-30 03:27:04,326 Epoch: [83/484] Iter:[250/495], Time: 0.37, lr: [0.008432891524430015], Loss: 2.136320, Acc:0.789967, Semantic loss: 0.807977, BCE loss: 0.557180, SB loss: 0.771163
2023-10-30 03:27:07,989 Epoch: [83/484] Iter:[260/495], Time: 0.37, lr: [0.008432508683928903], Loss: 2.138076, Acc:0.791184, Semantic loss: 0.808662, BCE loss: 0.557335, SB loss: 0.772079
2023-10-30 03:27:11,754 Epoch: [83/484] Iter:[270/495], Time: 0.37, lr: [0.008432125841496538], Loss: 2.135816, Acc:0.791193, Semantic loss: 0.809363, BCE loss: 0.554752, SB loss: 0.771701
2023-10-30 03:27:15,326 Epoch: [83/484] Iter:[280/495], Time: 0.37, lr: [0.008431742997132816], Loss: 2.133189, Acc:0.791432, Semantic loss: 0.807444, BCE loss: 0.553481, SB loss: 0.772264
2023-10-30 03:27:18,990 Epoch: [83/484] Iter:[290/495], Time: 0.37, lr: [0.008431360150837631], Loss: 2.126919, Acc:0.791480, Semantic loss: 0.804184, BCE loss: 0.551527, SB loss: 0.771208
2023-10-30 03:27:22,680 Epoch: [83/484] Iter:[300/495], Time: 0.37, lr: [0.008430977302610871], Loss: 2.136207, Acc:0.789895, Semantic loss: 0.810916, BCE loss: 0.551831, SB loss: 0.773460
2023-10-30 03:27:26,280 Epoch: [83/484] Iter:[310/495], Time: 0.37, lr: [0.008430594452452434], Loss: 2.134893, Acc:0.790286, Semantic loss: 0.809154, BCE loss: 0.552333, SB loss: 0.773406
2023-10-30 03:27:29,902 Epoch: [83/484] Iter:[320/495], Time: 0.37, lr: [0.00843021160036221], Loss: 2.137602, Acc:0.789715, Semantic loss: 0.811028, BCE loss: 0.551423, SB loss: 0.775151
2023-10-30 03:27:33,550 Epoch: [83/484] Iter:[330/495], Time: 0.37, lr: [0.00842982874634009], Loss: 2.138027, Acc:0.789580, Semantic loss: 0.811195, BCE loss: 0.552210, SB loss: 0.774622
2023-10-30 03:27:37,230 Epoch: [83/484] Iter:[340/495], Time: 0.37, lr: [0.008429445890385972], Loss: 2.140064, Acc:0.788313, Semantic loss: 0.814503, BCE loss: 0.549875, SB loss: 0.775685
2023-10-30 03:27:40,961 Epoch: [83/484] Iter:[350/495], Time: 0.37, lr: [0.008429063032499743], Loss: 2.143423, Acc:0.788916, Semantic loss: 0.815862, BCE loss: 0.550916, SB loss: 0.776645
2023-10-30 03:27:44,720 Epoch: [83/484] Iter:[360/495], Time: 0.37, lr: [0.0084286801726813], Loss: 2.139664, Acc:0.789016, Semantic loss: 0.812814, BCE loss: 0.551216, SB loss: 0.775635
2023-10-30 03:27:48,424 Epoch: [83/484] Iter:[370/495], Time: 0.37, lr: [0.008428297310930534], Loss: 2.138407, Acc:0.788816, Semantic loss: 0.811710, BCE loss: 0.551274, SB loss: 0.775423
2023-10-30 03:27:52,184 Epoch: [83/484] Iter:[380/495], Time: 0.37, lr: [0.008427914447247338], Loss: 2.134540, Acc:0.788987, Semantic loss: 0.809406, BCE loss: 0.549859, SB loss: 0.775275
2023-10-30 03:27:55,863 Epoch: [83/484] Iter:[390/495], Time: 0.37, lr: [0.008427531581631604], Loss: 2.137316, Acc:0.790021, Semantic loss: 0.810681, BCE loss: 0.550635, SB loss: 0.776000
2023-10-30 03:27:59,553 Epoch: [83/484] Iter:[400/495], Time: 0.37, lr: [0.008427148714083225], Loss: 2.136241, Acc:0.789457, Semantic loss: 0.810358, BCE loss: 0.550760, SB loss: 0.775123
2023-10-30 03:28:03,328 Epoch: [83/484] Iter:[410/495], Time: 0.37, lr: [0.008426765844602094], Loss: 2.136127, Acc:0.789212, Semantic loss: 0.811148, BCE loss: 0.549530, SB loss: 0.775449
2023-10-30 03:28:07,014 Epoch: [83/484] Iter:[420/495], Time: 0.37, lr: [0.008426382973188104], Loss: 2.136810, Acc:0.788858, Semantic loss: 0.812740, BCE loss: 0.548888, SB loss: 0.775182
2023-10-30 03:28:10,725 Epoch: [83/484] Iter:[430/495], Time: 0.37, lr: [0.008426000099841149], Loss: 2.133896, Acc:0.789597, Semantic loss: 0.810671, BCE loss: 0.548614, SB loss: 0.774611
2023-10-30 03:28:14,438 Epoch: [83/484] Iter:[440/495], Time: 0.37, lr: [0.008425617224561118], Loss: 2.138418, Acc:0.789547, Semantic loss: 0.813023, BCE loss: 0.549993, SB loss: 0.775402
2023-10-30 03:28:18,184 Epoch: [83/484] Iter:[450/495], Time: 0.37, lr: [0.008425234347347906], Loss: 2.139604, Acc:0.790183, Semantic loss: 0.813409, BCE loss: 0.550547, SB loss: 0.775648
2023-10-30 03:28:21,968 Epoch: [83/484] Iter:[460/495], Time: 0.37, lr: [0.008424851468201404], Loss: 2.139419, Acc:0.790442, Semantic loss: 0.812390, BCE loss: 0.552589, SB loss: 0.774439
2023-10-30 03:28:25,616 Epoch: [83/484] Iter:[470/495], Time: 0.37, lr: [0.008424468587121507], Loss: 2.138674, Acc:0.790625, Semantic loss: 0.813323, BCE loss: 0.551123, SB loss: 0.774227
2023-10-30 03:28:29,388 Epoch: [83/484] Iter:[480/495], Time: 0.37, lr: [0.008424085704108106], Loss: 2.136420, Acc:0.790771, Semantic loss: 0.811416, BCE loss: 0.550710, SB loss: 0.774294
2023-10-30 03:28:32,851 Epoch: [83/484] Iter:[490/495], Time: 0.37, lr: [0.008423702819161095], Loss: 2.136010, Acc:0.791099, Semantic loss: 0.810367, BCE loss: 0.551610, SB loss: 0.774034
2023-10-30 03:28:34,258 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:28:34,494 Loss: 2.103, MeanIU:  0.6835, Best_mIoU:  0.6835
2023-10-30 03:28:34,494 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169]
2023-10-30 03:28:36,608 Epoch: [84/484] Iter:[0/495], Time: 2.08, lr: [0.008423511375962452], Loss: 2.064470, Acc:0.703795, Semantic loss: 0.833735, BCE loss: 0.452108, SB loss: 0.778627
2023-10-30 03:28:40,618 Epoch: [84/484] Iter:[10/495], Time: 0.55, lr: [0.008423128488114821], Loss: 1.966264, Acc:0.802058, Semantic loss: 0.754962, BCE loss: 0.485579, SB loss: 0.725724
2023-10-30 03:28:44,259 Epoch: [84/484] Iter:[20/495], Time: 0.46, lr: [0.008422745598333312], Loss: 1.973658, Acc:0.810898, Semantic loss: 0.748696, BCE loss: 0.486901, SB loss: 0.738060
2023-10-30 03:28:47,983 Epoch: [84/484] Iter:[30/495], Time: 0.43, lr: [0.008422362706617817], Loss: 2.076075, Acc:0.802933, Semantic loss: 0.794752, BCE loss: 0.525616, SB loss: 0.755706
2023-10-30 03:28:51,672 Epoch: [84/484] Iter:[40/495], Time: 0.42, lr: [0.008421979812968227], Loss: 2.130425, Acc:0.800168, Semantic loss: 0.833306, BCE loss: 0.527265, SB loss: 0.769854
2023-10-30 03:28:55,303 Epoch: [84/484] Iter:[50/495], Time: 0.41, lr: [0.008421596917384434], Loss: 2.109189, Acc:0.795130, Semantic loss: 0.813370, BCE loss: 0.525215, SB loss: 0.770604
2023-10-30 03:28:58,982 Epoch: [84/484] Iter:[60/495], Time: 0.40, lr: [0.00842121401986633], Loss: 2.102042, Acc:0.796549, Semantic loss: 0.805297, BCE loss: 0.531151, SB loss: 0.765594
2023-10-30 03:29:02,587 Epoch: [84/484] Iter:[70/495], Time: 0.40, lr: [0.008420831120413813], Loss: 2.113460, Acc:0.795451, Semantic loss: 0.813198, BCE loss: 0.534750, SB loss: 0.765512
2023-10-30 03:29:06,277 Epoch: [84/484] Iter:[80/495], Time: 0.39, lr: [0.00842044821902677], Loss: 2.132724, Acc:0.797484, Semantic loss: 0.817961, BCE loss: 0.545677, SB loss: 0.769086
2023-10-30 03:29:09,926 Epoch: [84/484] Iter:[90/495], Time: 0.39, lr: [0.008420065315705093], Loss: 2.119315, Acc:0.796638, Semantic loss: 0.809917, BCE loss: 0.544291, SB loss: 0.765106
2023-10-30 03:29:13,583 Epoch: [84/484] Iter:[100/495], Time: 0.39, lr: [0.00841968241044868], Loss: 2.131485, Acc:0.798414, Semantic loss: 0.814346, BCE loss: 0.549699, SB loss: 0.767440
2023-10-30 03:29:17,158 Epoch: [84/484] Iter:[110/495], Time: 0.38, lr: [0.008419299503257418], Loss: 2.142768, Acc:0.798411, Semantic loss: 0.822146, BCE loss: 0.554738, SB loss: 0.765885
2023-10-30 03:29:20,960 Epoch: [84/484] Iter:[120/495], Time: 0.38, lr: [0.008418916594131201], Loss: 2.147215, Acc:0.793911, Semantic loss: 0.825020, BCE loss: 0.553501, SB loss: 0.768693
2023-10-30 03:29:24,636 Epoch: [84/484] Iter:[130/495], Time: 0.38, lr: [0.008418533683069924], Loss: 2.136140, Acc:0.797137, Semantic loss: 0.816228, BCE loss: 0.554345, SB loss: 0.765567
2023-10-30 03:29:28,295 Epoch: [84/484] Iter:[140/495], Time: 0.38, lr: [0.008418150770073475], Loss: 2.136200, Acc:0.799027, Semantic loss: 0.815623, BCE loss: 0.553948, SB loss: 0.766629
2023-10-30 03:29:32,007 Epoch: [84/484] Iter:[150/495], Time: 0.38, lr: [0.008417767855141749], Loss: 2.138975, Acc:0.796842, Semantic loss: 0.817645, BCE loss: 0.552294, SB loss: 0.769037
2023-10-30 03:29:35,699 Epoch: [84/484] Iter:[160/495], Time: 0.38, lr: [0.008417384938274639], Loss: 2.144357, Acc:0.796237, Semantic loss: 0.820784, BCE loss: 0.552425, SB loss: 0.771148
2023-10-30 03:29:39,298 Epoch: [84/484] Iter:[170/495], Time: 0.38, lr: [0.008417002019472037], Loss: 2.150617, Acc:0.795034, Semantic loss: 0.824788, BCE loss: 0.551564, SB loss: 0.774266
2023-10-30 03:29:42,973 Epoch: [84/484] Iter:[180/495], Time: 0.38, lr: [0.008416619098733834], Loss: 2.155385, Acc:0.794947, Semantic loss: 0.829659, BCE loss: 0.549099, SB loss: 0.776627
2023-10-30 03:29:46,841 Epoch: [84/484] Iter:[190/495], Time: 0.38, lr: [0.008416236176059922], Loss: 2.155321, Acc:0.796943, Semantic loss: 0.826303, BCE loss: 0.552460, SB loss: 0.776558
2023-10-30 03:29:50,559 Epoch: [84/484] Iter:[200/495], Time: 0.38, lr: [0.008415853251450197], Loss: 2.151393, Acc:0.797866, Semantic loss: 0.822057, BCE loss: 0.553666, SB loss: 0.775671
2023-10-30 03:29:54,309 Epoch: [84/484] Iter:[210/495], Time: 0.38, lr: [0.008415470324904549], Loss: 2.144751, Acc:0.797995, Semantic loss: 0.820241, BCE loss: 0.550258, SB loss: 0.774252
2023-10-30 03:29:58,028 Epoch: [84/484] Iter:[220/495], Time: 0.38, lr: [0.008415087396422868], Loss: 2.149938, Acc:0.798070, Semantic loss: 0.822090, BCE loss: 0.553451, SB loss: 0.774398
2023-10-30 03:30:01,688 Epoch: [84/484] Iter:[230/495], Time: 0.38, lr: [0.008414704466005049], Loss: 2.150473, Acc:0.796549, Semantic loss: 0.823322, BCE loss: 0.552329, SB loss: 0.774822
2023-10-30 03:30:05,348 Epoch: [84/484] Iter:[240/495], Time: 0.38, lr: [0.008414321533650985], Loss: 2.148377, Acc:0.795907, Semantic loss: 0.822785, BCE loss: 0.549310, SB loss: 0.776282
2023-10-30 03:30:08,996 Epoch: [84/484] Iter:[250/495], Time: 0.38, lr: [0.008413938599360567], Loss: 2.147734, Acc:0.795092, Semantic loss: 0.822308, BCE loss: 0.548521, SB loss: 0.776905
2023-10-30 03:30:12,710 Epoch: [84/484] Iter:[260/495], Time: 0.38, lr: [0.008413555663133688], Loss: 2.146998, Acc:0.793203, Semantic loss: 0.822146, BCE loss: 0.547614, SB loss: 0.777239
2023-10-30 03:30:16,452 Epoch: [84/484] Iter:[270/495], Time: 0.38, lr: [0.00841317272497024], Loss: 2.144219, Acc:0.793972, Semantic loss: 0.819678, BCE loss: 0.547378, SB loss: 0.777163
2023-10-30 03:30:20,057 Epoch: [84/484] Iter:[280/495], Time: 0.38, lr: [0.008412789784870114], Loss: 2.144538, Acc:0.794195, Semantic loss: 0.819773, BCE loss: 0.547625, SB loss: 0.777140
2023-10-30 03:30:23,692 Epoch: [84/484] Iter:[290/495], Time: 0.38, lr: [0.008412406842833203], Loss: 2.146174, Acc:0.794013, Semantic loss: 0.821060, BCE loss: 0.547612, SB loss: 0.777502
2023-10-30 03:30:27,424 Epoch: [84/484] Iter:[300/495], Time: 0.38, lr: [0.0084120238988594], Loss: 2.142179, Acc:0.793545, Semantic loss: 0.819358, BCE loss: 0.546202, SB loss: 0.776619
2023-10-30 03:30:31,076 Epoch: [84/484] Iter:[310/495], Time: 0.37, lr: [0.008411640952948597], Loss: 2.143132, Acc:0.794121, Semantic loss: 0.819358, BCE loss: 0.548526, SB loss: 0.775248
2023-10-30 03:30:34,718 Epoch: [84/484] Iter:[320/495], Time: 0.37, lr: [0.008411258005100687], Loss: 2.142299, Acc:0.795326, Semantic loss: 0.817269, BCE loss: 0.549546, SB loss: 0.775484
2023-10-30 03:30:38,434 Epoch: [84/484] Iter:[330/495], Time: 0.37, lr: [0.00841087505531556], Loss: 2.140522, Acc:0.793682, Semantic loss: 0.815773, BCE loss: 0.549010, SB loss: 0.775739
2023-10-30 03:30:42,140 Epoch: [84/484] Iter:[340/495], Time: 0.37, lr: [0.00841049210359311], Loss: 2.139267, Acc:0.794737, Semantic loss: 0.813874, BCE loss: 0.550403, SB loss: 0.774991
2023-10-30 03:30:45,763 Epoch: [84/484] Iter:[350/495], Time: 0.37, lr: [0.008410109149933228], Loss: 2.140972, Acc:0.795339, Semantic loss: 0.814579, BCE loss: 0.551191, SB loss: 0.775202
2023-10-30 03:30:49,532 Epoch: [84/484] Iter:[360/495], Time: 0.37, lr: [0.008409726194335807], Loss: 2.137952, Acc:0.794157, Semantic loss: 0.812939, BCE loss: 0.549423, SB loss: 0.775591
2023-10-30 03:30:53,259 Epoch: [84/484] Iter:[370/495], Time: 0.37, lr: [0.00840934323680074], Loss: 2.138076, Acc:0.793557, Semantic loss: 0.813693, BCE loss: 0.549687, SB loss: 0.774696
2023-10-30 03:30:56,936 Epoch: [84/484] Iter:[380/495], Time: 0.37, lr: [0.008408960277327916], Loss: 2.136484, Acc:0.793575, Semantic loss: 0.812024, BCE loss: 0.549089, SB loss: 0.775371
2023-10-30 03:31:00,608 Epoch: [84/484] Iter:[390/495], Time: 0.37, lr: [0.00840857731591723], Loss: 2.142560, Acc:0.793954, Semantic loss: 0.815435, BCE loss: 0.550004, SB loss: 0.777121
2023-10-30 03:31:04,294 Epoch: [84/484] Iter:[400/495], Time: 0.37, lr: [0.008408194352568574], Loss: 2.144096, Acc:0.793927, Semantic loss: 0.816896, BCE loss: 0.550537, SB loss: 0.776663
2023-10-30 03:31:07,915 Epoch: [84/484] Iter:[410/495], Time: 0.37, lr: [0.008407811387281838], Loss: 2.142584, Acc:0.793100, Semantic loss: 0.816002, BCE loss: 0.550179, SB loss: 0.776403
2023-10-30 03:31:11,750 Epoch: [84/484] Iter:[420/495], Time: 0.37, lr: [0.008407428420056916], Loss: 2.147498, Acc:0.792828, Semantic loss: 0.818098, BCE loss: 0.550889, SB loss: 0.778511
2023-10-30 03:31:15,417 Epoch: [84/484] Iter:[430/495], Time: 0.37, lr: [0.008407045450893701], Loss: 2.152247, Acc:0.792079, Semantic loss: 0.819770, BCE loss: 0.551479, SB loss: 0.780998
2023-10-30 03:31:19,086 Epoch: [84/484] Iter:[440/495], Time: 0.37, lr: [0.008406662479792083], Loss: 2.153203, Acc:0.792436, Semantic loss: 0.819768, BCE loss: 0.552033, SB loss: 0.781402
2023-10-30 03:31:22,775 Epoch: [84/484] Iter:[450/495], Time: 0.37, lr: [0.008406279506751956], Loss: 2.155732, Acc:0.792058, Semantic loss: 0.822189, BCE loss: 0.551924, SB loss: 0.781619
2023-10-30 03:31:26,505 Epoch: [84/484] Iter:[460/495], Time: 0.37, lr: [0.008405896531773208], Loss: 2.157785, Acc:0.792590, Semantic loss: 0.822191, BCE loss: 0.552905, SB loss: 0.782690
2023-10-30 03:31:30,074 Epoch: [84/484] Iter:[470/495], Time: 0.37, lr: [0.008405513554855736], Loss: 2.159944, Acc:0.792893, Semantic loss: 0.822621, BCE loss: 0.553874, SB loss: 0.783448
2023-10-30 03:31:33,773 Epoch: [84/484] Iter:[480/495], Time: 0.37, lr: [0.008405130575999429], Loss: 2.165711, Acc:0.792660, Semantic loss: 0.824243, BCE loss: 0.556626, SB loss: 0.784843
2023-10-30 03:31:37,239 Epoch: [84/484] Iter:[490/495], Time: 0.37, lr: [0.00840474759520418], Loss: 2.166566, Acc:0.793574, Semantic loss: 0.824023, BCE loss: 0.556925, SB loss: 0.785617
2023-10-30 03:31:38,649 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:31:38,907 Loss: 2.103, MeanIU:  0.6835, Best_mIoU:  0.6835
2023-10-30 03:31:38,908 [0.96960656 0.77094778 0.90065699 0.4297633  0.5001129  0.54059358
 0.61036461 0.68131805 0.90333877 0.56572587 0.9325482  0.73575721
 0.50311722 0.91454907 0.58242243 0.70245205 0.61610317 0.42554149
 0.70120169]
2023-10-30 03:31:40,950 Epoch: [85/484] Iter:[0/495], Time: 2.01, lr: [0.008404556104079421], Loss: 2.050009, Acc:0.710724, Semantic loss: 0.728641, BCE loss: 0.492302, SB loss: 0.829065
2023-10-30 03:31:44,917 Epoch: [85/484] Iter:[10/495], Time: 0.54, lr: [0.008404173120375556], Loss: 2.269952, Acc:0.780704, Semantic loss: 0.834302, BCE loss: 0.613641, SB loss: 0.822009
2023-10-30 03:31:48,780 Epoch: [85/484] Iter:[20/495], Time: 0.47, lr: [0.008403790134732482], Loss: 2.245066, Acc:0.788593, Semantic loss: 0.858832, BCE loss: 0.586799, SB loss: 0.799435
2023-10-30 03:31:52,356 Epoch: [85/484] Iter:[30/495], Time: 0.43, lr: [0.008403407147150085], Loss: 2.203512, Acc:0.793263, Semantic loss: 0.840469, BCE loss: 0.560466, SB loss: 0.802576
2023-10-30 03:31:56,013 Epoch: [85/484] Iter:[40/495], Time: 0.42, lr: [0.008403024157628261], Loss: 2.214534, Acc:0.792756, Semantic loss: 0.854751, BCE loss: 0.557136, SB loss: 0.802647
2023-10-30 03:31:59,709 Epoch: [85/484] Iter:[50/495], Time: 0.41, lr: [0.0084026411661669], Loss: 2.217889, Acc:0.793665, Semantic loss: 0.856706, BCE loss: 0.562325, SB loss: 0.798858
2023-10-30 03:32:03,369 Epoch: [85/484] Iter:[60/495], Time: 0.40, lr: [0.008402258172765896], Loss: 2.218764, Acc:0.791461, Semantic loss: 0.860996, BCE loss: 0.562553, SB loss: 0.795215
2023-10-30 03:32:06,986 Epoch: [85/484] Iter:[70/495], Time: 0.39, lr: [0.00840187517742514], Loss: 2.216701, Acc:0.794204, Semantic loss: 0.858864, BCE loss: 0.559531, SB loss: 0.798305
2023-10-30 03:32:10,723 Epoch: [85/484] Iter:[80/495], Time: 0.39, lr: [0.008401492180144523], Loss: 2.200590, Acc:0.797379, Semantic loss: 0.851075, BCE loss: 0.555275, SB loss: 0.794240
2023-10-30 03:32:14,397 Epoch: [85/484] Iter:[90/495], Time: 0.39, lr: [0.008401109180923938], Loss: 2.191565, Acc:0.793792, Semantic loss: 0.844920, BCE loss: 0.553471, SB loss: 0.793174
2023-10-30 03:32:18,056 Epoch: [85/484] Iter:[100/495], Time: 0.39, lr: [0.008400726179763278], Loss: 2.215175, Acc:0.792048, Semantic loss: 0.858235, BCE loss: 0.559200, SB loss: 0.797740
2023-10-30 03:32:21,699 Epoch: [85/484] Iter:[110/495], Time: 0.39, lr: [0.008400343176662432], Loss: 2.206723, Acc:0.790212, Semantic loss: 0.852919, BCE loss: 0.558666, SB loss: 0.795138
2023-10-30 03:32:25,445 Epoch: [85/484] Iter:[120/495], Time: 0.38, lr: [0.008399960171621293], Loss: 2.196574, Acc:0.788185, Semantic loss: 0.846198, BCE loss: 0.557607, SB loss: 0.792770
2023-10-30 03:32:29,106 Epoch: [85/484] Iter:[130/495], Time: 0.38, lr: [0.008399577164639753], Loss: 2.209361, Acc:0.785807, Semantic loss: 0.855622, BCE loss: 0.558559, SB loss: 0.795179
2023-10-30 03:32:32,840 Epoch: [85/484] Iter:[140/495], Time: 0.38, lr: [0.008399194155717705], Loss: 2.190038, Acc:0.782620, Semantic loss: 0.844256, BCE loss: 0.555940, SB loss: 0.789842
2023-10-30 03:32:36,618 Epoch: [85/484] Iter:[150/495], Time: 0.38, lr: [0.008398811144855039], Loss: 2.194611, Acc:0.784889, Semantic loss: 0.843344, BCE loss: 0.562007, SB loss: 0.789260
2023-10-30 03:32:40,362 Epoch: [85/484] Iter:[160/495], Time: 0.38, lr: [0.008398428132051649], Loss: 2.195013, Acc:0.783614, Semantic loss: 0.844610, BCE loss: 0.562254, SB loss: 0.788149
2023-10-30 03:32:44,011 Epoch: [85/484] Iter:[170/495], Time: 0.38, lr: [0.008398045117307424], Loss: 2.197402, Acc:0.784607, Semantic loss: 0.843526, BCE loss: 0.563542, SB loss: 0.790334
2023-10-30 03:32:47,822 Epoch: [85/484] Iter:[180/495], Time: 0.38, lr: [0.008397662100622259], Loss: 2.196599, Acc:0.784454, Semantic loss: 0.845452, BCE loss: 0.560679, SB loss: 0.790468
2023-10-30 03:32:51,501 Epoch: [85/484] Iter:[190/495], Time: 0.38, lr: [0.008397279081996044], Loss: 2.190153, Acc:0.786554, Semantic loss: 0.840950, BCE loss: 0.560919, SB loss: 0.788283
2023-10-30 03:32:55,283 Epoch: [85/484] Iter:[200/495], Time: 0.38, lr: [0.008396896061428669], Loss: 2.177074, Acc:0.786494, Semantic loss: 0.834889, BCE loss: 0.558494, SB loss: 0.783691
2023-10-30 03:32:58,968 Epoch: [85/484] Iter:[210/495], Time: 0.38, lr: [0.00839651303892003], Loss: 2.176532, Acc:0.787378, Semantic loss: 0.833986, BCE loss: 0.557832, SB loss: 0.784714
2023-10-30 03:33:02,605 Epoch: [85/484] Iter:[220/495], Time: 0.38, lr: [0.008396130014470015], Loss: 2.172906, Acc:0.787450, Semantic loss: 0.831014, BCE loss: 0.558996, SB loss: 0.782896
2023-10-30 03:33:06,340 Epoch: [85/484] Iter:[230/495], Time: 0.38, lr: [0.008395746988078517], Loss: 2.172613, Acc:0.787073, Semantic loss: 0.832415, BCE loss: 0.558142, SB loss: 0.782056
2023-10-30 03:33:09,995 Epoch: [85/484] Iter:[240/495], Time: 0.38, lr: [0.00839536395974543], Loss: 2.181006, Acc:0.788748, Semantic loss: 0.837787, BCE loss: 0.557820, SB loss: 0.785399
2023-10-30 03:33:13,679 Epoch: [85/484] Iter:[250/495], Time: 0.38, lr: [0.008394980929470644], Loss: 2.190956, Acc:0.788320, Semantic loss: 0.841691, BCE loss: 0.559406, SB loss: 0.789859
2023-10-30 03:33:17,364 Epoch: [85/484] Iter:[260/495], Time: 0.38, lr: [0.008394597897254049], Loss: 2.184499, Acc:0.788175, Semantic loss: 0.837012, BCE loss: 0.558743, SB loss: 0.788744
2023-10-30 03:33:21,060 Epoch: [85/484] Iter:[270/495], Time: 0.38, lr: [0.008394214863095538], Loss: 2.189029, Acc:0.787305, Semantic loss: 0.839957, BCE loss: 0.559297, SB loss: 0.789775
2023-10-30 03:33:24,793 Epoch: [85/484] Iter:[280/495], Time: 0.38, lr: [0.008393831826995003], Loss: 2.187237, Acc:0.786724, Semantic loss: 0.838381, BCE loss: 0.558733, SB loss: 0.790123
2023-10-30 03:33:28,432 Epoch: [85/484] Iter:[290/495], Time: 0.38, lr: [0.008393448788952335], Loss: 2.190118, Acc:0.787762, Semantic loss: 0.838338, BCE loss: 0.561345, SB loss: 0.790435
2023-10-30 03:33:32,138 Epoch: [85/484] Iter:[300/495], Time: 0.38, lr: [0.008393065748967426], Loss: 2.188020, Acc:0.786621, Semantic loss: 0.837052, BCE loss: 0.560492, SB loss: 0.790477
2023-10-30 03:33:35,881 Epoch: [85/484] Iter:[310/495], Time: 0.38, lr: [0.00839268270704017], Loss: 2.191987, Acc:0.785938, Semantic loss: 0.837933, BCE loss: 0.563131, SB loss: 0.790923
2023-10-30 03:33:39,491 Epoch: [85/484] Iter:[320/495], Time: 0.38, lr: [0.008392299663170455], Loss: 2.196808, Acc:0.785611, Semantic loss: 0.841819, BCE loss: 0.563637, SB loss: 0.791352
2023-10-30 03:33:43,207 Epoch: [85/484] Iter:[330/495], Time: 0.38, lr: [0.008391916617358176], Loss: 2.196498, Acc:0.784925, Semantic loss: 0.842598, BCE loss: 0.561886, SB loss: 0.792015
2023-10-30 03:33:46,823 Epoch: [85/484] Iter:[340/495], Time: 0.37, lr: [0.008391533569603222], Loss: 2.195456, Acc:0.784539, Semantic loss: 0.840005, BCE loss: 0.563065, SB loss: 0.792387
2023-10-30 03:33:50,442 Epoch: [85/484] Iter:[350/495], Time: 0.37, lr: [0.008391150519905483], Loss: 2.191558, Acc:0.784654, Semantic loss: 0.837336, BCE loss: 0.562322, SB loss: 0.791900
2023-10-30 03:33:54,225 Epoch: [85/484] Iter:[360/495], Time: 0.37, lr: [0.008390767468264854], Loss: 2.185736, Acc:0.784845, Semantic loss: 0.834972, BCE loss: 0.560514, SB loss: 0.790251
2023-10-30 03:33:57,962 Epoch: [85/484] Iter:[370/495], Time: 0.37, lr: [0.008390384414681228], Loss: 2.183723, Acc:0.784994, Semantic loss: 0.833031, BCE loss: 0.561375, SB loss: 0.789316
2023-10-30 03:34:01,623 Epoch: [85/484] Iter:[380/495], Time: 0.37, lr: [0.008390001359154492], Loss: 2.177486, Acc:0.786150, Semantic loss: 0.830243, BCE loss: 0.559643, SB loss: 0.787601
2023-10-30 03:34:05,372 Epoch: [85/484] Iter:[390/495], Time: 0.37, lr: [0.00838961830168454], Loss: 2.178896, Acc:0.786770, Semantic loss: 0.830471, BCE loss: 0.560626, SB loss: 0.787800
2023-10-30 03:34:09,155 Epoch: [85/484] Iter:[400/495], Time: 0.37, lr: [0.008389235242271266], Loss: 2.179225, Acc:0.786458, Semantic loss: 0.831692, BCE loss: 0.559308, SB loss: 0.788224
2023-10-30 03:34:12,854 Epoch: [85/484] Iter:[410/495], Time: 0.37, lr: [0.008388852180914556], Loss: 2.175420, Acc:0.787215, Semantic loss: 0.828969, BCE loss: 0.559644, SB loss: 0.786808
2023-10-30 03:34:16,489 Epoch: [85/484] Iter:[420/495], Time: 0.37, lr: [0.008388469117614305], Loss: 2.173266, Acc:0.786544, Semantic loss: 0.829739, BCE loss: 0.557403, SB loss: 0.786123
2023-10-30 03:34:20,184 Epoch: [85/484] Iter:[430/495], Time: 0.37, lr: [0.008388086052370403], Loss: 2.167484, Acc:0.786836, Semantic loss: 0.826726, BCE loss: 0.555807, SB loss: 0.784951
2023-10-30 03:34:23,875 Epoch: [85/484] Iter:[440/495], Time: 0.37, lr: [0.008387702985182743], Loss: 2.168964, Acc:0.787322, Semantic loss: 0.827802, BCE loss: 0.555336, SB loss: 0.785826
2023-10-30 03:34:27,551 Epoch: [85/484] Iter:[450/495], Time: 0.37, lr: [0.008387319916051217], Loss: 2.170395, Acc:0.787272, Semantic loss: 0.828898, BCE loss: 0.555123, SB loss: 0.786374
2023-10-30 03:34:31,280 Epoch: [85/484] Iter:[460/495], Time: 0.37, lr: [0.008386936844975714], Loss: 2.173164, Acc:0.787015, Semantic loss: 0.830427, BCE loss: 0.555849, SB loss: 0.786888
2023-10-30 03:34:34,966 Epoch: [85/484] Iter:[470/495], Time: 0.37, lr: [0.008386553771956127], Loss: 2.173872, Acc:0.787221, Semantic loss: 0.830652, BCE loss: 0.556389, SB loss: 0.786832
2023-10-30 03:34:38,673 Epoch: [85/484] Iter:[480/495], Time: 0.37, lr: [0.00838617069699235], Loss: 2.172883, Acc:0.786899, Semantic loss: 0.829592, BCE loss: 0.556742, SB loss: 0.786549
2023-10-30 03:34:42,182 Epoch: [85/484] Iter:[490/495], Time: 0.37, lr: [0.008385787620084269], Loss: 2.169557, Acc:0.786474, Semantic loss: 0.828049, BCE loss: 0.555876, SB loss: 0.785632
2023-10-30 03:37:37,950 0 [9.30793125e-01 6.25634168e-01 8.06799568e-01 1.49843034e-01
 2.25625336e-01 4.13776961e-01 4.27730749e-01 5.76443935e-01
 8.67070447e-01 4.32998041e-01 8.48083267e-01 5.94363215e-01
 6.73483070e-04 8.01052292e-01 0.00000000e+00 4.18056152e-02
 2.25808120e-02 1.91709037e-02 5.15923776e-01] 0.4368615119479936
2023-10-30 03:37:37,950 1 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ] 0.6627067987996593
2023-10-30 03:37:37,954 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:37:38,187 Loss: 2.048, MeanIU:  0.6627, Best_mIoU:  0.6835
2023-10-30 03:37:38,187 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ]
2023-10-30 03:37:40,362 Epoch: [86/484] Iter:[0/495], Time: 2.14, lr: [0.008385596080901083], Loss: 2.216410, Acc:0.768738, Semantic loss: 0.934711, BCE loss: 0.502751, SB loss: 0.778949
2023-10-30 03:37:44,116 Epoch: [86/484] Iter:[10/495], Time: 0.54, lr: [0.008385213001076348], Loss: 2.063316, Acc:0.783416, Semantic loss: 0.799474, BCE loss: 0.482239, SB loss: 0.781604
2023-10-30 03:37:47,816 Epoch: [86/484] Iter:[20/495], Time: 0.46, lr: [0.00838482991930704], Loss: 2.102200, Acc:0.792100, Semantic loss: 0.819497, BCE loss: 0.493997, SB loss: 0.788705
2023-10-30 03:37:51,250 Epoch: [86/484] Iter:[30/495], Time: 0.42, lr: [0.008384446835593052], Loss: 2.159764, Acc:0.804929, Semantic loss: 0.837881, BCE loss: 0.526566, SB loss: 0.795316
2023-10-30 03:37:54,741 Epoch: [86/484] Iter:[40/495], Time: 0.40, lr: [0.008384063749934272], Loss: 2.169767, Acc:0.803225, Semantic loss: 0.851806, BCE loss: 0.533495, SB loss: 0.784466
2023-10-30 03:37:58,169 Epoch: [86/484] Iter:[50/495], Time: 0.39, lr: [0.008383680662330596], Loss: 2.164643, Acc:0.798745, Semantic loss: 0.838677, BCE loss: 0.548590, SB loss: 0.777375
2023-10-30 03:38:01,647 Epoch: [86/484] Iter:[60/495], Time: 0.38, lr: [0.00838329757278191], Loss: 2.197181, Acc:0.800128, Semantic loss: 0.856052, BCE loss: 0.555691, SB loss: 0.785438
2023-10-30 03:38:05,127 Epoch: [86/484] Iter:[70/495], Time: 0.38, lr: [0.00838291448128811], Loss: 2.182171, Acc:0.800105, Semantic loss: 0.843945, BCE loss: 0.555184, SB loss: 0.783041
2023-10-30 03:38:08,669 Epoch: [86/484] Iter:[80/495], Time: 0.38, lr: [0.008382531387849087], Loss: 2.182363, Acc:0.799717, Semantic loss: 0.837280, BCE loss: 0.560346, SB loss: 0.784738
2023-10-30 03:38:12,355 Epoch: [86/484] Iter:[90/495], Time: 0.38, lr: [0.00838214829246473], Loss: 2.190663, Acc:0.800691, Semantic loss: 0.842319, BCE loss: 0.560764, SB loss: 0.787580
2023-10-30 03:38:15,846 Epoch: [86/484] Iter:[100/495], Time: 0.37, lr: [0.008381765195134932], Loss: 2.195459, Acc:0.798853, Semantic loss: 0.851695, BCE loss: 0.557771, SB loss: 0.785993
2023-10-30 03:38:19,444 Epoch: [86/484] Iter:[110/495], Time: 0.37, lr: [0.008381382095859584], Loss: 2.191046, Acc:0.798572, Semantic loss: 0.846487, BCE loss: 0.556796, SB loss: 0.787763
2023-10-30 03:38:23,070 Epoch: [86/484] Iter:[120/495], Time: 0.37, lr: [0.008380998994638575], Loss: 2.182251, Acc:0.794980, Semantic loss: 0.844106, BCE loss: 0.550788, SB loss: 0.787358
2023-10-30 03:38:26,689 Epoch: [86/484] Iter:[130/495], Time: 0.37, lr: [0.008380615891471798], Loss: 2.198738, Acc:0.794165, Semantic loss: 0.852476, BCE loss: 0.553882, SB loss: 0.792379
2023-10-30 03:38:30,300 Epoch: [86/484] Iter:[140/495], Time: 0.37, lr: [0.008380232786359148], Loss: 2.197969, Acc:0.792973, Semantic loss: 0.849088, BCE loss: 0.557530, SB loss: 0.791351
2023-10-30 03:38:34,016 Epoch: [86/484] Iter:[150/495], Time: 0.37, lr: [0.008379849679300512], Loss: 2.179058, Acc:0.793945, Semantic loss: 0.839347, BCE loss: 0.551607, SB loss: 0.788104
2023-10-30 03:38:37,595 Epoch: [86/484] Iter:[160/495], Time: 0.37, lr: [0.008379466570295781], Loss: 2.177302, Acc:0.792665, Semantic loss: 0.839488, BCE loss: 0.548860, SB loss: 0.788955
2023-10-30 03:38:41,202 Epoch: [86/484] Iter:[170/495], Time: 0.37, lr: [0.008379083459344846], Loss: 2.167015, Acc:0.792476, Semantic loss: 0.832324, BCE loss: 0.548053, SB loss: 0.786638
2023-10-30 03:38:44,834 Epoch: [86/484] Iter:[180/495], Time: 0.37, lr: [0.008378700346447603], Loss: 2.166282, Acc:0.790326, Semantic loss: 0.831355, BCE loss: 0.548812, SB loss: 0.786115
2023-10-30 03:38:48,384 Epoch: [86/484] Iter:[190/495], Time: 0.37, lr: [0.008378317231603939], Loss: 2.167922, Acc:0.790699, Semantic loss: 0.833584, BCE loss: 0.548558, SB loss: 0.785779
2023-10-30 03:38:51,977 Epoch: [86/484] Iter:[200/495], Time: 0.37, lr: [0.008377934114813744], Loss: 2.164406, Acc:0.790710, Semantic loss: 0.829578, BCE loss: 0.548895, SB loss: 0.785932
2023-10-30 03:38:55,566 Epoch: [86/484] Iter:[210/495], Time: 0.37, lr: [0.008377550996076913], Loss: 2.150778, Acc:0.790462, Semantic loss: 0.822814, BCE loss: 0.545864, SB loss: 0.782100
2023-10-30 03:38:59,307 Epoch: [86/484] Iter:[220/495], Time: 0.37, lr: [0.008377167875393334], Loss: 2.151793, Acc:0.791028, Semantic loss: 0.824581, BCE loss: 0.544992, SB loss: 0.782221
2023-10-30 03:39:02,950 Epoch: [86/484] Iter:[230/495], Time: 0.37, lr: [0.008376784752762902], Loss: 2.149910, Acc:0.792213, Semantic loss: 0.824533, BCE loss: 0.543548, SB loss: 0.781829
2023-10-30 03:39:06,570 Epoch: [86/484] Iter:[240/495], Time: 0.37, lr: [0.008376401628185506], Loss: 2.160182, Acc:0.790688, Semantic loss: 0.832320, BCE loss: 0.541587, SB loss: 0.786274
2023-10-30 03:39:10,121 Epoch: [86/484] Iter:[250/495], Time: 0.37, lr: [0.008376018501661033], Loss: 2.157636, Acc:0.789807, Semantic loss: 0.830376, BCE loss: 0.541248, SB loss: 0.786013
2023-10-30 03:39:13,710 Epoch: [86/484] Iter:[260/495], Time: 0.37, lr: [0.008375635373189382], Loss: 2.159380, Acc:0.790107, Semantic loss: 0.832194, BCE loss: 0.541988, SB loss: 0.785198
2023-10-30 03:39:17,448 Epoch: [86/484] Iter:[270/495], Time: 0.37, lr: [0.008375252242770439], Loss: 2.155289, Acc:0.789503, Semantic loss: 0.828083, BCE loss: 0.543195, SB loss: 0.784011
2023-10-30 03:39:21,113 Epoch: [86/484] Iter:[280/495], Time: 0.37, lr: [0.008374869110404096], Loss: 2.158298, Acc:0.789766, Semantic loss: 0.829487, BCE loss: 0.543383, SB loss: 0.785428
2023-10-30 03:39:24,808 Epoch: [86/484] Iter:[290/495], Time: 0.37, lr: [0.008374485976090246], Loss: 2.156897, Acc:0.789647, Semantic loss: 0.826403, BCE loss: 0.546516, SB loss: 0.783978
2023-10-30 03:39:28,523 Epoch: [86/484] Iter:[300/495], Time: 0.37, lr: [0.008374102839828777], Loss: 2.161408, Acc:0.789456, Semantic loss: 0.826737, BCE loss: 0.550149, SB loss: 0.784523
2023-10-30 03:39:32,160 Epoch: [86/484] Iter:[310/495], Time: 0.37, lr: [0.008373719701619584], Loss: 2.158053, Acc:0.790089, Semantic loss: 0.823447, BCE loss: 0.551430, SB loss: 0.783176
2023-10-30 03:39:35,824 Epoch: [86/484] Iter:[320/495], Time: 0.37, lr: [0.008373336561462554], Loss: 2.161094, Acc:0.790530, Semantic loss: 0.823747, BCE loss: 0.553584, SB loss: 0.783762
2023-10-30 03:39:39,480 Epoch: [86/484] Iter:[330/495], Time: 0.37, lr: [0.008372953419357579], Loss: 2.157652, Acc:0.791423, Semantic loss: 0.821116, BCE loss: 0.553928, SB loss: 0.782609
2023-10-30 03:39:43,154 Epoch: [86/484] Iter:[340/495], Time: 0.37, lr: [0.008372570275304553], Loss: 2.160210, Acc:0.790958, Semantic loss: 0.823097, BCE loss: 0.554248, SB loss: 0.782865
2023-10-30 03:39:47,023 Epoch: [86/484] Iter:[350/495], Time: 0.37, lr: [0.008372187129303363], Loss: 2.159051, Acc:0.791365, Semantic loss: 0.822567, BCE loss: 0.554029, SB loss: 0.782456
2023-10-30 03:39:50,703 Epoch: [86/484] Iter:[360/495], Time: 0.37, lr: [0.008371803981353903], Loss: 2.160164, Acc:0.791916, Semantic loss: 0.822179, BCE loss: 0.555675, SB loss: 0.782310
2023-10-30 03:39:54,305 Epoch: [86/484] Iter:[370/495], Time: 0.37, lr: [0.008371420831456063], Loss: 2.160054, Acc:0.792327, Semantic loss: 0.821503, BCE loss: 0.556307, SB loss: 0.782244
2023-10-30 03:39:58,007 Epoch: [86/484] Iter:[380/495], Time: 0.37, lr: [0.008371037679609736], Loss: 2.165310, Acc:0.790913, Semantic loss: 0.824621, BCE loss: 0.557583, SB loss: 0.783106
2023-10-30 03:40:01,726 Epoch: [86/484] Iter:[390/495], Time: 0.37, lr: [0.008370654525814808], Loss: 2.165035, Acc:0.790248, Semantic loss: 0.823975, BCE loss: 0.557674, SB loss: 0.783385
2023-10-30 03:40:05,283 Epoch: [86/484] Iter:[400/495], Time: 0.37, lr: [0.008370271370071175], Loss: 2.165541, Acc:0.790784, Semantic loss: 0.823390, BCE loss: 0.557627, SB loss: 0.784525
2023-10-30 03:40:09,039 Epoch: [86/484] Iter:[410/495], Time: 0.37, lr: [0.008369888212378725], Loss: 2.164073, Acc:0.790974, Semantic loss: 0.822969, BCE loss: 0.557067, SB loss: 0.784037
2023-10-30 03:40:12,693 Epoch: [86/484] Iter:[420/495], Time: 0.37, lr: [0.00836950505273735], Loss: 2.165912, Acc:0.791226, Semantic loss: 0.823993, BCE loss: 0.558261, SB loss: 0.783658
2023-10-30 03:40:16,340 Epoch: [86/484] Iter:[430/495], Time: 0.37, lr: [0.00836912189114694], Loss: 2.163406, Acc:0.790681, Semantic loss: 0.821626, BCE loss: 0.558383, SB loss: 0.783397
2023-10-30 03:40:20,004 Epoch: [86/484] Iter:[440/495], Time: 0.37, lr: [0.008368738727607388], Loss: 2.162070, Acc:0.790854, Semantic loss: 0.820799, BCE loss: 0.557604, SB loss: 0.783668
2023-10-30 03:40:23,769 Epoch: [86/484] Iter:[450/495], Time: 0.37, lr: [0.008368355562118584], Loss: 2.170782, Acc:0.790663, Semantic loss: 0.828497, BCE loss: 0.558007, SB loss: 0.784278
2023-10-30 03:40:27,448 Epoch: [86/484] Iter:[460/495], Time: 0.37, lr: [0.008367972394680418], Loss: 2.174480, Acc:0.789660, Semantic loss: 0.830084, BCE loss: 0.558046, SB loss: 0.786350
2023-10-30 03:40:31,102 Epoch: [86/484] Iter:[470/495], Time: 0.37, lr: [0.008367589225292783], Loss: 2.171316, Acc:0.789860, Semantic loss: 0.827732, BCE loss: 0.558021, SB loss: 0.785563
2023-10-30 03:40:34,733 Epoch: [86/484] Iter:[480/495], Time: 0.37, lr: [0.008367206053955566], Loss: 2.177168, Acc:0.790269, Semantic loss: 0.830897, BCE loss: 0.559749, SB loss: 0.786523
2023-10-30 03:40:38,233 Epoch: [86/484] Iter:[490/495], Time: 0.37, lr: [0.00836682288066866], Loss: 2.177234, Acc:0.789959, Semantic loss: 0.830986, BCE loss: 0.559918, SB loss: 0.786331
2023-10-30 03:40:39,629 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:40:39,867 Loss: 2.048, MeanIU:  0.6627, Best_mIoU:  0.6835
2023-10-30 03:40:39,867 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ]
2023-10-30 03:40:42,080 Epoch: [87/484] Iter:[0/495], Time: 2.18, lr: [0.008366631293294041], Loss: 2.519373, Acc:0.819043, Semantic loss: 1.155589, BCE loss: 0.542967, SB loss: 0.820817
2023-10-30 03:40:46,120 Epoch: [87/484] Iter:[10/495], Time: 0.57, lr: [0.0083662481170824], Loss: 2.085502, Acc:0.783492, Semantic loss: 0.809101, BCE loss: 0.503415, SB loss: 0.772986
2023-10-30 03:40:49,797 Epoch: [87/484] Iter:[20/495], Time: 0.47, lr: [0.008365864938920796], Loss: 2.159868, Acc:0.789763, Semantic loss: 0.822332, BCE loss: 0.563156, SB loss: 0.774380
2023-10-30 03:40:53,480 Epoch: [87/484] Iter:[30/495], Time: 0.44, lr: [0.00836548175880912], Loss: 2.147111, Acc:0.796552, Semantic loss: 0.793726, BCE loss: 0.582182, SB loss: 0.771203
2023-10-30 03:40:57,134 Epoch: [87/484] Iter:[40/495], Time: 0.42, lr: [0.008365098576747268], Loss: 2.147585, Acc:0.786282, Semantic loss: 0.809074, BCE loss: 0.569140, SB loss: 0.769372
2023-10-30 03:41:00,738 Epoch: [87/484] Iter:[50/495], Time: 0.41, lr: [0.008364715392735126], Loss: 2.174093, Acc:0.779524, Semantic loss: 0.829564, BCE loss: 0.560744, SB loss: 0.783786
2023-10-30 03:41:04,430 Epoch: [87/484] Iter:[60/495], Time: 0.40, lr: [0.008364332206772584], Loss: 2.158136, Acc:0.782673, Semantic loss: 0.817139, BCE loss: 0.559174, SB loss: 0.781824
2023-10-30 03:41:08,047 Epoch: [87/484] Iter:[70/495], Time: 0.40, lr: [0.008363949018859534], Loss: 2.161472, Acc:0.782777, Semantic loss: 0.820726, BCE loss: 0.555029, SB loss: 0.785718
2023-10-30 03:41:11,692 Epoch: [87/484] Iter:[80/495], Time: 0.39, lr: [0.00836356582899587], Loss: 2.148812, Acc:0.783364, Semantic loss: 0.814379, BCE loss: 0.551420, SB loss: 0.783014
2023-10-30 03:41:15,278 Epoch: [87/484] Iter:[90/495], Time: 0.39, lr: [0.008363182637181478], Loss: 2.158320, Acc:0.784369, Semantic loss: 0.823240, BCE loss: 0.549418, SB loss: 0.785663
2023-10-30 03:41:18,971 Epoch: [87/484] Iter:[100/495], Time: 0.39, lr: [0.00836279944341625], Loss: 2.143190, Acc:0.787054, Semantic loss: 0.813685, BCE loss: 0.549046, SB loss: 0.780459
2023-10-30 03:41:22,813 Epoch: [87/484] Iter:[110/495], Time: 0.39, lr: [0.00836241624770008], Loss: 2.128146, Acc:0.792595, Semantic loss: 0.802124, BCE loss: 0.551609, SB loss: 0.774413
2023-10-30 03:41:26,568 Epoch: [87/484] Iter:[120/495], Time: 0.39, lr: [0.008362033050032856], Loss: 2.147337, Acc:0.790761, Semantic loss: 0.811795, BCE loss: 0.556029, SB loss: 0.779513
2023-10-30 03:41:30,335 Epoch: [87/484] Iter:[130/495], Time: 0.38, lr: [0.008361649850414469], Loss: 2.147033, Acc:0.796468, Semantic loss: 0.807570, BCE loss: 0.560611, SB loss: 0.778852
2023-10-30 03:41:33,982 Epoch: [87/484] Iter:[140/495], Time: 0.38, lr: [0.00836126664884481], Loss: 2.149739, Acc:0.795314, Semantic loss: 0.808555, BCE loss: 0.560736, SB loss: 0.780448
2023-10-30 03:41:37,644 Epoch: [87/484] Iter:[150/495], Time: 0.38, lr: [0.008360883445323769], Loss: 2.156462, Acc:0.795912, Semantic loss: 0.813912, BCE loss: 0.560283, SB loss: 0.782266
2023-10-30 03:41:41,261 Epoch: [87/484] Iter:[160/495], Time: 0.38, lr: [0.008360500239851236], Loss: 2.150434, Acc:0.794933, Semantic loss: 0.812326, BCE loss: 0.558632, SB loss: 0.779476
2023-10-30 03:41:45,007 Epoch: [87/484] Iter:[170/495], Time: 0.38, lr: [0.008360117032427103], Loss: 2.153126, Acc:0.795123, Semantic loss: 0.815929, BCE loss: 0.555719, SB loss: 0.781478
2023-10-30 03:41:48,737 Epoch: [87/484] Iter:[180/495], Time: 0.38, lr: [0.008359733823051262], Loss: 2.147036, Acc:0.795162, Semantic loss: 0.814037, BCE loss: 0.553580, SB loss: 0.779420
2023-10-30 03:41:52,394 Epoch: [87/484] Iter:[190/495], Time: 0.38, lr: [0.008359350611723602], Loss: 2.144855, Acc:0.795278, Semantic loss: 0.815206, BCE loss: 0.550860, SB loss: 0.778789
2023-10-30 03:41:56,107 Epoch: [87/484] Iter:[200/495], Time: 0.38, lr: [0.008358967398444012], Loss: 2.143366, Acc:0.795756, Semantic loss: 0.813495, BCE loss: 0.552306, SB loss: 0.777565
2023-10-30 03:41:59,848 Epoch: [87/484] Iter:[210/495], Time: 0.38, lr: [0.008358584183212388], Loss: 2.151604, Acc:0.794662, Semantic loss: 0.819582, BCE loss: 0.553429, SB loss: 0.778592
2023-10-30 03:42:03,577 Epoch: [87/484] Iter:[220/495], Time: 0.38, lr: [0.008358200966028614], Loss: 2.142316, Acc:0.795949, Semantic loss: 0.814231, BCE loss: 0.551009, SB loss: 0.777076
2023-10-30 03:42:07,136 Epoch: [87/484] Iter:[230/495], Time: 0.38, lr: [0.008357817746892584], Loss: 2.138951, Acc:0.795390, Semantic loss: 0.811694, BCE loss: 0.549734, SB loss: 0.777523
2023-10-30 03:42:10,833 Epoch: [87/484] Iter:[240/495], Time: 0.38, lr: [0.008357434525804189], Loss: 2.129119, Acc:0.794980, Semantic loss: 0.805516, BCE loss: 0.547881, SB loss: 0.775721
2023-10-30 03:42:14,495 Epoch: [87/484] Iter:[250/495], Time: 0.38, lr: [0.008357051302763319], Loss: 2.141454, Acc:0.794317, Semantic loss: 0.812523, BCE loss: 0.550459, SB loss: 0.778472
2023-10-30 03:42:18,197 Epoch: [87/484] Iter:[260/495], Time: 0.38, lr: [0.008356668077769863], Loss: 2.139771, Acc:0.794520, Semantic loss: 0.811646, BCE loss: 0.550087, SB loss: 0.778038
2023-10-30 03:42:21,906 Epoch: [87/484] Iter:[270/495], Time: 0.38, lr: [0.008356284850823714], Loss: 2.141576, Acc:0.793954, Semantic loss: 0.813327, BCE loss: 0.550713, SB loss: 0.777535
2023-10-30 03:42:25,606 Epoch: [87/484] Iter:[280/495], Time: 0.38, lr: [0.008355901621924762], Loss: 2.138417, Acc:0.793664, Semantic loss: 0.813154, BCE loss: 0.549155, SB loss: 0.776108
2023-10-30 03:42:29,251 Epoch: [87/484] Iter:[290/495], Time: 0.38, lr: [0.008355518391072896], Loss: 2.133908, Acc:0.793986, Semantic loss: 0.809566, BCE loss: 0.548979, SB loss: 0.775363
2023-10-30 03:42:32,876 Epoch: [87/484] Iter:[300/495], Time: 0.38, lr: [0.00835513515826801], Loss: 2.140270, Acc:0.794341, Semantic loss: 0.814845, BCE loss: 0.549869, SB loss: 0.775555
2023-10-30 03:42:36,541 Epoch: [87/484] Iter:[310/495], Time: 0.38, lr: [0.008354751923509988], Loss: 2.149551, Acc:0.793887, Semantic loss: 0.819607, BCE loss: 0.552083, SB loss: 0.777862
2023-10-30 03:42:40,179 Epoch: [87/484] Iter:[320/495], Time: 0.37, lr: [0.008354368686798726], Loss: 2.149094, Acc:0.793434, Semantic loss: 0.819125, BCE loss: 0.551939, SB loss: 0.778030
2023-10-30 03:42:43,967 Epoch: [87/484] Iter:[330/495], Time: 0.37, lr: [0.008353985448134114], Loss: 2.151696, Acc:0.793769, Semantic loss: 0.818633, BCE loss: 0.553364, SB loss: 0.779699
2023-10-30 03:42:47,689 Epoch: [87/484] Iter:[340/495], Time: 0.37, lr: [0.00835360220751604], Loss: 2.149298, Acc:0.793276, Semantic loss: 0.817616, BCE loss: 0.552842, SB loss: 0.778840
2023-10-30 03:42:51,436 Epoch: [87/484] Iter:[350/495], Time: 0.37, lr: [0.0083532189649444], Loss: 2.149956, Acc:0.792684, Semantic loss: 0.817954, BCE loss: 0.552475, SB loss: 0.779528
2023-10-30 03:42:55,066 Epoch: [87/484] Iter:[360/495], Time: 0.37, lr: [0.008352835720419076], Loss: 2.148822, Acc:0.791776, Semantic loss: 0.817624, BCE loss: 0.551532, SB loss: 0.779666
2023-10-30 03:42:58,839 Epoch: [87/484] Iter:[370/495], Time: 0.37, lr: [0.008352452473939965], Loss: 2.146436, Acc:0.790884, Semantic loss: 0.816678, BCE loss: 0.550711, SB loss: 0.779047
2023-10-30 03:43:02,574 Epoch: [87/484] Iter:[380/495], Time: 0.37, lr: [0.008352069225506955], Loss: 2.144181, Acc:0.791600, Semantic loss: 0.814182, BCE loss: 0.551457, SB loss: 0.778542
2023-10-30 03:43:06,273 Epoch: [87/484] Iter:[390/495], Time: 0.37, lr: [0.008351685975119936], Loss: 2.142707, Acc:0.791352, Semantic loss: 0.813655, BCE loss: 0.551255, SB loss: 0.777797
2023-10-30 03:43:09,904 Epoch: [87/484] Iter:[400/495], Time: 0.37, lr: [0.0083513027227788], Loss: 2.144961, Acc:0.791556, Semantic loss: 0.815346, BCE loss: 0.550903, SB loss: 0.778712
2023-10-30 03:43:13,570 Epoch: [87/484] Iter:[410/495], Time: 0.37, lr: [0.008350919468483436], Loss: 2.142183, Acc:0.791062, Semantic loss: 0.812301, BCE loss: 0.551404, SB loss: 0.778478
2023-10-30 03:43:17,273 Epoch: [87/484] Iter:[420/495], Time: 0.37, lr: [0.008350536212233736], Loss: 2.144566, Acc:0.790832, Semantic loss: 0.813553, BCE loss: 0.552406, SB loss: 0.778607
2023-10-30 03:43:21,023 Epoch: [87/484] Iter:[430/495], Time: 0.37, lr: [0.00835015295402959], Loss: 2.144773, Acc:0.791554, Semantic loss: 0.814593, BCE loss: 0.551549, SB loss: 0.778631
2023-10-30 03:43:24,624 Epoch: [87/484] Iter:[440/495], Time: 0.37, lr: [0.008349769693870884], Loss: 2.142559, Acc:0.791471, Semantic loss: 0.814085, BCE loss: 0.550358, SB loss: 0.778115
2023-10-30 03:43:28,340 Epoch: [87/484] Iter:[450/495], Time: 0.37, lr: [0.008349386431757515], Loss: 2.142348, Acc:0.791703, Semantic loss: 0.812724, BCE loss: 0.551720, SB loss: 0.777904
2023-10-30 03:43:32,019 Epoch: [87/484] Iter:[460/495], Time: 0.37, lr: [0.00834900316768937], Loss: 2.142437, Acc:0.791705, Semantic loss: 0.813063, BCE loss: 0.551402, SB loss: 0.777972
2023-10-30 03:43:35,637 Epoch: [87/484] Iter:[470/495], Time: 0.37, lr: [0.008348619901666339], Loss: 2.143560, Acc:0.791996, Semantic loss: 0.812696, BCE loss: 0.552698, SB loss: 0.778166
2023-10-30 03:43:39,275 Epoch: [87/484] Iter:[480/495], Time: 0.37, lr: [0.008348236633688314], Loss: 2.144574, Acc:0.791830, Semantic loss: 0.812607, BCE loss: 0.553689, SB loss: 0.778277
2023-10-30 03:43:42,768 Epoch: [87/484] Iter:[490/495], Time: 0.37, lr: [0.008347853363755183], Loss: 2.141054, Acc:0.791212, Semantic loss: 0.811278, BCE loss: 0.552011, SB loss: 0.777765
2023-10-30 03:43:44,168 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:43:44,400 Loss: 2.048, MeanIU:  0.6627, Best_mIoU:  0.6835
2023-10-30 03:43:44,400 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ]
2023-10-30 03:43:46,603 Epoch: [88/484] Iter:[0/495], Time: 2.17, lr: [0.008347661728055417], Loss: 2.063056, Acc:0.871770, Semantic loss: 0.734073, BCE loss: 0.574336, SB loss: 0.754647
2023-10-30 03:43:50,707 Epoch: [88/484] Iter:[10/495], Time: 0.57, lr: [0.008347278455189424], Loss: 2.075208, Acc:0.784507, Semantic loss: 0.824816, BCE loss: 0.487041, SB loss: 0.763351
2023-10-30 03:43:54,415 Epoch: [88/484] Iter:[20/495], Time: 0.48, lr: [0.008346895180368052], Loss: 2.124105, Acc:0.792278, Semantic loss: 0.847105, BCE loss: 0.511132, SB loss: 0.765868
2023-10-30 03:43:58,056 Epoch: [88/484] Iter:[30/495], Time: 0.44, lr: [0.00834651190359119], Loss: 2.092480, Acc:0.792040, Semantic loss: 0.791731, BCE loss: 0.544018, SB loss: 0.756730
2023-10-30 03:44:01,592 Epoch: [88/484] Iter:[40/495], Time: 0.42, lr: [0.008346128624858732], Loss: 2.076741, Acc:0.791768, Semantic loss: 0.773582, BCE loss: 0.553510, SB loss: 0.749650
2023-10-30 03:44:05,312 Epoch: [88/484] Iter:[50/495], Time: 0.41, lr: [0.008345745344170563], Loss: 2.080388, Acc:0.793796, Semantic loss: 0.772933, BCE loss: 0.550035, SB loss: 0.757420
2023-10-30 03:44:08,979 Epoch: [88/484] Iter:[60/495], Time: 0.40, lr: [0.008345362061526578], Loss: 2.094988, Acc:0.794044, Semantic loss: 0.790551, BCE loss: 0.544751, SB loss: 0.759687
2023-10-30 03:44:12,712 Epoch: [88/484] Iter:[70/495], Time: 0.40, lr: [0.008344978776926663], Loss: 2.081122, Acc:0.794379, Semantic loss: 0.782050, BCE loss: 0.544155, SB loss: 0.754917
2023-10-30 03:44:16,491 Epoch: [88/484] Iter:[80/495], Time: 0.40, lr: [0.00834459549037071], Loss: 2.084897, Acc:0.791923, Semantic loss: 0.780751, BCE loss: 0.546275, SB loss: 0.757871
2023-10-30 03:44:20,174 Epoch: [88/484] Iter:[90/495], Time: 0.39, lr: [0.008344212201858612], Loss: 2.092779, Acc:0.790643, Semantic loss: 0.786198, BCE loss: 0.543695, SB loss: 0.762885
2023-10-30 03:44:23,941 Epoch: [88/484] Iter:[100/495], Time: 0.39, lr: [0.008343828911390256], Loss: 2.074369, Acc:0.790914, Semantic loss: 0.775143, BCE loss: 0.537961, SB loss: 0.761266
2023-10-30 03:44:27,508 Epoch: [88/484] Iter:[110/495], Time: 0.39, lr: [0.008343445618965533], Loss: 2.080796, Acc:0.788821, Semantic loss: 0.777748, BCE loss: 0.539543, SB loss: 0.763506
2023-10-30 03:44:31,126 Epoch: [88/484] Iter:[120/495], Time: 0.39, lr: [0.008343062324584333], Loss: 2.073568, Acc:0.788149, Semantic loss: 0.772432, BCE loss: 0.537365, SB loss: 0.763771
2023-10-30 03:44:34,841 Epoch: [88/484] Iter:[130/495], Time: 0.38, lr: [0.008342679028246544], Loss: 2.080791, Acc:0.787017, Semantic loss: 0.779943, BCE loss: 0.535171, SB loss: 0.765677
2023-10-30 03:44:38,523 Epoch: [88/484] Iter:[140/495], Time: 0.38, lr: [0.00834229572995206], Loss: 2.086966, Acc:0.788805, Semantic loss: 0.784252, BCE loss: 0.535323, SB loss: 0.767390
2023-10-30 03:44:42,166 Epoch: [88/484] Iter:[150/495], Time: 0.38, lr: [0.008341912429700771], Loss: 2.076888, Acc:0.788538, Semantic loss: 0.777630, BCE loss: 0.534038, SB loss: 0.765219
2023-10-30 03:44:45,782 Epoch: [88/484] Iter:[160/495], Time: 0.38, lr: [0.008341529127492564], Loss: 2.076290, Acc:0.789728, Semantic loss: 0.775976, BCE loss: 0.537516, SB loss: 0.762797
2023-10-30 03:44:49,502 Epoch: [88/484] Iter:[170/495], Time: 0.38, lr: [0.00834114582332733], Loss: 2.090237, Acc:0.789624, Semantic loss: 0.789508, BCE loss: 0.535644, SB loss: 0.765085
2023-10-30 03:44:53,101 Epoch: [88/484] Iter:[180/495], Time: 0.38, lr: [0.008340762517204961], Loss: 2.096153, Acc:0.789528, Semantic loss: 0.789160, BCE loss: 0.539762, SB loss: 0.767232
2023-10-30 03:44:56,857 Epoch: [88/484] Iter:[190/495], Time: 0.38, lr: [0.008340379209125346], Loss: 2.093435, Acc:0.789739, Semantic loss: 0.789103, BCE loss: 0.538841, SB loss: 0.765491
2023-10-30 03:45:00,489 Epoch: [88/484] Iter:[200/495], Time: 0.38, lr: [0.008339995899088373], Loss: 2.095187, Acc:0.789849, Semantic loss: 0.788077, BCE loss: 0.541750, SB loss: 0.765361
2023-10-30 03:45:04,250 Epoch: [88/484] Iter:[210/495], Time: 0.38, lr: [0.008339612587093934], Loss: 2.097965, Acc:0.788699, Semantic loss: 0.787724, BCE loss: 0.544018, SB loss: 0.766223
2023-10-30 03:45:07,937 Epoch: [88/484] Iter:[220/495], Time: 0.38, lr: [0.008339229273141919], Loss: 2.102136, Acc:0.788969, Semantic loss: 0.789037, BCE loss: 0.545631, SB loss: 0.767467
2023-10-30 03:45:11,726 Epoch: [88/484] Iter:[230/495], Time: 0.38, lr: [0.00833884595723222], Loss: 2.105876, Acc:0.789324, Semantic loss: 0.790074, BCE loss: 0.547131, SB loss: 0.768671
2023-10-30 03:45:15,612 Epoch: [88/484] Iter:[240/495], Time: 0.38, lr: [0.008338462639364722], Loss: 2.101621, Acc:0.789559, Semantic loss: 0.786510, BCE loss: 0.547627, SB loss: 0.767484
2023-10-30 03:45:19,347 Epoch: [88/484] Iter:[250/495], Time: 0.38, lr: [0.00833807931953932], Loss: 2.104827, Acc:0.789575, Semantic loss: 0.788823, BCE loss: 0.546677, SB loss: 0.769327
2023-10-30 03:45:23,071 Epoch: [88/484] Iter:[260/495], Time: 0.38, lr: [0.008337695997755901], Loss: 2.110301, Acc:0.789910, Semantic loss: 0.790659, BCE loss: 0.548143, SB loss: 0.771499
2023-10-30 03:45:26,892 Epoch: [88/484] Iter:[270/495], Time: 0.38, lr: [0.008337312674014358], Loss: 2.105590, Acc:0.790977, Semantic loss: 0.788166, BCE loss: 0.546374, SB loss: 0.771049
2023-10-30 03:45:30,632 Epoch: [88/484] Iter:[280/495], Time: 0.38, lr: [0.008336929348314577], Loss: 2.101459, Acc:0.792447, Semantic loss: 0.787016, BCE loss: 0.544531, SB loss: 0.769911
2023-10-30 03:45:34,435 Epoch: [88/484] Iter:[290/495], Time: 0.38, lr: [0.008336546020656449], Loss: 2.107364, Acc:0.793456, Semantic loss: 0.789102, BCE loss: 0.546539, SB loss: 0.771724
2023-10-30 03:45:38,154 Epoch: [88/484] Iter:[300/495], Time: 0.38, lr: [0.008336162691039867], Loss: 2.103247, Acc:0.794574, Semantic loss: 0.786747, BCE loss: 0.545768, SB loss: 0.770733
2023-10-30 03:45:41,829 Epoch: [88/484] Iter:[310/495], Time: 0.38, lr: [0.008335779359464718], Loss: 2.102916, Acc:0.793554, Semantic loss: 0.787019, BCE loss: 0.545735, SB loss: 0.770162
2023-10-30 03:45:45,700 Epoch: [88/484] Iter:[320/495], Time: 0.38, lr: [0.008335396025930891], Loss: 2.108359, Acc:0.793437, Semantic loss: 0.791050, BCE loss: 0.546199, SB loss: 0.771110
2023-10-30 03:45:49,332 Epoch: [88/484] Iter:[330/495], Time: 0.38, lr: [0.008335012690438279], Loss: 2.107298, Acc:0.794549, Semantic loss: 0.789879, BCE loss: 0.546723, SB loss: 0.770697
2023-10-30 03:45:53,186 Epoch: [88/484] Iter:[340/495], Time: 0.38, lr: [0.00833462935298677], Loss: 2.113385, Acc:0.792928, Semantic loss: 0.795607, BCE loss: 0.545478, SB loss: 0.772300
2023-10-30 03:45:56,997 Epoch: [88/484] Iter:[350/495], Time: 0.38, lr: [0.008334246013576255], Loss: 2.113337, Acc:0.792428, Semantic loss: 0.795672, BCE loss: 0.545076, SB loss: 0.772589
2023-10-30 03:46:00,686 Epoch: [88/484] Iter:[360/495], Time: 0.38, lr: [0.008333862672206623], Loss: 2.117346, Acc:0.793520, Semantic loss: 0.797993, BCE loss: 0.545633, SB loss: 0.773720
2023-10-30 03:46:04,396 Epoch: [88/484] Iter:[370/495], Time: 0.38, lr: [0.008333479328877763], Loss: 2.120710, Acc:0.793684, Semantic loss: 0.800270, BCE loss: 0.546707, SB loss: 0.773733
2023-10-30 03:46:08,066 Epoch: [88/484] Iter:[380/495], Time: 0.38, lr: [0.008333095983589566], Loss: 2.121167, Acc:0.794354, Semantic loss: 0.799533, BCE loss: 0.547415, SB loss: 0.774218
2023-10-30 03:46:11,953 Epoch: [88/484] Iter:[390/495], Time: 0.38, lr: [0.008332712636341923], Loss: 2.122481, Acc:0.794927, Semantic loss: 0.800214, BCE loss: 0.548105, SB loss: 0.774162
2023-10-30 03:46:15,647 Epoch: [88/484] Iter:[400/495], Time: 0.38, lr: [0.008332329287134722], Loss: 2.123313, Acc:0.795437, Semantic loss: 0.799353, BCE loss: 0.550245, SB loss: 0.773714
2023-10-30 03:46:19,330 Epoch: [88/484] Iter:[410/495], Time: 0.38, lr: [0.008331945935967852], Loss: 2.122387, Acc:0.795955, Semantic loss: 0.799142, BCE loss: 0.549830, SB loss: 0.773415
2023-10-30 03:46:23,169 Epoch: [88/484] Iter:[420/495], Time: 0.38, lr: [0.008331562582841205], Loss: 2.125793, Acc:0.795572, Semantic loss: 0.801360, BCE loss: 0.549856, SB loss: 0.774577
2023-10-30 03:46:26,891 Epoch: [88/484] Iter:[430/495], Time: 0.38, lr: [0.008331179227754672], Loss: 2.127600, Acc:0.795113, Semantic loss: 0.802228, BCE loss: 0.551036, SB loss: 0.774337
2023-10-30 03:46:30,546 Epoch: [88/484] Iter:[440/495], Time: 0.38, lr: [0.008330795870708138], Loss: 2.126587, Acc:0.795289, Semantic loss: 0.801742, BCE loss: 0.550680, SB loss: 0.774165
2023-10-30 03:46:34,218 Epoch: [88/484] Iter:[450/495], Time: 0.38, lr: [0.008330412511701496], Loss: 2.123396, Acc:0.795633, Semantic loss: 0.800550, BCE loss: 0.550194, SB loss: 0.772651
2023-10-30 03:46:37,865 Epoch: [88/484] Iter:[460/495], Time: 0.38, lr: [0.008330029150734636], Loss: 2.124774, Acc:0.795339, Semantic loss: 0.801114, BCE loss: 0.550408, SB loss: 0.773251
2023-10-30 03:46:41,521 Epoch: [88/484] Iter:[470/495], Time: 0.38, lr: [0.008329645787807444], Loss: 2.127554, Acc:0.794688, Semantic loss: 0.803960, BCE loss: 0.549224, SB loss: 0.774369
2023-10-30 03:46:45,148 Epoch: [88/484] Iter:[480/495], Time: 0.38, lr: [0.008329262422919816], Loss: 2.125236, Acc:0.794189, Semantic loss: 0.802817, BCE loss: 0.547944, SB loss: 0.774475
2023-10-30 03:46:48,665 Epoch: [88/484] Iter:[490/495], Time: 0.38, lr: [0.00832887905607164], Loss: 2.124941, Acc:0.793702, Semantic loss: 0.803515, BCE loss: 0.546632, SB loss: 0.774794
2023-10-30 03:46:50,058 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:46:50,293 Loss: 2.048, MeanIU:  0.6627, Best_mIoU:  0.6835
2023-10-30 03:46:50,293 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ]
2023-10-30 03:46:52,403 Epoch: [89/484] Iter:[0/495], Time: 2.08, lr: [0.00832868737191231], Loss: 2.375751, Acc:0.888128, Semantic loss: 1.099705, BCE loss: 0.453000, SB loss: 0.823046
2023-10-30 03:46:56,321 Epoch: [89/484] Iter:[10/495], Time: 0.54, lr: [0.008328304002123098], Loss: 2.211141, Acc:0.834044, Semantic loss: 0.925504, BCE loss: 0.515048, SB loss: 0.770590
2023-10-30 03:47:00,044 Epoch: [89/484] Iter:[20/495], Time: 0.46, lr: [0.008327920630373065], Loss: 2.227305, Acc:0.800128, Semantic loss: 0.891059, BCE loss: 0.539001, SB loss: 0.797244
2023-10-30 03:47:03,800 Epoch: [89/484] Iter:[30/495], Time: 0.43, lr: [0.008327537256662094], Loss: 2.200539, Acc:0.793009, Semantic loss: 0.861845, BCE loss: 0.531095, SB loss: 0.807599
2023-10-30 03:47:07,382 Epoch: [89/484] Iter:[40/495], Time: 0.42, lr: [0.008327153880990076], Loss: 2.272864, Acc:0.787734, Semantic loss: 0.913926, BCE loss: 0.532445, SB loss: 0.826493
2023-10-30 03:47:10,969 Epoch: [89/484] Iter:[50/495], Time: 0.40, lr: [0.008326770503356904], Loss: 2.241383, Acc:0.784727, Semantic loss: 0.879223, BCE loss: 0.535544, SB loss: 0.826616
2023-10-30 03:47:14,717 Epoch: [89/484] Iter:[60/495], Time: 0.40, lr: [0.008326387123762463], Loss: 2.232747, Acc:0.785940, Semantic loss: 0.866528, BCE loss: 0.544181, SB loss: 0.822037
2023-10-30 03:47:18,485 Epoch: [89/484] Iter:[70/495], Time: 0.40, lr: [0.008326003742206647], Loss: 2.222349, Acc:0.789620, Semantic loss: 0.855216, BCE loss: 0.548865, SB loss: 0.818268
2023-10-30 03:47:22,058 Epoch: [89/484] Iter:[80/495], Time: 0.39, lr: [0.008325620358689343], Loss: 2.199164, Acc:0.789369, Semantic loss: 0.841860, BCE loss: 0.547135, SB loss: 0.810169
2023-10-30 03:47:25,677 Epoch: [89/484] Iter:[90/495], Time: 0.39, lr: [0.00832523697321044], Loss: 2.196017, Acc:0.791737, Semantic loss: 0.841801, BCE loss: 0.545646, SB loss: 0.808570
2023-10-30 03:47:29,353 Epoch: [89/484] Iter:[100/495], Time: 0.39, lr: [0.00832485358576983], Loss: 2.195951, Acc:0.792027, Semantic loss: 0.845121, BCE loss: 0.541319, SB loss: 0.809510
2023-10-30 03:47:33,022 Epoch: [89/484] Iter:[110/495], Time: 0.38, lr: [0.0083244701963674], Loss: 2.200056, Acc:0.791215, Semantic loss: 0.849704, BCE loss: 0.540750, SB loss: 0.809602
2023-10-30 03:47:36,727 Epoch: [89/484] Iter:[120/495], Time: 0.38, lr: [0.008324086805003043], Loss: 2.196065, Acc:0.792959, Semantic loss: 0.848887, BCE loss: 0.542253, SB loss: 0.804926
2023-10-30 03:47:40,383 Epoch: [89/484] Iter:[130/495], Time: 0.38, lr: [0.008323703411676646], Loss: 2.202639, Acc:0.794428, Semantic loss: 0.851820, BCE loss: 0.545076, SB loss: 0.805743
2023-10-30 03:47:44,012 Epoch: [89/484] Iter:[140/495], Time: 0.38, lr: [0.008323320016388096], Loss: 2.195260, Acc:0.792894, Semantic loss: 0.846838, BCE loss: 0.544247, SB loss: 0.804175
2023-10-30 03:47:47,741 Epoch: [89/484] Iter:[150/495], Time: 0.38, lr: [0.008322936619137288], Loss: 2.192162, Acc:0.791943, Semantic loss: 0.842437, BCE loss: 0.547660, SB loss: 0.802065
2023-10-30 03:47:51,392 Epoch: [89/484] Iter:[160/495], Time: 0.38, lr: [0.008322553219924108], Loss: 2.185688, Acc:0.790598, Semantic loss: 0.838242, BCE loss: 0.546876, SB loss: 0.800570
2023-10-30 03:47:54,976 Epoch: [89/484] Iter:[170/495], Time: 0.38, lr: [0.008322169818748447], Loss: 2.188816, Acc:0.790518, Semantic loss: 0.838253, BCE loss: 0.549565, SB loss: 0.800998
2023-10-30 03:47:58,573 Epoch: [89/484] Iter:[180/495], Time: 0.38, lr: [0.008321786415610195], Loss: 2.175602, Acc:0.789476, Semantic loss: 0.830123, BCE loss: 0.547695, SB loss: 0.797785
2023-10-30 03:48:02,332 Epoch: [89/484] Iter:[190/495], Time: 0.38, lr: [0.008321403010509239], Loss: 2.180378, Acc:0.789778, Semantic loss: 0.833010, BCE loss: 0.550867, SB loss: 0.796501
2023-10-30 03:48:06,014 Epoch: [89/484] Iter:[200/495], Time: 0.38, lr: [0.008321019603445471], Loss: 2.172238, Acc:0.788048, Semantic loss: 0.825618, BCE loss: 0.552015, SB loss: 0.794605
2023-10-30 03:48:09,685 Epoch: [89/484] Iter:[210/495], Time: 0.38, lr: [0.008320636194418779], Loss: 2.163356, Acc:0.788057, Semantic loss: 0.821240, BCE loss: 0.550237, SB loss: 0.791879
2023-10-30 03:48:13,298 Epoch: [89/484] Iter:[220/495], Time: 0.38, lr: [0.008320252783429053], Loss: 2.149805, Acc:0.788359, Semantic loss: 0.815616, BCE loss: 0.545841, SB loss: 0.788347
2023-10-30 03:48:17,022 Epoch: [89/484] Iter:[230/495], Time: 0.38, lr: [0.008319869370476182], Loss: 2.153004, Acc:0.787858, Semantic loss: 0.819149, BCE loss: 0.545980, SB loss: 0.787875
2023-10-30 03:48:20,638 Epoch: [89/484] Iter:[240/495], Time: 0.37, lr: [0.008319485955560056], Loss: 2.164156, Acc:0.786676, Semantic loss: 0.825222, BCE loss: 0.547808, SB loss: 0.791127
2023-10-30 03:48:24,420 Epoch: [89/484] Iter:[250/495], Time: 0.37, lr: [0.008319102538680564], Loss: 2.162204, Acc:0.786662, Semantic loss: 0.824054, BCE loss: 0.546997, SB loss: 0.791152
2023-10-30 03:48:28,191 Epoch: [89/484] Iter:[260/495], Time: 0.37, lr: [0.008318719119837595], Loss: 2.169520, Acc:0.785397, Semantic loss: 0.829499, BCE loss: 0.548295, SB loss: 0.791725
2023-10-30 03:48:31,784 Epoch: [89/484] Iter:[270/495], Time: 0.37, lr: [0.00831833569903104], Loss: 2.172605, Acc:0.784359, Semantic loss: 0.830064, BCE loss: 0.551011, SB loss: 0.791531
2023-10-30 03:48:35,572 Epoch: [89/484] Iter:[280/495], Time: 0.37, lr: [0.008317952276260787], Loss: 2.174105, Acc:0.783991, Semantic loss: 0.832019, BCE loss: 0.549903, SB loss: 0.792184
2023-10-30 03:48:39,289 Epoch: [89/484] Iter:[290/495], Time: 0.37, lr: [0.008317568851526725], Loss: 2.175615, Acc:0.783722, Semantic loss: 0.830659, BCE loss: 0.553240, SB loss: 0.791716
2023-10-30 03:48:42,885 Epoch: [89/484] Iter:[300/495], Time: 0.37, lr: [0.008317185424828743], Loss: 2.173836, Acc:0.784063, Semantic loss: 0.828617, BCE loss: 0.552774, SB loss: 0.792445
2023-10-30 03:48:46,573 Epoch: [89/484] Iter:[310/495], Time: 0.37, lr: [0.008316801996166735], Loss: 2.170381, Acc:0.783834, Semantic loss: 0.826445, BCE loss: 0.552172, SB loss: 0.791764
2023-10-30 03:48:50,327 Epoch: [89/484] Iter:[320/495], Time: 0.37, lr: [0.008316418565540584], Loss: 2.170232, Acc:0.783315, Semantic loss: 0.826820, BCE loss: 0.550560, SB loss: 0.792852
2023-10-30 03:48:54,018 Epoch: [89/484] Iter:[330/495], Time: 0.37, lr: [0.008316035132950183], Loss: 2.164076, Acc:0.784076, Semantic loss: 0.822604, BCE loss: 0.550527, SB loss: 0.790945
2023-10-30 03:48:57,691 Epoch: [89/484] Iter:[340/495], Time: 0.37, lr: [0.00831565169839542], Loss: 2.171607, Acc:0.783999, Semantic loss: 0.827579, BCE loss: 0.551622, SB loss: 0.792406
2023-10-30 03:49:01,458 Epoch: [89/484] Iter:[350/495], Time: 0.37, lr: [0.008315268261876185], Loss: 2.167702, Acc:0.783676, Semantic loss: 0.826176, BCE loss: 0.550288, SB loss: 0.791238
2023-10-30 03:49:05,211 Epoch: [89/484] Iter:[360/495], Time: 0.37, lr: [0.008314884823392366], Loss: 2.167296, Acc:0.783911, Semantic loss: 0.823651, BCE loss: 0.551919, SB loss: 0.791726
2023-10-30 03:49:08,863 Epoch: [89/484] Iter:[370/495], Time: 0.37, lr: [0.008314501382943854], Loss: 2.175558, Acc:0.782987, Semantic loss: 0.829949, BCE loss: 0.551046, SB loss: 0.794563
2023-10-30 03:49:12,502 Epoch: [89/484] Iter:[380/495], Time: 0.37, lr: [0.008314117940530538], Loss: 2.174710, Acc:0.783711, Semantic loss: 0.828115, BCE loss: 0.552932, SB loss: 0.793663
2023-10-30 03:49:16,167 Epoch: [89/484] Iter:[390/495], Time: 0.37, lr: [0.008313734496152305], Loss: 2.170904, Acc:0.783994, Semantic loss: 0.825850, BCE loss: 0.552034, SB loss: 0.793020
2023-10-30 03:49:19,839 Epoch: [89/484] Iter:[400/495], Time: 0.37, lr: [0.008313351049809048], Loss: 2.171635, Acc:0.784007, Semantic loss: 0.826975, BCE loss: 0.551468, SB loss: 0.793191
2023-10-30 03:49:23,531 Epoch: [89/484] Iter:[410/495], Time: 0.37, lr: [0.008312967601500654], Loss: 2.168298, Acc:0.784187, Semantic loss: 0.824640, BCE loss: 0.551841, SB loss: 0.791817
2023-10-30 03:49:27,230 Epoch: [89/484] Iter:[420/495], Time: 0.37, lr: [0.008312584151227011], Loss: 2.167137, Acc:0.784663, Semantic loss: 0.824473, BCE loss: 0.550732, SB loss: 0.791932
2023-10-30 03:49:30,855 Epoch: [89/484] Iter:[430/495], Time: 0.37, lr: [0.008312200698988009], Loss: 2.164009, Acc:0.785235, Semantic loss: 0.822772, BCE loss: 0.549999, SB loss: 0.791238
2023-10-30 03:49:34,484 Epoch: [89/484] Iter:[440/495], Time: 0.37, lr: [0.00831181724478354], Loss: 2.161821, Acc:0.784922, Semantic loss: 0.822741, BCE loss: 0.548750, SB loss: 0.790329
2023-10-30 03:49:38,189 Epoch: [89/484] Iter:[450/495], Time: 0.37, lr: [0.008311433788613489], Loss: 2.166458, Acc:0.784416, Semantic loss: 0.826433, BCE loss: 0.549280, SB loss: 0.790745
2023-10-30 03:49:41,837 Epoch: [89/484] Iter:[460/495], Time: 0.37, lr: [0.008311050330477748], Loss: 2.172470, Acc:0.784257, Semantic loss: 0.829344, BCE loss: 0.550593, SB loss: 0.792533
2023-10-30 03:49:45,504 Epoch: [89/484] Iter:[470/495], Time: 0.37, lr: [0.008310666870376206], Loss: 2.172310, Acc:0.784009, Semantic loss: 0.829521, BCE loss: 0.549983, SB loss: 0.792806
2023-10-30 03:49:49,113 Epoch: [89/484] Iter:[480/495], Time: 0.37, lr: [0.00831028340830875], Loss: 2.169010, Acc:0.783480, Semantic loss: 0.827513, BCE loss: 0.549316, SB loss: 0.792181
2023-10-30 03:49:52,583 Epoch: [89/484] Iter:[490/495], Time: 0.37, lr: [0.008309899944275272], Loss: 2.164288, Acc:0.783252, Semantic loss: 0.824853, BCE loss: 0.548361, SB loss: 0.791073
2023-10-30 03:49:53,983 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:49:54,216 Loss: 2.048, MeanIU:  0.6627, Best_mIoU:  0.6835
2023-10-30 03:49:54,216 [0.96765251 0.7639005  0.90184466 0.39531341 0.51281134 0.56529178
 0.62320737 0.72251085 0.90401365 0.57626691 0.91966081 0.76136915
 0.53050105 0.91469371 0.51469055 0.5420105  0.32700299 0.46016354
 0.6885239 ]
2023-10-30 03:49:56,380 Epoch: [90/484] Iter:[0/495], Time: 2.13, lr: [0.008309708211521239], Loss: 1.900089, Acc:0.752270, Semantic loss: 0.732389, BCE loss: 0.396442, SB loss: 0.771259
2023-10-30 03:50:00,302 Epoch: [90/484] Iter:[10/495], Time: 0.55, lr: [0.008309324744538516], Loss: 2.092086, Acc:0.794416, Semantic loss: 0.757007, BCE loss: 0.580718, SB loss: 0.754361
2023-10-30 03:50:03,932 Epoch: [90/484] Iter:[20/495], Time: 0.46, lr: [0.008308941275589492], Loss: 2.166917, Acc:0.794611, Semantic loss: 0.826518, BCE loss: 0.560424, SB loss: 0.779975
2023-10-30 03:50:07,617 Epoch: [90/484] Iter:[30/495], Time: 0.43, lr: [0.008308557804674058], Loss: 2.230675, Acc:0.794215, Semantic loss: 0.865289, BCE loss: 0.567444, SB loss: 0.797942
2023-10-30 03:50:11,324 Epoch: [90/484] Iter:[40/495], Time: 0.42, lr: [0.0083081743317921], Loss: 2.174849, Acc:0.797857, Semantic loss: 0.837642, BCE loss: 0.557469, SB loss: 0.779737
2023-10-30 03:50:14,995 Epoch: [90/484] Iter:[50/495], Time: 0.41, lr: [0.00830779085694351], Loss: 2.190145, Acc:0.791794, Semantic loss: 0.841459, BCE loss: 0.566042, SB loss: 0.782644
2023-10-30 03:50:18,724 Epoch: [90/484] Iter:[60/495], Time: 0.40, lr: [0.008307407380128176], Loss: 2.184956, Acc:0.795559, Semantic loss: 0.834825, BCE loss: 0.571859, SB loss: 0.778272
2023-10-30 03:50:22,460 Epoch: [90/484] Iter:[70/495], Time: 0.40, lr: [0.008307023901345986], Loss: 2.152098, Acc:0.798215, Semantic loss: 0.821213, BCE loss: 0.557138, SB loss: 0.773747
2023-10-30 03:50:26,070 Epoch: [90/484] Iter:[80/495], Time: 0.39, lr: [0.008306640420596829], Loss: 2.150709, Acc:0.799922, Semantic loss: 0.823231, BCE loss: 0.554589, SB loss: 0.772889
2023-10-30 03:50:29,691 Epoch: [90/484] Iter:[90/495], Time: 0.39, lr: [0.008306256937880594], Loss: 2.146758, Acc:0.804101, Semantic loss: 0.819218, BCE loss: 0.556908, SB loss: 0.770632
2023-10-30 03:50:33,285 Epoch: [90/484] Iter:[100/495], Time: 0.39, lr: [0.008305873453197173], Loss: 2.125654, Acc:0.801850, Semantic loss: 0.809900, BCE loss: 0.549267, SB loss: 0.766487
2023-10-30 03:50:37,054 Epoch: [90/484] Iter:[110/495], Time: 0.39, lr: [0.00830548996654645], Loss: 2.115257, Acc:0.801671, Semantic loss: 0.800452, BCE loss: 0.552872, SB loss: 0.761933
2023-10-30 03:50:40,731 Epoch: [90/484] Iter:[120/495], Time: 0.38, lr: [0.008305106477928316], Loss: 2.111026, Acc:0.802644, Semantic loss: 0.797829, BCE loss: 0.552516, SB loss: 0.760680
2023-10-30 03:50:44,339 Epoch: [90/484] Iter:[130/495], Time: 0.38, lr: [0.008304722987342665], Loss: 2.118429, Acc:0.802041, Semantic loss: 0.802733, BCE loss: 0.551480, SB loss: 0.764216
2023-10-30 03:50:48,013 Epoch: [90/484] Iter:[140/495], Time: 0.38, lr: [0.008304339494789379], Loss: 2.106969, Acc:0.801966, Semantic loss: 0.794755, BCE loss: 0.550648, SB loss: 0.761567
2023-10-30 03:50:51,638 Epoch: [90/484] Iter:[150/495], Time: 0.38, lr: [0.008303956000268349], Loss: 2.095585, Acc:0.800511, Semantic loss: 0.790019, BCE loss: 0.546944, SB loss: 0.758622
2023-10-30 03:50:55,343 Epoch: [90/484] Iter:[160/495], Time: 0.38, lr: [0.008303572503779465], Loss: 2.095586, Acc:0.799409, Semantic loss: 0.793551, BCE loss: 0.541481, SB loss: 0.760554
2023-10-30 03:50:59,046 Epoch: [90/484] Iter:[170/495], Time: 0.38, lr: [0.008303189005322613], Loss: 2.096036, Acc:0.797566, Semantic loss: 0.794597, BCE loss: 0.541499, SB loss: 0.759940
2023-10-30 03:51:02,789 Epoch: [90/484] Iter:[180/495], Time: 0.38, lr: [0.008302805504897686], Loss: 2.102371, Acc:0.798220, Semantic loss: 0.797925, BCE loss: 0.542733, SB loss: 0.761713
2023-10-30 03:51:06,534 Epoch: [90/484] Iter:[190/495], Time: 0.38, lr: [0.008302422002504571], Loss: 2.103885, Acc:0.797021, Semantic loss: 0.798780, BCE loss: 0.543118, SB loss: 0.761988
2023-10-30 03:51:10,181 Epoch: [90/484] Iter:[200/495], Time: 0.38, lr: [0.008302038498143158], Loss: 2.111781, Acc:0.797766, Semantic loss: 0.800588, BCE loss: 0.546790, SB loss: 0.764403
2023-10-30 03:51:13,865 Epoch: [90/484] Iter:[210/495], Time: 0.38, lr: [0.008301654991813335], Loss: 2.124085, Acc:0.795250, Semantic loss: 0.809817, BCE loss: 0.547481, SB loss: 0.766787
2023-10-30 03:51:17,645 Epoch: [90/484] Iter:[220/495], Time: 0.38, lr: [0.008301271483514991], Loss: 2.121468, Acc:0.796300, Semantic loss: 0.806048, BCE loss: 0.547615, SB loss: 0.767805
2023-10-30 03:51:21,297 Epoch: [90/484] Iter:[230/495], Time: 0.38, lr: [0.008300887973248013], Loss: 2.121174, Acc:0.796081, Semantic loss: 0.805792, BCE loss: 0.546698, SB loss: 0.768684
2023-10-30 03:51:24,998 Epoch: [90/484] Iter:[240/495], Time: 0.38, lr: [0.008300504461012291], Loss: 2.117031, Acc:0.795588, Semantic loss: 0.803307, BCE loss: 0.545543, SB loss: 0.768182
2023-10-30 03:51:28,760 Epoch: [90/484] Iter:[250/495], Time: 0.38, lr: [0.008300120946807715], Loss: 2.119027, Acc:0.793818, Semantic loss: 0.802606, BCE loss: 0.547122, SB loss: 0.769299
2023-10-30 03:51:32,358 Epoch: [90/484] Iter:[260/495], Time: 0.38, lr: [0.008299737430634174], Loss: 2.119933, Acc:0.793817, Semantic loss: 0.802248, BCE loss: 0.548433, SB loss: 0.769251
2023-10-30 03:51:35,951 Epoch: [90/484] Iter:[270/495], Time: 0.38, lr: [0.008299353912491553], Loss: 2.115094, Acc:0.794667, Semantic loss: 0.798986, BCE loss: 0.548051, SB loss: 0.768058
2023-10-30 03:51:39,591 Epoch: [90/484] Iter:[280/495], Time: 0.37, lr: [0.008298970392379746], Loss: 2.111151, Acc:0.795643, Semantic loss: 0.796439, BCE loss: 0.547802, SB loss: 0.766910
2023-10-30 03:51:43,232 Epoch: [90/484] Iter:[290/495], Time: 0.37, lr: [0.00829858687029864], Loss: 2.108454, Acc:0.795062, Semantic loss: 0.796373, BCE loss: 0.544632, SB loss: 0.767449
2023-10-30 03:51:46,903 Epoch: [90/484] Iter:[300/495], Time: 0.37, lr: [0.008298203346248123], Loss: 2.106019, Acc:0.794749, Semantic loss: 0.795359, BCE loss: 0.542926, SB loss: 0.767734
2023-10-30 03:51:50,662 Epoch: [90/484] Iter:[310/495], Time: 0.37, lr: [0.008297819820228083], Loss: 2.102037, Acc:0.794027, Semantic loss: 0.794307, BCE loss: 0.540436, SB loss: 0.767294
2023-10-30 03:51:54,438 Epoch: [90/484] Iter:[320/495], Time: 0.37, lr: [0.008297436292238409], Loss: 2.102060, Acc:0.794951, Semantic loss: 0.793873, BCE loss: 0.541096, SB loss: 0.767091
2023-10-30 03:51:58,199 Epoch: [90/484] Iter:[330/495], Time: 0.37, lr: [0.008297052762278991], Loss: 2.107547, Acc:0.795392, Semantic loss: 0.797990, BCE loss: 0.541157, SB loss: 0.768400
2023-10-30 03:52:01,958 Epoch: [90/484] Iter:[340/495], Time: 0.37, lr: [0.008296669230349718], Loss: 2.102927, Acc:0.794789, Semantic loss: 0.796623, BCE loss: 0.538114, SB loss: 0.768190
2023-10-30 03:52:05,587 Epoch: [90/484] Iter:[350/495], Time: 0.37, lr: [0.008296285696450476], Loss: 2.104096, Acc:0.795760, Semantic loss: 0.796274, BCE loss: 0.539045, SB loss: 0.768777
2023-10-30 03:52:09,332 Epoch: [90/484] Iter:[360/495], Time: 0.37, lr: [0.008295902160581157], Loss: 2.109510, Acc:0.795151, Semantic loss: 0.800149, BCE loss: 0.539571, SB loss: 0.769790
2023-10-30 03:52:12,995 Epoch: [90/484] Iter:[370/495], Time: 0.37, lr: [0.008295518622741648], Loss: 2.105390, Acc:0.794860, Semantic loss: 0.797688, BCE loss: 0.538893, SB loss: 0.768810
2023-10-30 03:52:16,701 Epoch: [90/484] Iter:[380/495], Time: 0.37, lr: [0.008295135082931839], Loss: 2.105659, Acc:0.794883, Semantic loss: 0.797474, BCE loss: 0.539359, SB loss: 0.768826
2023-10-30 03:52:20,529 Epoch: [90/484] Iter:[390/495], Time: 0.37, lr: [0.008294751541151614], Loss: 2.104560, Acc:0.795489, Semantic loss: 0.796256, BCE loss: 0.540288, SB loss: 0.768016
2023-10-30 03:52:24,245 Epoch: [90/484] Iter:[400/495], Time: 0.37, lr: [0.008294367997400867], Loss: 2.106202, Acc:0.795303, Semantic loss: 0.796977, BCE loss: 0.540608, SB loss: 0.768617
2023-10-30 03:52:27,836 Epoch: [90/484] Iter:[410/495], Time: 0.37, lr: [0.008293984451679486], Loss: 2.107884, Acc:0.795529, Semantic loss: 0.797963, BCE loss: 0.541410, SB loss: 0.768511
2023-10-30 03:52:31,624 Epoch: [90/484] Iter:[420/495], Time: 0.37, lr: [0.008293600903987357], Loss: 2.107554, Acc:0.794620, Semantic loss: 0.797732, BCE loss: 0.540445, SB loss: 0.769377
2023-10-30 03:52:35,355 Epoch: [90/484] Iter:[430/495], Time: 0.37, lr: [0.00829321735432437], Loss: 2.108345, Acc:0.794053, Semantic loss: 0.798484, BCE loss: 0.540370, SB loss: 0.769490
2023-10-30 03:52:39,019 Epoch: [90/484] Iter:[440/495], Time: 0.37, lr: [0.008292833802690415], Loss: 2.111142, Acc:0.793881, Semantic loss: 0.799283, BCE loss: 0.542125, SB loss: 0.769734
2023-10-30 03:52:42,704 Epoch: [90/484] Iter:[450/495], Time: 0.37, lr: [0.008292450249085379], Loss: 2.108098, Acc:0.793880, Semantic loss: 0.797537, BCE loss: 0.541759, SB loss: 0.768803
2023-10-30 03:52:46,281 Epoch: [90/484] Iter:[460/495], Time: 0.37, lr: [0.00829206669350915], Loss: 2.111170, Acc:0.793961, Semantic loss: 0.798975, BCE loss: 0.542972, SB loss: 0.769223
2023-10-30 03:52:50,025 Epoch: [90/484] Iter:[470/495], Time: 0.37, lr: [0.008291683135961616], Loss: 2.116455, Acc:0.793966, Semantic loss: 0.801473, BCE loss: 0.542842, SB loss: 0.772140
2023-10-30 03:52:53,716 Epoch: [90/484] Iter:[480/495], Time: 0.37, lr: [0.008291299576442666], Loss: 2.114896, Acc:0.794661, Semantic loss: 0.799443, BCE loss: 0.542937, SB loss: 0.772516
2023-10-30 03:52:57,172 Epoch: [90/484] Iter:[490/495], Time: 0.37, lr: [0.008290916014952193], Loss: 2.113691, Acc:0.793770, Semantic loss: 0.799083, BCE loss: 0.542125, SB loss: 0.772483
2023-10-30 03:55:53,510 0 [0.92963014 0.61615869 0.81219756 0.1425048  0.21648405 0.38758358
 0.40264544 0.55102074 0.86316688 0.43524673 0.85488683 0.59817312
 0.01275997 0.79851177 0.         0.04917476 0.00739966 0.02067411
 0.54304668] 0.43375081628094203
2023-10-30 03:55:53,511 1 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424] 0.673276970911751
2023-10-30 03:55:53,514 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:55:53,748 Loss: 2.113, MeanIU:  0.6733, Best_mIoU:  0.6835
2023-10-30 03:55:53,748 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424]
2023-10-30 03:55:55,817 Epoch: [91/484] Iter:[0/495], Time: 2.04, lr: [0.008290724233467599], Loss: 1.777910, Acc:0.840535, Semantic loss: 0.635971, BCE loss: 0.446453, SB loss: 0.695486
2023-10-30 03:55:59,702 Epoch: [91/484] Iter:[10/495], Time: 0.54, lr: [0.008290340669019623], Loss: 2.009989, Acc:0.809476, Semantic loss: 0.728714, BCE loss: 0.548170, SB loss: 0.733105
2023-10-30 03:56:03,285 Epoch: [91/484] Iter:[20/495], Time: 0.45, lr: [0.008289957102599846], Loss: 2.069748, Acc:0.809276, Semantic loss: 0.750576, BCE loss: 0.569044, SB loss: 0.750129
2023-10-30 03:56:06,823 Epoch: [91/484] Iter:[30/495], Time: 0.42, lr: [0.00828957353420815], Loss: 2.083632, Acc:0.812647, Semantic loss: 0.766485, BCE loss: 0.558792, SB loss: 0.758355
2023-10-30 03:56:10,373 Epoch: [91/484] Iter:[40/495], Time: 0.40, lr: [0.008289189963844425], Loss: 2.120673, Acc:0.810025, Semantic loss: 0.777363, BCE loss: 0.577533, SB loss: 0.765777
2023-10-30 03:56:13,908 Epoch: [91/484] Iter:[50/495], Time: 0.39, lr: [0.008288806391508563], Loss: 2.106123, Acc:0.814360, Semantic loss: 0.770455, BCE loss: 0.576535, SB loss: 0.759133
2023-10-30 03:56:17,434 Epoch: [91/484] Iter:[60/495], Time: 0.39, lr: [0.008288422817200445], Loss: 2.104812, Acc:0.814051, Semantic loss: 0.771237, BCE loss: 0.575682, SB loss: 0.757892
2023-10-30 03:56:20,942 Epoch: [91/484] Iter:[70/495], Time: 0.38, lr: [0.008288039240919967], Loss: 2.123156, Acc:0.812744, Semantic loss: 0.788489, BCE loss: 0.575150, SB loss: 0.759516
2023-10-30 03:56:24,521 Epoch: [91/484] Iter:[80/495], Time: 0.38, lr: [0.008287655662667015], Loss: 2.131030, Acc:0.812510, Semantic loss: 0.788353, BCE loss: 0.583966, SB loss: 0.758711
2023-10-30 03:56:28,121 Epoch: [91/484] Iter:[90/495], Time: 0.38, lr: [0.008287272082441476], Loss: 2.127043, Acc:0.813789, Semantic loss: 0.782682, BCE loss: 0.581328, SB loss: 0.763033
2023-10-30 03:56:31,679 Epoch: [91/484] Iter:[100/495], Time: 0.38, lr: [0.008286888500243238], Loss: 2.131124, Acc:0.811286, Semantic loss: 0.787424, BCE loss: 0.578600, SB loss: 0.765100
2023-10-30 03:56:35,170 Epoch: [91/484] Iter:[110/495], Time: 0.37, lr: [0.008286504916072192], Loss: 2.131226, Acc:0.812101, Semantic loss: 0.784061, BCE loss: 0.584062, SB loss: 0.763103
2023-10-30 03:56:38,706 Epoch: [91/484] Iter:[120/495], Time: 0.37, lr: [0.008286121329928224], Loss: 2.129642, Acc:0.806380, Semantic loss: 0.784854, BCE loss: 0.580635, SB loss: 0.764152
2023-10-30 03:56:42,390 Epoch: [91/484] Iter:[130/495], Time: 0.37, lr: [0.008285737741811225], Loss: 2.128448, Acc:0.805609, Semantic loss: 0.783540, BCE loss: 0.578237, SB loss: 0.766671
2023-10-30 03:56:45,989 Epoch: [91/484] Iter:[140/495], Time: 0.37, lr: [0.00828535415172108], Loss: 2.138319, Acc:0.805099, Semantic loss: 0.789589, BCE loss: 0.582568, SB loss: 0.766162
2023-10-30 03:56:49,583 Epoch: [91/484] Iter:[150/495], Time: 0.37, lr: [0.00828497055965768], Loss: 2.138250, Acc:0.802803, Semantic loss: 0.791322, BCE loss: 0.578447, SB loss: 0.768480
2023-10-30 03:56:53,115 Epoch: [91/484] Iter:[160/495], Time: 0.37, lr: [0.008284586965620913], Loss: 2.148395, Acc:0.800034, Semantic loss: 0.800502, BCE loss: 0.575295, SB loss: 0.772598
2023-10-30 03:56:56,667 Epoch: [91/484] Iter:[170/495], Time: 0.37, lr: [0.008284203369610665], Loss: 2.140849, Acc:0.799338, Semantic loss: 0.796765, BCE loss: 0.573074, SB loss: 0.771010
2023-10-30 03:57:00,268 Epoch: [91/484] Iter:[180/495], Time: 0.37, lr: [0.008283819771626828], Loss: 2.139507, Acc:0.798197, Semantic loss: 0.799043, BCE loss: 0.569664, SB loss: 0.770800
2023-10-30 03:57:03,897 Epoch: [91/484] Iter:[190/495], Time: 0.37, lr: [0.008283436171669288], Loss: 2.155932, Acc:0.797750, Semantic loss: 0.808412, BCE loss: 0.571514, SB loss: 0.776006
2023-10-30 03:57:07,508 Epoch: [91/484] Iter:[200/495], Time: 0.37, lr: [0.008283052569737933], Loss: 2.148917, Acc:0.797308, Semantic loss: 0.803833, BCE loss: 0.569763, SB loss: 0.775320
2023-10-30 03:57:11,117 Epoch: [91/484] Iter:[210/495], Time: 0.37, lr: [0.008282668965832653], Loss: 2.145265, Acc:0.796937, Semantic loss: 0.801362, BCE loss: 0.568620, SB loss: 0.775283
2023-10-30 03:57:14,803 Epoch: [91/484] Iter:[220/495], Time: 0.37, lr: [0.008282285359953335], Loss: 2.141951, Acc:0.796752, Semantic loss: 0.801084, BCE loss: 0.565420, SB loss: 0.775447
2023-10-30 03:57:18,452 Epoch: [91/484] Iter:[230/495], Time: 0.37, lr: [0.008281901752099866], Loss: 2.136970, Acc:0.797682, Semantic loss: 0.798642, BCE loss: 0.565107, SB loss: 0.773221
2023-10-30 03:57:22,190 Epoch: [91/484] Iter:[240/495], Time: 0.37, lr: [0.008281518142272137], Loss: 2.137610, Acc:0.797232, Semantic loss: 0.798442, BCE loss: 0.565662, SB loss: 0.773505
2023-10-30 03:57:25,817 Epoch: [91/484] Iter:[250/495], Time: 0.37, lr: [0.008281134530470033], Loss: 2.140872, Acc:0.797713, Semantic loss: 0.801147, BCE loss: 0.566510, SB loss: 0.773214
2023-10-30 03:57:29,424 Epoch: [91/484] Iter:[260/495], Time: 0.37, lr: [0.008280750916693447], Loss: 2.137118, Acc:0.797857, Semantic loss: 0.798369, BCE loss: 0.566277, SB loss: 0.772472
2023-10-30 03:57:33,036 Epoch: [91/484] Iter:[270/495], Time: 0.37, lr: [0.008280367300942263], Loss: 2.141808, Acc:0.798093, Semantic loss: 0.801022, BCE loss: 0.566730, SB loss: 0.774056
2023-10-30 03:57:36,539 Epoch: [91/484] Iter:[280/495], Time: 0.37, lr: [0.008279983683216372], Loss: 2.133497, Acc:0.796464, Semantic loss: 0.797652, BCE loss: 0.562710, SB loss: 0.773135
2023-10-30 03:57:40,161 Epoch: [91/484] Iter:[290/495], Time: 0.37, lr: [0.00827960006351566], Loss: 2.131842, Acc:0.796003, Semantic loss: 0.797423, BCE loss: 0.560831, SB loss: 0.773588
2023-10-30 03:57:43,820 Epoch: [91/484] Iter:[300/495], Time: 0.37, lr: [0.008279216441840013], Loss: 2.130602, Acc:0.796060, Semantic loss: 0.796590, BCE loss: 0.560865, SB loss: 0.773147
2023-10-30 03:57:47,480 Epoch: [91/484] Iter:[310/495], Time: 0.37, lr: [0.008278832818189325], Loss: 2.129573, Acc:0.795717, Semantic loss: 0.797815, BCE loss: 0.558861, SB loss: 0.772897
2023-10-30 03:57:51,237 Epoch: [91/484] Iter:[320/495], Time: 0.37, lr: [0.008278449192563481], Loss: 2.134820, Acc:0.795867, Semantic loss: 0.800419, BCE loss: 0.559853, SB loss: 0.774548
2023-10-30 03:57:54,841 Epoch: [91/484] Iter:[330/495], Time: 0.37, lr: [0.008278065564962368], Loss: 2.135447, Acc:0.794744, Semantic loss: 0.801413, BCE loss: 0.558694, SB loss: 0.775340
2023-10-30 03:57:58,723 Epoch: [91/484] Iter:[340/495], Time: 0.37, lr: [0.008277681935385877], Loss: 2.134093, Acc:0.795009, Semantic loss: 0.800759, BCE loss: 0.558890, SB loss: 0.774444
2023-10-30 03:58:02,336 Epoch: [91/484] Iter:[350/495], Time: 0.37, lr: [0.008277298303833893], Loss: 2.132235, Acc:0.795263, Semantic loss: 0.799202, BCE loss: 0.559607, SB loss: 0.773426
2023-10-30 03:58:05,986 Epoch: [91/484] Iter:[360/495], Time: 0.37, lr: [0.008276914670306307], Loss: 2.133241, Acc:0.794828, Semantic loss: 0.800809, BCE loss: 0.559420, SB loss: 0.773012
2023-10-30 03:58:09,675 Epoch: [91/484] Iter:[370/495], Time: 0.37, lr: [0.008276531034803006], Loss: 2.135204, Acc:0.793858, Semantic loss: 0.802914, BCE loss: 0.559047, SB loss: 0.773243
2023-10-30 03:58:13,435 Epoch: [91/484] Iter:[380/495], Time: 0.37, lr: [0.008276147397323876], Loss: 2.141054, Acc:0.793825, Semantic loss: 0.806114, BCE loss: 0.560655, SB loss: 0.774285
2023-10-30 03:58:17,083 Epoch: [91/484] Iter:[390/495], Time: 0.37, lr: [0.008275763757868808], Loss: 2.139769, Acc:0.793751, Semantic loss: 0.804644, BCE loss: 0.560801, SB loss: 0.774323
2023-10-30 03:58:20,717 Epoch: [91/484] Iter:[400/495], Time: 0.37, lr: [0.008275380116437688], Loss: 2.136198, Acc:0.793862, Semantic loss: 0.802673, BCE loss: 0.559731, SB loss: 0.773794
2023-10-30 03:58:24,404 Epoch: [91/484] Iter:[410/495], Time: 0.37, lr: [0.008274996473030406], Loss: 2.139312, Acc:0.794457, Semantic loss: 0.804439, BCE loss: 0.560543, SB loss: 0.774330
2023-10-30 03:58:28,091 Epoch: [91/484] Iter:[420/495], Time: 0.37, lr: [0.008274612827646848], Loss: 2.141650, Acc:0.794059, Semantic loss: 0.806314, BCE loss: 0.560863, SB loss: 0.774473
2023-10-30 03:58:31,760 Epoch: [91/484] Iter:[430/495], Time: 0.37, lr: [0.008274229180286904], Loss: 2.139921, Acc:0.793649, Semantic loss: 0.804926, BCE loss: 0.561316, SB loss: 0.773679
2023-10-30 03:58:35,477 Epoch: [91/484] Iter:[440/495], Time: 0.37, lr: [0.00827384553095046], Loss: 2.139506, Acc:0.793189, Semantic loss: 0.804488, BCE loss: 0.561658, SB loss: 0.773359
2023-10-30 03:58:39,215 Epoch: [91/484] Iter:[450/495], Time: 0.37, lr: [0.008273461879637406], Loss: 2.136858, Acc:0.793775, Semantic loss: 0.803804, BCE loss: 0.560215, SB loss: 0.772839
2023-10-30 03:58:42,813 Epoch: [91/484] Iter:[460/495], Time: 0.37, lr: [0.008273078226347628], Loss: 2.134622, Acc:0.793432, Semantic loss: 0.804025, BCE loss: 0.558023, SB loss: 0.772575
2023-10-30 03:58:46,455 Epoch: [91/484] Iter:[470/495], Time: 0.37, lr: [0.008272694571081015], Loss: 2.134716, Acc:0.793106, Semantic loss: 0.803692, BCE loss: 0.557664, SB loss: 0.773360
2023-10-30 03:58:50,125 Epoch: [91/484] Iter:[480/495], Time: 0.37, lr: [0.008272310913837455], Loss: 2.133977, Acc:0.793795, Semantic loss: 0.802382, BCE loss: 0.558741, SB loss: 0.772854
2023-10-30 03:58:53,672 Epoch: [91/484] Iter:[490/495], Time: 0.37, lr: [0.008271927254616836], Loss: 2.135244, Acc:0.793696, Semantic loss: 0.803165, BCE loss: 0.559244, SB loss: 0.772835
2023-10-30 03:58:55,080 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 03:58:55,318 Loss: 2.113, MeanIU:  0.6733, Best_mIoU:  0.6835
2023-10-30 03:58:55,318 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424]
2023-10-30 03:58:57,214 Epoch: [92/484] Iter:[0/495], Time: 1.86, lr: [0.008271735424265094], Loss: 2.659800, Acc:0.837177, Semantic loss: 1.205067, BCE loss: 0.653366, SB loss: 0.801366
2023-10-30 03:59:01,289 Epoch: [92/484] Iter:[10/495], Time: 0.54, lr: [0.008271351762078676], Loss: 2.111961, Acc:0.814190, Semantic loss: 0.789523, BCE loss: 0.553562, SB loss: 0.768875
2023-10-30 03:59:04,879 Epoch: [92/484] Iter:[20/495], Time: 0.45, lr: [0.008270968097914918], Loss: 2.155709, Acc:0.793467, Semantic loss: 0.831386, BCE loss: 0.547850, SB loss: 0.776474
2023-10-30 03:59:08,521 Epoch: [92/484] Iter:[30/495], Time: 0.42, lr: [0.008270584431773708], Loss: 2.155442, Acc:0.785332, Semantic loss: 0.814984, BCE loss: 0.568059, SB loss: 0.772398
2023-10-30 03:59:12,172 Epoch: [92/484] Iter:[40/495], Time: 0.41, lr: [0.008270200763654935], Loss: 2.114910, Acc:0.789311, Semantic loss: 0.792034, BCE loss: 0.562716, SB loss: 0.760160
2023-10-30 03:59:15,796 Epoch: [92/484] Iter:[50/495], Time: 0.40, lr: [0.008269817093558488], Loss: 2.123393, Acc:0.792791, Semantic loss: 0.798250, BCE loss: 0.563862, SB loss: 0.761280
2023-10-30 03:59:19,572 Epoch: [92/484] Iter:[60/495], Time: 0.40, lr: [0.00826943342148425], Loss: 2.128342, Acc:0.790758, Semantic loss: 0.803142, BCE loss: 0.567574, SB loss: 0.757627
2023-10-30 03:59:23,203 Epoch: [92/484] Iter:[70/495], Time: 0.39, lr: [0.008269049747432113], Loss: 2.146603, Acc:0.794876, Semantic loss: 0.817489, BCE loss: 0.564546, SB loss: 0.764569
2023-10-30 03:59:26,919 Epoch: [92/484] Iter:[80/495], Time: 0.39, lr: [0.008268666071401963], Loss: 2.136191, Acc:0.795846, Semantic loss: 0.808549, BCE loss: 0.560480, SB loss: 0.767162
2023-10-30 03:59:30,606 Epoch: [92/484] Iter:[90/495], Time: 0.39, lr: [0.008268282393393691], Loss: 2.139379, Acc:0.797269, Semantic loss: 0.806616, BCE loss: 0.562299, SB loss: 0.770464
2023-10-30 03:59:34,236 Epoch: [92/484] Iter:[100/495], Time: 0.38, lr: [0.00826789871340718], Loss: 2.129988, Acc:0.797625, Semantic loss: 0.799692, BCE loss: 0.562062, SB loss: 0.768234
2023-10-30 03:59:37,930 Epoch: [92/484] Iter:[110/495], Time: 0.38, lr: [0.00826751503144232], Loss: 2.111967, Acc:0.797992, Semantic loss: 0.789441, BCE loss: 0.560331, SB loss: 0.762195
2023-10-30 03:59:41,608 Epoch: [92/484] Iter:[120/495], Time: 0.38, lr: [0.008267131347499], Loss: 2.103856, Acc:0.797296, Semantic loss: 0.783726, BCE loss: 0.561468, SB loss: 0.758662
2023-10-30 03:59:45,303 Epoch: [92/484] Iter:[130/495], Time: 0.38, lr: [0.008266747661577107], Loss: 2.113904, Acc:0.797372, Semantic loss: 0.785208, BCE loss: 0.566985, SB loss: 0.761711
2023-10-30 03:59:49,003 Epoch: [92/484] Iter:[140/495], Time: 0.38, lr: [0.008266363973676529], Loss: 2.102231, Acc:0.796801, Semantic loss: 0.779101, BCE loss: 0.562927, SB loss: 0.760202
2023-10-30 03:59:52,621 Epoch: [92/484] Iter:[150/495], Time: 0.38, lr: [0.008265980283797152], Loss: 2.105960, Acc:0.798536, Semantic loss: 0.781060, BCE loss: 0.562368, SB loss: 0.762532
2023-10-30 03:59:56,285 Epoch: [92/484] Iter:[160/495], Time: 0.38, lr: [0.008265596591938864], Loss: 2.104658, Acc:0.797259, Semantic loss: 0.782615, BCE loss: 0.559970, SB loss: 0.762074
2023-10-30 03:59:59,934 Epoch: [92/484] Iter:[170/495], Time: 0.38, lr: [0.008265212898101556], Loss: 2.107968, Acc:0.795122, Semantic loss: 0.784737, BCE loss: 0.560227, SB loss: 0.763004
2023-10-30 04:00:03,555 Epoch: [92/484] Iter:[180/495], Time: 0.38, lr: [0.008264829202285112], Loss: 2.107643, Acc:0.795239, Semantic loss: 0.784082, BCE loss: 0.560567, SB loss: 0.762994
2023-10-30 04:00:07,214 Epoch: [92/484] Iter:[190/495], Time: 0.38, lr: [0.008264445504489421], Loss: 2.113658, Acc:0.795172, Semantic loss: 0.789717, BCE loss: 0.559322, SB loss: 0.764619
2023-10-30 04:00:10,907 Epoch: [92/484] Iter:[200/495], Time: 0.38, lr: [0.008264061804714371], Loss: 2.110873, Acc:0.794112, Semantic loss: 0.791598, BCE loss: 0.556971, SB loss: 0.762303
2023-10-30 04:00:14,578 Epoch: [92/484] Iter:[210/495], Time: 0.38, lr: [0.008263678102959849], Loss: 2.105386, Acc:0.793228, Semantic loss: 0.789557, BCE loss: 0.555455, SB loss: 0.760374
2023-10-30 04:00:18,273 Epoch: [92/484] Iter:[220/495], Time: 0.38, lr: [0.008263294399225745], Loss: 2.106264, Acc:0.793099, Semantic loss: 0.790468, BCE loss: 0.556082, SB loss: 0.759714
2023-10-30 04:00:21,929 Epoch: [92/484] Iter:[230/495], Time: 0.37, lr: [0.008262910693511942], Loss: 2.104941, Acc:0.791544, Semantic loss: 0.791921, BCE loss: 0.553174, SB loss: 0.759846
2023-10-30 04:00:25,550 Epoch: [92/484] Iter:[240/495], Time: 0.37, lr: [0.008262526985818332], Loss: 2.106154, Acc:0.790069, Semantic loss: 0.792140, BCE loss: 0.553416, SB loss: 0.760598
2023-10-30 04:00:29,246 Epoch: [92/484] Iter:[250/495], Time: 0.37, lr: [0.008262143276144801], Loss: 2.110122, Acc:0.789649, Semantic loss: 0.793970, BCE loss: 0.553761, SB loss: 0.762391
2023-10-30 04:00:32,849 Epoch: [92/484] Iter:[260/495], Time: 0.37, lr: [0.008261759564491237], Loss: 2.118446, Acc:0.789903, Semantic loss: 0.799090, BCE loss: 0.554762, SB loss: 0.764594
2023-10-30 04:00:36,598 Epoch: [92/484] Iter:[270/495], Time: 0.37, lr: [0.008261375850857526], Loss: 2.113132, Acc:0.789106, Semantic loss: 0.797454, BCE loss: 0.551059, SB loss: 0.764618
2023-10-30 04:00:40,302 Epoch: [92/484] Iter:[280/495], Time: 0.37, lr: [0.008260992135243558], Loss: 2.113890, Acc:0.790525, Semantic loss: 0.796632, BCE loss: 0.551855, SB loss: 0.765403
2023-10-30 04:00:43,931 Epoch: [92/484] Iter:[290/495], Time: 0.37, lr: [0.00826060841764922], Loss: 2.111351, Acc:0.790151, Semantic loss: 0.795645, BCE loss: 0.549861, SB loss: 0.765845
2023-10-30 04:00:47,542 Epoch: [92/484] Iter:[300/495], Time: 0.37, lr: [0.008260224698074397], Loss: 2.116294, Acc:0.789577, Semantic loss: 0.798186, BCE loss: 0.550189, SB loss: 0.767920
2023-10-30 04:00:51,308 Epoch: [92/484] Iter:[310/495], Time: 0.37, lr: [0.008259840976518978], Loss: 2.115576, Acc:0.790667, Semantic loss: 0.799097, BCE loss: 0.548969, SB loss: 0.767511
2023-10-30 04:00:55,034 Epoch: [92/484] Iter:[320/495], Time: 0.37, lr: [0.008259457252982853], Loss: 2.114627, Acc:0.790357, Semantic loss: 0.798826, BCE loss: 0.548133, SB loss: 0.767668
2023-10-30 04:00:58,658 Epoch: [92/484] Iter:[330/495], Time: 0.37, lr: [0.008259073527465908], Loss: 2.116031, Acc:0.790181, Semantic loss: 0.800274, BCE loss: 0.548007, SB loss: 0.767750
2023-10-30 04:01:02,300 Epoch: [92/484] Iter:[340/495], Time: 0.37, lr: [0.00825868979996803], Loss: 2.119106, Acc:0.790293, Semantic loss: 0.800802, BCE loss: 0.549654, SB loss: 0.768650
2023-10-30 04:01:05,889 Epoch: [92/484] Iter:[350/495], Time: 0.37, lr: [0.008258306070489106], Loss: 2.120888, Acc:0.789715, Semantic loss: 0.801742, BCE loss: 0.549712, SB loss: 0.769433
2023-10-30 04:01:09,528 Epoch: [92/484] Iter:[360/495], Time: 0.37, lr: [0.008257922339029024], Loss: 2.119212, Acc:0.789466, Semantic loss: 0.802792, BCE loss: 0.547469, SB loss: 0.768951
2023-10-30 04:01:13,266 Epoch: [92/484] Iter:[370/495], Time: 0.37, lr: [0.00825753860558767], Loss: 2.121204, Acc:0.789479, Semantic loss: 0.803399, BCE loss: 0.548395, SB loss: 0.769410
2023-10-30 04:01:16,952 Epoch: [92/484] Iter:[380/495], Time: 0.37, lr: [0.008257154870164938], Loss: 2.115574, Acc:0.789750, Semantic loss: 0.800344, BCE loss: 0.547028, SB loss: 0.768202
2023-10-30 04:01:20,578 Epoch: [92/484] Iter:[390/495], Time: 0.37, lr: [0.008256771132760705], Loss: 2.111179, Acc:0.789835, Semantic loss: 0.797518, BCE loss: 0.546103, SB loss: 0.767558
2023-10-30 04:01:24,144 Epoch: [92/484] Iter:[400/495], Time: 0.37, lr: [0.008256387393374866], Loss: 2.113209, Acc:0.790349, Semantic loss: 0.798437, BCE loss: 0.546575, SB loss: 0.768197
2023-10-30 04:01:27,796 Epoch: [92/484] Iter:[410/495], Time: 0.37, lr: [0.008256003652007307], Loss: 2.111117, Acc:0.789966, Semantic loss: 0.797238, BCE loss: 0.545926, SB loss: 0.767953
2023-10-30 04:01:31,470 Epoch: [92/484] Iter:[420/495], Time: 0.37, lr: [0.008255619908657915], Loss: 2.114047, Acc:0.789615, Semantic loss: 0.801236, BCE loss: 0.544370, SB loss: 0.768441
2023-10-30 04:01:35,138 Epoch: [92/484] Iter:[430/495], Time: 0.37, lr: [0.008255236163326577], Loss: 2.112711, Acc:0.789137, Semantic loss: 0.800318, BCE loss: 0.543873, SB loss: 0.768520
2023-10-30 04:01:38,813 Epoch: [92/484] Iter:[440/495], Time: 0.37, lr: [0.00825485241601318], Loss: 2.112281, Acc:0.789002, Semantic loss: 0.800580, BCE loss: 0.543233, SB loss: 0.768468
2023-10-30 04:01:42,442 Epoch: [92/484] Iter:[450/495], Time: 0.37, lr: [0.00825446866671761], Loss: 2.109117, Acc:0.788329, Semantic loss: 0.799044, BCE loss: 0.542689, SB loss: 0.767384
2023-10-30 04:01:46,189 Epoch: [92/484] Iter:[460/495], Time: 0.37, lr: [0.00825408491543976], Loss: 2.108875, Acc:0.788284, Semantic loss: 0.798740, BCE loss: 0.542429, SB loss: 0.767707
2023-10-30 04:01:49,847 Epoch: [92/484] Iter:[470/495], Time: 0.37, lr: [0.008253701162179512], Loss: 2.111116, Acc:0.788176, Semantic loss: 0.801412, BCE loss: 0.541691, SB loss: 0.768013
2023-10-30 04:01:53,510 Epoch: [92/484] Iter:[480/495], Time: 0.37, lr: [0.008253317406936756], Loss: 2.110217, Acc:0.787935, Semantic loss: 0.800776, BCE loss: 0.541794, SB loss: 0.767647
2023-10-30 04:01:56,997 Epoch: [92/484] Iter:[490/495], Time: 0.37, lr: [0.008252933649711379], Loss: 2.112674, Acc:0.788202, Semantic loss: 0.803303, BCE loss: 0.541498, SB loss: 0.767874
2023-10-30 04:01:58,369 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:01:58,604 Loss: 2.113, MeanIU:  0.6733, Best_mIoU:  0.6835
2023-10-30 04:01:58,604 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424]
2023-10-30 04:02:00,738 Epoch: [93/484] Iter:[0/495], Time: 2.10, lr: [0.008252741770355171], Loss: 2.193310, Acc:0.727856, Semantic loss: 0.766350, BCE loss: 0.639889, SB loss: 0.787070
2023-10-30 04:02:04,660 Epoch: [93/484] Iter:[10/495], Time: 0.55, lr: [0.00825235801015565], Loss: 2.167774, Acc:0.764414, Semantic loss: 0.804492, BCE loss: 0.560924, SB loss: 0.802359
2023-10-30 04:02:08,420 Epoch: [93/484] Iter:[20/495], Time: 0.47, lr: [0.008251974247973224], Loss: 2.127742, Acc:0.762279, Semantic loss: 0.793127, BCE loss: 0.540998, SB loss: 0.793617
2023-10-30 04:02:12,057 Epoch: [93/484] Iter:[30/495], Time: 0.43, lr: [0.008251590483807783], Loss: 2.185772, Acc:0.776032, Semantic loss: 0.807418, BCE loss: 0.578031, SB loss: 0.800322
2023-10-30 04:02:15,785 Epoch: [93/484] Iter:[40/495], Time: 0.42, lr: [0.008251206717659214], Loss: 2.150853, Acc:0.789418, Semantic loss: 0.790719, BCE loss: 0.574298, SB loss: 0.785836
2023-10-30 04:02:19,430 Epoch: [93/484] Iter:[50/495], Time: 0.41, lr: [0.0082508229495274], Loss: 2.149090, Acc:0.790019, Semantic loss: 0.801506, BCE loss: 0.571421, SB loss: 0.776163
2023-10-30 04:02:23,091 Epoch: [93/484] Iter:[60/495], Time: 0.40, lr: [0.008250439179412237], Loss: 2.128477, Acc:0.790500, Semantic loss: 0.794568, BCE loss: 0.559691, SB loss: 0.774218
2023-10-30 04:02:26,768 Epoch: [93/484] Iter:[70/495], Time: 0.40, lr: [0.008250055407313604], Loss: 2.128146, Acc:0.789989, Semantic loss: 0.803070, BCE loss: 0.551611, SB loss: 0.773464
2023-10-30 04:02:30,459 Epoch: [93/484] Iter:[80/495], Time: 0.39, lr: [0.008249671633231393], Loss: 2.133626, Acc:0.790883, Semantic loss: 0.804742, BCE loss: 0.550899, SB loss: 0.777986
2023-10-30 04:02:34,146 Epoch: [93/484] Iter:[90/495], Time: 0.39, lr: [0.008249287857165489], Loss: 2.118211, Acc:0.789093, Semantic loss: 0.795611, BCE loss: 0.549340, SB loss: 0.773261
2023-10-30 04:02:37,829 Epoch: [93/484] Iter:[100/495], Time: 0.39, lr: [0.008248904079115778], Loss: 2.109187, Acc:0.792119, Semantic loss: 0.790358, BCE loss: 0.547604, SB loss: 0.771225
2023-10-30 04:02:41,494 Epoch: [93/484] Iter:[110/495], Time: 0.39, lr: [0.00824852029908215], Loss: 2.102973, Acc:0.794050, Semantic loss: 0.785897, BCE loss: 0.548114, SB loss: 0.768963
2023-10-30 04:02:45,128 Epoch: [93/484] Iter:[120/495], Time: 0.38, lr: [0.00824813651706449], Loss: 2.100303, Acc:0.792755, Semantic loss: 0.789693, BCE loss: 0.545015, SB loss: 0.765596
2023-10-30 04:02:48,844 Epoch: [93/484] Iter:[130/495], Time: 0.38, lr: [0.008247752733062687], Loss: 2.109044, Acc:0.789901, Semantic loss: 0.793534, BCE loss: 0.548257, SB loss: 0.767253
2023-10-30 04:02:52,504 Epoch: [93/484] Iter:[140/495], Time: 0.38, lr: [0.008247368947076627], Loss: 2.111457, Acc:0.790815, Semantic loss: 0.795599, BCE loss: 0.549551, SB loss: 0.766306
2023-10-30 04:02:56,252 Epoch: [93/484] Iter:[150/495], Time: 0.38, lr: [0.008246985159106199], Loss: 2.108156, Acc:0.790952, Semantic loss: 0.794010, BCE loss: 0.548342, SB loss: 0.765804
2023-10-30 04:02:59,981 Epoch: [93/484] Iter:[160/495], Time: 0.38, lr: [0.008246601369151287], Loss: 2.106266, Acc:0.793194, Semantic loss: 0.792618, BCE loss: 0.547152, SB loss: 0.766497
2023-10-30 04:03:03,588 Epoch: [93/484] Iter:[170/495], Time: 0.38, lr: [0.00824621757721178], Loss: 2.112125, Acc:0.793944, Semantic loss: 0.796319, BCE loss: 0.549904, SB loss: 0.765903
2023-10-30 04:03:07,337 Epoch: [93/484] Iter:[180/495], Time: 0.38, lr: [0.008245833783287566], Loss: 2.107007, Acc:0.793349, Semantic loss: 0.795575, BCE loss: 0.546344, SB loss: 0.765087
2023-10-30 04:03:11,030 Epoch: [93/484] Iter:[190/495], Time: 0.38, lr: [0.00824544998737853], Loss: 2.107654, Acc:0.791965, Semantic loss: 0.796133, BCE loss: 0.546246, SB loss: 0.765275
2023-10-30 04:03:14,809 Epoch: [93/484] Iter:[200/495], Time: 0.38, lr: [0.00824506618948456], Loss: 2.112758, Acc:0.790369, Semantic loss: 0.800136, BCE loss: 0.547871, SB loss: 0.764751
2023-10-30 04:03:18,509 Epoch: [93/484] Iter:[210/495], Time: 0.38, lr: [0.008244682389605544], Loss: 2.110493, Acc:0.789931, Semantic loss: 0.797605, BCE loss: 0.548644, SB loss: 0.764244
2023-10-30 04:03:22,173 Epoch: [93/484] Iter:[220/495], Time: 0.38, lr: [0.008244298587741368], Loss: 2.114675, Acc:0.789488, Semantic loss: 0.798597, BCE loss: 0.551521, SB loss: 0.764557
2023-10-30 04:03:25,784 Epoch: [93/484] Iter:[230/495], Time: 0.38, lr: [0.00824391478389192], Loss: 2.114885, Acc:0.788089, Semantic loss: 0.800036, BCE loss: 0.549306, SB loss: 0.765544
2023-10-30 04:03:29,549 Epoch: [93/484] Iter:[240/495], Time: 0.38, lr: [0.008243530978057084], Loss: 2.122193, Acc:0.788512, Semantic loss: 0.805663, BCE loss: 0.550579, SB loss: 0.765951
2023-10-30 04:03:33,161 Epoch: [93/484] Iter:[250/495], Time: 0.38, lr: [0.008243147170236751], Loss: 2.128192, Acc:0.788680, Semantic loss: 0.807673, BCE loss: 0.552823, SB loss: 0.767696
2023-10-30 04:03:36,939 Epoch: [93/484] Iter:[260/495], Time: 0.38, lr: [0.008242763360430805], Loss: 2.128690, Acc:0.788931, Semantic loss: 0.807017, BCE loss: 0.553911, SB loss: 0.767762
2023-10-30 04:03:40,667 Epoch: [93/484] Iter:[270/495], Time: 0.38, lr: [0.008242379548639137], Loss: 2.128691, Acc:0.790078, Semantic loss: 0.803472, BCE loss: 0.556296, SB loss: 0.768923
2023-10-30 04:03:44,379 Epoch: [93/484] Iter:[280/495], Time: 0.38, lr: [0.008241995734861628], Loss: 2.128737, Acc:0.790623, Semantic loss: 0.803579, BCE loss: 0.556555, SB loss: 0.768603
2023-10-30 04:03:48,031 Epoch: [93/484] Iter:[290/495], Time: 0.38, lr: [0.00824161191909817], Loss: 2.130307, Acc:0.790563, Semantic loss: 0.804848, BCE loss: 0.556352, SB loss: 0.769107
2023-10-30 04:03:51,669 Epoch: [93/484] Iter:[300/495], Time: 0.38, lr: [0.008241228101348648], Loss: 2.126014, Acc:0.789764, Semantic loss: 0.804084, BCE loss: 0.554019, SB loss: 0.767911
2023-10-30 04:03:55,334 Epoch: [93/484] Iter:[310/495], Time: 0.38, lr: [0.008240844281612949], Loss: 2.126973, Acc:0.790224, Semantic loss: 0.805043, BCE loss: 0.553795, SB loss: 0.768135
2023-10-30 04:03:58,975 Epoch: [93/484] Iter:[320/495], Time: 0.37, lr: [0.00824046045989096], Loss: 2.121906, Acc:0.788913, Semantic loss: 0.804400, BCE loss: 0.549799, SB loss: 0.767707
2023-10-30 04:04:02,710 Epoch: [93/484] Iter:[330/495], Time: 0.37, lr: [0.008240076636182567], Loss: 2.126743, Acc:0.790146, Semantic loss: 0.804802, BCE loss: 0.553569, SB loss: 0.768372
2023-10-30 04:04:06,349 Epoch: [93/484] Iter:[340/495], Time: 0.37, lr: [0.00823969281048766], Loss: 2.122927, Acc:0.790291, Semantic loss: 0.802274, BCE loss: 0.552859, SB loss: 0.767794
2023-10-30 04:04:10,088 Epoch: [93/484] Iter:[350/495], Time: 0.37, lr: [0.008239308982806124], Loss: 2.127651, Acc:0.789540, Semantic loss: 0.805487, BCE loss: 0.553653, SB loss: 0.768511
2023-10-30 04:04:13,796 Epoch: [93/484] Iter:[360/495], Time: 0.37, lr: [0.008238925153137842], Loss: 2.124469, Acc:0.789716, Semantic loss: 0.803361, BCE loss: 0.553396, SB loss: 0.767712
2023-10-30 04:04:17,516 Epoch: [93/484] Iter:[370/495], Time: 0.37, lr: [0.008238541321482707], Loss: 2.123119, Acc:0.791856, Semantic loss: 0.802781, BCE loss: 0.553227, SB loss: 0.767112
2023-10-30 04:04:21,178 Epoch: [93/484] Iter:[380/495], Time: 0.37, lr: [0.008238157487840606], Loss: 2.122087, Acc:0.792350, Semantic loss: 0.801857, BCE loss: 0.553884, SB loss: 0.766346
2023-10-30 04:04:24,836 Epoch: [93/484] Iter:[390/495], Time: 0.37, lr: [0.00823777365221142], Loss: 2.124566, Acc:0.793023, Semantic loss: 0.802547, BCE loss: 0.555511, SB loss: 0.766508
2023-10-30 04:04:28,455 Epoch: [93/484] Iter:[400/495], Time: 0.37, lr: [0.00823738981459504], Loss: 2.121908, Acc:0.793335, Semantic loss: 0.801699, BCE loss: 0.554294, SB loss: 0.765915
2023-10-30 04:04:32,135 Epoch: [93/484] Iter:[410/495], Time: 0.37, lr: [0.008237005974991352], Loss: 2.122526, Acc:0.793860, Semantic loss: 0.802952, BCE loss: 0.553126, SB loss: 0.766449
2023-10-30 04:04:35,829 Epoch: [93/484] Iter:[420/495], Time: 0.37, lr: [0.008236622133400243], Loss: 2.122242, Acc:0.794493, Semantic loss: 0.802355, BCE loss: 0.553069, SB loss: 0.766818
2023-10-30 04:04:39,617 Epoch: [93/484] Iter:[430/495], Time: 0.37, lr: [0.008236238289821599], Loss: 2.120164, Acc:0.794150, Semantic loss: 0.801379, BCE loss: 0.552546, SB loss: 0.766239
2023-10-30 04:04:43,381 Epoch: [93/484] Iter:[440/495], Time: 0.37, lr: [0.008235854444255307], Loss: 2.118558, Acc:0.794478, Semantic loss: 0.800371, BCE loss: 0.552795, SB loss: 0.765392
2023-10-30 04:04:47,215 Epoch: [93/484] Iter:[450/495], Time: 0.37, lr: [0.008235470596701256], Loss: 2.118635, Acc:0.794173, Semantic loss: 0.800274, BCE loss: 0.552574, SB loss: 0.765788
2023-10-30 04:04:50,855 Epoch: [93/484] Iter:[460/495], Time: 0.37, lr: [0.00823508674715933], Loss: 2.117270, Acc:0.794388, Semantic loss: 0.800186, BCE loss: 0.551765, SB loss: 0.765319
2023-10-30 04:04:54,572 Epoch: [93/484] Iter:[470/495], Time: 0.37, lr: [0.008234702895629416], Loss: 2.123036, Acc:0.794815, Semantic loss: 0.803631, BCE loss: 0.553563, SB loss: 0.765843
2023-10-30 04:04:58,241 Epoch: [93/484] Iter:[480/495], Time: 0.37, lr: [0.008234319042111403], Loss: 2.121583, Acc:0.794787, Semantic loss: 0.802351, BCE loss: 0.553307, SB loss: 0.765925
2023-10-30 04:05:01,706 Epoch: [93/484] Iter:[490/495], Time: 0.37, lr: [0.008233935186605175], Loss: 2.121047, Acc:0.793687, Semantic loss: 0.800906, BCE loss: 0.553604, SB loss: 0.766537
2023-10-30 04:05:03,105 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:05:03,357 Loss: 2.113, MeanIU:  0.6733, Best_mIoU:  0.6835
2023-10-30 04:05:03,357 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424]
2023-10-30 04:05:05,464 Epoch: [94/484] Iter:[0/495], Time: 2.07, lr: [0.008233743258106446], Loss: 2.347088, Acc:0.930756, Semantic loss: 0.861830, BCE loss: 0.693847, SB loss: 0.791411
2023-10-30 04:05:09,486 Epoch: [94/484] Iter:[10/495], Time: 0.55, lr: [0.008233359399617684], Loss: 2.152233, Acc:0.821062, Semantic loss: 0.786633, BCE loss: 0.549543, SB loss: 0.816057
2023-10-30 04:05:13,114 Epoch: [94/484] Iter:[20/495], Time: 0.46, lr: [0.008232975539140427], Loss: 2.059108, Acc:0.800707, Semantic loss: 0.763867, BCE loss: 0.526445, SB loss: 0.768796
2023-10-30 04:05:16,785 Epoch: [94/484] Iter:[30/495], Time: 0.43, lr: [0.008232591676674558], Loss: 2.048309, Acc:0.795120, Semantic loss: 0.765561, BCE loss: 0.516679, SB loss: 0.766069
2023-10-30 04:05:20,448 Epoch: [94/484] Iter:[40/495], Time: 0.42, lr: [0.008232207812219963], Loss: 2.080338, Acc:0.801541, Semantic loss: 0.779023, BCE loss: 0.535299, SB loss: 0.766016
2023-10-30 04:05:24,161 Epoch: [94/484] Iter:[50/495], Time: 0.41, lr: [0.008231823945776534], Loss: 2.099486, Acc:0.788349, Semantic loss: 0.784315, BCE loss: 0.546654, SB loss: 0.768517
2023-10-30 04:05:27,888 Epoch: [94/484] Iter:[60/495], Time: 0.40, lr: [0.008231440077344155], Loss: 2.102436, Acc:0.791632, Semantic loss: 0.783196, BCE loss: 0.549562, SB loss: 0.769678
2023-10-30 04:05:31,593 Epoch: [94/484] Iter:[70/495], Time: 0.40, lr: [0.008231056206922712], Loss: 2.112776, Acc:0.787104, Semantic loss: 0.796619, BCE loss: 0.542916, SB loss: 0.773240
2023-10-30 04:05:35,220 Epoch: [94/484] Iter:[80/495], Time: 0.39, lr: [0.00823067233451209], Loss: 2.136733, Acc:0.787271, Semantic loss: 0.805202, BCE loss: 0.550687, SB loss: 0.780843
2023-10-30 04:05:38,835 Epoch: [94/484] Iter:[90/495], Time: 0.39, lr: [0.008230288460112178], Loss: 2.171924, Acc:0.780107, Semantic loss: 0.826815, BCE loss: 0.555344, SB loss: 0.789764
2023-10-30 04:05:42,503 Epoch: [94/484] Iter:[100/495], Time: 0.39, lr: [0.008229904583722863], Loss: 2.176801, Acc:0.779606, Semantic loss: 0.823187, BCE loss: 0.563240, SB loss: 0.790374
2023-10-30 04:05:46,240 Epoch: [94/484] Iter:[110/495], Time: 0.39, lr: [0.008229520705344029], Loss: 2.173428, Acc:0.779961, Semantic loss: 0.819597, BCE loss: 0.564926, SB loss: 0.788905
2023-10-30 04:05:49,893 Epoch: [94/484] Iter:[120/495], Time: 0.38, lr: [0.008229136824975565], Loss: 2.172354, Acc:0.779718, Semantic loss: 0.820629, BCE loss: 0.565097, SB loss: 0.786628
2023-10-30 04:05:53,683 Epoch: [94/484] Iter:[130/495], Time: 0.38, lr: [0.008228752942617356], Loss: 2.175196, Acc:0.781147, Semantic loss: 0.821997, BCE loss: 0.566423, SB loss: 0.786776
2023-10-30 04:05:57,468 Epoch: [94/484] Iter:[140/495], Time: 0.38, lr: [0.008228369058269291], Loss: 2.169701, Acc:0.782654, Semantic loss: 0.818321, BCE loss: 0.566117, SB loss: 0.785264
2023-10-30 04:06:01,034 Epoch: [94/484] Iter:[150/495], Time: 0.38, lr: [0.008227985171931254], Loss: 2.180072, Acc:0.784873, Semantic loss: 0.821674, BCE loss: 0.570122, SB loss: 0.788276
2023-10-30 04:06:04,713 Epoch: [94/484] Iter:[160/495], Time: 0.38, lr: [0.008227601283603132], Loss: 2.176424, Acc:0.787620, Semantic loss: 0.816595, BCE loss: 0.573203, SB loss: 0.786626
2023-10-30 04:06:08,378 Epoch: [94/484] Iter:[170/495], Time: 0.38, lr: [0.008227217393284813], Loss: 2.177874, Acc:0.787285, Semantic loss: 0.814793, BCE loss: 0.573619, SB loss: 0.789462
2023-10-30 04:06:12,019 Epoch: [94/484] Iter:[180/495], Time: 0.38, lr: [0.00822683350097618], Loss: 2.169039, Acc:0.786147, Semantic loss: 0.812589, BCE loss: 0.567519, SB loss: 0.788930
2023-10-30 04:06:15,663 Epoch: [94/484] Iter:[190/495], Time: 0.38, lr: [0.008226449606677124], Loss: 2.162988, Acc:0.787233, Semantic loss: 0.811481, BCE loss: 0.564984, SB loss: 0.786523
2023-10-30 04:06:19,274 Epoch: [94/484] Iter:[200/495], Time: 0.38, lr: [0.008226065710387528], Loss: 2.161171, Acc:0.787500, Semantic loss: 0.811753, BCE loss: 0.563640, SB loss: 0.785778
2023-10-30 04:06:22,930 Epoch: [94/484] Iter:[210/495], Time: 0.38, lr: [0.008225681812107281], Loss: 2.161055, Acc:0.787601, Semantic loss: 0.812748, BCE loss: 0.561427, SB loss: 0.786880
2023-10-30 04:06:26,559 Epoch: [94/484] Iter:[220/495], Time: 0.38, lr: [0.008225297911836267], Loss: 2.152246, Acc:0.788541, Semantic loss: 0.807757, BCE loss: 0.560581, SB loss: 0.783907
2023-10-30 04:06:30,176 Epoch: [94/484] Iter:[230/495], Time: 0.38, lr: [0.008224914009574374], Loss: 2.148189, Acc:0.788210, Semantic loss: 0.807674, BCE loss: 0.558116, SB loss: 0.782399
2023-10-30 04:06:33,852 Epoch: [94/484] Iter:[240/495], Time: 0.38, lr: [0.008224530105321488], Loss: 2.142838, Acc:0.786774, Semantic loss: 0.804426, BCE loss: 0.556984, SB loss: 0.781429
2023-10-30 04:06:37,593 Epoch: [94/484] Iter:[250/495], Time: 0.38, lr: [0.008224146199077496], Loss: 2.138913, Acc:0.786819, Semantic loss: 0.803883, BCE loss: 0.554295, SB loss: 0.780734
2023-10-30 04:06:41,318 Epoch: [94/484] Iter:[260/495], Time: 0.38, lr: [0.008223762290842283], Loss: 2.140214, Acc:0.787353, Semantic loss: 0.804133, BCE loss: 0.555409, SB loss: 0.780671
2023-10-30 04:06:45,057 Epoch: [94/484] Iter:[270/495], Time: 0.38, lr: [0.008223378380615737], Loss: 2.140021, Acc:0.787247, Semantic loss: 0.805399, BCE loss: 0.555318, SB loss: 0.779304
2023-10-30 04:06:48,809 Epoch: [94/484] Iter:[280/495], Time: 0.38, lr: [0.008222994468397743], Loss: 2.135921, Acc:0.787526, Semantic loss: 0.803323, BCE loss: 0.554722, SB loss: 0.777876
2023-10-30 04:06:52,383 Epoch: [94/484] Iter:[290/495], Time: 0.37, lr: [0.008222610554188188], Loss: 2.136004, Acc:0.788512, Semantic loss: 0.803244, BCE loss: 0.554769, SB loss: 0.777990
2023-10-30 04:06:56,119 Epoch: [94/484] Iter:[300/495], Time: 0.37, lr: [0.008222226637986961], Loss: 2.131651, Acc:0.788683, Semantic loss: 0.801830, BCE loss: 0.553027, SB loss: 0.776794
2023-10-30 04:06:59,766 Epoch: [94/484] Iter:[310/495], Time: 0.37, lr: [0.008221842719793942], Loss: 2.136001, Acc:0.789940, Semantic loss: 0.804122, BCE loss: 0.554337, SB loss: 0.777542
2023-10-30 04:07:03,769 Epoch: [94/484] Iter:[320/495], Time: 0.37, lr: [0.008221458799609022], Loss: 2.136032, Acc:0.791063, Semantic loss: 0.804134, BCE loss: 0.554117, SB loss: 0.777781
2023-10-30 04:07:07,449 Epoch: [94/484] Iter:[330/495], Time: 0.37, lr: [0.008221074877432087], Loss: 2.135786, Acc:0.791246, Semantic loss: 0.802231, BCE loss: 0.555999, SB loss: 0.777556
2023-10-30 04:07:11,067 Epoch: [94/484] Iter:[340/495], Time: 0.37, lr: [0.008220690953263023], Loss: 2.130002, Acc:0.792687, Semantic loss: 0.799211, BCE loss: 0.554822, SB loss: 0.775969
2023-10-30 04:07:14,749 Epoch: [94/484] Iter:[350/495], Time: 0.37, lr: [0.008220307027101715], Loss: 2.127603, Acc:0.791507, Semantic loss: 0.798626, BCE loss: 0.553098, SB loss: 0.775879
2023-10-30 04:07:18,404 Epoch: [94/484] Iter:[360/495], Time: 0.37, lr: [0.00821992309894805], Loss: 2.126732, Acc:0.790791, Semantic loss: 0.798818, BCE loss: 0.551854, SB loss: 0.776060
2023-10-30 04:07:22,069 Epoch: [94/484] Iter:[370/495], Time: 0.37, lr: [0.008219539168801917], Loss: 2.122753, Acc:0.791318, Semantic loss: 0.796964, BCE loss: 0.551513, SB loss: 0.774276
2023-10-30 04:07:25,741 Epoch: [94/484] Iter:[380/495], Time: 0.37, lr: [0.008219155236663197], Loss: 2.123273, Acc:0.791250, Semantic loss: 0.797801, BCE loss: 0.551512, SB loss: 0.773960
2023-10-30 04:07:29,388 Epoch: [94/484] Iter:[390/495], Time: 0.37, lr: [0.008218771302531779], Loss: 2.121945, Acc:0.790742, Semantic loss: 0.796635, BCE loss: 0.550958, SB loss: 0.774352
2023-10-30 04:07:33,057 Epoch: [94/484] Iter:[400/495], Time: 0.37, lr: [0.008218387366407549], Loss: 2.125265, Acc:0.790512, Semantic loss: 0.800374, BCE loss: 0.549990, SB loss: 0.774901
2023-10-30 04:07:36,772 Epoch: [94/484] Iter:[410/495], Time: 0.37, lr: [0.008218003428290394], Loss: 2.125058, Acc:0.790808, Semantic loss: 0.799776, BCE loss: 0.551100, SB loss: 0.774182
2023-10-30 04:07:40,514 Epoch: [94/484] Iter:[420/495], Time: 0.37, lr: [0.0082176194881802], Loss: 2.125121, Acc:0.790990, Semantic loss: 0.799535, BCE loss: 0.551787, SB loss: 0.773800
2023-10-30 04:07:44,130 Epoch: [94/484] Iter:[430/495], Time: 0.37, lr: [0.008217235546076852], Loss: 2.128465, Acc:0.791385, Semantic loss: 0.800811, BCE loss: 0.553222, SB loss: 0.774431
2023-10-30 04:07:47,808 Epoch: [94/484] Iter:[440/495], Time: 0.37, lr: [0.008216851601980239], Loss: 2.128981, Acc:0.791685, Semantic loss: 0.801602, BCE loss: 0.552740, SB loss: 0.774639
2023-10-30 04:07:51,518 Epoch: [94/484] Iter:[450/495], Time: 0.37, lr: [0.008216467655890243], Loss: 2.127813, Acc:0.791864, Semantic loss: 0.800622, BCE loss: 0.553167, SB loss: 0.774024
2023-10-30 04:07:55,129 Epoch: [94/484] Iter:[460/495], Time: 0.37, lr: [0.008216083707806753], Loss: 2.128151, Acc:0.792256, Semantic loss: 0.801006, BCE loss: 0.553657, SB loss: 0.773488
2023-10-30 04:07:58,774 Epoch: [94/484] Iter:[470/495], Time: 0.37, lr: [0.008215699757729653], Loss: 2.126006, Acc:0.792309, Semantic loss: 0.800522, BCE loss: 0.552759, SB loss: 0.772725
2023-10-30 04:08:02,523 Epoch: [94/484] Iter:[480/495], Time: 0.37, lr: [0.008215315805658832], Loss: 2.126528, Acc:0.792422, Semantic loss: 0.801167, BCE loss: 0.552265, SB loss: 0.773097
2023-10-30 04:08:06,002 Epoch: [94/484] Iter:[490/495], Time: 0.37, lr: [0.008214931851594175], Loss: 2.128545, Acc:0.792407, Semantic loss: 0.802009, BCE loss: 0.553026, SB loss: 0.773509
2023-10-30 04:08:07,414 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:08:07,656 Loss: 2.113, MeanIU:  0.6733, Best_mIoU:  0.6835
2023-10-30 04:08:07,656 [0.9727156  0.78944347 0.89516569 0.42509708 0.51677809 0.53578638
 0.59212064 0.70580295 0.87511148 0.43111618 0.91967654 0.75792613
 0.54412382 0.92234647 0.56603471 0.64083965 0.51257539 0.47565793
 0.71394424]
2023-10-30 04:08:09,730 Epoch: [95/484] Iter:[0/495], Time: 2.04, lr: [0.00821473987381412], Loss: 1.742370, Acc:0.807499, Semantic loss: 0.670942, BCE loss: 0.365826, SB loss: 0.705603
2023-10-30 04:08:13,831 Epoch: [95/484] Iter:[10/495], Time: 0.56, lr: [0.008214355916758495], Loss: 2.018581, Acc:0.798811, Semantic loss: 0.716609, BCE loss: 0.579894, SB loss: 0.722078
2023-10-30 04:08:17,483 Epoch: [95/484] Iter:[20/495], Time: 0.47, lr: [0.00821397195770875], Loss: 2.126036, Acc:0.817580, Semantic loss: 0.796775, BCE loss: 0.578164, SB loss: 0.751097
2023-10-30 04:08:21,190 Epoch: [95/484] Iter:[30/495], Time: 0.44, lr: [0.008213587996664768], Loss: 2.111426, Acc:0.803330, Semantic loss: 0.807648, BCE loss: 0.550024, SB loss: 0.753754
2023-10-30 04:08:24,810 Epoch: [95/484] Iter:[40/495], Time: 0.42, lr: [0.008213204033626437], Loss: 2.092964, Acc:0.805874, Semantic loss: 0.795876, BCE loss: 0.542549, SB loss: 0.754539
2023-10-30 04:08:28,483 Epoch: [95/484] Iter:[50/495], Time: 0.41, lr: [0.008212820068593642], Loss: 2.108240, Acc:0.806067, Semantic loss: 0.804503, BCE loss: 0.536731, SB loss: 0.767007
2023-10-30 04:08:32,210 Epoch: [95/484] Iter:[60/495], Time: 0.40, lr: [0.008212436101566271], Loss: 2.123215, Acc:0.807614, Semantic loss: 0.812456, BCE loss: 0.537710, SB loss: 0.773049
2023-10-30 04:08:35,826 Epoch: [95/484] Iter:[70/495], Time: 0.40, lr: [0.00821205213254421], Loss: 2.111923, Acc:0.803539, Semantic loss: 0.803885, BCE loss: 0.538298, SB loss: 0.769739
2023-10-30 04:08:39,523 Epoch: [95/484] Iter:[80/495], Time: 0.39, lr: [0.008211668161527344], Loss: 2.102201, Acc:0.800665, Semantic loss: 0.796530, BCE loss: 0.534289, SB loss: 0.771382
2023-10-30 04:08:43,223 Epoch: [95/484] Iter:[90/495], Time: 0.39, lr: [0.008211284188515558], Loss: 2.104350, Acc:0.804277, Semantic loss: 0.799112, BCE loss: 0.533999, SB loss: 0.771239
2023-10-30 04:08:46,912 Epoch: [95/484] Iter:[100/495], Time: 0.39, lr: [0.00821090021350874], Loss: 2.125388, Acc:0.801427, Semantic loss: 0.810567, BCE loss: 0.536537, SB loss: 0.778284
2023-10-30 04:08:50,708 Epoch: [95/484] Iter:[110/495], Time: 0.39, lr: [0.008210516236506774], Loss: 2.122609, Acc:0.799384, Semantic loss: 0.807431, BCE loss: 0.536561, SB loss: 0.778616
2023-10-30 04:08:54,385 Epoch: [95/484] Iter:[120/495], Time: 0.39, lr: [0.008210132257509549], Loss: 2.125532, Acc:0.798476, Semantic loss: 0.809991, BCE loss: 0.537241, SB loss: 0.778300
2023-10-30 04:08:58,024 Epoch: [95/484] Iter:[130/495], Time: 0.38, lr: [0.008209748276516946], Loss: 2.133476, Acc:0.796333, Semantic loss: 0.813358, BCE loss: 0.540679, SB loss: 0.779439
2023-10-30 04:09:01,685 Epoch: [95/484] Iter:[140/495], Time: 0.38, lr: [0.008209364293528856], Loss: 2.123014, Acc:0.796708, Semantic loss: 0.806289, BCE loss: 0.541183, SB loss: 0.775542
2023-10-30 04:09:05,328 Epoch: [95/484] Iter:[150/495], Time: 0.38, lr: [0.008208980308545163], Loss: 2.121462, Acc:0.795342, Semantic loss: 0.806342, BCE loss: 0.539852, SB loss: 0.775268
2023-10-30 04:09:08,977 Epoch: [95/484] Iter:[160/495], Time: 0.38, lr: [0.008208596321565752], Loss: 2.115962, Acc:0.796063, Semantic loss: 0.802654, BCE loss: 0.538281, SB loss: 0.775028
2023-10-30 04:09:12,622 Epoch: [95/484] Iter:[170/495], Time: 0.38, lr: [0.008208212332590508], Loss: 2.112880, Acc:0.796729, Semantic loss: 0.802919, BCE loss: 0.535961, SB loss: 0.774000
2023-10-30 04:09:16,206 Epoch: [95/484] Iter:[180/495], Time: 0.38, lr: [0.008207828341619322], Loss: 2.113724, Acc:0.795544, Semantic loss: 0.804273, BCE loss: 0.536938, SB loss: 0.772513
2023-10-30 04:09:19,898 Epoch: [95/484] Iter:[190/495], Time: 0.38, lr: [0.008207444348652074], Loss: 2.103710, Acc:0.794290, Semantic loss: 0.797965, BCE loss: 0.536446, SB loss: 0.769299
2023-10-30 04:09:23,607 Epoch: [95/484] Iter:[200/495], Time: 0.38, lr: [0.008207060353688653], Loss: 2.098658, Acc:0.795118, Semantic loss: 0.794240, BCE loss: 0.536793, SB loss: 0.767626
2023-10-30 04:09:27,218 Epoch: [95/484] Iter:[210/495], Time: 0.38, lr: [0.008206676356728945], Loss: 2.105246, Acc:0.794309, Semantic loss: 0.798112, BCE loss: 0.537185, SB loss: 0.769949
2023-10-30 04:09:30,890 Epoch: [95/484] Iter:[220/495], Time: 0.38, lr: [0.008206292357772833], Loss: 2.108020, Acc:0.794393, Semantic loss: 0.799411, BCE loss: 0.537220, SB loss: 0.771390
2023-10-30 04:09:34,720 Epoch: [95/484] Iter:[230/495], Time: 0.38, lr: [0.008205908356820205], Loss: 2.108607, Acc:0.795268, Semantic loss: 0.800585, BCE loss: 0.538677, SB loss: 0.769345
2023-10-30 04:09:38,494 Epoch: [95/484] Iter:[240/495], Time: 0.38, lr: [0.008205524353870947], Loss: 2.108321, Acc:0.797168, Semantic loss: 0.800577, BCE loss: 0.539023, SB loss: 0.768721
2023-10-30 04:09:42,194 Epoch: [95/484] Iter:[250/495], Time: 0.38, lr: [0.008205140348924946], Loss: 2.108416, Acc:0.797548, Semantic loss: 0.799741, BCE loss: 0.540885, SB loss: 0.767790
2023-10-30 04:09:45,839 Epoch: [95/484] Iter:[260/495], Time: 0.38, lr: [0.008204756341982084], Loss: 2.109745, Acc:0.798218, Semantic loss: 0.799161, BCE loss: 0.544121, SB loss: 0.766463
2023-10-30 04:09:49,482 Epoch: [95/484] Iter:[270/495], Time: 0.38, lr: [0.00820437233304225], Loss: 2.120322, Acc:0.798194, Semantic loss: 0.803487, BCE loss: 0.549312, SB loss: 0.767523
2023-10-30 04:09:53,159 Epoch: [95/484] Iter:[280/495], Time: 0.38, lr: [0.008203988322105327], Loss: 2.119519, Acc:0.797288, Semantic loss: 0.803338, BCE loss: 0.548202, SB loss: 0.767980
2023-10-30 04:09:56,857 Epoch: [95/484] Iter:[290/495], Time: 0.38, lr: [0.008203604309171204], Loss: 2.117267, Acc:0.796261, Semantic loss: 0.801551, BCE loss: 0.547767, SB loss: 0.767949
2023-10-30 04:10:00,635 Epoch: [95/484] Iter:[300/495], Time: 0.38, lr: [0.008203220294239765], Loss: 2.119296, Acc:0.796729, Semantic loss: 0.803933, BCE loss: 0.547275, SB loss: 0.768088
2023-10-30 04:10:04,269 Epoch: [95/484] Iter:[310/495], Time: 0.37, lr: [0.008202836277310896], Loss: 2.120559, Acc:0.795818, Semantic loss: 0.805828, BCE loss: 0.545298, SB loss: 0.769433
2023-10-30 04:10:07,893 Epoch: [95/484] Iter:[320/495], Time: 0.37, lr: [0.008202452258384481], Loss: 2.119901, Acc:0.794735, Semantic loss: 0.805018, BCE loss: 0.545342, SB loss: 0.769541
2023-10-30 04:10:11,502 Epoch: [95/484] Iter:[330/495], Time: 0.37, lr: [0.008202068237460409], Loss: 2.117320, Acc:0.794827, Semantic loss: 0.802837, BCE loss: 0.545616, SB loss: 0.768868
2023-10-30 04:10:15,262 Epoch: [95/484] Iter:[340/495], Time: 0.37, lr: [0.008201684214538565], Loss: 2.118914, Acc:0.793744, Semantic loss: 0.803844, BCE loss: 0.545790, SB loss: 0.769280
2023-10-30 04:10:18,983 Epoch: [95/484] Iter:[350/495], Time: 0.37, lr: [0.008201300189618831], Loss: 2.114324, Acc:0.793085, Semantic loss: 0.802656, BCE loss: 0.543705, SB loss: 0.767963
2023-10-30 04:10:22,643 Epoch: [95/484] Iter:[360/495], Time: 0.37, lr: [0.008200916162701096], Loss: 2.115498, Acc:0.793322, Semantic loss: 0.802501, BCE loss: 0.543992, SB loss: 0.769005
2023-10-30 04:10:26,253 Epoch: [95/484] Iter:[370/495], Time: 0.37, lr: [0.008200532133785245], Loss: 2.113853, Acc:0.792763, Semantic loss: 0.800952, BCE loss: 0.544308, SB loss: 0.768593
2023-10-30 04:10:29,904 Epoch: [95/484] Iter:[380/495], Time: 0.37, lr: [0.008200148102871164], Loss: 2.112715, Acc:0.793232, Semantic loss: 0.799515, BCE loss: 0.544191, SB loss: 0.769009
2023-10-30 04:10:33,622 Epoch: [95/484] Iter:[390/495], Time: 0.37, lr: [0.008199764069958738], Loss: 2.110768, Acc:0.793113, Semantic loss: 0.799008, BCE loss: 0.542963, SB loss: 0.768796
2023-10-30 04:10:37,322 Epoch: [95/484] Iter:[400/495], Time: 0.37, lr: [0.008199380035047853], Loss: 2.112000, Acc:0.792593, Semantic loss: 0.798897, BCE loss: 0.543219, SB loss: 0.769883
2023-10-30 04:10:40,951 Epoch: [95/484] Iter:[410/495], Time: 0.37, lr: [0.008198995998138394], Loss: 2.113613, Acc:0.792047, Semantic loss: 0.800327, BCE loss: 0.542760, SB loss: 0.770526
2023-10-30 04:10:44,607 Epoch: [95/484] Iter:[420/495], Time: 0.37, lr: [0.008198611959230247], Loss: 2.117678, Acc:0.792016, Semantic loss: 0.801395, BCE loss: 0.544243, SB loss: 0.772039
2023-10-30 04:10:48,362 Epoch: [95/484] Iter:[430/495], Time: 0.37, lr: [0.008198227918323298], Loss: 2.116628, Acc:0.792185, Semantic loss: 0.800914, BCE loss: 0.543678, SB loss: 0.772036
2023-10-30 04:10:51,981 Epoch: [95/484] Iter:[440/495], Time: 0.37, lr: [0.008197843875417433], Loss: 2.118947, Acc:0.792143, Semantic loss: 0.803060, BCE loss: 0.543538, SB loss: 0.772349
2023-10-30 04:10:55,713 Epoch: [95/484] Iter:[450/495], Time: 0.37, lr: [0.008197459830512534], Loss: 2.118142, Acc:0.792174, Semantic loss: 0.802022, BCE loss: 0.543793, SB loss: 0.772327
2023-10-30 04:10:59,434 Epoch: [95/484] Iter:[460/495], Time: 0.37, lr: [0.00819707578360849], Loss: 2.117236, Acc:0.792747, Semantic loss: 0.801659, BCE loss: 0.544017, SB loss: 0.771559
2023-10-30 04:11:03,112 Epoch: [95/484] Iter:[470/495], Time: 0.37, lr: [0.008196691734705188], Loss: 2.119541, Acc:0.793228, Semantic loss: 0.803113, BCE loss: 0.544598, SB loss: 0.771830
2023-10-30 04:11:06,735 Epoch: [95/484] Iter:[480/495], Time: 0.37, lr: [0.00819630768380251], Loss: 2.115048, Acc:0.792624, Semantic loss: 0.800215, BCE loss: 0.544437, SB loss: 0.770396
2023-10-30 04:11:10,265 Epoch: [95/484] Iter:[490/495], Time: 0.37, lr: [0.008195923630900341], Loss: 2.115182, Acc:0.792983, Semantic loss: 0.800237, BCE loss: 0.544768, SB loss: 0.770177
2023-10-30 04:14:06,004 0 [9.34687257e-01 6.19974831e-01 8.20910441e-01 1.14132986e-01
 2.22153046e-01 4.07272643e-01 4.34816021e-01 5.62507580e-01
 8.77715475e-01 3.88689521e-01 8.62486418e-01 5.66777882e-01
 1.06629599e-02 7.69915347e-01 3.77501763e-04 6.30645256e-02
 5.49074037e-02 5.69217957e-02 5.38023642e-01] 0.4371577514260064
2023-10-30 04:14:06,004 1 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659] 0.69067622132108
2023-10-30 04:14:06,008 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:14:06,376 Loss: 2.056, MeanIU:  0.6907, Best_mIoU:  0.6907
2023-10-30 04:14:06,376 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659]
2023-10-30 04:14:08,664 Epoch: [96/484] Iter:[0/495], Time: 2.25, lr: [0.008195731603699413], Loss: 2.089200, Acc:0.877537, Semantic loss: 0.786456, BCE loss: 0.513179, SB loss: 0.789565
2023-10-30 04:14:12,504 Epoch: [96/484] Iter:[10/495], Time: 0.55, lr: [0.008195347547797797], Loss: 2.049020, Acc:0.806205, Semantic loss: 0.756815, BCE loss: 0.533218, SB loss: 0.758987
2023-10-30 04:14:16,172 Epoch: [96/484] Iter:[20/495], Time: 0.46, lr: [0.008194963489896406], Loss: 2.062543, Acc:0.797236, Semantic loss: 0.778329, BCE loss: 0.539360, SB loss: 0.744854
2023-10-30 04:14:19,706 Epoch: [96/484] Iter:[30/495], Time: 0.43, lr: [0.008194579429995123], Loss: 2.124414, Acc:0.790676, Semantic loss: 0.815560, BCE loss: 0.540163, SB loss: 0.768692
2023-10-30 04:14:23,152 Epoch: [96/484] Iter:[40/495], Time: 0.41, lr: [0.008194195368093838], Loss: 2.159350, Acc:0.785183, Semantic loss: 0.845607, BCE loss: 0.529643, SB loss: 0.784100
2023-10-30 04:14:26,809 Epoch: [96/484] Iter:[50/495], Time: 0.40, lr: [0.00819381130419243], Loss: 2.137876, Acc:0.782820, Semantic loss: 0.817062, BCE loss: 0.539904, SB loss: 0.780910
2023-10-30 04:14:30,252 Epoch: [96/484] Iter:[60/495], Time: 0.39, lr: [0.00819342723829079], Loss: 2.130488, Acc:0.782366, Semantic loss: 0.810555, BCE loss: 0.541340, SB loss: 0.778593
2023-10-30 04:14:33,775 Epoch: [96/484] Iter:[70/495], Time: 0.39, lr: [0.008193043170388803], Loss: 2.134171, Acc:0.782987, Semantic loss: 0.813540, BCE loss: 0.541612, SB loss: 0.779019
2023-10-30 04:14:37,436 Epoch: [96/484] Iter:[80/495], Time: 0.38, lr: [0.008192659100486352], Loss: 2.121066, Acc:0.783536, Semantic loss: 0.804641, BCE loss: 0.536963, SB loss: 0.779462
2023-10-30 04:14:41,119 Epoch: [96/484] Iter:[90/495], Time: 0.38, lr: [0.008192275028583324], Loss: 2.138489, Acc:0.785842, Semantic loss: 0.811926, BCE loss: 0.543228, SB loss: 0.783334
2023-10-30 04:14:44,729 Epoch: [96/484] Iter:[100/495], Time: 0.38, lr: [0.008191890954679603], Loss: 2.134007, Acc:0.786922, Semantic loss: 0.809825, BCE loss: 0.540139, SB loss: 0.784043
2023-10-30 04:14:48,301 Epoch: [96/484] Iter:[110/495], Time: 0.38, lr: [0.008191506878775073], Loss: 2.126085, Acc:0.788415, Semantic loss: 0.804376, BCE loss: 0.542116, SB loss: 0.779593
2023-10-30 04:14:51,955 Epoch: [96/484] Iter:[120/495], Time: 0.38, lr: [0.008191122800869624], Loss: 2.127187, Acc:0.787994, Semantic loss: 0.802526, BCE loss: 0.545552, SB loss: 0.779109
2023-10-30 04:14:55,569 Epoch: [96/484] Iter:[130/495], Time: 0.38, lr: [0.008190738720963138], Loss: 2.116076, Acc:0.788849, Semantic loss: 0.794406, BCE loss: 0.547171, SB loss: 0.774498
2023-10-30 04:14:59,131 Epoch: [96/484] Iter:[140/495], Time: 0.37, lr: [0.0081903546390555], Loss: 2.120717, Acc:0.788217, Semantic loss: 0.796155, BCE loss: 0.548910, SB loss: 0.775652
2023-10-30 04:15:02,889 Epoch: [96/484] Iter:[150/495], Time: 0.37, lr: [0.008189970555146597], Loss: 2.110447, Acc:0.789985, Semantic loss: 0.791133, BCE loss: 0.548073, SB loss: 0.771242
2023-10-30 04:15:06,413 Epoch: [96/484] Iter:[160/495], Time: 0.37, lr: [0.008189586469236313], Loss: 2.109973, Acc:0.790122, Semantic loss: 0.789110, BCE loss: 0.551579, SB loss: 0.769284
2023-10-30 04:15:10,065 Epoch: [96/484] Iter:[170/495], Time: 0.37, lr: [0.008189202381324536], Loss: 2.114297, Acc:0.790422, Semantic loss: 0.791036, BCE loss: 0.554142, SB loss: 0.769120
2023-10-30 04:15:13,649 Epoch: [96/484] Iter:[180/495], Time: 0.37, lr: [0.00818881829141115], Loss: 2.110602, Acc:0.790263, Semantic loss: 0.789707, BCE loss: 0.553629, SB loss: 0.767266
2023-10-30 04:15:17,265 Epoch: [96/484] Iter:[190/495], Time: 0.37, lr: [0.008188434199496036], Loss: 2.108344, Acc:0.790413, Semantic loss: 0.790083, BCE loss: 0.551226, SB loss: 0.767034
2023-10-30 04:15:20,917 Epoch: [96/484] Iter:[200/495], Time: 0.37, lr: [0.008188050105579084], Loss: 2.103482, Acc:0.789652, Semantic loss: 0.788576, BCE loss: 0.548495, SB loss: 0.766411
2023-10-30 04:15:24,602 Epoch: [96/484] Iter:[210/495], Time: 0.37, lr: [0.008187666009660177], Loss: 2.096045, Acc:0.789136, Semantic loss: 0.786951, BCE loss: 0.544310, SB loss: 0.764784
2023-10-30 04:15:28,244 Epoch: [96/484] Iter:[220/495], Time: 0.37, lr: [0.008187281911739201], Loss: 2.094628, Acc:0.790352, Semantic loss: 0.786595, BCE loss: 0.543979, SB loss: 0.764054
2023-10-30 04:15:31,803 Epoch: [96/484] Iter:[230/495], Time: 0.37, lr: [0.008186897811816043], Loss: 2.096738, Acc:0.789950, Semantic loss: 0.791972, BCE loss: 0.540458, SB loss: 0.764308
2023-10-30 04:15:35,545 Epoch: [96/484] Iter:[240/495], Time: 0.37, lr: [0.008186513709890587], Loss: 2.096685, Acc:0.791191, Semantic loss: 0.790731, BCE loss: 0.541370, SB loss: 0.764584
2023-10-30 04:15:39,165 Epoch: [96/484] Iter:[250/495], Time: 0.37, lr: [0.008186129605962716], Loss: 2.096256, Acc:0.792054, Semantic loss: 0.789300, BCE loss: 0.541719, SB loss: 0.765238
2023-10-30 04:15:42,834 Epoch: [96/484] Iter:[260/495], Time: 0.37, lr: [0.008185745500032317], Loss: 2.097761, Acc:0.791809, Semantic loss: 0.788595, BCE loss: 0.541906, SB loss: 0.767260
2023-10-30 04:15:46,457 Epoch: [96/484] Iter:[270/495], Time: 0.37, lr: [0.008185361392099274], Loss: 2.098335, Acc:0.791842, Semantic loss: 0.788857, BCE loss: 0.542836, SB loss: 0.766642
2023-10-30 04:15:50,134 Epoch: [96/484] Iter:[280/495], Time: 0.37, lr: [0.008184977282163474], Loss: 2.095072, Acc:0.791740, Semantic loss: 0.788113, BCE loss: 0.541246, SB loss: 0.765712
2023-10-30 04:15:53,901 Epoch: [96/484] Iter:[290/495], Time: 0.37, lr: [0.008184593170224802], Loss: 2.090321, Acc:0.791295, Semantic loss: 0.786480, BCE loss: 0.538971, SB loss: 0.764870
2023-10-30 04:15:57,530 Epoch: [96/484] Iter:[300/495], Time: 0.37, lr: [0.008184209056283141], Loss: 2.097093, Acc:0.791030, Semantic loss: 0.792258, BCE loss: 0.536865, SB loss: 0.767970
2023-10-30 04:16:01,219 Epoch: [96/484] Iter:[310/495], Time: 0.37, lr: [0.00818382494033838], Loss: 2.097936, Acc:0.790387, Semantic loss: 0.792024, BCE loss: 0.536376, SB loss: 0.769536
2023-10-30 04:16:04,915 Epoch: [96/484] Iter:[320/495], Time: 0.37, lr: [0.008183440822390399], Loss: 2.090956, Acc:0.791119, Semantic loss: 0.788444, BCE loss: 0.534181, SB loss: 0.768332
2023-10-30 04:16:08,536 Epoch: [96/484] Iter:[330/495], Time: 0.37, lr: [0.008183056702439087], Loss: 2.093359, Acc:0.791483, Semantic loss: 0.789305, BCE loss: 0.535613, SB loss: 0.768441
2023-10-30 04:16:12,140 Epoch: [96/484] Iter:[340/495], Time: 0.37, lr: [0.008182672580484327], Loss: 2.091826, Acc:0.791439, Semantic loss: 0.788418, BCE loss: 0.534903, SB loss: 0.768506
2023-10-30 04:16:15,757 Epoch: [96/484] Iter:[350/495], Time: 0.37, lr: [0.008182288456526004], Loss: 2.095700, Acc:0.791467, Semantic loss: 0.791517, BCE loss: 0.535903, SB loss: 0.768280
2023-10-30 04:16:19,477 Epoch: [96/484] Iter:[360/495], Time: 0.37, lr: [0.008181904330564007], Loss: 2.100253, Acc:0.791404, Semantic loss: 0.792093, BCE loss: 0.539288, SB loss: 0.768872
2023-10-30 04:16:23,106 Epoch: [96/484] Iter:[370/495], Time: 0.37, lr: [0.008181520202598215], Loss: 2.105920, Acc:0.793026, Semantic loss: 0.794344, BCE loss: 0.541430, SB loss: 0.770145
2023-10-30 04:16:26,629 Epoch: [96/484] Iter:[380/495], Time: 0.37, lr: [0.008181136072628516], Loss: 2.103515, Acc:0.792426, Semantic loss: 0.792666, BCE loss: 0.541395, SB loss: 0.769454
2023-10-30 04:16:30,294 Epoch: [96/484] Iter:[390/495], Time: 0.37, lr: [0.008180751940654795], Loss: 2.103502, Acc:0.792042, Semantic loss: 0.792553, BCE loss: 0.541483, SB loss: 0.769466
2023-10-30 04:16:33,911 Epoch: [96/484] Iter:[400/495], Time: 0.37, lr: [0.008180367806676938], Loss: 2.104059, Acc:0.792237, Semantic loss: 0.793047, BCE loss: 0.540921, SB loss: 0.770091
2023-10-30 04:16:37,567 Epoch: [96/484] Iter:[410/495], Time: 0.37, lr: [0.008179983670694826], Loss: 2.103433, Acc:0.793464, Semantic loss: 0.792108, BCE loss: 0.541613, SB loss: 0.769712
2023-10-30 04:16:41,246 Epoch: [96/484] Iter:[420/495], Time: 0.37, lr: [0.008179599532708349], Loss: 2.103710, Acc:0.792928, Semantic loss: 0.793666, BCE loss: 0.540664, SB loss: 0.769380
2023-10-30 04:16:44,877 Epoch: [96/484] Iter:[430/495], Time: 0.37, lr: [0.008179215392717388], Loss: 2.102174, Acc:0.792733, Semantic loss: 0.791621, BCE loss: 0.542241, SB loss: 0.768312
2023-10-30 04:16:48,605 Epoch: [96/484] Iter:[440/495], Time: 0.37, lr: [0.008178831250721831], Loss: 2.099684, Acc:0.793064, Semantic loss: 0.790081, BCE loss: 0.542066, SB loss: 0.767537
2023-10-30 04:16:52,321 Epoch: [96/484] Iter:[450/495], Time: 0.37, lr: [0.008178447106721562], Loss: 2.099613, Acc:0.793785, Semantic loss: 0.789107, BCE loss: 0.543254, SB loss: 0.767253
2023-10-30 04:16:55,977 Epoch: [96/484] Iter:[460/495], Time: 0.37, lr: [0.008178062960716465], Loss: 2.099062, Acc:0.794087, Semantic loss: 0.788692, BCE loss: 0.544653, SB loss: 0.765717
2023-10-30 04:16:59,587 Epoch: [96/484] Iter:[470/495], Time: 0.37, lr: [0.008177678812706425], Loss: 2.103774, Acc:0.795207, Semantic loss: 0.791507, BCE loss: 0.545471, SB loss: 0.766796
2023-10-30 04:17:03,291 Epoch: [96/484] Iter:[480/495], Time: 0.37, lr: [0.008177294662691329], Loss: 2.100871, Acc:0.795606, Semantic loss: 0.789545, BCE loss: 0.545922, SB loss: 0.765404
2023-10-30 04:17:06,761 Epoch: [96/484] Iter:[490/495], Time: 0.37, lr: [0.008176910510671057], Loss: 2.099760, Acc:0.795431, Semantic loss: 0.789905, BCE loss: 0.544872, SB loss: 0.764983
2023-10-30 04:17:08,169 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:17:08,413 Loss: 2.056, MeanIU:  0.6907, Best_mIoU:  0.6907
2023-10-30 04:17:08,413 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659]
2023-10-30 04:17:10,744 Epoch: [97/484] Iter:[0/495], Time: 2.30, lr: [0.008176718433908946], Loss: 1.868585, Acc:0.685176, Semantic loss: 0.624945, BCE loss: 0.574890, SB loss: 0.668750
2023-10-30 04:17:14,587 Epoch: [97/484] Iter:[10/495], Time: 0.56, lr: [0.0081763342788807], Loss: 1.866208, Acc:0.797419, Semantic loss: 0.678335, BCE loss: 0.473636, SB loss: 0.714236
2023-10-30 04:17:18,239 Epoch: [97/484] Iter:[20/495], Time: 0.47, lr: [0.008175950121846994], Loss: 1.957720, Acc:0.804759, Semantic loss: 0.724226, BCE loss: 0.498037, SB loss: 0.735457
2023-10-30 04:17:21,936 Epoch: [97/484] Iter:[30/495], Time: 0.44, lr: [0.008175565962807711], Loss: 2.045631, Acc:0.797115, Semantic loss: 0.756962, BCE loss: 0.533288, SB loss: 0.755380
2023-10-30 04:17:25,585 Epoch: [97/484] Iter:[40/495], Time: 0.42, lr: [0.008175181801762738], Loss: 2.013728, Acc:0.802253, Semantic loss: 0.737784, BCE loss: 0.533667, SB loss: 0.742276
2023-10-30 04:17:29,127 Epoch: [97/484] Iter:[50/495], Time: 0.41, lr: [0.008174797638711958], Loss: 2.029698, Acc:0.798922, Semantic loss: 0.738932, BCE loss: 0.544018, SB loss: 0.746747
2023-10-30 04:17:32,746 Epoch: [97/484] Iter:[60/495], Time: 0.40, lr: [0.008174413473655258], Loss: 2.017754, Acc:0.795658, Semantic loss: 0.735313, BCE loss: 0.537926, SB loss: 0.744516
2023-10-30 04:17:36,348 Epoch: [97/484] Iter:[70/495], Time: 0.39, lr: [0.00817402930659252], Loss: 2.043245, Acc:0.798195, Semantic loss: 0.759999, BCE loss: 0.534304, SB loss: 0.748941
2023-10-30 04:17:40,016 Epoch: [97/484] Iter:[80/495], Time: 0.39, lr: [0.008173645137523632], Loss: 2.031962, Acc:0.791455, Semantic loss: 0.762678, BCE loss: 0.521300, SB loss: 0.747984
2023-10-30 04:17:43,712 Epoch: [97/484] Iter:[90/495], Time: 0.39, lr: [0.008173260966448473], Loss: 2.033836, Acc:0.796537, Semantic loss: 0.762940, BCE loss: 0.524324, SB loss: 0.746572
2023-10-30 04:17:47,400 Epoch: [97/484] Iter:[100/495], Time: 0.39, lr: [0.008172876793366934], Loss: 2.034058, Acc:0.799663, Semantic loss: 0.759522, BCE loss: 0.526742, SB loss: 0.747795
2023-10-30 04:17:51,110 Epoch: [97/484] Iter:[110/495], Time: 0.38, lr: [0.008172492618278897], Loss: 2.047264, Acc:0.797290, Semantic loss: 0.764542, BCE loss: 0.533052, SB loss: 0.749670
2023-10-30 04:17:54,837 Epoch: [97/484] Iter:[120/495], Time: 0.38, lr: [0.008172108441184246], Loss: 2.059330, Acc:0.797748, Semantic loss: 0.772827, BCE loss: 0.532084, SB loss: 0.754418
2023-10-30 04:17:58,516 Epoch: [97/484] Iter:[130/495], Time: 0.38, lr: [0.008171724262082868], Loss: 2.060929, Acc:0.797724, Semantic loss: 0.775218, BCE loss: 0.531502, SB loss: 0.754209
2023-10-30 04:18:02,133 Epoch: [97/484] Iter:[140/495], Time: 0.38, lr: [0.008171340080974646], Loss: 2.064116, Acc:0.795561, Semantic loss: 0.778561, BCE loss: 0.532709, SB loss: 0.752847
2023-10-30 04:18:05,857 Epoch: [97/484] Iter:[150/495], Time: 0.38, lr: [0.008170955897859466], Loss: 2.065667, Acc:0.793810, Semantic loss: 0.775527, BCE loss: 0.537433, SB loss: 0.752707
2023-10-30 04:18:09,538 Epoch: [97/484] Iter:[160/495], Time: 0.38, lr: [0.008170571712737211], Loss: 2.066721, Acc:0.794255, Semantic loss: 0.773802, BCE loss: 0.540986, SB loss: 0.751933
2023-10-30 04:18:13,198 Epoch: [97/484] Iter:[170/495], Time: 0.38, lr: [0.008170187525607765], Loss: 2.079625, Acc:0.795522, Semantic loss: 0.780542, BCE loss: 0.542395, SB loss: 0.756689
2023-10-30 04:18:16,893 Epoch: [97/484] Iter:[180/495], Time: 0.38, lr: [0.008169803336471016], Loss: 2.083060, Acc:0.795886, Semantic loss: 0.779975, BCE loss: 0.544309, SB loss: 0.758776
2023-10-30 04:18:20,588 Epoch: [97/484] Iter:[190/495], Time: 0.38, lr: [0.008169419145326847], Loss: 2.083554, Acc:0.795672, Semantic loss: 0.779224, BCE loss: 0.545063, SB loss: 0.759268
2023-10-30 04:18:24,193 Epoch: [97/484] Iter:[200/495], Time: 0.38, lr: [0.00816903495217514], Loss: 2.084969, Acc:0.796623, Semantic loss: 0.780422, BCE loss: 0.544678, SB loss: 0.759869
2023-10-30 04:18:27,898 Epoch: [97/484] Iter:[210/495], Time: 0.38, lr: [0.008168650757015783], Loss: 2.085068, Acc:0.795549, Semantic loss: 0.780006, BCE loss: 0.544025, SB loss: 0.761038
2023-10-30 04:18:31,553 Epoch: [97/484] Iter:[220/495], Time: 0.38, lr: [0.00816826655984866], Loss: 2.093217, Acc:0.792903, Semantic loss: 0.785006, BCE loss: 0.545321, SB loss: 0.762889
2023-10-30 04:18:35,104 Epoch: [97/484] Iter:[230/495], Time: 0.38, lr: [0.008167882360673654], Loss: 2.090463, Acc:0.795737, Semantic loss: 0.782268, BCE loss: 0.546922, SB loss: 0.761274
2023-10-30 04:18:38,715 Epoch: [97/484] Iter:[240/495], Time: 0.37, lr: [0.008167498159490652], Loss: 2.092581, Acc:0.795615, Semantic loss: 0.783934, BCE loss: 0.546291, SB loss: 0.762356
2023-10-30 04:18:42,405 Epoch: [97/484] Iter:[250/495], Time: 0.37, lr: [0.008167113956299536], Loss: 2.094035, Acc:0.794426, Semantic loss: 0.784751, BCE loss: 0.546761, SB loss: 0.762523
2023-10-30 04:18:46,049 Epoch: [97/484] Iter:[260/495], Time: 0.37, lr: [0.008166729751100192], Loss: 2.099610, Acc:0.795032, Semantic loss: 0.785989, BCE loss: 0.550819, SB loss: 0.762801
2023-10-30 04:18:49,870 Epoch: [97/484] Iter:[270/495], Time: 0.37, lr: [0.008166345543892504], Loss: 2.102778, Acc:0.794010, Semantic loss: 0.788166, BCE loss: 0.550585, SB loss: 0.764026
2023-10-30 04:18:53,524 Epoch: [97/484] Iter:[280/495], Time: 0.37, lr: [0.008165961334676357], Loss: 2.105137, Acc:0.794739, Semantic loss: 0.789509, BCE loss: 0.551413, SB loss: 0.764215
2023-10-30 04:18:57,196 Epoch: [97/484] Iter:[290/495], Time: 0.37, lr: [0.008165577123451635], Loss: 2.103219, Acc:0.794219, Semantic loss: 0.788233, BCE loss: 0.551356, SB loss: 0.763629
2023-10-30 04:19:01,030 Epoch: [97/484] Iter:[300/495], Time: 0.37, lr: [0.008165192910218224], Loss: 2.100946, Acc:0.794850, Semantic loss: 0.787363, BCE loss: 0.550980, SB loss: 0.762603
2023-10-30 04:19:04,780 Epoch: [97/484] Iter:[310/495], Time: 0.37, lr: [0.008164808694976006], Loss: 2.102293, Acc:0.794110, Semantic loss: 0.787053, BCE loss: 0.551811, SB loss: 0.763429
2023-10-30 04:19:08,426 Epoch: [97/484] Iter:[320/495], Time: 0.37, lr: [0.008164424477724867], Loss: 2.101727, Acc:0.792895, Semantic loss: 0.787610, BCE loss: 0.550244, SB loss: 0.763873
2023-10-30 04:19:12,079 Epoch: [97/484] Iter:[330/495], Time: 0.37, lr: [0.008164040258464692], Loss: 2.102407, Acc:0.793286, Semantic loss: 0.788150, BCE loss: 0.549282, SB loss: 0.764975
2023-10-30 04:19:15,677 Epoch: [97/484] Iter:[340/495], Time: 0.37, lr: [0.008163656037195363], Loss: 2.104374, Acc:0.794452, Semantic loss: 0.790686, BCE loss: 0.549059, SB loss: 0.764629
2023-10-30 04:19:19,508 Epoch: [97/484] Iter:[350/495], Time: 0.37, lr: [0.008163271813916765], Loss: 2.102732, Acc:0.793455, Semantic loss: 0.790934, BCE loss: 0.547627, SB loss: 0.764171
2023-10-30 04:19:23,272 Epoch: [97/484] Iter:[360/495], Time: 0.37, lr: [0.008162887588628787], Loss: 2.108223, Acc:0.793498, Semantic loss: 0.793218, BCE loss: 0.548786, SB loss: 0.766220
2023-10-30 04:19:26,986 Epoch: [97/484] Iter:[370/495], Time: 0.37, lr: [0.008162503361331307], Loss: 2.112706, Acc:0.793613, Semantic loss: 0.794976, BCE loss: 0.549976, SB loss: 0.767754
2023-10-30 04:19:30,599 Epoch: [97/484] Iter:[380/495], Time: 0.37, lr: [0.008162119132024213], Loss: 2.113773, Acc:0.793212, Semantic loss: 0.795881, BCE loss: 0.549198, SB loss: 0.768694
2023-10-30 04:19:34,337 Epoch: [97/484] Iter:[390/495], Time: 0.37, lr: [0.00816173490070739], Loss: 2.113856, Acc:0.793233, Semantic loss: 0.795499, BCE loss: 0.549260, SB loss: 0.769098
2023-10-30 04:19:38,107 Epoch: [97/484] Iter:[400/495], Time: 0.37, lr: [0.008161350667380718], Loss: 2.111612, Acc:0.793797, Semantic loss: 0.794702, BCE loss: 0.549124, SB loss: 0.767786
2023-10-30 04:19:41,846 Epoch: [97/484] Iter:[410/495], Time: 0.37, lr: [0.008160966432044087], Loss: 2.114148, Acc:0.794190, Semantic loss: 0.794976, BCE loss: 0.551147, SB loss: 0.768026
2023-10-30 04:19:45,487 Epoch: [97/484] Iter:[420/495], Time: 0.37, lr: [0.008160582194697378], Loss: 2.111320, Acc:0.794317, Semantic loss: 0.793627, BCE loss: 0.550859, SB loss: 0.766835
2023-10-30 04:19:49,238 Epoch: [97/484] Iter:[430/495], Time: 0.37, lr: [0.008160197955340474], Loss: 2.113132, Acc:0.793921, Semantic loss: 0.794461, BCE loss: 0.550769, SB loss: 0.767902
2023-10-30 04:19:52,849 Epoch: [97/484] Iter:[440/495], Time: 0.37, lr: [0.008159813713973263], Loss: 2.114886, Acc:0.793237, Semantic loss: 0.796405, BCE loss: 0.550535, SB loss: 0.767945
2023-10-30 04:19:56,464 Epoch: [97/484] Iter:[450/495], Time: 0.37, lr: [0.008159429470595628], Loss: 2.115263, Acc:0.792763, Semantic loss: 0.796582, BCE loss: 0.550718, SB loss: 0.767963
2023-10-30 04:20:00,235 Epoch: [97/484] Iter:[460/495], Time: 0.37, lr: [0.008159045225207452], Loss: 2.112489, Acc:0.792915, Semantic loss: 0.795688, BCE loss: 0.549098, SB loss: 0.767703
2023-10-30 04:20:03,953 Epoch: [97/484] Iter:[470/495], Time: 0.37, lr: [0.00815866097780862], Loss: 2.110211, Acc:0.793405, Semantic loss: 0.794975, BCE loss: 0.547744, SB loss: 0.767492
2023-10-30 04:20:07,573 Epoch: [97/484] Iter:[480/495], Time: 0.37, lr: [0.008158276728399017], Loss: 2.109900, Acc:0.793447, Semantic loss: 0.795435, BCE loss: 0.547067, SB loss: 0.767398
2023-10-30 04:20:11,036 Epoch: [97/484] Iter:[490/495], Time: 0.37, lr: [0.008157892476978526], Loss: 2.108114, Acc:0.794096, Semantic loss: 0.794745, BCE loss: 0.546800, SB loss: 0.766569
2023-10-30 04:20:12,428 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:20:12,665 Loss: 2.056, MeanIU:  0.6907, Best_mIoU:  0.6907
2023-10-30 04:20:12,665 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659]
2023-10-30 04:20:14,728 Epoch: [98/484] Iter:[0/495], Time: 2.03, lr: [0.008157700350514161], Loss: 1.996524, Acc:0.773953, Semantic loss: 0.715653, BCE loss: 0.492747, SB loss: 0.788124
2023-10-30 04:20:18,777 Epoch: [98/484] Iter:[10/495], Time: 0.55, lr: [0.008157316096077123], Loss: 1.996779, Acc:0.810918, Semantic loss: 0.764346, BCE loss: 0.483655, SB loss: 0.748779
2023-10-30 04:20:22,416 Epoch: [98/484] Iter:[20/495], Time: 0.46, lr: [0.008156931839628906], Loss: 2.052632, Acc:0.799295, Semantic loss: 0.788799, BCE loss: 0.511080, SB loss: 0.752753
2023-10-30 04:20:26,118 Epoch: [98/484] Iter:[30/495], Time: 0.43, lr: [0.008156547581169397], Loss: 2.040399, Acc:0.797524, Semantic loss: 0.773868, BCE loss: 0.511700, SB loss: 0.754830
2023-10-30 04:20:29,713 Epoch: [98/484] Iter:[40/495], Time: 0.41, lr: [0.008156163320698483], Loss: 2.067484, Acc:0.796988, Semantic loss: 0.786035, BCE loss: 0.529401, SB loss: 0.752049
2023-10-30 04:20:33,286 Epoch: [98/484] Iter:[50/495], Time: 0.40, lr: [0.008155779058216042], Loss: 2.081366, Acc:0.794276, Semantic loss: 0.793630, BCE loss: 0.533835, SB loss: 0.753901
2023-10-30 04:20:37,009 Epoch: [98/484] Iter:[60/495], Time: 0.40, lr: [0.00815539479372196], Loss: 2.065732, Acc:0.793708, Semantic loss: 0.784849, BCE loss: 0.528754, SB loss: 0.752128
2023-10-30 04:20:40,704 Epoch: [98/484] Iter:[70/495], Time: 0.39, lr: [0.008155010527216122], Loss: 2.065394, Acc:0.795532, Semantic loss: 0.777483, BCE loss: 0.534940, SB loss: 0.752971
2023-10-30 04:20:44,412 Epoch: [98/484] Iter:[80/495], Time: 0.39, lr: [0.008154626258698413], Loss: 2.072734, Acc:0.797517, Semantic loss: 0.779667, BCE loss: 0.539916, SB loss: 0.753151
2023-10-30 04:20:48,007 Epoch: [98/484] Iter:[90/495], Time: 0.39, lr: [0.008154241988168717], Loss: 2.058166, Acc:0.800587, Semantic loss: 0.774137, BCE loss: 0.536658, SB loss: 0.747371
2023-10-30 04:20:51,656 Epoch: [98/484] Iter:[100/495], Time: 0.39, lr: [0.008153857715626916], Loss: 2.085825, Acc:0.798589, Semantic loss: 0.791493, BCE loss: 0.540977, SB loss: 0.753355
2023-10-30 04:20:55,368 Epoch: [98/484] Iter:[110/495], Time: 0.38, lr: [0.008153473441072897], Loss: 2.077802, Acc:0.797541, Semantic loss: 0.789309, BCE loss: 0.538822, SB loss: 0.749671
2023-10-30 04:20:59,002 Epoch: [98/484] Iter:[120/495], Time: 0.38, lr: [0.008153089164506543], Loss: 2.080635, Acc:0.798618, Semantic loss: 0.790629, BCE loss: 0.540607, SB loss: 0.749399
2023-10-30 04:21:02,625 Epoch: [98/484] Iter:[130/495], Time: 0.38, lr: [0.008152704885927736], Loss: 2.077389, Acc:0.797308, Semantic loss: 0.788789, BCE loss: 0.540575, SB loss: 0.748025
2023-10-30 04:21:06,238 Epoch: [98/484] Iter:[140/495], Time: 0.38, lr: [0.008152320605336364], Loss: 2.072141, Acc:0.796474, Semantic loss: 0.784696, BCE loss: 0.540269, SB loss: 0.747177
2023-10-30 04:21:09,900 Epoch: [98/484] Iter:[150/495], Time: 0.38, lr: [0.008151936322732306], Loss: 2.081450, Acc:0.796254, Semantic loss: 0.788914, BCE loss: 0.542483, SB loss: 0.750053
2023-10-30 04:21:13,519 Epoch: [98/484] Iter:[160/495], Time: 0.38, lr: [0.008151552038115451], Loss: 2.068127, Acc:0.796388, Semantic loss: 0.780317, BCE loss: 0.540028, SB loss: 0.747781
2023-10-30 04:21:17,204 Epoch: [98/484] Iter:[170/495], Time: 0.38, lr: [0.00815116775148568], Loss: 2.066345, Acc:0.797847, Semantic loss: 0.775998, BCE loss: 0.541629, SB loss: 0.748719
2023-10-30 04:21:20,861 Epoch: [98/484] Iter:[180/495], Time: 0.38, lr: [0.008150783462842879], Loss: 2.072983, Acc:0.796540, Semantic loss: 0.783218, BCE loss: 0.540940, SB loss: 0.748825
2023-10-30 04:21:24,466 Epoch: [98/484] Iter:[190/495], Time: 0.38, lr: [0.008150399172186929], Loss: 2.082880, Acc:0.798334, Semantic loss: 0.786934, BCE loss: 0.543613, SB loss: 0.752333
2023-10-30 04:21:28,079 Epoch: [98/484] Iter:[200/495], Time: 0.38, lr: [0.008150014879517718], Loss: 2.079266, Acc:0.798107, Semantic loss: 0.785195, BCE loss: 0.542196, SB loss: 0.751875
2023-10-30 04:21:31,789 Epoch: [98/484] Iter:[210/495], Time: 0.37, lr: [0.008149630584835126], Loss: 2.078755, Acc:0.796715, Semantic loss: 0.784434, BCE loss: 0.541771, SB loss: 0.752550
2023-10-30 04:21:35,427 Epoch: [98/484] Iter:[220/495], Time: 0.37, lr: [0.00814924628813904], Loss: 2.077565, Acc:0.797144, Semantic loss: 0.781906, BCE loss: 0.543482, SB loss: 0.752177
2023-10-30 04:21:39,142 Epoch: [98/484] Iter:[230/495], Time: 0.37, lr: [0.00814886198942934], Loss: 2.075363, Acc:0.797314, Semantic loss: 0.779927, BCE loss: 0.544046, SB loss: 0.751390
2023-10-30 04:21:42,755 Epoch: [98/484] Iter:[240/495], Time: 0.37, lr: [0.008148477688705918], Loss: 2.075427, Acc:0.798227, Semantic loss: 0.778878, BCE loss: 0.545450, SB loss: 0.751100
2023-10-30 04:21:46,526 Epoch: [98/484] Iter:[250/495], Time: 0.37, lr: [0.008148093385968648], Loss: 2.075563, Acc:0.797609, Semantic loss: 0.779689, BCE loss: 0.544027, SB loss: 0.751847
2023-10-30 04:21:50,436 Epoch: [98/484] Iter:[260/495], Time: 0.37, lr: [0.008147709081217421], Loss: 2.076208, Acc:0.798558, Semantic loss: 0.778907, BCE loss: 0.545108, SB loss: 0.752194
2023-10-30 04:21:54,172 Epoch: [98/484] Iter:[270/495], Time: 0.37, lr: [0.008147324774452118], Loss: 2.076678, Acc:0.798947, Semantic loss: 0.779234, BCE loss: 0.545001, SB loss: 0.752444
2023-10-30 04:21:57,933 Epoch: [98/484] Iter:[280/495], Time: 0.37, lr: [0.008146940465672624], Loss: 2.083046, Acc:0.798406, Semantic loss: 0.780949, BCE loss: 0.547065, SB loss: 0.755032
2023-10-30 04:22:01,614 Epoch: [98/484] Iter:[290/495], Time: 0.37, lr: [0.00814655615487882], Loss: 2.083976, Acc:0.798124, Semantic loss: 0.782480, BCE loss: 0.546316, SB loss: 0.755180
2023-10-30 04:22:05,293 Epoch: [98/484] Iter:[300/495], Time: 0.37, lr: [0.008146171842070593], Loss: 2.090994, Acc:0.796741, Semantic loss: 0.786661, BCE loss: 0.546124, SB loss: 0.758208
2023-10-30 04:22:08,947 Epoch: [98/484] Iter:[310/495], Time: 0.37, lr: [0.008145787527247825], Loss: 2.091215, Acc:0.795632, Semantic loss: 0.784768, BCE loss: 0.546365, SB loss: 0.760082
2023-10-30 04:22:12,630 Epoch: [98/484] Iter:[320/495], Time: 0.37, lr: [0.008145403210410403], Loss: 2.096898, Acc:0.796060, Semantic loss: 0.788567, BCE loss: 0.547110, SB loss: 0.761222
2023-10-30 04:22:16,342 Epoch: [98/484] Iter:[330/495], Time: 0.37, lr: [0.008145018891558206], Loss: 2.098401, Acc:0.796901, Semantic loss: 0.789649, BCE loss: 0.546413, SB loss: 0.762340
2023-10-30 04:22:20,084 Epoch: [98/484] Iter:[340/495], Time: 0.37, lr: [0.008144634570691122], Loss: 2.100020, Acc:0.796409, Semantic loss: 0.788750, BCE loss: 0.547108, SB loss: 0.764162
2023-10-30 04:22:23,822 Epoch: [98/484] Iter:[350/495], Time: 0.37, lr: [0.008144250247809034], Loss: 2.104431, Acc:0.795503, Semantic loss: 0.791366, BCE loss: 0.547744, SB loss: 0.765321
2023-10-30 04:22:27,430 Epoch: [98/484] Iter:[360/495], Time: 0.37, lr: [0.008143865922911823], Loss: 2.109842, Acc:0.794300, Semantic loss: 0.795252, BCE loss: 0.547955, SB loss: 0.766636
2023-10-30 04:22:31,037 Epoch: [98/484] Iter:[370/495], Time: 0.37, lr: [0.008143481595999378], Loss: 2.109847, Acc:0.793730, Semantic loss: 0.796201, BCE loss: 0.547156, SB loss: 0.766490
2023-10-30 04:22:34,720 Epoch: [98/484] Iter:[380/495], Time: 0.37, lr: [0.008143097267071575], Loss: 2.107244, Acc:0.793956, Semantic loss: 0.794269, BCE loss: 0.546825, SB loss: 0.766151
2023-10-30 04:22:38,462 Epoch: [98/484] Iter:[390/495], Time: 0.37, lr: [0.008142712936128305], Loss: 2.106256, Acc:0.795172, Semantic loss: 0.793352, BCE loss: 0.546663, SB loss: 0.766242
2023-10-30 04:22:42,144 Epoch: [98/484] Iter:[400/495], Time: 0.37, lr: [0.008142328603169447], Loss: 2.104238, Acc:0.794996, Semantic loss: 0.792730, BCE loss: 0.545203, SB loss: 0.766304
2023-10-30 04:22:45,836 Epoch: [98/484] Iter:[410/495], Time: 0.37, lr: [0.008141944268194888], Loss: 2.106773, Acc:0.793908, Semantic loss: 0.793950, BCE loss: 0.546130, SB loss: 0.766692
2023-10-30 04:22:49,393 Epoch: [98/484] Iter:[420/495], Time: 0.37, lr: [0.00814155993120451], Loss: 2.106263, Acc:0.793374, Semantic loss: 0.794481, BCE loss: 0.545083, SB loss: 0.766700
2023-10-30 04:22:53,142 Epoch: [98/484] Iter:[430/495], Time: 0.37, lr: [0.008141175592198197], Loss: 2.106722, Acc:0.792874, Semantic loss: 0.793975, BCE loss: 0.546129, SB loss: 0.766618
2023-10-30 04:22:56,824 Epoch: [98/484] Iter:[440/495], Time: 0.37, lr: [0.008140791251175835], Loss: 2.104592, Acc:0.792787, Semantic loss: 0.792358, BCE loss: 0.545666, SB loss: 0.766569
2023-10-30 04:23:00,465 Epoch: [98/484] Iter:[450/495], Time: 0.37, lr: [0.008140406908137303], Loss: 2.102439, Acc:0.793239, Semantic loss: 0.791115, BCE loss: 0.545576, SB loss: 0.765748
2023-10-30 04:23:04,125 Epoch: [98/484] Iter:[460/495], Time: 0.37, lr: [0.008140022563082487], Loss: 2.104028, Acc:0.793298, Semantic loss: 0.792958, BCE loss: 0.544917, SB loss: 0.766152
2023-10-30 04:23:07,774 Epoch: [98/484] Iter:[470/495], Time: 0.37, lr: [0.00813963821601127], Loss: 2.105371, Acc:0.792655, Semantic loss: 0.793286, BCE loss: 0.545259, SB loss: 0.766825
2023-10-30 04:23:11,464 Epoch: [98/484] Iter:[480/495], Time: 0.37, lr: [0.008139253866923539], Loss: 2.104973, Acc:0.792481, Semantic loss: 0.792584, BCE loss: 0.546060, SB loss: 0.766329
2023-10-30 04:23:14,925 Epoch: [98/484] Iter:[490/495], Time: 0.37, lr: [0.008138869515819172], Loss: 2.111014, Acc:0.792166, Semantic loss: 0.796605, BCE loss: 0.546371, SB loss: 0.768037
2023-10-30 04:23:16,317 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:23:16,553 Loss: 2.056, MeanIU:  0.6907, Best_mIoU:  0.6907
2023-10-30 04:23:16,553 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659]
2023-10-30 04:23:18,763 Epoch: [99/484] Iter:[0/495], Time: 2.18, lr: [0.008138677339510715], Loss: 1.894565, Acc:0.735401, Semantic loss: 0.704851, BCE loss: 0.434261, SB loss: 0.755452
2023-10-30 04:23:22,701 Epoch: [99/484] Iter:[10/495], Time: 0.56, lr: [0.008138292985381181], Loss: 2.040433, Acc:0.793507, Semantic loss: 0.727566, BCE loss: 0.573977, SB loss: 0.738889
2023-10-30 04:23:26,512 Epoch: [99/484] Iter:[20/495], Time: 0.47, lr: [0.008137908629234724], Loss: 2.126826, Acc:0.792836, Semantic loss: 0.789492, BCE loss: 0.564438, SB loss: 0.772897
2023-10-30 04:23:30,210 Epoch: [99/484] Iter:[30/495], Time: 0.44, lr: [0.008137524271071226], Loss: 2.125728, Acc:0.794555, Semantic loss: 0.794657, BCE loss: 0.564749, SB loss: 0.766322
2023-10-30 04:23:33,867 Epoch: [99/484] Iter:[40/495], Time: 0.42, lr: [0.008137139910890571], Loss: 2.081569, Acc:0.786677, Semantic loss: 0.775468, BCE loss: 0.552805, SB loss: 0.753296
2023-10-30 04:23:37,666 Epoch: [99/484] Iter:[50/495], Time: 0.41, lr: [0.008136755548692642], Loss: 2.111191, Acc:0.794901, Semantic loss: 0.788646, BCE loss: 0.560513, SB loss: 0.762032
2023-10-30 04:23:41,364 Epoch: [99/484] Iter:[60/495], Time: 0.41, lr: [0.008136371184477324], Loss: 2.106163, Acc:0.794418, Semantic loss: 0.781893, BCE loss: 0.566179, SB loss: 0.758090
2023-10-30 04:23:44,968 Epoch: [99/484] Iter:[70/495], Time: 0.40, lr: [0.008135986818244498], Loss: 2.093427, Acc:0.791368, Semantic loss: 0.778402, BCE loss: 0.557189, SB loss: 0.757837
2023-10-30 04:23:48,733 Epoch: [99/484] Iter:[80/495], Time: 0.40, lr: [0.008135602449994051], Loss: 2.096457, Acc:0.794678, Semantic loss: 0.782151, BCE loss: 0.558587, SB loss: 0.755720
2023-10-30 04:23:52,339 Epoch: [99/484] Iter:[90/495], Time: 0.39, lr: [0.008135218079725864], Loss: 2.089510, Acc:0.799362, Semantic loss: 0.780899, BCE loss: 0.552934, SB loss: 0.755677
2023-10-30 04:23:55,986 Epoch: [99/484] Iter:[100/495], Time: 0.39, lr: [0.008134833707439823], Loss: 2.078627, Acc:0.795553, Semantic loss: 0.775557, BCE loss: 0.547013, SB loss: 0.756056
2023-10-30 04:23:59,596 Epoch: [99/484] Iter:[110/495], Time: 0.39, lr: [0.008134449333135807], Loss: 2.090889, Acc:0.796548, Semantic loss: 0.781921, BCE loss: 0.551055, SB loss: 0.757913
2023-10-30 04:24:03,389 Epoch: [99/484] Iter:[120/495], Time: 0.39, lr: [0.008134064956813703], Loss: 2.091632, Acc:0.792735, Semantic loss: 0.782974, BCE loss: 0.550104, SB loss: 0.758555
2023-10-30 04:24:06,922 Epoch: [99/484] Iter:[130/495], Time: 0.38, lr: [0.008133680578473393], Loss: 2.087383, Acc:0.791790, Semantic loss: 0.780165, BCE loss: 0.547915, SB loss: 0.759303
2023-10-30 04:24:10,551 Epoch: [99/484] Iter:[140/495], Time: 0.38, lr: [0.00813329619811476], Loss: 2.092089, Acc:0.787411, Semantic loss: 0.785272, BCE loss: 0.543390, SB loss: 0.763427
2023-10-30 04:24:14,236 Epoch: [99/484] Iter:[150/495], Time: 0.38, lr: [0.00813291181573769], Loss: 2.093965, Acc:0.785837, Semantic loss: 0.784347, BCE loss: 0.545315, SB loss: 0.764304
2023-10-30 04:24:17,858 Epoch: [99/484] Iter:[160/495], Time: 0.38, lr: [0.008132527431342065], Loss: 2.090597, Acc:0.785775, Semantic loss: 0.784991, BCE loss: 0.541904, SB loss: 0.763703
2023-10-30 04:24:21,498 Epoch: [99/484] Iter:[170/495], Time: 0.38, lr: [0.008132143044927766], Loss: 2.090467, Acc:0.785629, Semantic loss: 0.784672, BCE loss: 0.541141, SB loss: 0.764655
2023-10-30 04:24:25,126 Epoch: [99/484] Iter:[180/495], Time: 0.38, lr: [0.008131758656494681], Loss: 2.080995, Acc:0.787551, Semantic loss: 0.780191, BCE loss: 0.539486, SB loss: 0.761318
2023-10-30 04:24:28,862 Epoch: [99/484] Iter:[190/495], Time: 0.38, lr: [0.00813137426604269], Loss: 2.078843, Acc:0.787885, Semantic loss: 0.780280, BCE loss: 0.537472, SB loss: 0.761091
2023-10-30 04:24:32,447 Epoch: [99/484] Iter:[200/495], Time: 0.38, lr: [0.008130989873571677], Loss: 2.077702, Acc:0.789859, Semantic loss: 0.780132, BCE loss: 0.535634, SB loss: 0.761935
2023-10-30 04:24:36,140 Epoch: [99/484] Iter:[210/495], Time: 0.38, lr: [0.008130605479081525], Loss: 2.076407, Acc:0.789842, Semantic loss: 0.780096, BCE loss: 0.535306, SB loss: 0.761005
2023-10-30 04:24:39,707 Epoch: [99/484] Iter:[220/495], Time: 0.38, lr: [0.00813022108257212], Loss: 2.073271, Acc:0.790757, Semantic loss: 0.778774, BCE loss: 0.534699, SB loss: 0.759799
2023-10-30 04:24:43,305 Epoch: [99/484] Iter:[230/495], Time: 0.38, lr: [0.00812983668404334], Loss: 2.075149, Acc:0.790222, Semantic loss: 0.779676, BCE loss: 0.534833, SB loss: 0.760640
2023-10-30 04:24:47,005 Epoch: [99/484] Iter:[240/495], Time: 0.38, lr: [0.008129452283495073], Loss: 2.071964, Acc:0.791205, Semantic loss: 0.775946, BCE loss: 0.535795, SB loss: 0.760223
2023-10-30 04:24:50,674 Epoch: [99/484] Iter:[250/495], Time: 0.37, lr: [0.008129067880927201], Loss: 2.074735, Acc:0.792093, Semantic loss: 0.776135, BCE loss: 0.537639, SB loss: 0.760960
2023-10-30 04:24:54,495 Epoch: [99/484] Iter:[260/495], Time: 0.38, lr: [0.008128683476339608], Loss: 2.074898, Acc:0.791818, Semantic loss: 0.777449, BCE loss: 0.536810, SB loss: 0.760638
2023-10-30 04:24:58,209 Epoch: [99/484] Iter:[270/495], Time: 0.37, lr: [0.008128299069732175], Loss: 2.072953, Acc:0.792968, Semantic loss: 0.777139, BCE loss: 0.536138, SB loss: 0.759676
2023-10-30 04:25:01,811 Epoch: [99/484] Iter:[280/495], Time: 0.37, lr: [0.008127914661104785], Loss: 2.073470, Acc:0.792360, Semantic loss: 0.777162, BCE loss: 0.537395, SB loss: 0.758913
2023-10-30 04:25:05,450 Epoch: [99/484] Iter:[290/495], Time: 0.37, lr: [0.008127530250457326], Loss: 2.071560, Acc:0.791629, Semantic loss: 0.776577, BCE loss: 0.535899, SB loss: 0.759084
2023-10-30 04:25:09,196 Epoch: [99/484] Iter:[300/495], Time: 0.37, lr: [0.008127145837789677], Loss: 2.067685, Acc:0.791426, Semantic loss: 0.774838, BCE loss: 0.534679, SB loss: 0.758168
2023-10-30 04:25:12,922 Epoch: [99/484] Iter:[310/495], Time: 0.37, lr: [0.008126761423101722], Loss: 2.072168, Acc:0.792344, Semantic loss: 0.776600, BCE loss: 0.536170, SB loss: 0.759398
2023-10-30 04:25:16,569 Epoch: [99/484] Iter:[320/495], Time: 0.37, lr: [0.008126377006393345], Loss: 2.077341, Acc:0.793381, Semantic loss: 0.779587, BCE loss: 0.538127, SB loss: 0.759628
2023-10-30 04:25:20,225 Epoch: [99/484] Iter:[330/495], Time: 0.37, lr: [0.008125992587664426], Loss: 2.079716, Acc:0.793160, Semantic loss: 0.782012, BCE loss: 0.538255, SB loss: 0.759449
2023-10-30 04:25:23,852 Epoch: [99/484] Iter:[340/495], Time: 0.37, lr: [0.008125608166914855], Loss: 2.080161, Acc:0.791651, Semantic loss: 0.781477, BCE loss: 0.539531, SB loss: 0.759153
2023-10-30 04:25:27,748 Epoch: [99/484] Iter:[350/495], Time: 0.37, lr: [0.008125223744144509], Loss: 2.084085, Acc:0.791047, Semantic loss: 0.782922, BCE loss: 0.541573, SB loss: 0.759590
2023-10-30 04:25:31,422 Epoch: [99/484] Iter:[360/495], Time: 0.37, lr: [0.008124839319353271], Loss: 2.084432, Acc:0.792112, Semantic loss: 0.782104, BCE loss: 0.542116, SB loss: 0.760212
2023-10-30 04:25:35,078 Epoch: [99/484] Iter:[370/495], Time: 0.37, lr: [0.008124454892541029], Loss: 2.082551, Acc:0.791475, Semantic loss: 0.781153, BCE loss: 0.541949, SB loss: 0.759448
2023-10-30 04:25:38,796 Epoch: [99/484] Iter:[380/495], Time: 0.37, lr: [0.008124070463707663], Loss: 2.087610, Acc:0.791903, Semantic loss: 0.782630, BCE loss: 0.544693, SB loss: 0.760288
2023-10-30 04:25:42,508 Epoch: [99/484] Iter:[390/495], Time: 0.37, lr: [0.008123686032853055], Loss: 2.089170, Acc:0.791335, Semantic loss: 0.782816, BCE loss: 0.546016, SB loss: 0.760337
2023-10-30 04:25:46,191 Epoch: [99/484] Iter:[400/495], Time: 0.37, lr: [0.00812330159997709], Loss: 2.090226, Acc:0.790945, Semantic loss: 0.783604, BCE loss: 0.545881, SB loss: 0.760741
2023-10-30 04:25:49,879 Epoch: [99/484] Iter:[410/495], Time: 0.37, lr: [0.008122917165079652], Loss: 2.091580, Acc:0.790444, Semantic loss: 0.784061, BCE loss: 0.545682, SB loss: 0.761837
2023-10-30 04:25:53,659 Epoch: [99/484] Iter:[420/495], Time: 0.37, lr: [0.008122532728160622], Loss: 2.090987, Acc:0.790938, Semantic loss: 0.783740, BCE loss: 0.545635, SB loss: 0.761613
2023-10-30 04:25:57,305 Epoch: [99/484] Iter:[430/495], Time: 0.37, lr: [0.008122148289219883], Loss: 2.091642, Acc:0.790583, Semantic loss: 0.784119, BCE loss: 0.546240, SB loss: 0.761284
2023-10-30 04:26:00,953 Epoch: [99/484] Iter:[440/495], Time: 0.37, lr: [0.00812176384825732], Loss: 2.091055, Acc:0.790454, Semantic loss: 0.784148, BCE loss: 0.545259, SB loss: 0.761647
2023-10-30 04:26:04,630 Epoch: [99/484] Iter:[450/495], Time: 0.37, lr: [0.008121379405272813], Loss: 2.091555, Acc:0.791100, Semantic loss: 0.784927, BCE loss: 0.545219, SB loss: 0.761409
2023-10-30 04:26:08,374 Epoch: [99/484] Iter:[460/495], Time: 0.37, lr: [0.00812099496026625], Loss: 2.092624, Acc:0.790108, Semantic loss: 0.786240, BCE loss: 0.544948, SB loss: 0.761436
2023-10-30 04:26:12,093 Epoch: [99/484] Iter:[470/495], Time: 0.37, lr: [0.008120610513237507], Loss: 2.096352, Acc:0.791044, Semantic loss: 0.787405, BCE loss: 0.546276, SB loss: 0.762670
2023-10-30 04:26:15,849 Epoch: [99/484] Iter:[480/495], Time: 0.37, lr: [0.008120226064186473], Loss: 2.093853, Acc:0.790875, Semantic loss: 0.786169, BCE loss: 0.545149, SB loss: 0.762535
2023-10-30 04:26:19,374 Epoch: [99/484] Iter:[490/495], Time: 0.37, lr: [0.00811984161311303], Loss: 2.094270, Acc:0.791184, Semantic loss: 0.785817, BCE loss: 0.545872, SB loss: 0.762581
2023-10-30 04:26:20,768 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:26:21,007 Loss: 2.056, MeanIU:  0.6907, Best_mIoU:  0.6907
2023-10-30 04:26:21,007 [0.97385217 0.79449259 0.90458085 0.43882424 0.51302218 0.54516287
 0.62761716 0.72113099 0.90577697 0.58220108 0.93245706 0.73681971
 0.49966031 0.91753128 0.50462624 0.68672133 0.66438928 0.4680753
 0.70590659]
2023-10-30 04:26:23,144 Epoch: [100/484] Iter:[0/495], Time: 2.10, lr: [0.008119649386817867], Loss: 2.036101, Acc:0.807159, Semantic loss: 0.747048, BCE loss: 0.587002, SB loss: 0.702051
2023-10-30 04:26:27,117 Epoch: [100/484] Iter:[10/495], Time: 0.55, lr: [0.008119264932710587], Loss: 2.115571, Acc:0.786304, Semantic loss: 0.786835, BCE loss: 0.540271, SB loss: 0.788465
2023-10-30 04:26:30,798 Epoch: [100/484] Iter:[20/495], Time: 0.46, lr: [0.008118880476580605], Loss: 2.196493, Acc:0.787747, Semantic loss: 0.856468, BCE loss: 0.571351, SB loss: 0.768674
2023-10-30 04:26:34,452 Epoch: [100/484] Iter:[30/495], Time: 0.43, lr: [0.008118496018427804], Loss: 2.181517, Acc:0.779464, Semantic loss: 0.849891, BCE loss: 0.571078, SB loss: 0.760548
2023-10-30 04:26:38,159 Epoch: [100/484] Iter:[40/495], Time: 0.42, lr: [0.008118111558252065], Loss: 2.155738, Acc:0.785471, Semantic loss: 0.827596, BCE loss: 0.571591, SB loss: 0.756551
2023-10-30 04:26:41,781 Epoch: [100/484] Iter:[50/495], Time: 0.41, lr: [0.008117727096053271], Loss: 2.170098, Acc:0.783738, Semantic loss: 0.839154, BCE loss: 0.566756, SB loss: 0.764187
2023-10-30 04:26:45,484 Epoch: [100/484] Iter:[60/495], Time: 0.40, lr: [0.008117342631831307], Loss: 2.147449, Acc:0.785916, Semantic loss: 0.826559, BCE loss: 0.557936, SB loss: 0.762955
2023-10-30 04:26:49,285 Epoch: [100/484] Iter:[70/495], Time: 0.40, lr: [0.008116958165586056], Loss: 2.129997, Acc:0.787068, Semantic loss: 0.815336, BCE loss: 0.553215, SB loss: 0.761446
2023-10-30 04:26:53,022 Epoch: [100/484] Iter:[80/495], Time: 0.39, lr: [0.008116573697317398], Loss: 2.128468, Acc:0.790561, Semantic loss: 0.807996, BCE loss: 0.558515, SB loss: 0.761958
2023-10-30 04:26:56,670 Epoch: [100/484] Iter:[90/495], Time: 0.39, lr: [0.00811618922702522], Loss: 2.131809, Acc:0.794883, Semantic loss: 0.802833, BCE loss: 0.568930, SB loss: 0.760045
2023-10-30 04:27:00,393 Epoch: [100/484] Iter:[100/495], Time: 0.39, lr: [0.008115804754709398], Loss: 2.123425, Acc:0.793541, Semantic loss: 0.801889, BCE loss: 0.562926, SB loss: 0.758610
2023-10-30 04:27:04,100 Epoch: [100/484] Iter:[110/495], Time: 0.39, lr: [0.008115420280369821], Loss: 2.127753, Acc:0.793588, Semantic loss: 0.803617, BCE loss: 0.562848, SB loss: 0.761289
2023-10-30 04:27:07,918 Epoch: [100/484] Iter:[120/495], Time: 0.39, lr: [0.008115035804006372], Loss: 2.118691, Acc:0.795523, Semantic loss: 0.797961, BCE loss: 0.562136, SB loss: 0.758594
2023-10-30 04:27:11,618 Epoch: [100/484] Iter:[130/495], Time: 0.39, lr: [0.00811465132561893], Loss: 2.114636, Acc:0.793245, Semantic loss: 0.796063, BCE loss: 0.559886, SB loss: 0.758687
2023-10-30 04:27:15,306 Epoch: [100/484] Iter:[140/495], Time: 0.38, lr: [0.008114266845207378], Loss: 2.098185, Acc:0.793418, Semantic loss: 0.788211, BCE loss: 0.553813, SB loss: 0.756161
2023-10-30 04:27:18,899 Epoch: [100/484] Iter:[150/495], Time: 0.38, lr: [0.008113882362771604], Loss: 2.095185, Acc:0.791249, Semantic loss: 0.789089, BCE loss: 0.549367, SB loss: 0.756729
2023-10-30 04:27:22,623 Epoch: [100/484] Iter:[160/495], Time: 0.38, lr: [0.008113497878311485], Loss: 2.094565, Acc:0.791349, Semantic loss: 0.787210, BCE loss: 0.549931, SB loss: 0.757424
2023-10-30 04:27:26,403 Epoch: [100/484] Iter:[170/495], Time: 0.38, lr: [0.008113113391826906], Loss: 2.089844, Acc:0.791902, Semantic loss: 0.784588, BCE loss: 0.548026, SB loss: 0.757230
2023-10-30 04:27:30,140 Epoch: [100/484] Iter:[180/495], Time: 0.38, lr: [0.008112728903317748], Loss: 2.089978, Acc:0.794618, Semantic loss: 0.787709, BCE loss: 0.544539, SB loss: 0.757730
2023-10-30 04:27:33,858 Epoch: [100/484] Iter:[190/495], Time: 0.38, lr: [0.008112344412783898], Loss: 2.086382, Acc:0.794846, Semantic loss: 0.784726, BCE loss: 0.544421, SB loss: 0.757235
2023-10-30 04:27:37,579 Epoch: [100/484] Iter:[200/495], Time: 0.38, lr: [0.008111959920225235], Loss: 2.087292, Acc:0.794944, Semantic loss: 0.785298, BCE loss: 0.545384, SB loss: 0.756610
2023-10-30 04:27:41,245 Epoch: [100/484] Iter:[210/495], Time: 0.38, lr: [0.008111575425641641], Loss: 2.092164, Acc:0.795136, Semantic loss: 0.788428, BCE loss: 0.546535, SB loss: 0.757201
2023-10-30 04:27:44,942 Epoch: [100/484] Iter:[220/495], Time: 0.38, lr: [0.008111190929033004], Loss: 2.086700, Acc:0.794387, Semantic loss: 0.786668, BCE loss: 0.544355, SB loss: 0.755677
2023-10-30 04:27:48,628 Epoch: [100/484] Iter:[230/495], Time: 0.38, lr: [0.0081108064303992], Loss: 2.089787, Acc:0.793592, Semantic loss: 0.789622, BCE loss: 0.542834, SB loss: 0.757331
2023-10-30 04:27:52,292 Epoch: [100/484] Iter:[240/495], Time: 0.38, lr: [0.008110421929740116], Loss: 2.090825, Acc:0.795247, Semantic loss: 0.790964, BCE loss: 0.543148, SB loss: 0.756713
2023-10-30 04:27:55,938 Epoch: [100/484] Iter:[250/495], Time: 0.38, lr: [0.008110037427055634], Loss: 2.092725, Acc:0.794452, Semantic loss: 0.791246, BCE loss: 0.543750, SB loss: 0.757729
2023-10-30 04:27:59,549 Epoch: [100/484] Iter:[260/495], Time: 0.38, lr: [0.008109652922345634], Loss: 2.092093, Acc:0.795448, Semantic loss: 0.791414, BCE loss: 0.543666, SB loss: 0.757013
2023-10-30 04:28:03,155 Epoch: [100/484] Iter:[270/495], Time: 0.38, lr: [0.008109268415610002], Loss: 2.096182, Acc:0.795754, Semantic loss: 0.792746, BCE loss: 0.546421, SB loss: 0.757015
2023-10-30 04:28:06,780 Epoch: [100/484] Iter:[280/495], Time: 0.38, lr: [0.00810888390684862], Loss: 2.095911, Acc:0.794981, Semantic loss: 0.793526, BCE loss: 0.544219, SB loss: 0.758166
2023-10-30 04:28:10,448 Epoch: [100/484] Iter:[290/495], Time: 0.38, lr: [0.008108499396061368], Loss: 2.087482, Acc:0.795940, Semantic loss: 0.787318, BCE loss: 0.543371, SB loss: 0.756793
2023-10-30 04:28:14,085 Epoch: [100/484] Iter:[300/495], Time: 0.38, lr: [0.008108114883248132], Loss: 2.086380, Acc:0.796298, Semantic loss: 0.786115, BCE loss: 0.543296, SB loss: 0.756970
2023-10-30 04:28:17,820 Epoch: [100/484] Iter:[310/495], Time: 0.38, lr: [0.008107730368408792], Loss: 2.091191, Acc:0.797046, Semantic loss: 0.787045, BCE loss: 0.545849, SB loss: 0.758297
2023-10-30 04:28:21,458 Epoch: [100/484] Iter:[320/495], Time: 0.38, lr: [0.008107345851543234], Loss: 2.092779, Acc:0.797309, Semantic loss: 0.786237, BCE loss: 0.547467, SB loss: 0.759075
2023-10-30 04:28:25,122 Epoch: [100/484] Iter:[330/495], Time: 0.37, lr: [0.008106961332651335], Loss: 2.089282, Acc:0.796551, Semantic loss: 0.785271, BCE loss: 0.545653, SB loss: 0.758358
2023-10-30 04:28:28,776 Epoch: [100/484] Iter:[340/495], Time: 0.37, lr: [0.00810657681173298], Loss: 2.087276, Acc:0.797134, Semantic loss: 0.783919, BCE loss: 0.545486, SB loss: 0.757871
2023-10-30 04:28:32,383 Epoch: [100/484] Iter:[350/495], Time: 0.37, lr: [0.008106192288788056], Loss: 2.087389, Acc:0.798348, Semantic loss: 0.783628, BCE loss: 0.546846, SB loss: 0.756914
2023-10-30 04:28:36,053 Epoch: [100/484] Iter:[360/495], Time: 0.37, lr: [0.00810580776381644], Loss: 2.089784, Acc:0.798592, Semantic loss: 0.784604, BCE loss: 0.547259, SB loss: 0.757922
2023-10-30 04:28:39,712 Epoch: [100/484] Iter:[370/495], Time: 0.37, lr: [0.008105423236818015], Loss: 2.087329, Acc:0.797399, Semantic loss: 0.782881, BCE loss: 0.546988, SB loss: 0.757459
2023-10-30 04:28:43,480 Epoch: [100/484] Iter:[380/495], Time: 0.37, lr: [0.008105038707792665], Loss: 2.091930, Acc:0.796314, Semantic loss: 0.785895, BCE loss: 0.546949, SB loss: 0.759085
2023-10-30 04:28:47,089 Epoch: [100/484] Iter:[390/495], Time: 0.37, lr: [0.008104654176740273], Loss: 2.092796, Acc:0.797202, Semantic loss: 0.786852, BCE loss: 0.546302, SB loss: 0.759642
2023-10-30 04:28:50,758 Epoch: [100/484] Iter:[400/495], Time: 0.37, lr: [0.00810426964366072], Loss: 2.093090, Acc:0.797235, Semantic loss: 0.787165, BCE loss: 0.546108, SB loss: 0.759817
2023-10-30 04:28:54,568 Epoch: [100/484] Iter:[410/495], Time: 0.37, lr: [0.00810388510855389], Loss: 2.091050, Acc:0.796870, Semantic loss: 0.786451, BCE loss: 0.545493, SB loss: 0.759106
2023-10-30 04:28:58,196 Epoch: [100/484] Iter:[420/495], Time: 0.37, lr: [0.008103500571419661], Loss: 2.089741, Acc:0.796682, Semantic loss: 0.785994, BCE loss: 0.544501, SB loss: 0.759247
2023-10-30 04:29:01,948 Epoch: [100/484] Iter:[430/495], Time: 0.37, lr: [0.008103116032257923], Loss: 2.092220, Acc:0.796857, Semantic loss: 0.787680, BCE loss: 0.544896, SB loss: 0.759645
2023-10-30 04:29:05,684 Epoch: [100/484] Iter:[440/495], Time: 0.37, lr: [0.00810273149106855], Loss: 2.092888, Acc:0.797643, Semantic loss: 0.787047, BCE loss: 0.545973, SB loss: 0.759868
2023-10-30 04:29:09,368 Epoch: [100/484] Iter:[450/495], Time: 0.37, lr: [0.008102346947851433], Loss: 2.091749, Acc:0.797998, Semantic loss: 0.786586, BCE loss: 0.546126, SB loss: 0.759037
2023-10-30 04:29:13,041 Epoch: [100/484] Iter:[460/495], Time: 0.37, lr: [0.008101962402606447], Loss: 2.089429, Acc:0.797717, Semantic loss: 0.785895, BCE loss: 0.544819, SB loss: 0.758715
2023-10-30 04:29:16,864 Epoch: [100/484] Iter:[470/495], Time: 0.37, lr: [0.008101577855333478], Loss: 2.093729, Acc:0.797904, Semantic loss: 0.788662, BCE loss: 0.544865, SB loss: 0.760202
2023-10-30 04:29:20,562 Epoch: [100/484] Iter:[480/495], Time: 0.37, lr: [0.008101193306032409], Loss: 2.092084, Acc:0.797813, Semantic loss: 0.787624, BCE loss: 0.544588, SB loss: 0.759872
2023-10-30 04:29:24,092 Epoch: [100/484] Iter:[490/495], Time: 0.37, lr: [0.008100808754703119], Loss: 2.090029, Acc:0.798276, Semantic loss: 0.785617, BCE loss: 0.544577, SB loss: 0.759835
2023-10-30 04:32:20,747 0 [0.93848715 0.64649066 0.82357067 0.11106353 0.22412197 0.40752675
 0.38725006 0.57472631 0.87857666 0.4590833  0.86507201 0.59663396
 0.01004277 0.80575038 0.00184111 0.05886122 0.0248627  0.02243898
 0.59465915] 0.443739964655516
2023-10-30 04:32:20,748 1 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ] 0.6795324585152462
2023-10-30 04:32:20,751 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:32:21,001 Loss: 2.081, MeanIU:  0.6795, Best_mIoU:  0.6907
2023-10-30 04:32:21,001 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ]
2023-10-30 04:32:23,199 Epoch: [101/484] Iter:[0/495], Time: 2.16, lr: [0.008100616478277856], Loss: 2.595976, Acc:0.801094, Semantic loss: 0.953305, BCE loss: 0.807428, SB loss: 0.835244
2023-10-30 04:32:27,037 Epoch: [101/484] Iter:[10/495], Time: 0.55, lr: [0.008100231923906019], Loss: 2.155659, Acc:0.806357, Semantic loss: 0.816609, BCE loss: 0.594186, SB loss: 0.744864
2023-10-30 04:32:30,531 Epoch: [101/484] Iter:[20/495], Time: 0.45, lr: [0.008099847367505669], Loss: 2.103570, Acc:0.797547, Semantic loss: 0.794973, BCE loss: 0.570100, SB loss: 0.738497
2023-10-30 04:32:33,990 Epoch: [101/484] Iter:[30/495], Time: 0.42, lr: [0.008099462809076686], Loss: 2.125863, Acc:0.798526, Semantic loss: 0.801593, BCE loss: 0.573633, SB loss: 0.750637
2023-10-30 04:32:37,513 Epoch: [101/484] Iter:[40/495], Time: 0.40, lr: [0.008099078248618954], Loss: 2.129592, Acc:0.809869, Semantic loss: 0.795147, BCE loss: 0.576708, SB loss: 0.757736
2023-10-30 04:32:40,961 Epoch: [101/484] Iter:[50/495], Time: 0.39, lr: [0.008098693686132358], Loss: 2.122997, Acc:0.804655, Semantic loss: 0.793175, BCE loss: 0.570761, SB loss: 0.759061
2023-10-30 04:32:44,402 Epoch: [101/484] Iter:[60/495], Time: 0.38, lr: [0.008098309121616777], Loss: 2.108017, Acc:0.800359, Semantic loss: 0.790166, BCE loss: 0.561107, SB loss: 0.756744
2023-10-30 04:32:47,874 Epoch: [101/484] Iter:[70/495], Time: 0.38, lr: [0.008097924555072095], Loss: 2.091243, Acc:0.800340, Semantic loss: 0.785051, BCE loss: 0.549029, SB loss: 0.757164
2023-10-30 04:32:51,338 Epoch: [101/484] Iter:[80/495], Time: 0.37, lr: [0.008097539986498191], Loss: 2.095565, Acc:0.800379, Semantic loss: 0.784280, BCE loss: 0.551836, SB loss: 0.759450
2023-10-30 04:32:55,016 Epoch: [101/484] Iter:[90/495], Time: 0.37, lr: [0.00809715541589495], Loss: 2.085627, Acc:0.797522, Semantic loss: 0.782359, BCE loss: 0.545436, SB loss: 0.757832
2023-10-30 04:32:58,592 Epoch: [101/484] Iter:[100/495], Time: 0.37, lr: [0.008096770843262257], Loss: 2.084380, Acc:0.798344, Semantic loss: 0.779811, BCE loss: 0.546960, SB loss: 0.757610
2023-10-30 04:33:02,278 Epoch: [101/484] Iter:[110/495], Time: 0.37, lr: [0.008096386268599988], Loss: 2.096618, Acc:0.797691, Semantic loss: 0.789578, BCE loss: 0.545766, SB loss: 0.761273
2023-10-30 04:33:05,817 Epoch: [101/484] Iter:[120/495], Time: 0.37, lr: [0.008096001691908028], Loss: 2.143927, Acc:0.800058, Semantic loss: 0.815441, BCE loss: 0.559300, SB loss: 0.769186
2023-10-30 04:33:09,447 Epoch: [101/484] Iter:[130/495], Time: 0.37, lr: [0.008095617113186262], Loss: 2.131445, Acc:0.797945, Semantic loss: 0.810523, BCE loss: 0.554832, SB loss: 0.766089
2023-10-30 04:33:13,094 Epoch: [101/484] Iter:[140/495], Time: 0.37, lr: [0.008095232532434566], Loss: 2.128063, Acc:0.799250, Semantic loss: 0.808527, BCE loss: 0.553688, SB loss: 0.765847
2023-10-30 04:33:16,741 Epoch: [101/484] Iter:[150/495], Time: 0.37, lr: [0.008094847949652827], Loss: 2.121249, Acc:0.797808, Semantic loss: 0.805169, BCE loss: 0.550753, SB loss: 0.765327
2023-10-30 04:33:20,364 Epoch: [101/484] Iter:[160/495], Time: 0.37, lr: [0.008094463364840926], Loss: 2.111411, Acc:0.797864, Semantic loss: 0.798759, BCE loss: 0.548710, SB loss: 0.763942
2023-10-30 04:33:24,091 Epoch: [101/484] Iter:[170/495], Time: 0.37, lr: [0.008094078777998746], Loss: 2.118638, Acc:0.797194, Semantic loss: 0.803350, BCE loss: 0.547070, SB loss: 0.768219
2023-10-30 04:33:27,752 Epoch: [101/484] Iter:[180/495], Time: 0.37, lr: [0.008093694189126166], Loss: 2.117670, Acc:0.798538, Semantic loss: 0.803336, BCE loss: 0.546092, SB loss: 0.768242
2023-10-30 04:33:31,455 Epoch: [101/484] Iter:[190/495], Time: 0.37, lr: [0.00809330959822307], Loss: 2.117964, Acc:0.796321, Semantic loss: 0.804518, BCE loss: 0.543983, SB loss: 0.769463
2023-10-30 04:33:35,031 Epoch: [101/484] Iter:[200/495], Time: 0.37, lr: [0.008092925005289341], Loss: 2.123963, Acc:0.797290, Semantic loss: 0.805536, BCE loss: 0.548957, SB loss: 0.769470
2023-10-30 04:33:38,666 Epoch: [101/484] Iter:[210/495], Time: 0.37, lr: [0.00809254041032486], Loss: 2.128222, Acc:0.796352, Semantic loss: 0.809263, BCE loss: 0.548710, SB loss: 0.770249
2023-10-30 04:33:42,256 Epoch: [101/484] Iter:[220/495], Time: 0.37, lr: [0.008092155813329508], Loss: 2.125427, Acc:0.797863, Semantic loss: 0.806204, BCE loss: 0.549401, SB loss: 0.769822
2023-10-30 04:33:45,916 Epoch: [101/484] Iter:[230/495], Time: 0.37, lr: [0.00809177121430317], Loss: 2.121866, Acc:0.797788, Semantic loss: 0.804393, BCE loss: 0.547167, SB loss: 0.770306
2023-10-30 04:33:49,598 Epoch: [101/484] Iter:[240/495], Time: 0.37, lr: [0.008091386613245724], Loss: 2.122820, Acc:0.798528, Semantic loss: 0.805498, BCE loss: 0.548098, SB loss: 0.769224
2023-10-30 04:33:53,250 Epoch: [101/484] Iter:[250/495], Time: 0.37, lr: [0.008091002010157056], Loss: 2.127788, Acc:0.797877, Semantic loss: 0.809099, BCE loss: 0.548131, SB loss: 0.770557
2023-10-30 04:33:56,901 Epoch: [101/484] Iter:[260/495], Time: 0.37, lr: [0.008090617405037045], Loss: 2.138389, Acc:0.797308, Semantic loss: 0.812593, BCE loss: 0.552711, SB loss: 0.773085
2023-10-30 04:34:00,560 Epoch: [101/484] Iter:[270/495], Time: 0.37, lr: [0.008090232797885575], Loss: 2.142929, Acc:0.798890, Semantic loss: 0.814325, BCE loss: 0.554884, SB loss: 0.773719
2023-10-30 04:34:04,227 Epoch: [101/484] Iter:[280/495], Time: 0.37, lr: [0.008089848188702526], Loss: 2.141428, Acc:0.798010, Semantic loss: 0.814334, BCE loss: 0.553908, SB loss: 0.773187
2023-10-30 04:34:07,870 Epoch: [101/484] Iter:[290/495], Time: 0.37, lr: [0.008089463577487781], Loss: 2.140263, Acc:0.798854, Semantic loss: 0.813008, BCE loss: 0.554183, SB loss: 0.773071
2023-10-30 04:34:11,567 Epoch: [101/484] Iter:[300/495], Time: 0.37, lr: [0.008089078964241225], Loss: 2.139406, Acc:0.799032, Semantic loss: 0.812724, BCE loss: 0.553746, SB loss: 0.772936
2023-10-30 04:34:15,180 Epoch: [101/484] Iter:[310/495], Time: 0.37, lr: [0.008088694348962732], Loss: 2.135704, Acc:0.798346, Semantic loss: 0.809907, BCE loss: 0.553493, SB loss: 0.772305
2023-10-30 04:34:18,916 Epoch: [101/484] Iter:[320/495], Time: 0.37, lr: [0.008088309731652194], Loss: 2.136471, Acc:0.799055, Semantic loss: 0.809442, BCE loss: 0.554224, SB loss: 0.772804
2023-10-30 04:34:22,602 Epoch: [101/484] Iter:[330/495], Time: 0.37, lr: [0.008087925112309484], Loss: 2.132650, Acc:0.798681, Semantic loss: 0.807397, BCE loss: 0.552821, SB loss: 0.772432
2023-10-30 04:34:26,410 Epoch: [101/484] Iter:[340/495], Time: 0.37, lr: [0.008087540490934488], Loss: 2.130047, Acc:0.797118, Semantic loss: 0.806643, BCE loss: 0.551078, SB loss: 0.772325
2023-10-30 04:34:30,070 Epoch: [101/484] Iter:[350/495], Time: 0.37, lr: [0.008087155867527089], Loss: 2.136819, Acc:0.796440, Semantic loss: 0.811201, BCE loss: 0.552182, SB loss: 0.773435
2023-10-30 04:34:33,699 Epoch: [101/484] Iter:[360/495], Time: 0.37, lr: [0.008086771242087168], Loss: 2.132646, Acc:0.795584, Semantic loss: 0.809220, BCE loss: 0.551289, SB loss: 0.772137
2023-10-30 04:34:37,381 Epoch: [101/484] Iter:[370/495], Time: 0.37, lr: [0.008086386614614605], Loss: 2.132928, Acc:0.795522, Semantic loss: 0.810212, BCE loss: 0.551058, SB loss: 0.771659
2023-10-30 04:34:41,022 Epoch: [101/484] Iter:[380/495], Time: 0.37, lr: [0.008086001985109283], Loss: 2.132288, Acc:0.796230, Semantic loss: 0.808873, BCE loss: 0.551252, SB loss: 0.772162
2023-10-30 04:34:44,750 Epoch: [101/484] Iter:[390/495], Time: 0.37, lr: [0.008085617353571084], Loss: 2.140409, Acc:0.795977, Semantic loss: 0.814776, BCE loss: 0.551933, SB loss: 0.773700
2023-10-30 04:34:48,490 Epoch: [101/484] Iter:[400/495], Time: 0.37, lr: [0.008085232719999889], Loss: 2.139887, Acc:0.795428, Semantic loss: 0.814145, BCE loss: 0.551992, SB loss: 0.773750
2023-10-30 04:34:52,159 Epoch: [101/484] Iter:[410/495], Time: 0.37, lr: [0.008084848084395581], Loss: 2.138689, Acc:0.795713, Semantic loss: 0.812452, BCE loss: 0.553504, SB loss: 0.772733
2023-10-30 04:34:55,759 Epoch: [101/484] Iter:[420/495], Time: 0.37, lr: [0.00808446344675804], Loss: 2.135803, Acc:0.796009, Semantic loss: 0.810281, BCE loss: 0.553158, SB loss: 0.772364
2023-10-30 04:34:59,382 Epoch: [101/484] Iter:[430/495], Time: 0.37, lr: [0.00808407880708715], Loss: 2.135464, Acc:0.796761, Semantic loss: 0.810051, BCE loss: 0.552978, SB loss: 0.772435
2023-10-30 04:35:02,989 Epoch: [101/484] Iter:[440/495], Time: 0.37, lr: [0.008083694165382793], Loss: 2.134019, Acc:0.797673, Semantic loss: 0.809633, BCE loss: 0.552743, SB loss: 0.771643
2023-10-30 04:35:06,665 Epoch: [101/484] Iter:[450/495], Time: 0.37, lr: [0.00808330952164485], Loss: 2.131763, Acc:0.797482, Semantic loss: 0.809199, BCE loss: 0.551475, SB loss: 0.771089
2023-10-30 04:35:10,372 Epoch: [101/484] Iter:[460/495], Time: 0.37, lr: [0.0080829248758732], Loss: 2.130954, Acc:0.797784, Semantic loss: 0.808530, BCE loss: 0.551066, SB loss: 0.771358
2023-10-30 04:35:14,031 Epoch: [101/484] Iter:[470/495], Time: 0.37, lr: [0.008082540228067727], Loss: 2.130516, Acc:0.797991, Semantic loss: 0.808313, BCE loss: 0.551397, SB loss: 0.770806
2023-10-30 04:35:17,699 Epoch: [101/484] Iter:[480/495], Time: 0.37, lr: [0.008082155578228313], Loss: 2.128614, Acc:0.798669, Semantic loss: 0.806849, BCE loss: 0.551724, SB loss: 0.770041
2023-10-30 04:35:21,243 Epoch: [101/484] Iter:[490/495], Time: 0.37, lr: [0.00808177092635484], Loss: 2.126715, Acc:0.798636, Semantic loss: 0.805408, BCE loss: 0.551623, SB loss: 0.769684
2023-10-30 04:35:22,638 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:35:22,879 Loss: 2.081, MeanIU:  0.6795, Best_mIoU:  0.6907
2023-10-30 04:35:22,879 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ]
2023-10-30 04:35:25,030 Epoch: [102/484] Iter:[0/495], Time: 2.12, lr: [0.008081578599655293], Loss: 2.175269, Acc:0.774879, Semantic loss: 0.752783, BCE loss: 0.596679, SB loss: 0.825807
2023-10-30 04:35:28,908 Epoch: [102/484] Iter:[10/495], Time: 0.54, lr: [0.008081193944730508], Loss: 2.115721, Acc:0.801103, Semantic loss: 0.798186, BCE loss: 0.554388, SB loss: 0.763147
2023-10-30 04:35:32,533 Epoch: [102/484] Iter:[20/495], Time: 0.46, lr: [0.008080809287771367], Loss: 2.177941, Acc:0.798387, Semantic loss: 0.854807, BCE loss: 0.523252, SB loss: 0.799882
2023-10-30 04:35:36,168 Epoch: [102/484] Iter:[30/495], Time: 0.43, lr: [0.008080424628777753], Loss: 2.101845, Acc:0.806747, Semantic loss: 0.808408, BCE loss: 0.517141, SB loss: 0.776295
2023-10-30 04:35:40,010 Epoch: [102/484] Iter:[40/495], Time: 0.42, lr: [0.008080039967749548], Loss: 2.090264, Acc:0.802901, Semantic loss: 0.793279, BCE loss: 0.525214, SB loss: 0.771770
2023-10-30 04:35:43,686 Epoch: [102/484] Iter:[50/495], Time: 0.41, lr: [0.00807965530468663], Loss: 2.096645, Acc:0.801977, Semantic loss: 0.784415, BCE loss: 0.542744, SB loss: 0.769485
2023-10-30 04:35:47,372 Epoch: [102/484] Iter:[60/495], Time: 0.40, lr: [0.008079270639588883], Loss: 2.111779, Acc:0.798746, Semantic loss: 0.791369, BCE loss: 0.549387, SB loss: 0.771023
2023-10-30 04:35:51,061 Epoch: [102/484] Iter:[70/495], Time: 0.40, lr: [0.00807888597245619], Loss: 2.098651, Acc:0.797447, Semantic loss: 0.786211, BCE loss: 0.542437, SB loss: 0.770003
2023-10-30 04:35:54,714 Epoch: [102/484] Iter:[80/495], Time: 0.39, lr: [0.008078501303288431], Loss: 2.085571, Acc:0.797541, Semantic loss: 0.783835, BCE loss: 0.535883, SB loss: 0.765853
2023-10-30 04:35:58,452 Epoch: [102/484] Iter:[90/495], Time: 0.39, lr: [0.008078116632085486], Loss: 2.082128, Acc:0.796578, Semantic loss: 0.784075, BCE loss: 0.534313, SB loss: 0.763740
2023-10-30 04:36:02,104 Epoch: [102/484] Iter:[100/495], Time: 0.39, lr: [0.008077731958847239], Loss: 2.073550, Acc:0.795806, Semantic loss: 0.785269, BCE loss: 0.528826, SB loss: 0.759455
2023-10-30 04:36:05,772 Epoch: [102/484] Iter:[110/495], Time: 0.39, lr: [0.008077347283573571], Loss: 2.078945, Acc:0.794934, Semantic loss: 0.784492, BCE loss: 0.531012, SB loss: 0.763441
2023-10-30 04:36:09,564 Epoch: [102/484] Iter:[120/495], Time: 0.39, lr: [0.008076962606264365], Loss: 2.067997, Acc:0.796802, Semantic loss: 0.773333, BCE loss: 0.534169, SB loss: 0.760494
2023-10-30 04:36:13,184 Epoch: [102/484] Iter:[130/495], Time: 0.38, lr: [0.0080765779269195], Loss: 2.073105, Acc:0.794824, Semantic loss: 0.777583, BCE loss: 0.532883, SB loss: 0.762638
2023-10-30 04:36:16,843 Epoch: [102/484] Iter:[140/495], Time: 0.38, lr: [0.008076193245538857], Loss: 2.084693, Acc:0.795955, Semantic loss: 0.783920, BCE loss: 0.536841, SB loss: 0.763932
2023-10-30 04:36:20,492 Epoch: [102/484] Iter:[150/495], Time: 0.38, lr: [0.00807580856212232], Loss: 2.089976, Acc:0.796590, Semantic loss: 0.789117, BCE loss: 0.534552, SB loss: 0.766308
2023-10-30 04:36:24,224 Epoch: [102/484] Iter:[160/495], Time: 0.38, lr: [0.008075423876669766], Loss: 2.092941, Acc:0.796281, Semantic loss: 0.787523, BCE loss: 0.538546, SB loss: 0.766872
2023-10-30 04:36:27,907 Epoch: [102/484] Iter:[170/495], Time: 0.38, lr: [0.008075039189181083], Loss: 2.087564, Acc:0.795478, Semantic loss: 0.785753, BCE loss: 0.535470, SB loss: 0.766341
2023-10-30 04:36:31,608 Epoch: [102/484] Iter:[180/495], Time: 0.38, lr: [0.008074654499656149], Loss: 2.086045, Acc:0.796117, Semantic loss: 0.782667, BCE loss: 0.538277, SB loss: 0.765101
2023-10-30 04:36:35,352 Epoch: [102/484] Iter:[190/495], Time: 0.38, lr: [0.008074269808094845], Loss: 2.092868, Acc:0.796247, Semantic loss: 0.787560, BCE loss: 0.539800, SB loss: 0.765508
2023-10-30 04:36:39,048 Epoch: [102/484] Iter:[200/495], Time: 0.38, lr: [0.008073885114497054], Loss: 2.091242, Acc:0.797310, Semantic loss: 0.784898, BCE loss: 0.540653, SB loss: 0.765691
2023-10-30 04:36:42,702 Epoch: [102/484] Iter:[210/495], Time: 0.38, lr: [0.008073500418862655], Loss: 2.091797, Acc:0.797161, Semantic loss: 0.784853, BCE loss: 0.541695, SB loss: 0.765249
2023-10-30 04:36:46,334 Epoch: [102/484] Iter:[220/495], Time: 0.38, lr: [0.008073115721191532], Loss: 2.098508, Acc:0.796705, Semantic loss: 0.793488, BCE loss: 0.540130, SB loss: 0.764890
2023-10-30 04:36:50,029 Epoch: [102/484] Iter:[230/495], Time: 0.38, lr: [0.008072731021483565], Loss: 2.098405, Acc:0.797613, Semantic loss: 0.791996, BCE loss: 0.541405, SB loss: 0.765004
2023-10-30 04:36:53,748 Epoch: [102/484] Iter:[240/495], Time: 0.38, lr: [0.008072346319738634], Loss: 2.088130, Acc:0.796707, Semantic loss: 0.788521, BCE loss: 0.536471, SB loss: 0.763138
2023-10-30 04:36:57,447 Epoch: [102/484] Iter:[250/495], Time: 0.38, lr: [0.008071961615956623], Loss: 2.083742, Acc:0.797493, Semantic loss: 0.785380, BCE loss: 0.536981, SB loss: 0.761381
2023-10-30 04:37:01,139 Epoch: [102/484] Iter:[260/495], Time: 0.38, lr: [0.008071576910137412], Loss: 2.087391, Acc:0.797902, Semantic loss: 0.787163, BCE loss: 0.538310, SB loss: 0.761918
2023-10-30 04:37:04,946 Epoch: [102/484] Iter:[270/495], Time: 0.38, lr: [0.008071192202280884], Loss: 2.083722, Acc:0.798033, Semantic loss: 0.785188, BCE loss: 0.537473, SB loss: 0.761062
2023-10-30 04:37:08,554 Epoch: [102/484] Iter:[280/495], Time: 0.38, lr: [0.008070807492386919], Loss: 2.081313, Acc:0.798758, Semantic loss: 0.784156, BCE loss: 0.537985, SB loss: 0.759172
2023-10-30 04:37:12,160 Epoch: [102/484] Iter:[290/495], Time: 0.38, lr: [0.008070422780455395], Loss: 2.090063, Acc:0.796425, Semantic loss: 0.788952, BCE loss: 0.540376, SB loss: 0.760735
2023-10-30 04:37:15,808 Epoch: [102/484] Iter:[300/495], Time: 0.38, lr: [0.008070038066486198], Loss: 2.090440, Acc:0.797011, Semantic loss: 0.788910, BCE loss: 0.539304, SB loss: 0.762227
2023-10-30 04:37:19,469 Epoch: [102/484] Iter:[310/495], Time: 0.37, lr: [0.00806965335047921], Loss: 2.085543, Acc:0.796130, Semantic loss: 0.786723, BCE loss: 0.537790, SB loss: 0.761030
2023-10-30 04:37:23,172 Epoch: [102/484] Iter:[320/495], Time: 0.37, lr: [0.008069268632434307], Loss: 2.082336, Acc:0.796340, Semantic loss: 0.785003, BCE loss: 0.538024, SB loss: 0.759309
2023-10-30 04:37:26,871 Epoch: [102/484] Iter:[330/495], Time: 0.37, lr: [0.008068883912351374], Loss: 2.085891, Acc:0.795356, Semantic loss: 0.786591, BCE loss: 0.540181, SB loss: 0.759120
2023-10-30 04:37:30,589 Epoch: [102/484] Iter:[340/495], Time: 0.37, lr: [0.008068499190230293], Loss: 2.088272, Acc:0.795942, Semantic loss: 0.788315, BCE loss: 0.541792, SB loss: 0.758165
2023-10-30 04:37:34,235 Epoch: [102/484] Iter:[350/495], Time: 0.37, lr: [0.008068114466070943], Loss: 2.090648, Acc:0.795517, Semantic loss: 0.789301, BCE loss: 0.543252, SB loss: 0.758095
2023-10-30 04:37:37,858 Epoch: [102/484] Iter:[360/495], Time: 0.37, lr: [0.008067729739873205], Loss: 2.091349, Acc:0.795346, Semantic loss: 0.788759, BCE loss: 0.544634, SB loss: 0.757956
2023-10-30 04:37:41,486 Epoch: [102/484] Iter:[370/495], Time: 0.37, lr: [0.008067345011636962], Loss: 2.089598, Acc:0.794800, Semantic loss: 0.787101, BCE loss: 0.544817, SB loss: 0.757680
2023-10-30 04:37:45,245 Epoch: [102/484] Iter:[380/495], Time: 0.37, lr: [0.008066960281362093], Loss: 2.090961, Acc:0.794908, Semantic loss: 0.787603, BCE loss: 0.544637, SB loss: 0.758721
2023-10-30 04:37:48,989 Epoch: [102/484] Iter:[390/495], Time: 0.37, lr: [0.008066575549048481], Loss: 2.097884, Acc:0.795918, Semantic loss: 0.790050, BCE loss: 0.547358, SB loss: 0.760476
2023-10-30 04:37:52,612 Epoch: [102/484] Iter:[400/495], Time: 0.37, lr: [0.008066190814696008], Loss: 2.106440, Acc:0.796013, Semantic loss: 0.793947, BCE loss: 0.549498, SB loss: 0.762995
2023-10-30 04:37:56,261 Epoch: [102/484] Iter:[410/495], Time: 0.37, lr: [0.008065806078304552], Loss: 2.106466, Acc:0.795281, Semantic loss: 0.793397, BCE loss: 0.549528, SB loss: 0.763541
2023-10-30 04:37:59,903 Epoch: [102/484] Iter:[420/495], Time: 0.37, lr: [0.008065421339873997], Loss: 2.105982, Acc:0.795514, Semantic loss: 0.792593, BCE loss: 0.549900, SB loss: 0.763489
2023-10-30 04:38:03,559 Epoch: [102/484] Iter:[430/495], Time: 0.37, lr: [0.008065036599404224], Loss: 2.102632, Acc:0.795687, Semantic loss: 0.790645, BCE loss: 0.549500, SB loss: 0.762487
2023-10-30 04:38:07,264 Epoch: [102/484] Iter:[440/495], Time: 0.37, lr: [0.008064651856895111], Loss: 2.102340, Acc:0.795758, Semantic loss: 0.790501, BCE loss: 0.548398, SB loss: 0.763440
2023-10-30 04:38:10,934 Epoch: [102/484] Iter:[450/495], Time: 0.37, lr: [0.008064267112346542], Loss: 2.107130, Acc:0.794589, Semantic loss: 0.794513, BCE loss: 0.548286, SB loss: 0.764331
2023-10-30 04:38:14,584 Epoch: [102/484] Iter:[460/495], Time: 0.37, lr: [0.008063882365758397], Loss: 2.109657, Acc:0.794128, Semantic loss: 0.795414, BCE loss: 0.548323, SB loss: 0.765920
2023-10-30 04:38:18,269 Epoch: [102/484] Iter:[470/495], Time: 0.37, lr: [0.008063497617130558], Loss: 2.109742, Acc:0.794219, Semantic loss: 0.794619, BCE loss: 0.549005, SB loss: 0.766118
2023-10-30 04:38:21,879 Epoch: [102/484] Iter:[480/495], Time: 0.37, lr: [0.008063112866462904], Loss: 2.110158, Acc:0.793435, Semantic loss: 0.794481, BCE loss: 0.549069, SB loss: 0.766609
2023-10-30 04:38:25,435 Epoch: [102/484] Iter:[490/495], Time: 0.37, lr: [0.008062728113755318], Loss: 2.108818, Acc:0.792699, Semantic loss: 0.794050, BCE loss: 0.548007, SB loss: 0.766760
2023-10-30 04:38:26,835 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:38:27,074 Loss: 2.081, MeanIU:  0.6795, Best_mIoU:  0.6907
2023-10-30 04:38:27,074 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ]
2023-10-30 04:38:29,423 Epoch: [103/484] Iter:[0/495], Time: 2.31, lr: [0.008062535736636513], Loss: 2.589793, Acc:0.792323, Semantic loss: 0.949431, BCE loss: 0.863510, SB loss: 0.776853
2023-10-30 04:38:33,300 Epoch: [103/484] Iter:[10/495], Time: 0.56, lr: [0.008062150980868805], Loss: 2.111783, Acc:0.808185, Semantic loss: 0.729486, BCE loss: 0.632766, SB loss: 0.749531
2023-10-30 04:38:37,065 Epoch: [103/484] Iter:[20/495], Time: 0.47, lr: [0.008061766223060868], Loss: 2.102715, Acc:0.818185, Semantic loss: 0.743663, BCE loss: 0.610056, SB loss: 0.748996
2023-10-30 04:38:40,679 Epoch: [103/484] Iter:[30/495], Time: 0.44, lr: [0.00806138146321258], Loss: 2.158444, Acc:0.786427, Semantic loss: 0.827209, BCE loss: 0.570264, SB loss: 0.760971
2023-10-30 04:38:44,287 Epoch: [103/484] Iter:[40/495], Time: 0.42, lr: [0.008060996701323826], Loss: 2.119400, Acc:0.790760, Semantic loss: 0.804704, BCE loss: 0.558921, SB loss: 0.755775
2023-10-30 04:38:47,843 Epoch: [103/484] Iter:[50/495], Time: 0.41, lr: [0.008060611937394484], Loss: 2.117511, Acc:0.786720, Semantic loss: 0.804495, BCE loss: 0.554090, SB loss: 0.758926
2023-10-30 04:38:51,514 Epoch: [103/484] Iter:[60/495], Time: 0.40, lr: [0.008060227171424435], Loss: 2.128341, Acc:0.784733, Semantic loss: 0.818878, BCE loss: 0.549197, SB loss: 0.760266
2023-10-30 04:38:55,127 Epoch: [103/484] Iter:[70/495], Time: 0.39, lr: [0.008059842403413562], Loss: 2.141644, Acc:0.786279, Semantic loss: 0.824968, BCE loss: 0.553957, SB loss: 0.762718
2023-10-30 04:38:58,761 Epoch: [103/484] Iter:[80/495], Time: 0.39, lr: [0.008059457633361744], Loss: 2.145009, Acc:0.782553, Semantic loss: 0.828029, BCE loss: 0.552602, SB loss: 0.764377
2023-10-30 04:39:02,453 Epoch: [103/484] Iter:[90/495], Time: 0.39, lr: [0.008059072861268862], Loss: 2.140263, Acc:0.782884, Semantic loss: 0.822856, BCE loss: 0.551160, SB loss: 0.766248
2023-10-30 04:39:06,091 Epoch: [103/484] Iter:[100/495], Time: 0.39, lr: [0.008058688087134799], Loss: 2.144663, Acc:0.780857, Semantic loss: 0.825945, BCE loss: 0.549508, SB loss: 0.769210
2023-10-30 04:39:09,781 Epoch: [103/484] Iter:[110/495], Time: 0.38, lr: [0.008058303310959433], Loss: 2.142974, Acc:0.783497, Semantic loss: 0.822121, BCE loss: 0.548132, SB loss: 0.772721
2023-10-30 04:39:13,508 Epoch: [103/484] Iter:[120/495], Time: 0.38, lr: [0.008057918532742646], Loss: 2.137624, Acc:0.785159, Semantic loss: 0.814551, BCE loss: 0.551055, SB loss: 0.772018
2023-10-30 04:39:17,117 Epoch: [103/484] Iter:[130/495], Time: 0.38, lr: [0.00805753375248432], Loss: 2.141805, Acc:0.784660, Semantic loss: 0.813635, BCE loss: 0.553051, SB loss: 0.775118
2023-10-30 04:39:20,789 Epoch: [103/484] Iter:[140/495], Time: 0.38, lr: [0.008057148970184334], Loss: 2.130883, Acc:0.784856, Semantic loss: 0.808895, BCE loss: 0.550559, SB loss: 0.771429
2023-10-30 04:39:24,438 Epoch: [103/484] Iter:[150/495], Time: 0.38, lr: [0.008056764185842571], Loss: 2.136060, Acc:0.786311, Semantic loss: 0.813176, BCE loss: 0.552217, SB loss: 0.770667
2023-10-30 04:39:28,136 Epoch: [103/484] Iter:[160/495], Time: 0.38, lr: [0.008056379399458911], Loss: 2.125785, Acc:0.783455, Semantic loss: 0.807903, BCE loss: 0.547841, SB loss: 0.770042
2023-10-30 04:39:31,851 Epoch: [103/484] Iter:[170/495], Time: 0.38, lr: [0.008055994611033233], Loss: 2.128264, Acc:0.785370, Semantic loss: 0.808035, BCE loss: 0.549350, SB loss: 0.770880
2023-10-30 04:39:35,513 Epoch: [103/484] Iter:[180/495], Time: 0.38, lr: [0.00805560982056542], Loss: 2.130384, Acc:0.784884, Semantic loss: 0.811735, BCE loss: 0.547729, SB loss: 0.770920
2023-10-30 04:39:39,198 Epoch: [103/484] Iter:[190/495], Time: 0.38, lr: [0.00805522502805535], Loss: 2.133594, Acc:0.784909, Semantic loss: 0.814076, BCE loss: 0.547871, SB loss: 0.771646
2023-10-30 04:39:42,856 Epoch: [103/484] Iter:[200/495], Time: 0.38, lr: [0.008054840233502909], Loss: 2.119023, Acc:0.784520, Semantic loss: 0.806802, BCE loss: 0.542870, SB loss: 0.769351
2023-10-30 04:39:46,468 Epoch: [103/484] Iter:[210/495], Time: 0.38, lr: [0.008054455436907972], Loss: 2.118770, Acc:0.785121, Semantic loss: 0.806702, BCE loss: 0.542681, SB loss: 0.769388
2023-10-30 04:39:50,174 Epoch: [103/484] Iter:[220/495], Time: 0.38, lr: [0.008054070638270421], Loss: 2.121769, Acc:0.783568, Semantic loss: 0.810768, BCE loss: 0.540320, SB loss: 0.770681
2023-10-30 04:39:53,866 Epoch: [103/484] Iter:[230/495], Time: 0.38, lr: [0.00805368583759014], Loss: 2.129850, Acc:0.782526, Semantic loss: 0.817147, BCE loss: 0.538814, SB loss: 0.773889
2023-10-30 04:39:57,594 Epoch: [103/484] Iter:[240/495], Time: 0.38, lr: [0.008053301034867007], Loss: 2.138436, Acc:0.783805, Semantic loss: 0.822253, BCE loss: 0.539709, SB loss: 0.776474
2023-10-30 04:40:01,286 Epoch: [103/484] Iter:[250/495], Time: 0.38, lr: [0.008052916230100904], Loss: 2.138475, Acc:0.783860, Semantic loss: 0.820648, BCE loss: 0.540700, SB loss: 0.777127
2023-10-30 04:40:05,019 Epoch: [103/484] Iter:[260/495], Time: 0.38, lr: [0.00805253142329171], Loss: 2.143222, Acc:0.784307, Semantic loss: 0.820671, BCE loss: 0.544756, SB loss: 0.777795
2023-10-30 04:40:08,678 Epoch: [103/484] Iter:[270/495], Time: 0.37, lr: [0.008052146614439308], Loss: 2.146031, Acc:0.782852, Semantic loss: 0.822174, BCE loss: 0.544336, SB loss: 0.779522
2023-10-30 04:40:12,412 Epoch: [103/484] Iter:[280/495], Time: 0.37, lr: [0.008051761803543576], Loss: 2.141198, Acc:0.783287, Semantic loss: 0.819106, BCE loss: 0.544967, SB loss: 0.777125
2023-10-30 04:40:16,076 Epoch: [103/484] Iter:[290/495], Time: 0.37, lr: [0.008051376990604396], Loss: 2.141393, Acc:0.784106, Semantic loss: 0.820047, BCE loss: 0.544138, SB loss: 0.777207
2023-10-30 04:40:19,717 Epoch: [103/484] Iter:[300/495], Time: 0.37, lr: [0.008050992175621649], Loss: 2.138742, Acc:0.783588, Semantic loss: 0.818878, BCE loss: 0.542891, SB loss: 0.776973
2023-10-30 04:40:23,429 Epoch: [103/484] Iter:[310/495], Time: 0.37, lr: [0.008050607358595216], Loss: 2.139982, Acc:0.784672, Semantic loss: 0.819215, BCE loss: 0.543004, SB loss: 0.777764
2023-10-30 04:40:27,218 Epoch: [103/484] Iter:[320/495], Time: 0.37, lr: [0.008050222539524976], Loss: 2.138607, Acc:0.786121, Semantic loss: 0.817662, BCE loss: 0.543699, SB loss: 0.777246
2023-10-30 04:40:30,872 Epoch: [103/484] Iter:[330/495], Time: 0.37, lr: [0.00804983771841081], Loss: 2.133174, Acc:0.785625, Semantic loss: 0.815540, BCE loss: 0.541395, SB loss: 0.776239
2023-10-30 04:40:34,593 Epoch: [103/484] Iter:[340/495], Time: 0.37, lr: [0.0080494528952526], Loss: 2.136723, Acc:0.785677, Semantic loss: 0.816155, BCE loss: 0.542644, SB loss: 0.777924
2023-10-30 04:40:38,264 Epoch: [103/484] Iter:[350/495], Time: 0.37, lr: [0.008049068070050226], Loss: 2.132205, Acc:0.786490, Semantic loss: 0.813525, BCE loss: 0.541379, SB loss: 0.777301
2023-10-30 04:40:41,841 Epoch: [103/484] Iter:[360/495], Time: 0.37, lr: [0.008048683242803566], Loss: 2.130188, Acc:0.786783, Semantic loss: 0.812638, BCE loss: 0.540852, SB loss: 0.776698
2023-10-30 04:40:45,558 Epoch: [103/484] Iter:[370/495], Time: 0.37, lr: [0.008048298413512504], Loss: 2.129713, Acc:0.787589, Semantic loss: 0.811680, BCE loss: 0.541754, SB loss: 0.776280
2023-10-30 04:40:49,253 Epoch: [103/484] Iter:[380/495], Time: 0.37, lr: [0.008047913582176918], Loss: 2.131758, Acc:0.787639, Semantic loss: 0.814280, BCE loss: 0.541657, SB loss: 0.775821
2023-10-30 04:40:52,889 Epoch: [103/484] Iter:[390/495], Time: 0.37, lr: [0.008047528748796691], Loss: 2.130211, Acc:0.787472, Semantic loss: 0.812673, BCE loss: 0.542072, SB loss: 0.775466
2023-10-30 04:40:56,596 Epoch: [103/484] Iter:[400/495], Time: 0.37, lr: [0.0080471439133717], Loss: 2.127755, Acc:0.787059, Semantic loss: 0.811860, BCE loss: 0.540465, SB loss: 0.775430
2023-10-30 04:41:00,400 Epoch: [103/484] Iter:[410/495], Time: 0.37, lr: [0.008046759075901832], Loss: 2.128690, Acc:0.787128, Semantic loss: 0.811042, BCE loss: 0.541909, SB loss: 0.775739
2023-10-30 04:41:04,144 Epoch: [103/484] Iter:[420/495], Time: 0.37, lr: [0.008046374236386959], Loss: 2.127490, Acc:0.786769, Semantic loss: 0.810449, BCE loss: 0.541295, SB loss: 0.775746
2023-10-30 04:41:07,869 Epoch: [103/484] Iter:[430/495], Time: 0.37, lr: [0.008045989394826966], Loss: 2.126208, Acc:0.787746, Semantic loss: 0.809286, BCE loss: 0.541457, SB loss: 0.775465
2023-10-30 04:41:11,517 Epoch: [103/484] Iter:[440/495], Time: 0.37, lr: [0.008045604551221736], Loss: 2.122842, Acc:0.786940, Semantic loss: 0.807358, BCE loss: 0.540428, SB loss: 0.775056
2023-10-30 04:41:15,183 Epoch: [103/484] Iter:[450/495], Time: 0.37, lr: [0.008045219705571144], Loss: 2.124373, Acc:0.787797, Semantic loss: 0.807455, BCE loss: 0.542128, SB loss: 0.774790
2023-10-30 04:41:18,895 Epoch: [103/484] Iter:[460/495], Time: 0.37, lr: [0.008044834857875074], Loss: 2.126204, Acc:0.788228, Semantic loss: 0.807531, BCE loss: 0.544273, SB loss: 0.774400
2023-10-30 04:41:22,474 Epoch: [103/484] Iter:[470/495], Time: 0.37, lr: [0.008044450008133404], Loss: 2.127400, Acc:0.788694, Semantic loss: 0.807922, BCE loss: 0.545148, SB loss: 0.774330
2023-10-30 04:41:26,126 Epoch: [103/484] Iter:[480/495], Time: 0.37, lr: [0.008044065156346016], Loss: 2.126691, Acc:0.789292, Semantic loss: 0.807030, BCE loss: 0.545672, SB loss: 0.773989
2023-10-30 04:41:29,557 Epoch: [103/484] Iter:[490/495], Time: 0.37, lr: [0.00804368030251279], Loss: 2.126183, Acc:0.788675, Semantic loss: 0.806107, BCE loss: 0.546606, SB loss: 0.773470
2023-10-30 04:41:30,953 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:41:31,192 Loss: 2.081, MeanIU:  0.6795, Best_mIoU:  0.6907
2023-10-30 04:41:31,192 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ]
2023-10-30 04:41:33,563 Epoch: [104/484] Iter:[0/495], Time: 2.34, lr: [0.00804348787482895], Loss: 2.008629, Acc:0.913740, Semantic loss: 0.791166, BCE loss: 0.537224, SB loss: 0.680240
2023-10-30 04:41:37,556 Epoch: [104/484] Iter:[10/495], Time: 0.58, lr: [0.008043103017926743], Loss: 2.268558, Acc:0.815453, Semantic loss: 0.906205, BCE loss: 0.558907, SB loss: 0.803446
2023-10-30 04:41:41,216 Epoch: [104/484] Iter:[20/495], Time: 0.48, lr: [0.008042718158978399], Loss: 2.190769, Acc:0.811675, Semantic loss: 0.852960, BCE loss: 0.550299, SB loss: 0.787510
2023-10-30 04:41:44,845 Epoch: [104/484] Iter:[30/495], Time: 0.44, lr: [0.008042333297983798], Loss: 2.124563, Acc:0.814229, Semantic loss: 0.799203, BCE loss: 0.556903, SB loss: 0.768457
2023-10-30 04:41:48,503 Epoch: [104/484] Iter:[40/495], Time: 0.42, lr: [0.008041948434942821], Loss: 2.164875, Acc:0.778680, Semantic loss: 0.827493, BCE loss: 0.538797, SB loss: 0.798585
2023-10-30 04:41:52,314 Epoch: [104/484] Iter:[50/495], Time: 0.41, lr: [0.008041563569855347], Loss: 2.225448, Acc:0.776316, Semantic loss: 0.866933, BCE loss: 0.536883, SB loss: 0.821631
2023-10-30 04:41:56,037 Epoch: [104/484] Iter:[60/495], Time: 0.41, lr: [0.008041178702721257], Loss: 2.249574, Acc:0.776000, Semantic loss: 0.867321, BCE loss: 0.558743, SB loss: 0.823509
2023-10-30 04:41:59,689 Epoch: [104/484] Iter:[70/495], Time: 0.40, lr: [0.008040793833540432], Loss: 2.233025, Acc:0.779105, Semantic loss: 0.855140, BCE loss: 0.558768, SB loss: 0.819116
2023-10-30 04:42:03,373 Epoch: [104/484] Iter:[80/495], Time: 0.40, lr: [0.008040408962312753], Loss: 2.207198, Acc:0.784847, Semantic loss: 0.837483, BCE loss: 0.561668, SB loss: 0.808047
2023-10-30 04:42:06,934 Epoch: [104/484] Iter:[90/495], Time: 0.39, lr: [0.008040024089038098], Loss: 2.202787, Acc:0.784642, Semantic loss: 0.836033, BCE loss: 0.563289, SB loss: 0.803465
2023-10-30 04:42:10,659 Epoch: [104/484] Iter:[100/495], Time: 0.39, lr: [0.008039639213716348], Loss: 2.188155, Acc:0.785368, Semantic loss: 0.827477, BCE loss: 0.563485, SB loss: 0.797193
2023-10-30 04:42:14,421 Epoch: [104/484] Iter:[110/495], Time: 0.39, lr: [0.008039254336347383], Loss: 2.192681, Acc:0.787518, Semantic loss: 0.831833, BCE loss: 0.566667, SB loss: 0.794182
2023-10-30 04:42:18,146 Epoch: [104/484] Iter:[120/495], Time: 0.39, lr: [0.008038869456931082], Loss: 2.181777, Acc:0.788681, Semantic loss: 0.826684, BCE loss: 0.563818, SB loss: 0.791276
2023-10-30 04:42:21,795 Epoch: [104/484] Iter:[130/495], Time: 0.39, lr: [0.00803848457546733], Loss: 2.183673, Acc:0.788873, Semantic loss: 0.828644, BCE loss: 0.560206, SB loss: 0.794824
2023-10-30 04:42:25,411 Epoch: [104/484] Iter:[140/495], Time: 0.38, lr: [0.008038099691956003], Loss: 2.187187, Acc:0.790397, Semantic loss: 0.830347, BCE loss: 0.561042, SB loss: 0.795798
2023-10-30 04:42:29,104 Epoch: [104/484] Iter:[150/495], Time: 0.38, lr: [0.008037714806396982], Loss: 2.184481, Acc:0.788238, Semantic loss: 0.834825, BCE loss: 0.557287, SB loss: 0.792369
2023-10-30 04:42:32,763 Epoch: [104/484] Iter:[160/495], Time: 0.38, lr: [0.008037329918790147], Loss: 2.187231, Acc:0.785862, Semantic loss: 0.838161, BCE loss: 0.554884, SB loss: 0.794186
2023-10-30 04:42:36,479 Epoch: [104/484] Iter:[170/495], Time: 0.38, lr: [0.008036945029135378], Loss: 2.177331, Acc:0.786476, Semantic loss: 0.834043, BCE loss: 0.552932, SB loss: 0.790357
2023-10-30 04:42:40,118 Epoch: [104/484] Iter:[180/495], Time: 0.38, lr: [0.008036560137432557], Loss: 2.177057, Acc:0.787204, Semantic loss: 0.833395, BCE loss: 0.555072, SB loss: 0.788589
2023-10-30 04:42:43,751 Epoch: [104/484] Iter:[190/495], Time: 0.38, lr: [0.008036175243681562], Loss: 2.169663, Acc:0.788113, Semantic loss: 0.828554, BCE loss: 0.553854, SB loss: 0.787255
2023-10-30 04:42:47,473 Epoch: [104/484] Iter:[200/495], Time: 0.38, lr: [0.008035790347882273], Loss: 2.155885, Acc:0.788606, Semantic loss: 0.821403, BCE loss: 0.550737, SB loss: 0.783746
2023-10-30 04:42:51,091 Epoch: [104/484] Iter:[210/495], Time: 0.38, lr: [0.008035405450034571], Loss: 2.152547, Acc:0.790887, Semantic loss: 0.818264, BCE loss: 0.553636, SB loss: 0.780648
2023-10-30 04:42:54,795 Epoch: [104/484] Iter:[220/495], Time: 0.38, lr: [0.008035020550138336], Loss: 2.153130, Acc:0.790080, Semantic loss: 0.820022, BCE loss: 0.551645, SB loss: 0.781463
2023-10-30 04:42:58,524 Epoch: [104/484] Iter:[230/495], Time: 0.38, lr: [0.00803463564819345], Loss: 2.149605, Acc:0.790591, Semantic loss: 0.817198, BCE loss: 0.552085, SB loss: 0.780322
2023-10-30 04:43:02,182 Epoch: [104/484] Iter:[240/495], Time: 0.38, lr: [0.008034250744199788], Loss: 2.143413, Acc:0.791723, Semantic loss: 0.812795, BCE loss: 0.552218, SB loss: 0.778400
2023-10-30 04:43:05,923 Epoch: [104/484] Iter:[250/495], Time: 0.38, lr: [0.008033865838157236], Loss: 2.142770, Acc:0.792842, Semantic loss: 0.812581, BCE loss: 0.552596, SB loss: 0.777592
2023-10-30 04:43:09,742 Epoch: [104/484] Iter:[260/495], Time: 0.38, lr: [0.00803348093006567], Loss: 2.146497, Acc:0.793109, Semantic loss: 0.814319, BCE loss: 0.553452, SB loss: 0.778726
2023-10-30 04:43:13,399 Epoch: [104/484] Iter:[270/495], Time: 0.38, lr: [0.00803309601992497], Loss: 2.142522, Acc:0.792903, Semantic loss: 0.812765, BCE loss: 0.551729, SB loss: 0.778029
2023-10-30 04:43:16,992 Epoch: [104/484] Iter:[280/495], Time: 0.38, lr: [0.008032711107735018], Loss: 2.142157, Acc:0.793395, Semantic loss: 0.810401, BCE loss: 0.553437, SB loss: 0.778319
2023-10-30 04:43:20,710 Epoch: [104/484] Iter:[290/495], Time: 0.38, lr: [0.008032326193495695], Loss: 2.141197, Acc:0.793203, Semantic loss: 0.808233, BCE loss: 0.554437, SB loss: 0.778527
2023-10-30 04:43:24,393 Epoch: [104/484] Iter:[300/495], Time: 0.38, lr: [0.008031941277206876], Loss: 2.140225, Acc:0.792476, Semantic loss: 0.808105, BCE loss: 0.554101, SB loss: 0.778019
2023-10-30 04:43:28,174 Epoch: [104/484] Iter:[310/495], Time: 0.38, lr: [0.008031556358868446], Loss: 2.138675, Acc:0.792804, Semantic loss: 0.807005, BCE loss: 0.553885, SB loss: 0.777785
2023-10-30 04:43:31,885 Epoch: [104/484] Iter:[320/495], Time: 0.38, lr: [0.008031171438480282], Loss: 2.138652, Acc:0.793603, Semantic loss: 0.807270, BCE loss: 0.555081, SB loss: 0.776301
2023-10-30 04:43:35,500 Epoch: [104/484] Iter:[330/495], Time: 0.38, lr: [0.008030786516042264], Loss: 2.135897, Acc:0.793502, Semantic loss: 0.807508, BCE loss: 0.553740, SB loss: 0.774648
2023-10-30 04:43:39,215 Epoch: [104/484] Iter:[340/495], Time: 0.38, lr: [0.008030401591554276], Loss: 2.131094, Acc:0.793806, Semantic loss: 0.805073, BCE loss: 0.553082, SB loss: 0.772939
2023-10-30 04:43:42,938 Epoch: [104/484] Iter:[350/495], Time: 0.38, lr: [0.008030016665016192], Loss: 2.133520, Acc:0.793037, Semantic loss: 0.809027, BCE loss: 0.550964, SB loss: 0.773528
2023-10-30 04:43:46,625 Epoch: [104/484] Iter:[360/495], Time: 0.38, lr: [0.008029631736427895], Loss: 2.132109, Acc:0.791444, Semantic loss: 0.809497, BCE loss: 0.549775, SB loss: 0.772837
2023-10-30 04:43:50,400 Epoch: [104/484] Iter:[370/495], Time: 0.38, lr: [0.008029246805789265], Loss: 2.134161, Acc:0.792561, Semantic loss: 0.808094, BCE loss: 0.552871, SB loss: 0.773197
2023-10-30 04:43:54,113 Epoch: [104/484] Iter:[380/495], Time: 0.38, lr: [0.008028861873100182], Loss: 2.129024, Acc:0.791945, Semantic loss: 0.804322, BCE loss: 0.552138, SB loss: 0.772565
2023-10-30 04:43:57,850 Epoch: [104/484] Iter:[390/495], Time: 0.37, lr: [0.008028476938360524], Loss: 2.123303, Acc:0.791487, Semantic loss: 0.801891, BCE loss: 0.550204, SB loss: 0.771208
2023-10-30 04:44:01,628 Epoch: [104/484] Iter:[400/495], Time: 0.38, lr: [0.008028092001570173], Loss: 2.127751, Acc:0.791793, Semantic loss: 0.804105, BCE loss: 0.550913, SB loss: 0.772732
2023-10-30 04:44:05,288 Epoch: [104/484] Iter:[410/495], Time: 0.37, lr: [0.008027707062729006], Loss: 2.125914, Acc:0.791416, Semantic loss: 0.802425, BCE loss: 0.550478, SB loss: 0.773010
2023-10-30 04:44:09,015 Epoch: [104/484] Iter:[420/495], Time: 0.37, lr: [0.008027322121836907], Loss: 2.125725, Acc:0.791406, Semantic loss: 0.802768, BCE loss: 0.550067, SB loss: 0.772889
2023-10-30 04:44:12,670 Epoch: [104/484] Iter:[430/495], Time: 0.37, lr: [0.008026937178893754], Loss: 2.124784, Acc:0.791699, Semantic loss: 0.801684, BCE loss: 0.550233, SB loss: 0.772866
2023-10-30 04:44:16,328 Epoch: [104/484] Iter:[440/495], Time: 0.37, lr: [0.008026552233899422], Loss: 2.123811, Acc:0.791145, Semantic loss: 0.801654, BCE loss: 0.550168, SB loss: 0.771989
2023-10-30 04:44:20,083 Epoch: [104/484] Iter:[450/495], Time: 0.37, lr: [0.008026167286853798], Loss: 2.127999, Acc:0.789959, Semantic loss: 0.806527, BCE loss: 0.549024, SB loss: 0.772447
2023-10-30 04:44:23,762 Epoch: [104/484] Iter:[460/495], Time: 0.37, lr: [0.008025782337756759], Loss: 2.130117, Acc:0.789625, Semantic loss: 0.807130, BCE loss: 0.549295, SB loss: 0.773692
2023-10-30 04:44:27,469 Epoch: [104/484] Iter:[470/495], Time: 0.37, lr: [0.008025397386608185], Loss: 2.132811, Acc:0.789894, Semantic loss: 0.807783, BCE loss: 0.550479, SB loss: 0.774549
2023-10-30 04:44:31,041 Epoch: [104/484] Iter:[480/495], Time: 0.37, lr: [0.008025012433407952], Loss: 2.137846, Acc:0.788957, Semantic loss: 0.810444, BCE loss: 0.551374, SB loss: 0.776028
2023-10-30 04:44:34,554 Epoch: [104/484] Iter:[490/495], Time: 0.37, lr: [0.008024627478155947], Loss: 2.142014, Acc:0.788722, Semantic loss: 0.812203, BCE loss: 0.552610, SB loss: 0.777201
2023-10-30 04:44:35,961 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:44:36,199 Loss: 2.081, MeanIU:  0.6795, Best_mIoU:  0.6907
2023-10-30 04:44:36,199 [0.97280057 0.79805769 0.9073032  0.24748778 0.50461018 0.548263
 0.63942769 0.72275105 0.90952512 0.5879679  0.93154246 0.72733147
 0.41922897 0.93266364 0.6267551  0.74399205 0.52781404 0.44796098
 0.7156338 ]
2023-10-30 04:44:38,513 Epoch: [105/484] Iter:[0/495], Time: 2.28, lr: [0.008024434999760488], Loss: 1.818676, Acc:0.757044, Semantic loss: 0.664583, BCE loss: 0.413505, SB loss: 0.740588
2023-10-30 04:44:42,379 Epoch: [105/484] Iter:[10/495], Time: 0.56, lr: [0.008024050041430591], Loss: 2.009116, Acc:0.804727, Semantic loss: 0.725143, BCE loss: 0.554999, SB loss: 0.728975
2023-10-30 04:44:46,036 Epoch: [105/484] Iter:[20/495], Time: 0.47, lr: [0.008023665081048618], Loss: 2.144706, Acc:0.787098, Semantic loss: 0.807587, BCE loss: 0.568044, SB loss: 0.769075
2023-10-30 04:44:49,746 Epoch: [105/484] Iter:[30/495], Time: 0.44, lr: [0.008023280118614447], Loss: 2.142932, Acc:0.789597, Semantic loss: 0.818771, BCE loss: 0.552273, SB loss: 0.771888
2023-10-30 04:44:53,321 Epoch: [105/484] Iter:[40/495], Time: 0.42, lr: [0.008022895154127959], Loss: 2.166171, Acc:0.791361, Semantic loss: 0.827165, BCE loss: 0.564089, SB loss: 0.774917
2023-10-30 04:44:57,101 Epoch: [105/484] Iter:[50/495], Time: 0.41, lr: [0.008022510187589035], Loss: 2.178225, Acc:0.789885, Semantic loss: 0.831673, BCE loss: 0.565814, SB loss: 0.780738
2023-10-30 04:45:00,778 Epoch: [105/484] Iter:[60/495], Time: 0.40, lr: [0.00802212521899755], Loss: 2.215209, Acc:0.787236, Semantic loss: 0.848702, BCE loss: 0.578916, SB loss: 0.787591
2023-10-30 04:45:04,405 Epoch: [105/484] Iter:[70/495], Time: 0.40, lr: [0.008021740248353386], Loss: 2.174031, Acc:0.789552, Semantic loss: 0.821025, BCE loss: 0.573661, SB loss: 0.779345
2023-10-30 04:45:08,016 Epoch: [105/484] Iter:[80/495], Time: 0.39, lr: [0.008021355275656424], Loss: 2.152188, Acc:0.788568, Semantic loss: 0.809998, BCE loss: 0.561717, SB loss: 0.780474
2023-10-30 04:45:11,697 Epoch: [105/484] Iter:[90/495], Time: 0.39, lr: [0.008020970300906543], Loss: 2.129551, Acc:0.789065, Semantic loss: 0.800203, BCE loss: 0.554717, SB loss: 0.774631
2023-10-30 04:45:15,366 Epoch: [105/484] Iter:[100/495], Time: 0.39, lr: [0.008020585324103621], Loss: 2.131365, Acc:0.794074, Semantic loss: 0.802566, BCE loss: 0.553121, SB loss: 0.775677
2023-10-30 04:45:19,092 Epoch: [105/484] Iter:[110/495], Time: 0.39, lr: [0.008020200345247539], Loss: 2.120485, Acc:0.791702, Semantic loss: 0.799490, BCE loss: 0.550282, SB loss: 0.770713
2023-10-30 04:45:22,770 Epoch: [105/484] Iter:[120/495], Time: 0.38, lr: [0.008019815364338177], Loss: 2.122328, Acc:0.794361, Semantic loss: 0.800746, BCE loss: 0.550334, SB loss: 0.771248
2023-10-30 04:45:26,439 Epoch: [105/484] Iter:[130/495], Time: 0.38, lr: [0.008019430381375413], Loss: 2.140697, Acc:0.793080, Semantic loss: 0.809512, BCE loss: 0.553634, SB loss: 0.777551
2023-10-30 04:45:30,130 Epoch: [105/484] Iter:[140/495], Time: 0.38, lr: [0.008019045396359128], Loss: 2.136979, Acc:0.796106, Semantic loss: 0.806014, BCE loss: 0.556028, SB loss: 0.774937
2023-10-30 04:45:33,727 Epoch: [105/484] Iter:[150/495], Time: 0.38, lr: [0.008018660409289198], Loss: 2.138607, Acc:0.796923, Semantic loss: 0.809779, BCE loss: 0.552430, SB loss: 0.776399
2023-10-30 04:45:37,302 Epoch: [105/484] Iter:[160/495], Time: 0.38, lr: [0.00801827542016551], Loss: 2.136202, Acc:0.796321, Semantic loss: 0.807420, BCE loss: 0.554723, SB loss: 0.774058
2023-10-30 04:45:40,959 Epoch: [105/484] Iter:[170/495], Time: 0.38, lr: [0.008017890428987935], Loss: 2.141935, Acc:0.797192, Semantic loss: 0.810559, BCE loss: 0.556060, SB loss: 0.775316
2023-10-30 04:45:44,610 Epoch: [105/484] Iter:[180/495], Time: 0.38, lr: [0.008017505435756358], Loss: 2.143078, Acc:0.797719, Semantic loss: 0.809518, BCE loss: 0.557658, SB loss: 0.775902
2023-10-30 04:45:48,340 Epoch: [105/484] Iter:[190/495], Time: 0.38, lr: [0.008017120440470656], Loss: 2.141691, Acc:0.796149, Semantic loss: 0.808096, BCE loss: 0.559014, SB loss: 0.774581
2023-10-30 04:45:51,966 Epoch: [105/484] Iter:[200/495], Time: 0.38, lr: [0.008016735443130708], Loss: 2.136017, Acc:0.796429, Semantic loss: 0.805233, BCE loss: 0.558332, SB loss: 0.772452
2023-10-30 04:45:55,690 Epoch: [105/484] Iter:[210/495], Time: 0.38, lr: [0.008016350443736397], Loss: 2.131577, Acc:0.796828, Semantic loss: 0.802885, BCE loss: 0.556577, SB loss: 0.772115
2023-10-30 04:45:59,518 Epoch: [105/484] Iter:[220/495], Time: 0.38, lr: [0.008015965442287599], Loss: 2.139262, Acc:0.798240, Semantic loss: 0.808548, BCE loss: 0.558647, SB loss: 0.772067
2023-10-30 04:46:03,278 Epoch: [105/484] Iter:[230/495], Time: 0.38, lr: [0.008015580438784193], Loss: 2.138790, Acc:0.798354, Semantic loss: 0.806330, BCE loss: 0.558872, SB loss: 0.773588
2023-10-30 04:46:06,988 Epoch: [105/484] Iter:[240/495], Time: 0.38, lr: [0.00801519543322606], Loss: 2.135595, Acc:0.799866, Semantic loss: 0.805299, BCE loss: 0.557574, SB loss: 0.772723
2023-10-30 04:46:10,628 Epoch: [105/484] Iter:[250/495], Time: 0.38, lr: [0.00801481042561308], Loss: 2.134094, Acc:0.799061, Semantic loss: 0.804735, BCE loss: 0.556222, SB loss: 0.773137
2023-10-30 04:46:14,381 Epoch: [105/484] Iter:[260/495], Time: 0.38, lr: [0.00801442541594513], Loss: 2.125550, Acc:0.799027, Semantic loss: 0.800640, BCE loss: 0.554966, SB loss: 0.769944
2023-10-30 04:46:17,956 Epoch: [105/484] Iter:[270/495], Time: 0.38, lr: [0.008014040404222092], Loss: 2.132082, Acc:0.798161, Semantic loss: 0.805844, BCE loss: 0.554707, SB loss: 0.771531
2023-10-30 04:46:21,669 Epoch: [105/484] Iter:[280/495], Time: 0.38, lr: [0.008013655390443844], Loss: 2.125641, Acc:0.797348, Semantic loss: 0.801668, BCE loss: 0.554634, SB loss: 0.769338
2023-10-30 04:46:25,276 Epoch: [105/484] Iter:[290/495], Time: 0.37, lr: [0.008013270374610266], Loss: 2.123029, Acc:0.796651, Semantic loss: 0.799720, BCE loss: 0.554692, SB loss: 0.768616
2023-10-30 04:46:28,935 Epoch: [105/484] Iter:[300/495], Time: 0.37, lr: [0.008012885356721235], Loss: 2.116341, Acc:0.796576, Semantic loss: 0.796947, BCE loss: 0.551930, SB loss: 0.767463
2023-10-30 04:46:32,589 Epoch: [105/484] Iter:[310/495], Time: 0.37, lr: [0.008012500336776633], Loss: 2.118510, Acc:0.796616, Semantic loss: 0.796933, BCE loss: 0.553778, SB loss: 0.767798
2023-10-30 04:46:36,288 Epoch: [105/484] Iter:[320/495], Time: 0.37, lr: [0.008012115314776337], Loss: 2.120223, Acc:0.796929, Semantic loss: 0.797518, BCE loss: 0.554538, SB loss: 0.768167
2023-10-30 04:46:40,003 Epoch: [105/484] Iter:[330/495], Time: 0.37, lr: [0.008011730290720229], Loss: 2.120420, Acc:0.796409, Semantic loss: 0.799462, BCE loss: 0.552444, SB loss: 0.768514
2023-10-30 04:46:43,757 Epoch: [105/484] Iter:[340/495], Time: 0.37, lr: [0.008011345264608186], Loss: 2.123497, Acc:0.796190, Semantic loss: 0.801100, BCE loss: 0.552694, SB loss: 0.769703
2023-10-30 04:46:47,399 Epoch: [105/484] Iter:[350/495], Time: 0.37, lr: [0.008010960236440087], Loss: 2.120268, Acc:0.796563, Semantic loss: 0.798897, BCE loss: 0.552980, SB loss: 0.768391
2023-10-30 04:46:51,100 Epoch: [105/484] Iter:[360/495], Time: 0.37, lr: [0.008010575206215816], Loss: 2.117802, Acc:0.795957, Semantic loss: 0.797247, BCE loss: 0.552481, SB loss: 0.768074
2023-10-30 04:46:54,708 Epoch: [105/484] Iter:[370/495], Time: 0.37, lr: [0.008010190173935245], Loss: 2.118266, Acc:0.796199, Semantic loss: 0.797077, BCE loss: 0.552775, SB loss: 0.768413
2023-10-30 04:46:58,486 Epoch: [105/484] Iter:[380/495], Time: 0.37, lr: [0.008009805139598257], Loss: 2.115341, Acc:0.796502, Semantic loss: 0.795186, BCE loss: 0.552982, SB loss: 0.767173
2023-10-30 04:47:02,246 Epoch: [105/484] Iter:[390/495], Time: 0.37, lr: [0.008009420103204733], Loss: 2.116135, Acc:0.797190, Semantic loss: 0.795921, BCE loss: 0.552839, SB loss: 0.767375
2023-10-30 04:47:05,952 Epoch: [105/484] Iter:[400/495], Time: 0.37, lr: [0.008009035064754547], Loss: 2.118562, Acc:0.798163, Semantic loss: 0.796690, BCE loss: 0.553628, SB loss: 0.768244
2023-10-30 04:47:09,607 Epoch: [105/484] Iter:[410/495], Time: 0.37, lr: [0.008008650024247582], Loss: 2.118148, Acc:0.797994, Semantic loss: 0.797212, BCE loss: 0.552442, SB loss: 0.768493
2023-10-30 04:47:13,263 Epoch: [105/484] Iter:[420/495], Time: 0.37, lr: [0.008008264981683718], Loss: 2.118668, Acc:0.798147, Semantic loss: 0.796989, BCE loss: 0.553436, SB loss: 0.768242
2023-10-30 04:47:16,952 Epoch: [105/484] Iter:[430/495], Time: 0.37, lr: [0.008007879937062829], Loss: 2.119529, Acc:0.798202, Semantic loss: 0.797611, BCE loss: 0.553735, SB loss: 0.768184
2023-10-30 04:47:20,645 Epoch: [105/484] Iter:[440/495], Time: 0.37, lr: [0.008007494890384801], Loss: 2.116847, Acc:0.797617, Semantic loss: 0.796717, BCE loss: 0.552379, SB loss: 0.767750
2023-10-30 04:47:24,376 Epoch: [105/484] Iter:[450/495], Time: 0.37, lr: [0.008007109841649509], Loss: 2.117143, Acc:0.797165, Semantic loss: 0.796464, BCE loss: 0.552632, SB loss: 0.768047
2023-10-30 04:47:28,095 Epoch: [105/484] Iter:[460/495], Time: 0.37, lr: [0.008006724790856831], Loss: 2.115520, Acc:0.797217, Semantic loss: 0.795379, BCE loss: 0.553057, SB loss: 0.767085
2023-10-30 04:47:31,770 Epoch: [105/484] Iter:[470/495], Time: 0.37, lr: [0.008006339738006648], Loss: 2.114611, Acc:0.797342, Semantic loss: 0.793984, BCE loss: 0.553780, SB loss: 0.766848
2023-10-30 04:47:35,464 Epoch: [105/484] Iter:[480/495], Time: 0.37, lr: [0.008005954683098839], Loss: 2.112598, Acc:0.796134, Semantic loss: 0.793901, BCE loss: 0.551825, SB loss: 0.766872
2023-10-30 04:47:38,941 Epoch: [105/484] Iter:[490/495], Time: 0.37, lr: [0.008005569626133283], Loss: 2.111192, Acc:0.796707, Semantic loss: 0.793535, BCE loss: 0.551291, SB loss: 0.766365
2023-10-30 04:50:35,309 0 [9.19471224e-01 5.78025868e-01 8.03231346e-01 1.18613333e-01
 2.28179300e-01 3.93132333e-01 4.08610817e-01 5.56632169e-01
 8.73044545e-01 4.36784302e-01 8.50557978e-01 4.33560820e-01
 3.31097555e-02 7.02388478e-01 2.53590663e-06 5.71050132e-02
 6.32584858e-02 2.29927439e-02 5.44056511e-01] 0.42225039768833383
2023-10-30 04:50:35,309 1 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352] 0.6483590037796034
2023-10-30 04:50:35,313 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:50:35,549 Loss: 2.173, MeanIU:  0.6484, Best_mIoU:  0.6907
2023-10-30 04:50:35,549 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352]
2023-10-30 04:50:37,626 Epoch: [106/484] Iter:[0/495], Time: 2.05, lr: [0.008005377096878813], Loss: 1.910756, Acc:0.749639, Semantic loss: 0.763969, BCE loss: 0.386376, SB loss: 0.760411
2023-10-30 04:50:41,434 Epoch: [106/484] Iter:[10/495], Time: 0.53, lr: [0.008004992036826409], Loss: 2.080852, Acc:0.760880, Semantic loss: 0.793685, BCE loss: 0.515897, SB loss: 0.771270
2023-10-30 04:50:45,022 Epoch: [106/484] Iter:[20/495], Time: 0.45, lr: [0.008004606974715956], Loss: 2.143612, Acc:0.785648, Semantic loss: 0.825591, BCE loss: 0.540948, SB loss: 0.777073
2023-10-30 04:50:48,451 Epoch: [106/484] Iter:[30/495], Time: 0.42, lr: [0.008004221910547334], Loss: 2.095986, Acc:0.783615, Semantic loss: 0.801834, BCE loss: 0.530817, SB loss: 0.763336
2023-10-30 04:50:51,840 Epoch: [106/484] Iter:[40/495], Time: 0.40, lr: [0.008003836844320418], Loss: 2.130765, Acc:0.781589, Semantic loss: 0.819020, BCE loss: 0.539637, SB loss: 0.772108
2023-10-30 04:50:55,366 Epoch: [106/484] Iter:[50/495], Time: 0.39, lr: [0.00800345177603509], Loss: 2.095154, Acc:0.776979, Semantic loss: 0.811317, BCE loss: 0.521375, SB loss: 0.762461
2023-10-30 04:50:58,898 Epoch: [106/484] Iter:[60/495], Time: 0.38, lr: [0.008003066705691229], Loss: 2.084582, Acc:0.786346, Semantic loss: 0.802598, BCE loss: 0.525462, SB loss: 0.756522
2023-10-30 04:51:02,506 Epoch: [106/484] Iter:[70/495], Time: 0.38, lr: [0.008002681633288712], Loss: 2.130763, Acc:0.788768, Semantic loss: 0.824186, BCE loss: 0.533520, SB loss: 0.773057
2023-10-30 04:51:05,980 Epoch: [106/484] Iter:[80/495], Time: 0.38, lr: [0.008002296558827419], Loss: 2.149160, Acc:0.790056, Semantic loss: 0.841444, BCE loss: 0.527665, SB loss: 0.780050
2023-10-30 04:51:09,487 Epoch: [106/484] Iter:[90/495], Time: 0.37, lr: [0.008001911482307231], Loss: 2.141956, Acc:0.789807, Semantic loss: 0.833682, BCE loss: 0.534343, SB loss: 0.773931
2023-10-30 04:51:13,115 Epoch: [106/484] Iter:[100/495], Time: 0.37, lr: [0.008001526403728023], Loss: 2.138576, Acc:0.791172, Semantic loss: 0.827389, BCE loss: 0.538864, SB loss: 0.772323
2023-10-30 04:51:16,743 Epoch: [106/484] Iter:[110/495], Time: 0.37, lr: [0.008001141323089678], Loss: 2.133512, Acc:0.791677, Semantic loss: 0.819119, BCE loss: 0.542746, SB loss: 0.771647
2023-10-30 04:51:20,340 Epoch: [106/484] Iter:[120/495], Time: 0.37, lr: [0.008000756240392072], Loss: 2.140577, Acc:0.792148, Semantic loss: 0.823647, BCE loss: 0.543874, SB loss: 0.773056
2023-10-30 04:51:24,004 Epoch: [106/484] Iter:[130/495], Time: 0.37, lr: [0.008000371155635084], Loss: 2.142126, Acc:0.792079, Semantic loss: 0.823182, BCE loss: 0.543934, SB loss: 0.775010
2023-10-30 04:51:27,566 Epoch: [106/484] Iter:[140/495], Time: 0.37, lr: [0.007999986068818592], Loss: 2.130215, Acc:0.793670, Semantic loss: 0.815394, BCE loss: 0.543376, SB loss: 0.771445
2023-10-30 04:51:31,184 Epoch: [106/484] Iter:[150/495], Time: 0.37, lr: [0.007999600979942477], Loss: 2.128045, Acc:0.793036, Semantic loss: 0.813128, BCE loss: 0.544531, SB loss: 0.770387
2023-10-30 04:51:34,903 Epoch: [106/484] Iter:[160/495], Time: 0.37, lr: [0.007999215889006619], Loss: 2.138574, Acc:0.793881, Semantic loss: 0.819344, BCE loss: 0.547106, SB loss: 0.772124
2023-10-30 04:51:38,420 Epoch: [106/484] Iter:[170/495], Time: 0.37, lr: [0.007998830796010895], Loss: 2.135010, Acc:0.794234, Semantic loss: 0.814867, BCE loss: 0.547560, SB loss: 0.772583
2023-10-30 04:51:42,032 Epoch: [106/484] Iter:[180/495], Time: 0.37, lr: [0.007998445700955181], Loss: 2.128273, Acc:0.794112, Semantic loss: 0.810270, BCE loss: 0.547009, SB loss: 0.770994
2023-10-30 04:51:45,771 Epoch: [106/484] Iter:[190/495], Time: 0.37, lr: [0.007998060603839362], Loss: 2.127033, Acc:0.795426, Semantic loss: 0.808097, BCE loss: 0.547728, SB loss: 0.771208
2023-10-30 04:51:49,528 Epoch: [106/484] Iter:[200/495], Time: 0.37, lr: [0.00799767550466331], Loss: 2.125275, Acc:0.796864, Semantic loss: 0.803540, BCE loss: 0.551532, SB loss: 0.770203
2023-10-30 04:51:53,126 Epoch: [106/484] Iter:[210/495], Time: 0.37, lr: [0.007997290403426907], Loss: 2.127602, Acc:0.798291, Semantic loss: 0.803622, BCE loss: 0.551889, SB loss: 0.772091
2023-10-30 04:51:56,827 Epoch: [106/484] Iter:[220/495], Time: 0.37, lr: [0.007996905300130034], Loss: 2.127881, Acc:0.799552, Semantic loss: 0.802825, BCE loss: 0.554822, SB loss: 0.770234
2023-10-30 04:52:00,444 Epoch: [106/484] Iter:[230/495], Time: 0.37, lr: [0.007996520194772566], Loss: 2.126696, Acc:0.799189, Semantic loss: 0.801526, BCE loss: 0.555190, SB loss: 0.769980
2023-10-30 04:52:04,097 Epoch: [106/484] Iter:[240/495], Time: 0.37, lr: [0.007996135087354384], Loss: 2.120674, Acc:0.797948, Semantic loss: 0.798992, BCE loss: 0.552819, SB loss: 0.768863
2023-10-30 04:52:07,682 Epoch: [106/484] Iter:[250/495], Time: 0.37, lr: [0.007995749977875366], Loss: 2.121136, Acc:0.798469, Semantic loss: 0.799772, BCE loss: 0.551482, SB loss: 0.769882
2023-10-30 04:52:11,272 Epoch: [106/484] Iter:[260/495], Time: 0.37, lr: [0.00799536486633539], Loss: 2.123370, Acc:0.797894, Semantic loss: 0.801753, BCE loss: 0.550387, SB loss: 0.771230
2023-10-30 04:52:14,967 Epoch: [106/484] Iter:[270/495], Time: 0.37, lr: [0.007994979752734336], Loss: 2.123157, Acc:0.796960, Semantic loss: 0.801873, BCE loss: 0.550816, SB loss: 0.770468
2023-10-30 04:52:18,681 Epoch: [106/484] Iter:[280/495], Time: 0.37, lr: [0.00799459463707208], Loss: 2.118535, Acc:0.797935, Semantic loss: 0.798603, BCE loss: 0.550278, SB loss: 0.769655
2023-10-30 04:52:22,222 Epoch: [106/484] Iter:[290/495], Time: 0.37, lr: [0.007994209519348504], Loss: 2.119914, Acc:0.797739, Semantic loss: 0.800569, BCE loss: 0.549366, SB loss: 0.769979
2023-10-30 04:52:25,887 Epoch: [106/484] Iter:[300/495], Time: 0.37, lr: [0.007993824399563485], Loss: 2.118224, Acc:0.796064, Semantic loss: 0.799478, BCE loss: 0.548710, SB loss: 0.770036
2023-10-30 04:52:29,567 Epoch: [106/484] Iter:[310/495], Time: 0.37, lr: [0.007993439277716901], Loss: 2.116557, Acc:0.796038, Semantic loss: 0.798750, BCE loss: 0.548231, SB loss: 0.769577
2023-10-30 04:52:33,307 Epoch: [106/484] Iter:[320/495], Time: 0.37, lr: [0.007993054153808632], Loss: 2.113595, Acc:0.796021, Semantic loss: 0.796768, BCE loss: 0.548424, SB loss: 0.768403
2023-10-30 04:52:36,973 Epoch: [106/484] Iter:[330/495], Time: 0.37, lr: [0.007992669027838555], Loss: 2.112048, Acc:0.796766, Semantic loss: 0.795920, BCE loss: 0.547985, SB loss: 0.768143
2023-10-30 04:52:40,578 Epoch: [106/484] Iter:[340/495], Time: 0.37, lr: [0.007992283899806552], Loss: 2.122284, Acc:0.795683, Semantic loss: 0.804485, BCE loss: 0.546619, SB loss: 0.771180
2023-10-30 04:52:44,196 Epoch: [106/484] Iter:[350/495], Time: 0.37, lr: [0.007991898769712496], Loss: 2.119701, Acc:0.794650, Semantic loss: 0.803596, BCE loss: 0.545731, SB loss: 0.770375
2023-10-30 04:52:47,914 Epoch: [106/484] Iter:[360/495], Time: 0.37, lr: [0.00799151363755627], Loss: 2.120177, Acc:0.793376, Semantic loss: 0.803343, BCE loss: 0.546881, SB loss: 0.769953
2023-10-30 04:52:51,529 Epoch: [106/484] Iter:[370/495], Time: 0.37, lr: [0.007991128503337752], Loss: 2.116946, Acc:0.794337, Semantic loss: 0.800467, BCE loss: 0.547889, SB loss: 0.768590
2023-10-30 04:52:55,156 Epoch: [106/484] Iter:[380/495], Time: 0.37, lr: [0.007990743367056819], Loss: 2.121295, Acc:0.794970, Semantic loss: 0.803900, BCE loss: 0.548332, SB loss: 0.769064
2023-10-30 04:52:58,759 Epoch: [106/484] Iter:[390/495], Time: 0.37, lr: [0.00799035822871335], Loss: 2.122763, Acc:0.794758, Semantic loss: 0.804024, BCE loss: 0.549379, SB loss: 0.769361
2023-10-30 04:53:02,426 Epoch: [106/484] Iter:[400/495], Time: 0.37, lr: [0.007989973088307224], Loss: 2.122043, Acc:0.795137, Semantic loss: 0.803104, BCE loss: 0.549739, SB loss: 0.769200
2023-10-30 04:53:06,090 Epoch: [106/484] Iter:[410/495], Time: 0.37, lr: [0.007989587945838319], Loss: 2.126186, Acc:0.794909, Semantic loss: 0.805898, BCE loss: 0.549301, SB loss: 0.770987
2023-10-30 04:53:09,680 Epoch: [106/484] Iter:[420/495], Time: 0.37, lr: [0.007989202801306513], Loss: 2.124631, Acc:0.793987, Semantic loss: 0.804267, BCE loss: 0.549350, SB loss: 0.771014
2023-10-30 04:53:13,234 Epoch: [106/484] Iter:[430/495], Time: 0.37, lr: [0.007988817654711686], Loss: 2.127582, Acc:0.793650, Semantic loss: 0.806625, BCE loss: 0.549395, SB loss: 0.771562
2023-10-30 04:53:16,820 Epoch: [106/484] Iter:[440/495], Time: 0.37, lr: [0.007988432506053715], Loss: 2.123803, Acc:0.793945, Semantic loss: 0.804536, BCE loss: 0.548732, SB loss: 0.770535
2023-10-30 04:53:20,445 Epoch: [106/484] Iter:[450/495], Time: 0.37, lr: [0.007988047355332479], Loss: 2.126190, Acc:0.793220, Semantic loss: 0.804933, BCE loss: 0.550696, SB loss: 0.770561
2023-10-30 04:53:24,061 Epoch: [106/484] Iter:[460/495], Time: 0.37, lr: [0.007987662202547856], Loss: 2.121789, Acc:0.793810, Semantic loss: 0.802855, BCE loss: 0.550006, SB loss: 0.768928
2023-10-30 04:53:27,615 Epoch: [106/484] Iter:[470/495], Time: 0.37, lr: [0.007987277047699725], Loss: 2.124125, Acc:0.793928, Semantic loss: 0.804156, BCE loss: 0.550633, SB loss: 0.769336
2023-10-30 04:53:31,255 Epoch: [106/484] Iter:[480/495], Time: 0.37, lr: [0.007986891890787964], Loss: 2.132140, Acc:0.793469, Semantic loss: 0.810823, BCE loss: 0.549674, SB loss: 0.771643
2023-10-30 04:53:34,726 Epoch: [106/484] Iter:[490/495], Time: 0.36, lr: [0.007986506731812454], Loss: 2.131682, Acc:0.792778, Semantic loss: 0.810653, BCE loss: 0.549511, SB loss: 0.771517
2023-10-30 04:53:36,138 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:53:36,378 Loss: 2.173, MeanIU:  0.6484, Best_mIoU:  0.6907
2023-10-30 04:53:36,378 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352]
2023-10-30 04:53:38,406 Epoch: [107/484] Iter:[0/495], Time: 1.99, lr: [0.007986314151550752], Loss: 1.833776, Acc:0.735879, Semantic loss: 0.588067, BCE loss: 0.522213, SB loss: 0.723496
2023-10-30 04:53:42,464 Epoch: [107/484] Iter:[10/495], Time: 0.55, lr: [0.007985928989479384], Loss: 2.098513, Acc:0.787880, Semantic loss: 0.754612, BCE loss: 0.551407, SB loss: 0.792493
2023-10-30 04:53:46,294 Epoch: [107/484] Iter:[20/495], Time: 0.47, lr: [0.007985543825343961], Loss: 2.097639, Acc:0.809800, Semantic loss: 0.753551, BCE loss: 0.565725, SB loss: 0.778363
2023-10-30 04:53:50,100 Epoch: [107/484] Iter:[30/495], Time: 0.44, lr: [0.00798515865914436], Loss: 2.071235, Acc:0.811829, Semantic loss: 0.753532, BCE loss: 0.550928, SB loss: 0.766776
2023-10-30 04:53:53,817 Epoch: [107/484] Iter:[40/495], Time: 0.42, lr: [0.00798477349088046], Loss: 2.092863, Acc:0.815806, Semantic loss: 0.759263, BCE loss: 0.557851, SB loss: 0.775749
2023-10-30 04:53:57,378 Epoch: [107/484] Iter:[50/495], Time: 0.41, lr: [0.007984388320552139], Loss: 2.073839, Acc:0.814736, Semantic loss: 0.752697, BCE loss: 0.560646, SB loss: 0.760496
2023-10-30 04:54:00,961 Epoch: [107/484] Iter:[60/495], Time: 0.40, lr: [0.007984003148159278], Loss: 2.104385, Acc:0.809212, Semantic loss: 0.774223, BCE loss: 0.563590, SB loss: 0.766572
2023-10-30 04:54:04,578 Epoch: [107/484] Iter:[70/495], Time: 0.40, lr: [0.007983617973701751], Loss: 2.104005, Acc:0.807067, Semantic loss: 0.775988, BCE loss: 0.561295, SB loss: 0.766721
2023-10-30 04:54:08,401 Epoch: [107/484] Iter:[80/495], Time: 0.39, lr: [0.007983232797179439], Loss: 2.082248, Acc:0.807962, Semantic loss: 0.764646, BCE loss: 0.553671, SB loss: 0.763931
2023-10-30 04:54:12,096 Epoch: [107/484] Iter:[90/495], Time: 0.39, lr: [0.007982847618592219], Loss: 2.101934, Acc:0.807980, Semantic loss: 0.779467, BCE loss: 0.556945, SB loss: 0.765522
2023-10-30 04:54:15,787 Epoch: [107/484] Iter:[100/495], Time: 0.39, lr: [0.007982462437939966], Loss: 2.105668, Acc:0.808091, Semantic loss: 0.782658, BCE loss: 0.557715, SB loss: 0.765295
2023-10-30 04:54:19,461 Epoch: [107/484] Iter:[110/495], Time: 0.39, lr: [0.007982077255222566], Loss: 2.105974, Acc:0.808778, Semantic loss: 0.783301, BCE loss: 0.556706, SB loss: 0.765967
2023-10-30 04:54:23,028 Epoch: [107/484] Iter:[120/495], Time: 0.39, lr: [0.007981692070439892], Loss: 2.111905, Acc:0.804124, Semantic loss: 0.791445, BCE loss: 0.552464, SB loss: 0.767996
2023-10-30 04:54:26,774 Epoch: [107/484] Iter:[130/495], Time: 0.38, lr: [0.007981306883591822], Loss: 2.095175, Acc:0.801791, Semantic loss: 0.781661, BCE loss: 0.549169, SB loss: 0.764345
2023-10-30 04:54:30,389 Epoch: [107/484] Iter:[140/495], Time: 0.38, lr: [0.007980921694678237], Loss: 2.103096, Acc:0.803310, Semantic loss: 0.785382, BCE loss: 0.551260, SB loss: 0.766454
2023-10-30 04:54:34,063 Epoch: [107/484] Iter:[150/495], Time: 0.38, lr: [0.007980536503699013], Loss: 2.107312, Acc:0.806210, Semantic loss: 0.788689, BCE loss: 0.552359, SB loss: 0.766264
2023-10-30 04:54:37,762 Epoch: [107/484] Iter:[160/495], Time: 0.38, lr: [0.007980151310654028], Loss: 2.112851, Acc:0.805510, Semantic loss: 0.794396, BCE loss: 0.551886, SB loss: 0.766570
2023-10-30 04:54:41,438 Epoch: [107/484] Iter:[170/495], Time: 0.38, lr: [0.007979766115543161], Loss: 2.122250, Acc:0.804142, Semantic loss: 0.797839, BCE loss: 0.555501, SB loss: 0.768910
2023-10-30 04:54:45,123 Epoch: [107/484] Iter:[180/495], Time: 0.38, lr: [0.007979380918366289], Loss: 2.111821, Acc:0.801336, Semantic loss: 0.792658, BCE loss: 0.551158, SB loss: 0.768006
2023-10-30 04:54:48,787 Epoch: [107/484] Iter:[190/495], Time: 0.38, lr: [0.007978995719123291], Loss: 2.109749, Acc:0.802130, Semantic loss: 0.790912, BCE loss: 0.552444, SB loss: 0.766393
2023-10-30 04:54:52,350 Epoch: [107/484] Iter:[200/495], Time: 0.38, lr: [0.007978610517814047], Loss: 2.102418, Acc:0.801522, Semantic loss: 0.787427, BCE loss: 0.549225, SB loss: 0.765766
2023-10-30 04:54:55,972 Epoch: [107/484] Iter:[210/495], Time: 0.38, lr: [0.007978225314438432], Loss: 2.102180, Acc:0.801190, Semantic loss: 0.786940, BCE loss: 0.549503, SB loss: 0.765737
2023-10-30 04:54:59,597 Epoch: [107/484] Iter:[220/495], Time: 0.38, lr: [0.007977840108996324], Loss: 2.110414, Acc:0.798807, Semantic loss: 0.793613, BCE loss: 0.548671, SB loss: 0.768129
2023-10-30 04:55:03,263 Epoch: [107/484] Iter:[230/495], Time: 0.38, lr: [0.007977454901487603], Loss: 2.120458, Acc:0.796083, Semantic loss: 0.801986, BCE loss: 0.548542, SB loss: 0.769929
2023-10-30 04:55:06,948 Epoch: [107/484] Iter:[240/495], Time: 0.38, lr: [0.007977069691912149], Loss: 2.120446, Acc:0.795884, Semantic loss: 0.801784, BCE loss: 0.549733, SB loss: 0.768929
2023-10-30 04:55:10,653 Epoch: [107/484] Iter:[250/495], Time: 0.38, lr: [0.007976684480269834], Loss: 2.117409, Acc:0.795982, Semantic loss: 0.799647, BCE loss: 0.548940, SB loss: 0.768823
2023-10-30 04:55:14,307 Epoch: [107/484] Iter:[260/495], Time: 0.38, lr: [0.00797629926656054], Loss: 2.135579, Acc:0.793919, Semantic loss: 0.813514, BCE loss: 0.550180, SB loss: 0.771884
2023-10-30 04:55:18,022 Epoch: [107/484] Iter:[270/495], Time: 0.37, lr: [0.007975914050784145], Loss: 2.130818, Acc:0.794587, Semantic loss: 0.809969, BCE loss: 0.549212, SB loss: 0.771638
2023-10-30 04:55:21,772 Epoch: [107/484] Iter:[280/495], Time: 0.37, lr: [0.007975528832940525], Loss: 2.128706, Acc:0.794481, Semantic loss: 0.808448, BCE loss: 0.548741, SB loss: 0.771517
2023-10-30 04:55:25,477 Epoch: [107/484] Iter:[290/495], Time: 0.37, lr: [0.00797514361302956], Loss: 2.128571, Acc:0.795913, Semantic loss: 0.806869, BCE loss: 0.550588, SB loss: 0.771114
2023-10-30 04:55:29,065 Epoch: [107/484] Iter:[300/495], Time: 0.37, lr: [0.007974758391051127], Loss: 2.127920, Acc:0.795362, Semantic loss: 0.806643, BCE loss: 0.549864, SB loss: 0.771413
2023-10-30 04:55:32,753 Epoch: [107/484] Iter:[310/495], Time: 0.37, lr: [0.007974373167005104], Loss: 2.127067, Acc:0.794756, Semantic loss: 0.806470, BCE loss: 0.547996, SB loss: 0.772600
2023-10-30 04:55:36,406 Epoch: [107/484] Iter:[320/495], Time: 0.37, lr: [0.00797398794089137], Loss: 2.129244, Acc:0.795006, Semantic loss: 0.807002, BCE loss: 0.549034, SB loss: 0.773207
2023-10-30 04:55:40,091 Epoch: [107/484] Iter:[330/495], Time: 0.37, lr: [0.0079736027127098], Loss: 2.130396, Acc:0.795442, Semantic loss: 0.807105, BCE loss: 0.550535, SB loss: 0.772757
2023-10-30 04:55:43,779 Epoch: [107/484] Iter:[340/495], Time: 0.37, lr: [0.007973217482460274], Loss: 2.130860, Acc:0.795660, Semantic loss: 0.807174, BCE loss: 0.551078, SB loss: 0.772607
2023-10-30 04:55:47,497 Epoch: [107/484] Iter:[350/495], Time: 0.37, lr: [0.007972832250142671], Loss: 2.134450, Acc:0.796237, Semantic loss: 0.808857, BCE loss: 0.552402, SB loss: 0.773191
2023-10-30 04:55:51,079 Epoch: [107/484] Iter:[360/495], Time: 0.37, lr: [0.007972447015756869], Loss: 2.128655, Acc:0.794829, Semantic loss: 0.805423, BCE loss: 0.550170, SB loss: 0.773062
2023-10-30 04:55:54,737 Epoch: [107/484] Iter:[370/495], Time: 0.37, lr: [0.007972061779302741], Loss: 2.129598, Acc:0.794233, Semantic loss: 0.806771, BCE loss: 0.548711, SB loss: 0.774116
2023-10-30 04:55:58,456 Epoch: [107/484] Iter:[380/495], Time: 0.37, lr: [0.00797167654078017], Loss: 2.124432, Acc:0.794079, Semantic loss: 0.804039, BCE loss: 0.547483, SB loss: 0.772910
2023-10-30 04:56:02,110 Epoch: [107/484] Iter:[390/495], Time: 0.37, lr: [0.007971291300189032], Loss: 2.126649, Acc:0.794429, Semantic loss: 0.805592, BCE loss: 0.547621, SB loss: 0.773436
2023-10-30 04:56:05,715 Epoch: [107/484] Iter:[400/495], Time: 0.37, lr: [0.007970906057529205], Loss: 2.125154, Acc:0.795038, Semantic loss: 0.804494, BCE loss: 0.547785, SB loss: 0.772875
2023-10-30 04:56:09,361 Epoch: [107/484] Iter:[410/495], Time: 0.37, lr: [0.007970520812800566], Loss: 2.122017, Acc:0.794935, Semantic loss: 0.804035, BCE loss: 0.546530, SB loss: 0.771452
2023-10-30 04:56:12,975 Epoch: [107/484] Iter:[420/495], Time: 0.37, lr: [0.007970135566002994], Loss: 2.118061, Acc:0.794883, Semantic loss: 0.802035, BCE loss: 0.545466, SB loss: 0.770560
2023-10-30 04:56:16,621 Epoch: [107/484] Iter:[430/495], Time: 0.37, lr: [0.007969750317136367], Loss: 2.117546, Acc:0.794290, Semantic loss: 0.801609, BCE loss: 0.545543, SB loss: 0.770393
2023-10-30 04:56:20,338 Epoch: [107/484] Iter:[440/495], Time: 0.37, lr: [0.007969365066200561], Loss: 2.115574, Acc:0.794421, Semantic loss: 0.801274, BCE loss: 0.544644, SB loss: 0.769656
2023-10-30 04:56:23,972 Epoch: [107/484] Iter:[450/495], Time: 0.37, lr: [0.007968979813195455], Loss: 2.116224, Acc:0.794550, Semantic loss: 0.801446, BCE loss: 0.544466, SB loss: 0.770312
2023-10-30 04:56:27,573 Epoch: [107/484] Iter:[460/495], Time: 0.37, lr: [0.007968594558120927], Loss: 2.116534, Acc:0.794088, Semantic loss: 0.801897, BCE loss: 0.544287, SB loss: 0.770351
2023-10-30 04:56:31,203 Epoch: [107/484] Iter:[470/495], Time: 0.37, lr: [0.007968209300976855], Loss: 2.111606, Acc:0.794065, Semantic loss: 0.799718, BCE loss: 0.542474, SB loss: 0.769414
2023-10-30 04:56:34,840 Epoch: [107/484] Iter:[480/495], Time: 0.37, lr: [0.007967824041763114], Loss: 2.113825, Acc:0.794346, Semantic loss: 0.801952, BCE loss: 0.541922, SB loss: 0.769951
2023-10-30 04:56:38,339 Epoch: [107/484] Iter:[490/495], Time: 0.37, lr: [0.007967438780479584], Loss: 2.116211, Acc:0.793989, Semantic loss: 0.802976, BCE loss: 0.542453, SB loss: 0.770782
2023-10-30 04:56:39,743 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:56:39,986 Loss: 2.173, MeanIU:  0.6484, Best_mIoU:  0.6907
2023-10-30 04:56:39,986 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352]
2023-10-30 04:56:42,290 Epoch: [108/484] Iter:[0/495], Time: 2.27, lr: [0.00796724614906161], Loss: 2.681712, Acc:0.868190, Semantic loss: 1.013037, BCE loss: 0.885989, SB loss: 0.782686
2023-10-30 04:56:46,152 Epoch: [108/484] Iter:[10/495], Time: 0.56, lr: [0.007966860884673167], Loss: 2.428479, Acc:0.783003, Semantic loss: 1.028673, BCE loss: 0.586274, SB loss: 0.813533
2023-10-30 04:56:49,817 Epoch: [108/484] Iter:[20/495], Time: 0.47, lr: [0.00796647561821463], Loss: 2.318617, Acc:0.768996, Semantic loss: 0.973707, BCE loss: 0.541830, SB loss: 0.803081
2023-10-30 04:56:53,501 Epoch: [108/484] Iter:[30/495], Time: 0.43, lr: [0.007966090349685873], Loss: 2.250495, Acc:0.777920, Semantic loss: 0.899952, BCE loss: 0.545685, SB loss: 0.804857
2023-10-30 04:56:57,081 Epoch: [108/484] Iter:[40/495], Time: 0.42, lr: [0.007965705079086777], Loss: 2.343706, Acc:0.766853, Semantic loss: 0.982067, BCE loss: 0.539578, SB loss: 0.822061
2023-10-30 04:57:00,809 Epoch: [108/484] Iter:[50/495], Time: 0.41, lr: [0.007965319806417218], Loss: 2.278825, Acc:0.763274, Semantic loss: 0.937258, BCE loss: 0.530285, SB loss: 0.811281
2023-10-30 04:57:04,493 Epoch: [108/484] Iter:[60/495], Time: 0.40, lr: [0.007964934531677076], Loss: 2.272612, Acc:0.770733, Semantic loss: 0.921185, BCE loss: 0.547002, SB loss: 0.804425
2023-10-30 04:57:08,154 Epoch: [108/484] Iter:[70/495], Time: 0.40, lr: [0.007964549254866225], Loss: 2.240303, Acc:0.773192, Semantic loss: 0.890731, BCE loss: 0.549748, SB loss: 0.799824
2023-10-30 04:57:11,857 Epoch: [108/484] Iter:[80/495], Time: 0.39, lr: [0.007964163975984545], Loss: 2.245784, Acc:0.774124, Semantic loss: 0.890875, BCE loss: 0.555020, SB loss: 0.799890
2023-10-30 04:57:15,647 Epoch: [108/484] Iter:[90/495], Time: 0.39, lr: [0.007963778695031913], Loss: 2.252449, Acc:0.774003, Semantic loss: 0.896752, BCE loss: 0.558192, SB loss: 0.797505
2023-10-30 04:57:19,305 Epoch: [108/484] Iter:[100/495], Time: 0.39, lr: [0.007963393412008208], Loss: 2.234580, Acc:0.775720, Semantic loss: 0.884993, BCE loss: 0.559294, SB loss: 0.790292
2023-10-30 04:57:23,114 Epoch: [108/484] Iter:[110/495], Time: 0.39, lr: [0.007963008126913303], Loss: 2.230582, Acc:0.778653, Semantic loss: 0.878953, BCE loss: 0.561531, SB loss: 0.790097
2023-10-30 04:57:26,854 Epoch: [108/484] Iter:[120/495], Time: 0.39, lr: [0.007962622839747082], Loss: 2.234822, Acc:0.780353, Semantic loss: 0.881852, BCE loss: 0.557987, SB loss: 0.794984
2023-10-30 04:57:30,462 Epoch: [108/484] Iter:[130/495], Time: 0.39, lr: [0.007962237550509416], Loss: 2.251551, Acc:0.779776, Semantic loss: 0.891639, BCE loss: 0.557663, SB loss: 0.802249
2023-10-30 04:57:34,164 Epoch: [108/484] Iter:[140/495], Time: 0.38, lr: [0.00796185225920019], Loss: 2.247664, Acc:0.782836, Semantic loss: 0.885735, BCE loss: 0.559477, SB loss: 0.802452
2023-10-30 04:57:37,788 Epoch: [108/484] Iter:[150/495], Time: 0.38, lr: [0.007961466965819272], Loss: 2.258259, Acc:0.781891, Semantic loss: 0.891812, BCE loss: 0.557368, SB loss: 0.809079
2023-10-30 04:57:41,427 Epoch: [108/484] Iter:[160/495], Time: 0.38, lr: [0.007961081670366547], Loss: 2.249971, Acc:0.780487, Semantic loss: 0.886775, BCE loss: 0.556170, SB loss: 0.807026
2023-10-30 04:57:45,166 Epoch: [108/484] Iter:[170/495], Time: 0.38, lr: [0.007960696372841889], Loss: 2.244003, Acc:0.781221, Semantic loss: 0.881703, BCE loss: 0.554507, SB loss: 0.807793
2023-10-30 04:57:48,813 Epoch: [108/484] Iter:[180/495], Time: 0.38, lr: [0.007960311073245177], Loss: 2.236512, Acc:0.781692, Semantic loss: 0.874631, BCE loss: 0.556708, SB loss: 0.805173
2023-10-30 04:57:52,436 Epoch: [108/484] Iter:[190/495], Time: 0.38, lr: [0.007959925771576287], Loss: 2.231150, Acc:0.781930, Semantic loss: 0.870044, BCE loss: 0.556675, SB loss: 0.804432
2023-10-30 04:57:56,155 Epoch: [108/484] Iter:[200/495], Time: 0.38, lr: [0.007959540467835096], Loss: 2.219229, Acc:0.782447, Semantic loss: 0.862784, BCE loss: 0.555526, SB loss: 0.800920
2023-10-30 04:57:59,890 Epoch: [108/484] Iter:[210/495], Time: 0.38, lr: [0.007959155162021486], Loss: 2.210568, Acc:0.784405, Semantic loss: 0.857708, BCE loss: 0.555403, SB loss: 0.797457
2023-10-30 04:58:03,573 Epoch: [108/484] Iter:[220/495], Time: 0.38, lr: [0.00795876985413533], Loss: 2.215005, Acc:0.785866, Semantic loss: 0.859170, BCE loss: 0.557950, SB loss: 0.797885
2023-10-30 04:58:07,271 Epoch: [108/484] Iter:[230/495], Time: 0.38, lr: [0.007958384544176505], Loss: 2.209728, Acc:0.787292, Semantic loss: 0.855784, BCE loss: 0.558276, SB loss: 0.795668
2023-10-30 04:58:10,920 Epoch: [108/484] Iter:[240/495], Time: 0.38, lr: [0.007957999232144889], Loss: 2.209380, Acc:0.786894, Semantic loss: 0.854905, BCE loss: 0.558343, SB loss: 0.796133
2023-10-30 04:58:14,639 Epoch: [108/484] Iter:[250/495], Time: 0.38, lr: [0.007957613918040361], Loss: 2.201431, Acc:0.787868, Semantic loss: 0.850107, BCE loss: 0.558810, SB loss: 0.792514
2023-10-30 04:58:18,340 Epoch: [108/484] Iter:[260/495], Time: 0.38, lr: [0.007957228601862798], Loss: 2.192287, Acc:0.787966, Semantic loss: 0.845815, BCE loss: 0.556526, SB loss: 0.789946
2023-10-30 04:58:22,011 Epoch: [108/484] Iter:[270/495], Time: 0.38, lr: [0.007956843283612076], Loss: 2.185807, Acc:0.787118, Semantic loss: 0.842678, BCE loss: 0.554008, SB loss: 0.789120
2023-10-30 04:58:25,661 Epoch: [108/484] Iter:[280/495], Time: 0.38, lr: [0.007956457963288073], Loss: 2.185358, Acc:0.788055, Semantic loss: 0.841912, BCE loss: 0.554492, SB loss: 0.788954
2023-10-30 04:58:29,344 Epoch: [108/484] Iter:[290/495], Time: 0.38, lr: [0.007956072640890667], Loss: 2.182617, Acc:0.788357, Semantic loss: 0.841848, BCE loss: 0.553675, SB loss: 0.787094
2023-10-30 04:58:32,966 Epoch: [108/484] Iter:[300/495], Time: 0.38, lr: [0.007955687316419734], Loss: 2.182103, Acc:0.788710, Semantic loss: 0.842029, BCE loss: 0.554376, SB loss: 0.785698
2023-10-30 04:58:36,620 Epoch: [108/484] Iter:[310/495], Time: 0.37, lr: [0.00795530198987515], Loss: 2.172347, Acc:0.788816, Semantic loss: 0.836301, BCE loss: 0.553070, SB loss: 0.782976
2023-10-30 04:58:40,336 Epoch: [108/484] Iter:[320/495], Time: 0.37, lr: [0.007954916661256795], Loss: 2.167965, Acc:0.788553, Semantic loss: 0.833542, BCE loss: 0.552667, SB loss: 0.781755
2023-10-30 04:58:44,013 Epoch: [108/484] Iter:[330/495], Time: 0.37, lr: [0.007954531330564545], Loss: 2.171066, Acc:0.789408, Semantic loss: 0.834574, BCE loss: 0.553938, SB loss: 0.782554
2023-10-30 04:58:47,678 Epoch: [108/484] Iter:[340/495], Time: 0.37, lr: [0.00795414599779828], Loss: 2.165708, Acc:0.788886, Semantic loss: 0.833232, BCE loss: 0.550914, SB loss: 0.781562
2023-10-30 04:58:51,424 Epoch: [108/484] Iter:[350/495], Time: 0.37, lr: [0.007953760662957872], Loss: 2.164225, Acc:0.789852, Semantic loss: 0.831406, BCE loss: 0.551651, SB loss: 0.781167
2023-10-30 04:58:55,198 Epoch: [108/484] Iter:[360/495], Time: 0.37, lr: [0.007953375326043201], Loss: 2.162063, Acc:0.790224, Semantic loss: 0.829883, BCE loss: 0.550737, SB loss: 0.781443
2023-10-30 04:58:58,980 Epoch: [108/484] Iter:[370/495], Time: 0.37, lr: [0.007952989987054144], Loss: 2.159538, Acc:0.791399, Semantic loss: 0.827801, BCE loss: 0.550597, SB loss: 0.781140
2023-10-30 04:59:02,732 Epoch: [108/484] Iter:[380/495], Time: 0.37, lr: [0.007952604645990579], Loss: 2.162935, Acc:0.791808, Semantic loss: 0.828381, BCE loss: 0.553151, SB loss: 0.781403
2023-10-30 04:59:06,438 Epoch: [108/484] Iter:[390/495], Time: 0.37, lr: [0.007952219302852382], Loss: 2.163985, Acc:0.792347, Semantic loss: 0.827164, BCE loss: 0.555081, SB loss: 0.781740
2023-10-30 04:59:10,193 Epoch: [108/484] Iter:[400/495], Time: 0.37, lr: [0.00795183395763943], Loss: 2.162123, Acc:0.792836, Semantic loss: 0.826773, BCE loss: 0.554022, SB loss: 0.781328
2023-10-30 04:59:13,820 Epoch: [108/484] Iter:[410/495], Time: 0.37, lr: [0.0079514486103516], Loss: 2.162154, Acc:0.792655, Semantic loss: 0.825982, BCE loss: 0.554851, SB loss: 0.781321
2023-10-30 04:59:17,523 Epoch: [108/484] Iter:[420/495], Time: 0.37, lr: [0.007951063260988772], Loss: 2.160755, Acc:0.792514, Semantic loss: 0.823615, BCE loss: 0.556493, SB loss: 0.780646
2023-10-30 04:59:21,139 Epoch: [108/484] Iter:[430/495], Time: 0.37, lr: [0.007950677909550818], Loss: 2.157455, Acc:0.792781, Semantic loss: 0.821953, BCE loss: 0.555899, SB loss: 0.779603
2023-10-30 04:59:24,789 Epoch: [108/484] Iter:[440/495], Time: 0.37, lr: [0.007950292556037618], Loss: 2.157150, Acc:0.792895, Semantic loss: 0.822617, BCE loss: 0.554932, SB loss: 0.779600
2023-10-30 04:59:28,576 Epoch: [108/484] Iter:[450/495], Time: 0.37, lr: [0.00794990720044905], Loss: 2.157851, Acc:0.792812, Semantic loss: 0.823726, BCE loss: 0.554823, SB loss: 0.779302
2023-10-30 04:59:32,310 Epoch: [108/484] Iter:[460/495], Time: 0.37, lr: [0.007949521842784989], Loss: 2.157341, Acc:0.792308, Semantic loss: 0.822567, BCE loss: 0.555172, SB loss: 0.779601
2023-10-30 04:59:35,989 Epoch: [108/484] Iter:[470/495], Time: 0.37, lr: [0.007949136483045315], Loss: 2.154889, Acc:0.791958, Semantic loss: 0.821178, BCE loss: 0.554504, SB loss: 0.779207
2023-10-30 04:59:39,619 Epoch: [108/484] Iter:[480/495], Time: 0.37, lr: [0.0079487511212299], Loss: 2.156109, Acc:0.791454, Semantic loss: 0.823067, BCE loss: 0.553402, SB loss: 0.779639
2023-10-30 04:59:43,203 Epoch: [108/484] Iter:[490/495], Time: 0.37, lr: [0.007948365757338623], Loss: 2.154541, Acc:0.791403, Semantic loss: 0.822352, BCE loss: 0.553086, SB loss: 0.779102
2023-10-30 04:59:44,582 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 04:59:44,827 Loss: 2.173, MeanIU:  0.6484, Best_mIoU:  0.6907
2023-10-30 04:59:44,828 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352]
2023-10-30 04:59:46,652 Epoch: [109/484] Iter:[0/495], Time: 1.79, lr: [0.0079481730746145], Loss: 1.759520, Acc:0.692242, Semantic loss: 0.565383, BCE loss: 0.476907, SB loss: 0.717230
2023-10-30 04:59:50,629 Epoch: [109/484] Iter:[10/495], Time: 0.52, lr: [0.007947787707609202], Loss: 1.940310, Acc:0.776388, Semantic loss: 0.719632, BCE loss: 0.486743, SB loss: 0.733935
2023-10-30 04:59:54,296 Epoch: [109/484] Iter:[20/495], Time: 0.45, lr: [0.007947402338527736], Loss: 1.980368, Acc:0.786759, Semantic loss: 0.747689, BCE loss: 0.483716, SB loss: 0.748962
2023-10-30 04:59:57,914 Epoch: [109/484] Iter:[30/495], Time: 0.42, lr: [0.007947016967369979], Loss: 1.980908, Acc:0.773181, Semantic loss: 0.755393, BCE loss: 0.477757, SB loss: 0.747758
2023-10-30 05:00:01,599 Epoch: [109/484] Iter:[40/495], Time: 0.41, lr: [0.007946631594135807], Loss: 1.968172, Acc:0.781024, Semantic loss: 0.747683, BCE loss: 0.480826, SB loss: 0.739663
2023-10-30 05:00:05,230 Epoch: [109/484] Iter:[50/495], Time: 0.40, lr: [0.007946246218825097], Loss: 1.990310, Acc:0.781293, Semantic loss: 0.754847, BCE loss: 0.487715, SB loss: 0.747748
2023-10-30 05:00:08,852 Epoch: [109/484] Iter:[60/495], Time: 0.39, lr: [0.007945860841437726], Loss: 1.997554, Acc:0.780149, Semantic loss: 0.772715, BCE loss: 0.476897, SB loss: 0.747942
2023-10-30 05:00:12,734 Epoch: [109/484] Iter:[70/495], Time: 0.39, lr: [0.007945475461973571], Loss: 2.003596, Acc:0.782680, Semantic loss: 0.774249, BCE loss: 0.480784, SB loss: 0.748562
2023-10-30 05:00:16,372 Epoch: [109/484] Iter:[80/495], Time: 0.39, lr: [0.007945090080432508], Loss: 2.045095, Acc:0.783881, Semantic loss: 0.792960, BCE loss: 0.496543, SB loss: 0.755592
2023-10-30 05:00:20,016 Epoch: [109/484] Iter:[90/495], Time: 0.39, lr: [0.007944704696814414], Loss: 2.058344, Acc:0.786516, Semantic loss: 0.795759, BCE loss: 0.503661, SB loss: 0.758924
2023-10-30 05:00:23,713 Epoch: [109/484] Iter:[100/495], Time: 0.38, lr: [0.007944319311119169], Loss: 2.066183, Acc:0.787381, Semantic loss: 0.798566, BCE loss: 0.507335, SB loss: 0.760281
2023-10-30 05:00:27,475 Epoch: [109/484] Iter:[110/495], Time: 0.38, lr: [0.007943933923346646], Loss: 2.084648, Acc:0.789572, Semantic loss: 0.806519, BCE loss: 0.512923, SB loss: 0.765206
2023-10-30 05:00:31,178 Epoch: [109/484] Iter:[120/495], Time: 0.38, lr: [0.007943548533496724], Loss: 2.086486, Acc:0.791960, Semantic loss: 0.804973, BCE loss: 0.515884, SB loss: 0.765629
2023-10-30 05:00:34,963 Epoch: [109/484] Iter:[130/495], Time: 0.38, lr: [0.00794316314156928], Loss: 2.098704, Acc:0.792031, Semantic loss: 0.811433, BCE loss: 0.519901, SB loss: 0.767370
2023-10-30 05:00:38,543 Epoch: [109/484] Iter:[140/495], Time: 0.38, lr: [0.007942777747564187], Loss: 2.098208, Acc:0.791841, Semantic loss: 0.810780, BCE loss: 0.520610, SB loss: 0.766819
2023-10-30 05:00:42,118 Epoch: [109/484] Iter:[150/495], Time: 0.38, lr: [0.007942392351481326], Loss: 2.095059, Acc:0.791905, Semantic loss: 0.809424, BCE loss: 0.521419, SB loss: 0.764215
2023-10-30 05:00:45,747 Epoch: [109/484] Iter:[160/495], Time: 0.38, lr: [0.007942006953320573], Loss: 2.082857, Acc:0.789944, Semantic loss: 0.802888, BCE loss: 0.518819, SB loss: 0.761150
2023-10-30 05:00:49,441 Epoch: [109/484] Iter:[170/495], Time: 0.38, lr: [0.007941621553081805], Loss: 2.089561, Acc:0.789380, Semantic loss: 0.808202, BCE loss: 0.518379, SB loss: 0.762980
2023-10-30 05:00:53,065 Epoch: [109/484] Iter:[180/495], Time: 0.38, lr: [0.007941236150764896], Loss: 2.093958, Acc:0.790369, Semantic loss: 0.807845, BCE loss: 0.521444, SB loss: 0.764668
2023-10-30 05:00:56,822 Epoch: [109/484] Iter:[190/495], Time: 0.38, lr: [0.007940850746369726], Loss: 2.101667, Acc:0.791851, Semantic loss: 0.810741, BCE loss: 0.523232, SB loss: 0.767694
2023-10-30 05:01:00,506 Epoch: [109/484] Iter:[200/495], Time: 0.38, lr: [0.007940465339896171], Loss: 2.105298, Acc:0.793034, Semantic loss: 0.809322, BCE loss: 0.526035, SB loss: 0.769941
2023-10-30 05:01:04,190 Epoch: [109/484] Iter:[210/495], Time: 0.38, lr: [0.007940079931344107], Loss: 2.099899, Acc:0.790786, Semantic loss: 0.804432, BCE loss: 0.526593, SB loss: 0.768874
2023-10-30 05:01:07,832 Epoch: [109/484] Iter:[220/495], Time: 0.38, lr: [0.007939694520713409], Loss: 2.098316, Acc:0.792455, Semantic loss: 0.801432, BCE loss: 0.529072, SB loss: 0.767813
2023-10-30 05:01:11,489 Epoch: [109/484] Iter:[230/495], Time: 0.37, lr: [0.007939309108003955], Loss: 2.107363, Acc:0.791957, Semantic loss: 0.807041, BCE loss: 0.530584, SB loss: 0.769738
2023-10-30 05:01:15,129 Epoch: [109/484] Iter:[240/495], Time: 0.37, lr: [0.007938923693215624], Loss: 2.110474, Acc:0.788681, Semantic loss: 0.809811, BCE loss: 0.529585, SB loss: 0.771079
2023-10-30 05:01:18,774 Epoch: [109/484] Iter:[250/495], Time: 0.37, lr: [0.00793853827634829], Loss: 2.110298, Acc:0.789088, Semantic loss: 0.809320, BCE loss: 0.529494, SB loss: 0.771483
2023-10-30 05:01:22,506 Epoch: [109/484] Iter:[260/495], Time: 0.37, lr: [0.00793815285740183], Loss: 2.109698, Acc:0.788939, Semantic loss: 0.807369, BCE loss: 0.531691, SB loss: 0.770639
2023-10-30 05:01:26,159 Epoch: [109/484] Iter:[270/495], Time: 0.37, lr: [0.007937767436376123], Loss: 2.106491, Acc:0.789546, Semantic loss: 0.806301, BCE loss: 0.531101, SB loss: 0.769089
2023-10-30 05:01:29,855 Epoch: [109/484] Iter:[280/495], Time: 0.37, lr: [0.007937382013271042], Loss: 2.102275, Acc:0.788309, Semantic loss: 0.804033, BCE loss: 0.530299, SB loss: 0.767943
2023-10-30 05:01:33,576 Epoch: [109/484] Iter:[290/495], Time: 0.37, lr: [0.007936996588086467], Loss: 2.111470, Acc:0.787351, Semantic loss: 0.810051, BCE loss: 0.530899, SB loss: 0.770520
2023-10-30 05:01:37,263 Epoch: [109/484] Iter:[300/495], Time: 0.37, lr: [0.00793661116082227], Loss: 2.106911, Acc:0.787114, Semantic loss: 0.806525, BCE loss: 0.530041, SB loss: 0.770344
2023-10-30 05:01:41,098 Epoch: [109/484] Iter:[310/495], Time: 0.37, lr: [0.007936225731478331], Loss: 2.108800, Acc:0.786438, Semantic loss: 0.807613, BCE loss: 0.530373, SB loss: 0.770815
2023-10-30 05:01:44,911 Epoch: [109/484] Iter:[320/495], Time: 0.37, lr: [0.007935840300054526], Loss: 2.109489, Acc:0.786625, Semantic loss: 0.808383, BCE loss: 0.529750, SB loss: 0.771356
2023-10-30 05:01:48,602 Epoch: [109/484] Iter:[330/495], Time: 0.37, lr: [0.007935454866550734], Loss: 2.123376, Acc:0.787182, Semantic loss: 0.815112, BCE loss: 0.534304, SB loss: 0.773960
2023-10-30 05:01:52,268 Epoch: [109/484] Iter:[340/495], Time: 0.37, lr: [0.007935069430966826], Loss: 2.129009, Acc:0.786609, Semantic loss: 0.818703, BCE loss: 0.534207, SB loss: 0.776099
2023-10-30 05:01:56,030 Epoch: [109/484] Iter:[350/495], Time: 0.37, lr: [0.007934683993302683], Loss: 2.134661, Acc:0.786104, Semantic loss: 0.821073, BCE loss: 0.535718, SB loss: 0.777869
2023-10-30 05:01:59,678 Epoch: [109/484] Iter:[360/495], Time: 0.37, lr: [0.00793429855355818], Loss: 2.142871, Acc:0.786439, Semantic loss: 0.824356, BCE loss: 0.538225, SB loss: 0.780290
2023-10-30 05:02:03,411 Epoch: [109/484] Iter:[370/495], Time: 0.37, lr: [0.007933913111733191], Loss: 2.143331, Acc:0.786070, Semantic loss: 0.825332, BCE loss: 0.537642, SB loss: 0.780357
2023-10-30 05:02:07,105 Epoch: [109/484] Iter:[380/495], Time: 0.37, lr: [0.007933527667827598], Loss: 2.153731, Acc:0.785030, Semantic loss: 0.831762, BCE loss: 0.539038, SB loss: 0.782931
2023-10-30 05:02:10,749 Epoch: [109/484] Iter:[390/495], Time: 0.37, lr: [0.007933142221841273], Loss: 2.155238, Acc:0.784392, Semantic loss: 0.831690, BCE loss: 0.539343, SB loss: 0.784205
2023-10-30 05:02:14,438 Epoch: [109/484] Iter:[400/495], Time: 0.37, lr: [0.007932756773774094], Loss: 2.154555, Acc:0.783670, Semantic loss: 0.830471, BCE loss: 0.539993, SB loss: 0.784090
2023-10-30 05:02:18,154 Epoch: [109/484] Iter:[410/495], Time: 0.37, lr: [0.007932371323625937], Loss: 2.158225, Acc:0.784654, Semantic loss: 0.832693, BCE loss: 0.540966, SB loss: 0.784566
2023-10-30 05:02:21,828 Epoch: [109/484] Iter:[420/495], Time: 0.37, lr: [0.00793198587139668], Loss: 2.159905, Acc:0.784622, Semantic loss: 0.831581, BCE loss: 0.542966, SB loss: 0.785358
2023-10-30 05:02:25,508 Epoch: [109/484] Iter:[430/495], Time: 0.37, lr: [0.007931600417086196], Loss: 2.160102, Acc:0.784308, Semantic loss: 0.831922, BCE loss: 0.542923, SB loss: 0.785257
2023-10-30 05:02:29,241 Epoch: [109/484] Iter:[440/495], Time: 0.37, lr: [0.007931214960694365], Loss: 2.157460, Acc:0.784046, Semantic loss: 0.830573, BCE loss: 0.542765, SB loss: 0.784122
2023-10-30 05:02:32,840 Epoch: [109/484] Iter:[450/495], Time: 0.37, lr: [0.00793082950222106], Loss: 2.155250, Acc:0.784079, Semantic loss: 0.828702, BCE loss: 0.542681, SB loss: 0.783866
2023-10-30 05:02:36,569 Epoch: [109/484] Iter:[460/495], Time: 0.37, lr: [0.00793044404166616], Loss: 2.153749, Acc:0.784354, Semantic loss: 0.826978, BCE loss: 0.543291, SB loss: 0.783480
2023-10-30 05:02:40,294 Epoch: [109/484] Iter:[470/495], Time: 0.37, lr: [0.007930058579029542], Loss: 2.154240, Acc:0.784269, Semantic loss: 0.826691, BCE loss: 0.542878, SB loss: 0.784670
2023-10-30 05:02:44,023 Epoch: [109/484] Iter:[480/495], Time: 0.37, lr: [0.00792967311431108], Loss: 2.153459, Acc:0.785012, Semantic loss: 0.826249, BCE loss: 0.543623, SB loss: 0.783587
2023-10-30 05:02:47,501 Epoch: [109/484] Iter:[490/495], Time: 0.37, lr: [0.00792928764751065], Loss: 2.157947, Acc:0.784346, Semantic loss: 0.828921, BCE loss: 0.544658, SB loss: 0.784368
2023-10-30 05:02:48,899 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:02:49,133 Loss: 2.173, MeanIU:  0.6484, Best_mIoU:  0.6907
2023-10-30 05:02:49,134 [0.95153686 0.70366422 0.89260035 0.2582966  0.46421256 0.54817798
 0.59316339 0.69881158 0.90055061 0.48428077 0.91938384 0.69136853
 0.46616875 0.89607332 0.60692637 0.71275225 0.47516422 0.35542536
 0.70026352]
2023-10-30 05:02:51,226 Epoch: [110/484] Iter:[0/495], Time: 2.06, lr: [0.007929094913329658], Loss: 2.222786, Acc:0.757210, Semantic loss: 0.906345, BCE loss: 0.481768, SB loss: 0.834673
2023-10-30 05:02:55,188 Epoch: [110/484] Iter:[10/495], Time: 0.55, lr: [0.007928709443406047], Loss: 2.126412, Acc:0.745955, Semantic loss: 0.834198, BCE loss: 0.497288, SB loss: 0.794926
2023-10-30 05:02:58,925 Epoch: [110/484] Iter:[20/495], Time: 0.46, lr: [0.00792832397140016], Loss: 2.170689, Acc:0.780719, Semantic loss: 0.835532, BCE loss: 0.545595, SB loss: 0.789561
2023-10-30 05:03:02,586 Epoch: [110/484] Iter:[30/495], Time: 0.43, lr: [0.007927938497311871], Loss: 2.126190, Acc:0.784790, Semantic loss: 0.810394, BCE loss: 0.528755, SB loss: 0.787041
2023-10-30 05:03:06,304 Epoch: [110/484] Iter:[40/495], Time: 0.42, lr: [0.007927553021141062], Loss: 2.157691, Acc:0.776156, Semantic loss: 0.820114, BCE loss: 0.540815, SB loss: 0.796762
2023-10-30 05:03:09,925 Epoch: [110/484] Iter:[50/495], Time: 0.41, lr: [0.007927167542887602], Loss: 2.160715, Acc:0.778672, Semantic loss: 0.824606, BCE loss: 0.538242, SB loss: 0.797867
2023-10-30 05:03:13,521 Epoch: [110/484] Iter:[60/495], Time: 0.40, lr: [0.007926782062551372], Loss: 2.137348, Acc:0.786414, Semantic loss: 0.803518, BCE loss: 0.547302, SB loss: 0.786528
2023-10-30 05:03:17,212 Epoch: [110/484] Iter:[70/495], Time: 0.39, lr: [0.007926396580132247], Loss: 2.119233, Acc:0.789797, Semantic loss: 0.792996, BCE loss: 0.545802, SB loss: 0.780434
2023-10-30 05:03:20,833 Epoch: [110/484] Iter:[80/495], Time: 0.39, lr: [0.007926011095630103], Loss: 2.121786, Acc:0.787958, Semantic loss: 0.795791, BCE loss: 0.542619, SB loss: 0.783376
2023-10-30 05:03:24,562 Epoch: [110/484] Iter:[90/495], Time: 0.39, lr: [0.007925625609044817], Loss: 2.122435, Acc:0.785842, Semantic loss: 0.797364, BCE loss: 0.542296, SB loss: 0.782775
2023-10-30 05:03:28,157 Epoch: [110/484] Iter:[100/495], Time: 0.39, lr: [0.007925240120376263], Loss: 2.106229, Acc:0.788894, Semantic loss: 0.790571, BCE loss: 0.539005, SB loss: 0.776653
2023-10-30 05:03:31,746 Epoch: [110/484] Iter:[110/495], Time: 0.38, lr: [0.00792485462962432], Loss: 2.097013, Acc:0.785758, Semantic loss: 0.788136, BCE loss: 0.533641, SB loss: 0.775236
2023-10-30 05:03:35,321 Epoch: [110/484] Iter:[120/495], Time: 0.38, lr: [0.007924469136788861], Loss: 2.085320, Acc:0.786370, Semantic loss: 0.780646, BCE loss: 0.534143, SB loss: 0.770532
2023-10-30 05:03:39,042 Epoch: [110/484] Iter:[130/495], Time: 0.38, lr: [0.007924083641869768], Loss: 2.077835, Acc:0.785274, Semantic loss: 0.776578, BCE loss: 0.533021, SB loss: 0.768236
2023-10-30 05:03:42,699 Epoch: [110/484] Iter:[140/495], Time: 0.38, lr: [0.00792369814486691], Loss: 2.085950, Acc:0.784505, Semantic loss: 0.780369, BCE loss: 0.536684, SB loss: 0.768897
2023-10-30 05:03:46,347 Epoch: [110/484] Iter:[150/495], Time: 0.38, lr: [0.007923312645780166], Loss: 2.092633, Acc:0.786335, Semantic loss: 0.783531, BCE loss: 0.540323, SB loss: 0.768779
2023-10-30 05:03:50,078 Epoch: [110/484] Iter:[160/495], Time: 0.38, lr: [0.007922927144609413], Loss: 2.092600, Acc:0.788544, Semantic loss: 0.782607, BCE loss: 0.542123, SB loss: 0.767870
2023-10-30 05:03:53,753 Epoch: [110/484] Iter:[170/495], Time: 0.38, lr: [0.007922541641354527], Loss: 2.083575, Acc:0.788180, Semantic loss: 0.777798, BCE loss: 0.540365, SB loss: 0.765412
2023-10-30 05:03:57,439 Epoch: [110/484] Iter:[180/495], Time: 0.38, lr: [0.007922156136015383], Loss: 2.083745, Acc:0.787631, Semantic loss: 0.779002, BCE loss: 0.540823, SB loss: 0.763920
2023-10-30 05:04:01,082 Epoch: [110/484] Iter:[190/495], Time: 0.38, lr: [0.007921770628591856], Loss: 2.083674, Acc:0.787957, Semantic loss: 0.778813, BCE loss: 0.541228, SB loss: 0.763633
2023-10-30 05:04:04,733 Epoch: [110/484] Iter:[200/495], Time: 0.38, lr: [0.007921385119083824], Loss: 2.079223, Acc:0.787985, Semantic loss: 0.776492, BCE loss: 0.538498, SB loss: 0.764233
2023-10-30 05:04:08,475 Epoch: [110/484] Iter:[210/495], Time: 0.38, lr: [0.007920999607491163], Loss: 2.075871, Acc:0.789168, Semantic loss: 0.776311, BCE loss: 0.535932, SB loss: 0.763628
2023-10-30 05:04:12,094 Epoch: [110/484] Iter:[220/495], Time: 0.38, lr: [0.007920614093813748], Loss: 2.074166, Acc:0.790017, Semantic loss: 0.776079, BCE loss: 0.535407, SB loss: 0.762679
2023-10-30 05:04:15,777 Epoch: [110/484] Iter:[230/495], Time: 0.37, lr: [0.007920228578051455], Loss: 2.078184, Acc:0.790177, Semantic loss: 0.778816, BCE loss: 0.535697, SB loss: 0.763672
2023-10-30 05:04:19,512 Epoch: [110/484] Iter:[240/495], Time: 0.37, lr: [0.007919843060204162], Loss: 2.075747, Acc:0.791398, Semantic loss: 0.776442, BCE loss: 0.536338, SB loss: 0.762968
2023-10-30 05:04:23,152 Epoch: [110/484] Iter:[250/495], Time: 0.37, lr: [0.007919457540271742], Loss: 2.081124, Acc:0.790252, Semantic loss: 0.781313, BCE loss: 0.536403, SB loss: 0.763407
2023-10-30 05:04:26,753 Epoch: [110/484] Iter:[260/495], Time: 0.37, lr: [0.007919072018254073], Loss: 2.081591, Acc:0.789944, Semantic loss: 0.782196, BCE loss: 0.536660, SB loss: 0.762735
2023-10-30 05:04:30,519 Epoch: [110/484] Iter:[270/495], Time: 0.37, lr: [0.007918686494151029], Loss: 2.083698, Acc:0.789565, Semantic loss: 0.782748, BCE loss: 0.537481, SB loss: 0.763469
2023-10-30 05:04:34,198 Epoch: [110/484] Iter:[280/495], Time: 0.37, lr: [0.007918300967962488], Loss: 2.084935, Acc:0.788787, Semantic loss: 0.783824, BCE loss: 0.537712, SB loss: 0.763398
2023-10-30 05:04:37,879 Epoch: [110/484] Iter:[290/495], Time: 0.37, lr: [0.007917915439688323], Loss: 2.085134, Acc:0.789491, Semantic loss: 0.783521, BCE loss: 0.538356, SB loss: 0.763257
2023-10-30 05:04:41,620 Epoch: [110/484] Iter:[300/495], Time: 0.37, lr: [0.007917529909328414], Loss: 2.084406, Acc:0.790018, Semantic loss: 0.783106, BCE loss: 0.537928, SB loss: 0.763373
2023-10-30 05:04:45,253 Epoch: [110/484] Iter:[310/495], Time: 0.37, lr: [0.007917144376882634], Loss: 2.085990, Acc:0.788970, Semantic loss: 0.783103, BCE loss: 0.538770, SB loss: 0.764117
2023-10-30 05:04:48,978 Epoch: [110/484] Iter:[320/495], Time: 0.37, lr: [0.00791675884235086], Loss: 2.084373, Acc:0.790142, Semantic loss: 0.781071, BCE loss: 0.540427, SB loss: 0.762875
2023-10-30 05:04:52,782 Epoch: [110/484] Iter:[330/495], Time: 0.37, lr: [0.007916373305732968], Loss: 2.083417, Acc:0.788726, Semantic loss: 0.780649, BCE loss: 0.540549, SB loss: 0.762219
2023-10-30 05:04:56,376 Epoch: [110/484] Iter:[340/495], Time: 0.37, lr: [0.007915987767028832], Loss: 2.086901, Acc:0.789116, Semantic loss: 0.782349, BCE loss: 0.541743, SB loss: 0.762808
2023-10-30 05:05:00,062 Epoch: [110/484] Iter:[350/495], Time: 0.37, lr: [0.00791560222623833], Loss: 2.090755, Acc:0.788637, Semantic loss: 0.785101, BCE loss: 0.542703, SB loss: 0.762952
2023-10-30 05:05:03,696 Epoch: [110/484] Iter:[360/495], Time: 0.37, lr: [0.007915216683361335], Loss: 2.092467, Acc:0.789117, Semantic loss: 0.785504, BCE loss: 0.543316, SB loss: 0.763646
2023-10-30 05:05:07,334 Epoch: [110/484] Iter:[370/495], Time: 0.37, lr: [0.007914831138397726], Loss: 2.092605, Acc:0.789498, Semantic loss: 0.785968, BCE loss: 0.543932, SB loss: 0.762705
2023-10-30 05:05:11,119 Epoch: [110/484] Iter:[380/495], Time: 0.37, lr: [0.007914445591347378], Loss: 2.095152, Acc:0.790045, Semantic loss: 0.786936, BCE loss: 0.545632, SB loss: 0.762584
2023-10-30 05:05:14,896 Epoch: [110/484] Iter:[390/495], Time: 0.37, lr: [0.007914060042210165], Loss: 2.098534, Acc:0.790682, Semantic loss: 0.788374, BCE loss: 0.545806, SB loss: 0.764353
2023-10-30 05:05:18,520 Epoch: [110/484] Iter:[400/495], Time: 0.37, lr: [0.007913674490985964], Loss: 2.102686, Acc:0.790089, Semantic loss: 0.788585, BCE loss: 0.548190, SB loss: 0.765911
2023-10-30 05:05:22,269 Epoch: [110/484] Iter:[410/495], Time: 0.37, lr: [0.007913288937674652], Loss: 2.108112, Acc:0.789457, Semantic loss: 0.794027, BCE loss: 0.547012, SB loss: 0.767072
2023-10-30 05:05:25,949 Epoch: [110/484] Iter:[420/495], Time: 0.37, lr: [0.007912903382276104], Loss: 2.109174, Acc:0.789389, Semantic loss: 0.793686, BCE loss: 0.548301, SB loss: 0.767187
2023-10-30 05:05:29,568 Epoch: [110/484] Iter:[430/495], Time: 0.37, lr: [0.007912517824790192], Loss: 2.114176, Acc:0.788631, Semantic loss: 0.796625, BCE loss: 0.547827, SB loss: 0.769724
2023-10-30 05:05:33,306 Epoch: [110/484] Iter:[440/495], Time: 0.37, lr: [0.007912132265216795], Loss: 2.117701, Acc:0.787439, Semantic loss: 0.798108, BCE loss: 0.548620, SB loss: 0.770974
2023-10-30 05:05:36,999 Epoch: [110/484] Iter:[450/495], Time: 0.37, lr: [0.00791174670355579], Loss: 2.118431, Acc:0.787289, Semantic loss: 0.798780, BCE loss: 0.548501, SB loss: 0.771150
2023-10-30 05:05:40,672 Epoch: [110/484] Iter:[460/495], Time: 0.37, lr: [0.00791136113980705], Loss: 2.118284, Acc:0.787000, Semantic loss: 0.799143, BCE loss: 0.547646, SB loss: 0.771495
2023-10-30 05:05:44,357 Epoch: [110/484] Iter:[470/495], Time: 0.37, lr: [0.007910975573970453], Loss: 2.118970, Acc:0.787197, Semantic loss: 0.799618, BCE loss: 0.547002, SB loss: 0.772350
2023-10-30 05:05:48,095 Epoch: [110/484] Iter:[480/495], Time: 0.37, lr: [0.007910590006045874], Loss: 2.118304, Acc:0.787536, Semantic loss: 0.799763, BCE loss: 0.546633, SB loss: 0.771907
2023-10-30 05:05:51,603 Epoch: [110/484] Iter:[490/495], Time: 0.37, lr: [0.007910204436033186], Loss: 2.118575, Acc:0.787636, Semantic loss: 0.799379, BCE loss: 0.547183, SB loss: 0.772013
2023-10-30 05:08:48,972 0 [0.93355313 0.63658133 0.81081485 0.13785518 0.16378318 0.37975404
 0.39966983 0.56118361 0.86757585 0.41780777 0.83978768 0.53149288
 0.00491555 0.79168947 0.00201854 0.04424026 0.02146009 0.04647208
 0.51354343] 0.4265367762657741
2023-10-30 05:08:48,972 1 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385] 0.6706972242808207
2023-10-30 05:08:48,976 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:08:49,219 Loss: 2.158, MeanIU:  0.6707, Best_mIoU:  0.6907
2023-10-30 05:08:49,220 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385]
2023-10-30 05:08:51,410 Epoch: [111/484] Iter:[0/495], Time: 2.16, lr: [0.007910011650243763], Loss: 2.285393, Acc:0.888212, Semantic loss: 0.824162, BCE loss: 0.711607, SB loss: 0.749624
2023-10-30 05:08:55,151 Epoch: [111/484] Iter:[10/495], Time: 0.54, lr: [0.007909626077098681], Loss: 2.271434, Acc:0.786890, Semantic loss: 0.895806, BCE loss: 0.587364, SB loss: 0.788263
2023-10-30 05:08:58,723 Epoch: [111/484] Iter:[20/495], Time: 0.45, lr: [0.007909240501865183], Loss: 2.185671, Acc:0.781224, Semantic loss: 0.845496, BCE loss: 0.558735, SB loss: 0.781440
2023-10-30 05:09:02,171 Epoch: [111/484] Iter:[30/495], Time: 0.42, lr: [0.00790885492454314], Loss: 2.144736, Acc:0.789991, Semantic loss: 0.822388, BCE loss: 0.551818, SB loss: 0.770530
2023-10-30 05:09:05,604 Epoch: [111/484] Iter:[40/495], Time: 0.40, lr: [0.007908469345132433], Loss: 2.132530, Acc:0.789589, Semantic loss: 0.799283, BCE loss: 0.565786, SB loss: 0.767462
2023-10-30 05:09:09,112 Epoch: [111/484] Iter:[50/495], Time: 0.39, lr: [0.007908083763632931], Loss: 2.120403, Acc:0.791423, Semantic loss: 0.792349, BCE loss: 0.560823, SB loss: 0.767231
2023-10-30 05:09:12,593 Epoch: [111/484] Iter:[60/495], Time: 0.38, lr: [0.007907698180044515], Loss: 2.109543, Acc:0.788352, Semantic loss: 0.789261, BCE loss: 0.555895, SB loss: 0.764387
2023-10-30 05:09:16,166 Epoch: [111/484] Iter:[70/495], Time: 0.38, lr: [0.007907312594367059], Loss: 2.118551, Acc:0.791627, Semantic loss: 0.789045, BCE loss: 0.563689, SB loss: 0.765816
2023-10-30 05:09:19,668 Epoch: [111/484] Iter:[80/495], Time: 0.38, lr: [0.007906927006600438], Loss: 2.114005, Acc:0.790846, Semantic loss: 0.787710, BCE loss: 0.557040, SB loss: 0.769255
2023-10-30 05:09:23,269 Epoch: [111/484] Iter:[90/495], Time: 0.37, lr: [0.007906541416744526], Loss: 2.106406, Acc:0.792776, Semantic loss: 0.785720, BCE loss: 0.551970, SB loss: 0.768716
2023-10-30 05:09:26,841 Epoch: [111/484] Iter:[100/495], Time: 0.37, lr: [0.007906155824799201], Loss: 2.096919, Acc:0.794742, Semantic loss: 0.782626, BCE loss: 0.553572, SB loss: 0.760721
2023-10-30 05:09:30,378 Epoch: [111/484] Iter:[110/495], Time: 0.37, lr: [0.00790577023076434], Loss: 2.096289, Acc:0.793338, Semantic loss: 0.784507, BCE loss: 0.551720, SB loss: 0.760062
2023-10-30 05:09:34,005 Epoch: [111/484] Iter:[120/495], Time: 0.37, lr: [0.00790538463463981], Loss: 2.089220, Acc:0.794445, Semantic loss: 0.777976, BCE loss: 0.553141, SB loss: 0.758103
2023-10-30 05:09:37,623 Epoch: [111/484] Iter:[130/495], Time: 0.37, lr: [0.007904999036425497], Loss: 2.101645, Acc:0.794492, Semantic loss: 0.784091, BCE loss: 0.555856, SB loss: 0.761697
2023-10-30 05:09:41,238 Epoch: [111/484] Iter:[140/495], Time: 0.37, lr: [0.007904613436121272], Loss: 2.098417, Acc:0.796136, Semantic loss: 0.780285, BCE loss: 0.557049, SB loss: 0.761083
2023-10-30 05:09:44,933 Epoch: [111/484] Iter:[150/495], Time: 0.37, lr: [0.007904227833727007], Loss: 2.103757, Acc:0.796288, Semantic loss: 0.781864, BCE loss: 0.560429, SB loss: 0.761464
2023-10-30 05:09:48,515 Epoch: [111/484] Iter:[160/495], Time: 0.37, lr: [0.007903842229242584], Loss: 2.090301, Acc:0.797297, Semantic loss: 0.777585, BCE loss: 0.554318, SB loss: 0.758398
2023-10-30 05:09:52,119 Epoch: [111/484] Iter:[170/495], Time: 0.37, lr: [0.007903456622667874], Loss: 2.097759, Acc:0.796134, Semantic loss: 0.782740, BCE loss: 0.554750, SB loss: 0.760268
2023-10-30 05:09:55,761 Epoch: [111/484] Iter:[180/495], Time: 0.37, lr: [0.007903071014002751], Loss: 2.096450, Acc:0.795246, Semantic loss: 0.782648, BCE loss: 0.555308, SB loss: 0.758495
2023-10-30 05:09:59,529 Epoch: [111/484] Iter:[190/495], Time: 0.37, lr: [0.007902685403247093], Loss: 2.100010, Acc:0.794201, Semantic loss: 0.786259, BCE loss: 0.554771, SB loss: 0.758979
2023-10-30 05:10:03,151 Epoch: [111/484] Iter:[200/495], Time: 0.37, lr: [0.007902299790400776], Loss: 2.101372, Acc:0.792999, Semantic loss: 0.786001, BCE loss: 0.555407, SB loss: 0.759964
2023-10-30 05:10:06,748 Epoch: [111/484] Iter:[210/495], Time: 0.37, lr: [0.007901914175463674], Loss: 2.090092, Acc:0.793025, Semantic loss: 0.780205, BCE loss: 0.552701, SB loss: 0.757185
2023-10-30 05:10:10,425 Epoch: [111/484] Iter:[220/495], Time: 0.37, lr: [0.007901528558435664], Loss: 2.095878, Acc:0.793197, Semantic loss: 0.784264, BCE loss: 0.552779, SB loss: 0.758835
2023-10-30 05:10:14,200 Epoch: [111/484] Iter:[230/495], Time: 0.37, lr: [0.007901142939316617], Loss: 2.099988, Acc:0.793950, Semantic loss: 0.787411, BCE loss: 0.554500, SB loss: 0.758077
2023-10-30 05:10:17,745 Epoch: [111/484] Iter:[240/495], Time: 0.37, lr: [0.007900757318106414], Loss: 2.096901, Acc:0.793219, Semantic loss: 0.786913, BCE loss: 0.552144, SB loss: 0.757844
2023-10-30 05:10:21,440 Epoch: [111/484] Iter:[250/495], Time: 0.37, lr: [0.007900371694804925], Loss: 2.097333, Acc:0.792657, Semantic loss: 0.786817, BCE loss: 0.551039, SB loss: 0.759478
2023-10-30 05:10:25,147 Epoch: [111/484] Iter:[260/495], Time: 0.37, lr: [0.007899986069412028], Loss: 2.101069, Acc:0.792248, Semantic loss: 0.789800, BCE loss: 0.552663, SB loss: 0.758606
2023-10-30 05:10:28,768 Epoch: [111/484] Iter:[270/495], Time: 0.37, lr: [0.007899600441927598], Loss: 2.100334, Acc:0.792869, Semantic loss: 0.788807, BCE loss: 0.552861, SB loss: 0.758666
2023-10-30 05:10:32,428 Epoch: [111/484] Iter:[280/495], Time: 0.37, lr: [0.00789921481235151], Loss: 2.098543, Acc:0.793415, Semantic loss: 0.787707, BCE loss: 0.552653, SB loss: 0.758183
2023-10-30 05:10:36,008 Epoch: [111/484] Iter:[290/495], Time: 0.37, lr: [0.00789882918068364], Loss: 2.096798, Acc:0.794449, Semantic loss: 0.786835, BCE loss: 0.552826, SB loss: 0.757137
2023-10-30 05:10:39,781 Epoch: [111/484] Iter:[300/495], Time: 0.37, lr: [0.007898443546923862], Loss: 2.091505, Acc:0.793367, Semantic loss: 0.784834, BCE loss: 0.550439, SB loss: 0.756233
2023-10-30 05:10:43,395 Epoch: [111/484] Iter:[310/495], Time: 0.37, lr: [0.007898057911072051], Loss: 2.095996, Acc:0.792620, Semantic loss: 0.787033, BCE loss: 0.551637, SB loss: 0.757325
2023-10-30 05:10:47,020 Epoch: [111/484] Iter:[320/495], Time: 0.37, lr: [0.007897672273128084], Loss: 2.100668, Acc:0.790519, Semantic loss: 0.789289, BCE loss: 0.552610, SB loss: 0.758769
2023-10-30 05:10:50,790 Epoch: [111/484] Iter:[330/495], Time: 0.37, lr: [0.007897286633091832], Loss: 2.101463, Acc:0.790646, Semantic loss: 0.788169, BCE loss: 0.554119, SB loss: 0.759175
2023-10-30 05:10:54,540 Epoch: [111/484] Iter:[340/495], Time: 0.37, lr: [0.007896900990963174], Loss: 2.098062, Acc:0.791355, Semantic loss: 0.786367, BCE loss: 0.552998, SB loss: 0.758697
2023-10-30 05:10:58,301 Epoch: [111/484] Iter:[350/495], Time: 0.37, lr: [0.007896515346741986], Loss: 2.095487, Acc:0.791852, Semantic loss: 0.785011, BCE loss: 0.551890, SB loss: 0.758587
2023-10-30 05:11:01,926 Epoch: [111/484] Iter:[360/495], Time: 0.37, lr: [0.007896129700428139], Loss: 2.096603, Acc:0.791943, Semantic loss: 0.785860, BCE loss: 0.551124, SB loss: 0.759619
2023-10-30 05:11:05,562 Epoch: [111/484] Iter:[370/495], Time: 0.37, lr: [0.00789574405202151], Loss: 2.104177, Acc:0.792102, Semantic loss: 0.789648, BCE loss: 0.552478, SB loss: 0.762050
2023-10-30 05:11:09,259 Epoch: [111/484] Iter:[380/495], Time: 0.37, lr: [0.007895358401521977], Loss: 2.101651, Acc:0.791870, Semantic loss: 0.789216, BCE loss: 0.551143, SB loss: 0.761293
2023-10-30 05:11:12,993 Epoch: [111/484] Iter:[390/495], Time: 0.37, lr: [0.007894972748929412], Loss: 2.104486, Acc:0.793049, Semantic loss: 0.790838, BCE loss: 0.552027, SB loss: 0.761621
2023-10-30 05:11:16,677 Epoch: [111/484] Iter:[400/495], Time: 0.37, lr: [0.007894587094243687], Loss: 2.103656, Acc:0.793198, Semantic loss: 0.791291, BCE loss: 0.551152, SB loss: 0.761212
2023-10-30 05:11:20,353 Epoch: [111/484] Iter:[410/495], Time: 0.37, lr: [0.007894201437464683], Loss: 2.107750, Acc:0.793168, Semantic loss: 0.794527, BCE loss: 0.551040, SB loss: 0.762183
2023-10-30 05:11:24,076 Epoch: [111/484] Iter:[420/495], Time: 0.37, lr: [0.00789381577859227], Loss: 2.109668, Acc:0.792529, Semantic loss: 0.795801, BCE loss: 0.551002, SB loss: 0.762866
2023-10-30 05:11:27,725 Epoch: [111/484] Iter:[430/495], Time: 0.37, lr: [0.007893430117626329], Loss: 2.110242, Acc:0.792446, Semantic loss: 0.796024, BCE loss: 0.551129, SB loss: 0.763089
2023-10-30 05:11:31,383 Epoch: [111/484] Iter:[440/495], Time: 0.37, lr: [0.00789304445456673], Loss: 2.110435, Acc:0.792561, Semantic loss: 0.795804, BCE loss: 0.551294, SB loss: 0.763337
2023-10-30 05:11:35,112 Epoch: [111/484] Iter:[450/495], Time: 0.37, lr: [0.007892658789413348], Loss: 2.110163, Acc:0.792683, Semantic loss: 0.795576, BCE loss: 0.550784, SB loss: 0.763803
2023-10-30 05:11:38,736 Epoch: [111/484] Iter:[460/495], Time: 0.37, lr: [0.007892273122166062], Loss: 2.112830, Acc:0.793369, Semantic loss: 0.796114, BCE loss: 0.552873, SB loss: 0.763842
2023-10-30 05:11:42,350 Epoch: [111/484] Iter:[470/495], Time: 0.37, lr: [0.007891887452824741], Loss: 2.114455, Acc:0.792451, Semantic loss: 0.797645, BCE loss: 0.551919, SB loss: 0.764891
2023-10-30 05:11:46,067 Epoch: [111/484] Iter:[480/495], Time: 0.37, lr: [0.007891501781389266], Loss: 2.115788, Acc:0.792004, Semantic loss: 0.798689, BCE loss: 0.551542, SB loss: 0.765557
2023-10-30 05:11:49,679 Epoch: [111/484] Iter:[490/495], Time: 0.37, lr: [0.007891116107859508], Loss: 2.116843, Acc:0.791601, Semantic loss: 0.799710, BCE loss: 0.550949, SB loss: 0.766184
2023-10-30 05:11:51,080 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:11:51,321 Loss: 2.158, MeanIU:  0.6707, Best_mIoU:  0.6907
2023-10-30 05:11:51,321 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385]
2023-10-30 05:11:53,407 Epoch: [112/484] Iter:[0/495], Time: 2.05, lr: [0.007890923270309234], Loss: 2.097849, Acc:0.872893, Semantic loss: 0.717589, BCE loss: 0.607797, SB loss: 0.772463
2023-10-30 05:11:57,548 Epoch: [112/484] Iter:[10/495], Time: 0.56, lr: [0.007890537593637819], Loss: 1.986778, Acc:0.799086, Semantic loss: 0.695858, BCE loss: 0.550121, SB loss: 0.740799
2023-10-30 05:12:01,294 Epoch: [112/484] Iter:[20/495], Time: 0.47, lr: [0.007890151914871808], Loss: 2.113969, Acc:0.804568, Semantic loss: 0.753891, BCE loss: 0.601089, SB loss: 0.758988
2023-10-30 05:12:04,958 Epoch: [112/484] Iter:[30/495], Time: 0.44, lr: [0.007889766234011079], Loss: 2.093038, Acc:0.807279, Semantic loss: 0.759211, BCE loss: 0.584421, SB loss: 0.749406
2023-10-30 05:12:08,709 Epoch: [112/484] Iter:[40/495], Time: 0.42, lr: [0.007889380551055505], Loss: 2.120229, Acc:0.805656, Semantic loss: 0.787321, BCE loss: 0.564350, SB loss: 0.768558
2023-10-30 05:12:12,464 Epoch: [112/484] Iter:[50/495], Time: 0.41, lr: [0.007888994866004959], Loss: 2.125388, Acc:0.800151, Semantic loss: 0.794277, BCE loss: 0.566022, SB loss: 0.765089
2023-10-30 05:12:16,067 Epoch: [112/484] Iter:[60/495], Time: 0.41, lr: [0.00788860917885932], Loss: 2.118612, Acc:0.800703, Semantic loss: 0.790722, BCE loss: 0.567791, SB loss: 0.760099
2023-10-30 05:12:19,719 Epoch: [112/484] Iter:[70/495], Time: 0.40, lr: [0.007888223489618457], Loss: 2.104746, Acc:0.797609, Semantic loss: 0.784594, BCE loss: 0.561263, SB loss: 0.758889
2023-10-30 05:12:23,289 Epoch: [112/484] Iter:[80/495], Time: 0.39, lr: [0.007887837798282251], Loss: 2.107499, Acc:0.798803, Semantic loss: 0.784820, BCE loss: 0.566059, SB loss: 0.756620
2023-10-30 05:12:27,118 Epoch: [112/484] Iter:[90/495], Time: 0.39, lr: [0.007887452104850572], Loss: 2.101902, Acc:0.799733, Semantic loss: 0.785438, BCE loss: 0.560712, SB loss: 0.755752
2023-10-30 05:12:30,894 Epoch: [112/484] Iter:[100/495], Time: 0.39, lr: [0.007887066409323299], Loss: 2.106187, Acc:0.799269, Semantic loss: 0.783186, BCE loss: 0.568694, SB loss: 0.754308
2023-10-30 05:12:34,564 Epoch: [112/484] Iter:[110/495], Time: 0.39, lr: [0.007886680711700303], Loss: 2.099382, Acc:0.802029, Semantic loss: 0.777253, BCE loss: 0.569934, SB loss: 0.752195
2023-10-30 05:12:38,259 Epoch: [112/484] Iter:[120/495], Time: 0.39, lr: [0.007886295011981462], Loss: 2.101822, Acc:0.798912, Semantic loss: 0.782235, BCE loss: 0.567137, SB loss: 0.752450
2023-10-30 05:12:41,945 Epoch: [112/484] Iter:[130/495], Time: 0.39, lr: [0.00788590931016665], Loss: 2.104801, Acc:0.800210, Semantic loss: 0.783799, BCE loss: 0.569988, SB loss: 0.751015
2023-10-30 05:12:45,554 Epoch: [112/484] Iter:[140/495], Time: 0.38, lr: [0.007885523606255739], Loss: 2.097777, Acc:0.800657, Semantic loss: 0.780663, BCE loss: 0.567478, SB loss: 0.749637
2023-10-30 05:12:49,231 Epoch: [112/484] Iter:[150/495], Time: 0.38, lr: [0.007885137900248603], Loss: 2.094299, Acc:0.801151, Semantic loss: 0.778902, BCE loss: 0.567184, SB loss: 0.748213
2023-10-30 05:12:52,897 Epoch: [112/484] Iter:[160/495], Time: 0.38, lr: [0.007884752192145121], Loss: 2.096676, Acc:0.801546, Semantic loss: 0.778645, BCE loss: 0.569385, SB loss: 0.748647
2023-10-30 05:12:56,565 Epoch: [112/484] Iter:[170/495], Time: 0.38, lr: [0.007884366481945166], Loss: 2.100904, Acc:0.799883, Semantic loss: 0.785237, BCE loss: 0.566138, SB loss: 0.749529
2023-10-30 05:13:00,362 Epoch: [112/484] Iter:[180/495], Time: 0.38, lr: [0.007883980769648613], Loss: 2.115790, Acc:0.799647, Semantic loss: 0.795873, BCE loss: 0.567344, SB loss: 0.752573
2023-10-30 05:13:04,077 Epoch: [112/484] Iter:[190/495], Time: 0.38, lr: [0.007883595055255335], Loss: 2.113185, Acc:0.799954, Semantic loss: 0.791774, BCE loss: 0.568223, SB loss: 0.753188
2023-10-30 05:13:07,842 Epoch: [112/484] Iter:[200/495], Time: 0.38, lr: [0.007883209338765209], Loss: 2.119258, Acc:0.801181, Semantic loss: 0.796590, BCE loss: 0.569407, SB loss: 0.753262
2023-10-30 05:13:11,477 Epoch: [112/484] Iter:[210/495], Time: 0.38, lr: [0.007882823620178107], Loss: 2.121292, Acc:0.802713, Semantic loss: 0.796385, BCE loss: 0.569371, SB loss: 0.755536
2023-10-30 05:13:15,145 Epoch: [112/484] Iter:[220/495], Time: 0.38, lr: [0.007882437899493906], Loss: 2.118142, Acc:0.802146, Semantic loss: 0.795602, BCE loss: 0.567031, SB loss: 0.755509
2023-10-30 05:13:18,731 Epoch: [112/484] Iter:[230/495], Time: 0.38, lr: [0.007882052176712477], Loss: 2.122829, Acc:0.801337, Semantic loss: 0.801247, BCE loss: 0.565485, SB loss: 0.756096
2023-10-30 05:13:22,408 Epoch: [112/484] Iter:[240/495], Time: 0.38, lr: [0.0078816664518337], Loss: 2.119366, Acc:0.801162, Semantic loss: 0.800147, BCE loss: 0.562505, SB loss: 0.756714
2023-10-30 05:13:26,080 Epoch: [112/484] Iter:[250/495], Time: 0.38, lr: [0.007881280724857444], Loss: 2.116783, Acc:0.800571, Semantic loss: 0.798929, BCE loss: 0.561125, SB loss: 0.756729
2023-10-30 05:13:29,698 Epoch: [112/484] Iter:[260/495], Time: 0.38, lr: [0.007880894995783587], Loss: 2.113283, Acc:0.798897, Semantic loss: 0.799015, BCE loss: 0.556979, SB loss: 0.757289
2023-10-30 05:13:33,392 Epoch: [112/484] Iter:[270/495], Time: 0.38, lr: [0.007880509264612002], Loss: 2.113513, Acc:0.798503, Semantic loss: 0.799703, BCE loss: 0.555973, SB loss: 0.757837
2023-10-30 05:13:37,154 Epoch: [112/484] Iter:[280/495], Time: 0.38, lr: [0.007880123531342565], Loss: 2.114919, Acc:0.798687, Semantic loss: 0.799614, BCE loss: 0.556995, SB loss: 0.758311
2023-10-30 05:13:40,763 Epoch: [112/484] Iter:[290/495], Time: 0.38, lr: [0.00787973779597515], Loss: 2.108339, Acc:0.799036, Semantic loss: 0.796257, BCE loss: 0.555050, SB loss: 0.757032
2023-10-30 05:13:44,518 Epoch: [112/484] Iter:[300/495], Time: 0.38, lr: [0.007879352058509629], Loss: 2.106476, Acc:0.796963, Semantic loss: 0.797634, BCE loss: 0.551306, SB loss: 0.757536
2023-10-30 05:13:48,199 Epoch: [112/484] Iter:[310/495], Time: 0.38, lr: [0.00787896631894588], Loss: 2.108898, Acc:0.796390, Semantic loss: 0.798911, BCE loss: 0.552042, SB loss: 0.757944
2023-10-30 05:13:51,946 Epoch: [112/484] Iter:[320/495], Time: 0.38, lr: [0.007878580577283774], Loss: 2.111665, Acc:0.796082, Semantic loss: 0.800731, BCE loss: 0.552615, SB loss: 0.758319
2023-10-30 05:13:55,676 Epoch: [112/484] Iter:[330/495], Time: 0.38, lr: [0.00787819483352319], Loss: 2.108654, Acc:0.795589, Semantic loss: 0.796800, BCE loss: 0.553587, SB loss: 0.758268
2023-10-30 05:13:59,347 Epoch: [112/484] Iter:[340/495], Time: 0.38, lr: [0.007877809087663997], Loss: 2.104604, Acc:0.795423, Semantic loss: 0.793862, BCE loss: 0.553150, SB loss: 0.757591
2023-10-30 05:14:02,979 Epoch: [112/484] Iter:[350/495], Time: 0.37, lr: [0.007877423339706074], Loss: 2.102117, Acc:0.795051, Semantic loss: 0.791000, BCE loss: 0.554083, SB loss: 0.757034
2023-10-30 05:14:06,652 Epoch: [112/484] Iter:[360/495], Time: 0.37, lr: [0.007877037589649295], Loss: 2.099903, Acc:0.794518, Semantic loss: 0.789139, BCE loss: 0.554027, SB loss: 0.756738
2023-10-30 05:14:10,309 Epoch: [112/484] Iter:[370/495], Time: 0.37, lr: [0.007876651837493531], Loss: 2.097629, Acc:0.793529, Semantic loss: 0.789068, BCE loss: 0.551737, SB loss: 0.756823
2023-10-30 05:14:13,934 Epoch: [112/484] Iter:[380/495], Time: 0.37, lr: [0.007876266083238659], Loss: 2.093509, Acc:0.793302, Semantic loss: 0.787053, BCE loss: 0.550209, SB loss: 0.756247
2023-10-30 05:14:17,727 Epoch: [112/484] Iter:[390/495], Time: 0.37, lr: [0.00787588032688455], Loss: 2.094915, Acc:0.793567, Semantic loss: 0.787649, BCE loss: 0.550667, SB loss: 0.756600
2023-10-30 05:14:21,384 Epoch: [112/484] Iter:[400/495], Time: 0.37, lr: [0.007875494568431085], Loss: 2.095049, Acc:0.793812, Semantic loss: 0.787537, BCE loss: 0.550070, SB loss: 0.757442
2023-10-30 05:14:25,035 Epoch: [112/484] Iter:[410/495], Time: 0.37, lr: [0.007875108807878133], Loss: 2.092028, Acc:0.792913, Semantic loss: 0.786321, BCE loss: 0.549039, SB loss: 0.756668
2023-10-30 05:14:28,803 Epoch: [112/484] Iter:[420/495], Time: 0.37, lr: [0.007874723045225568], Loss: 2.090191, Acc:0.792959, Semantic loss: 0.785049, BCE loss: 0.548715, SB loss: 0.756428
2023-10-30 05:14:32,377 Epoch: [112/484] Iter:[430/495], Time: 0.37, lr: [0.007874337280473268], Loss: 2.091935, Acc:0.793008, Semantic loss: 0.785446, BCE loss: 0.549056, SB loss: 0.757433
2023-10-30 05:14:36,040 Epoch: [112/484] Iter:[440/495], Time: 0.37, lr: [0.007873951513621105], Loss: 2.092944, Acc:0.792376, Semantic loss: 0.786753, BCE loss: 0.548562, SB loss: 0.757629
2023-10-30 05:14:39,696 Epoch: [112/484] Iter:[450/495], Time: 0.37, lr: [0.007873565744668952], Loss: 2.092426, Acc:0.791311, Semantic loss: 0.786593, BCE loss: 0.547785, SB loss: 0.758048
2023-10-30 05:14:43,346 Epoch: [112/484] Iter:[460/495], Time: 0.37, lr: [0.007873179973616685], Loss: 2.093692, Acc:0.791107, Semantic loss: 0.787690, BCE loss: 0.547021, SB loss: 0.758981
2023-10-30 05:14:47,010 Epoch: [112/484] Iter:[470/495], Time: 0.37, lr: [0.007872794200464179], Loss: 2.091050, Acc:0.791445, Semantic loss: 0.786109, BCE loss: 0.546063, SB loss: 0.758877
2023-10-30 05:14:50,674 Epoch: [112/484] Iter:[480/495], Time: 0.37, lr: [0.007872408425211306], Loss: 2.091149, Acc:0.791705, Semantic loss: 0.785389, BCE loss: 0.546999, SB loss: 0.758762
2023-10-30 05:14:54,197 Epoch: [112/484] Iter:[490/495], Time: 0.37, lr: [0.00787202264785794], Loss: 2.090701, Acc:0.791398, Semantic loss: 0.785181, BCE loss: 0.546935, SB loss: 0.758586
2023-10-30 05:14:55,600 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:14:55,837 Loss: 2.158, MeanIU:  0.6707, Best_mIoU:  0.6907
2023-10-30 05:14:55,837 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385]
2023-10-30 05:14:57,638 Epoch: [113/484] Iter:[0/495], Time: 1.77, lr: [0.007871829758393536], Loss: 1.860100, Acc:0.720121, Semantic loss: 0.747015, BCE loss: 0.378859, SB loss: 0.734227
2023-10-30 05:15:01,683 Epoch: [113/484] Iter:[10/495], Time: 0.53, lr: [0.007871443977889197], Loss: 2.171263, Acc:0.786869, Semantic loss: 0.827545, BCE loss: 0.570972, SB loss: 0.772746
2023-10-30 05:15:05,391 Epoch: [113/484] Iter:[20/495], Time: 0.45, lr: [0.007871058195284053], Loss: 2.141550, Acc:0.806077, Semantic loss: 0.820083, BCE loss: 0.554691, SB loss: 0.766777
2023-10-30 05:15:08,981 Epoch: [113/484] Iter:[30/495], Time: 0.42, lr: [0.007870672410577977], Loss: 2.177177, Acc:0.800017, Semantic loss: 0.823900, BCE loss: 0.572334, SB loss: 0.780944
2023-10-30 05:15:12,620 Epoch: [113/484] Iter:[40/495], Time: 0.41, lr: [0.007870286623770843], Loss: 2.173990, Acc:0.792548, Semantic loss: 0.812601, BCE loss: 0.565351, SB loss: 0.796038
2023-10-30 05:15:16,196 Epoch: [113/484] Iter:[50/495], Time: 0.40, lr: [0.007869900834862524], Loss: 2.215893, Acc:0.783876, Semantic loss: 0.843179, BCE loss: 0.564012, SB loss: 0.808701
2023-10-30 05:15:19,827 Epoch: [113/484] Iter:[60/495], Time: 0.39, lr: [0.007869515043852898], Loss: 2.183748, Acc:0.779054, Semantic loss: 0.831692, BCE loss: 0.555674, SB loss: 0.796382
2023-10-30 05:15:23,541 Epoch: [113/484] Iter:[70/495], Time: 0.39, lr: [0.007869129250741834], Loss: 2.176948, Acc:0.778666, Semantic loss: 0.823816, BCE loss: 0.557434, SB loss: 0.795698
2023-10-30 05:15:27,220 Epoch: [113/484] Iter:[80/495], Time: 0.39, lr: [0.007868743455529209], Loss: 2.144234, Acc:0.784937, Semantic loss: 0.804088, BCE loss: 0.554365, SB loss: 0.785781
2023-10-30 05:15:30,912 Epoch: [113/484] Iter:[90/495], Time: 0.39, lr: [0.007868357658214897], Loss: 2.156664, Acc:0.783985, Semantic loss: 0.812607, BCE loss: 0.555230, SB loss: 0.788828
2023-10-30 05:15:34,684 Epoch: [113/484] Iter:[100/495], Time: 0.38, lr: [0.007867971858798771], Loss: 2.155079, Acc:0.787600, Semantic loss: 0.806214, BCE loss: 0.563035, SB loss: 0.785830
2023-10-30 05:15:38,425 Epoch: [113/484] Iter:[110/495], Time: 0.38, lr: [0.007867586057280706], Loss: 2.143136, Acc:0.785639, Semantic loss: 0.807116, BCE loss: 0.553183, SB loss: 0.782837
2023-10-30 05:15:42,060 Epoch: [113/484] Iter:[120/495], Time: 0.38, lr: [0.007867200253660576], Loss: 2.148606, Acc:0.784298, Semantic loss: 0.813212, BCE loss: 0.550901, SB loss: 0.784494
2023-10-30 05:15:45,732 Epoch: [113/484] Iter:[130/495], Time: 0.38, lr: [0.007866814447938252], Loss: 2.139154, Acc:0.788210, Semantic loss: 0.804854, BCE loss: 0.552442, SB loss: 0.781858
2023-10-30 05:15:49,301 Epoch: [113/484] Iter:[140/495], Time: 0.38, lr: [0.007866428640113615], Loss: 2.137585, Acc:0.787932, Semantic loss: 0.805025, BCE loss: 0.551305, SB loss: 0.781256
2023-10-30 05:15:52,916 Epoch: [113/484] Iter:[150/495], Time: 0.38, lr: [0.00786604283018653], Loss: 2.132478, Acc:0.785416, Semantic loss: 0.801555, BCE loss: 0.554519, SB loss: 0.776404
2023-10-30 05:15:56,647 Epoch: [113/484] Iter:[160/495], Time: 0.38, lr: [0.007865657018156879], Loss: 2.124797, Acc:0.786471, Semantic loss: 0.797296, BCE loss: 0.555552, SB loss: 0.771948
2023-10-30 05:16:00,322 Epoch: [113/484] Iter:[170/495], Time: 0.38, lr: [0.007865271204024532], Loss: 2.125295, Acc:0.789146, Semantic loss: 0.799069, BCE loss: 0.555543, SB loss: 0.770684
2023-10-30 05:16:04,236 Epoch: [113/484] Iter:[180/495], Time: 0.38, lr: [0.007864885387789362], Loss: 2.124055, Acc:0.789577, Semantic loss: 0.797926, BCE loss: 0.557543, SB loss: 0.768586
2023-10-30 05:16:07,870 Epoch: [113/484] Iter:[190/495], Time: 0.38, lr: [0.007864499569451245], Loss: 2.120961, Acc:0.792507, Semantic loss: 0.795243, BCE loss: 0.558616, SB loss: 0.767102
2023-10-30 05:16:11,587 Epoch: [113/484] Iter:[200/495], Time: 0.38, lr: [0.007864113749010056], Loss: 2.113785, Acc:0.793741, Semantic loss: 0.792599, BCE loss: 0.556280, SB loss: 0.764907
2023-10-30 05:16:15,188 Epoch: [113/484] Iter:[210/495], Time: 0.38, lr: [0.007863727926465666], Loss: 2.111168, Acc:0.793906, Semantic loss: 0.792710, BCE loss: 0.553615, SB loss: 0.764843
2023-10-30 05:16:18,820 Epoch: [113/484] Iter:[220/495], Time: 0.38, lr: [0.007863342101817949], Loss: 2.101757, Acc:0.795167, Semantic loss: 0.787705, BCE loss: 0.551340, SB loss: 0.762713
2023-10-30 05:16:22,515 Epoch: [113/484] Iter:[230/495], Time: 0.38, lr: [0.007862956275066781], Loss: 2.116593, Acc:0.796016, Semantic loss: 0.795696, BCE loss: 0.554749, SB loss: 0.766148
2023-10-30 05:16:26,225 Epoch: [113/484] Iter:[240/495], Time: 0.37, lr: [0.007862570446212034], Loss: 2.110218, Acc:0.794220, Semantic loss: 0.792434, BCE loss: 0.553361, SB loss: 0.764423
2023-10-30 05:16:29,917 Epoch: [113/484] Iter:[250/495], Time: 0.37, lr: [0.007862184615253582], Loss: 2.113413, Acc:0.793625, Semantic loss: 0.794395, BCE loss: 0.554790, SB loss: 0.764228
2023-10-30 05:16:33,510 Epoch: [113/484] Iter:[260/495], Time: 0.37, lr: [0.007861798782191301], Loss: 2.110295, Acc:0.793416, Semantic loss: 0.792879, BCE loss: 0.553998, SB loss: 0.763418
2023-10-30 05:16:37,182 Epoch: [113/484] Iter:[270/495], Time: 0.37, lr: [0.007861412947025062], Loss: 2.108289, Acc:0.792453, Semantic loss: 0.793316, BCE loss: 0.550175, SB loss: 0.764798
2023-10-30 05:16:40,790 Epoch: [113/484] Iter:[280/495], Time: 0.37, lr: [0.007861027109754741], Loss: 2.108775, Acc:0.792589, Semantic loss: 0.794266, BCE loss: 0.549536, SB loss: 0.764973
2023-10-30 05:16:44,526 Epoch: [113/484] Iter:[290/495], Time: 0.37, lr: [0.00786064127038021], Loss: 2.102714, Acc:0.792857, Semantic loss: 0.792429, BCE loss: 0.546558, SB loss: 0.763727
2023-10-30 05:16:48,216 Epoch: [113/484] Iter:[300/495], Time: 0.37, lr: [0.007860255428901343], Loss: 2.101249, Acc:0.793516, Semantic loss: 0.792159, BCE loss: 0.546074, SB loss: 0.763017
2023-10-30 05:16:51,811 Epoch: [113/484] Iter:[310/495], Time: 0.37, lr: [0.007859869585318017], Loss: 2.097382, Acc:0.794309, Semantic loss: 0.790252, BCE loss: 0.545416, SB loss: 0.761714
2023-10-30 05:16:55,488 Epoch: [113/484] Iter:[320/495], Time: 0.37, lr: [0.0078594837396301], Loss: 2.094219, Acc:0.793732, Semantic loss: 0.788386, BCE loss: 0.545022, SB loss: 0.760811
2023-10-30 05:16:59,201 Epoch: [113/484] Iter:[330/495], Time: 0.37, lr: [0.00785909789183747], Loss: 2.090587, Acc:0.793967, Semantic loss: 0.787130, BCE loss: 0.543806, SB loss: 0.759651
2023-10-30 05:17:02,913 Epoch: [113/484] Iter:[340/495], Time: 0.37, lr: [0.007858712041939999], Loss: 2.095288, Acc:0.794372, Semantic loss: 0.789917, BCE loss: 0.544111, SB loss: 0.761260
2023-10-30 05:17:06,507 Epoch: [113/484] Iter:[350/495], Time: 0.37, lr: [0.007858326189937563], Loss: 2.097943, Acc:0.794640, Semantic loss: 0.791444, BCE loss: 0.544607, SB loss: 0.761892
2023-10-30 05:17:10,120 Epoch: [113/484] Iter:[360/495], Time: 0.37, lr: [0.007857940335830031], Loss: 2.097287, Acc:0.795320, Semantic loss: 0.790951, BCE loss: 0.544015, SB loss: 0.762322
2023-10-30 05:17:13,732 Epoch: [113/484] Iter:[370/495], Time: 0.37, lr: [0.007857554479617281], Loss: 2.095686, Acc:0.795727, Semantic loss: 0.790160, BCE loss: 0.543724, SB loss: 0.761802
2023-10-30 05:17:17,318 Epoch: [113/484] Iter:[380/495], Time: 0.37, lr: [0.007857168621299185], Loss: 2.094420, Acc:0.795877, Semantic loss: 0.789768, BCE loss: 0.544004, SB loss: 0.760647
2023-10-30 05:17:20,963 Epoch: [113/484] Iter:[390/495], Time: 0.37, lr: [0.007856782760875616], Loss: 2.093397, Acc:0.796000, Semantic loss: 0.789722, BCE loss: 0.542926, SB loss: 0.760749
2023-10-30 05:17:24,708 Epoch: [113/484] Iter:[400/495], Time: 0.37, lr: [0.00785639689834645], Loss: 2.093529, Acc:0.795728, Semantic loss: 0.791440, BCE loss: 0.540736, SB loss: 0.761353
2023-10-30 05:17:28,446 Epoch: [113/484] Iter:[410/495], Time: 0.37, lr: [0.00785601103371156], Loss: 2.090687, Acc:0.796511, Semantic loss: 0.788703, BCE loss: 0.541434, SB loss: 0.760551
2023-10-30 05:17:32,088 Epoch: [113/484] Iter:[420/495], Time: 0.37, lr: [0.007855625166970815], Loss: 2.093048, Acc:0.796531, Semantic loss: 0.790077, BCE loss: 0.541590, SB loss: 0.761381
2023-10-30 05:17:35,731 Epoch: [113/484] Iter:[430/495], Time: 0.37, lr: [0.007855239298124093], Loss: 2.092751, Acc:0.796455, Semantic loss: 0.790355, BCE loss: 0.540800, SB loss: 0.761596
2023-10-30 05:17:39,395 Epoch: [113/484] Iter:[440/495], Time: 0.37, lr: [0.007854853427171267], Loss: 2.095469, Acc:0.797182, Semantic loss: 0.792278, BCE loss: 0.540964, SB loss: 0.762227
2023-10-30 05:17:43,088 Epoch: [113/484] Iter:[450/495], Time: 0.37, lr: [0.007854467554112213], Loss: 2.095473, Acc:0.797615, Semantic loss: 0.792310, BCE loss: 0.540927, SB loss: 0.762236
2023-10-30 05:17:46,774 Epoch: [113/484] Iter:[460/495], Time: 0.37, lr: [0.007854081678946799], Loss: 2.096781, Acc:0.797304, Semantic loss: 0.792866, BCE loss: 0.541574, SB loss: 0.762341
2023-10-30 05:17:50,397 Epoch: [113/484] Iter:[470/495], Time: 0.37, lr: [0.007853695801674901], Loss: 2.105183, Acc:0.797472, Semantic loss: 0.797627, BCE loss: 0.544174, SB loss: 0.763382
2023-10-30 05:17:54,041 Epoch: [113/484] Iter:[480/495], Time: 0.37, lr: [0.007853309922296393], Loss: 2.106148, Acc:0.796777, Semantic loss: 0.799202, BCE loss: 0.543987, SB loss: 0.762958
2023-10-30 05:17:57,496 Epoch: [113/484] Iter:[490/495], Time: 0.37, lr: [0.007852924040811149], Loss: 2.107621, Acc:0.796087, Semantic loss: 0.799189, BCE loss: 0.544832, SB loss: 0.763600
2023-10-30 05:17:58,902 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:17:59,139 Loss: 2.158, MeanIU:  0.6707, Best_mIoU:  0.6907
2023-10-30 05:17:59,140 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385]
2023-10-30 05:18:01,405 Epoch: [114/484] Iter:[0/495], Time: 2.23, lr: [0.007852731099278462], Loss: 2.376904, Acc:0.901643, Semantic loss: 0.760568, BCE loss: 0.757606, SB loss: 0.858731
2023-10-30 05:18:05,265 Epoch: [114/484] Iter:[10/495], Time: 0.55, lr: [0.007852345214632876], Loss: 2.222550, Acc:0.755306, Semantic loss: 0.834720, BCE loss: 0.522699, SB loss: 0.865132
2023-10-30 05:18:08,913 Epoch: [114/484] Iter:[20/495], Time: 0.46, lr: [0.007851959327880235], Loss: 2.210159, Acc:0.761216, Semantic loss: 0.835727, BCE loss: 0.547899, SB loss: 0.826533
2023-10-30 05:18:12,513 Epoch: [114/484] Iter:[30/495], Time: 0.43, lr: [0.007851573439020416], Loss: 2.221095, Acc:0.765232, Semantic loss: 0.844001, BCE loss: 0.547890, SB loss: 0.829204
2023-10-30 05:18:16,231 Epoch: [114/484] Iter:[40/495], Time: 0.42, lr: [0.007851187548053291], Loss: 2.216237, Acc:0.778571, Semantic loss: 0.836093, BCE loss: 0.553674, SB loss: 0.826470
2023-10-30 05:18:19,927 Epoch: [114/484] Iter:[50/495], Time: 0.41, lr: [0.007850801654978734], Loss: 2.265819, Acc:0.778738, Semantic loss: 0.875189, BCE loss: 0.555542, SB loss: 0.835088
2023-10-30 05:18:23,588 Epoch: [114/484] Iter:[60/495], Time: 0.40, lr: [0.007850415759796616], Loss: 2.247733, Acc:0.780351, Semantic loss: 0.859103, BCE loss: 0.562011, SB loss: 0.826619
2023-10-30 05:18:27,388 Epoch: [114/484] Iter:[70/495], Time: 0.40, lr: [0.00785002986250681], Loss: 2.219303, Acc:0.781151, Semantic loss: 0.849161, BCE loss: 0.556418, SB loss: 0.813724
2023-10-30 05:18:31,088 Epoch: [114/484] Iter:[80/495], Time: 0.39, lr: [0.007849643963109195], Loss: 2.216784, Acc:0.781035, Semantic loss: 0.845647, BCE loss: 0.560086, SB loss: 0.811052
2023-10-30 05:18:34,704 Epoch: [114/484] Iter:[90/495], Time: 0.39, lr: [0.00784925806160364], Loss: 2.211223, Acc:0.784977, Semantic loss: 0.837295, BCE loss: 0.569808, SB loss: 0.804121
2023-10-30 05:18:38,495 Epoch: [114/484] Iter:[100/495], Time: 0.39, lr: [0.007848872157990018], Loss: 2.223642, Acc:0.783843, Semantic loss: 0.847348, BCE loss: 0.571902, SB loss: 0.804392
2023-10-30 05:18:42,197 Epoch: [114/484] Iter:[110/495], Time: 0.39, lr: [0.007848486252268203], Loss: 2.220332, Acc:0.782504, Semantic loss: 0.848829, BCE loss: 0.569331, SB loss: 0.802172
2023-10-30 05:18:45,817 Epoch: [114/484] Iter:[120/495], Time: 0.39, lr: [0.00784810034443807], Loss: 2.201513, Acc:0.782134, Semantic loss: 0.839594, BCE loss: 0.565066, SB loss: 0.796852
2023-10-30 05:18:49,400 Epoch: [114/484] Iter:[130/495], Time: 0.38, lr: [0.00784771443449949], Loss: 2.194283, Acc:0.786678, Semantic loss: 0.836143, BCE loss: 0.564552, SB loss: 0.793588
2023-10-30 05:18:53,018 Epoch: [114/484] Iter:[140/495], Time: 0.38, lr: [0.007847328522452337], Loss: 2.196539, Acc:0.787882, Semantic loss: 0.835811, BCE loss: 0.566739, SB loss: 0.793989
2023-10-30 05:18:56,750 Epoch: [114/484] Iter:[150/495], Time: 0.38, lr: [0.007846942608296485], Loss: 2.185408, Acc:0.788909, Semantic loss: 0.831229, BCE loss: 0.563314, SB loss: 0.790865
2023-10-30 05:19:00,406 Epoch: [114/484] Iter:[160/495], Time: 0.38, lr: [0.007846556692031808], Loss: 2.184172, Acc:0.790605, Semantic loss: 0.829822, BCE loss: 0.564504, SB loss: 0.789846
2023-10-30 05:19:04,075 Epoch: [114/484] Iter:[170/495], Time: 0.38, lr: [0.007846170773658177], Loss: 2.177568, Acc:0.791416, Semantic loss: 0.828708, BCE loss: 0.559697, SB loss: 0.789163
2023-10-30 05:19:07,675 Epoch: [114/484] Iter:[180/495], Time: 0.38, lr: [0.007845784853175464], Loss: 2.170733, Acc:0.792174, Semantic loss: 0.827251, BCE loss: 0.555974, SB loss: 0.787507
2023-10-30 05:19:11,340 Epoch: [114/484] Iter:[190/495], Time: 0.38, lr: [0.007845398930583546], Loss: 2.167419, Acc:0.792299, Semantic loss: 0.826480, BCE loss: 0.555158, SB loss: 0.785781
2023-10-30 05:19:14,878 Epoch: [114/484] Iter:[200/495], Time: 0.38, lr: [0.007845013005882296], Loss: 2.161203, Acc:0.791914, Semantic loss: 0.823944, BCE loss: 0.552905, SB loss: 0.784354
2023-10-30 05:19:18,560 Epoch: [114/484] Iter:[210/495], Time: 0.38, lr: [0.007844627079071584], Loss: 2.160255, Acc:0.789599, Semantic loss: 0.823658, BCE loss: 0.551892, SB loss: 0.784705
2023-10-30 05:19:22,185 Epoch: [114/484] Iter:[220/495], Time: 0.38, lr: [0.007844241150151284], Loss: 2.161288, Acc:0.790338, Semantic loss: 0.824226, BCE loss: 0.552724, SB loss: 0.784337
2023-10-30 05:19:25,811 Epoch: [114/484] Iter:[230/495], Time: 0.38, lr: [0.007843855219121272], Loss: 2.160927, Acc:0.790029, Semantic loss: 0.824286, BCE loss: 0.552519, SB loss: 0.784122
2023-10-30 05:19:29,431 Epoch: [114/484] Iter:[240/495], Time: 0.37, lr: [0.00784346928598142], Loss: 2.158349, Acc:0.789737, Semantic loss: 0.821731, BCE loss: 0.553606, SB loss: 0.783012
2023-10-30 05:19:33,108 Epoch: [114/484] Iter:[250/495], Time: 0.37, lr: [0.007843083350731597], Loss: 2.158064, Acc:0.790900, Semantic loss: 0.822031, BCE loss: 0.553445, SB loss: 0.782587
2023-10-30 05:19:36,701 Epoch: [114/484] Iter:[260/495], Time: 0.37, lr: [0.007842697413371682], Loss: 2.157081, Acc:0.792665, Semantic loss: 0.821322, BCE loss: 0.554145, SB loss: 0.781614
2023-10-30 05:19:40,426 Epoch: [114/484] Iter:[270/495], Time: 0.37, lr: [0.007842311473901544], Loss: 2.154898, Acc:0.793177, Semantic loss: 0.819246, BCE loss: 0.554736, SB loss: 0.780916
2023-10-30 05:19:44,200 Epoch: [114/484] Iter:[280/495], Time: 0.37, lr: [0.007841925532321058], Loss: 2.150379, Acc:0.793764, Semantic loss: 0.817356, BCE loss: 0.553425, SB loss: 0.779599
2023-10-30 05:19:47,855 Epoch: [114/484] Iter:[290/495], Time: 0.37, lr: [0.007841539588630096], Loss: 2.146341, Acc:0.794648, Semantic loss: 0.814326, BCE loss: 0.553495, SB loss: 0.778520
2023-10-30 05:19:51,477 Epoch: [114/484] Iter:[300/495], Time: 0.37, lr: [0.007841153642828533], Loss: 2.146054, Acc:0.793961, Semantic loss: 0.814742, BCE loss: 0.553526, SB loss: 0.777785
2023-10-30 05:19:55,105 Epoch: [114/484] Iter:[310/495], Time: 0.37, lr: [0.007840767694916241], Loss: 2.146413, Acc:0.793973, Semantic loss: 0.814362, BCE loss: 0.554834, SB loss: 0.777216
2023-10-30 05:19:58,812 Epoch: [114/484] Iter:[320/495], Time: 0.37, lr: [0.007840381744893092], Loss: 2.141633, Acc:0.793766, Semantic loss: 0.811861, BCE loss: 0.553978, SB loss: 0.775794
2023-10-30 05:20:02,483 Epoch: [114/484] Iter:[330/495], Time: 0.37, lr: [0.00783999579275896], Loss: 2.144537, Acc:0.792870, Semantic loss: 0.814220, BCE loss: 0.553604, SB loss: 0.776713
2023-10-30 05:20:06,130 Epoch: [114/484] Iter:[340/495], Time: 0.37, lr: [0.007839609838513716], Loss: 2.145310, Acc:0.792043, Semantic loss: 0.814686, BCE loss: 0.553469, SB loss: 0.777155
2023-10-30 05:20:09,867 Epoch: [114/484] Iter:[350/495], Time: 0.37, lr: [0.007839223882157235], Loss: 2.144524, Acc:0.791623, Semantic loss: 0.813458, BCE loss: 0.554034, SB loss: 0.777032
2023-10-30 05:20:13,597 Epoch: [114/484] Iter:[360/495], Time: 0.37, lr: [0.007838837923689392], Loss: 2.141227, Acc:0.792011, Semantic loss: 0.811768, BCE loss: 0.552677, SB loss: 0.776782
2023-10-30 05:20:17,313 Epoch: [114/484] Iter:[370/495], Time: 0.37, lr: [0.007838451963110055], Loss: 2.135742, Acc:0.792678, Semantic loss: 0.807887, BCE loss: 0.552191, SB loss: 0.775664
2023-10-30 05:20:20,908 Epoch: [114/484] Iter:[380/495], Time: 0.37, lr: [0.0078380660004191], Loss: 2.136531, Acc:0.792998, Semantic loss: 0.810002, BCE loss: 0.550301, SB loss: 0.776229
2023-10-30 05:20:24,563 Epoch: [114/484] Iter:[390/495], Time: 0.37, lr: [0.007837680035616402], Loss: 2.137906, Acc:0.792588, Semantic loss: 0.811120, BCE loss: 0.550777, SB loss: 0.776009
2023-10-30 05:20:28,261 Epoch: [114/484] Iter:[400/495], Time: 0.37, lr: [0.007837294068701827], Loss: 2.138796, Acc:0.792434, Semantic loss: 0.810517, BCE loss: 0.551348, SB loss: 0.776930
2023-10-30 05:20:31,993 Epoch: [114/484] Iter:[410/495], Time: 0.37, lr: [0.007836908099675254], Loss: 2.134988, Acc:0.793221, Semantic loss: 0.808452, BCE loss: 0.549990, SB loss: 0.776546
2023-10-30 05:20:35,686 Epoch: [114/484] Iter:[420/495], Time: 0.37, lr: [0.007836522128536555], Loss: 2.132516, Acc:0.793234, Semantic loss: 0.807689, BCE loss: 0.549032, SB loss: 0.775795
2023-10-30 05:20:39,353 Epoch: [114/484] Iter:[430/495], Time: 0.37, lr: [0.0078361361552856], Loss: 2.133042, Acc:0.793169, Semantic loss: 0.807922, BCE loss: 0.549080, SB loss: 0.776041
2023-10-30 05:20:43,070 Epoch: [114/484] Iter:[440/495], Time: 0.37, lr: [0.007835750179922267], Loss: 2.135283, Acc:0.792860, Semantic loss: 0.809866, BCE loss: 0.548433, SB loss: 0.776984
2023-10-30 05:20:46,741 Epoch: [114/484] Iter:[450/495], Time: 0.37, lr: [0.007835364202446422], Loss: 2.131117, Acc:0.792450, Semantic loss: 0.807955, BCE loss: 0.547268, SB loss: 0.775894
2023-10-30 05:20:50,325 Epoch: [114/484] Iter:[460/495], Time: 0.37, lr: [0.007834978222857943], Loss: 2.135522, Acc:0.792487, Semantic loss: 0.810402, BCE loss: 0.548722, SB loss: 0.776398
2023-10-30 05:20:54,092 Epoch: [114/484] Iter:[470/495], Time: 0.37, lr: [0.007834592241156702], Loss: 2.132759, Acc:0.792196, Semantic loss: 0.808745, BCE loss: 0.548280, SB loss: 0.775733
2023-10-30 05:20:57,732 Epoch: [114/484] Iter:[480/495], Time: 0.37, lr: [0.00783420625734257], Loss: 2.135732, Acc:0.792731, Semantic loss: 0.811174, BCE loss: 0.548239, SB loss: 0.776319
2023-10-30 05:21:01,190 Epoch: [114/484] Iter:[490/495], Time: 0.37, lr: [0.00783382027141542], Loss: 2.133016, Acc:0.793121, Semantic loss: 0.809715, BCE loss: 0.547195, SB loss: 0.776106
2023-10-30 05:21:02,594 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:21:02,831 Loss: 2.158, MeanIU:  0.6707, Best_mIoU:  0.6907
2023-10-30 05:21:02,831 [0.97216541 0.79567372 0.88952278 0.42211022 0.47177949 0.52297424
 0.61028909 0.70537564 0.8942203  0.5614402  0.91224332 0.75587184
 0.54151999 0.92029624 0.55790731 0.67845572 0.36968313 0.45399477
 0.70772385]
2023-10-30 05:21:04,879 Epoch: [115/484] Iter:[0/495], Time: 2.01, lr: [0.007833627277659422], Loss: 2.043446, Acc:0.782363, Semantic loss: 0.751484, BCE loss: 0.463006, SB loss: 0.828957
2023-10-30 05:21:08,846 Epoch: [115/484] Iter:[10/495], Time: 0.54, lr: [0.007833241288562508], Loss: 2.094338, Acc:0.760285, Semantic loss: 0.858263, BCE loss: 0.504565, SB loss: 0.731509
2023-10-30 05:21:12,530 Epoch: [115/484] Iter:[20/495], Time: 0.46, lr: [0.00783285529735226], Loss: 2.071489, Acc:0.786056, Semantic loss: 0.796900, BCE loss: 0.527141, SB loss: 0.747448
2023-10-30 05:21:16,153 Epoch: [115/484] Iter:[30/495], Time: 0.43, lr: [0.007832469304028547], Loss: 2.050089, Acc:0.791496, Semantic loss: 0.784138, BCE loss: 0.522177, SB loss: 0.743774
2023-10-30 05:21:19,739 Epoch: [115/484] Iter:[40/495], Time: 0.41, lr: [0.007832083308591246], Loss: 2.032767, Acc:0.783683, Semantic loss: 0.769923, BCE loss: 0.513832, SB loss: 0.749012
2023-10-30 05:21:23,441 Epoch: [115/484] Iter:[50/495], Time: 0.40, lr: [0.007831697311040227], Loss: 2.030647, Acc:0.795372, Semantic loss: 0.760861, BCE loss: 0.525413, SB loss: 0.744373
2023-10-30 05:21:27,194 Epoch: [115/484] Iter:[60/495], Time: 0.40, lr: [0.007831311311375362], Loss: 2.044342, Acc:0.786536, Semantic loss: 0.770730, BCE loss: 0.519790, SB loss: 0.753822
2023-10-30 05:21:30,844 Epoch: [115/484] Iter:[70/495], Time: 0.39, lr: [0.007830925309596526], Loss: 2.036691, Acc:0.792404, Semantic loss: 0.763821, BCE loss: 0.522433, SB loss: 0.750437
2023-10-30 05:21:34,452 Epoch: [115/484] Iter:[80/495], Time: 0.39, lr: [0.00783053930570359], Loss: 2.040901, Acc:0.798140, Semantic loss: 0.762002, BCE loss: 0.529260, SB loss: 0.749639
2023-10-30 05:21:38,057 Epoch: [115/484] Iter:[90/495], Time: 0.39, lr: [0.007830153299696427], Loss: 2.040096, Acc:0.798472, Semantic loss: 0.761605, BCE loss: 0.531381, SB loss: 0.747110
2023-10-30 05:21:41,752 Epoch: [115/484] Iter:[100/495], Time: 0.38, lr: [0.007829767291574911], Loss: 2.062278, Acc:0.798432, Semantic loss: 0.775320, BCE loss: 0.533514, SB loss: 0.753443
2023-10-30 05:21:45,453 Epoch: [115/484] Iter:[110/495], Time: 0.38, lr: [0.007829381281338912], Loss: 2.056937, Acc:0.796610, Semantic loss: 0.771278, BCE loss: 0.529487, SB loss: 0.756173
2023-10-30 05:21:48,995 Epoch: [115/484] Iter:[120/495], Time: 0.38, lr: [0.007828995268988306], Loss: 2.065090, Acc:0.796011, Semantic loss: 0.773276, BCE loss: 0.534801, SB loss: 0.757013
2023-10-30 05:21:52,583 Epoch: [115/484] Iter:[130/495], Time: 0.38, lr: [0.007828609254522962], Loss: 2.064808, Acc:0.794847, Semantic loss: 0.774881, BCE loss: 0.533626, SB loss: 0.756300
2023-10-30 05:21:56,261 Epoch: [115/484] Iter:[140/495], Time: 0.38, lr: [0.007828223237942755], Loss: 2.066166, Acc:0.794376, Semantic loss: 0.776576, BCE loss: 0.533572, SB loss: 0.756017
2023-10-30 05:21:59,974 Epoch: [115/484] Iter:[150/495], Time: 0.38, lr: [0.007827837219247557], Loss: 2.077374, Acc:0.795842, Semantic loss: 0.781434, BCE loss: 0.538761, SB loss: 0.757179
2023-10-30 05:22:03,632 Epoch: [115/484] Iter:[160/495], Time: 0.38, lr: [0.007827451198437238], Loss: 2.090877, Acc:0.794350, Semantic loss: 0.790862, BCE loss: 0.540442, SB loss: 0.759573
2023-10-30 05:22:07,296 Epoch: [115/484] Iter:[170/495], Time: 0.38, lr: [0.007827065175511676], Loss: 2.083592, Acc:0.793869, Semantic loss: 0.786784, BCE loss: 0.538251, SB loss: 0.758558
2023-10-30 05:22:10,850 Epoch: [115/484] Iter:[180/495], Time: 0.38, lr: [0.007826679150470738], Loss: 2.087103, Acc:0.793978, Semantic loss: 0.790437, BCE loss: 0.538367, SB loss: 0.758299
2023-10-30 05:22:14,527 Epoch: [115/484] Iter:[190/495], Time: 0.38, lr: [0.007826293123314298], Loss: 2.082571, Acc:0.793181, Semantic loss: 0.787481, BCE loss: 0.536636, SB loss: 0.758454
2023-10-30 05:22:18,212 Epoch: [115/484] Iter:[200/495], Time: 0.37, lr: [0.00782590709404223], Loss: 2.080350, Acc:0.792621, Semantic loss: 0.785298, BCE loss: 0.536475, SB loss: 0.758577
2023-10-30 05:22:21,894 Epoch: [115/484] Iter:[210/495], Time: 0.37, lr: [0.007825521062654408], Loss: 2.080759, Acc:0.793858, Semantic loss: 0.786387, BCE loss: 0.536364, SB loss: 0.758009
2023-10-30 05:22:25,604 Epoch: [115/484] Iter:[220/495], Time: 0.37, lr: [0.0078251350291507], Loss: 2.082619, Acc:0.794278, Semantic loss: 0.787016, BCE loss: 0.537775, SB loss: 0.757828
2023-10-30 05:22:29,278 Epoch: [115/484] Iter:[230/495], Time: 0.37, lr: [0.007824748993530981], Loss: 2.082772, Acc:0.794133, Semantic loss: 0.787338, BCE loss: 0.537315, SB loss: 0.758119
2023-10-30 05:22:32,991 Epoch: [115/484] Iter:[240/495], Time: 0.37, lr: [0.007824362955795122], Loss: 2.082247, Acc:0.794544, Semantic loss: 0.786497, BCE loss: 0.538949, SB loss: 0.756801
2023-10-30 05:22:36,635 Epoch: [115/484] Iter:[250/495], Time: 0.37, lr: [0.007823976915942997], Loss: 2.084019, Acc:0.793904, Semantic loss: 0.789467, BCE loss: 0.538468, SB loss: 0.756084
2023-10-30 05:22:40,263 Epoch: [115/484] Iter:[260/495], Time: 0.37, lr: [0.007823590873974476], Loss: 2.075066, Acc:0.794015, Semantic loss: 0.783588, BCE loss: 0.536298, SB loss: 0.755179
2023-10-30 05:22:43,934 Epoch: [115/484] Iter:[270/495], Time: 0.37, lr: [0.007823204829889433], Loss: 2.074073, Acc:0.792564, Semantic loss: 0.784219, BCE loss: 0.534731, SB loss: 0.755123
2023-10-30 05:22:47,497 Epoch: [115/484] Iter:[280/495], Time: 0.37, lr: [0.007822818783687744], Loss: 2.072217, Acc:0.791732, Semantic loss: 0.783679, BCE loss: 0.533394, SB loss: 0.755143
2023-10-30 05:22:51,141 Epoch: [115/484] Iter:[290/495], Time: 0.37, lr: [0.007822432735369275], Loss: 2.075461, Acc:0.791457, Semantic loss: 0.785157, BCE loss: 0.534282, SB loss: 0.756022
2023-10-30 05:22:54,837 Epoch: [115/484] Iter:[300/495], Time: 0.37, lr: [0.007822046684933902], Loss: 2.081863, Acc:0.791237, Semantic loss: 0.789131, BCE loss: 0.535815, SB loss: 0.756918
2023-10-30 05:22:58,531 Epoch: [115/484] Iter:[310/495], Time: 0.37, lr: [0.007821660632381496], Loss: 2.078987, Acc:0.791868, Semantic loss: 0.786957, BCE loss: 0.535836, SB loss: 0.756194
2023-10-30 05:23:02,274 Epoch: [115/484] Iter:[320/495], Time: 0.37, lr: [0.007821274577711928], Loss: 2.079034, Acc:0.792430, Semantic loss: 0.785997, BCE loss: 0.537472, SB loss: 0.755566
2023-10-30 05:23:05,986 Epoch: [115/484] Iter:[330/495], Time: 0.37, lr: [0.007820888520925075], Loss: 2.085490, Acc:0.793053, Semantic loss: 0.791196, BCE loss: 0.537432, SB loss: 0.756862
2023-10-30 05:23:09,532 Epoch: [115/484] Iter:[340/495], Time: 0.37, lr: [0.007820502462020804], Loss: 2.085002, Acc:0.792191, Semantic loss: 0.790350, BCE loss: 0.536958, SB loss: 0.757695
2023-10-30 05:23:13,182 Epoch: [115/484] Iter:[350/495], Time: 0.37, lr: [0.00782011640099899], Loss: 2.087727, Acc:0.791147, Semantic loss: 0.793868, BCE loss: 0.535762, SB loss: 0.758096
2023-10-30 05:23:16,878 Epoch: [115/484] Iter:[360/495], Time: 0.37, lr: [0.007819730337859503], Loss: 2.088553, Acc:0.790750, Semantic loss: 0.793472, BCE loss: 0.536185, SB loss: 0.758896
2023-10-30 05:23:20,488 Epoch: [115/484] Iter:[370/495], Time: 0.37, lr: [0.00781934427260222], Loss: 2.097914, Acc:0.790855, Semantic loss: 0.799145, BCE loss: 0.537400, SB loss: 0.761369
2023-10-30 05:23:24,206 Epoch: [115/484] Iter:[380/495], Time: 0.37, lr: [0.007818958205227008], Loss: 2.097878, Acc:0.790349, Semantic loss: 0.798892, BCE loss: 0.537065, SB loss: 0.761921
2023-10-30 05:23:28,104 Epoch: [115/484] Iter:[390/495], Time: 0.37, lr: [0.007818572135733741], Loss: 2.100197, Acc:0.790824, Semantic loss: 0.800101, BCE loss: 0.537389, SB loss: 0.762707
2023-10-30 05:23:31,760 Epoch: [115/484] Iter:[400/495], Time: 0.37, lr: [0.007818186064122292], Loss: 2.104870, Acc:0.792333, Semantic loss: 0.801146, BCE loss: 0.539760, SB loss: 0.763965
2023-10-30 05:23:35,456 Epoch: [115/484] Iter:[410/495], Time: 0.37, lr: [0.007817799990392532], Loss: 2.103472, Acc:0.791490, Semantic loss: 0.800241, BCE loss: 0.539664, SB loss: 0.763567
2023-10-30 05:23:39,158 Epoch: [115/484] Iter:[420/495], Time: 0.37, lr: [0.007817413914544335], Loss: 2.106888, Acc:0.792155, Semantic loss: 0.801057, BCE loss: 0.541966, SB loss: 0.763865
2023-10-30 05:23:42,816 Epoch: [115/484] Iter:[430/495], Time: 0.37, lr: [0.00781702783657757], Loss: 2.107778, Acc:0.790894, Semantic loss: 0.801919, BCE loss: 0.541496, SB loss: 0.764363
2023-10-30 05:23:46,477 Epoch: [115/484] Iter:[440/495], Time: 0.37, lr: [0.007816641756492113], Loss: 2.107477, Acc:0.791095, Semantic loss: 0.801632, BCE loss: 0.540715, SB loss: 0.765131
2023-10-30 05:23:50,072 Epoch: [115/484] Iter:[450/495], Time: 0.37, lr: [0.007816255674287832], Loss: 2.110614, Acc:0.790778, Semantic loss: 0.804197, BCE loss: 0.540194, SB loss: 0.766223
2023-10-30 05:23:53,781 Epoch: [115/484] Iter:[460/495], Time: 0.37, lr: [0.007815869589964603], Loss: 2.107908, Acc:0.790021, Semantic loss: 0.801379, BCE loss: 0.540665, SB loss: 0.765863
2023-10-30 05:23:57,483 Epoch: [115/484] Iter:[470/495], Time: 0.37, lr: [0.007815483503522295], Loss: 2.109916, Acc:0.790108, Semantic loss: 0.802565, BCE loss: 0.541489, SB loss: 0.765861
2023-10-30 05:24:01,173 Epoch: [115/484] Iter:[480/495], Time: 0.37, lr: [0.007815097414960781], Loss: 2.111849, Acc:0.790141, Semantic loss: 0.803289, BCE loss: 0.542710, SB loss: 0.765850
2023-10-30 05:24:04,684 Epoch: [115/484] Iter:[490/495], Time: 0.37, lr: [0.007814711324279935], Loss: 2.113080, Acc:0.789604, Semantic loss: 0.804760, BCE loss: 0.542636, SB loss: 0.765684
2023-10-30 05:27:00,893 0 [9.29264730e-01 6.05015330e-01 8.03794194e-01 1.23906504e-01
 2.32552002e-01 3.78560421e-01 3.77705886e-01 5.70017222e-01
 8.63047548e-01 4.30151036e-01 8.16513979e-01 5.95698569e-01
 6.83136843e-04 7.77563875e-01 3.62207160e-07 3.28363894e-02
 1.41529132e-02 3.08038034e-03 5.44219511e-01] 0.42625073626890675
2023-10-30 05:27:00,893 1 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429] 0.6401462719444075
2023-10-30 05:27:00,897 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:27:01,138 Loss: 2.144, MeanIU:  0.6401, Best_mIoU:  0.6907
2023-10-30 05:27:01,138 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429]
2023-10-30 05:27:03,114 Epoch: [116/484] Iter:[0/495], Time: 1.94, lr: [0.00781451827814472], Loss: 1.884159, Acc:0.718815, Semantic loss: 0.635036, BCE loss: 0.505595, SB loss: 0.743528
2023-10-30 05:27:06,948 Epoch: [116/484] Iter:[10/495], Time: 0.53, lr: [0.007814132184284632], Loss: 2.166975, Acc:0.808938, Semantic loss: 0.766281, BCE loss: 0.586424, SB loss: 0.814270
2023-10-30 05:27:10,643 Epoch: [116/484] Iter:[20/495], Time: 0.45, lr: [0.007813746088304891], Loss: 2.145364, Acc:0.789726, Semantic loss: 0.779028, BCE loss: 0.568250, SB loss: 0.798086
2023-10-30 05:27:14,147 Epoch: [116/484] Iter:[30/495], Time: 0.42, lr: [0.007813359990205368], Loss: 2.135962, Acc:0.802934, Semantic loss: 0.775511, BCE loss: 0.559824, SB loss: 0.800627
2023-10-30 05:27:17,643 Epoch: [116/484] Iter:[40/495], Time: 0.40, lr: [0.007812973889985935], Loss: 2.112108, Acc:0.803826, Semantic loss: 0.768584, BCE loss: 0.556630, SB loss: 0.786894
2023-10-30 05:27:21,261 Epoch: [116/484] Iter:[50/495], Time: 0.39, lr: [0.007812587787646465], Loss: 2.097708, Acc:0.801632, Semantic loss: 0.759731, BCE loss: 0.556522, SB loss: 0.781455
2023-10-30 05:27:24,826 Epoch: [116/484] Iter:[60/495], Time: 0.39, lr: [0.007812201683186827], Loss: 2.103282, Acc:0.805444, Semantic loss: 0.772452, BCE loss: 0.549552, SB loss: 0.781278
2023-10-30 05:27:28,383 Epoch: [116/484] Iter:[70/495], Time: 0.38, lr: [0.007811815576606897], Loss: 2.101577, Acc:0.799668, Semantic loss: 0.776136, BCE loss: 0.538917, SB loss: 0.786524
2023-10-30 05:27:31,963 Epoch: [116/484] Iter:[80/495], Time: 0.38, lr: [0.007811429467906546], Loss: 2.098091, Acc:0.798232, Semantic loss: 0.775584, BCE loss: 0.540413, SB loss: 0.782094
2023-10-30 05:27:35,433 Epoch: [116/484] Iter:[90/495], Time: 0.38, lr: [0.0078110433570856425], Loss: 2.097851, Acc:0.796963, Semantic loss: 0.776032, BCE loss: 0.545440, SB loss: 0.776379
2023-10-30 05:27:38,951 Epoch: [116/484] Iter:[100/495], Time: 0.37, lr: [0.007810657244144061], Loss: 2.091046, Acc:0.792254, Semantic loss: 0.777800, BCE loss: 0.536056, SB loss: 0.777190
2023-10-30 05:27:42,514 Epoch: [116/484] Iter:[110/495], Time: 0.37, lr: [0.007810271129081676], Loss: 2.084570, Acc:0.788936, Semantic loss: 0.775243, BCE loss: 0.534720, SB loss: 0.774607
2023-10-30 05:27:46,069 Epoch: [116/484] Iter:[120/495], Time: 0.37, lr: [0.007809885011898354], Loss: 2.078328, Acc:0.791781, Semantic loss: 0.771395, BCE loss: 0.538037, SB loss: 0.768896
2023-10-30 05:27:49,676 Epoch: [116/484] Iter:[130/495], Time: 0.37, lr: [0.007809498892593969], Loss: 2.085981, Acc:0.792711, Semantic loss: 0.770390, BCE loss: 0.544634, SB loss: 0.770957
2023-10-30 05:27:53,321 Epoch: [116/484] Iter:[140/495], Time: 0.37, lr: [0.007809112771168394], Loss: 2.088526, Acc:0.791334, Semantic loss: 0.773845, BCE loss: 0.541697, SB loss: 0.772984
2023-10-30 05:27:56,927 Epoch: [116/484] Iter:[150/495], Time: 0.37, lr: [0.0078087266476215], Loss: 2.079043, Acc:0.793120, Semantic loss: 0.769813, BCE loss: 0.540702, SB loss: 0.768528
2023-10-30 05:28:00,588 Epoch: [116/484] Iter:[160/495], Time: 0.37, lr: [0.007808340521953159], Loss: 2.083960, Acc:0.792001, Semantic loss: 0.772123, BCE loss: 0.541840, SB loss: 0.769996
2023-10-30 05:28:04,268 Epoch: [116/484] Iter:[170/495], Time: 0.37, lr: [0.007807954394163242], Loss: 2.094908, Acc:0.790805, Semantic loss: 0.781164, BCE loss: 0.543240, SB loss: 0.770503
2023-10-30 05:28:07,924 Epoch: [116/484] Iter:[180/495], Time: 0.37, lr: [0.007807568264251621], Loss: 2.103265, Acc:0.790935, Semantic loss: 0.783477, BCE loss: 0.549129, SB loss: 0.770659
2023-10-30 05:28:11,530 Epoch: [116/484] Iter:[190/495], Time: 0.37, lr: [0.007807182132218169], Loss: 2.104403, Acc:0.791280, Semantic loss: 0.784556, BCE loss: 0.548380, SB loss: 0.771466
2023-10-30 05:28:15,112 Epoch: [116/484] Iter:[200/495], Time: 0.37, lr: [0.0078067959980627575], Loss: 2.124945, Acc:0.789972, Semantic loss: 0.801546, BCE loss: 0.547585, SB loss: 0.775814
2023-10-30 05:28:18,737 Epoch: [116/484] Iter:[210/495], Time: 0.37, lr: [0.007806409861785256], Loss: 2.134019, Acc:0.787787, Semantic loss: 0.808103, BCE loss: 0.548208, SB loss: 0.777708
2023-10-30 05:28:22,392 Epoch: [116/484] Iter:[220/495], Time: 0.37, lr: [0.007806023723385538], Loss: 2.140427, Acc:0.786832, Semantic loss: 0.810131, BCE loss: 0.549799, SB loss: 0.780496
2023-10-30 05:28:26,096 Epoch: [116/484] Iter:[230/495], Time: 0.37, lr: [0.007805637582863476], Loss: 2.145672, Acc:0.785105, Semantic loss: 0.812068, BCE loss: 0.552370, SB loss: 0.781233
2023-10-30 05:28:29,691 Epoch: [116/484] Iter:[240/495], Time: 0.37, lr: [0.00780525144021894], Loss: 2.157704, Acc:0.785304, Semantic loss: 0.818615, BCE loss: 0.554055, SB loss: 0.785034
2023-10-30 05:28:33,323 Epoch: [116/484] Iter:[250/495], Time: 0.37, lr: [0.007804865295451802], Loss: 2.161248, Acc:0.783600, Semantic loss: 0.821029, BCE loss: 0.554165, SB loss: 0.786054
2023-10-30 05:28:37,009 Epoch: [116/484] Iter:[260/495], Time: 0.37, lr: [0.007804479148561934], Loss: 2.164000, Acc:0.782241, Semantic loss: 0.823602, BCE loss: 0.552519, SB loss: 0.787880
2023-10-30 05:28:40,617 Epoch: [116/484] Iter:[270/495], Time: 0.37, lr: [0.007804092999549207], Loss: 2.165081, Acc:0.783915, Semantic loss: 0.822540, BCE loss: 0.554563, SB loss: 0.787977
2023-10-30 05:28:44,445 Epoch: [116/484] Iter:[280/495], Time: 0.37, lr: [0.0078037068484134945], Loss: 2.175322, Acc:0.783492, Semantic loss: 0.827683, BCE loss: 0.557999, SB loss: 0.789641
2023-10-30 05:28:48,187 Epoch: [116/484] Iter:[290/495], Time: 0.37, lr: [0.007803320695154666], Loss: 2.180964, Acc:0.783852, Semantic loss: 0.831139, BCE loss: 0.559270, SB loss: 0.790554
2023-10-30 05:28:51,828 Epoch: [116/484] Iter:[300/495], Time: 0.37, lr: [0.007802934539772594], Loss: 2.177679, Acc:0.785124, Semantic loss: 0.827961, BCE loss: 0.559551, SB loss: 0.790168
2023-10-30 05:28:55,533 Epoch: [116/484] Iter:[310/495], Time: 0.37, lr: [0.00780254838226715], Loss: 2.180641, Acc:0.785179, Semantic loss: 0.830208, BCE loss: 0.558989, SB loss: 0.791444
2023-10-30 05:28:59,203 Epoch: [116/484] Iter:[320/495], Time: 0.37, lr: [0.007802162222638206], Loss: 2.183242, Acc:0.785323, Semantic loss: 0.830805, BCE loss: 0.559812, SB loss: 0.792625
2023-10-30 05:29:02,824 Epoch: [116/484] Iter:[330/495], Time: 0.37, lr: [0.0078017760608856315], Loss: 2.180352, Acc:0.786555, Semantic loss: 0.828247, BCE loss: 0.560426, SB loss: 0.791679
2023-10-30 05:29:06,494 Epoch: [116/484] Iter:[340/495], Time: 0.37, lr: [0.0078013898970093], Loss: 2.177396, Acc:0.786889, Semantic loss: 0.826485, BCE loss: 0.560871, SB loss: 0.790040
2023-10-30 05:29:10,213 Epoch: [116/484] Iter:[350/495], Time: 0.37, lr: [0.007801003731009084], Loss: 2.173986, Acc:0.787641, Semantic loss: 0.825186, BCE loss: 0.559741, SB loss: 0.789059
2023-10-30 05:29:13,857 Epoch: [116/484] Iter:[360/495], Time: 0.37, lr: [0.0078006175628848535], Loss: 2.179963, Acc:0.787820, Semantic loss: 0.827938, BCE loss: 0.563079, SB loss: 0.788947
2023-10-30 05:29:17,593 Epoch: [116/484] Iter:[370/495], Time: 0.37, lr: [0.007800231392636478], Loss: 2.177760, Acc:0.788683, Semantic loss: 0.826051, BCE loss: 0.562594, SB loss: 0.789115
2023-10-30 05:29:21,262 Epoch: [116/484] Iter:[380/495], Time: 0.37, lr: [0.007799845220263831], Loss: 2.176865, Acc:0.788888, Semantic loss: 0.825102, BCE loss: 0.562733, SB loss: 0.789030
2023-10-30 05:29:24,881 Epoch: [116/484] Iter:[390/495], Time: 0.37, lr: [0.007799459045766787], Loss: 2.172181, Acc:0.789313, Semantic loss: 0.822277, BCE loss: 0.562711, SB loss: 0.787193
2023-10-30 05:29:28,541 Epoch: [116/484] Iter:[400/495], Time: 0.37, lr: [0.007799072869145212], Loss: 2.169104, Acc:0.789477, Semantic loss: 0.820060, BCE loss: 0.562162, SB loss: 0.786882
2023-10-30 05:29:32,158 Epoch: [116/484] Iter:[410/495], Time: 0.37, lr: [0.007798686690398979], Loss: 2.169751, Acc:0.789062, Semantic loss: 0.821770, BCE loss: 0.561353, SB loss: 0.786629
2023-10-30 05:29:35,840 Epoch: [116/484] Iter:[420/495], Time: 0.37, lr: [0.0077983005095279626], Loss: 2.170083, Acc:0.789737, Semantic loss: 0.821524, BCE loss: 0.562043, SB loss: 0.786517
2023-10-30 05:29:39,416 Epoch: [116/484] Iter:[430/495], Time: 0.37, lr: [0.007797914326532032], Loss: 2.168695, Acc:0.789087, Semantic loss: 0.821078, BCE loss: 0.561833, SB loss: 0.785784
2023-10-30 05:29:43,096 Epoch: [116/484] Iter:[440/495], Time: 0.37, lr: [0.007797528141411058], Loss: 2.173424, Acc:0.788709, Semantic loss: 0.822925, BCE loss: 0.562593, SB loss: 0.787906
2023-10-30 05:29:46,731 Epoch: [116/484] Iter:[450/495], Time: 0.37, lr: [0.007797141954164912], Loss: 2.171692, Acc:0.789415, Semantic loss: 0.821570, BCE loss: 0.562321, SB loss: 0.787802
2023-10-30 05:29:50,413 Epoch: [116/484] Iter:[460/495], Time: 0.37, lr: [0.007796755764793464], Loss: 2.169378, Acc:0.789869, Semantic loss: 0.820374, BCE loss: 0.561871, SB loss: 0.787133
2023-10-30 05:29:54,064 Epoch: [116/484] Iter:[470/495], Time: 0.37, lr: [0.007796369573296589], Loss: 2.167898, Acc:0.790284, Semantic loss: 0.819503, BCE loss: 0.561790, SB loss: 0.786606
2023-10-30 05:29:57,725 Epoch: [116/484] Iter:[480/495], Time: 0.37, lr: [0.007795983379674156], Loss: 2.169387, Acc:0.790346, Semantic loss: 0.820608, BCE loss: 0.561606, SB loss: 0.787173
2023-10-30 05:30:01,254 Epoch: [116/484] Iter:[490/495], Time: 0.37, lr: [0.007795597183926036], Loss: 2.172262, Acc:0.790682, Semantic loss: 0.821709, BCE loss: 0.562367, SB loss: 0.788185
2023-10-30 05:30:02,652 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:30:02,893 Loss: 2.144, MeanIU:  0.6401, Best_mIoU:  0.6907
2023-10-30 05:30:02,893 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429]
2023-10-30 05:30:05,060 Epoch: [117/484] Iter:[0/495], Time: 2.13, lr: [0.007795404085254805], Loss: 1.849807, Acc:0.873177, Semantic loss: 0.609518, BCE loss: 0.446800, SB loss: 0.793489
2023-10-30 05:30:08,971 Epoch: [117/484] Iter:[10/495], Time: 0.55, lr: [0.0077950178863179145], Loss: 2.103467, Acc:0.810141, Semantic loss: 0.806191, BCE loss: 0.510061, SB loss: 0.787215
2023-10-30 05:30:12,571 Epoch: [117/484] Iter:[20/495], Time: 0.46, lr: [0.007794631685255017], Loss: 2.118805, Acc:0.798248, Semantic loss: 0.803210, BCE loss: 0.544704, SB loss: 0.770891
2023-10-30 05:30:16,167 Epoch: [117/484] Iter:[30/495], Time: 0.43, lr: [0.007794245482065982], Loss: 2.109295, Acc:0.795466, Semantic loss: 0.789172, BCE loss: 0.559619, SB loss: 0.760504
2023-10-30 05:30:19,788 Epoch: [117/484] Iter:[40/495], Time: 0.41, lr: [0.00779385927675068], Loss: 2.152381, Acc:0.791526, Semantic loss: 0.821235, BCE loss: 0.556733, SB loss: 0.774414
2023-10-30 05:30:23,434 Epoch: [117/484] Iter:[50/495], Time: 0.40, lr: [0.007793473069308986], Loss: 2.156855, Acc:0.784514, Semantic loss: 0.825773, BCE loss: 0.555968, SB loss: 0.775114
2023-10-30 05:30:26,970 Epoch: [117/484] Iter:[60/495], Time: 0.39, lr: [0.007793086859740768], Loss: 2.114629, Acc:0.782520, Semantic loss: 0.807876, BCE loss: 0.540921, SB loss: 0.765833
2023-10-30 05:30:30,787 Epoch: [117/484] Iter:[70/495], Time: 0.39, lr: [0.007792700648045897], Loss: 2.122394, Acc:0.777474, Semantic loss: 0.819783, BCE loss: 0.530263, SB loss: 0.772348
2023-10-30 05:30:34,401 Epoch: [117/484] Iter:[80/495], Time: 0.39, lr: [0.007792314434224247], Loss: 2.168263, Acc:0.780653, Semantic loss: 0.837820, BCE loss: 0.543802, SB loss: 0.786641
2023-10-30 05:30:38,091 Epoch: [117/484] Iter:[90/495], Time: 0.39, lr: [0.007791928218275687], Loss: 2.152907, Acc:0.783100, Semantic loss: 0.827607, BCE loss: 0.542358, SB loss: 0.782942
2023-10-30 05:30:41,743 Epoch: [117/484] Iter:[100/495], Time: 0.38, lr: [0.0077915420002000885], Loss: 2.162832, Acc:0.782721, Semantic loss: 0.836412, BCE loss: 0.540412, SB loss: 0.786008
2023-10-30 05:30:45,415 Epoch: [117/484] Iter:[110/495], Time: 0.38, lr: [0.007791155779997321], Loss: 2.156083, Acc:0.781953, Semantic loss: 0.831798, BCE loss: 0.539483, SB loss: 0.784802
2023-10-30 05:30:49,074 Epoch: [117/484] Iter:[120/495], Time: 0.38, lr: [0.007790769557667257], Loss: 2.143414, Acc:0.782187, Semantic loss: 0.822651, BCE loss: 0.540179, SB loss: 0.780585
2023-10-30 05:30:52,699 Epoch: [117/484] Iter:[130/495], Time: 0.38, lr: [0.007790383333209771], Loss: 2.144578, Acc:0.779921, Semantic loss: 0.828619, BCE loss: 0.535228, SB loss: 0.780732
2023-10-30 05:30:56,387 Epoch: [117/484] Iter:[140/495], Time: 0.38, lr: [0.007789997106624729], Loss: 2.147926, Acc:0.782761, Semantic loss: 0.825544, BCE loss: 0.543138, SB loss: 0.779244
2023-10-30 05:31:00,044 Epoch: [117/484] Iter:[150/495], Time: 0.38, lr: [0.007789610877912003], Loss: 2.142913, Acc:0.786362, Semantic loss: 0.818241, BCE loss: 0.545575, SB loss: 0.779097
2023-10-30 05:31:03,699 Epoch: [117/484] Iter:[160/495], Time: 0.38, lr: [0.0077892246470714676], Loss: 2.134055, Acc:0.787807, Semantic loss: 0.812028, BCE loss: 0.544262, SB loss: 0.777765
2023-10-30 05:31:07,371 Epoch: [117/484] Iter:[170/495], Time: 0.38, lr: [0.00778883841410299], Loss: 2.126113, Acc:0.788561, Semantic loss: 0.807581, BCE loss: 0.542923, SB loss: 0.775608
2023-10-30 05:31:11,100 Epoch: [117/484] Iter:[180/495], Time: 0.38, lr: [0.007788452179006444], Loss: 2.139143, Acc:0.788900, Semantic loss: 0.818419, BCE loss: 0.542829, SB loss: 0.777894
2023-10-30 05:31:14,758 Epoch: [117/484] Iter:[190/495], Time: 0.38, lr: [0.007788065941781698], Loss: 2.134890, Acc:0.790867, Semantic loss: 0.812524, BCE loss: 0.546525, SB loss: 0.775842
2023-10-30 05:31:18,455 Epoch: [117/484] Iter:[200/495], Time: 0.38, lr: [0.007787679702428623], Loss: 2.135265, Acc:0.791514, Semantic loss: 0.813727, BCE loss: 0.545729, SB loss: 0.775809
2023-10-30 05:31:22,097 Epoch: [117/484] Iter:[210/495], Time: 0.38, lr: [0.007787293460947093], Loss: 2.133736, Acc:0.791041, Semantic loss: 0.812374, BCE loss: 0.546123, SB loss: 0.775238
2023-10-30 05:31:25,816 Epoch: [117/484] Iter:[220/495], Time: 0.38, lr: [0.007786907217336976], Loss: 2.127603, Acc:0.789924, Semantic loss: 0.809432, BCE loss: 0.544907, SB loss: 0.773264
2023-10-30 05:31:29,472 Epoch: [117/484] Iter:[230/495], Time: 0.37, lr: [0.007786520971598145], Loss: 2.128748, Acc:0.791285, Semantic loss: 0.808049, BCE loss: 0.547540, SB loss: 0.773159
2023-10-30 05:31:33,083 Epoch: [117/484] Iter:[240/495], Time: 0.37, lr: [0.007786134723730469], Loss: 2.138458, Acc:0.792272, Semantic loss: 0.815351, BCE loss: 0.547641, SB loss: 0.775466
2023-10-30 05:31:36,690 Epoch: [117/484] Iter:[250/495], Time: 0.37, lr: [0.00778574847373382], Loss: 2.142970, Acc:0.791367, Semantic loss: 0.817927, BCE loss: 0.548060, SB loss: 0.776983
2023-10-30 05:31:40,281 Epoch: [117/484] Iter:[260/495], Time: 0.37, lr: [0.00778536222160807], Loss: 2.140764, Acc:0.791471, Semantic loss: 0.816650, BCE loss: 0.548421, SB loss: 0.775694
2023-10-30 05:31:43,923 Epoch: [117/484] Iter:[270/495], Time: 0.37, lr: [0.007784975967353089], Loss: 2.145507, Acc:0.791238, Semantic loss: 0.819004, BCE loss: 0.548859, SB loss: 0.777644
2023-10-30 05:31:47,632 Epoch: [117/484] Iter:[280/495], Time: 0.37, lr: [0.007784589710968745], Loss: 2.140676, Acc:0.791722, Semantic loss: 0.816963, BCE loss: 0.547135, SB loss: 0.776578
2023-10-30 05:31:51,285 Epoch: [117/484] Iter:[290/495], Time: 0.37, lr: [0.007784203452454915], Loss: 2.139014, Acc:0.790377, Semantic loss: 0.815274, BCE loss: 0.545973, SB loss: 0.777768
2023-10-30 05:31:54,998 Epoch: [117/484] Iter:[300/495], Time: 0.37, lr: [0.0077838171918114644], Loss: 2.141217, Acc:0.791191, Semantic loss: 0.813909, BCE loss: 0.548303, SB loss: 0.779004
2023-10-30 05:31:58,793 Epoch: [117/484] Iter:[310/495], Time: 0.37, lr: [0.007783430929038266], Loss: 2.139438, Acc:0.791226, Semantic loss: 0.812784, BCE loss: 0.547764, SB loss: 0.778891
2023-10-30 05:32:02,479 Epoch: [117/484] Iter:[320/495], Time: 0.37, lr: [0.007783044664135191], Loss: 2.135017, Acc:0.791963, Semantic loss: 0.809556, BCE loss: 0.548329, SB loss: 0.777132
2023-10-30 05:32:06,187 Epoch: [117/484] Iter:[330/495], Time: 0.37, lr: [0.00778265839710211], Loss: 2.140188, Acc:0.792020, Semantic loss: 0.811728, BCE loss: 0.550241, SB loss: 0.778219
2023-10-30 05:32:09,987 Epoch: [117/484] Iter:[340/495], Time: 0.37, lr: [0.0077822721279388945], Loss: 2.138503, Acc:0.792724, Semantic loss: 0.809305, BCE loss: 0.551960, SB loss: 0.777238
2023-10-30 05:32:13,625 Epoch: [117/484] Iter:[350/495], Time: 0.37, lr: [0.007781885856645412], Loss: 2.143169, Acc:0.793730, Semantic loss: 0.810895, BCE loss: 0.553778, SB loss: 0.778496
2023-10-30 05:32:17,263 Epoch: [117/484] Iter:[360/495], Time: 0.37, lr: [0.007781499583221538], Loss: 2.138975, Acc:0.794225, Semantic loss: 0.808867, BCE loss: 0.552846, SB loss: 0.777261
2023-10-30 05:32:20,971 Epoch: [117/484] Iter:[370/495], Time: 0.37, lr: [0.007781113307667139], Loss: 2.143275, Acc:0.794514, Semantic loss: 0.810267, BCE loss: 0.554141, SB loss: 0.778866
2023-10-30 05:32:24,550 Epoch: [117/484] Iter:[380/495], Time: 0.37, lr: [0.007780727029982087], Loss: 2.139887, Acc:0.794178, Semantic loss: 0.808291, BCE loss: 0.554047, SB loss: 0.777549
2023-10-30 05:32:28,264 Epoch: [117/484] Iter:[390/495], Time: 0.37, lr: [0.007780340750166256], Loss: 2.140195, Acc:0.793819, Semantic loss: 0.808333, BCE loss: 0.554853, SB loss: 0.777008
2023-10-30 05:32:31,961 Epoch: [117/484] Iter:[400/495], Time: 0.37, lr: [0.007779954468219513], Loss: 2.136724, Acc:0.793940, Semantic loss: 0.807481, BCE loss: 0.553424, SB loss: 0.775819
2023-10-30 05:32:35,656 Epoch: [117/484] Iter:[410/495], Time: 0.37, lr: [0.007779568184141731], Loss: 2.137390, Acc:0.793992, Semantic loss: 0.809346, BCE loss: 0.551880, SB loss: 0.776163
2023-10-30 05:32:39,347 Epoch: [117/484] Iter:[420/495], Time: 0.37, lr: [0.007779181897932778], Loss: 2.136885, Acc:0.793783, Semantic loss: 0.808934, BCE loss: 0.551167, SB loss: 0.776784
2023-10-30 05:32:43,020 Epoch: [117/484] Iter:[430/495], Time: 0.37, lr: [0.007778795609592525], Loss: 2.140604, Acc:0.793808, Semantic loss: 0.811311, BCE loss: 0.551669, SB loss: 0.777624
2023-10-30 05:32:46,746 Epoch: [117/484] Iter:[440/495], Time: 0.37, lr: [0.007778409319120845], Loss: 2.139477, Acc:0.793501, Semantic loss: 0.810573, BCE loss: 0.551311, SB loss: 0.777594
2023-10-30 05:32:50,351 Epoch: [117/484] Iter:[450/495], Time: 0.37, lr: [0.007778023026517608], Loss: 2.140482, Acc:0.794404, Semantic loss: 0.810336, BCE loss: 0.552439, SB loss: 0.777707
2023-10-30 05:32:54,075 Epoch: [117/484] Iter:[460/495], Time: 0.37, lr: [0.007777636731782682], Loss: 2.141971, Acc:0.794483, Semantic loss: 0.809834, BCE loss: 0.554055, SB loss: 0.778082
2023-10-30 05:32:57,691 Epoch: [117/484] Iter:[470/495], Time: 0.37, lr: [0.007777250434915941], Loss: 2.138929, Acc:0.794392, Semantic loss: 0.808490, BCE loss: 0.553092, SB loss: 0.777347
2023-10-30 05:33:01,346 Epoch: [117/484] Iter:[480/495], Time: 0.37, lr: [0.0077768641359172545], Loss: 2.138373, Acc:0.794648, Semantic loss: 0.808734, BCE loss: 0.553115, SB loss: 0.776524
2023-10-30 05:33:04,815 Epoch: [117/484] Iter:[490/495], Time: 0.37, lr: [0.007776477834786492], Loss: 2.140290, Acc:0.794230, Semantic loss: 0.808883, BCE loss: 0.554220, SB loss: 0.777186
2023-10-30 05:33:06,220 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:33:06,455 Loss: 2.144, MeanIU:  0.6401, Best_mIoU:  0.6907
2023-10-30 05:33:06,455 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429]
2023-10-30 05:33:08,269 Epoch: [118/484] Iter:[0/495], Time: 1.78, lr: [0.007776284683421543], Loss: 2.833045, Acc:0.643049, Semantic loss: 1.306547, BCE loss: 0.581841, SB loss: 0.944656
2023-10-30 05:33:12,212 Epoch: [118/484] Iter:[10/495], Time: 0.52, lr: [0.007775898379092424], Loss: 2.069529, Acc:0.777351, Semantic loss: 0.797581, BCE loss: 0.514742, SB loss: 0.757207
2023-10-30 05:33:15,885 Epoch: [118/484] Iter:[20/495], Time: 0.45, lr: [0.007775512072630907], Loss: 2.086228, Acc:0.783519, Semantic loss: 0.805559, BCE loss: 0.513732, SB loss: 0.766937
2023-10-30 05:33:19,626 Epoch: [118/484] Iter:[30/495], Time: 0.42, lr: [0.0077751257640368615], Loss: 2.017559, Acc:0.795477, Semantic loss: 0.775212, BCE loss: 0.491050, SB loss: 0.751297
2023-10-30 05:33:23,316 Epoch: [118/484] Iter:[40/495], Time: 0.41, lr: [0.007774739453310158], Loss: 2.001705, Acc:0.791054, Semantic loss: 0.768639, BCE loss: 0.489334, SB loss: 0.743733
2023-10-30 05:33:26,947 Epoch: [118/484] Iter:[50/495], Time: 0.40, lr: [0.007774353140450666], Loss: 2.009305, Acc:0.799536, Semantic loss: 0.759982, BCE loss: 0.506494, SB loss: 0.742829
2023-10-30 05:33:30,636 Epoch: [118/484] Iter:[60/495], Time: 0.40, lr: [0.007773966825458258], Loss: 2.011470, Acc:0.796220, Semantic loss: 0.759224, BCE loss: 0.512243, SB loss: 0.740003
2023-10-30 05:33:34,261 Epoch: [118/484] Iter:[70/495], Time: 0.39, lr: [0.007773580508332805], Loss: 2.020969, Acc:0.795095, Semantic loss: 0.759983, BCE loss: 0.517339, SB loss: 0.743647
2023-10-30 05:33:37,889 Epoch: [118/484] Iter:[80/495], Time: 0.39, lr: [0.0077731941890741745], Loss: 2.039491, Acc:0.794597, Semantic loss: 0.767542, BCE loss: 0.523776, SB loss: 0.748173
2023-10-30 05:33:41,480 Epoch: [118/484] Iter:[90/495], Time: 0.38, lr: [0.007772807867682238], Loss: 2.047331, Acc:0.794566, Semantic loss: 0.770238, BCE loss: 0.528945, SB loss: 0.748148
2023-10-30 05:33:45,166 Epoch: [118/484] Iter:[100/495], Time: 0.38, lr: [0.007772421544156866], Loss: 2.040736, Acc:0.791555, Semantic loss: 0.768606, BCE loss: 0.525933, SB loss: 0.746197
2023-10-30 05:33:48,818 Epoch: [118/484] Iter:[110/495], Time: 0.38, lr: [0.007772035218497929], Loss: 2.045013, Acc:0.791280, Semantic loss: 0.774115, BCE loss: 0.523081, SB loss: 0.747816
2023-10-30 05:33:52,416 Epoch: [118/484] Iter:[120/495], Time: 0.38, lr: [0.0077716488907052985], Loss: 2.046910, Acc:0.787557, Semantic loss: 0.776898, BCE loss: 0.520073, SB loss: 0.749938
2023-10-30 05:33:56,097 Epoch: [118/484] Iter:[130/495], Time: 0.38, lr: [0.007771262560778844], Loss: 2.067403, Acc:0.787661, Semantic loss: 0.786329, BCE loss: 0.527371, SB loss: 0.753703
2023-10-30 05:33:59,849 Epoch: [118/484] Iter:[140/495], Time: 0.38, lr: [0.007770876228718434], Loss: 2.076364, Acc:0.787036, Semantic loss: 0.789018, BCE loss: 0.532211, SB loss: 0.755135
2023-10-30 05:34:03,459 Epoch: [118/484] Iter:[150/495], Time: 0.38, lr: [0.007770489894523942], Loss: 2.081045, Acc:0.789140, Semantic loss: 0.789388, BCE loss: 0.534649, SB loss: 0.757009
2023-10-30 05:34:07,214 Epoch: [118/484] Iter:[160/495], Time: 0.38, lr: [0.007770103558195237], Loss: 2.073176, Acc:0.787455, Semantic loss: 0.783810, BCE loss: 0.534462, SB loss: 0.754904
2023-10-30 05:34:10,900 Epoch: [118/484] Iter:[170/495], Time: 0.38, lr: [0.007769717219732189], Loss: 2.074336, Acc:0.789663, Semantic loss: 0.783823, BCE loss: 0.535515, SB loss: 0.754998
2023-10-30 05:34:14,535 Epoch: [118/484] Iter:[180/495], Time: 0.38, lr: [0.0077693308791346675], Loss: 2.070154, Acc:0.790505, Semantic loss: 0.781438, BCE loss: 0.535827, SB loss: 0.752889
2023-10-30 05:34:18,262 Epoch: [118/484] Iter:[190/495], Time: 0.38, lr: [0.007768944536402545], Loss: 2.070656, Acc:0.790192, Semantic loss: 0.779761, BCE loss: 0.538037, SB loss: 0.752858
2023-10-30 05:34:21,831 Epoch: [118/484] Iter:[200/495], Time: 0.37, lr: [0.007768558191535688], Loss: 2.068649, Acc:0.789692, Semantic loss: 0.778517, BCE loss: 0.536216, SB loss: 0.753916
2023-10-30 05:34:25,469 Epoch: [118/484] Iter:[210/495], Time: 0.37, lr: [0.007768171844533972], Loss: 2.065001, Acc:0.791618, Semantic loss: 0.775855, BCE loss: 0.537683, SB loss: 0.751463
2023-10-30 05:34:29,134 Epoch: [118/484] Iter:[220/495], Time: 0.37, lr: [0.007767785495397264], Loss: 2.069892, Acc:0.791527, Semantic loss: 0.779376, BCE loss: 0.536830, SB loss: 0.753686
2023-10-30 05:34:32,769 Epoch: [118/484] Iter:[230/495], Time: 0.37, lr: [0.007767399144125434], Loss: 2.068902, Acc:0.789557, Semantic loss: 0.780151, BCE loss: 0.534470, SB loss: 0.754281
2023-10-30 05:34:36,539 Epoch: [118/484] Iter:[240/495], Time: 0.37, lr: [0.007767012790718354], Loss: 2.072184, Acc:0.790928, Semantic loss: 0.782216, BCE loss: 0.535007, SB loss: 0.754961
2023-10-30 05:34:40,200 Epoch: [118/484] Iter:[250/495], Time: 0.37, lr: [0.007766626435175892], Loss: 2.069389, Acc:0.790548, Semantic loss: 0.781049, BCE loss: 0.534982, SB loss: 0.753358
2023-10-30 05:34:43,813 Epoch: [118/484] Iter:[260/495], Time: 0.37, lr: [0.007766240077497919], Loss: 2.066906, Acc:0.790951, Semantic loss: 0.780836, BCE loss: 0.532976, SB loss: 0.753094
2023-10-30 05:34:47,528 Epoch: [118/484] Iter:[270/495], Time: 0.37, lr: [0.007765853717684306], Loss: 2.069958, Acc:0.791286, Semantic loss: 0.781898, BCE loss: 0.534143, SB loss: 0.753917
2023-10-30 05:34:51,176 Epoch: [118/484] Iter:[280/495], Time: 0.37, lr: [0.007765467355734922], Loss: 2.070075, Acc:0.791795, Semantic loss: 0.779924, BCE loss: 0.536051, SB loss: 0.754100
2023-10-30 05:34:54,882 Epoch: [118/484] Iter:[290/495], Time: 0.37, lr: [0.007765080991649638], Loss: 2.071928, Acc:0.791403, Semantic loss: 0.780734, BCE loss: 0.536075, SB loss: 0.755119
2023-10-30 05:34:58,553 Epoch: [118/484] Iter:[300/495], Time: 0.37, lr: [0.007764694625428324], Loss: 2.067173, Acc:0.791905, Semantic loss: 0.779324, BCE loss: 0.532922, SB loss: 0.754927
2023-10-30 05:35:02,274 Epoch: [118/484] Iter:[310/495], Time: 0.37, lr: [0.007764308257070849], Loss: 2.067875, Acc:0.791180, Semantic loss: 0.781255, BCE loss: 0.531245, SB loss: 0.755376
2023-10-30 05:35:05,969 Epoch: [118/484] Iter:[320/495], Time: 0.37, lr: [0.007763921886577085], Loss: 2.071492, Acc:0.790030, Semantic loss: 0.783861, BCE loss: 0.532384, SB loss: 0.755246
2023-10-30 05:35:09,731 Epoch: [118/484] Iter:[330/495], Time: 0.37, lr: [0.0077635355139469], Loss: 2.070234, Acc:0.790222, Semantic loss: 0.781628, BCE loss: 0.533632, SB loss: 0.754975
2023-10-30 05:35:13,424 Epoch: [118/484] Iter:[340/495], Time: 0.37, lr: [0.007763149139180165], Loss: 2.075434, Acc:0.790887, Semantic loss: 0.784521, BCE loss: 0.535220, SB loss: 0.755693
2023-10-30 05:35:17,091 Epoch: [118/484] Iter:[350/495], Time: 0.37, lr: [0.007762762762276752], Loss: 2.070828, Acc:0.790722, Semantic loss: 0.782331, BCE loss: 0.534551, SB loss: 0.753946
2023-10-30 05:35:20,768 Epoch: [118/484] Iter:[360/495], Time: 0.37, lr: [0.0077623763832365255], Loss: 2.072420, Acc:0.790867, Semantic loss: 0.782935, BCE loss: 0.535086, SB loss: 0.754398
2023-10-30 05:35:24,474 Epoch: [118/484] Iter:[370/495], Time: 0.37, lr: [0.007761990002059361], Loss: 2.076052, Acc:0.790867, Semantic loss: 0.784782, BCE loss: 0.535565, SB loss: 0.755705
2023-10-30 05:35:28,184 Epoch: [118/484] Iter:[380/495], Time: 0.37, lr: [0.007761603618745128], Loss: 2.078687, Acc:0.790368, Semantic loss: 0.786803, BCE loss: 0.535631, SB loss: 0.756254
2023-10-30 05:35:31,857 Epoch: [118/484] Iter:[390/495], Time: 0.37, lr: [0.007761217233293693], Loss: 2.079134, Acc:0.790242, Semantic loss: 0.786077, BCE loss: 0.536188, SB loss: 0.756870
2023-10-30 05:35:35,561 Epoch: [118/484] Iter:[400/495], Time: 0.37, lr: [0.0077608308457049295], Loss: 2.074985, Acc:0.789716, Semantic loss: 0.783603, BCE loss: 0.535448, SB loss: 0.755935
2023-10-30 05:35:39,209 Epoch: [118/484] Iter:[410/495], Time: 0.37, lr: [0.0077604444559787045], Loss: 2.075698, Acc:0.788899, Semantic loss: 0.783631, BCE loss: 0.534659, SB loss: 0.757408
2023-10-30 05:35:43,004 Epoch: [118/484] Iter:[420/495], Time: 0.37, lr: [0.00776005806411489], Loss: 2.076292, Acc:0.790007, Semantic loss: 0.783305, BCE loss: 0.535616, SB loss: 0.757372
2023-10-30 05:35:46,623 Epoch: [118/484] Iter:[430/495], Time: 0.37, lr: [0.0077596716701133555], Loss: 2.085378, Acc:0.790472, Semantic loss: 0.787821, BCE loss: 0.537775, SB loss: 0.759782
2023-10-30 05:35:50,206 Epoch: [118/484] Iter:[440/495], Time: 0.37, lr: [0.00775928527397397], Loss: 2.085185, Acc:0.789440, Semantic loss: 0.787922, BCE loss: 0.537384, SB loss: 0.759879
2023-10-30 05:35:53,791 Epoch: [118/484] Iter:[450/495], Time: 0.37, lr: [0.007758898875696604], Loss: 2.083388, Acc:0.789612, Semantic loss: 0.787021, BCE loss: 0.536535, SB loss: 0.759832
2023-10-30 05:35:57,543 Epoch: [118/484] Iter:[460/495], Time: 0.37, lr: [0.007758512475281127], Loss: 2.085087, Acc:0.789328, Semantic loss: 0.787850, BCE loss: 0.537390, SB loss: 0.759847
2023-10-30 05:36:01,311 Epoch: [118/484] Iter:[470/495], Time: 0.37, lr: [0.0077581260727274115], Loss: 2.084863, Acc:0.789416, Semantic loss: 0.787622, BCE loss: 0.537287, SB loss: 0.759955
2023-10-30 05:36:05,101 Epoch: [118/484] Iter:[480/495], Time: 0.37, lr: [0.007757739668035324], Loss: 2.086378, Acc:0.789772, Semantic loss: 0.789171, BCE loss: 0.536711, SB loss: 0.760496
2023-10-30 05:36:08,660 Epoch: [118/484] Iter:[490/495], Time: 0.37, lr: [0.007757353261204734], Loss: 2.086736, Acc:0.790467, Semantic loss: 0.788771, BCE loss: 0.537688, SB loss: 0.760277
2023-10-30 05:36:10,050 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:36:10,296 Loss: 2.144, MeanIU:  0.6401, Best_mIoU:  0.6907
2023-10-30 05:36:10,296 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429]
2023-10-30 05:36:12,372 Epoch: [119/484] Iter:[0/495], Time: 2.04, lr: [0.0077571600569874615], Loss: 2.679541, Acc:0.770798, Semantic loss: 1.009460, BCE loss: 0.698556, SB loss: 0.971525
2023-10-30 05:36:16,223 Epoch: [119/484] Iter:[10/495], Time: 0.54, lr: [0.007756773646948877], Loss: 2.143081, Acc:0.783534, Semantic loss: 0.786426, BCE loss: 0.580080, SB loss: 0.776575
2023-10-30 05:36:19,800 Epoch: [119/484] Iter:[20/495], Time: 0.45, lr: [0.007756387234771464], Loss: 2.112320, Acc:0.790932, Semantic loss: 0.785344, BCE loss: 0.558215, SB loss: 0.768761
2023-10-30 05:36:23,487 Epoch: [119/484] Iter:[30/495], Time: 0.42, lr: [0.007756000820455097], Loss: 2.056395, Acc:0.787239, Semantic loss: 0.762582, BCE loss: 0.541087, SB loss: 0.752725
2023-10-30 05:36:27,047 Epoch: [119/484] Iter:[40/495], Time: 0.41, lr: [0.007755614403999641], Loss: 2.079314, Acc:0.780216, Semantic loss: 0.772008, BCE loss: 0.541139, SB loss: 0.766167
2023-10-30 05:36:30,718 Epoch: [119/484] Iter:[50/495], Time: 0.40, lr: [0.007755227985404969], Loss: 2.071845, Acc:0.780985, Semantic loss: 0.769824, BCE loss: 0.535906, SB loss: 0.766115
2023-10-30 05:36:34,284 Epoch: [119/484] Iter:[60/495], Time: 0.39, lr: [0.007754841564670949], Loss: 2.058038, Acc:0.780557, Semantic loss: 0.772561, BCE loss: 0.521887, SB loss: 0.763591
2023-10-30 05:36:38,004 Epoch: [119/484] Iter:[70/495], Time: 0.39, lr: [0.007754455141797451], Loss: 2.053666, Acc:0.778250, Semantic loss: 0.772645, BCE loss: 0.520724, SB loss: 0.760296
2023-10-30 05:36:41,602 Epoch: [119/484] Iter:[80/495], Time: 0.39, lr: [0.007754068716784345], Loss: 2.056522, Acc:0.777631, Semantic loss: 0.770569, BCE loss: 0.524728, SB loss: 0.761226
2023-10-30 05:36:45,349 Epoch: [119/484] Iter:[90/495], Time: 0.38, lr: [0.0077536822896315], Loss: 2.050638, Acc:0.782460, Semantic loss: 0.766918, BCE loss: 0.524607, SB loss: 0.759113
2023-10-30 05:36:49,007 Epoch: [119/484] Iter:[100/495], Time: 0.38, lr: [0.007753295860338785], Loss: 2.060865, Acc:0.787041, Semantic loss: 0.771140, BCE loss: 0.531168, SB loss: 0.758556
2023-10-30 05:36:52,709 Epoch: [119/484] Iter:[110/495], Time: 0.38, lr: [0.007752909428906072], Loss: 2.052568, Acc:0.790264, Semantic loss: 0.763477, BCE loss: 0.534294, SB loss: 0.754797
2023-10-30 05:36:56,418 Epoch: [119/484] Iter:[120/495], Time: 0.38, lr: [0.00775252299533323], Loss: 2.061162, Acc:0.790454, Semantic loss: 0.769243, BCE loss: 0.535531, SB loss: 0.756388
2023-10-30 05:37:00,108 Epoch: [119/484] Iter:[130/495], Time: 0.38, lr: [0.007752136559620128], Loss: 2.052557, Acc:0.793465, Semantic loss: 0.764577, BCE loss: 0.534909, SB loss: 0.753071
2023-10-30 05:37:03,950 Epoch: [119/484] Iter:[140/495], Time: 0.38, lr: [0.007751750121766635], Loss: 2.052474, Acc:0.794479, Semantic loss: 0.764467, BCE loss: 0.536427, SB loss: 0.751581
2023-10-30 05:37:07,684 Epoch: [119/484] Iter:[150/495], Time: 0.38, lr: [0.007751363681772621], Loss: 2.061368, Acc:0.792048, Semantic loss: 0.772870, BCE loss: 0.534506, SB loss: 0.753991
2023-10-30 05:37:11,360 Epoch: [119/484] Iter:[160/495], Time: 0.38, lr: [0.007750977239637955], Loss: 2.074822, Acc:0.793460, Semantic loss: 0.777295, BCE loss: 0.540995, SB loss: 0.756531
2023-10-30 05:37:14,974 Epoch: [119/484] Iter:[170/495], Time: 0.38, lr: [0.007750590795362508], Loss: 2.068007, Acc:0.794957, Semantic loss: 0.772852, BCE loss: 0.539295, SB loss: 0.755860
2023-10-30 05:37:18,585 Epoch: [119/484] Iter:[180/495], Time: 0.38, lr: [0.007750204348946149], Loss: 2.062740, Acc:0.794380, Semantic loss: 0.771423, BCE loss: 0.533952, SB loss: 0.757366
2023-10-30 05:37:22,260 Epoch: [119/484] Iter:[190/495], Time: 0.38, lr: [0.007749817900388748], Loss: 2.064818, Acc:0.795251, Semantic loss: 0.773710, BCE loss: 0.533569, SB loss: 0.757539
2023-10-30 05:37:25,932 Epoch: [119/484] Iter:[200/495], Time: 0.38, lr: [0.007749431449690174], Loss: 2.073744, Acc:0.795723, Semantic loss: 0.781064, BCE loss: 0.534140, SB loss: 0.758540
2023-10-30 05:37:29,609 Epoch: [119/484] Iter:[210/495], Time: 0.38, lr: [0.007749044996850296], Loss: 2.074558, Acc:0.793379, Semantic loss: 0.782332, BCE loss: 0.533451, SB loss: 0.758775
2023-10-30 05:37:33,338 Epoch: [119/484] Iter:[220/495], Time: 0.38, lr: [0.007748658541868984], Loss: 2.081100, Acc:0.793147, Semantic loss: 0.784220, BCE loss: 0.538152, SB loss: 0.758728
2023-10-30 05:37:37,000 Epoch: [119/484] Iter:[230/495], Time: 0.38, lr: [0.0077482720847461065], Loss: 2.080809, Acc:0.791604, Semantic loss: 0.784103, BCE loss: 0.538089, SB loss: 0.758616
2023-10-30 05:37:40,704 Epoch: [119/484] Iter:[240/495], Time: 0.37, lr: [0.007747885625481534], Loss: 2.088176, Acc:0.792870, Semantic loss: 0.787254, BCE loss: 0.540104, SB loss: 0.760818
2023-10-30 05:37:44,484 Epoch: [119/484] Iter:[250/495], Time: 0.38, lr: [0.007747499164075136], Loss: 2.090824, Acc:0.793650, Semantic loss: 0.789192, BCE loss: 0.540332, SB loss: 0.761299
2023-10-30 05:37:48,095 Epoch: [119/484] Iter:[260/495], Time: 0.37, lr: [0.007747112700526782], Loss: 2.093170, Acc:0.794304, Semantic loss: 0.791021, BCE loss: 0.540413, SB loss: 0.761735
2023-10-30 05:37:51,860 Epoch: [119/484] Iter:[270/495], Time: 0.37, lr: [0.00774672623483634], Loss: 2.097248, Acc:0.793566, Semantic loss: 0.797587, BCE loss: 0.538320, SB loss: 0.761340
2023-10-30 05:37:55,519 Epoch: [119/484] Iter:[280/495], Time: 0.37, lr: [0.007746339767003682], Loss: 2.095755, Acc:0.794414, Semantic loss: 0.795997, BCE loss: 0.538518, SB loss: 0.761239
2023-10-30 05:37:59,243 Epoch: [119/484] Iter:[290/495], Time: 0.37, lr: [0.007745953297028674], Loss: 2.097587, Acc:0.794843, Semantic loss: 0.797120, BCE loss: 0.538755, SB loss: 0.761713
2023-10-30 05:38:02,912 Epoch: [119/484] Iter:[300/495], Time: 0.37, lr: [0.007745566824911189], Loss: 2.098331, Acc:0.794202, Semantic loss: 0.795766, BCE loss: 0.540790, SB loss: 0.761775
2023-10-30 05:38:06,676 Epoch: [119/484] Iter:[310/495], Time: 0.37, lr: [0.007745180350651092], Loss: 2.101038, Acc:0.794761, Semantic loss: 0.796819, BCE loss: 0.542634, SB loss: 0.761585
2023-10-30 05:38:10,264 Epoch: [119/484] Iter:[320/495], Time: 0.37, lr: [0.007744793874248257], Loss: 2.103568, Acc:0.795069, Semantic loss: 0.797818, BCE loss: 0.543147, SB loss: 0.762603
2023-10-30 05:38:13,918 Epoch: [119/484] Iter:[330/495], Time: 0.37, lr: [0.007744407395702551], Loss: 2.104545, Acc:0.793958, Semantic loss: 0.799037, BCE loss: 0.541743, SB loss: 0.763765
2023-10-30 05:38:17,549 Epoch: [119/484] Iter:[340/495], Time: 0.37, lr: [0.0077440209150138415], Loss: 2.108787, Acc:0.793007, Semantic loss: 0.800635, BCE loss: 0.543725, SB loss: 0.764427
2023-10-30 05:38:21,235 Epoch: [119/484] Iter:[350/495], Time: 0.37, lr: [0.007743634432182002], Loss: 2.111203, Acc:0.792935, Semantic loss: 0.800904, BCE loss: 0.544861, SB loss: 0.765438
2023-10-30 05:38:24,853 Epoch: [119/484] Iter:[360/495], Time: 0.37, lr: [0.007743247947206899], Loss: 2.112255, Acc:0.792545, Semantic loss: 0.802082, BCE loss: 0.544284, SB loss: 0.765889
2023-10-30 05:38:28,570 Epoch: [119/484] Iter:[370/495], Time: 0.37, lr: [0.007742861460088402], Loss: 2.110244, Acc:0.792830, Semantic loss: 0.801100, BCE loss: 0.544085, SB loss: 0.765058
2023-10-30 05:38:32,197 Epoch: [119/484] Iter:[380/495], Time: 0.37, lr: [0.007742474970826381], Loss: 2.112331, Acc:0.792679, Semantic loss: 0.804541, BCE loss: 0.543253, SB loss: 0.764536
2023-10-30 05:38:35,993 Epoch: [119/484] Iter:[390/495], Time: 0.37, lr: [0.007742088479420702], Loss: 2.114370, Acc:0.791735, Semantic loss: 0.805676, BCE loss: 0.543513, SB loss: 0.765181
2023-10-30 05:38:39,612 Epoch: [119/484] Iter:[400/495], Time: 0.37, lr: [0.00774170198587124], Loss: 2.114295, Acc:0.791665, Semantic loss: 0.804145, BCE loss: 0.545136, SB loss: 0.765015
2023-10-30 05:38:43,246 Epoch: [119/484] Iter:[410/495], Time: 0.37, lr: [0.0077413154901778605], Loss: 2.113801, Acc:0.792090, Semantic loss: 0.802893, BCE loss: 0.545408, SB loss: 0.765500
2023-10-30 05:38:46,937 Epoch: [119/484] Iter:[420/495], Time: 0.37, lr: [0.007740928992340431], Loss: 2.111449, Acc:0.793023, Semantic loss: 0.800920, BCE loss: 0.545851, SB loss: 0.764678
2023-10-30 05:38:50,631 Epoch: [119/484] Iter:[430/495], Time: 0.37, lr: [0.007740542492358825], Loss: 2.109004, Acc:0.793042, Semantic loss: 0.799949, BCE loss: 0.544612, SB loss: 0.764442
2023-10-30 05:38:54,295 Epoch: [119/484] Iter:[440/495], Time: 0.37, lr: [0.00774015599023291], Loss: 2.107427, Acc:0.793747, Semantic loss: 0.798182, BCE loss: 0.544777, SB loss: 0.764468
2023-10-30 05:38:58,006 Epoch: [119/484] Iter:[450/495], Time: 0.37, lr: [0.0077397694859625546], Loss: 2.104494, Acc:0.794401, Semantic loss: 0.796385, BCE loss: 0.544603, SB loss: 0.763506
2023-10-30 05:39:01,625 Epoch: [119/484] Iter:[460/495], Time: 0.37, lr: [0.0077393829795476266], Loss: 2.103298, Acc:0.794121, Semantic loss: 0.796631, BCE loss: 0.543197, SB loss: 0.763470
2023-10-30 05:39:05,421 Epoch: [119/484] Iter:[470/495], Time: 0.37, lr: [0.007738996470987997], Loss: 2.101318, Acc:0.793846, Semantic loss: 0.796960, BCE loss: 0.541445, SB loss: 0.762913
2023-10-30 05:39:09,028 Epoch: [119/484] Iter:[480/495], Time: 0.37, lr: [0.007738609960283535], Loss: 2.101651, Acc:0.794044, Semantic loss: 0.795958, BCE loss: 0.542795, SB loss: 0.762898
2023-10-30 05:39:12,504 Epoch: [119/484] Iter:[490/495], Time: 0.37, lr: [0.007738223447434109], Loss: 2.101511, Acc:0.793669, Semantic loss: 0.795377, BCE loss: 0.543042, SB loss: 0.763091
2023-10-30 05:39:13,908 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:39:14,148 Loss: 2.144, MeanIU:  0.6401, Best_mIoU:  0.6907
2023-10-30 05:39:14,148 [0.96934482 0.77413833 0.88291623 0.38598066 0.42763004 0.51712861
 0.56137472 0.69862125 0.89860869 0.55665149 0.92484684 0.6321122
 0.36458529 0.90599025 0.50493222 0.63915191 0.53836347 0.32984785
 0.65055429]
2023-10-30 05:39:16,283 Epoch: [120/484] Iter:[0/495], Time: 2.10, lr: [0.007738030190204992], Loss: 1.939484, Acc:0.818958, Semantic loss: 0.809268, BCE loss: 0.411274, SB loss: 0.718942
2023-10-30 05:39:20,102 Epoch: [120/484] Iter:[10/495], Time: 0.54, lr: [0.0077376436741378755], Loss: 2.055459, Acc:0.788628, Semantic loss: 0.771820, BCE loss: 0.554788, SB loss: 0.728851
2023-10-30 05:39:23,671 Epoch: [120/484] Iter:[20/495], Time: 0.45, lr: [0.007737257155925465], Loss: 2.110217, Acc:0.776260, Semantic loss: 0.798841, BCE loss: 0.553715, SB loss: 0.757660
2023-10-30 05:39:27,394 Epoch: [120/484] Iter:[30/495], Time: 0.43, lr: [0.007736870635567634], Loss: 2.159977, Acc:0.771907, Semantic loss: 0.837377, BCE loss: 0.560406, SB loss: 0.762194
2023-10-30 05:39:31,236 Epoch: [120/484] Iter:[40/495], Time: 0.42, lr: [0.007736484113064251], Loss: 2.151390, Acc:0.775748, Semantic loss: 0.829936, BCE loss: 0.552373, SB loss: 0.769081
2023-10-30 05:39:34,935 Epoch: [120/484] Iter:[50/495], Time: 0.41, lr: [0.007736097588415181], Loss: 2.175386, Acc:0.786996, Semantic loss: 0.833843, BCE loss: 0.564363, SB loss: 0.777179
2023-10-30 05:39:38,574 Epoch: [120/484] Iter:[60/495], Time: 0.40, lr: [0.007735711061620297], Loss: 2.182294, Acc:0.788835, Semantic loss: 0.832499, BCE loss: 0.566143, SB loss: 0.783652
2023-10-30 05:39:42,140 Epoch: [120/484] Iter:[70/495], Time: 0.39, lr: [0.0077353245326794665], Loss: 2.177615, Acc:0.788660, Semantic loss: 0.827976, BCE loss: 0.558934, SB loss: 0.790705
2023-10-30 05:39:45,758 Epoch: [120/484] Iter:[80/495], Time: 0.39, lr: [0.007734938001592556], Loss: 2.181206, Acc:0.784050, Semantic loss: 0.834417, BCE loss: 0.552980, SB loss: 0.793810
2023-10-30 05:39:49,383 Epoch: [120/484] Iter:[90/495], Time: 0.39, lr: [0.00773455146835944], Loss: 2.169039, Acc:0.790636, Semantic loss: 0.825811, BCE loss: 0.555019, SB loss: 0.788210
2023-10-30 05:39:52,980 Epoch: [120/484] Iter:[100/495], Time: 0.38, lr: [0.007734164932979983], Loss: 2.165317, Acc:0.791262, Semantic loss: 0.820045, BCE loss: 0.559500, SB loss: 0.785771
2023-10-30 05:39:56,575 Epoch: [120/484] Iter:[110/495], Time: 0.38, lr: [0.007733778395454058], Loss: 2.145825, Acc:0.791168, Semantic loss: 0.805257, BCE loss: 0.558958, SB loss: 0.781610
2023-10-30 05:40:00,230 Epoch: [120/484] Iter:[120/495], Time: 0.38, lr: [0.007733391855781529], Loss: 2.152652, Acc:0.790457, Semantic loss: 0.812848, BCE loss: 0.557474, SB loss: 0.782330
2023-10-30 05:40:03,856 Epoch: [120/484] Iter:[130/495], Time: 0.38, lr: [0.007733005313962264], Loss: 2.147712, Acc:0.790101, Semantic loss: 0.812889, BCE loss: 0.555465, SB loss: 0.779358
2023-10-30 05:40:07,526 Epoch: [120/484] Iter:[140/495], Time: 0.38, lr: [0.007732618769996139], Loss: 2.143856, Acc:0.790269, Semantic loss: 0.811653, BCE loss: 0.553765, SB loss: 0.778438
2023-10-30 05:40:11,142 Epoch: [120/484] Iter:[150/495], Time: 0.38, lr: [0.0077322322238830175], Loss: 2.148502, Acc:0.790516, Semantic loss: 0.814348, BCE loss: 0.553769, SB loss: 0.780385
2023-10-30 05:40:14,830 Epoch: [120/484] Iter:[160/495], Time: 0.38, lr: [0.007731845675622768], Loss: 2.157359, Acc:0.792184, Semantic loss: 0.820544, BCE loss: 0.553026, SB loss: 0.783789
2023-10-30 05:40:18,395 Epoch: [120/484] Iter:[170/495], Time: 0.38, lr: [0.007731459125215263], Loss: 2.154620, Acc:0.794035, Semantic loss: 0.819805, BCE loss: 0.550995, SB loss: 0.783820
2023-10-30 05:40:22,112 Epoch: [120/484] Iter:[180/495], Time: 0.38, lr: [0.007731072572660368], Loss: 2.145840, Acc:0.792479, Semantic loss: 0.813267, BCE loss: 0.551606, SB loss: 0.780966
2023-10-30 05:40:25,682 Epoch: [120/484] Iter:[190/495], Time: 0.37, lr: [0.007730686017957954], Loss: 2.144630, Acc:0.792759, Semantic loss: 0.813849, BCE loss: 0.550803, SB loss: 0.779978
2023-10-30 05:40:29,338 Epoch: [120/484] Iter:[200/495], Time: 0.37, lr: [0.007730299461107888], Loss: 2.147263, Acc:0.790699, Semantic loss: 0.815056, BCE loss: 0.550146, SB loss: 0.782061
2023-10-30 05:40:33,073 Epoch: [120/484] Iter:[210/495], Time: 0.37, lr: [0.007729912902110038], Loss: 2.152166, Acc:0.790810, Semantic loss: 0.818143, BCE loss: 0.550851, SB loss: 0.783171
2023-10-30 05:40:36,673 Epoch: [120/484] Iter:[220/495], Time: 0.37, lr: [0.0077295263409642755], Loss: 2.154980, Acc:0.789741, Semantic loss: 0.819780, BCE loss: 0.552591, SB loss: 0.782609
2023-10-30 05:40:40,303 Epoch: [120/484] Iter:[230/495], Time: 0.37, lr: [0.007729139777670467], Loss: 2.150791, Acc:0.788828, Semantic loss: 0.818023, BCE loss: 0.551308, SB loss: 0.781460
2023-10-30 05:40:43,992 Epoch: [120/484] Iter:[240/495], Time: 0.37, lr: [0.007728753212228482], Loss: 2.155423, Acc:0.787561, Semantic loss: 0.819474, BCE loss: 0.551620, SB loss: 0.784329
2023-10-30 05:40:47,657 Epoch: [120/484] Iter:[250/495], Time: 0.37, lr: [0.00772836664463819], Loss: 2.154531, Acc:0.788940, Semantic loss: 0.818548, BCE loss: 0.552770, SB loss: 0.783213
2023-10-30 05:40:51,329 Epoch: [120/484] Iter:[260/495], Time: 0.37, lr: [0.007727980074899458], Loss: 2.150862, Acc:0.787787, Semantic loss: 0.816313, BCE loss: 0.551730, SB loss: 0.782818
2023-10-30 05:40:55,043 Epoch: [120/484] Iter:[270/495], Time: 0.37, lr: [0.007727593503012156], Loss: 2.144700, Acc:0.787608, Semantic loss: 0.812733, BCE loss: 0.550329, SB loss: 0.781638
2023-10-30 05:40:58,719 Epoch: [120/484] Iter:[280/495], Time: 0.37, lr: [0.0077272069289761516], Loss: 2.138668, Acc:0.789866, Semantic loss: 0.809841, BCE loss: 0.549632, SB loss: 0.779195
2023-10-30 05:41:02,529 Epoch: [120/484] Iter:[290/495], Time: 0.37, lr: [0.007726820352791314], Loss: 2.139502, Acc:0.790505, Semantic loss: 0.809392, BCE loss: 0.550131, SB loss: 0.779979
2023-10-30 05:41:06,174 Epoch: [120/484] Iter:[300/495], Time: 0.37, lr: [0.007726433774457512], Loss: 2.137378, Acc:0.791856, Semantic loss: 0.807373, BCE loss: 0.550981, SB loss: 0.779024
2023-10-30 05:41:09,839 Epoch: [120/484] Iter:[310/495], Time: 0.37, lr: [0.007726047193974614], Loss: 2.133984, Acc:0.791251, Semantic loss: 0.805864, BCE loss: 0.550511, SB loss: 0.777610
2023-10-30 05:41:13,577 Epoch: [120/484] Iter:[320/495], Time: 0.37, lr: [0.007725660611342487], Loss: 2.140780, Acc:0.792426, Semantic loss: 0.809027, BCE loss: 0.553105, SB loss: 0.778649
2023-10-30 05:41:17,305 Epoch: [120/484] Iter:[330/495], Time: 0.37, lr: [0.007725274026561002], Loss: 2.138944, Acc:0.791949, Semantic loss: 0.809426, BCE loss: 0.551618, SB loss: 0.777900
2023-10-30 05:41:20,994 Epoch: [120/484] Iter:[340/495], Time: 0.37, lr: [0.007724887439630027], Loss: 2.141040, Acc:0.791231, Semantic loss: 0.812023, BCE loss: 0.550774, SB loss: 0.778243
2023-10-30 05:41:24,643 Epoch: [120/484] Iter:[350/495], Time: 0.37, lr: [0.00772450085054943], Loss: 2.135402, Acc:0.790789, Semantic loss: 0.809453, BCE loss: 0.549176, SB loss: 0.776773
2023-10-30 05:41:28,268 Epoch: [120/484] Iter:[360/495], Time: 0.37, lr: [0.007724114259319079], Loss: 2.132179, Acc:0.791010, Semantic loss: 0.807267, BCE loss: 0.547989, SB loss: 0.776924
2023-10-30 05:41:31,884 Epoch: [120/484] Iter:[370/495], Time: 0.37, lr: [0.007723727665938844], Loss: 2.141941, Acc:0.790773, Semantic loss: 0.812978, BCE loss: 0.549828, SB loss: 0.779134
2023-10-30 05:41:35,595 Epoch: [120/484] Iter:[380/495], Time: 0.37, lr: [0.007723341070408591], Loss: 2.137596, Acc:0.789772, Semantic loss: 0.810261, BCE loss: 0.549590, SB loss: 0.777746
2023-10-30 05:41:39,275 Epoch: [120/484] Iter:[390/495], Time: 0.37, lr: [0.007722954472728192], Loss: 2.134188, Acc:0.789593, Semantic loss: 0.807867, BCE loss: 0.549843, SB loss: 0.776478
2023-10-30 05:41:42,975 Epoch: [120/484] Iter:[400/495], Time: 0.37, lr: [0.007722567872897512], Loss: 2.130836, Acc:0.791102, Semantic loss: 0.805632, BCE loss: 0.550607, SB loss: 0.774597
2023-10-30 05:41:46,623 Epoch: [120/484] Iter:[410/495], Time: 0.37, lr: [0.007722181270916421], Loss: 2.131010, Acc:0.790505, Semantic loss: 0.805802, BCE loss: 0.550876, SB loss: 0.774332
2023-10-30 05:41:50,281 Epoch: [120/484] Iter:[420/495], Time: 0.37, lr: [0.0077217946667847885], Loss: 2.128141, Acc:0.790645, Semantic loss: 0.803835, BCE loss: 0.550260, SB loss: 0.774046
2023-10-30 05:41:53,922 Epoch: [120/484] Iter:[430/495], Time: 0.37, lr: [0.0077214080605024805], Loss: 2.125949, Acc:0.790614, Semantic loss: 0.802620, BCE loss: 0.550293, SB loss: 0.773035
2023-10-30 05:41:57,523 Epoch: [120/484] Iter:[440/495], Time: 0.37, lr: [0.007721021452069368], Loss: 2.133439, Acc:0.791271, Semantic loss: 0.808226, BCE loss: 0.551231, SB loss: 0.773982
2023-10-30 05:42:01,190 Epoch: [120/484] Iter:[450/495], Time: 0.37, lr: [0.007720634841485316], Loss: 2.130883, Acc:0.790760, Semantic loss: 0.807204, BCE loss: 0.550735, SB loss: 0.772944
2023-10-30 05:42:04,891 Epoch: [120/484] Iter:[460/495], Time: 0.37, lr: [0.007720248228750195], Loss: 2.133871, Acc:0.790131, Semantic loss: 0.810460, BCE loss: 0.549667, SB loss: 0.773744
2023-10-30 05:42:08,630 Epoch: [120/484] Iter:[470/495], Time: 0.37, lr: [0.007719861613863874], Loss: 2.133866, Acc:0.790564, Semantic loss: 0.810758, BCE loss: 0.549905, SB loss: 0.773204
2023-10-30 05:42:12,260 Epoch: [120/484] Iter:[480/495], Time: 0.37, lr: [0.007719474996826221], Loss: 2.134378, Acc:0.790711, Semantic loss: 0.810644, BCE loss: 0.550263, SB loss: 0.773472
2023-10-30 05:42:15,740 Epoch: [120/484] Iter:[490/495], Time: 0.37, lr: [0.007719088377637104], Loss: 2.133738, Acc:0.790020, Semantic loss: 0.810461, BCE loss: 0.549106, SB loss: 0.774172
2023-10-30 05:45:13,029 0 [9.33480100e-01 6.27403843e-01 8.04028997e-01 1.34339682e-01
 2.47474616e-01 4.20118899e-01 4.34653129e-01 5.72346924e-01
 8.68883862e-01 4.37992195e-01 8.32743549e-01 6.02816466e-01
 3.31759326e-03 7.71071324e-01 5.79566303e-06 1.62272549e-02
 4.41021082e-02 1.86150109e-02 5.16841938e-01] 0.4361296467202715
2023-10-30 05:45:13,030 1 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481] 0.6534702459352371
2023-10-30 05:45:13,033 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:45:13,269 Loss: 2.081, MeanIU:  0.6535, Best_mIoU:  0.6907
2023-10-30 05:45:13,269 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481]
2023-10-30 05:45:15,318 Epoch: [121/484] Iter:[0/495], Time: 2.02, lr: [0.007718895067235705], Loss: 1.925630, Acc:0.796686, Semantic loss: 0.684772, BCE loss: 0.419071, SB loss: 0.821787
2023-10-30 05:45:19,164 Epoch: [121/484] Iter:[10/495], Time: 0.53, lr: [0.007718508444819143], Loss: 2.168320, Acc:0.806259, Semantic loss: 0.801172, BCE loss: 0.551015, SB loss: 0.816133
2023-10-30 05:45:22,689 Epoch: [121/484] Iter:[20/495], Time: 0.45, lr: [0.00771812182025079], Loss: 2.182278, Acc:0.795591, Semantic loss: 0.802936, BCE loss: 0.569547, SB loss: 0.809794
2023-10-30 05:45:26,159 Epoch: [121/484] Iter:[30/495], Time: 0.41, lr: [0.007717735193530509], Loss: 2.232889, Acc:0.796673, Semantic loss: 0.843000, BCE loss: 0.569796, SB loss: 0.820093
2023-10-30 05:45:29,608 Epoch: [121/484] Iter:[40/495], Time: 0.40, lr: [0.007717348564658173], Loss: 2.237291, Acc:0.798740, Semantic loss: 0.835280, BCE loss: 0.586433, SB loss: 0.815578
2023-10-30 05:45:33,104 Epoch: [121/484] Iter:[50/495], Time: 0.39, lr: [0.0077169619336336474], Loss: 2.207557, Acc:0.797328, Semantic loss: 0.824216, BCE loss: 0.578530, SB loss: 0.804812
2023-10-30 05:45:36,661 Epoch: [121/484] Iter:[60/495], Time: 0.38, lr: [0.007716575300456802], Loss: 2.185328, Acc:0.798712, Semantic loss: 0.809064, BCE loss: 0.580968, SB loss: 0.795296
2023-10-30 05:45:40,102 Epoch: [121/484] Iter:[70/495], Time: 0.38, lr: [0.007716188665127504], Loss: 2.172017, Acc:0.802264, Semantic loss: 0.807034, BCE loss: 0.571074, SB loss: 0.793909
2023-10-30 05:45:43,652 Epoch: [121/484] Iter:[80/495], Time: 0.37, lr: [0.007715802027645622], Loss: 2.169887, Acc:0.802805, Semantic loss: 0.810887, BCE loss: 0.569129, SB loss: 0.789871
2023-10-30 05:45:47,165 Epoch: [121/484] Iter:[90/495], Time: 0.37, lr: [0.007715415388011023], Loss: 2.176527, Acc:0.805349, Semantic loss: 0.820502, BCE loss: 0.565915, SB loss: 0.790109
2023-10-30 05:45:50,784 Epoch: [121/484] Iter:[100/495], Time: 0.37, lr: [0.007715028746223578], Loss: 2.153518, Acc:0.803770, Semantic loss: 0.810070, BCE loss: 0.558841, SB loss: 0.784607
2023-10-30 05:45:54,344 Epoch: [121/484] Iter:[110/495], Time: 0.37, lr: [0.007714642102283151], Loss: 2.155558, Acc:0.803442, Semantic loss: 0.809598, BCE loss: 0.561483, SB loss: 0.784476
2023-10-30 05:45:57,814 Epoch: [121/484] Iter:[120/495], Time: 0.37, lr: [0.007714255456189614], Loss: 2.149805, Acc:0.803370, Semantic loss: 0.807640, BCE loss: 0.560778, SB loss: 0.781388
2023-10-30 05:46:01,473 Epoch: [121/484] Iter:[130/495], Time: 0.37, lr: [0.007713868807942832], Loss: 2.138945, Acc:0.800238, Semantic loss: 0.805935, BCE loss: 0.553540, SB loss: 0.779469
2023-10-30 05:46:05,073 Epoch: [121/484] Iter:[140/495], Time: 0.37, lr: [0.007713482157542676], Loss: 2.133634, Acc:0.800540, Semantic loss: 0.804845, BCE loss: 0.552127, SB loss: 0.776662
2023-10-30 05:46:08,815 Epoch: [121/484] Iter:[150/495], Time: 0.37, lr: [0.007713095504989012], Loss: 2.133383, Acc:0.800443, Semantic loss: 0.802467, BCE loss: 0.554334, SB loss: 0.776583
2023-10-30 05:46:12,507 Epoch: [121/484] Iter:[160/495], Time: 0.37, lr: [0.007712708850281709], Loss: 2.130999, Acc:0.801598, Semantic loss: 0.800702, BCE loss: 0.555102, SB loss: 0.775195
2023-10-30 05:46:16,143 Epoch: [121/484] Iter:[170/495], Time: 0.37, lr: [0.007712322193420635], Loss: 2.132570, Acc:0.800855, Semantic loss: 0.803314, BCE loss: 0.554432, SB loss: 0.774823
2023-10-30 05:46:19,713 Epoch: [121/484] Iter:[180/495], Time: 0.37, lr: [0.007711935534405657], Loss: 2.129411, Acc:0.801497, Semantic loss: 0.801765, BCE loss: 0.553624, SB loss: 0.774022
2023-10-30 05:46:23,369 Epoch: [121/484] Iter:[190/495], Time: 0.37, lr: [0.007711548873236645], Loss: 2.120128, Acc:0.797340, Semantic loss: 0.796912, BCE loss: 0.550808, SB loss: 0.772408
2023-10-30 05:46:27,093 Epoch: [121/484] Iter:[200/495], Time: 0.37, lr: [0.007711162209913465], Loss: 2.105897, Acc:0.794163, Semantic loss: 0.790975, BCE loss: 0.546222, SB loss: 0.768701
2023-10-30 05:46:30,781 Epoch: [121/484] Iter:[210/495], Time: 0.37, lr: [0.007710775544435984], Loss: 2.105303, Acc:0.793636, Semantic loss: 0.792772, BCE loss: 0.542616, SB loss: 0.769915
2023-10-30 05:46:34,401 Epoch: [121/484] Iter:[220/495], Time: 0.37, lr: [0.007710388876804074], Loss: 2.109436, Acc:0.793300, Semantic loss: 0.795506, BCE loss: 0.542903, SB loss: 0.771027
2023-10-30 05:46:37,969 Epoch: [121/484] Iter:[230/495], Time: 0.37, lr: [0.0077100022070176], Loss: 2.107929, Acc:0.793111, Semantic loss: 0.794069, BCE loss: 0.542906, SB loss: 0.770953
2023-10-30 05:46:41,559 Epoch: [121/484] Iter:[240/495], Time: 0.37, lr: [0.007709615535076431], Loss: 2.103109, Acc:0.791319, Semantic loss: 0.792294, BCE loss: 0.541353, SB loss: 0.769463
2023-10-30 05:46:45,179 Epoch: [121/484] Iter:[250/495], Time: 0.37, lr: [0.007709228860980435], Loss: 2.100014, Acc:0.792925, Semantic loss: 0.788999, BCE loss: 0.542240, SB loss: 0.768774
2023-10-30 05:46:48,917 Epoch: [121/484] Iter:[260/495], Time: 0.37, lr: [0.007708842184729479], Loss: 2.100272, Acc:0.792450, Semantic loss: 0.789983, BCE loss: 0.542030, SB loss: 0.768259
2023-10-30 05:46:52,572 Epoch: [121/484] Iter:[270/495], Time: 0.37, lr: [0.00770845550632343], Loss: 2.099445, Acc:0.792258, Semantic loss: 0.789511, BCE loss: 0.542443, SB loss: 0.767491
2023-10-30 05:46:56,234 Epoch: [121/484] Iter:[280/495], Time: 0.37, lr: [0.007708068825762158], Loss: 2.099445, Acc:0.791789, Semantic loss: 0.790359, BCE loss: 0.541302, SB loss: 0.767784
2023-10-30 05:46:59,925 Epoch: [121/484] Iter:[290/495], Time: 0.37, lr: [0.007707682143045529], Loss: 2.102719, Acc:0.791347, Semantic loss: 0.791110, BCE loss: 0.542962, SB loss: 0.768648
2023-10-30 05:47:03,573 Epoch: [121/484] Iter:[300/495], Time: 0.37, lr: [0.0077072954581734136], Loss: 2.103127, Acc:0.791247, Semantic loss: 0.791193, BCE loss: 0.544340, SB loss: 0.767594
2023-10-30 05:47:07,280 Epoch: [121/484] Iter:[310/495], Time: 0.37, lr: [0.007706908771145678], Loss: 2.105538, Acc:0.791566, Semantic loss: 0.792315, BCE loss: 0.544758, SB loss: 0.768465
2023-10-30 05:47:10,862 Epoch: [121/484] Iter:[320/495], Time: 0.37, lr: [0.007706522081962188], Loss: 2.109349, Acc:0.791931, Semantic loss: 0.793203, BCE loss: 0.547405, SB loss: 0.768742
2023-10-30 05:47:14,454 Epoch: [121/484] Iter:[330/495], Time: 0.37, lr: [0.007706135390622816], Loss: 2.103745, Acc:0.792714, Semantic loss: 0.790001, BCE loss: 0.547396, SB loss: 0.766348
2023-10-30 05:47:18,155 Epoch: [121/484] Iter:[340/495], Time: 0.37, lr: [0.0077057486971274245], Loss: 2.104663, Acc:0.793059, Semantic loss: 0.789538, BCE loss: 0.548963, SB loss: 0.766162
2023-10-30 05:47:21,773 Epoch: [121/484] Iter:[350/495], Time: 0.37, lr: [0.007705362001475885], Loss: 2.103158, Acc:0.794521, Semantic loss: 0.788816, BCE loss: 0.549637, SB loss: 0.764704
2023-10-30 05:47:25,511 Epoch: [121/484] Iter:[360/495], Time: 0.37, lr: [0.007704975303668064], Loss: 2.100819, Acc:0.795468, Semantic loss: 0.788067, BCE loss: 0.548305, SB loss: 0.764446
2023-10-30 05:47:29,183 Epoch: [121/484] Iter:[370/495], Time: 0.37, lr: [0.007704588603703828], Loss: 2.099139, Acc:0.795610, Semantic loss: 0.786434, BCE loss: 0.548399, SB loss: 0.764306
2023-10-30 05:47:32,875 Epoch: [121/484] Iter:[380/495], Time: 0.37, lr: [0.007704201901583048], Loss: 2.096926, Acc:0.795517, Semantic loss: 0.785246, BCE loss: 0.548208, SB loss: 0.763472
2023-10-30 05:47:36,591 Epoch: [121/484] Iter:[390/495], Time: 0.37, lr: [0.0077038151973055895], Loss: 2.098614, Acc:0.795104, Semantic loss: 0.786413, BCE loss: 0.548423, SB loss: 0.763778
2023-10-30 05:47:40,301 Epoch: [121/484] Iter:[400/495], Time: 0.37, lr: [0.007703428490871319], Loss: 2.101454, Acc:0.795608, Semantic loss: 0.787479, BCE loss: 0.550132, SB loss: 0.763844
2023-10-30 05:47:43,929 Epoch: [121/484] Iter:[410/495], Time: 0.37, lr: [0.007703041782280107], Loss: 2.101847, Acc:0.796172, Semantic loss: 0.787736, BCE loss: 0.550678, SB loss: 0.763433
2023-10-30 05:47:47,553 Epoch: [121/484] Iter:[420/495], Time: 0.37, lr: [0.00770265507153182], Loss: 2.098598, Acc:0.796084, Semantic loss: 0.785570, BCE loss: 0.550252, SB loss: 0.762776
2023-10-30 05:47:51,207 Epoch: [121/484] Iter:[430/495], Time: 0.37, lr: [0.007702268358626323], Loss: 2.101066, Acc:0.795393, Semantic loss: 0.787609, BCE loss: 0.550445, SB loss: 0.763012
2023-10-30 05:47:54,891 Epoch: [121/484] Iter:[440/495], Time: 0.37, lr: [0.007701881643563488], Loss: 2.098422, Acc:0.795621, Semantic loss: 0.786306, BCE loss: 0.549787, SB loss: 0.762330
2023-10-30 05:47:58,545 Epoch: [121/484] Iter:[450/495], Time: 0.37, lr: [0.007701494926343179], Loss: 2.099236, Acc:0.795284, Semantic loss: 0.786472, BCE loss: 0.550587, SB loss: 0.762177
2023-10-30 05:48:02,174 Epoch: [121/484] Iter:[460/495], Time: 0.37, lr: [0.007701108206965267], Loss: 2.097630, Acc:0.794672, Semantic loss: 0.786131, BCE loss: 0.549567, SB loss: 0.761931
2023-10-30 05:48:05,821 Epoch: [121/484] Iter:[470/495], Time: 0.37, lr: [0.007700721485429617], Loss: 2.098610, Acc:0.794832, Semantic loss: 0.786321, BCE loss: 0.549816, SB loss: 0.762472
2023-10-30 05:48:09,520 Epoch: [121/484] Iter:[480/495], Time: 0.37, lr: [0.0077003347617360975], Loss: 2.096762, Acc:0.794440, Semantic loss: 0.785777, BCE loss: 0.548819, SB loss: 0.762166
2023-10-30 05:48:12,956 Epoch: [121/484] Iter:[490/495], Time: 0.37, lr: [0.007699948035884576], Loss: 2.095769, Acc:0.793437, Semantic loss: 0.785386, BCE loss: 0.547953, SB loss: 0.762430
2023-10-30 05:48:14,356 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:48:14,602 Loss: 2.081, MeanIU:  0.6535, Best_mIoU:  0.6907
2023-10-30 05:48:14,602 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481]
2023-10-30 05:48:16,659 Epoch: [122/484] Iter:[0/495], Time: 2.02, lr: [0.007699754672149522], Loss: 2.635851, Acc:0.876485, Semantic loss: 0.920380, BCE loss: 0.760460, SB loss: 0.955012
2023-10-30 05:48:20,701 Epoch: [122/484] Iter:[10/495], Time: 0.55, lr: [0.007699367943060749], Loss: 2.195656, Acc:0.831852, Semantic loss: 0.808137, BCE loss: 0.605782, SB loss: 0.781737
2023-10-30 05:48:24,300 Epoch: [122/484] Iter:[20/495], Time: 0.46, lr: [0.007698981211813643], Loss: 2.142459, Acc:0.810785, Semantic loss: 0.814556, BCE loss: 0.560567, SB loss: 0.767336
2023-10-30 05:48:27,897 Epoch: [122/484] Iter:[30/495], Time: 0.43, lr: [0.007698594478408069], Loss: 2.163707, Acc:0.799189, Semantic loss: 0.824536, BCE loss: 0.560287, SB loss: 0.778884
2023-10-30 05:48:31,695 Epoch: [122/484] Iter:[40/495], Time: 0.42, lr: [0.007698207742843898], Loss: 2.095302, Acc:0.799726, Semantic loss: 0.800574, BCE loss: 0.533375, SB loss: 0.761352
2023-10-30 05:48:35,337 Epoch: [122/484] Iter:[50/495], Time: 0.41, lr: [0.007697821005120996], Loss: 2.076728, Acc:0.792040, Semantic loss: 0.791058, BCE loss: 0.525194, SB loss: 0.760476
2023-10-30 05:48:38,950 Epoch: [122/484] Iter:[60/495], Time: 0.40, lr: [0.007697434265239231], Loss: 2.060611, Acc:0.789833, Semantic loss: 0.781735, BCE loss: 0.522218, SB loss: 0.756658
2023-10-30 05:48:42,518 Epoch: [122/484] Iter:[70/495], Time: 0.39, lr: [0.00769704752319847], Loss: 2.092593, Acc:0.787474, Semantic loss: 0.800313, BCE loss: 0.528851, SB loss: 0.763430
2023-10-30 05:48:46,208 Epoch: [122/484] Iter:[80/495], Time: 0.39, lr: [0.007696660778998581], Loss: 2.088078, Acc:0.787569, Semantic loss: 0.796298, BCE loss: 0.528393, SB loss: 0.763387
2023-10-30 05:48:49,942 Epoch: [122/484] Iter:[90/495], Time: 0.39, lr: [0.007696274032639429], Loss: 2.107331, Acc:0.789902, Semantic loss: 0.805396, BCE loss: 0.534588, SB loss: 0.767347
2023-10-30 05:48:53,681 Epoch: [122/484] Iter:[100/495], Time: 0.39, lr: [0.007695887284120884], Loss: 2.092950, Acc:0.787843, Semantic loss: 0.797361, BCE loss: 0.531267, SB loss: 0.764322
2023-10-30 05:48:57,344 Epoch: [122/484] Iter:[110/495], Time: 0.38, lr: [0.007695500533442812], Loss: 2.106425, Acc:0.789218, Semantic loss: 0.805273, BCE loss: 0.534567, SB loss: 0.766585
2023-10-30 05:49:01,019 Epoch: [122/484] Iter:[120/495], Time: 0.38, lr: [0.0076951137806050805], Loss: 2.097453, Acc:0.788324, Semantic loss: 0.800018, BCE loss: 0.536729, SB loss: 0.760706
2023-10-30 05:49:04,685 Epoch: [122/484] Iter:[130/495], Time: 0.38, lr: [0.007694727025607559], Loss: 2.086397, Acc:0.789808, Semantic loss: 0.792553, BCE loss: 0.536773, SB loss: 0.757071
2023-10-30 05:49:08,354 Epoch: [122/484] Iter:[140/495], Time: 0.38, lr: [0.007694340268450112], Loss: 2.087308, Acc:0.792457, Semantic loss: 0.792843, BCE loss: 0.535716, SB loss: 0.758750
2023-10-30 05:49:11,955 Epoch: [122/484] Iter:[150/495], Time: 0.38, lr: [0.0076939535091326075], Loss: 2.081599, Acc:0.792688, Semantic loss: 0.790850, BCE loss: 0.533653, SB loss: 0.757096
2023-10-30 05:49:15,537 Epoch: [122/484] Iter:[160/495], Time: 0.38, lr: [0.007693566747654914], Loss: 2.086123, Acc:0.793703, Semantic loss: 0.790707, BCE loss: 0.534383, SB loss: 0.761033
2023-10-30 05:49:19,133 Epoch: [122/484] Iter:[170/495], Time: 0.38, lr: [0.007693179984016897], Loss: 2.077074, Acc:0.794797, Semantic loss: 0.789525, BCE loss: 0.530090, SB loss: 0.757459
2023-10-30 05:49:22,952 Epoch: [122/484] Iter:[180/495], Time: 0.38, lr: [0.007692793218218425], Loss: 2.076003, Acc:0.794703, Semantic loss: 0.789151, BCE loss: 0.529305, SB loss: 0.757548
2023-10-30 05:49:26,689 Epoch: [122/484] Iter:[190/495], Time: 0.38, lr: [0.007692406450259364], Loss: 2.078322, Acc:0.794592, Semantic loss: 0.791031, BCE loss: 0.529944, SB loss: 0.757347
2023-10-30 05:49:30,415 Epoch: [122/484] Iter:[200/495], Time: 0.38, lr: [0.007692019680139582], Loss: 2.088340, Acc:0.795192, Semantic loss: 0.793738, BCE loss: 0.533286, SB loss: 0.761317
2023-10-30 05:49:33,981 Epoch: [122/484] Iter:[210/495], Time: 0.38, lr: [0.007691632907858949], Loss: 2.086910, Acc:0.794242, Semantic loss: 0.793553, BCE loss: 0.533172, SB loss: 0.760184
2023-10-30 05:49:37,591 Epoch: [122/484] Iter:[220/495], Time: 0.38, lr: [0.007691246133417328], Loss: 2.086745, Acc:0.794698, Semantic loss: 0.791611, BCE loss: 0.535414, SB loss: 0.759720
2023-10-30 05:49:41,244 Epoch: [122/484] Iter:[230/495], Time: 0.37, lr: [0.007690859356814587], Loss: 2.095424, Acc:0.794660, Semantic loss: 0.794190, BCE loss: 0.535290, SB loss: 0.765945
2023-10-30 05:49:44,894 Epoch: [122/484] Iter:[240/495], Time: 0.37, lr: [0.007690472578050595], Loss: 2.091723, Acc:0.793757, Semantic loss: 0.791384, BCE loss: 0.535689, SB loss: 0.764650
2023-10-30 05:49:48,491 Epoch: [122/484] Iter:[250/495], Time: 0.37, lr: [0.007690085797125216], Loss: 2.090456, Acc:0.793355, Semantic loss: 0.790540, BCE loss: 0.535192, SB loss: 0.764724
2023-10-30 05:49:52,172 Epoch: [122/484] Iter:[260/495], Time: 0.37, lr: [0.00768969901403832], Loss: 2.089735, Acc:0.794131, Semantic loss: 0.790162, BCE loss: 0.534750, SB loss: 0.764824
2023-10-30 05:49:55,866 Epoch: [122/484] Iter:[270/495], Time: 0.37, lr: [0.007689312228789775], Loss: 2.090998, Acc:0.795374, Semantic loss: 0.790797, BCE loss: 0.535151, SB loss: 0.765050
2023-10-30 05:49:59,541 Epoch: [122/484] Iter:[280/495], Time: 0.37, lr: [0.007688925441379444], Loss: 2.088840, Acc:0.796210, Semantic loss: 0.789612, BCE loss: 0.534381, SB loss: 0.764846
2023-10-30 05:50:03,323 Epoch: [122/484] Iter:[290/495], Time: 0.37, lr: [0.007688538651807198], Loss: 2.088308, Acc:0.795101, Semantic loss: 0.791219, BCE loss: 0.533123, SB loss: 0.763966
2023-10-30 05:50:07,037 Epoch: [122/484] Iter:[300/495], Time: 0.37, lr: [0.007688151860072902], Loss: 2.091621, Acc:0.795242, Semantic loss: 0.791955, BCE loss: 0.534005, SB loss: 0.765661
2023-10-30 05:50:10,675 Epoch: [122/484] Iter:[310/495], Time: 0.37, lr: [0.007687765066176425], Loss: 2.096001, Acc:0.794761, Semantic loss: 0.795178, BCE loss: 0.535562, SB loss: 0.765261
2023-10-30 05:50:14,363 Epoch: [122/484] Iter:[320/495], Time: 0.37, lr: [0.00768737827011763], Loss: 2.093295, Acc:0.793514, Semantic loss: 0.793608, BCE loss: 0.535856, SB loss: 0.763831
2023-10-30 05:50:18,064 Epoch: [122/484] Iter:[330/495], Time: 0.37, lr: [0.007686991471896387], Loss: 2.090473, Acc:0.792123, Semantic loss: 0.791353, BCE loss: 0.535336, SB loss: 0.763785
2023-10-30 05:50:21,725 Epoch: [122/484] Iter:[340/495], Time: 0.37, lr: [0.007686604671512564], Loss: 2.094617, Acc:0.792387, Semantic loss: 0.796053, BCE loss: 0.534123, SB loss: 0.764441
2023-10-30 05:50:25,415 Epoch: [122/484] Iter:[350/495], Time: 0.37, lr: [0.007686217868966025], Loss: 2.095441, Acc:0.792296, Semantic loss: 0.796048, BCE loss: 0.535468, SB loss: 0.763924
2023-10-30 05:50:29,094 Epoch: [122/484] Iter:[360/495], Time: 0.37, lr: [0.00768583106425664], Loss: 2.099448, Acc:0.791574, Semantic loss: 0.797036, BCE loss: 0.536676, SB loss: 0.765735
2023-10-30 05:50:32,793 Epoch: [122/484] Iter:[370/495], Time: 0.37, lr: [0.007685444257384275], Loss: 2.101585, Acc:0.791420, Semantic loss: 0.798653, BCE loss: 0.536001, SB loss: 0.766930
2023-10-30 05:50:36,447 Epoch: [122/484] Iter:[380/495], Time: 0.37, lr: [0.007685057448348796], Loss: 2.103316, Acc:0.791381, Semantic loss: 0.799360, BCE loss: 0.537476, SB loss: 0.766481
2023-10-30 05:50:40,083 Epoch: [122/484] Iter:[390/495], Time: 0.37, lr: [0.007684670637150071], Loss: 2.103860, Acc:0.791580, Semantic loss: 0.799612, BCE loss: 0.537877, SB loss: 0.766371
2023-10-30 05:50:43,841 Epoch: [122/484] Iter:[400/495], Time: 0.37, lr: [0.007684283823787965], Loss: 2.103209, Acc:0.791689, Semantic loss: 0.797350, BCE loss: 0.539373, SB loss: 0.766485
2023-10-30 05:50:47,677 Epoch: [122/484] Iter:[410/495], Time: 0.37, lr: [0.007683897008262346], Loss: 2.103023, Acc:0.792096, Semantic loss: 0.796868, BCE loss: 0.539725, SB loss: 0.766429
2023-10-30 05:50:51,285 Epoch: [122/484] Iter:[420/495], Time: 0.37, lr: [0.007683510190573082], Loss: 2.105037, Acc:0.792310, Semantic loss: 0.797315, BCE loss: 0.540882, SB loss: 0.766839
2023-10-30 05:50:54,840 Epoch: [122/484] Iter:[430/495], Time: 0.37, lr: [0.007683123370720039], Loss: 2.105165, Acc:0.792165, Semantic loss: 0.797114, BCE loss: 0.541341, SB loss: 0.766710
2023-10-30 05:50:58,582 Epoch: [122/484] Iter:[440/495], Time: 0.37, lr: [0.007682736548703083], Loss: 2.102314, Acc:0.792210, Semantic loss: 0.796220, BCE loss: 0.540459, SB loss: 0.765636
2023-10-30 05:51:02,254 Epoch: [122/484] Iter:[450/495], Time: 0.37, lr: [0.007682349724522083], Loss: 2.100106, Acc:0.793272, Semantic loss: 0.794746, BCE loss: 0.540224, SB loss: 0.765135
2023-10-30 05:51:05,909 Epoch: [122/484] Iter:[460/495], Time: 0.37, lr: [0.007681962898176904], Loss: 2.101234, Acc:0.793192, Semantic loss: 0.795010, BCE loss: 0.541165, SB loss: 0.765059
2023-10-30 05:51:09,639 Epoch: [122/484] Iter:[470/495], Time: 0.37, lr: [0.007681576069667414], Loss: 2.101428, Acc:0.793379, Semantic loss: 0.794637, BCE loss: 0.541542, SB loss: 0.765250
2023-10-30 05:51:13,368 Epoch: [122/484] Iter:[480/495], Time: 0.37, lr: [0.007681189238993479], Loss: 2.102481, Acc:0.793329, Semantic loss: 0.795043, BCE loss: 0.542353, SB loss: 0.765086
2023-10-30 05:51:16,879 Epoch: [122/484] Iter:[490/495], Time: 0.37, lr: [0.007680802406154964], Loss: 2.105580, Acc:0.794538, Semantic loss: 0.795444, BCE loss: 0.544388, SB loss: 0.765748
2023-10-30 05:51:18,278 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:51:18,516 Loss: 2.081, MeanIU:  0.6535, Best_mIoU:  0.6907
2023-10-30 05:51:18,516 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481]
2023-10-30 05:51:20,638 Epoch: [123/484] Iter:[0/495], Time: 2.09, lr: [0.007680608988923949], Loss: 1.824093, Acc:0.837844, Semantic loss: 0.672949, BCE loss: 0.472580, SB loss: 0.678565
2023-10-30 05:51:24,742 Epoch: [123/484] Iter:[10/495], Time: 0.56, lr: [0.007680222152838318], Loss: 2.075303, Acc:0.818850, Semantic loss: 0.760683, BCE loss: 0.568748, SB loss: 0.745871
2023-10-30 05:51:28,272 Epoch: [123/484] Iter:[20/495], Time: 0.46, lr: [0.007679835314587775], Loss: 2.024335, Acc:0.799085, Semantic loss: 0.758425, BCE loss: 0.518809, SB loss: 0.747101
2023-10-30 05:51:31,900 Epoch: [123/484] Iter:[30/495], Time: 0.43, lr: [0.0076794484741721895], Loss: 2.119860, Acc:0.791089, Semantic loss: 0.826760, BCE loss: 0.533885, SB loss: 0.759214
2023-10-30 05:51:35,461 Epoch: [123/484] Iter:[40/495], Time: 0.41, lr: [0.007679061631591425], Loss: 2.099716, Acc:0.791615, Semantic loss: 0.811902, BCE loss: 0.533056, SB loss: 0.754757
2023-10-30 05:51:39,147 Epoch: [123/484] Iter:[50/495], Time: 0.40, lr: [0.00767867478684535], Loss: 2.106075, Acc:0.797109, Semantic loss: 0.813576, BCE loss: 0.532277, SB loss: 0.760222
2023-10-30 05:51:42,823 Epoch: [123/484] Iter:[60/495], Time: 0.40, lr: [0.00767828793993383], Loss: 2.103566, Acc:0.793215, Semantic loss: 0.815992, BCE loss: 0.531621, SB loss: 0.755954
2023-10-30 05:51:46,486 Epoch: [123/484] Iter:[70/495], Time: 0.39, lr: [0.007677901090856732], Loss: 2.112322, Acc:0.793856, Semantic loss: 0.824664, BCE loss: 0.530994, SB loss: 0.756664
2023-10-30 05:51:50,104 Epoch: [123/484] Iter:[80/495], Time: 0.39, lr: [0.007677514239613923], Loss: 2.121082, Acc:0.785150, Semantic loss: 0.834329, BCE loss: 0.527302, SB loss: 0.759451
2023-10-30 05:51:53,689 Epoch: [123/484] Iter:[90/495], Time: 0.39, lr: [0.007677127386205268], Loss: 2.130934, Acc:0.785274, Semantic loss: 0.834170, BCE loss: 0.530034, SB loss: 0.766730
2023-10-30 05:51:57,369 Epoch: [123/484] Iter:[100/495], Time: 0.38, lr: [0.007676740530630637], Loss: 2.123300, Acc:0.780411, Semantic loss: 0.833325, BCE loss: 0.523436, SB loss: 0.766539
2023-10-30 05:52:00,955 Epoch: [123/484] Iter:[110/495], Time: 0.38, lr: [0.007676353672889894], Loss: 2.136654, Acc:0.781604, Semantic loss: 0.834545, BCE loss: 0.532252, SB loss: 0.769858
2023-10-30 05:52:04,581 Epoch: [123/484] Iter:[120/495], Time: 0.38, lr: [0.007675966812982908], Loss: 2.128402, Acc:0.780908, Semantic loss: 0.829159, BCE loss: 0.528955, SB loss: 0.770288
2023-10-30 05:52:08,162 Epoch: [123/484] Iter:[130/495], Time: 0.38, lr: [0.007675579950909541], Loss: 2.119137, Acc:0.783369, Semantic loss: 0.823111, BCE loss: 0.525321, SB loss: 0.770705
2023-10-30 05:52:11,811 Epoch: [123/484] Iter:[140/495], Time: 0.38, lr: [0.007675193086669664], Loss: 2.118412, Acc:0.782100, Semantic loss: 0.823041, BCE loss: 0.526413, SB loss: 0.768958
2023-10-30 05:52:15,483 Epoch: [123/484] Iter:[150/495], Time: 0.38, lr: [0.007674806220263141], Loss: 2.122285, Acc:0.781487, Semantic loss: 0.824611, BCE loss: 0.527845, SB loss: 0.769830
2023-10-30 05:52:19,087 Epoch: [123/484] Iter:[160/495], Time: 0.38, lr: [0.00767441935168984], Loss: 2.120426, Acc:0.781676, Semantic loss: 0.822011, BCE loss: 0.528986, SB loss: 0.769429
2023-10-30 05:52:22,730 Epoch: [123/484] Iter:[170/495], Time: 0.38, lr: [0.0076740324809496255], Loss: 2.121699, Acc:0.782549, Semantic loss: 0.821936, BCE loss: 0.528882, SB loss: 0.770881
2023-10-30 05:52:26,456 Epoch: [123/484] Iter:[180/495], Time: 0.38, lr: [0.007673645608042367], Loss: 2.112538, Acc:0.782999, Semantic loss: 0.812226, BCE loss: 0.529584, SB loss: 0.770728
2023-10-30 05:52:30,209 Epoch: [123/484] Iter:[190/495], Time: 0.38, lr: [0.007673258732967928], Loss: 2.115383, Acc:0.784885, Semantic loss: 0.813529, BCE loss: 0.529051, SB loss: 0.772802
2023-10-30 05:52:33,817 Epoch: [123/484] Iter:[200/495], Time: 0.37, lr: [0.007672871855726178], Loss: 2.117398, Acc:0.784893, Semantic loss: 0.815480, BCE loss: 0.529154, SB loss: 0.772764
2023-10-30 05:52:37,516 Epoch: [123/484] Iter:[210/495], Time: 0.37, lr: [0.0076724849763169815], Loss: 2.115178, Acc:0.784960, Semantic loss: 0.810993, BCE loss: 0.531696, SB loss: 0.772489
2023-10-30 05:52:41,175 Epoch: [123/484] Iter:[220/495], Time: 0.37, lr: [0.007672098094740204], Loss: 2.110240, Acc:0.785753, Semantic loss: 0.808086, BCE loss: 0.531021, SB loss: 0.771133
2023-10-30 05:52:44,816 Epoch: [123/484] Iter:[230/495], Time: 0.37, lr: [0.0076717112109957126], Loss: 2.114022, Acc:0.786316, Semantic loss: 0.808568, BCE loss: 0.533425, SB loss: 0.772029
2023-10-30 05:52:48,431 Epoch: [123/484] Iter:[240/495], Time: 0.37, lr: [0.007671324325083375], Loss: 2.119160, Acc:0.786372, Semantic loss: 0.811334, BCE loss: 0.534933, SB loss: 0.772894
2023-10-30 05:52:52,079 Epoch: [123/484] Iter:[250/495], Time: 0.37, lr: [0.007670937437003056], Loss: 2.125772, Acc:0.786037, Semantic loss: 0.815695, BCE loss: 0.537159, SB loss: 0.772919
2023-10-30 05:52:55,693 Epoch: [123/484] Iter:[260/495], Time: 0.37, lr: [0.007670550546754623], Loss: 2.124347, Acc:0.786408, Semantic loss: 0.815994, BCE loss: 0.536504, SB loss: 0.771849
2023-10-30 05:52:59,348 Epoch: [123/484] Iter:[270/495], Time: 0.37, lr: [0.007670163654337943], Loss: 2.130503, Acc:0.785898, Semantic loss: 0.820549, BCE loss: 0.537435, SB loss: 0.772518
2023-10-30 05:53:03,000 Epoch: [123/484] Iter:[280/495], Time: 0.37, lr: [0.007669776759752881], Loss: 2.128787, Acc:0.785243, Semantic loss: 0.819100, BCE loss: 0.536936, SB loss: 0.772751
2023-10-30 05:53:06,776 Epoch: [123/484] Iter:[290/495], Time: 0.37, lr: [0.0076693898629993035], Loss: 2.123474, Acc:0.786192, Semantic loss: 0.816792, BCE loss: 0.535167, SB loss: 0.771515
2023-10-30 05:53:10,493 Epoch: [123/484] Iter:[300/495], Time: 0.37, lr: [0.007669002964077076], Loss: 2.127861, Acc:0.787112, Semantic loss: 0.816634, BCE loss: 0.539143, SB loss: 0.772084
2023-10-30 05:53:14,143 Epoch: [123/484] Iter:[310/495], Time: 0.37, lr: [0.007668616062986066], Loss: 2.124264, Acc:0.788657, Semantic loss: 0.813453, BCE loss: 0.539936, SB loss: 0.770875
2023-10-30 05:53:17,832 Epoch: [123/484] Iter:[320/495], Time: 0.37, lr: [0.00766822915972614], Loss: 2.124678, Acc:0.788866, Semantic loss: 0.814195, BCE loss: 0.539202, SB loss: 0.771281
2023-10-30 05:53:21,489 Epoch: [123/484] Iter:[330/495], Time: 0.37, lr: [0.0076678422542971626], Loss: 2.124431, Acc:0.789865, Semantic loss: 0.813239, BCE loss: 0.540244, SB loss: 0.770948
2023-10-30 05:53:25,151 Epoch: [123/484] Iter:[340/495], Time: 0.37, lr: [0.007667455346699003], Loss: 2.120465, Acc:0.790261, Semantic loss: 0.811248, BCE loss: 0.539879, SB loss: 0.769338
2023-10-30 05:53:28,836 Epoch: [123/484] Iter:[350/495], Time: 0.37, lr: [0.007667068436931525], Loss: 2.119797, Acc:0.790090, Semantic loss: 0.811215, BCE loss: 0.539298, SB loss: 0.769284
2023-10-30 05:53:32,471 Epoch: [123/484] Iter:[360/495], Time: 0.37, lr: [0.0076666815249945945], Loss: 2.116596, Acc:0.789682, Semantic loss: 0.809960, BCE loss: 0.537876, SB loss: 0.768760
2023-10-30 05:53:36,126 Epoch: [123/484] Iter:[370/495], Time: 0.37, lr: [0.007666294610888079], Loss: 2.120868, Acc:0.789937, Semantic loss: 0.812946, BCE loss: 0.536299, SB loss: 0.771623
2023-10-30 05:53:39,710 Epoch: [123/484] Iter:[380/495], Time: 0.37, lr: [0.007665907694611844], Loss: 2.125324, Acc:0.789323, Semantic loss: 0.815386, BCE loss: 0.537495, SB loss: 0.772443
2023-10-30 05:53:43,409 Epoch: [123/484] Iter:[390/495], Time: 0.37, lr: [0.007665520776165756], Loss: 2.125282, Acc:0.789588, Semantic loss: 0.813819, BCE loss: 0.539332, SB loss: 0.772132
2023-10-30 05:53:47,081 Epoch: [123/484] Iter:[400/495], Time: 0.37, lr: [0.007665133855549681], Loss: 2.127150, Acc:0.790849, Semantic loss: 0.813856, BCE loss: 0.540239, SB loss: 0.773055
2023-10-30 05:53:50,759 Epoch: [123/484] Iter:[410/495], Time: 0.37, lr: [0.007664746932763485], Loss: 2.129399, Acc:0.789146, Semantic loss: 0.816369, BCE loss: 0.539924, SB loss: 0.773105
2023-10-30 05:53:54,388 Epoch: [123/484] Iter:[420/495], Time: 0.37, lr: [0.007664360007807036], Loss: 2.130351, Acc:0.789447, Semantic loss: 0.816197, BCE loss: 0.541222, SB loss: 0.772933
2023-10-30 05:53:58,078 Epoch: [123/484] Iter:[430/495], Time: 0.37, lr: [0.007663973080680195], Loss: 2.125872, Acc:0.790080, Semantic loss: 0.812926, BCE loss: 0.540900, SB loss: 0.772047
2023-10-30 05:54:01,807 Epoch: [123/484] Iter:[440/495], Time: 0.37, lr: [0.007663586151382834], Loss: 2.125105, Acc:0.790621, Semantic loss: 0.811323, BCE loss: 0.541909, SB loss: 0.771873
2023-10-30 05:54:05,423 Epoch: [123/484] Iter:[450/495], Time: 0.37, lr: [0.007663199219914816], Loss: 2.123182, Acc:0.791386, Semantic loss: 0.810072, BCE loss: 0.542266, SB loss: 0.770844
2023-10-30 05:54:09,023 Epoch: [123/484] Iter:[460/495], Time: 0.37, lr: [0.007662812286276006], Loss: 2.127081, Acc:0.791325, Semantic loss: 0.813277, BCE loss: 0.542133, SB loss: 0.771671
2023-10-30 05:54:12,677 Epoch: [123/484] Iter:[470/495], Time: 0.37, lr: [0.007662425350466274], Loss: 2.126305, Acc:0.790966, Semantic loss: 0.813427, BCE loss: 0.540775, SB loss: 0.772103
2023-10-30 05:54:16,431 Epoch: [123/484] Iter:[480/495], Time: 0.37, lr: [0.00766203841248548], Loss: 2.122472, Acc:0.791006, Semantic loss: 0.811242, BCE loss: 0.539471, SB loss: 0.771759
2023-10-30 05:54:19,970 Epoch: [123/484] Iter:[490/495], Time: 0.37, lr: [0.007661651472333496], Loss: 2.120668, Acc:0.790934, Semantic loss: 0.809724, BCE loss: 0.540000, SB loss: 0.770944
2023-10-30 05:54:21,381 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:54:21,621 Loss: 2.081, MeanIU:  0.6535, Best_mIoU:  0.6907
2023-10-30 05:54:21,621 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481]
2023-10-30 05:54:23,671 Epoch: [124/484] Iter:[0/495], Time: 2.02, lr: [0.007661458001443266], Loss: 1.929251, Acc:0.699158, Semantic loss: 0.798705, BCE loss: 0.408735, SB loss: 0.721812
2023-10-30 05:54:27,788 Epoch: [124/484] Iter:[10/495], Time: 0.56, lr: [0.007661071058034242], Loss: 2.073797, Acc:0.815293, Semantic loss: 0.772463, BCE loss: 0.550347, SB loss: 0.750986
2023-10-30 05:54:31,504 Epoch: [124/484] Iter:[20/495], Time: 0.47, lr: [0.00766068411245369], Loss: 2.021035, Acc:0.820276, Semantic loss: 0.745558, BCE loss: 0.535057, SB loss: 0.740420
2023-10-30 05:54:35,296 Epoch: [124/484] Iter:[30/495], Time: 0.44, lr: [0.007660297164701476], Loss: 2.080232, Acc:0.814131, Semantic loss: 0.772137, BCE loss: 0.542391, SB loss: 0.765704
2023-10-30 05:54:38,957 Epoch: [124/484] Iter:[40/495], Time: 0.42, lr: [0.007659910214777468], Loss: 2.074877, Acc:0.817038, Semantic loss: 0.762882, BCE loss: 0.552722, SB loss: 0.759272
2023-10-30 05:54:42,587 Epoch: [124/484] Iter:[50/495], Time: 0.41, lr: [0.007659523262681528], Loss: 2.094639, Acc:0.810084, Semantic loss: 0.777450, BCE loss: 0.555392, SB loss: 0.761797
2023-10-30 05:54:46,221 Epoch: [124/484] Iter:[60/495], Time: 0.40, lr: [0.007659136308413526], Loss: 2.072927, Acc:0.806770, Semantic loss: 0.770290, BCE loss: 0.542597, SB loss: 0.760040
2023-10-30 05:54:49,827 Epoch: [124/484] Iter:[70/495], Time: 0.40, lr: [0.007658749351973324], Loss: 2.095059, Acc:0.808711, Semantic loss: 0.785969, BCE loss: 0.549134, SB loss: 0.759956
2023-10-30 05:54:53,466 Epoch: [124/484] Iter:[80/495], Time: 0.39, lr: [0.007658362393360791], Loss: 2.078252, Acc:0.806119, Semantic loss: 0.774269, BCE loss: 0.547592, SB loss: 0.756391
2023-10-30 05:54:57,069 Epoch: [124/484] Iter:[90/495], Time: 0.39, lr: [0.007657975432575792], Loss: 2.074830, Acc:0.804835, Semantic loss: 0.773928, BCE loss: 0.544449, SB loss: 0.756454
2023-10-30 05:55:00,723 Epoch: [124/484] Iter:[100/495], Time: 0.39, lr: [0.007657588469618193], Loss: 2.090050, Acc:0.806582, Semantic loss: 0.783801, BCE loss: 0.542122, SB loss: 0.764127
2023-10-30 05:55:04,348 Epoch: [124/484] Iter:[110/495], Time: 0.38, lr: [0.007657201504487858], Loss: 2.082538, Acc:0.807883, Semantic loss: 0.779642, BCE loss: 0.542055, SB loss: 0.760842
2023-10-30 05:55:08,025 Epoch: [124/484] Iter:[120/495], Time: 0.38, lr: [0.007656814537184656], Loss: 2.090576, Acc:0.806273, Semantic loss: 0.782450, BCE loss: 0.544980, SB loss: 0.763147
2023-10-30 05:55:11,721 Epoch: [124/484] Iter:[130/495], Time: 0.38, lr: [0.007656427567708448], Loss: 2.082537, Acc:0.805255, Semantic loss: 0.777883, BCE loss: 0.543011, SB loss: 0.761643
2023-10-30 05:55:15,334 Epoch: [124/484] Iter:[140/495], Time: 0.38, lr: [0.007656040596059105], Loss: 2.080721, Acc:0.802757, Semantic loss: 0.776074, BCE loss: 0.542924, SB loss: 0.761723
2023-10-30 05:55:18,963 Epoch: [124/484] Iter:[150/495], Time: 0.38, lr: [0.007655653622236488], Loss: 2.084217, Acc:0.803466, Semantic loss: 0.775963, BCE loss: 0.545226, SB loss: 0.763027
2023-10-30 05:55:22,667 Epoch: [124/484] Iter:[160/495], Time: 0.38, lr: [0.007655266646240467], Loss: 2.083423, Acc:0.803821, Semantic loss: 0.773722, BCE loss: 0.547365, SB loss: 0.762336
2023-10-30 05:55:26,405 Epoch: [124/484] Iter:[170/495], Time: 0.38, lr: [0.007654879668070907], Loss: 2.094352, Acc:0.801035, Semantic loss: 0.782211, BCE loss: 0.550562, SB loss: 0.761578
2023-10-30 05:55:30,076 Epoch: [124/484] Iter:[180/495], Time: 0.38, lr: [0.007654492687727671], Loss: 2.094680, Acc:0.800987, Semantic loss: 0.777890, BCE loss: 0.556323, SB loss: 0.760467
2023-10-30 05:55:33,653 Epoch: [124/484] Iter:[190/495], Time: 0.38, lr: [0.0076541057052106265], Loss: 2.085101, Acc:0.799346, Semantic loss: 0.773781, BCE loss: 0.553128, SB loss: 0.758192
2023-10-30 05:55:37,316 Epoch: [124/484] Iter:[200/495], Time: 0.38, lr: [0.007653718720519639], Loss: 2.087242, Acc:0.800749, Semantic loss: 0.772638, BCE loss: 0.555059, SB loss: 0.759545
2023-10-30 05:55:40,905 Epoch: [124/484] Iter:[210/495], Time: 0.38, lr: [0.007653331733654574], Loss: 2.081828, Acc:0.800609, Semantic loss: 0.771414, BCE loss: 0.552677, SB loss: 0.757736
2023-10-30 05:55:44,525 Epoch: [124/484] Iter:[220/495], Time: 0.37, lr: [0.007652944744615297], Loss: 2.077621, Acc:0.798720, Semantic loss: 0.770584, BCE loss: 0.550066, SB loss: 0.756971
2023-10-30 05:55:48,182 Epoch: [124/484] Iter:[230/495], Time: 0.37, lr: [0.007652557753401674], Loss: 2.077226, Acc:0.798905, Semantic loss: 0.770651, BCE loss: 0.550145, SB loss: 0.756430
2023-10-30 05:55:51,770 Epoch: [124/484] Iter:[240/495], Time: 0.37, lr: [0.007652170760013572], Loss: 2.074518, Acc:0.799340, Semantic loss: 0.771233, BCE loss: 0.547950, SB loss: 0.755335
2023-10-30 05:55:55,354 Epoch: [124/484] Iter:[250/495], Time: 0.37, lr: [0.007651783764450853], Loss: 2.073816, Acc:0.799790, Semantic loss: 0.772252, BCE loss: 0.547469, SB loss: 0.754095
2023-10-30 05:55:59,011 Epoch: [124/484] Iter:[260/495], Time: 0.37, lr: [0.007651396766713386], Loss: 2.073193, Acc:0.798605, Semantic loss: 0.772717, BCE loss: 0.546338, SB loss: 0.754139
2023-10-30 05:56:02,780 Epoch: [124/484] Iter:[270/495], Time: 0.37, lr: [0.007651009766801034], Loss: 2.083269, Acc:0.798568, Semantic loss: 0.779161, BCE loss: 0.547239, SB loss: 0.756868
2023-10-30 05:56:06,402 Epoch: [124/484] Iter:[280/495], Time: 0.37, lr: [0.007650622764713664], Loss: 2.084473, Acc:0.798197, Semantic loss: 0.780499, BCE loss: 0.546190, SB loss: 0.757785
2023-10-30 05:56:10,232 Epoch: [124/484] Iter:[290/495], Time: 0.37, lr: [0.007650235760451142], Loss: 2.090519, Acc:0.799141, Semantic loss: 0.785921, BCE loss: 0.545461, SB loss: 0.759137
2023-10-30 05:56:13,923 Epoch: [124/484] Iter:[300/495], Time: 0.37, lr: [0.007649848754013331], Loss: 2.090012, Acc:0.799733, Semantic loss: 0.784185, BCE loss: 0.547036, SB loss: 0.758791
2023-10-30 05:56:17,575 Epoch: [124/484] Iter:[310/495], Time: 0.37, lr: [0.0076494617454001], Loss: 2.088382, Acc:0.799405, Semantic loss: 0.785477, BCE loss: 0.544889, SB loss: 0.758016
2023-10-30 05:56:21,296 Epoch: [124/484] Iter:[320/495], Time: 0.37, lr: [0.007649074734611312], Loss: 2.091071, Acc:0.798657, Semantic loss: 0.786907, BCE loss: 0.544203, SB loss: 0.759961
2023-10-30 05:56:24,981 Epoch: [124/484] Iter:[330/495], Time: 0.37, lr: [0.007648687721646835], Loss: 2.091834, Acc:0.798645, Semantic loss: 0.787444, BCE loss: 0.544007, SB loss: 0.760384
2023-10-30 05:56:28,634 Epoch: [124/484] Iter:[340/495], Time: 0.37, lr: [0.0076483007065065315], Loss: 2.088810, Acc:0.798651, Semantic loss: 0.785901, BCE loss: 0.542417, SB loss: 0.760492
2023-10-30 05:56:32,303 Epoch: [124/484] Iter:[350/495], Time: 0.37, lr: [0.0076479136891902675], Loss: 2.091890, Acc:0.799234, Semantic loss: 0.788169, BCE loss: 0.542729, SB loss: 0.760992
2023-10-30 05:56:36,042 Epoch: [124/484] Iter:[360/495], Time: 0.37, lr: [0.007647526669697908], Loss: 2.093614, Acc:0.799124, Semantic loss: 0.788057, BCE loss: 0.544512, SB loss: 0.761045
2023-10-30 05:56:39,660 Epoch: [124/484] Iter:[370/495], Time: 0.37, lr: [0.007647139648029321], Loss: 2.093578, Acc:0.798471, Semantic loss: 0.788435, BCE loss: 0.544017, SB loss: 0.761126
2023-10-30 05:56:43,294 Epoch: [124/484] Iter:[380/495], Time: 0.37, lr: [0.00764675262418437], Loss: 2.093565, Acc:0.798708, Semantic loss: 0.788159, BCE loss: 0.544536, SB loss: 0.760870
2023-10-30 05:56:46,982 Epoch: [124/484] Iter:[390/495], Time: 0.37, lr: [0.007646365598162921], Loss: 2.091059, Acc:0.798079, Semantic loss: 0.787473, BCE loss: 0.543697, SB loss: 0.759888
2023-10-30 05:56:50,601 Epoch: [124/484] Iter:[400/495], Time: 0.37, lr: [0.007645978569964839], Loss: 2.091220, Acc:0.798295, Semantic loss: 0.787174, BCE loss: 0.543701, SB loss: 0.760345
2023-10-30 05:56:54,395 Epoch: [124/484] Iter:[410/495], Time: 0.37, lr: [0.007645591539589989], Loss: 2.095639, Acc:0.798470, Semantic loss: 0.788264, BCE loss: 0.546107, SB loss: 0.761268
2023-10-30 05:56:58,126 Epoch: [124/484] Iter:[420/495], Time: 0.37, lr: [0.007645204507038237], Loss: 2.096979, Acc:0.798014, Semantic loss: 0.789399, BCE loss: 0.545506, SB loss: 0.762074
2023-10-30 05:57:01,761 Epoch: [124/484] Iter:[430/495], Time: 0.37, lr: [0.0076448174723094476], Loss: 2.095791, Acc:0.798269, Semantic loss: 0.788297, BCE loss: 0.545605, SB loss: 0.761889
2023-10-30 05:57:05,365 Epoch: [124/484] Iter:[440/495], Time: 0.37, lr: [0.0076444304354034865], Loss: 2.095746, Acc:0.797920, Semantic loss: 0.789035, BCE loss: 0.544876, SB loss: 0.761835
2023-10-30 05:57:09,098 Epoch: [124/484] Iter:[450/495], Time: 0.37, lr: [0.007644043396320219], Loss: 2.095085, Acc:0.797118, Semantic loss: 0.789794, BCE loss: 0.544069, SB loss: 0.761222
2023-10-30 05:57:12,787 Epoch: [124/484] Iter:[460/495], Time: 0.37, lr: [0.007643656355059509], Loss: 2.092826, Acc:0.796964, Semantic loss: 0.789178, BCE loss: 0.542965, SB loss: 0.760683
2023-10-30 05:57:16,487 Epoch: [124/484] Iter:[470/495], Time: 0.37, lr: [0.007643269311621225], Loss: 2.089915, Acc:0.796421, Semantic loss: 0.786965, BCE loss: 0.542432, SB loss: 0.760518
2023-10-30 05:57:20,155 Epoch: [124/484] Iter:[480/495], Time: 0.37, lr: [0.00764288226600523], Loss: 2.090699, Acc:0.796333, Semantic loss: 0.787378, BCE loss: 0.542631, SB loss: 0.760689
2023-10-30 05:57:23,632 Epoch: [124/484] Iter:[490/495], Time: 0.37, lr: [0.007642495218211389], Loss: 2.090865, Acc:0.795700, Semantic loss: 0.787787, BCE loss: 0.542152, SB loss: 0.760926
2023-10-30 05:57:25,024 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 05:57:25,267 Loss: 2.081, MeanIU:  0.6535, Best_mIoU:  0.6907
2023-10-30 05:57:25,267 [0.96599062 0.76089178 0.88447661 0.45317711 0.47757716 0.56240511
 0.64088335 0.71119625 0.89643208 0.53286036 0.90896034 0.75896199
 0.4743922  0.91610189 0.51792846 0.61908409 0.24511557 0.40475489
 0.68474481]
2023-10-30 05:57:27,273 Epoch: [125/484] Iter:[0/495], Time: 1.97, lr: [0.007642301693497736], Loss: 2.479275, Acc:0.627920, Semantic loss: 1.027506, BCE loss: 0.553500, SB loss: 0.898269
2023-10-30 05:57:31,292 Epoch: [125/484] Iter:[10/495], Time: 0.54, lr: [0.007641914642436873], Loss: 1.853856, Acc:0.771768, Semantic loss: 0.674776, BCE loss: 0.470920, SB loss: 0.708160
2023-10-30 05:57:35,074 Epoch: [125/484] Iter:[20/495], Time: 0.47, lr: [0.007641527589197829], Loss: 1.954477, Acc:0.799299, Semantic loss: 0.715338, BCE loss: 0.519401, SB loss: 0.719738
2023-10-30 05:57:38,782 Epoch: [125/484] Iter:[30/495], Time: 0.43, lr: [0.007641140533780467], Loss: 1.992376, Acc:0.800081, Semantic loss: 0.740805, BCE loss: 0.511954, SB loss: 0.739617
2023-10-30 05:57:42,472 Epoch: [125/484] Iter:[40/495], Time: 0.42, lr: [0.007640753476184652], Loss: 2.010046, Acc:0.799148, Semantic loss: 0.747298, BCE loss: 0.519475, SB loss: 0.743273
2023-10-30 05:57:46,235 Epoch: [125/484] Iter:[50/495], Time: 0.41, lr: [0.00764036641641025], Loss: 2.018659, Acc:0.803313, Semantic loss: 0.743741, BCE loss: 0.532933, SB loss: 0.741985
2023-10-30 05:57:49,933 Epoch: [125/484] Iter:[60/495], Time: 0.40, lr: [0.0076399793544571284], Loss: 2.023781, Acc:0.801577, Semantic loss: 0.754046, BCE loss: 0.533982, SB loss: 0.735753
2023-10-30 05:57:53,473 Epoch: [125/484] Iter:[70/495], Time: 0.40, lr: [0.007639592290325148], Loss: 2.007061, Acc:0.794491, Semantic loss: 0.746373, BCE loss: 0.522562, SB loss: 0.738125
2023-10-30 05:57:57,199 Epoch: [125/484] Iter:[80/495], Time: 0.39, lr: [0.007639205224014177], Loss: 2.010382, Acc:0.796646, Semantic loss: 0.747370, BCE loss: 0.525000, SB loss: 0.738012
2023-10-30 05:58:00,903 Epoch: [125/484] Iter:[90/495], Time: 0.39, lr: [0.0076388181555240775], Loss: 2.005055, Acc:0.795862, Semantic loss: 0.745862, BCE loss: 0.518084, SB loss: 0.741109
2023-10-30 05:58:04,601 Epoch: [125/484] Iter:[100/495], Time: 0.39, lr: [0.0076384310848547155], Loss: 2.004108, Acc:0.796281, Semantic loss: 0.746459, BCE loss: 0.518184, SB loss: 0.739465
2023-10-30 05:58:08,203 Epoch: [125/484] Iter:[110/495], Time: 0.39, lr: [0.007638044012005959], Loss: 2.015200, Acc:0.796460, Semantic loss: 0.754322, BCE loss: 0.520975, SB loss: 0.739903
2023-10-30 05:58:11,948 Epoch: [125/484] Iter:[120/495], Time: 0.39, lr: [0.007637656936977669], Loss: 2.048457, Acc:0.794920, Semantic loss: 0.770658, BCE loss: 0.527336, SB loss: 0.750463
2023-10-30 05:58:15,682 Epoch: [125/484] Iter:[130/495], Time: 0.38, lr: [0.007637269859769713], Loss: 2.090020, Acc:0.797423, Semantic loss: 0.789593, BCE loss: 0.538608, SB loss: 0.761819
2023-10-30 05:58:19,370 Epoch: [125/484] Iter:[140/495], Time: 0.38, lr: [0.0076368827803819555], Loss: 2.083941, Acc:0.798307, Semantic loss: 0.785170, BCE loss: 0.538427, SB loss: 0.760345
2023-10-30 05:58:23,087 Epoch: [125/484] Iter:[150/495], Time: 0.38, lr: [0.007636495698814262], Loss: 2.082269, Acc:0.798131, Semantic loss: 0.786185, BCE loss: 0.537425, SB loss: 0.758659
2023-10-30 05:58:26,837 Epoch: [125/484] Iter:[160/495], Time: 0.38, lr: [0.007636108615066495], Loss: 2.085738, Acc:0.799496, Semantic loss: 0.787473, BCE loss: 0.538134, SB loss: 0.760131
2023-10-30 05:58:30,495 Epoch: [125/484] Iter:[170/495], Time: 0.38, lr: [0.007635721529138522], Loss: 2.079747, Acc:0.798874, Semantic loss: 0.784940, BCE loss: 0.536523, SB loss: 0.758284
2023-10-30 05:58:34,181 Epoch: [125/484] Iter:[180/495], Time: 0.38, lr: [0.007635334441030206], Loss: 2.075319, Acc:0.798963, Semantic loss: 0.783297, BCE loss: 0.536464, SB loss: 0.755558
2023-10-30 05:58:37,927 Epoch: [125/484] Iter:[190/495], Time: 0.38, lr: [0.007634947350741415], Loss: 2.065303, Acc:0.797604, Semantic loss: 0.776568, BCE loss: 0.534257, SB loss: 0.754478
2023-10-30 05:58:41,548 Epoch: [125/484] Iter:[200/495], Time: 0.38, lr: [0.007634560258272008], Loss: 2.067963, Acc:0.797989, Semantic loss: 0.777646, BCE loss: 0.533820, SB loss: 0.756497
2023-10-30 05:58:45,248 Epoch: [125/484] Iter:[210/495], Time: 0.38, lr: [0.007634173163621857], Loss: 2.082473, Acc:0.797589, Semantic loss: 0.787186, BCE loss: 0.536410, SB loss: 0.758877
2023-10-30 05:58:48,865 Epoch: [125/484] Iter:[220/495], Time: 0.38, lr: [0.007633786066790823], Loss: 2.082163, Acc:0.796607, Semantic loss: 0.786171, BCE loss: 0.535913, SB loss: 0.760079
2023-10-30 05:58:52,641 Epoch: [125/484] Iter:[230/495], Time: 0.38, lr: [0.007633398967778771], Loss: 2.082832, Acc:0.796186, Semantic loss: 0.787140, BCE loss: 0.535151, SB loss: 0.760541
2023-10-30 05:58:56,347 Epoch: [125/484] Iter:[240/495], Time: 0.38, lr: [0.007633011866585567], Loss: 2.083846, Acc:0.797780, Semantic loss: 0.786006, BCE loss: 0.538549, SB loss: 0.759291
2023-10-30 05:59:00,004 Epoch: [125/484] Iter:[250/495], Time: 0.38, lr: [0.0076326247632110735], Loss: 2.086071, Acc:0.796921, Semantic loss: 0.787928, BCE loss: 0.537905, SB loss: 0.760239
2023-10-30 05:59:03,758 Epoch: [125/484] Iter:[260/495], Time: 0.38, lr: [0.007632237657655157], Loss: 2.084021, Acc:0.795798, Semantic loss: 0.788043, BCE loss: 0.535251, SB loss: 0.760727
2023-10-30 05:59:07,503 Epoch: [125/484] Iter:[270/495], Time: 0.38, lr: [0.007631850549917682], Loss: 2.085766, Acc:0.796112, Semantic loss: 0.787727, BCE loss: 0.535315, SB loss: 0.762723
2023-10-30 05:59:11,207 Epoch: [125/484] Iter:[280/495], Time: 0.38, lr: [0.007631463439998513], Loss: 2.084848, Acc:0.794532, Semantic loss: 0.787673, BCE loss: 0.535019, SB loss: 0.762157
2023-10-30 05:59:14,899 Epoch: [125/484] Iter:[290/495], Time: 0.38, lr: [0.007631076327897515], Loss: 2.094972, Acc:0.792387, Semantic loss: 0.794474, BCE loss: 0.536059, SB loss: 0.764438
2023-10-30 05:59:18,547 Epoch: [125/484] Iter:[300/495], Time: 0.38, lr: [0.0076306892136145535], Loss: 2.090697, Acc:0.792977, Semantic loss: 0.791749, BCE loss: 0.535668, SB loss: 0.763280
2023-10-30 05:59:22,196 Epoch: [125/484] Iter:[310/495], Time: 0.38, lr: [0.007630302097149493], Loss: 2.092098, Acc:0.793836, Semantic loss: 0.791111, BCE loss: 0.536521, SB loss: 0.764466
2023-10-30 05:59:25,785 Epoch: [125/484] Iter:[320/495], Time: 0.38, lr: [0.007629914978502196], Loss: 2.094109, Acc:0.793698, Semantic loss: 0.792535, BCE loss: 0.536983, SB loss: 0.764591
2023-10-30 05:59:29,380 Epoch: [125/484] Iter:[330/495], Time: 0.37, lr: [0.00762952785767253], Loss: 2.100320, Acc:0.792876, Semantic loss: 0.795695, BCE loss: 0.538759, SB loss: 0.765867
2023-10-30 05:59:33,076 Epoch: [125/484] Iter:[340/495], Time: 0.37, lr: [0.007629140734660357], Loss: 2.103721, Acc:0.792471, Semantic loss: 0.797652, BCE loss: 0.539196, SB loss: 0.766873
2023-10-30 05:59:36,866 Epoch: [125/484] Iter:[350/495], Time: 0.37, lr: [0.007628753609465545], Loss: 2.104525, Acc:0.791969, Semantic loss: 0.796636, BCE loss: 0.540762, SB loss: 0.767126
2023-10-30 05:59:40,533 Epoch: [125/484] Iter:[360/495], Time: 0.37, lr: [0.007628366482087955], Loss: 2.104201, Acc:0.792629, Semantic loss: 0.796160, BCE loss: 0.540675, SB loss: 0.767367
2023-10-30 05:59:44,252 Epoch: [125/484] Iter:[370/495], Time: 0.37, lr: [0.007627979352527454], Loss: 2.104485, Acc:0.791165, Semantic loss: 0.796207, BCE loss: 0.540338, SB loss: 0.767940
2023-10-30 05:59:47,922 Epoch: [125/484] Iter:[380/495], Time: 0.37, lr: [0.007627592220783907], Loss: 2.101374, Acc:0.791196, Semantic loss: 0.794139, BCE loss: 0.540033, SB loss: 0.767202
2023-10-30 05:59:51,569 Epoch: [125/484] Iter:[390/495], Time: 0.37, lr: [0.007627205086857177], Loss: 2.100955, Acc:0.791312, Semantic loss: 0.793684, BCE loss: 0.540067, SB loss: 0.767205
2023-10-30 05:59:55,342 Epoch: [125/484] Iter:[400/495], Time: 0.37, lr: [0.007626817950747128], Loss: 2.100504, Acc:0.790964, Semantic loss: 0.793612, BCE loss: 0.539998, SB loss: 0.766894
2023-10-30 05:59:58,933 Epoch: [125/484] Iter:[410/495], Time: 0.37, lr: [0.007626430812453626], Loss: 2.099140, Acc:0.791170, Semantic loss: 0.792794, BCE loss: 0.539884, SB loss: 0.766461
2023-10-30 06:00:02,617 Epoch: [125/484] Iter:[420/495], Time: 0.37, lr: [0.007626043671976535], Loss: 2.101611, Acc:0.790463, Semantic loss: 0.794303, BCE loss: 0.540474, SB loss: 0.766834
2023-10-30 06:00:06,167 Epoch: [125/484] Iter:[430/495], Time: 0.37, lr: [0.007625656529315721], Loss: 2.102818, Acc:0.791258, Semantic loss: 0.795394, BCE loss: 0.540843, SB loss: 0.766581
2023-10-30 06:00:09,873 Epoch: [125/484] Iter:[440/495], Time: 0.37, lr: [0.007625269384471045], Loss: 2.102283, Acc:0.791730, Semantic loss: 0.795287, BCE loss: 0.540440, SB loss: 0.766555
2023-10-30 06:00:13,653 Epoch: [125/484] Iter:[450/495], Time: 0.37, lr: [0.007624882237442375], Loss: 2.104470, Acc:0.791440, Semantic loss: 0.796985, BCE loss: 0.540880, SB loss: 0.766605
2023-10-30 06:00:17,509 Epoch: [125/484] Iter:[460/495], Time: 0.37, lr: [0.007624495088229575], Loss: 2.106939, Acc:0.791390, Semantic loss: 0.798362, BCE loss: 0.542385, SB loss: 0.766192
2023-10-30 06:00:21,270 Epoch: [125/484] Iter:[470/495], Time: 0.37, lr: [0.007624107936832507], Loss: 2.106851, Acc:0.791732, Semantic loss: 0.798263, BCE loss: 0.543092, SB loss: 0.765497
2023-10-30 06:00:24,880 Epoch: [125/484] Iter:[480/495], Time: 0.37, lr: [0.007623720783251038], Loss: 2.107424, Acc:0.792202, Semantic loss: 0.798580, BCE loss: 0.543390, SB loss: 0.765453
2023-10-30 06:00:28,477 Epoch: [125/484] Iter:[490/495], Time: 0.37, lr: [0.0076233336274850304], Loss: 2.106177, Acc:0.792038, Semantic loss: 0.797726, BCE loss: 0.543299, SB loss: 0.765152
2023-10-30 06:03:24,461 0 [0.93559715 0.63327232 0.80504562 0.06995286 0.22167241 0.40494264
 0.41830364 0.56274194 0.86285225 0.4347833  0.85099815 0.53416546
 0.00475278 0.78516515 0.00102103 0.03656528 0.04667199 0.01575832
 0.5235245 ] 0.42883088360600324
2023-10-30 06:03:24,462 1 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591] 0.6757330561932776
2023-10-30 06:03:24,465 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:03:24,720 Loss: 2.034, MeanIU:  0.6757, Best_mIoU:  0.6907
2023-10-30 06:03:24,720 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591]
2023-10-30 06:03:26,902 Epoch: [126/484] Iter:[0/495], Time: 2.15, lr: [0.007623140048782783], Loss: 2.056189, Acc:0.756642, Semantic loss: 0.697896, BCE loss: 0.643381, SB loss: 0.714912
2023-10-30 06:03:30,626 Epoch: [126/484] Iter:[10/495], Time: 0.53, lr: [0.007622752889739716], Loss: 2.018400, Acc:0.797919, Semantic loss: 0.752866, BCE loss: 0.513209, SB loss: 0.752325
2023-10-30 06:03:34,328 Epoch: [126/484] Iter:[20/495], Time: 0.46, lr: [0.00762236572851177], Loss: 2.028274, Acc:0.796605, Semantic loss: 0.754125, BCE loss: 0.531666, SB loss: 0.742484
2023-10-30 06:03:37,858 Epoch: [126/484] Iter:[30/495], Time: 0.42, lr: [0.007621978565098814], Loss: 2.077105, Acc:0.785728, Semantic loss: 0.780093, BCE loss: 0.541123, SB loss: 0.755889
2023-10-30 06:03:41,266 Epoch: [126/484] Iter:[40/495], Time: 0.40, lr: [0.00762159139950071], Loss: 2.056103, Acc:0.787358, Semantic loss: 0.766721, BCE loss: 0.536713, SB loss: 0.752669
2023-10-30 06:03:44,823 Epoch: [126/484] Iter:[50/495], Time: 0.39, lr: [0.007621204231717323], Loss: 2.056016, Acc:0.788688, Semantic loss: 0.766795, BCE loss: 0.534342, SB loss: 0.754880
2023-10-30 06:03:48,346 Epoch: [126/484] Iter:[60/495], Time: 0.39, lr: [0.007620817061748515], Loss: 2.060843, Acc:0.790349, Semantic loss: 0.762384, BCE loss: 0.542052, SB loss: 0.756407
2023-10-30 06:03:51,889 Epoch: [126/484] Iter:[70/495], Time: 0.38, lr: [0.007620429889594152], Loss: 2.055099, Acc:0.790815, Semantic loss: 0.761351, BCE loss: 0.539274, SB loss: 0.754474
2023-10-30 06:03:55,389 Epoch: [126/484] Iter:[80/495], Time: 0.38, lr: [0.0076200427152540995], Loss: 2.054939, Acc:0.794219, Semantic loss: 0.759003, BCE loss: 0.544470, SB loss: 0.751466
2023-10-30 06:03:59,059 Epoch: [126/484] Iter:[90/495], Time: 0.38, lr: [0.00761965553872822], Loss: 2.034469, Acc:0.793711, Semantic loss: 0.747233, BCE loss: 0.543443, SB loss: 0.743793
2023-10-30 06:04:02,649 Epoch: [126/484] Iter:[100/495], Time: 0.38, lr: [0.007619268360016378], Loss: 2.047586, Acc:0.795823, Semantic loss: 0.754509, BCE loss: 0.545955, SB loss: 0.747122
2023-10-30 06:04:06,322 Epoch: [126/484] Iter:[110/495], Time: 0.37, lr: [0.007618881179118439], Loss: 2.037358, Acc:0.793777, Semantic loss: 0.751548, BCE loss: 0.540073, SB loss: 0.745738
2023-10-30 06:04:09,791 Epoch: [126/484] Iter:[120/495], Time: 0.37, lr: [0.007618493996034266], Loss: 2.054847, Acc:0.798128, Semantic loss: 0.757716, BCE loss: 0.550094, SB loss: 0.747037
2023-10-30 06:04:13,409 Epoch: [126/484] Iter:[130/495], Time: 0.37, lr: [0.007618106810763723], Loss: 2.044290, Acc:0.796307, Semantic loss: 0.757011, BCE loss: 0.542113, SB loss: 0.745166
2023-10-30 06:04:16,973 Epoch: [126/484] Iter:[140/495], Time: 0.37, lr: [0.007617719623306676], Loss: 2.050242, Acc:0.798507, Semantic loss: 0.760533, BCE loss: 0.541487, SB loss: 0.748222
2023-10-30 06:04:20,501 Epoch: [126/484] Iter:[150/495], Time: 0.37, lr: [0.007617332433662987], Loss: 2.055266, Acc:0.797420, Semantic loss: 0.763766, BCE loss: 0.542724, SB loss: 0.748777
2023-10-30 06:04:24,212 Epoch: [126/484] Iter:[160/495], Time: 0.37, lr: [0.007616945241832519], Loss: 2.052743, Acc:0.796245, Semantic loss: 0.763450, BCE loss: 0.542229, SB loss: 0.747063
2023-10-30 06:04:27,914 Epoch: [126/484] Iter:[170/495], Time: 0.37, lr: [0.007616558047815141], Loss: 2.066828, Acc:0.795838, Semantic loss: 0.769791, BCE loss: 0.546004, SB loss: 0.751033
2023-10-30 06:04:31,521 Epoch: [126/484] Iter:[180/495], Time: 0.37, lr: [0.007616170851610712], Loss: 2.065856, Acc:0.797335, Semantic loss: 0.768157, BCE loss: 0.548570, SB loss: 0.749129
2023-10-30 06:04:35,066 Epoch: [126/484] Iter:[190/495], Time: 0.37, lr: [0.0076157836532191004], Loss: 2.063633, Acc:0.797027, Semantic loss: 0.765861, BCE loss: 0.547670, SB loss: 0.750101
2023-10-30 06:04:38,831 Epoch: [126/484] Iter:[200/495], Time: 0.37, lr: [0.0076153964526401675], Loss: 2.071294, Acc:0.798208, Semantic loss: 0.769977, BCE loss: 0.550983, SB loss: 0.750333
2023-10-30 06:04:42,461 Epoch: [126/484] Iter:[210/495], Time: 0.37, lr: [0.007615009249873778], Loss: 2.072009, Acc:0.798961, Semantic loss: 0.771536, BCE loss: 0.551340, SB loss: 0.749133
2023-10-30 06:04:45,977 Epoch: [126/484] Iter:[220/495], Time: 0.37, lr: [0.007614622044919797], Loss: 2.073108, Acc:0.798540, Semantic loss: 0.773404, BCE loss: 0.550276, SB loss: 0.749429
2023-10-30 06:04:49,599 Epoch: [126/484] Iter:[230/495], Time: 0.37, lr: [0.007614234837778087], Loss: 2.070715, Acc:0.799032, Semantic loss: 0.773402, BCE loss: 0.548588, SB loss: 0.748725
2023-10-30 06:04:53,183 Epoch: [126/484] Iter:[240/495], Time: 0.37, lr: [0.00761384762844851], Loss: 2.077314, Acc:0.799509, Semantic loss: 0.777199, BCE loss: 0.550776, SB loss: 0.749339
2023-10-30 06:04:56,800 Epoch: [126/484] Iter:[250/495], Time: 0.37, lr: [0.007613460416930937], Loss: 2.089362, Acc:0.799174, Semantic loss: 0.785219, BCE loss: 0.551758, SB loss: 0.752385
2023-10-30 06:05:00,393 Epoch: [126/484] Iter:[260/495], Time: 0.37, lr: [0.007613073203225224], Loss: 2.087197, Acc:0.798206, Semantic loss: 0.783593, BCE loss: 0.551967, SB loss: 0.751637
2023-10-30 06:05:03,990 Epoch: [126/484] Iter:[270/495], Time: 0.37, lr: [0.00761268598733124], Loss: 2.089945, Acc:0.798651, Semantic loss: 0.784230, BCE loss: 0.553516, SB loss: 0.752199
2023-10-30 06:05:07,592 Epoch: [126/484] Iter:[280/495], Time: 0.37, lr: [0.007612298769248848], Loss: 2.082134, Acc:0.798299, Semantic loss: 0.780772, BCE loss: 0.550391, SB loss: 0.750971
2023-10-30 06:05:11,314 Epoch: [126/484] Iter:[290/495], Time: 0.37, lr: [0.007611911548977912], Loss: 2.086660, Acc:0.799401, Semantic loss: 0.784134, BCE loss: 0.550112, SB loss: 0.752414
2023-10-30 06:05:15,002 Epoch: [126/484] Iter:[300/495], Time: 0.37, lr: [0.007611524326518294], Loss: 2.082772, Acc:0.799324, Semantic loss: 0.783123, BCE loss: 0.547651, SB loss: 0.751999
2023-10-30 06:05:18,649 Epoch: [126/484] Iter:[310/495], Time: 0.37, lr: [0.00761113710186986], Loss: 2.079316, Acc:0.799440, Semantic loss: 0.781127, BCE loss: 0.547396, SB loss: 0.750793
2023-10-30 06:05:22,341 Epoch: [126/484] Iter:[320/495], Time: 0.37, lr: [0.0076107498750324735], Loss: 2.081813, Acc:0.799939, Semantic loss: 0.784085, BCE loss: 0.546242, SB loss: 0.751487
2023-10-30 06:05:25,986 Epoch: [126/484] Iter:[330/495], Time: 0.37, lr: [0.0076103626460059986], Loss: 2.081956, Acc:0.799405, Semantic loss: 0.783782, BCE loss: 0.545410, SB loss: 0.752764
2023-10-30 06:05:29,687 Epoch: [126/484] Iter:[340/495], Time: 0.37, lr: [0.0076099754147902965], Loss: 2.084288, Acc:0.798564, Semantic loss: 0.784941, BCE loss: 0.545148, SB loss: 0.754199
2023-10-30 06:05:33,351 Epoch: [126/484] Iter:[350/495], Time: 0.37, lr: [0.007609588181385235], Loss: 2.083152, Acc:0.798457, Semantic loss: 0.785587, BCE loss: 0.543233, SB loss: 0.754332
2023-10-30 06:05:36,994 Epoch: [126/484] Iter:[360/495], Time: 0.37, lr: [0.007609200945790677], Loss: 2.082779, Acc:0.799351, Semantic loss: 0.786101, BCE loss: 0.542144, SB loss: 0.754535
2023-10-30 06:05:40,627 Epoch: [126/484] Iter:[370/495], Time: 0.37, lr: [0.007608813708006483], Loss: 2.086410, Acc:0.798419, Semantic loss: 0.788714, BCE loss: 0.542313, SB loss: 0.755383
2023-10-30 06:05:44,255 Epoch: [126/484] Iter:[380/495], Time: 0.37, lr: [0.007608426468032522], Loss: 2.090223, Acc:0.797240, Semantic loss: 0.790409, BCE loss: 0.543748, SB loss: 0.756065
2023-10-30 06:05:48,047 Epoch: [126/484] Iter:[390/495], Time: 0.37, lr: [0.007608039225868654], Loss: 2.093663, Acc:0.796265, Semantic loss: 0.791872, BCE loss: 0.543558, SB loss: 0.758233
2023-10-30 06:05:51,734 Epoch: [126/484] Iter:[400/495], Time: 0.37, lr: [0.007607651981514743], Loss: 2.094303, Acc:0.795866, Semantic loss: 0.791808, BCE loss: 0.544390, SB loss: 0.758105
2023-10-30 06:05:55,409 Epoch: [126/484] Iter:[410/495], Time: 0.37, lr: [0.007607264734970654], Loss: 2.096286, Acc:0.796321, Semantic loss: 0.793276, BCE loss: 0.543624, SB loss: 0.759386
2023-10-30 06:05:59,153 Epoch: [126/484] Iter:[420/495], Time: 0.37, lr: [0.007606877486236249], Loss: 2.094247, Acc:0.796189, Semantic loss: 0.792163, BCE loss: 0.543639, SB loss: 0.758445
2023-10-30 06:06:02,761 Epoch: [126/484] Iter:[430/495], Time: 0.37, lr: [0.007606490235311395], Loss: 2.094478, Acc:0.795675, Semantic loss: 0.792012, BCE loss: 0.543492, SB loss: 0.758974
2023-10-30 06:06:06,473 Epoch: [126/484] Iter:[440/495], Time: 0.37, lr: [0.007606102982195953], Loss: 2.095701, Acc:0.795200, Semantic loss: 0.792557, BCE loss: 0.544071, SB loss: 0.759073
2023-10-30 06:06:10,126 Epoch: [126/484] Iter:[450/495], Time: 0.37, lr: [0.007605715726889788], Loss: 2.096408, Acc:0.794512, Semantic loss: 0.793556, BCE loss: 0.543708, SB loss: 0.759145
2023-10-30 06:06:13,774 Epoch: [126/484] Iter:[460/495], Time: 0.37, lr: [0.007605328469392763], Loss: 2.097868, Acc:0.794862, Semantic loss: 0.794143, BCE loss: 0.544746, SB loss: 0.758979
2023-10-30 06:06:17,326 Epoch: [126/484] Iter:[470/495], Time: 0.37, lr: [0.007604941209704741], Loss: 2.099647, Acc:0.794429, Semantic loss: 0.795701, BCE loss: 0.544374, SB loss: 0.759572
2023-10-30 06:06:21,111 Epoch: [126/484] Iter:[480/495], Time: 0.37, lr: [0.007604553947825585], Loss: 2.102690, Acc:0.793873, Semantic loss: 0.797669, BCE loss: 0.544107, SB loss: 0.760914
2023-10-30 06:06:24,628 Epoch: [126/484] Iter:[490/495], Time: 0.37, lr: [0.007604166683755163], Loss: 2.104826, Acc:0.793729, Semantic loss: 0.798590, BCE loss: 0.545248, SB loss: 0.760989
2023-10-30 06:06:26,010 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:06:26,254 Loss: 2.034, MeanIU:  0.6757, Best_mIoU:  0.6907
2023-10-30 06:06:26,254 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591]
2023-10-30 06:06:28,212 Epoch: [127/484] Iter:[0/495], Time: 1.92, lr: [0.007603973050898182], Loss: 2.330065, Acc:0.647104, Semantic loss: 0.978665, BCE loss: 0.460097, SB loss: 0.891304
2023-10-30 06:06:32,155 Epoch: [127/484] Iter:[10/495], Time: 0.53, lr: [0.007603585783540598], Loss: 2.045729, Acc:0.805200, Semantic loss: 0.774448, BCE loss: 0.500781, SB loss: 0.770500
2023-10-30 06:06:35,763 Epoch: [127/484] Iter:[20/495], Time: 0.45, lr: [0.007603198513991406], Loss: 2.011675, Acc:0.793386, Semantic loss: 0.754733, BCE loss: 0.486808, SB loss: 0.770134
2023-10-30 06:06:39,477 Epoch: [127/484] Iter:[30/495], Time: 0.43, lr: [0.007602811242250467], Loss: 2.041575, Acc:0.782947, Semantic loss: 0.767061, BCE loss: 0.497655, SB loss: 0.776858
2023-10-30 06:06:43,122 Epoch: [127/484] Iter:[40/495], Time: 0.41, lr: [0.007602423968317645], Loss: 2.049147, Acc:0.780450, Semantic loss: 0.785364, BCE loss: 0.492867, SB loss: 0.770917
2023-10-30 06:06:46,807 Epoch: [127/484] Iter:[50/495], Time: 0.40, lr: [0.007602036692192804], Loss: 2.108080, Acc:0.775944, Semantic loss: 0.816659, BCE loss: 0.511618, SB loss: 0.779804
2023-10-30 06:06:50,477 Epoch: [127/484] Iter:[60/495], Time: 0.40, lr: [0.007601649413875806], Loss: 2.072812, Acc:0.774145, Semantic loss: 0.794821, BCE loss: 0.504787, SB loss: 0.773204
2023-10-30 06:06:54,214 Epoch: [127/484] Iter:[70/495], Time: 0.39, lr: [0.007601262133366517], Loss: 2.083173, Acc:0.779717, Semantic loss: 0.788333, BCE loss: 0.521741, SB loss: 0.773099
2023-10-30 06:06:57,933 Epoch: [127/484] Iter:[80/495], Time: 0.39, lr: [0.007600874850664796], Loss: 2.077524, Acc:0.781295, Semantic loss: 0.779717, BCE loss: 0.528631, SB loss: 0.769175
2023-10-30 06:07:01,704 Epoch: [127/484] Iter:[90/495], Time: 0.39, lr: [0.007600487565770513], Loss: 2.063614, Acc:0.780606, Semantic loss: 0.773578, BCE loss: 0.523241, SB loss: 0.766795
2023-10-30 06:07:05,438 Epoch: [127/484] Iter:[100/495], Time: 0.39, lr: [0.007600100278683527], Loss: 2.088750, Acc:0.783080, Semantic loss: 0.782024, BCE loss: 0.537285, SB loss: 0.769442
2023-10-30 06:07:09,097 Epoch: [127/484] Iter:[110/495], Time: 0.39, lr: [0.007599712989403702], Loss: 2.093467, Acc:0.787335, Semantic loss: 0.780758, BCE loss: 0.546441, SB loss: 0.766268
2023-10-30 06:07:12,675 Epoch: [127/484] Iter:[120/495], Time: 0.38, lr: [0.007599325697930902], Loss: 2.094364, Acc:0.786972, Semantic loss: 0.784385, BCE loss: 0.545218, SB loss: 0.764761
2023-10-30 06:07:16,364 Epoch: [127/484] Iter:[130/495], Time: 0.38, lr: [0.007598938404264991], Loss: 2.081008, Acc:0.786703, Semantic loss: 0.778514, BCE loss: 0.541587, SB loss: 0.760908
2023-10-30 06:07:20,022 Epoch: [127/484] Iter:[140/495], Time: 0.38, lr: [0.00759855110840583], Loss: 2.088597, Acc:0.786203, Semantic loss: 0.787381, BCE loss: 0.539968, SB loss: 0.761248
2023-10-30 06:07:23,737 Epoch: [127/484] Iter:[150/495], Time: 0.38, lr: [0.007598163810353284], Loss: 2.087991, Acc:0.784656, Semantic loss: 0.785062, BCE loss: 0.540439, SB loss: 0.762490
2023-10-30 06:07:27,464 Epoch: [127/484] Iter:[160/495], Time: 0.38, lr: [0.007597776510107217], Loss: 2.077577, Acc:0.786034, Semantic loss: 0.779917, BCE loss: 0.538345, SB loss: 0.759316
2023-10-30 06:07:31,216 Epoch: [127/484] Iter:[170/495], Time: 0.38, lr: [0.007597389207667493], Loss: 2.079839, Acc:0.784292, Semantic loss: 0.784050, BCE loss: 0.535726, SB loss: 0.760063
2023-10-30 06:07:34,900 Epoch: [127/484] Iter:[180/495], Time: 0.38, lr: [0.007597001903033973], Loss: 2.074008, Acc:0.785028, Semantic loss: 0.784771, BCE loss: 0.531060, SB loss: 0.758177
2023-10-30 06:07:38,590 Epoch: [127/484] Iter:[190/495], Time: 0.38, lr: [0.0075966145962065214], Loss: 2.079388, Acc:0.785034, Semantic loss: 0.787191, BCE loss: 0.531862, SB loss: 0.760335
2023-10-30 06:07:42,228 Epoch: [127/484] Iter:[200/495], Time: 0.38, lr: [0.007596227287185001], Loss: 2.095099, Acc:0.785294, Semantic loss: 0.793281, BCE loss: 0.538111, SB loss: 0.763706
2023-10-30 06:07:45,918 Epoch: [127/484] Iter:[210/495], Time: 0.38, lr: [0.007595839975969277], Loss: 2.097556, Acc:0.783669, Semantic loss: 0.794031, BCE loss: 0.538531, SB loss: 0.764993
2023-10-30 06:07:49,566 Epoch: [127/484] Iter:[220/495], Time: 0.38, lr: [0.007595452662559209], Loss: 2.096284, Acc:0.784227, Semantic loss: 0.792682, BCE loss: 0.537846, SB loss: 0.765755
2023-10-30 06:07:53,297 Epoch: [127/484] Iter:[230/495], Time: 0.38, lr: [0.007595065346954663], Loss: 2.094482, Acc:0.785001, Semantic loss: 0.791113, BCE loss: 0.538693, SB loss: 0.764676
2023-10-30 06:07:57,066 Epoch: [127/484] Iter:[240/495], Time: 0.38, lr: [0.0075946780291555015], Loss: 2.094536, Acc:0.785476, Semantic loss: 0.791739, BCE loss: 0.537426, SB loss: 0.765370
2023-10-30 06:08:00,722 Epoch: [127/484] Iter:[250/495], Time: 0.38, lr: [0.007594290709161588], Loss: 2.101478, Acc:0.784319, Semantic loss: 0.795837, BCE loss: 0.538324, SB loss: 0.767317
2023-10-30 06:08:04,381 Epoch: [127/484] Iter:[260/495], Time: 0.38, lr: [0.007593903386972786], Loss: 2.101520, Acc:0.784811, Semantic loss: 0.797071, BCE loss: 0.537441, SB loss: 0.767008
2023-10-30 06:08:08,040 Epoch: [127/484] Iter:[270/495], Time: 0.38, lr: [0.007593516062588957], Loss: 2.100899, Acc:0.786067, Semantic loss: 0.794893, BCE loss: 0.540206, SB loss: 0.765800
2023-10-30 06:08:11,623 Epoch: [127/484] Iter:[280/495], Time: 0.37, lr: [0.007593128736009967], Loss: 2.103917, Acc:0.786930, Semantic loss: 0.796078, BCE loss: 0.541180, SB loss: 0.766659
2023-10-30 06:08:15,353 Epoch: [127/484] Iter:[290/495], Time: 0.37, lr: [0.007592741407235677], Loss: 2.105760, Acc:0.786675, Semantic loss: 0.797791, BCE loss: 0.541252, SB loss: 0.766718
2023-10-30 06:08:19,044 Epoch: [127/484] Iter:[300/495], Time: 0.37, lr: [0.007592354076265949], Loss: 2.108974, Acc:0.788447, Semantic loss: 0.798616, BCE loss: 0.542926, SB loss: 0.767432
2023-10-30 06:08:22,821 Epoch: [127/484] Iter:[310/495], Time: 0.37, lr: [0.007591966743100649], Loss: 2.114454, Acc:0.788437, Semantic loss: 0.801046, BCE loss: 0.544996, SB loss: 0.768412
2023-10-30 06:08:26,500 Epoch: [127/484] Iter:[320/495], Time: 0.37, lr: [0.007591579407739637], Loss: 2.118913, Acc:0.789186, Semantic loss: 0.803598, BCE loss: 0.546303, SB loss: 0.769012
2023-10-30 06:08:30,094 Epoch: [127/484] Iter:[330/495], Time: 0.37, lr: [0.007591192070182781], Loss: 2.117322, Acc:0.788958, Semantic loss: 0.803439, BCE loss: 0.544844, SB loss: 0.769039
2023-10-30 06:08:33,889 Epoch: [127/484] Iter:[340/495], Time: 0.37, lr: [0.007590804730429939], Loss: 2.115376, Acc:0.788109, Semantic loss: 0.802884, BCE loss: 0.544148, SB loss: 0.768344
2023-10-30 06:08:37,721 Epoch: [127/484] Iter:[350/495], Time: 0.37, lr: [0.007590417388480976], Loss: 2.122641, Acc:0.788728, Semantic loss: 0.806643, BCE loss: 0.544854, SB loss: 0.771145
2023-10-30 06:08:41,375 Epoch: [127/484] Iter:[360/495], Time: 0.37, lr: [0.007590030044335755], Loss: 2.124051, Acc:0.788789, Semantic loss: 0.807712, BCE loss: 0.545058, SB loss: 0.771280
2023-10-30 06:08:45,155 Epoch: [127/484] Iter:[370/495], Time: 0.37, lr: [0.007589642697994139], Loss: 2.119984, Acc:0.789223, Semantic loss: 0.804241, BCE loss: 0.545828, SB loss: 0.769915
2023-10-30 06:08:48,868 Epoch: [127/484] Iter:[380/495], Time: 0.37, lr: [0.0075892553494559915], Loss: 2.123751, Acc:0.788778, Semantic loss: 0.805882, BCE loss: 0.546624, SB loss: 0.771245
2023-10-30 06:08:52,632 Epoch: [127/484] Iter:[390/495], Time: 0.37, lr: [0.007588867998721174], Loss: 2.133132, Acc:0.788937, Semantic loss: 0.810664, BCE loss: 0.548120, SB loss: 0.774349
2023-10-30 06:08:56,350 Epoch: [127/484] Iter:[400/495], Time: 0.37, lr: [0.00758848064578955], Loss: 2.133485, Acc:0.788178, Semantic loss: 0.810148, BCE loss: 0.547119, SB loss: 0.776218
2023-10-30 06:08:59,969 Epoch: [127/484] Iter:[410/495], Time: 0.37, lr: [0.007588093290660985], Loss: 2.132384, Acc:0.789067, Semantic loss: 0.807839, BCE loss: 0.548942, SB loss: 0.775603
2023-10-30 06:09:03,617 Epoch: [127/484] Iter:[420/495], Time: 0.37, lr: [0.007587705933335338], Loss: 2.128443, Acc:0.789196, Semantic loss: 0.805578, BCE loss: 0.548714, SB loss: 0.774151
2023-10-30 06:09:07,320 Epoch: [127/484] Iter:[430/495], Time: 0.37, lr: [0.007587318573812475], Loss: 2.128842, Acc:0.788687, Semantic loss: 0.804616, BCE loss: 0.550293, SB loss: 0.773933
2023-10-30 06:09:10,995 Epoch: [127/484] Iter:[440/495], Time: 0.37, lr: [0.007586931212092258], Loss: 2.125115, Acc:0.789019, Semantic loss: 0.802384, BCE loss: 0.549742, SB loss: 0.772989
2023-10-30 06:09:14,671 Epoch: [127/484] Iter:[450/495], Time: 0.37, lr: [0.007586543848174547], Loss: 2.126484, Acc:0.788773, Semantic loss: 0.803874, BCE loss: 0.549078, SB loss: 0.773533
2023-10-30 06:09:18,327 Epoch: [127/484] Iter:[460/495], Time: 0.37, lr: [0.007586156482059209], Loss: 2.125516, Acc:0.788947, Semantic loss: 0.804058, BCE loss: 0.547973, SB loss: 0.773485
2023-10-30 06:09:21,987 Epoch: [127/484] Iter:[470/495], Time: 0.37, lr: [0.007585769113746104], Loss: 2.123376, Acc:0.789525, Semantic loss: 0.803031, BCE loss: 0.547344, SB loss: 0.773001
2023-10-30 06:09:25,563 Epoch: [127/484] Iter:[480/495], Time: 0.37, lr: [0.007585381743235097], Loss: 2.121326, Acc:0.789043, Semantic loss: 0.802454, BCE loss: 0.546698, SB loss: 0.772174
2023-10-30 06:09:29,084 Epoch: [127/484] Iter:[490/495], Time: 0.37, lr: [0.00758499437052605], Loss: 2.121520, Acc:0.789357, Semantic loss: 0.802207, BCE loss: 0.547117, SB loss: 0.772195
2023-10-30 06:09:30,480 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:09:30,719 Loss: 2.034, MeanIU:  0.6757, Best_mIoU:  0.6907
2023-10-30 06:09:30,719 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591]
2023-10-30 06:09:32,885 Epoch: [128/484] Iter:[0/495], Time: 2.13, lr: [0.007584800683347218], Loss: 1.729852, Acc:0.788095, Semantic loss: 0.548248, BCE loss: 0.527474, SB loss: 0.654130
2023-10-30 06:09:36,905 Epoch: [128/484] Iter:[10/495], Time: 0.56, lr: [0.007584413307340854], Loss: 1.967031, Acc:0.820588, Semantic loss: 0.700542, BCE loss: 0.525847, SB loss: 0.740642
2023-10-30 06:09:40,619 Epoch: [128/484] Iter:[20/495], Time: 0.47, lr: [0.007584025929136106], Loss: 2.055026, Acc:0.802715, Semantic loss: 0.793018, BCE loss: 0.514038, SB loss: 0.747969
2023-10-30 06:09:44,291 Epoch: [128/484] Iter:[30/495], Time: 0.44, lr: [0.007583638548732839], Loss: 2.121676, Acc:0.802252, Semantic loss: 0.820857, BCE loss: 0.545349, SB loss: 0.755470
2023-10-30 06:09:47,867 Epoch: [128/484] Iter:[40/495], Time: 0.42, lr: [0.007583251166130911], Loss: 2.157563, Acc:0.797339, Semantic loss: 0.824830, BCE loss: 0.562779, SB loss: 0.769954
2023-10-30 06:09:51,522 Epoch: [128/484] Iter:[50/495], Time: 0.41, lr: [0.00758286378133019], Loss: 2.137965, Acc:0.790261, Semantic loss: 0.815098, BCE loss: 0.556360, SB loss: 0.766507
2023-10-30 06:09:55,165 Epoch: [128/484] Iter:[60/495], Time: 0.40, lr: [0.007582476394330536], Loss: 2.148323, Acc:0.789303, Semantic loss: 0.821484, BCE loss: 0.557939, SB loss: 0.768899
2023-10-30 06:09:58,830 Epoch: [128/484] Iter:[70/495], Time: 0.40, lr: [0.007582089005131813], Loss: 2.129560, Acc:0.793298, Semantic loss: 0.808083, BCE loss: 0.559459, SB loss: 0.762017
2023-10-30 06:10:02,471 Epoch: [128/484] Iter:[80/495], Time: 0.39, lr: [0.007581701613733884], Loss: 2.125770, Acc:0.795988, Semantic loss: 0.801370, BCE loss: 0.562320, SB loss: 0.762079
2023-10-30 06:10:06,024 Epoch: [128/484] Iter:[90/495], Time: 0.39, lr: [0.007581314220136609], Loss: 2.120001, Acc:0.797127, Semantic loss: 0.798523, BCE loss: 0.561390, SB loss: 0.760088
2023-10-30 06:10:09,690 Epoch: [128/484] Iter:[100/495], Time: 0.39, lr: [0.007580926824339853], Loss: 2.122673, Acc:0.797313, Semantic loss: 0.801323, BCE loss: 0.558506, SB loss: 0.762844
2023-10-30 06:10:13,334 Epoch: [128/484] Iter:[110/495], Time: 0.38, lr: [0.0075805394263434795], Loss: 2.106556, Acc:0.795286, Semantic loss: 0.794324, BCE loss: 0.553091, SB loss: 0.759141
2023-10-30 06:10:16,991 Epoch: [128/484] Iter:[120/495], Time: 0.38, lr: [0.007580152026147347], Loss: 2.111468, Acc:0.795569, Semantic loss: 0.795502, BCE loss: 0.553358, SB loss: 0.762608
2023-10-30 06:10:20,616 Epoch: [128/484] Iter:[130/495], Time: 0.38, lr: [0.007579764623751323], Loss: 2.113209, Acc:0.796373, Semantic loss: 0.791911, BCE loss: 0.559784, SB loss: 0.761514
2023-10-30 06:10:24,265 Epoch: [128/484] Iter:[140/495], Time: 0.38, lr: [0.007579377219155266], Loss: 2.121417, Acc:0.795716, Semantic loss: 0.796893, BCE loss: 0.559431, SB loss: 0.765093
2023-10-30 06:10:27,836 Epoch: [128/484] Iter:[150/495], Time: 0.38, lr: [0.007578989812359041], Loss: 2.122810, Acc:0.794602, Semantic loss: 0.799017, BCE loss: 0.556650, SB loss: 0.767142
2023-10-30 06:10:31,443 Epoch: [128/484] Iter:[160/495], Time: 0.38, lr: [0.00757860240336251], Loss: 2.112873, Acc:0.794656, Semantic loss: 0.794395, BCE loss: 0.553300, SB loss: 0.765177
2023-10-30 06:10:35,031 Epoch: [128/484] Iter:[170/495], Time: 0.38, lr: [0.007578214992165535], Loss: 2.112456, Acc:0.795046, Semantic loss: 0.791080, BCE loss: 0.557086, SB loss: 0.764290
2023-10-30 06:10:38,648 Epoch: [128/484] Iter:[180/495], Time: 0.38, lr: [0.007577827578767981], Loss: 2.103802, Acc:0.793789, Semantic loss: 0.788843, BCE loss: 0.551730, SB loss: 0.763229
2023-10-30 06:10:42,241 Epoch: [128/484] Iter:[190/495], Time: 0.37, lr: [0.007577440163169706], Loss: 2.109273, Acc:0.793513, Semantic loss: 0.790934, BCE loss: 0.554351, SB loss: 0.763989
2023-10-30 06:10:45,953 Epoch: [128/484] Iter:[200/495], Time: 0.37, lr: [0.007577052745370575], Loss: 2.105370, Acc:0.794155, Semantic loss: 0.789008, BCE loss: 0.552523, SB loss: 0.763839
2023-10-30 06:10:49,612 Epoch: [128/484] Iter:[210/495], Time: 0.37, lr: [0.007576665325370451], Loss: 2.104267, Acc:0.794143, Semantic loss: 0.787764, BCE loss: 0.553131, SB loss: 0.763372
2023-10-30 06:10:53,324 Epoch: [128/484] Iter:[220/495], Time: 0.37, lr: [0.007576277903169195], Loss: 2.111408, Acc:0.794139, Semantic loss: 0.790808, BCE loss: 0.555218, SB loss: 0.765382
2023-10-30 06:10:57,000 Epoch: [128/484] Iter:[230/495], Time: 0.37, lr: [0.007575890478766671], Loss: 2.113050, Acc:0.794365, Semantic loss: 0.791521, BCE loss: 0.555775, SB loss: 0.765754
2023-10-30 06:11:00,693 Epoch: [128/484] Iter:[240/495], Time: 0.37, lr: [0.007575503052162742], Loss: 2.117377, Acc:0.794166, Semantic loss: 0.793813, BCE loss: 0.557554, SB loss: 0.766010
2023-10-30 06:11:04,305 Epoch: [128/484] Iter:[250/495], Time: 0.37, lr: [0.007575115623357268], Loss: 2.114529, Acc:0.793630, Semantic loss: 0.791991, BCE loss: 0.557371, SB loss: 0.765167
2023-10-30 06:11:07,959 Epoch: [128/484] Iter:[260/495], Time: 0.37, lr: [0.007574728192350112], Loss: 2.111443, Acc:0.793889, Semantic loss: 0.792541, BCE loss: 0.555682, SB loss: 0.763220
2023-10-30 06:11:11,622 Epoch: [128/484] Iter:[270/495], Time: 0.37, lr: [0.007574340759141136], Loss: 2.109206, Acc:0.793837, Semantic loss: 0.790970, BCE loss: 0.555305, SB loss: 0.762931
2023-10-30 06:11:15,282 Epoch: [128/484] Iter:[280/495], Time: 0.37, lr: [0.0075739533237302046], Loss: 2.108710, Acc:0.794350, Semantic loss: 0.790782, BCE loss: 0.555501, SB loss: 0.762426
2023-10-30 06:11:18,947 Epoch: [128/484] Iter:[290/495], Time: 0.37, lr: [0.007573565886117178], Loss: 2.114073, Acc:0.793580, Semantic loss: 0.793799, BCE loss: 0.556640, SB loss: 0.763635
2023-10-30 06:11:22,569 Epoch: [128/484] Iter:[300/495], Time: 0.37, lr: [0.00757317844630192], Loss: 2.113381, Acc:0.793703, Semantic loss: 0.793312, BCE loss: 0.557015, SB loss: 0.763054
2023-10-30 06:11:26,157 Epoch: [128/484] Iter:[310/495], Time: 0.37, lr: [0.007572791004284291], Loss: 2.108522, Acc:0.793855, Semantic loss: 0.791479, BCE loss: 0.555532, SB loss: 0.761510
2023-10-30 06:11:29,811 Epoch: [128/484] Iter:[320/495], Time: 0.37, lr: [0.007572403560064155], Loss: 2.104463, Acc:0.793714, Semantic loss: 0.789774, BCE loss: 0.553855, SB loss: 0.760835
2023-10-30 06:11:33,431 Epoch: [128/484] Iter:[330/495], Time: 0.37, lr: [0.007572016113641375], Loss: 2.102237, Acc:0.793799, Semantic loss: 0.787792, BCE loss: 0.553754, SB loss: 0.760691
2023-10-30 06:11:37,005 Epoch: [128/484] Iter:[340/495], Time: 0.37, lr: [0.007571628665015809], Loss: 2.100589, Acc:0.793497, Semantic loss: 0.787962, BCE loss: 0.552658, SB loss: 0.759969
2023-10-30 06:11:40,657 Epoch: [128/484] Iter:[350/495], Time: 0.37, lr: [0.0075712412141873235], Loss: 2.100423, Acc:0.793409, Semantic loss: 0.788680, BCE loss: 0.550950, SB loss: 0.760794
2023-10-30 06:11:44,361 Epoch: [128/484] Iter:[360/495], Time: 0.37, lr: [0.00757085376115578], Loss: 2.099247, Acc:0.793616, Semantic loss: 0.788756, BCE loss: 0.549902, SB loss: 0.760589
2023-10-30 06:11:48,045 Epoch: [128/484] Iter:[370/495], Time: 0.37, lr: [0.007570466305921037], Loss: 2.099104, Acc:0.793172, Semantic loss: 0.789590, BCE loss: 0.549168, SB loss: 0.760346
2023-10-30 06:11:51,642 Epoch: [128/484] Iter:[380/495], Time: 0.37, lr: [0.007570078848482963], Loss: 2.098541, Acc:0.793183, Semantic loss: 0.790734, BCE loss: 0.547068, SB loss: 0.760740
2023-10-30 06:11:55,243 Epoch: [128/484] Iter:[390/495], Time: 0.37, lr: [0.0075696913888414165], Loss: 2.102458, Acc:0.793557, Semantic loss: 0.792582, BCE loss: 0.548785, SB loss: 0.761091
2023-10-30 06:11:58,999 Epoch: [128/484] Iter:[400/495], Time: 0.37, lr: [0.00756930392699626], Loss: 2.100669, Acc:0.794202, Semantic loss: 0.791744, BCE loss: 0.548093, SB loss: 0.760832
2023-10-30 06:12:02,660 Epoch: [128/484] Iter:[410/495], Time: 0.37, lr: [0.007568916462947354], Loss: 2.103078, Acc:0.794293, Semantic loss: 0.793094, BCE loss: 0.547931, SB loss: 0.762053
2023-10-30 06:12:06,292 Epoch: [128/484] Iter:[420/495], Time: 0.37, lr: [0.007568528996694563], Loss: 2.098637, Acc:0.793727, Semantic loss: 0.791151, BCE loss: 0.546059, SB loss: 0.761427
2023-10-30 06:12:09,951 Epoch: [128/484] Iter:[430/495], Time: 0.37, lr: [0.007568141528237748], Loss: 2.097768, Acc:0.793183, Semantic loss: 0.790602, BCE loss: 0.545722, SB loss: 0.761444
2023-10-30 06:12:13,611 Epoch: [128/484] Iter:[440/495], Time: 0.37, lr: [0.0075677540575767735], Loss: 2.094172, Acc:0.793081, Semantic loss: 0.789265, BCE loss: 0.544100, SB loss: 0.760808
2023-10-30 06:12:17,235 Epoch: [128/484] Iter:[450/495], Time: 0.37, lr: [0.007567366584711497], Loss: 2.092215, Acc:0.792765, Semantic loss: 0.788367, BCE loss: 0.543498, SB loss: 0.760350
2023-10-30 06:12:20,797 Epoch: [128/484] Iter:[460/495], Time: 0.37, lr: [0.007566979109641784], Loss: 2.093867, Acc:0.792682, Semantic loss: 0.790038, BCE loss: 0.544056, SB loss: 0.759773
2023-10-30 06:12:24,521 Epoch: [128/484] Iter:[470/495], Time: 0.37, lr: [0.007566591632367497], Loss: 2.091552, Acc:0.792714, Semantic loss: 0.788129, BCE loss: 0.543840, SB loss: 0.759583
2023-10-30 06:12:28,265 Epoch: [128/484] Iter:[480/495], Time: 0.37, lr: [0.007566204152888495], Loss: 2.090070, Acc:0.792205, Semantic loss: 0.788070, BCE loss: 0.543008, SB loss: 0.758992
2023-10-30 06:12:31,742 Epoch: [128/484] Iter:[490/495], Time: 0.37, lr: [0.007565816671204642], Loss: 2.090707, Acc:0.792898, Semantic loss: 0.787831, BCE loss: 0.543178, SB loss: 0.759699
2023-10-30 06:12:33,146 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:12:33,382 Loss: 2.034, MeanIU:  0.6757, Best_mIoU:  0.6907
2023-10-30 06:12:33,382 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591]
2023-10-30 06:12:35,424 Epoch: [129/484] Iter:[0/495], Time: 2.01, lr: [0.007565622929535854], Loss: 1.941035, Acc:0.840230, Semantic loss: 0.750760, BCE loss: 0.434368, SB loss: 0.755907
2023-10-30 06:12:39,439 Epoch: [129/484] Iter:[10/495], Time: 0.55, lr: [0.007565235444544465], Loss: 2.026211, Acc:0.799902, Semantic loss: 0.742574, BCE loss: 0.560874, SB loss: 0.722762
2023-10-30 06:12:43,157 Epoch: [129/484] Iter:[20/495], Time: 0.46, lr: [0.007564847957347879], Loss: 2.108976, Acc:0.790015, Semantic loss: 0.800852, BCE loss: 0.559272, SB loss: 0.748852
2023-10-30 06:12:46,793 Epoch: [129/484] Iter:[30/495], Time: 0.43, lr: [0.007564460467945958], Loss: 2.146471, Acc:0.785711, Semantic loss: 0.827022, BCE loss: 0.555018, SB loss: 0.764431
2023-10-30 06:12:50,526 Epoch: [129/484] Iter:[40/495], Time: 0.42, lr: [0.007564072976338566], Loss: 2.117882, Acc:0.792294, Semantic loss: 0.802230, BCE loss: 0.559429, SB loss: 0.756222
2023-10-30 06:12:54,198 Epoch: [129/484] Iter:[50/495], Time: 0.41, lr: [0.007563685482525563], Loss: 2.135533, Acc:0.789404, Semantic loss: 0.801776, BCE loss: 0.574928, SB loss: 0.758830
2023-10-30 06:12:57,994 Epoch: [129/484] Iter:[60/495], Time: 0.40, lr: [0.007563297986506812], Loss: 2.132894, Acc:0.792248, Semantic loss: 0.803104, BCE loss: 0.569702, SB loss: 0.760089
2023-10-30 06:13:01,617 Epoch: [129/484] Iter:[70/495], Time: 0.40, lr: [0.007562910488282173], Loss: 2.135398, Acc:0.790834, Semantic loss: 0.798632, BCE loss: 0.569863, SB loss: 0.766902
2023-10-30 06:13:05,241 Epoch: [129/484] Iter:[80/495], Time: 0.39, lr: [0.007562522987851509], Loss: 2.132282, Acc:0.793744, Semantic loss: 0.795756, BCE loss: 0.568750, SB loss: 0.767777
2023-10-30 06:13:08,957 Epoch: [129/484] Iter:[90/495], Time: 0.39, lr: [0.007562135485214682], Loss: 2.099714, Acc:0.793399, Semantic loss: 0.778027, BCE loss: 0.562197, SB loss: 0.759491
2023-10-30 06:13:12,677 Epoch: [129/484] Iter:[100/495], Time: 0.39, lr: [0.007561747980371554], Loss: 2.102503, Acc:0.791213, Semantic loss: 0.782801, BCE loss: 0.559917, SB loss: 0.759786
2023-10-30 06:13:16,462 Epoch: [129/484] Iter:[110/495], Time: 0.39, lr: [0.007561360473321985], Loss: 2.103241, Acc:0.794513, Semantic loss: 0.783316, BCE loss: 0.560806, SB loss: 0.759119
2023-10-30 06:13:20,134 Epoch: [129/484] Iter:[120/495], Time: 0.39, lr: [0.00756097296406584], Loss: 2.092922, Acc:0.796274, Semantic loss: 0.780124, BCE loss: 0.555835, SB loss: 0.756963
2023-10-30 06:13:23,769 Epoch: [129/484] Iter:[130/495], Time: 0.38, lr: [0.007560585452602978], Loss: 2.105047, Acc:0.797289, Semantic loss: 0.792204, BCE loss: 0.555625, SB loss: 0.757218
2023-10-30 06:13:27,422 Epoch: [129/484] Iter:[140/495], Time: 0.38, lr: [0.007560197938933263], Loss: 2.097499, Acc:0.796500, Semantic loss: 0.788733, BCE loss: 0.554529, SB loss: 0.754237
2023-10-30 06:13:31,123 Epoch: [129/484] Iter:[150/495], Time: 0.38, lr: [0.007559810423056554], Loss: 2.090773, Acc:0.796797, Semantic loss: 0.784702, BCE loss: 0.554049, SB loss: 0.752023
2023-10-30 06:13:34,970 Epoch: [129/484] Iter:[160/495], Time: 0.38, lr: [0.007559422904972716], Loss: 2.101713, Acc:0.796397, Semantic loss: 0.789439, BCE loss: 0.558601, SB loss: 0.753673
2023-10-30 06:13:38,577 Epoch: [129/484] Iter:[170/495], Time: 0.38, lr: [0.007559035384681607], Loss: 2.105436, Acc:0.798103, Semantic loss: 0.790769, BCE loss: 0.558195, SB loss: 0.756472
2023-10-30 06:13:42,204 Epoch: [129/484] Iter:[180/495], Time: 0.38, lr: [0.007558647862183091], Loss: 2.114758, Acc:0.796408, Semantic loss: 0.799965, BCE loss: 0.557269, SB loss: 0.757524
2023-10-30 06:13:45,885 Epoch: [129/484] Iter:[190/495], Time: 0.38, lr: [0.00755826033747703], Loss: 2.114876, Acc:0.794647, Semantic loss: 0.798293, BCE loss: 0.557041, SB loss: 0.759542
2023-10-30 06:13:49,642 Epoch: [129/484] Iter:[200/495], Time: 0.38, lr: [0.007557872810563285], Loss: 2.123987, Acc:0.793569, Semantic loss: 0.803186, BCE loss: 0.557841, SB loss: 0.762960
2023-10-30 06:13:53,318 Epoch: [129/484] Iter:[210/495], Time: 0.38, lr: [0.007557485281441718], Loss: 2.129853, Acc:0.792947, Semantic loss: 0.805992, BCE loss: 0.559129, SB loss: 0.764731
2023-10-30 06:13:57,093 Epoch: [129/484] Iter:[220/495], Time: 0.38, lr: [0.00755709775011219], Loss: 2.144776, Acc:0.793906, Semantic loss: 0.814696, BCE loss: 0.558909, SB loss: 0.771171
2023-10-30 06:14:00,814 Epoch: [129/484] Iter:[230/495], Time: 0.38, lr: [0.0075567102165745624], Loss: 2.144281, Acc:0.792137, Semantic loss: 0.814909, BCE loss: 0.556787, SB loss: 0.772585
2023-10-30 06:14:04,457 Epoch: [129/484] Iter:[240/495], Time: 0.38, lr: [0.007556322680828698], Loss: 2.138170, Acc:0.793522, Semantic loss: 0.809779, BCE loss: 0.556611, SB loss: 0.771781
2023-10-30 06:14:08,146 Epoch: [129/484] Iter:[250/495], Time: 0.38, lr: [0.007555935142874457], Loss: 2.136959, Acc:0.794242, Semantic loss: 0.806738, BCE loss: 0.558087, SB loss: 0.772134
2023-10-30 06:14:11,817 Epoch: [129/484] Iter:[260/495], Time: 0.38, lr: [0.007555547602711702], Loss: 2.140732, Acc:0.793760, Semantic loss: 0.810285, BCE loss: 0.558553, SB loss: 0.771894
2023-10-30 06:14:15,493 Epoch: [129/484] Iter:[270/495], Time: 0.38, lr: [0.0075551600603402935], Loss: 2.142317, Acc:0.794041, Semantic loss: 0.810960, BCE loss: 0.558516, SB loss: 0.772841
2023-10-30 06:14:19,240 Epoch: [129/484] Iter:[280/495], Time: 0.38, lr: [0.007554772515760095], Loss: 2.134279, Acc:0.794658, Semantic loss: 0.806121, BCE loss: 0.557373, SB loss: 0.770785
2023-10-30 06:14:22,885 Epoch: [129/484] Iter:[290/495], Time: 0.38, lr: [0.007554384968970965], Loss: 2.130191, Acc:0.795100, Semantic loss: 0.804191, BCE loss: 0.555947, SB loss: 0.770052
2023-10-30 06:14:26,559 Epoch: [129/484] Iter:[300/495], Time: 0.38, lr: [0.007553997419972769], Loss: 2.127862, Acc:0.794948, Semantic loss: 0.804891, BCE loss: 0.553084, SB loss: 0.769887
2023-10-30 06:14:30,276 Epoch: [129/484] Iter:[310/495], Time: 0.38, lr: [0.007553609868765365], Loss: 2.124047, Acc:0.795872, Semantic loss: 0.802991, BCE loss: 0.552675, SB loss: 0.768381
2023-10-30 06:14:33,951 Epoch: [129/484] Iter:[320/495], Time: 0.38, lr: [0.007553222315348615], Loss: 2.120656, Acc:0.795510, Semantic loss: 0.802228, BCE loss: 0.550677, SB loss: 0.767751
2023-10-30 06:14:37,615 Epoch: [129/484] Iter:[330/495], Time: 0.38, lr: [0.007552834759722381], Loss: 2.125780, Acc:0.795796, Semantic loss: 0.806232, BCE loss: 0.551632, SB loss: 0.767916
2023-10-30 06:14:41,263 Epoch: [129/484] Iter:[340/495], Time: 0.37, lr: [0.007552447201886526], Loss: 2.118809, Acc:0.794598, Semantic loss: 0.802928, BCE loss: 0.550211, SB loss: 0.765671
2023-10-30 06:14:44,892 Epoch: [129/484] Iter:[350/495], Time: 0.37, lr: [0.007552059641840908], Loss: 2.119915, Acc:0.794440, Semantic loss: 0.802654, BCE loss: 0.550401, SB loss: 0.766860
2023-10-30 06:14:48,563 Epoch: [129/484] Iter:[360/495], Time: 0.37, lr: [0.007551672079585392], Loss: 2.114649, Acc:0.794525, Semantic loss: 0.799876, BCE loss: 0.549270, SB loss: 0.765502
2023-10-30 06:14:52,311 Epoch: [129/484] Iter:[370/495], Time: 0.37, lr: [0.007551284515119838], Loss: 2.113722, Acc:0.795206, Semantic loss: 0.799499, BCE loss: 0.548604, SB loss: 0.765620
2023-10-30 06:14:56,005 Epoch: [129/484] Iter:[380/495], Time: 0.37, lr: [0.007550896948444107], Loss: 2.113169, Acc:0.795361, Semantic loss: 0.797963, BCE loss: 0.548789, SB loss: 0.766417
2023-10-30 06:14:59,688 Epoch: [129/484] Iter:[390/495], Time: 0.37, lr: [0.007550509379558059], Loss: 2.111626, Acc:0.795718, Semantic loss: 0.796966, BCE loss: 0.548999, SB loss: 0.765661
2023-10-30 06:15:03,300 Epoch: [129/484] Iter:[400/495], Time: 0.37, lr: [0.007550121808461559], Loss: 2.110182, Acc:0.795685, Semantic loss: 0.796668, BCE loss: 0.547670, SB loss: 0.765844
2023-10-30 06:15:06,951 Epoch: [129/484] Iter:[410/495], Time: 0.37, lr: [0.007549734235154464], Loss: 2.108323, Acc:0.794902, Semantic loss: 0.796347, BCE loss: 0.546301, SB loss: 0.765674
2023-10-30 06:15:10,646 Epoch: [129/484] Iter:[420/495], Time: 0.37, lr: [0.007549346659636638], Loss: 2.109118, Acc:0.795475, Semantic loss: 0.796213, BCE loss: 0.546980, SB loss: 0.765925
2023-10-30 06:15:14,387 Epoch: [129/484] Iter:[430/495], Time: 0.37, lr: [0.007548959081907941], Loss: 2.114206, Acc:0.795495, Semantic loss: 0.799911, BCE loss: 0.546281, SB loss: 0.768014
2023-10-30 06:15:18,009 Epoch: [129/484] Iter:[440/495], Time: 0.37, lr: [0.007548571501968236], Loss: 2.115563, Acc:0.794687, Semantic loss: 0.801668, BCE loss: 0.545880, SB loss: 0.768014
2023-10-30 06:15:21,786 Epoch: [129/484] Iter:[450/495], Time: 0.37, lr: [0.007548183919817383], Loss: 2.113078, Acc:0.794039, Semantic loss: 0.800753, BCE loss: 0.544973, SB loss: 0.767352
2023-10-30 06:15:25,404 Epoch: [129/484] Iter:[460/495], Time: 0.37, lr: [0.007547796335455243], Loss: 2.113708, Acc:0.794337, Semantic loss: 0.799537, BCE loss: 0.547210, SB loss: 0.766961
2023-10-30 06:15:29,109 Epoch: [129/484] Iter:[470/495], Time: 0.37, lr: [0.007547408748881679], Loss: 2.114912, Acc:0.795047, Semantic loss: 0.798822, BCE loss: 0.548934, SB loss: 0.767156
2023-10-30 06:15:32,775 Epoch: [129/484] Iter:[480/495], Time: 0.37, lr: [0.00754702116009655], Loss: 2.112884, Acc:0.794998, Semantic loss: 0.797604, BCE loss: 0.548801, SB loss: 0.766479
2023-10-30 06:15:36,272 Epoch: [129/484] Iter:[490/495], Time: 0.37, lr: [0.007546633569099717], Loss: 2.115182, Acc:0.795256, Semantic loss: 0.800001, BCE loss: 0.547989, SB loss: 0.767192
2023-10-30 06:15:37,681 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:15:37,916 Loss: 2.034, MeanIU:  0.6757, Best_mIoU:  0.6907
2023-10-30 06:15:37,916 [0.96771356 0.76813954 0.89601897 0.27237792 0.51076366 0.57087683
 0.63448247 0.71755263 0.90630793 0.56771807 0.92086327 0.74044371
 0.52230359 0.91810518 0.53529619 0.69702443 0.55190047 0.42740375
 0.71363591]
2023-10-30 06:15:39,928 Epoch: [130/484] Iter:[0/495], Time: 1.98, lr: [0.007546439772771869], Loss: 2.379326, Acc:0.915109, Semantic loss: 0.780240, BCE loss: 0.771175, SB loss: 0.827912
2023-10-30 06:15:43,954 Epoch: [130/484] Iter:[10/495], Time: 0.55, lr: [0.007546052178457221], Loss: 2.223627, Acc:0.802841, Semantic loss: 0.833109, BCE loss: 0.590864, SB loss: 0.799654
2023-10-30 06:15:47,682 Epoch: [130/484] Iter:[20/495], Time: 0.46, lr: [0.007545664581930523], Loss: 2.121464, Acc:0.798281, Semantic loss: 0.779084, BCE loss: 0.564135, SB loss: 0.778245
2023-10-30 06:15:51,305 Epoch: [130/484] Iter:[30/495], Time: 0.43, lr: [0.0075452769831916375], Loss: 2.091669, Acc:0.795637, Semantic loss: 0.768566, BCE loss: 0.554791, SB loss: 0.768312
2023-10-30 06:15:55,019 Epoch: [130/484] Iter:[40/495], Time: 0.42, lr: [0.007544889382240424], Loss: 2.101801, Acc:0.793928, Semantic loss: 0.778359, BCE loss: 0.551356, SB loss: 0.772086
2023-10-30 06:15:58,545 Epoch: [130/484] Iter:[50/495], Time: 0.40, lr: [0.0075445017790767436], Loss: 2.078664, Acc:0.782805, Semantic loss: 0.769044, BCE loss: 0.541785, SB loss: 0.767835
2023-10-30 06:16:02,170 Epoch: [130/484] Iter:[60/495], Time: 0.40, lr: [0.007544114173700457], Loss: 2.108184, Acc:0.779471, Semantic loss: 0.798666, BCE loss: 0.540864, SB loss: 0.768654
2023-10-30 06:16:05,797 Epoch: [130/484] Iter:[70/495], Time: 0.39, lr: [0.007543726566111425], Loss: 2.103956, Acc:0.779052, Semantic loss: 0.797103, BCE loss: 0.539861, SB loss: 0.766992
2023-10-30 06:16:09,488 Epoch: [130/484] Iter:[80/495], Time: 0.39, lr: [0.007543338956309511], Loss: 2.101522, Acc:0.776529, Semantic loss: 0.793288, BCE loss: 0.539825, SB loss: 0.768409
2023-10-30 06:16:13,086 Epoch: [130/484] Iter:[90/495], Time: 0.39, lr: [0.007542951344294573], Loss: 2.097152, Acc:0.780545, Semantic loss: 0.791414, BCE loss: 0.536643, SB loss: 0.769095
2023-10-30 06:16:16,783 Epoch: [130/484] Iter:[100/495], Time: 0.38, lr: [0.007542563730066474], Loss: 2.098728, Acc:0.781490, Semantic loss: 0.791097, BCE loss: 0.536868, SB loss: 0.770763
2023-10-30 06:16:20,443 Epoch: [130/484] Iter:[110/495], Time: 0.38, lr: [0.007542176113625074], Loss: 2.094230, Acc:0.782548, Semantic loss: 0.790979, BCE loss: 0.534303, SB loss: 0.768948
2023-10-30 06:16:24,166 Epoch: [130/484] Iter:[120/495], Time: 0.38, lr: [0.007541788494970236], Loss: 2.092668, Acc:0.782150, Semantic loss: 0.789442, BCE loss: 0.533003, SB loss: 0.770223
2023-10-30 06:16:27,885 Epoch: [130/484] Iter:[130/495], Time: 0.38, lr: [0.007541400874101818], Loss: 2.098841, Acc:0.785089, Semantic loss: 0.792446, BCE loss: 0.536404, SB loss: 0.769990
2023-10-30 06:16:31,655 Epoch: [130/484] Iter:[140/495], Time: 0.38, lr: [0.007541013251019682], Loss: 2.098500, Acc:0.789561, Semantic loss: 0.792484, BCE loss: 0.537182, SB loss: 0.768835
2023-10-30 06:16:35,367 Epoch: [130/484] Iter:[150/495], Time: 0.38, lr: [0.007540625625723689], Loss: 2.096060, Acc:0.791198, Semantic loss: 0.788192, BCE loss: 0.540245, SB loss: 0.767623
2023-10-30 06:16:39,044 Epoch: [130/484] Iter:[160/495], Time: 0.38, lr: [0.0075402379982137], Loss: 2.092148, Acc:0.791358, Semantic loss: 0.786001, BCE loss: 0.539157, SB loss: 0.766990
2023-10-30 06:16:42,671 Epoch: [130/484] Iter:[170/495], Time: 0.38, lr: [0.007539850368489577], Loss: 2.091750, Acc:0.791408, Semantic loss: 0.785460, BCE loss: 0.538482, SB loss: 0.767808
2023-10-30 06:16:46,233 Epoch: [130/484] Iter:[180/495], Time: 0.38, lr: [0.007539462736551179], Loss: 2.089155, Acc:0.790818, Semantic loss: 0.786590, BCE loss: 0.536168, SB loss: 0.766398
2023-10-30 06:16:50,003 Epoch: [130/484] Iter:[190/495], Time: 0.38, lr: [0.0075390751023983685], Loss: 2.090999, Acc:0.790585, Semantic loss: 0.790481, BCE loss: 0.536348, SB loss: 0.764169
2023-10-30 06:16:53,675 Epoch: [130/484] Iter:[200/495], Time: 0.38, lr: [0.007538687466031006], Loss: 2.084574, Acc:0.791151, Semantic loss: 0.786539, BCE loss: 0.535356, SB loss: 0.762679
2023-10-30 06:16:57,377 Epoch: [130/484] Iter:[210/495], Time: 0.38, lr: [0.007538299827448951], Loss: 2.078487, Acc:0.791907, Semantic loss: 0.784204, BCE loss: 0.532936, SB loss: 0.761347
2023-10-30 06:17:01,114 Epoch: [130/484] Iter:[220/495], Time: 0.38, lr: [0.007537912186652065], Loss: 2.078715, Acc:0.791847, Semantic loss: 0.784922, BCE loss: 0.532887, SB loss: 0.760906
2023-10-30 06:17:04,818 Epoch: [130/484] Iter:[230/495], Time: 0.38, lr: [0.007537524543640209], Loss: 2.084895, Acc:0.792660, Semantic loss: 0.788835, BCE loss: 0.533806, SB loss: 0.762255
2023-10-30 06:17:08,482 Epoch: [130/484] Iter:[240/495], Time: 0.38, lr: [0.007537136898413244], Loss: 2.088307, Acc:0.792872, Semantic loss: 0.790156, BCE loss: 0.534853, SB loss: 0.763298
2023-10-30 06:17:12,188 Epoch: [130/484] Iter:[250/495], Time: 0.38, lr: [0.00753674925097103], Loss: 2.090577, Acc:0.792884, Semantic loss: 0.793210, BCE loss: 0.535139, SB loss: 0.762228
2023-10-30 06:17:15,893 Epoch: [130/484] Iter:[260/495], Time: 0.38, lr: [0.007536361601313429], Loss: 2.093890, Acc:0.792696, Semantic loss: 0.795217, BCE loss: 0.535039, SB loss: 0.763634
2023-10-30 06:17:19,593 Epoch: [130/484] Iter:[270/495], Time: 0.38, lr: [0.0075359739494403], Loss: 2.098552, Acc:0.792819, Semantic loss: 0.797156, BCE loss: 0.537911, SB loss: 0.763485
2023-10-30 06:17:23,316 Epoch: [130/484] Iter:[280/495], Time: 0.37, lr: [0.007535586295351507], Loss: 2.103891, Acc:0.792302, Semantic loss: 0.798623, BCE loss: 0.541345, SB loss: 0.763922
2023-10-30 06:17:27,080 Epoch: [130/484] Iter:[290/495], Time: 0.38, lr: [0.0075351986390469064], Loss: 2.108851, Acc:0.791743, Semantic loss: 0.800492, BCE loss: 0.543001, SB loss: 0.765359
2023-10-30 06:17:30,902 Epoch: [130/484] Iter:[300/495], Time: 0.38, lr: [0.007534810980526361], Loss: 2.108718, Acc:0.792465, Semantic loss: 0.800892, BCE loss: 0.542356, SB loss: 0.765469
2023-10-30 06:17:34,623 Epoch: [130/484] Iter:[310/495], Time: 0.38, lr: [0.0075344233197897304], Loss: 2.109470, Acc:0.793176, Semantic loss: 0.799757, BCE loss: 0.543895, SB loss: 0.765818
2023-10-30 06:17:38,216 Epoch: [130/484] Iter:[320/495], Time: 0.37, lr: [0.007534035656836877], Loss: 2.115221, Acc:0.795168, Semantic loss: 0.801895, BCE loss: 0.547026, SB loss: 0.766300
2023-10-30 06:17:41,829 Epoch: [130/484] Iter:[330/495], Time: 0.37, lr: [0.00753364799166766], Loss: 2.109561, Acc:0.795151, Semantic loss: 0.798278, BCE loss: 0.546282, SB loss: 0.765001
2023-10-30 06:17:45,452 Epoch: [130/484] Iter:[340/495], Time: 0.37, lr: [0.007533260324281942], Loss: 2.106471, Acc:0.795158, Semantic loss: 0.797622, BCE loss: 0.544208, SB loss: 0.764641
2023-10-30 06:17:49,199 Epoch: [130/484] Iter:[350/495], Time: 0.37, lr: [0.007532872654679581], Loss: 2.103032, Acc:0.795214, Semantic loss: 0.796187, BCE loss: 0.543124, SB loss: 0.763721
2023-10-30 06:17:52,772 Epoch: [130/484] Iter:[360/495], Time: 0.37, lr: [0.0075324849828604405], Loss: 2.107330, Acc:0.795322, Semantic loss: 0.798400, BCE loss: 0.543491, SB loss: 0.765438
2023-10-30 06:17:56,482 Epoch: [130/484] Iter:[370/495], Time: 0.37, lr: [0.007532097308824377], Loss: 2.106850, Acc:0.795190, Semantic loss: 0.798001, BCE loss: 0.544559, SB loss: 0.764291
2023-10-30 06:18:00,174 Epoch: [130/484] Iter:[380/495], Time: 0.37, lr: [0.007531709632571255], Loss: 2.106706, Acc:0.793684, Semantic loss: 0.797524, BCE loss: 0.544793, SB loss: 0.764390
2023-10-30 06:18:03,895 Epoch: [130/484] Iter:[390/495], Time: 0.37, lr: [0.007531321954100932], Loss: 2.103963, Acc:0.793468, Semantic loss: 0.795601, BCE loss: 0.544856, SB loss: 0.763505
2023-10-30 06:18:07,605 Epoch: [130/484] Iter:[400/495], Time: 0.37, lr: [0.00753093427341327], Loss: 2.104942, Acc:0.793966, Semantic loss: 0.795358, BCE loss: 0.545277, SB loss: 0.764307
2023-10-30 06:18:11,231 Epoch: [130/484] Iter:[410/495], Time: 0.37, lr: [0.007530546590508129], Loss: 2.100069, Acc:0.793809, Semantic loss: 0.791643, BCE loss: 0.545190, SB loss: 0.763235
2023-10-30 06:18:14,887 Epoch: [130/484] Iter:[420/495], Time: 0.37, lr: [0.007530158905385371], Loss: 2.098160, Acc:0.794109, Semantic loss: 0.790811, BCE loss: 0.544566, SB loss: 0.762783
2023-10-30 06:18:18,616 Epoch: [130/484] Iter:[430/495], Time: 0.37, lr: [0.007529771218044855], Loss: 2.096904, Acc:0.793854, Semantic loss: 0.790979, BCE loss: 0.543370, SB loss: 0.762555
2023-10-30 06:18:22,296 Epoch: [130/484] Iter:[440/495], Time: 0.37, lr: [0.007529383528486442], Loss: 2.101514, Acc:0.794180, Semantic loss: 0.794444, BCE loss: 0.542781, SB loss: 0.764288
2023-10-30 06:18:26,007 Epoch: [130/484] Iter:[450/495], Time: 0.37, lr: [0.007528995836709992], Loss: 2.102279, Acc:0.794372, Semantic loss: 0.794041, BCE loss: 0.543777, SB loss: 0.764460
2023-10-30 06:18:29,656 Epoch: [130/484] Iter:[460/495], Time: 0.37, lr: [0.007528608142715366], Loss: 2.102531, Acc:0.794790, Semantic loss: 0.794711, BCE loss: 0.543921, SB loss: 0.763899
2023-10-30 06:18:33,305 Epoch: [130/484] Iter:[470/495], Time: 0.37, lr: [0.0075282204465024205], Loss: 2.105003, Acc:0.795594, Semantic loss: 0.794881, BCE loss: 0.545671, SB loss: 0.764450
2023-10-30 06:18:37,044 Epoch: [130/484] Iter:[480/495], Time: 0.37, lr: [0.007527832748071023], Loss: 2.101694, Acc:0.794681, Semantic loss: 0.793557, BCE loss: 0.544346, SB loss: 0.763791
2023-10-30 06:18:40,548 Epoch: [130/484] Iter:[490/495], Time: 0.37, lr: [0.007527445047421028], Loss: 2.101762, Acc:0.795310, Semantic loss: 0.793337, BCE loss: 0.544034, SB loss: 0.764391
2023-10-30 06:21:37,615 0 [9.39044698e-01 6.43190183e-01 8.27646850e-01 1.52102376e-01
 2.02553827e-01 4.09663746e-01 4.37937092e-01 5.57468024e-01
 8.88077833e-01 4.77567852e-01 8.72181650e-01 6.00424975e-01
 3.05687556e-02 7.89925139e-01 2.54497142e-04 3.89370051e-02
 3.37834892e-02 3.82802861e-02 5.81921004e-01] 0.4485015411549049
2023-10-30 06:21:37,615 1 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913] 0.6488097081925328
2023-10-30 06:21:37,619 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:21:37,857 Loss: 2.121, MeanIU:  0.6488, Best_mIoU:  0.6907
2023-10-30 06:21:37,857 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913]
2023-10-30 06:21:40,101 Epoch: [131/484] Iter:[0/495], Time: 2.21, lr: [0.007527251196264013], Loss: 1.894478, Acc:0.836653, Semantic loss: 0.641803, BCE loss: 0.603382, SB loss: 0.649292
2023-10-30 06:21:43,710 Epoch: [131/484] Iter:[10/495], Time: 0.53, lr: [0.007526863492285865], Loss: 1.936577, Acc:0.796303, Semantic loss: 0.730683, BCE loss: 0.504593, SB loss: 0.701302
2023-10-30 06:21:47,221 Epoch: [131/484] Iter:[20/495], Time: 0.44, lr: [0.007526475786088771], Loss: 1.994302, Acc:0.802027, Semantic loss: 0.751538, BCE loss: 0.516817, SB loss: 0.725946
2023-10-30 06:21:50,712 Epoch: [131/484] Iter:[30/495], Time: 0.41, lr: [0.007526088077672593], Loss: 2.003613, Acc:0.793003, Semantic loss: 0.755094, BCE loss: 0.520627, SB loss: 0.727892
2023-10-30 06:21:54,177 Epoch: [131/484] Iter:[40/495], Time: 0.40, lr: [0.007525700367037193], Loss: 2.122074, Acc:0.789724, Semantic loss: 0.836974, BCE loss: 0.533089, SB loss: 0.752011
2023-10-30 06:21:57,663 Epoch: [131/484] Iter:[50/495], Time: 0.39, lr: [0.007525312654182425], Loss: 2.062417, Acc:0.788590, Semantic loss: 0.788716, BCE loss: 0.529598, SB loss: 0.744104
2023-10-30 06:22:01,147 Epoch: [131/484] Iter:[60/495], Time: 0.38, lr: [0.007524924939108157], Loss: 2.064766, Acc:0.784645, Semantic loss: 0.791482, BCE loss: 0.522983, SB loss: 0.750301
2023-10-30 06:22:04,636 Epoch: [131/484] Iter:[70/495], Time: 0.38, lr: [0.007524537221814244], Loss: 2.086640, Acc:0.784519, Semantic loss: 0.801844, BCE loss: 0.526836, SB loss: 0.757960
2023-10-30 06:22:08,214 Epoch: [131/484] Iter:[80/495], Time: 0.37, lr: [0.007524149502300549], Loss: 2.128142, Acc:0.783412, Semantic loss: 0.819490, BCE loss: 0.544369, SB loss: 0.764284
2023-10-30 06:22:11,693 Epoch: [131/484] Iter:[90/495], Time: 0.37, lr: [0.007523761780566931], Loss: 2.129733, Acc:0.780408, Semantic loss: 0.819253, BCE loss: 0.544627, SB loss: 0.765853
2023-10-30 06:22:15,203 Epoch: [131/484] Iter:[100/495], Time: 0.37, lr: [0.00752337405661325], Loss: 2.127921, Acc:0.779910, Semantic loss: 0.817976, BCE loss: 0.541042, SB loss: 0.768903
2023-10-30 06:22:18,877 Epoch: [131/484] Iter:[110/495], Time: 0.37, lr: [0.0075229863304393674], Loss: 2.115889, Acc:0.780354, Semantic loss: 0.809766, BCE loss: 0.538516, SB loss: 0.767607
2023-10-30 06:22:22,523 Epoch: [131/484] Iter:[120/495], Time: 0.37, lr: [0.007522598602045142], Loss: 2.102667, Acc:0.776883, Semantic loss: 0.803338, BCE loss: 0.534742, SB loss: 0.764587
2023-10-30 06:22:26,264 Epoch: [131/484] Iter:[130/495], Time: 0.37, lr: [0.007522210871430433], Loss: 2.105666, Acc:0.778546, Semantic loss: 0.800884, BCE loss: 0.539432, SB loss: 0.765350
2023-10-30 06:22:29,861 Epoch: [131/484] Iter:[140/495], Time: 0.37, lr: [0.007521823138595103], Loss: 2.116782, Acc:0.783276, Semantic loss: 0.808129, BCE loss: 0.539609, SB loss: 0.769044
2023-10-30 06:22:33,445 Epoch: [131/484] Iter:[150/495], Time: 0.37, lr: [0.007521435403539011], Loss: 2.106446, Acc:0.782768, Semantic loss: 0.801408, BCE loss: 0.538994, SB loss: 0.766044
2023-10-30 06:22:37,086 Epoch: [131/484] Iter:[160/495], Time: 0.37, lr: [0.007521047666262016], Loss: 2.101059, Acc:0.783293, Semantic loss: 0.796191, BCE loss: 0.539906, SB loss: 0.764963
2023-10-30 06:22:40,710 Epoch: [131/484] Iter:[170/495], Time: 0.37, lr: [0.0075206599267639805], Loss: 2.100463, Acc:0.783550, Semantic loss: 0.794496, BCE loss: 0.542327, SB loss: 0.763639
2023-10-30 06:22:44,334 Epoch: [131/484] Iter:[180/495], Time: 0.37, lr: [0.007520272185044763], Loss: 2.097509, Acc:0.784603, Semantic loss: 0.796076, BCE loss: 0.538234, SB loss: 0.763199
2023-10-30 06:22:47,955 Epoch: [131/484] Iter:[190/495], Time: 0.37, lr: [0.0075198844411042244], Loss: 2.099713, Acc:0.784872, Semantic loss: 0.799273, BCE loss: 0.536178, SB loss: 0.764262
2023-10-30 06:22:51,582 Epoch: [131/484] Iter:[200/495], Time: 0.37, lr: [0.007519496694942223], Loss: 2.099534, Acc:0.786290, Semantic loss: 0.797147, BCE loss: 0.536983, SB loss: 0.765405
2023-10-30 06:22:55,202 Epoch: [131/484] Iter:[210/495], Time: 0.37, lr: [0.00751910894655862], Loss: 2.095128, Acc:0.786298, Semantic loss: 0.794526, BCE loss: 0.536639, SB loss: 0.763964
2023-10-30 06:22:58,757 Epoch: [131/484] Iter:[220/495], Time: 0.37, lr: [0.007518721195953274], Loss: 2.092511, Acc:0.785494, Semantic loss: 0.793549, BCE loss: 0.535455, SB loss: 0.763508
2023-10-30 06:23:02,357 Epoch: [131/484] Iter:[230/495], Time: 0.37, lr: [0.007518333443126047], Loss: 2.090996, Acc:0.785496, Semantic loss: 0.791117, BCE loss: 0.538100, SB loss: 0.761780
2023-10-30 06:23:06,126 Epoch: [131/484] Iter:[240/495], Time: 0.37, lr: [0.0075179456880767985], Loss: 2.093997, Acc:0.786175, Semantic loss: 0.790483, BCE loss: 0.542088, SB loss: 0.761425
2023-10-30 06:23:09,800 Epoch: [131/484] Iter:[250/495], Time: 0.37, lr: [0.007517557930805388], Loss: 2.091261, Acc:0.787533, Semantic loss: 0.789525, BCE loss: 0.540622, SB loss: 0.761115
2023-10-30 06:23:13,437 Epoch: [131/484] Iter:[260/495], Time: 0.37, lr: [0.007517170171311675], Loss: 2.090838, Acc:0.787129, Semantic loss: 0.790775, BCE loss: 0.538571, SB loss: 0.761492
2023-10-30 06:23:17,092 Epoch: [131/484] Iter:[270/495], Time: 0.37, lr: [0.0075167824095955195], Loss: 2.096257, Acc:0.786779, Semantic loss: 0.792439, BCE loss: 0.539891, SB loss: 0.763927
2023-10-30 06:23:20,713 Epoch: [131/484] Iter:[280/495], Time: 0.37, lr: [0.007516394645656782], Loss: 2.106006, Acc:0.786631, Semantic loss: 0.797116, BCE loss: 0.541935, SB loss: 0.766954
2023-10-30 06:23:24,373 Epoch: [131/484] Iter:[290/495], Time: 0.37, lr: [0.007516006879495322], Loss: 2.106999, Acc:0.787021, Semantic loss: 0.796254, BCE loss: 0.543674, SB loss: 0.767071
2023-10-30 06:23:27,987 Epoch: [131/484] Iter:[300/495], Time: 0.37, lr: [0.007515619111110999], Loss: 2.107944, Acc:0.786638, Semantic loss: 0.799202, BCE loss: 0.540804, SB loss: 0.767938
2023-10-30 06:23:31,654 Epoch: [131/484] Iter:[310/495], Time: 0.37, lr: [0.007515231340503673], Loss: 2.109172, Acc:0.786278, Semantic loss: 0.798775, BCE loss: 0.541772, SB loss: 0.768625
2023-10-30 06:23:35,274 Epoch: [131/484] Iter:[320/495], Time: 0.37, lr: [0.007514843567673204], Loss: 2.110999, Acc:0.787082, Semantic loss: 0.799360, BCE loss: 0.542909, SB loss: 0.768731
2023-10-30 06:23:38,928 Epoch: [131/484] Iter:[330/495], Time: 0.37, lr: [0.007514455792619453], Loss: 2.112754, Acc:0.786355, Semantic loss: 0.800319, BCE loss: 0.542989, SB loss: 0.769446
2023-10-30 06:23:42,523 Epoch: [131/484] Iter:[340/495], Time: 0.37, lr: [0.007514068015342278], Loss: 2.107786, Acc:0.785441, Semantic loss: 0.799756, BCE loss: 0.539916, SB loss: 0.768114
2023-10-30 06:23:46,104 Epoch: [131/484] Iter:[350/495], Time: 0.37, lr: [0.007513680235841539], Loss: 2.107036, Acc:0.784303, Semantic loss: 0.798720, BCE loss: 0.540542, SB loss: 0.767774
2023-10-30 06:23:49,713 Epoch: [131/484] Iter:[360/495], Time: 0.37, lr: [0.007513292454117096], Loss: 2.108571, Acc:0.784877, Semantic loss: 0.798111, BCE loss: 0.542484, SB loss: 0.767976
2023-10-30 06:23:53,489 Epoch: [131/484] Iter:[370/495], Time: 0.37, lr: [0.00751290467016881], Loss: 2.104809, Acc:0.785898, Semantic loss: 0.795397, BCE loss: 0.543337, SB loss: 0.766075
2023-10-30 06:23:57,110 Epoch: [131/484] Iter:[380/495], Time: 0.37, lr: [0.007512516883996538], Loss: 2.101810, Acc:0.786573, Semantic loss: 0.793187, BCE loss: 0.543287, SB loss: 0.765336
2023-10-30 06:24:00,761 Epoch: [131/484] Iter:[390/495], Time: 0.37, lr: [0.007512129095600141], Loss: 2.100851, Acc:0.787231, Semantic loss: 0.793304, BCE loss: 0.542943, SB loss: 0.764604
2023-10-30 06:24:04,439 Epoch: [131/484] Iter:[400/495], Time: 0.37, lr: [0.007511741304979479], Loss: 2.101605, Acc:0.786727, Semantic loss: 0.793978, BCE loss: 0.542816, SB loss: 0.764811
2023-10-30 06:24:08,127 Epoch: [131/484] Iter:[410/495], Time: 0.37, lr: [0.007511353512134412], Loss: 2.099772, Acc:0.786322, Semantic loss: 0.792636, BCE loss: 0.542196, SB loss: 0.764941
2023-10-30 06:24:11,704 Epoch: [131/484] Iter:[420/495], Time: 0.37, lr: [0.0075109657170648], Loss: 2.102177, Acc:0.786944, Semantic loss: 0.793750, BCE loss: 0.542722, SB loss: 0.765705
2023-10-30 06:24:15,390 Epoch: [131/484] Iter:[430/495], Time: 0.37, lr: [0.007510577919770501], Loss: 2.098682, Acc:0.786775, Semantic loss: 0.793027, BCE loss: 0.540828, SB loss: 0.764827
2023-10-30 06:24:19,075 Epoch: [131/484] Iter:[440/495], Time: 0.37, lr: [0.007510190120251375], Loss: 2.101247, Acc:0.787327, Semantic loss: 0.795634, BCE loss: 0.540620, SB loss: 0.764993
2023-10-30 06:24:22,640 Epoch: [131/484] Iter:[450/495], Time: 0.37, lr: [0.007509802318507282], Loss: 2.100696, Acc:0.787428, Semantic loss: 0.795423, BCE loss: 0.540676, SB loss: 0.764598
2023-10-30 06:24:26,261 Epoch: [131/484] Iter:[460/495], Time: 0.37, lr: [0.007509414514538081], Loss: 2.101447, Acc:0.787498, Semantic loss: 0.795365, BCE loss: 0.540891, SB loss: 0.765191
2023-10-30 06:24:29,892 Epoch: [131/484] Iter:[470/495], Time: 0.37, lr: [0.007509026708343634], Loss: 2.098118, Acc:0.787488, Semantic loss: 0.793646, BCE loss: 0.540199, SB loss: 0.764273
2023-10-30 06:24:33,466 Epoch: [131/484] Iter:[480/495], Time: 0.37, lr: [0.007508638899923797], Loss: 2.097975, Acc:0.786957, Semantic loss: 0.794986, BCE loss: 0.539009, SB loss: 0.763979
2023-10-30 06:24:36,886 Epoch: [131/484] Iter:[490/495], Time: 0.36, lr: [0.0075082510892784315], Loss: 2.097441, Acc:0.787514, Semantic loss: 0.794258, BCE loss: 0.539583, SB loss: 0.763600
2023-10-30 06:24:38,281 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:24:38,516 Loss: 2.121, MeanIU:  0.6488, Best_mIoU:  0.6907
2023-10-30 06:24:38,517 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913]
2023-10-30 06:24:40,569 Epoch: [132/484] Iter:[0/495], Time: 2.02, lr: [0.007508057183121132], Loss: 2.081547, Acc:0.824007, Semantic loss: 0.757733, BCE loss: 0.474650, SB loss: 0.849165
2023-10-30 06:24:44,559 Epoch: [132/484] Iter:[10/495], Time: 0.55, lr: [0.00750766936913721], Loss: 2.094186, Acc:0.810004, Semantic loss: 0.824951, BCE loss: 0.501092, SB loss: 0.768143
2023-10-30 06:24:48,237 Epoch: [132/484] Iter:[20/495], Time: 0.46, lr: [0.007507281552927407], Loss: 2.032370, Acc:0.810160, Semantic loss: 0.777615, BCE loss: 0.506925, SB loss: 0.747830
2023-10-30 06:24:51,959 Epoch: [132/484] Iter:[30/495], Time: 0.43, lr: [0.0075068937344915845], Loss: 2.034918, Acc:0.809688, Semantic loss: 0.782755, BCE loss: 0.505402, SB loss: 0.746761
2023-10-30 06:24:55,652 Epoch: [132/484] Iter:[40/495], Time: 0.42, lr: [0.0075065059138296], Loss: 2.035845, Acc:0.811950, Semantic loss: 0.765898, BCE loss: 0.515168, SB loss: 0.754779
2023-10-30 06:24:59,357 Epoch: [132/484] Iter:[50/495], Time: 0.41, lr: [0.007506118090941313], Loss: 2.024876, Acc:0.812422, Semantic loss: 0.760848, BCE loss: 0.516978, SB loss: 0.747050
2023-10-30 06:25:03,094 Epoch: [132/484] Iter:[60/495], Time: 0.40, lr: [0.007505730265826585], Loss: 2.018509, Acc:0.806303, Semantic loss: 0.760459, BCE loss: 0.507066, SB loss: 0.750983
2023-10-30 06:25:06,712 Epoch: [132/484] Iter:[70/495], Time: 0.40, lr: [0.007505342438485273], Loss: 2.044408, Acc:0.798192, Semantic loss: 0.777104, BCE loss: 0.509533, SB loss: 0.757770
2023-10-30 06:25:10,428 Epoch: [132/484] Iter:[80/495], Time: 0.39, lr: [0.007504954608917238], Loss: 2.043348, Acc:0.799297, Semantic loss: 0.773522, BCE loss: 0.511834, SB loss: 0.757992
2023-10-30 06:25:14,097 Epoch: [132/484] Iter:[90/495], Time: 0.39, lr: [0.007504566777122339], Loss: 2.038120, Acc:0.796589, Semantic loss: 0.773445, BCE loss: 0.509766, SB loss: 0.754910
2023-10-30 06:25:17,875 Epoch: [132/484] Iter:[100/495], Time: 0.39, lr: [0.007504178943100436], Loss: 2.056877, Acc:0.795922, Semantic loss: 0.787228, BCE loss: 0.510413, SB loss: 0.759237
2023-10-30 06:25:21,565 Epoch: [132/484] Iter:[110/495], Time: 0.39, lr: [0.0075037911068513855], Loss: 2.054537, Acc:0.798960, Semantic loss: 0.778038, BCE loss: 0.517785, SB loss: 0.758714
2023-10-30 06:25:25,222 Epoch: [132/484] Iter:[120/495], Time: 0.39, lr: [0.007503403268375048], Loss: 2.038801, Acc:0.795448, Semantic loss: 0.771287, BCE loss: 0.512573, SB loss: 0.754941
2023-10-30 06:25:28,983 Epoch: [132/484] Iter:[130/495], Time: 0.38, lr: [0.007503015427671285], Loss: 2.043948, Acc:0.794133, Semantic loss: 0.773554, BCE loss: 0.515710, SB loss: 0.754684
2023-10-30 06:25:32,661 Epoch: [132/484] Iter:[140/495], Time: 0.38, lr: [0.007502627584739954], Loss: 2.049416, Acc:0.793806, Semantic loss: 0.773033, BCE loss: 0.520161, SB loss: 0.756222
2023-10-30 06:25:36,363 Epoch: [132/484] Iter:[150/495], Time: 0.38, lr: [0.007502239739580915], Loss: 2.058868, Acc:0.793526, Semantic loss: 0.778864, BCE loss: 0.519411, SB loss: 0.760594
2023-10-30 06:25:40,126 Epoch: [132/484] Iter:[160/495], Time: 0.38, lr: [0.007501851892194027], Loss: 2.070423, Acc:0.792245, Semantic loss: 0.783807, BCE loss: 0.521942, SB loss: 0.764674
2023-10-30 06:25:43,862 Epoch: [132/484] Iter:[170/495], Time: 0.38, lr: [0.007501464042579148], Loss: 2.080224, Acc:0.792454, Semantic loss: 0.789206, BCE loss: 0.523507, SB loss: 0.767512
2023-10-30 06:25:47,583 Epoch: [132/484] Iter:[180/495], Time: 0.38, lr: [0.007501076190736139], Loss: 2.088223, Acc:0.792605, Semantic loss: 0.793424, BCE loss: 0.527066, SB loss: 0.767733
2023-10-30 06:25:51,278 Epoch: [132/484] Iter:[190/495], Time: 0.38, lr: [0.007500688336664857], Loss: 2.084650, Acc:0.793656, Semantic loss: 0.791194, BCE loss: 0.527331, SB loss: 0.766125
2023-10-30 06:25:54,918 Epoch: [132/484] Iter:[200/495], Time: 0.38, lr: [0.007500300480365163], Loss: 2.084357, Acc:0.794061, Semantic loss: 0.791221, BCE loss: 0.527135, SB loss: 0.766000
2023-10-30 06:25:58,578 Epoch: [132/484] Iter:[210/495], Time: 0.38, lr: [0.007499912621836916], Loss: 2.085813, Acc:0.793709, Semantic loss: 0.792400, BCE loss: 0.526902, SB loss: 0.766511
2023-10-30 06:26:02,300 Epoch: [132/484] Iter:[220/495], Time: 0.38, lr: [0.0074995247610799756], Loss: 2.092759, Acc:0.792554, Semantic loss: 0.796288, BCE loss: 0.528851, SB loss: 0.767619
2023-10-30 06:26:05,937 Epoch: [132/484] Iter:[230/495], Time: 0.38, lr: [0.0074991368980942], Loss: 2.098899, Acc:0.791698, Semantic loss: 0.799026, BCE loss: 0.531431, SB loss: 0.768441
2023-10-30 06:26:09,625 Epoch: [132/484] Iter:[240/495], Time: 0.38, lr: [0.007498749032879448], Loss: 2.097189, Acc:0.792870, Semantic loss: 0.798136, BCE loss: 0.532061, SB loss: 0.766992
2023-10-30 06:26:13,219 Epoch: [132/484] Iter:[250/495], Time: 0.38, lr: [0.0074983611654355796], Loss: 2.105967, Acc:0.791393, Semantic loss: 0.802938, BCE loss: 0.534633, SB loss: 0.768396
2023-10-30 06:26:16,970 Epoch: [132/484] Iter:[260/495], Time: 0.38, lr: [0.0074979732957624525], Loss: 2.109648, Acc:0.790820, Semantic loss: 0.804566, BCE loss: 0.535940, SB loss: 0.769143
2023-10-30 06:26:20,703 Epoch: [132/484] Iter:[270/495], Time: 0.38, lr: [0.007497585423859927], Loss: 2.110972, Acc:0.792140, Semantic loss: 0.804759, BCE loss: 0.536787, SB loss: 0.769426
2023-10-30 06:26:24,408 Epoch: [132/484] Iter:[280/495], Time: 0.38, lr: [0.007497197549727861], Loss: 2.111177, Acc:0.792744, Semantic loss: 0.803707, BCE loss: 0.537242, SB loss: 0.770228
2023-10-30 06:26:28,081 Epoch: [132/484] Iter:[290/495], Time: 0.38, lr: [0.0074968096733661164], Loss: 2.110146, Acc:0.793475, Semantic loss: 0.802537, BCE loss: 0.536059, SB loss: 0.771549
2023-10-30 06:26:31,867 Epoch: [132/484] Iter:[300/495], Time: 0.38, lr: [0.00749642179477455], Loss: 2.106895, Acc:0.792847, Semantic loss: 0.800811, BCE loss: 0.535375, SB loss: 0.770709
2023-10-30 06:26:35,691 Epoch: [132/484] Iter:[310/495], Time: 0.38, lr: [0.00749603391395302], Loss: 2.108930, Acc:0.792969, Semantic loss: 0.800428, BCE loss: 0.538654, SB loss: 0.769848
2023-10-30 06:26:39,328 Epoch: [132/484] Iter:[320/495], Time: 0.38, lr: [0.007495646030901386], Loss: 2.113549, Acc:0.792572, Semantic loss: 0.802166, BCE loss: 0.540241, SB loss: 0.771142
2023-10-30 06:26:42,934 Epoch: [132/484] Iter:[330/495], Time: 0.38, lr: [0.007495258145619508], Loss: 2.114620, Acc:0.793190, Semantic loss: 0.802431, BCE loss: 0.540614, SB loss: 0.771575
2023-10-30 06:26:46,716 Epoch: [132/484] Iter:[340/495], Time: 0.38, lr: [0.007494870258107244], Loss: 2.112161, Acc:0.792469, Semantic loss: 0.801325, BCE loss: 0.538911, SB loss: 0.771925
2023-10-30 06:26:50,382 Epoch: [132/484] Iter:[350/495], Time: 0.38, lr: [0.007494482368364453], Loss: 2.113425, Acc:0.793256, Semantic loss: 0.800586, BCE loss: 0.540920, SB loss: 0.771918
2023-10-30 06:26:53,957 Epoch: [132/484] Iter:[360/495], Time: 0.38, lr: [0.007494094476390992], Loss: 2.112009, Acc:0.792635, Semantic loss: 0.799211, BCE loss: 0.540640, SB loss: 0.772159
2023-10-30 06:26:57,568 Epoch: [132/484] Iter:[370/495], Time: 0.37, lr: [0.007493706582186724], Loss: 2.111248, Acc:0.791233, Semantic loss: 0.799808, BCE loss: 0.538426, SB loss: 0.773015
2023-10-30 06:27:01,409 Epoch: [132/484] Iter:[380/495], Time: 0.37, lr: [0.0074933186857515065], Loss: 2.108969, Acc:0.790653, Semantic loss: 0.797977, BCE loss: 0.538805, SB loss: 0.772188
2023-10-30 06:27:05,031 Epoch: [132/484] Iter:[390/495], Time: 0.37, lr: [0.0074929307870851974], Loss: 2.111744, Acc:0.790869, Semantic loss: 0.798737, BCE loss: 0.540065, SB loss: 0.772942
2023-10-30 06:27:08,806 Epoch: [132/484] Iter:[400/495], Time: 0.37, lr: [0.007492542886187654], Loss: 2.109259, Acc:0.791013, Semantic loss: 0.797451, BCE loss: 0.539895, SB loss: 0.771913
2023-10-30 06:27:12,549 Epoch: [132/484] Iter:[410/495], Time: 0.37, lr: [0.007492154983058739], Loss: 2.107385, Acc:0.791305, Semantic loss: 0.797094, BCE loss: 0.539005, SB loss: 0.771285
2023-10-30 06:27:16,279 Epoch: [132/484] Iter:[420/495], Time: 0.37, lr: [0.007491767077698307], Loss: 2.105726, Acc:0.790600, Semantic loss: 0.795750, BCE loss: 0.539783, SB loss: 0.770193
2023-10-30 06:27:20,081 Epoch: [132/484] Iter:[430/495], Time: 0.37, lr: [0.007491379170106219], Loss: 2.104042, Acc:0.790624, Semantic loss: 0.794241, BCE loss: 0.539641, SB loss: 0.770161
2023-10-30 06:27:23,874 Epoch: [132/484] Iter:[440/495], Time: 0.37, lr: [0.007490991260282334], Loss: 2.105622, Acc:0.791497, Semantic loss: 0.795761, BCE loss: 0.539651, SB loss: 0.770209
2023-10-30 06:27:27,664 Epoch: [132/484] Iter:[450/495], Time: 0.37, lr: [0.007490603348226511], Loss: 2.105032, Acc:0.791696, Semantic loss: 0.795342, BCE loss: 0.539908, SB loss: 0.769783
2023-10-30 06:27:31,410 Epoch: [132/484] Iter:[460/495], Time: 0.37, lr: [0.007490215433938609], Loss: 2.108073, Acc:0.792033, Semantic loss: 0.796653, BCE loss: 0.541995, SB loss: 0.769425
2023-10-30 06:27:35,030 Epoch: [132/484] Iter:[470/495], Time: 0.37, lr: [0.007489827517418484], Loss: 2.110160, Acc:0.792560, Semantic loss: 0.796979, BCE loss: 0.542852, SB loss: 0.770329
2023-10-30 06:27:38,659 Epoch: [132/484] Iter:[480/495], Time: 0.37, lr: [0.007489439598665997], Loss: 2.111387, Acc:0.792253, Semantic loss: 0.797249, BCE loss: 0.543573, SB loss: 0.770565
2023-10-30 06:27:42,085 Epoch: [132/484] Iter:[490/495], Time: 0.37, lr: [0.007489051677681007], Loss: 2.108363, Acc:0.791762, Semantic loss: 0.794620, BCE loss: 0.544399, SB loss: 0.769344
2023-10-30 06:27:43,490 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:27:43,731 Loss: 2.121, MeanIU:  0.6488, Best_mIoU:  0.6907
2023-10-30 06:27:43,731 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913]
2023-10-30 06:27:45,845 Epoch: [133/484] Iter:[0/495], Time: 2.08, lr: [0.0074888577163512784], Loss: 2.417574, Acc:0.786431, Semantic loss: 0.985968, BCE loss: 0.567730, SB loss: 0.863876
2023-10-30 06:27:49,786 Epoch: [133/484] Iter:[10/495], Time: 0.55, lr: [0.007488469792017265], Loss: 2.157553, Acc:0.803617, Semantic loss: 0.796621, BCE loss: 0.604909, SB loss: 0.756023
2023-10-30 06:27:53,561 Epoch: [133/484] Iter:[20/495], Time: 0.47, lr: [0.007488081865450396], Loss: 2.041729, Acc:0.819066, Semantic loss: 0.749418, BCE loss: 0.552813, SB loss: 0.739498
2023-10-30 06:27:57,199 Epoch: [133/484] Iter:[30/495], Time: 0.43, lr: [0.007487693936650528], Loss: 2.068615, Acc:0.799776, Semantic loss: 0.770403, BCE loss: 0.545515, SB loss: 0.752697
2023-10-30 06:28:00,837 Epoch: [133/484] Iter:[40/495], Time: 0.42, lr: [0.007487306005617521], Loss: 2.103416, Acc:0.799045, Semantic loss: 0.776838, BCE loss: 0.561987, SB loss: 0.764591
2023-10-30 06:28:04,472 Epoch: [133/484] Iter:[50/495], Time: 0.41, lr: [0.007486918072351232], Loss: 2.090662, Acc:0.801259, Semantic loss: 0.774375, BCE loss: 0.561771, SB loss: 0.754517
2023-10-30 06:28:08,107 Epoch: [133/484] Iter:[60/495], Time: 0.40, lr: [0.0074865301368515205], Loss: 2.087171, Acc:0.804776, Semantic loss: 0.779844, BCE loss: 0.553842, SB loss: 0.753485
2023-10-30 06:28:11,714 Epoch: [133/484] Iter:[70/495], Time: 0.39, lr: [0.007486142199118246], Loss: 2.075203, Acc:0.799425, Semantic loss: 0.775542, BCE loss: 0.546198, SB loss: 0.753464
2023-10-30 06:28:15,371 Epoch: [133/484] Iter:[80/495], Time: 0.39, lr: [0.007485754259151263], Loss: 2.066367, Acc:0.801037, Semantic loss: 0.768478, BCE loss: 0.548408, SB loss: 0.749481
2023-10-30 06:28:19,024 Epoch: [133/484] Iter:[90/495], Time: 0.39, lr: [0.007485366316950434], Loss: 2.065372, Acc:0.798810, Semantic loss: 0.768816, BCE loss: 0.544377, SB loss: 0.752179
2023-10-30 06:28:22,743 Epoch: [133/484] Iter:[100/495], Time: 0.39, lr: [0.007484978372515615], Loss: 2.076792, Acc:0.802433, Semantic loss: 0.773838, BCE loss: 0.548445, SB loss: 0.754509
2023-10-30 06:28:26,382 Epoch: [133/484] Iter:[110/495], Time: 0.38, lr: [0.007484590425846667], Loss: 2.072226, Acc:0.802157, Semantic loss: 0.768819, BCE loss: 0.550005, SB loss: 0.753402
2023-10-30 06:28:29,955 Epoch: [133/484] Iter:[120/495], Time: 0.38, lr: [0.007484202476943447], Loss: 2.066328, Acc:0.800625, Semantic loss: 0.765304, BCE loss: 0.547215, SB loss: 0.753808
2023-10-30 06:28:33,692 Epoch: [133/484] Iter:[130/495], Time: 0.38, lr: [0.007483814525805814], Loss: 2.065435, Acc:0.800239, Semantic loss: 0.763435, BCE loss: 0.547163, SB loss: 0.754838
2023-10-30 06:28:37,432 Epoch: [133/484] Iter:[140/495], Time: 0.38, lr: [0.007483426572433626], Loss: 2.063688, Acc:0.799001, Semantic loss: 0.764956, BCE loss: 0.545423, SB loss: 0.753309
2023-10-30 06:28:40,995 Epoch: [133/484] Iter:[150/495], Time: 0.38, lr: [0.007483038616826742], Loss: 2.061887, Acc:0.799792, Semantic loss: 0.765400, BCE loss: 0.544282, SB loss: 0.752205
2023-10-30 06:28:44,639 Epoch: [133/484] Iter:[160/495], Time: 0.38, lr: [0.007482650658985017], Loss: 2.070364, Acc:0.797903, Semantic loss: 0.772635, BCE loss: 0.542165, SB loss: 0.755564
2023-10-30 06:28:48,284 Epoch: [133/484] Iter:[170/495], Time: 0.38, lr: [0.007482262698908316], Loss: 2.078967, Acc:0.795257, Semantic loss: 0.777527, BCE loss: 0.543259, SB loss: 0.758181
2023-10-30 06:28:51,918 Epoch: [133/484] Iter:[180/495], Time: 0.38, lr: [0.00748187473659649], Loss: 2.078154, Acc:0.795987, Semantic loss: 0.774942, BCE loss: 0.545630, SB loss: 0.757582
2023-10-30 06:28:55,555 Epoch: [133/484] Iter:[190/495], Time: 0.38, lr: [0.007481486772049403], Loss: 2.073070, Acc:0.795802, Semantic loss: 0.774372, BCE loss: 0.542381, SB loss: 0.756317
2023-10-30 06:28:59,368 Epoch: [133/484] Iter:[200/495], Time: 0.38, lr: [0.007481098805266912], Loss: 2.081559, Acc:0.795903, Semantic loss: 0.775663, BCE loss: 0.547154, SB loss: 0.758742
2023-10-30 06:29:03,044 Epoch: [133/484] Iter:[210/495], Time: 0.38, lr: [0.007480710836248874], Loss: 2.090299, Acc:0.797902, Semantic loss: 0.778620, BCE loss: 0.550124, SB loss: 0.761555
2023-10-30 06:29:06,647 Epoch: [133/484] Iter:[220/495], Time: 0.38, lr: [0.007480322864995147], Loss: 2.091199, Acc:0.799653, Semantic loss: 0.778679, BCE loss: 0.551883, SB loss: 0.760637
2023-10-30 06:29:10,475 Epoch: [133/484] Iter:[230/495], Time: 0.38, lr: [0.007479934891505592], Loss: 2.091305, Acc:0.800757, Semantic loss: 0.779180, BCE loss: 0.551778, SB loss: 0.760346
2023-10-30 06:29:14,312 Epoch: [133/484] Iter:[240/495], Time: 0.38, lr: [0.007479546915780063], Loss: 2.092167, Acc:0.801131, Semantic loss: 0.778812, BCE loss: 0.552908, SB loss: 0.760446
2023-10-30 06:29:17,877 Epoch: [133/484] Iter:[250/495], Time: 0.37, lr: [0.007479158937818422], Loss: 2.100021, Acc:0.800028, Semantic loss: 0.784822, BCE loss: 0.552764, SB loss: 0.762435
2023-10-30 06:29:21,516 Epoch: [133/484] Iter:[260/495], Time: 0.37, lr: [0.0074787709576205254], Loss: 2.097621, Acc:0.799744, Semantic loss: 0.783443, BCE loss: 0.551191, SB loss: 0.762988
2023-10-30 06:29:25,228 Epoch: [133/484] Iter:[270/495], Time: 0.37, lr: [0.007478382975186232], Loss: 2.097645, Acc:0.798749, Semantic loss: 0.781954, BCE loss: 0.552567, SB loss: 0.763124
2023-10-30 06:29:28,933 Epoch: [133/484] Iter:[280/495], Time: 0.37, lr: [0.0074779949905154006], Loss: 2.096545, Acc:0.799772, Semantic loss: 0.779839, BCE loss: 0.553302, SB loss: 0.763404
2023-10-30 06:29:32,631 Epoch: [133/484] Iter:[290/495], Time: 0.37, lr: [0.007477607003607889], Loss: 2.101046, Acc:0.799983, Semantic loss: 0.780958, BCE loss: 0.554752, SB loss: 0.765336
2023-10-30 06:29:36,266 Epoch: [133/484] Iter:[300/495], Time: 0.37, lr: [0.007477219014463555], Loss: 2.097455, Acc:0.800505, Semantic loss: 0.779175, BCE loss: 0.554573, SB loss: 0.763707
2023-10-30 06:29:39,847 Epoch: [133/484] Iter:[310/495], Time: 0.37, lr: [0.0074768310230822555], Loss: 2.092523, Acc:0.801447, Semantic loss: 0.777776, BCE loss: 0.552805, SB loss: 0.761941
2023-10-30 06:29:43,641 Epoch: [133/484] Iter:[320/495], Time: 0.37, lr: [0.00747644302946385], Loss: 2.092291, Acc:0.800914, Semantic loss: 0.778087, BCE loss: 0.551844, SB loss: 0.762360
2023-10-30 06:29:47,233 Epoch: [133/484] Iter:[330/495], Time: 0.37, lr: [0.007476055033608197], Loss: 2.091476, Acc:0.800211, Semantic loss: 0.779521, BCE loss: 0.549948, SB loss: 0.762007
2023-10-30 06:29:50,824 Epoch: [133/484] Iter:[340/495], Time: 0.37, lr: [0.0074756670355151525], Loss: 2.090630, Acc:0.799659, Semantic loss: 0.779802, BCE loss: 0.548806, SB loss: 0.762022
2023-10-30 06:29:54,430 Epoch: [133/484] Iter:[350/495], Time: 0.37, lr: [0.007475279035184578], Loss: 2.092317, Acc:0.798784, Semantic loss: 0.781215, BCE loss: 0.549125, SB loss: 0.761977
2023-10-30 06:29:58,155 Epoch: [133/484] Iter:[360/495], Time: 0.37, lr: [0.00747489103261633], Loss: 2.094470, Acc:0.798255, Semantic loss: 0.782837, BCE loss: 0.548909, SB loss: 0.762724
2023-10-30 06:30:01,770 Epoch: [133/484] Iter:[370/495], Time: 0.37, lr: [0.007474503027810266], Loss: 2.092817, Acc:0.799452, Semantic loss: 0.780851, BCE loss: 0.549992, SB loss: 0.761975
2023-10-30 06:30:05,334 Epoch: [133/484] Iter:[380/495], Time: 0.37, lr: [0.007474115020766244], Loss: 2.092141, Acc:0.799136, Semantic loss: 0.781138, BCE loss: 0.549441, SB loss: 0.761562
2023-10-30 06:30:08,965 Epoch: [133/484] Iter:[390/495], Time: 0.37, lr: [0.007473727011484121], Loss: 2.087068, Acc:0.798584, Semantic loss: 0.779433, BCE loss: 0.547883, SB loss: 0.759753
2023-10-30 06:30:12,555 Epoch: [133/484] Iter:[400/495], Time: 0.37, lr: [0.007473338999963757], Loss: 2.086622, Acc:0.797756, Semantic loss: 0.779669, BCE loss: 0.547304, SB loss: 0.759650
2023-10-30 06:30:16,217 Epoch: [133/484] Iter:[410/495], Time: 0.37, lr: [0.007472950986205009], Loss: 2.083555, Acc:0.797625, Semantic loss: 0.777751, BCE loss: 0.546767, SB loss: 0.759037
2023-10-30 06:30:19,913 Epoch: [133/484] Iter:[420/495], Time: 0.37, lr: [0.007472562970207736], Loss: 2.085799, Acc:0.797005, Semantic loss: 0.779142, BCE loss: 0.546668, SB loss: 0.759988
2023-10-30 06:30:23,639 Epoch: [133/484] Iter:[430/495], Time: 0.37, lr: [0.007472174951971794], Loss: 2.088839, Acc:0.796544, Semantic loss: 0.781852, BCE loss: 0.546522, SB loss: 0.760465
2023-10-30 06:30:27,372 Epoch: [133/484] Iter:[440/495], Time: 0.37, lr: [0.007471786931497043], Loss: 2.093806, Acc:0.796239, Semantic loss: 0.786081, BCE loss: 0.544995, SB loss: 0.762731
2023-10-30 06:30:31,071 Epoch: [133/484] Iter:[450/495], Time: 0.37, lr: [0.00747139890878334], Loss: 2.096241, Acc:0.795951, Semantic loss: 0.787322, BCE loss: 0.545682, SB loss: 0.763237
2023-10-30 06:30:34,730 Epoch: [133/484] Iter:[460/495], Time: 0.37, lr: [0.007471010883830544], Loss: 2.101853, Acc:0.795566, Semantic loss: 0.790222, BCE loss: 0.546839, SB loss: 0.764793
2023-10-30 06:30:38,340 Epoch: [133/484] Iter:[470/495], Time: 0.37, lr: [0.007470622856638509], Loss: 2.101194, Acc:0.795610, Semantic loss: 0.789391, BCE loss: 0.547153, SB loss: 0.764650
2023-10-30 06:30:41,953 Epoch: [133/484] Iter:[480/495], Time: 0.37, lr: [0.007470234827207096], Loss: 2.100892, Acc:0.795862, Semantic loss: 0.789438, BCE loss: 0.546404, SB loss: 0.765050
2023-10-30 06:30:45,451 Epoch: [133/484] Iter:[490/495], Time: 0.37, lr: [0.007469846795536163], Loss: 2.101457, Acc:0.795884, Semantic loss: 0.790792, BCE loss: 0.546353, SB loss: 0.764312
2023-10-30 06:30:46,852 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:30:47,092 Loss: 2.121, MeanIU:  0.6488, Best_mIoU:  0.6907
2023-10-30 06:30:47,092 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913]
2023-10-30 06:30:49,118 Epoch: [134/484] Iter:[0/495], Time: 1.99, lr: [0.00746965277886083], Loss: 2.239462, Acc:0.813026, Semantic loss: 0.830587, BCE loss: 0.540258, SB loss: 0.868617
2023-10-30 06:30:52,974 Epoch: [134/484] Iter:[10/495], Time: 0.53, lr: [0.0074692647438303495], Loss: 2.028092, Acc:0.795199, Semantic loss: 0.698145, BCE loss: 0.543382, SB loss: 0.786565
2023-10-30 06:30:56,730 Epoch: [134/484] Iter:[20/495], Time: 0.46, lr: [0.007468876706559994], Loss: 2.000146, Acc:0.771339, Semantic loss: 0.721271, BCE loss: 0.518995, SB loss: 0.759880
2023-10-30 06:31:00,346 Epoch: [134/484] Iter:[30/495], Time: 0.43, lr: [0.0074684886670496175], Loss: 2.080504, Acc:0.773067, Semantic loss: 0.767929, BCE loss: 0.536313, SB loss: 0.776263
2023-10-30 06:31:03,958 Epoch: [134/484] Iter:[40/495], Time: 0.41, lr: [0.0074681006252990826], Loss: 2.073783, Acc:0.777906, Semantic loss: 0.770539, BCE loss: 0.522023, SB loss: 0.781221
2023-10-30 06:31:07,589 Epoch: [134/484] Iter:[50/495], Time: 0.40, lr: [0.007467712581308243], Loss: 2.092553, Acc:0.774940, Semantic loss: 0.776954, BCE loss: 0.535279, SB loss: 0.780320
2023-10-30 06:31:11,270 Epoch: [134/484] Iter:[60/495], Time: 0.40, lr: [0.0074673245350769584], Loss: 2.090567, Acc:0.775182, Semantic loss: 0.778602, BCE loss: 0.535243, SB loss: 0.776722
2023-10-30 06:31:15,072 Epoch: [134/484] Iter:[70/495], Time: 0.39, lr: [0.007466936486605087], Loss: 2.103311, Acc:0.777056, Semantic loss: 0.782358, BCE loss: 0.542407, SB loss: 0.778546
2023-10-30 06:31:18,700 Epoch: [134/484] Iter:[80/495], Time: 0.39, lr: [0.007466548435892484], Loss: 2.128824, Acc:0.778467, Semantic loss: 0.799527, BCE loss: 0.548476, SB loss: 0.780821
2023-10-30 06:31:22,355 Epoch: [134/484] Iter:[90/495], Time: 0.39, lr: [0.0074661603829390116], Loss: 2.123014, Acc:0.779043, Semantic loss: 0.796345, BCE loss: 0.549388, SB loss: 0.777281
2023-10-30 06:31:26,116 Epoch: [134/484] Iter:[100/495], Time: 0.39, lr: [0.007465772327744523], Loss: 2.140082, Acc:0.782372, Semantic loss: 0.801370, BCE loss: 0.557098, SB loss: 0.781614
2023-10-30 06:31:29,744 Epoch: [134/484] Iter:[110/495], Time: 0.38, lr: [0.007465384270308878], Loss: 2.140712, Acc:0.786367, Semantic loss: 0.798694, BCE loss: 0.562791, SB loss: 0.779227
2023-10-30 06:31:33,359 Epoch: [134/484] Iter:[120/495], Time: 0.38, lr: [0.0074649962106319336], Loss: 2.129862, Acc:0.789581, Semantic loss: 0.792287, BCE loss: 0.560841, SB loss: 0.776733
2023-10-30 06:31:36,980 Epoch: [134/484] Iter:[130/495], Time: 0.38, lr: [0.007464608148713548], Loss: 2.134811, Acc:0.788452, Semantic loss: 0.798052, BCE loss: 0.556451, SB loss: 0.780307
2023-10-30 06:31:40,623 Epoch: [134/484] Iter:[140/495], Time: 0.38, lr: [0.0074642200845535765], Loss: 2.133748, Acc:0.789736, Semantic loss: 0.796404, BCE loss: 0.557974, SB loss: 0.779370
2023-10-30 06:31:44,336 Epoch: [134/484] Iter:[150/495], Time: 0.38, lr: [0.00746383201815188], Loss: 2.138024, Acc:0.788990, Semantic loss: 0.797767, BCE loss: 0.558644, SB loss: 0.781612
2023-10-30 06:31:47,989 Epoch: [134/484] Iter:[160/495], Time: 0.38, lr: [0.007463443949508314], Loss: 2.139536, Acc:0.789023, Semantic loss: 0.797487, BCE loss: 0.559719, SB loss: 0.782330
2023-10-30 06:31:51,609 Epoch: [134/484] Iter:[170/495], Time: 0.38, lr: [0.007463055878622737], Loss: 2.134276, Acc:0.788203, Semantic loss: 0.793642, BCE loss: 0.562359, SB loss: 0.778275
2023-10-30 06:31:55,243 Epoch: [134/484] Iter:[180/495], Time: 0.38, lr: [0.007462667805495006], Loss: 2.129943, Acc:0.789393, Semantic loss: 0.789523, BCE loss: 0.564177, SB loss: 0.776243
2023-10-30 06:31:58,859 Epoch: [134/484] Iter:[190/495], Time: 0.38, lr: [0.0074622797301249775], Loss: 2.126422, Acc:0.790073, Semantic loss: 0.788168, BCE loss: 0.562461, SB loss: 0.775793
2023-10-30 06:32:02,540 Epoch: [134/484] Iter:[200/495], Time: 0.38, lr: [0.007461891652512513], Loss: 2.129977, Acc:0.791565, Semantic loss: 0.790648, BCE loss: 0.563112, SB loss: 0.776217
2023-10-30 06:32:06,203 Epoch: [134/484] Iter:[210/495], Time: 0.37, lr: [0.007461503572657464], Loss: 2.129519, Acc:0.791034, Semantic loss: 0.791376, BCE loss: 0.560830, SB loss: 0.777312
2023-10-30 06:32:09,784 Epoch: [134/484] Iter:[220/495], Time: 0.37, lr: [0.007461115490559691], Loss: 2.128346, Acc:0.792609, Semantic loss: 0.791378, BCE loss: 0.559858, SB loss: 0.777110
2023-10-30 06:32:13,385 Epoch: [134/484] Iter:[230/495], Time: 0.37, lr: [0.007460727406219052], Loss: 2.118514, Acc:0.793447, Semantic loss: 0.786781, BCE loss: 0.557062, SB loss: 0.774671
2023-10-30 06:32:17,068 Epoch: [134/484] Iter:[240/495], Time: 0.37, lr: [0.007460339319635403], Loss: 2.121612, Acc:0.794437, Semantic loss: 0.788537, BCE loss: 0.558020, SB loss: 0.775055
2023-10-30 06:32:20,695 Epoch: [134/484] Iter:[250/495], Time: 0.37, lr: [0.007459951230808603], Loss: 2.117335, Acc:0.791663, Semantic loss: 0.789470, BCE loss: 0.553827, SB loss: 0.774039
2023-10-30 06:32:24,342 Epoch: [134/484] Iter:[260/495], Time: 0.37, lr: [0.007459563139738509], Loss: 2.120276, Acc:0.792319, Semantic loss: 0.791255, BCE loss: 0.554552, SB loss: 0.774469
2023-10-30 06:32:27,943 Epoch: [134/484] Iter:[270/495], Time: 0.37, lr: [0.007459175046424978], Loss: 2.115174, Acc:0.793330, Semantic loss: 0.787996, BCE loss: 0.554295, SB loss: 0.772883
2023-10-30 06:32:31,669 Epoch: [134/484] Iter:[280/495], Time: 0.37, lr: [0.0074587869508678665], Loss: 2.113887, Acc:0.795001, Semantic loss: 0.786923, BCE loss: 0.554491, SB loss: 0.772472
2023-10-30 06:32:35,339 Epoch: [134/484] Iter:[290/495], Time: 0.37, lr: [0.007458398853067032], Loss: 2.114077, Acc:0.796058, Semantic loss: 0.786169, BCE loss: 0.556700, SB loss: 0.771208
2023-10-30 06:32:38,951 Epoch: [134/484] Iter:[300/495], Time: 0.37, lr: [0.007458010753022333], Loss: 2.114331, Acc:0.795686, Semantic loss: 0.786401, BCE loss: 0.556859, SB loss: 0.771070
2023-10-30 06:32:42,635 Epoch: [134/484] Iter:[310/495], Time: 0.37, lr: [0.0074576226507336255], Loss: 2.115770, Acc:0.794511, Semantic loss: 0.790462, BCE loss: 0.554474, SB loss: 0.770834
2023-10-30 06:32:46,358 Epoch: [134/484] Iter:[320/495], Time: 0.37, lr: [0.007457234546200767], Loss: 2.113592, Acc:0.793199, Semantic loss: 0.789783, BCE loss: 0.554389, SB loss: 0.769421
2023-10-30 06:32:49,973 Epoch: [134/484] Iter:[330/495], Time: 0.37, lr: [0.007456846439423616], Loss: 2.111369, Acc:0.793644, Semantic loss: 0.788999, BCE loss: 0.553215, SB loss: 0.769155
2023-10-30 06:32:53,740 Epoch: [134/484] Iter:[340/495], Time: 0.37, lr: [0.0074564583304020295], Loss: 2.112388, Acc:0.794089, Semantic loss: 0.790117, BCE loss: 0.553459, SB loss: 0.768813
2023-10-30 06:32:57,383 Epoch: [134/484] Iter:[350/495], Time: 0.37, lr: [0.0074560702191358635], Loss: 2.112066, Acc:0.794580, Semantic loss: 0.789250, BCE loss: 0.555092, SB loss: 0.767723
2023-10-30 06:33:01,099 Epoch: [134/484] Iter:[360/495], Time: 0.37, lr: [0.007455682105624976], Loss: 2.109702, Acc:0.794627, Semantic loss: 0.788690, BCE loss: 0.553572, SB loss: 0.767440
2023-10-30 06:33:04,760 Epoch: [134/484] Iter:[370/495], Time: 0.37, lr: [0.007455293989869223], Loss: 2.106265, Acc:0.795765, Semantic loss: 0.787092, BCE loss: 0.553349, SB loss: 0.765823
2023-10-30 06:33:08,481 Epoch: [134/484] Iter:[380/495], Time: 0.37, lr: [0.007454905871868462], Loss: 2.104598, Acc:0.795771, Semantic loss: 0.785772, BCE loss: 0.553328, SB loss: 0.765499
2023-10-30 06:33:12,159 Epoch: [134/484] Iter:[390/495], Time: 0.37, lr: [0.007454517751622552], Loss: 2.105088, Acc:0.796349, Semantic loss: 0.786895, BCE loss: 0.551740, SB loss: 0.766454
2023-10-30 06:33:15,878 Epoch: [134/484] Iter:[400/495], Time: 0.37, lr: [0.007454129629131349], Loss: 2.104419, Acc:0.796555, Semantic loss: 0.785924, BCE loss: 0.552550, SB loss: 0.765945
2023-10-30 06:33:19,513 Epoch: [134/484] Iter:[410/495], Time: 0.37, lr: [0.00745374150439471], Loss: 2.103917, Acc:0.795910, Semantic loss: 0.786288, BCE loss: 0.551481, SB loss: 0.766147
2023-10-30 06:33:23,284 Epoch: [134/484] Iter:[420/495], Time: 0.37, lr: [0.007453353377412492], Loss: 2.105644, Acc:0.795216, Semantic loss: 0.786654, BCE loss: 0.552514, SB loss: 0.766476
2023-10-30 06:33:26,914 Epoch: [134/484] Iter:[430/495], Time: 0.37, lr: [0.007452965248184551], Loss: 2.109201, Acc:0.795956, Semantic loss: 0.788013, BCE loss: 0.554937, SB loss: 0.766251
2023-10-30 06:33:30,580 Epoch: [134/484] Iter:[440/495], Time: 0.37, lr: [0.007452577116710747], Loss: 2.110205, Acc:0.795797, Semantic loss: 0.788348, BCE loss: 0.555923, SB loss: 0.765935
2023-10-30 06:33:34,283 Epoch: [134/484] Iter:[450/495], Time: 0.37, lr: [0.007452188982990935], Loss: 2.108159, Acc:0.795561, Semantic loss: 0.787724, BCE loss: 0.554683, SB loss: 0.765752
2023-10-30 06:33:37,904 Epoch: [134/484] Iter:[460/495], Time: 0.37, lr: [0.007451800847024971], Loss: 2.105366, Acc:0.795341, Semantic loss: 0.786790, BCE loss: 0.553104, SB loss: 0.765471
2023-10-30 06:33:41,453 Epoch: [134/484] Iter:[470/495], Time: 0.37, lr: [0.0074514127088127135], Loss: 2.107711, Acc:0.795416, Semantic loss: 0.788622, BCE loss: 0.553283, SB loss: 0.765806
2023-10-30 06:33:45,198 Epoch: [134/484] Iter:[480/495], Time: 0.37, lr: [0.007451024568354019], Loss: 2.111031, Acc:0.794336, Semantic loss: 0.791215, BCE loss: 0.553032, SB loss: 0.766783
2023-10-30 06:33:48,675 Epoch: [134/484] Iter:[490/495], Time: 0.37, lr: [0.0074506364256487455], Loss: 2.110719, Acc:0.793804, Semantic loss: 0.791487, BCE loss: 0.552506, SB loss: 0.766726
2023-10-30 06:33:50,092 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:33:50,332 Loss: 2.121, MeanIU:  0.6488, Best_mIoU:  0.6907
2023-10-30 06:33:50,332 [0.97180835 0.79978215 0.90575501 0.51315562 0.46870515 0.56412675
 0.62793566 0.70182695 0.91073333 0.59881947 0.92944782 0.74549973
 0.48506802 0.89911151 0.50228397 0.37243502 0.07767097 0.52996984
 0.72324913]
2023-10-30 06:33:52,369 Epoch: [135/484] Iter:[0/495], Time: 2.00, lr: [0.007450442353453598], Loss: 1.858493, Acc:0.855827, Semantic loss: 0.616539, BCE loss: 0.487403, SB loss: 0.754551
2023-10-30 06:33:56,320 Epoch: [135/484] Iter:[10/495], Time: 0.54, lr: [0.007450054207378186], Loss: 1.980140, Acc:0.804988, Semantic loss: 0.722947, BCE loss: 0.529159, SB loss: 0.728034
2023-10-30 06:34:00,057 Epoch: [135/484] Iter:[20/495], Time: 0.46, lr: [0.007449666059055838], Loss: 2.083964, Acc:0.800606, Semantic loss: 0.821931, BCE loss: 0.539798, SB loss: 0.722235
2023-10-30 06:34:03,857 Epoch: [135/484] Iter:[30/495], Time: 0.44, lr: [0.007449277908486409], Loss: 2.080092, Acc:0.808798, Semantic loss: 0.792064, BCE loss: 0.549862, SB loss: 0.738165
2023-10-30 06:34:07,485 Epoch: [135/484] Iter:[40/495], Time: 0.42, lr: [0.007448889755669755], Loss: 2.069191, Acc:0.812796, Semantic loss: 0.775165, BCE loss: 0.556187, SB loss: 0.737838
2023-10-30 06:34:11,081 Epoch: [135/484] Iter:[50/495], Time: 0.41, lr: [0.007448501600605736], Loss: 2.068393, Acc:0.812944, Semantic loss: 0.770186, BCE loss: 0.560906, SB loss: 0.737301
2023-10-30 06:34:14,822 Epoch: [135/484] Iter:[60/495], Time: 0.40, lr: [0.007448113443294206], Loss: 2.093991, Acc:0.808086, Semantic loss: 0.790948, BCE loss: 0.554673, SB loss: 0.748370
2023-10-30 06:34:18,456 Epoch: [135/484] Iter:[70/495], Time: 0.40, lr: [0.007447725283735024], Loss: 2.086273, Acc:0.803051, Semantic loss: 0.789921, BCE loss: 0.551996, SB loss: 0.744355
2023-10-30 06:34:22,130 Epoch: [135/484] Iter:[80/495], Time: 0.39, lr: [0.007447337121928046], Loss: 2.077653, Acc:0.802596, Semantic loss: 0.786095, BCE loss: 0.546283, SB loss: 0.745276
2023-10-30 06:34:25,804 Epoch: [135/484] Iter:[90/495], Time: 0.39, lr: [0.007446948957873129], Loss: 2.089894, Acc:0.797931, Semantic loss: 0.792267, BCE loss: 0.547575, SB loss: 0.750053
2023-10-30 06:34:29,423 Epoch: [135/484] Iter:[100/495], Time: 0.39, lr: [0.0074465607915701285], Loss: 2.091567, Acc:0.799051, Semantic loss: 0.791246, BCE loss: 0.548852, SB loss: 0.751468
2023-10-30 06:34:32,996 Epoch: [135/484] Iter:[110/495], Time: 0.38, lr: [0.007446172623018902], Loss: 2.101326, Acc:0.798641, Semantic loss: 0.802124, BCE loss: 0.546132, SB loss: 0.753070
2023-10-30 06:34:36,616 Epoch: [135/484] Iter:[120/495], Time: 0.38, lr: [0.007445784452219307], Loss: 2.083370, Acc:0.798407, Semantic loss: 0.791296, BCE loss: 0.542973, SB loss: 0.749101
2023-10-30 06:34:40,157 Epoch: [135/484] Iter:[130/495], Time: 0.38, lr: [0.007445396279171199], Loss: 2.072144, Acc:0.798529, Semantic loss: 0.783439, BCE loss: 0.540422, SB loss: 0.748283
2023-10-30 06:34:43,827 Epoch: [135/484] Iter:[140/495], Time: 0.38, lr: [0.0074450081038744354], Loss: 2.087454, Acc:0.797702, Semantic loss: 0.793104, BCE loss: 0.542068, SB loss: 0.752282
2023-10-30 06:34:47,465 Epoch: [135/484] Iter:[150/495], Time: 0.38, lr: [0.0074446199263288725], Loss: 2.093472, Acc:0.797392, Semantic loss: 0.796724, BCE loss: 0.543094, SB loss: 0.753655
2023-10-30 06:34:51,214 Epoch: [135/484] Iter:[160/495], Time: 0.38, lr: [0.007444231746534369], Loss: 2.090510, Acc:0.797412, Semantic loss: 0.791946, BCE loss: 0.546782, SB loss: 0.751782
2023-10-30 06:34:54,845 Epoch: [135/484] Iter:[170/495], Time: 0.38, lr: [0.00744384356449078], Loss: 2.081088, Acc:0.797737, Semantic loss: 0.787960, BCE loss: 0.541519, SB loss: 0.751610
2023-10-30 06:34:58,510 Epoch: [135/484] Iter:[180/495], Time: 0.38, lr: [0.007443455380197961], Loss: 2.081754, Acc:0.797983, Semantic loss: 0.788099, BCE loss: 0.541042, SB loss: 0.752614
2023-10-30 06:35:02,202 Epoch: [135/484] Iter:[190/495], Time: 0.38, lr: [0.0074430671936557705], Loss: 2.080000, Acc:0.799021, Semantic loss: 0.789148, BCE loss: 0.539731, SB loss: 0.751122
2023-10-30 06:35:05,784 Epoch: [135/484] Iter:[200/495], Time: 0.38, lr: [0.007442679004864062], Loss: 2.090048, Acc:0.798920, Semantic loss: 0.797545, BCE loss: 0.540359, SB loss: 0.752144
2023-10-30 06:35:09,457 Epoch: [135/484] Iter:[210/495], Time: 0.37, lr: [0.0074422908138226974], Loss: 2.091081, Acc:0.798831, Semantic loss: 0.796933, BCE loss: 0.540809, SB loss: 0.753339
2023-10-30 06:35:13,127 Epoch: [135/484] Iter:[220/495], Time: 0.37, lr: [0.007441902620531529], Loss: 2.091814, Acc:0.800013, Semantic loss: 0.796471, BCE loss: 0.542119, SB loss: 0.753224
2023-10-30 06:35:16,772 Epoch: [135/484] Iter:[230/495], Time: 0.37, lr: [0.007441514424990414], Loss: 2.088222, Acc:0.799823, Semantic loss: 0.793556, BCE loss: 0.542776, SB loss: 0.751890
2023-10-30 06:35:20,310 Epoch: [135/484] Iter:[240/495], Time: 0.37, lr: [0.007441126227199212], Loss: 2.086191, Acc:0.798498, Semantic loss: 0.793087, BCE loss: 0.541550, SB loss: 0.751554
2023-10-30 06:35:24,049 Epoch: [135/484] Iter:[250/495], Time: 0.37, lr: [0.007440738027157775], Loss: 2.078938, Acc:0.797259, Semantic loss: 0.789343, BCE loss: 0.539262, SB loss: 0.750333
2023-10-30 06:35:27,892 Epoch: [135/484] Iter:[260/495], Time: 0.37, lr: [0.007440349824865963], Loss: 2.077795, Acc:0.796948, Semantic loss: 0.790333, BCE loss: 0.535819, SB loss: 0.751642
2023-10-30 06:35:31,556 Epoch: [135/484] Iter:[270/495], Time: 0.37, lr: [0.007439961620323631], Loss: 2.078282, Acc:0.797750, Semantic loss: 0.790121, BCE loss: 0.536413, SB loss: 0.751748
2023-10-30 06:35:35,180 Epoch: [135/484] Iter:[280/495], Time: 0.37, lr: [0.007439573413530635], Loss: 2.082593, Acc:0.798994, Semantic loss: 0.789682, BCE loss: 0.540019, SB loss: 0.752892
2023-10-30 06:35:38,791 Epoch: [135/484] Iter:[290/495], Time: 0.37, lr: [0.007439185204486832], Loss: 2.080468, Acc:0.799027, Semantic loss: 0.788100, BCE loss: 0.540317, SB loss: 0.752050
2023-10-30 06:35:42,587 Epoch: [135/484] Iter:[300/495], Time: 0.37, lr: [0.007438796993192078], Loss: 2.076459, Acc:0.797792, Semantic loss: 0.786096, BCE loss: 0.538331, SB loss: 0.752032
2023-10-30 06:35:46,189 Epoch: [135/484] Iter:[310/495], Time: 0.37, lr: [0.007438408779646232], Loss: 2.082836, Acc:0.797180, Semantic loss: 0.789384, BCE loss: 0.539007, SB loss: 0.754445
2023-10-30 06:35:49,885 Epoch: [135/484] Iter:[320/495], Time: 0.37, lr: [0.007438020563849147], Loss: 2.080712, Acc:0.796931, Semantic loss: 0.788730, BCE loss: 0.537512, SB loss: 0.754469
2023-10-30 06:35:53,678 Epoch: [135/484] Iter:[330/495], Time: 0.37, lr: [0.007437632345800681], Loss: 2.079413, Acc:0.797556, Semantic loss: 0.787558, BCE loss: 0.538210, SB loss: 0.753646
2023-10-30 06:35:57,217 Epoch: [135/484] Iter:[340/495], Time: 0.37, lr: [0.0074372441255006905], Loss: 2.081448, Acc:0.798089, Semantic loss: 0.789193, BCE loss: 0.538148, SB loss: 0.754106
2023-10-30 06:36:00,887 Epoch: [135/484] Iter:[350/495], Time: 0.37, lr: [0.0074368559029490315], Loss: 2.084971, Acc:0.797954, Semantic loss: 0.791415, BCE loss: 0.538508, SB loss: 0.755048
2023-10-30 06:36:04,676 Epoch: [135/484] Iter:[360/495], Time: 0.37, lr: [0.00743646767814556], Loss: 2.087717, Acc:0.798366, Semantic loss: 0.791463, BCE loss: 0.539362, SB loss: 0.756893
2023-10-30 06:36:08,293 Epoch: [135/484] Iter:[370/495], Time: 0.37, lr: [0.0074360794510901305], Loss: 2.088532, Acc:0.799029, Semantic loss: 0.790168, BCE loss: 0.541430, SB loss: 0.756934
2023-10-30 06:36:11,980 Epoch: [135/484] Iter:[380/495], Time: 0.37, lr: [0.007435691221782605], Loss: 2.089596, Acc:0.799018, Semantic loss: 0.790072, BCE loss: 0.542590, SB loss: 0.756934
2023-10-30 06:36:15,621 Epoch: [135/484] Iter:[390/495], Time: 0.37, lr: [0.007435302990222834], Loss: 2.091832, Acc:0.798645, Semantic loss: 0.793531, BCE loss: 0.541355, SB loss: 0.756946
2023-10-30 06:36:19,346 Epoch: [135/484] Iter:[400/495], Time: 0.37, lr: [0.007434914756410678], Loss: 2.093421, Acc:0.798614, Semantic loss: 0.792632, BCE loss: 0.544027, SB loss: 0.756762
2023-10-30 06:36:23,070 Epoch: [135/484] Iter:[410/495], Time: 0.37, lr: [0.00743452652034599], Loss: 2.089882, Acc:0.798996, Semantic loss: 0.791614, BCE loss: 0.542388, SB loss: 0.755880
2023-10-30 06:36:26,719 Epoch: [135/484] Iter:[420/495], Time: 0.37, lr: [0.007434138282028628], Loss: 2.094697, Acc:0.798112, Semantic loss: 0.794064, BCE loss: 0.542702, SB loss: 0.757932
2023-10-30 06:36:30,432 Epoch: [135/484] Iter:[430/495], Time: 0.37, lr: [0.0074337500414584454], Loss: 2.100025, Acc:0.798401, Semantic loss: 0.797418, BCE loss: 0.543803, SB loss: 0.758804
2023-10-30 06:36:34,090 Epoch: [135/484] Iter:[440/495], Time: 0.37, lr: [0.007433361798635303], Loss: 2.099179, Acc:0.798237, Semantic loss: 0.796697, BCE loss: 0.543801, SB loss: 0.758681
2023-10-30 06:36:37,763 Epoch: [135/484] Iter:[450/495], Time: 0.37, lr: [0.0074329735535590535], Loss: 2.097347, Acc:0.797887, Semantic loss: 0.794537, BCE loss: 0.544475, SB loss: 0.758335
2023-10-30 06:36:41,526 Epoch: [135/484] Iter:[460/495], Time: 0.37, lr: [0.007432585306229556], Loss: 2.093685, Acc:0.797480, Semantic loss: 0.792441, BCE loss: 0.543201, SB loss: 0.758044
2023-10-30 06:36:45,086 Epoch: [135/484] Iter:[470/495], Time: 0.37, lr: [0.007432197056646664], Loss: 2.090936, Acc:0.796988, Semantic loss: 0.791613, BCE loss: 0.541499, SB loss: 0.757825
2023-10-30 06:36:48,781 Epoch: [135/484] Iter:[480/495], Time: 0.37, lr: [0.007431808804810234], Loss: 2.089742, Acc:0.797357, Semantic loss: 0.791022, BCE loss: 0.541351, SB loss: 0.757369
2023-10-30 06:36:52,313 Epoch: [135/484] Iter:[490/495], Time: 0.37, lr: [0.0074314205507201225], Loss: 2.094198, Acc:0.796645, Semantic loss: 0.793037, BCE loss: 0.542769, SB loss: 0.758391
2023-10-30 06:39:48,892 0 [9.30836954e-01 6.04638454e-01 8.05791646e-01 1.81431723e-01
 2.47374932e-01 3.86527563e-01 3.50758544e-01 5.71233683e-01
 8.77084472e-01 4.06608349e-01 8.19241549e-01 5.67369987e-01
 5.02676983e-04 7.90199277e-01 1.54625885e-04 3.83300637e-02
 1.23869812e-02 5.88793404e-03 5.15265982e-01] 0.42692765243603636
2023-10-30 06:39:48,892 1 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094] 0.639029613101076
2023-10-30 06:39:48,896 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:39:49,134 Loss: 2.110, MeanIU:  0.6390, Best_mIoU:  0.6907
2023-10-30 06:39:49,134 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094]
2023-10-30 06:39:51,415 Epoch: [136/484] Iter:[0/495], Time: 2.25, lr: [0.007431226422829892], Loss: 1.770726, Acc:0.863037, Semantic loss: 0.531657, BCE loss: 0.609209, SB loss: 0.629860
2023-10-30 06:39:55,126 Epoch: [136/484] Iter:[10/495], Time: 0.54, lr: [0.007430838165358988], Loss: 2.083341, Acc:0.791811, Semantic loss: 0.787694, BCE loss: 0.538634, SB loss: 0.757013
2023-10-30 06:39:58,677 Epoch: [136/484] Iter:[20/495], Time: 0.45, lr: [0.007430449905634044], Loss: 2.046676, Acc:0.793659, Semantic loss: 0.773037, BCE loss: 0.522899, SB loss: 0.750740
2023-10-30 06:40:02,081 Epoch: [136/484] Iter:[30/495], Time: 0.42, lr: [0.007430061643654915], Loss: 2.025266, Acc:0.787200, Semantic loss: 0.779101, BCE loss: 0.507793, SB loss: 0.738372
2023-10-30 06:40:05,528 Epoch: [136/484] Iter:[40/495], Time: 0.40, lr: [0.0074296733794214555], Loss: 2.014751, Acc:0.788802, Semantic loss: 0.772222, BCE loss: 0.510087, SB loss: 0.732442
2023-10-30 06:40:08,953 Epoch: [136/484] Iter:[50/495], Time: 0.39, lr: [0.0074292851129335235], Loss: 2.030543, Acc:0.785443, Semantic loss: 0.786079, BCE loss: 0.509886, SB loss: 0.734578
2023-10-30 06:40:12,438 Epoch: [136/484] Iter:[60/495], Time: 0.38, lr: [0.007428896844190976], Loss: 2.031975, Acc:0.782348, Semantic loss: 0.789523, BCE loss: 0.504895, SB loss: 0.737557
2023-10-30 06:40:15,931 Epoch: [136/484] Iter:[70/495], Time: 0.38, lr: [0.007428508573193666], Loss: 2.030011, Acc:0.783167, Semantic loss: 0.783302, BCE loss: 0.510429, SB loss: 0.736281
2023-10-30 06:40:19,620 Epoch: [136/484] Iter:[80/495], Time: 0.38, lr: [0.00742812029994145], Loss: 2.041162, Acc:0.781010, Semantic loss: 0.787656, BCE loss: 0.516254, SB loss: 0.737252
2023-10-30 06:40:23,384 Epoch: [136/484] Iter:[90/495], Time: 0.38, lr: [0.007427732024434186], Loss: 2.051322, Acc:0.782875, Semantic loss: 0.789241, BCE loss: 0.521416, SB loss: 0.740665
2023-10-30 06:40:27,113 Epoch: [136/484] Iter:[100/495], Time: 0.38, lr: [0.007427343746671727], Loss: 2.065232, Acc:0.791148, Semantic loss: 0.787104, BCE loss: 0.532057, SB loss: 0.746071
2023-10-30 06:40:30,625 Epoch: [136/484] Iter:[110/495], Time: 0.37, lr: [0.007426955466653933], Loss: 2.063681, Acc:0.794243, Semantic loss: 0.783290, BCE loss: 0.535592, SB loss: 0.744799
2023-10-30 06:40:34,138 Epoch: [136/484] Iter:[120/495], Time: 0.37, lr: [0.007426567184380655], Loss: 2.072558, Acc:0.796331, Semantic loss: 0.787173, BCE loss: 0.538110, SB loss: 0.747275
2023-10-30 06:40:37,726 Epoch: [136/484] Iter:[130/495], Time: 0.37, lr: [0.007426178899851753], Loss: 2.085375, Acc:0.792742, Semantic loss: 0.792676, BCE loss: 0.541058, SB loss: 0.751641
2023-10-30 06:40:41,423 Epoch: [136/484] Iter:[140/495], Time: 0.37, lr: [0.007425790613067081], Loss: 2.081937, Acc:0.796343, Semantic loss: 0.791085, BCE loss: 0.539843, SB loss: 0.751009
2023-10-30 06:40:45,005 Epoch: [136/484] Iter:[150/495], Time: 0.37, lr: [0.007425402324026496], Loss: 2.086421, Acc:0.796018, Semantic loss: 0.797830, BCE loss: 0.537550, SB loss: 0.751041
2023-10-30 06:40:48,578 Epoch: [136/484] Iter:[160/495], Time: 0.37, lr: [0.007425014032729851], Loss: 2.070073, Acc:0.795627, Semantic loss: 0.788541, BCE loss: 0.531574, SB loss: 0.749958
2023-10-30 06:40:52,190 Epoch: [136/484] Iter:[170/495], Time: 0.37, lr: [0.007424625739177004], Loss: 2.073578, Acc:0.798501, Semantic loss: 0.787402, BCE loss: 0.534332, SB loss: 0.751844
2023-10-30 06:40:55,799 Epoch: [136/484] Iter:[180/495], Time: 0.37, lr: [0.0074242374433678105], Loss: 2.075787, Acc:0.797575, Semantic loss: 0.789614, BCE loss: 0.533890, SB loss: 0.752283
2023-10-30 06:40:59,412 Epoch: [136/484] Iter:[190/495], Time: 0.37, lr: [0.007423849145302126], Loss: 2.070333, Acc:0.797636, Semantic loss: 0.785236, BCE loss: 0.533405, SB loss: 0.751692
2023-10-30 06:41:02,961 Epoch: [136/484] Iter:[200/495], Time: 0.37, lr: [0.007423460844979807], Loss: 2.067650, Acc:0.797545, Semantic loss: 0.784999, BCE loss: 0.530771, SB loss: 0.751880
2023-10-30 06:41:06,565 Epoch: [136/484] Iter:[210/495], Time: 0.37, lr: [0.007423072542400709], Loss: 2.059661, Acc:0.798057, Semantic loss: 0.779559, BCE loss: 0.532296, SB loss: 0.747806
2023-10-30 06:41:10,173 Epoch: [136/484] Iter:[220/495], Time: 0.37, lr: [0.007422684237564686], Loss: 2.054464, Acc:0.797739, Semantic loss: 0.774745, BCE loss: 0.531944, SB loss: 0.747776
2023-10-30 06:41:13,851 Epoch: [136/484] Iter:[230/495], Time: 0.37, lr: [0.007422295930471598], Loss: 2.057864, Acc:0.798243, Semantic loss: 0.776999, BCE loss: 0.531766, SB loss: 0.749099
2023-10-30 06:41:17,452 Epoch: [136/484] Iter:[240/495], Time: 0.37, lr: [0.007421907621121295], Loss: 2.057532, Acc:0.798981, Semantic loss: 0.775826, BCE loss: 0.533477, SB loss: 0.748228
2023-10-30 06:41:21,046 Epoch: [136/484] Iter:[250/495], Time: 0.37, lr: [0.007421519309513636], Loss: 2.062945, Acc:0.797031, Semantic loss: 0.776840, BCE loss: 0.537092, SB loss: 0.749014
2023-10-30 06:41:24,692 Epoch: [136/484] Iter:[260/495], Time: 0.37, lr: [0.007421130995648477], Loss: 2.064539, Acc:0.797065, Semantic loss: 0.776658, BCE loss: 0.537207, SB loss: 0.750674
2023-10-30 06:41:28,442 Epoch: [136/484] Iter:[270/495], Time: 0.37, lr: [0.00742074267952567], Loss: 2.064083, Acc:0.797114, Semantic loss: 0.776805, BCE loss: 0.536992, SB loss: 0.750286
2023-10-30 06:41:32,083 Epoch: [136/484] Iter:[280/495], Time: 0.37, lr: [0.007420354361145075], Loss: 2.065372, Acc:0.796508, Semantic loss: 0.776857, BCE loss: 0.538094, SB loss: 0.750421
2023-10-30 06:41:35,764 Epoch: [136/484] Iter:[290/495], Time: 0.37, lr: [0.007419966040506547], Loss: 2.066221, Acc:0.797371, Semantic loss: 0.776858, BCE loss: 0.538431, SB loss: 0.750932
2023-10-30 06:41:39,516 Epoch: [136/484] Iter:[300/495], Time: 0.37, lr: [0.00741957771760994], Loss: 2.065538, Acc:0.797493, Semantic loss: 0.775894, BCE loss: 0.539348, SB loss: 0.750296
2023-10-30 06:41:43,137 Epoch: [136/484] Iter:[310/495], Time: 0.37, lr: [0.00741918939245511], Loss: 2.066420, Acc:0.797254, Semantic loss: 0.775143, BCE loss: 0.540580, SB loss: 0.750697
2023-10-30 06:41:46,773 Epoch: [136/484] Iter:[320/495], Time: 0.37, lr: [0.007418801065041912], Loss: 2.064926, Acc:0.797121, Semantic loss: 0.773143, BCE loss: 0.542278, SB loss: 0.749505
2023-10-30 06:41:50,391 Epoch: [136/484] Iter:[330/495], Time: 0.37, lr: [0.0074184127353702015], Loss: 2.064067, Acc:0.796644, Semantic loss: 0.773818, BCE loss: 0.540569, SB loss: 0.749680
2023-10-30 06:41:53,991 Epoch: [136/484] Iter:[340/495], Time: 0.37, lr: [0.007418024403439836], Loss: 2.065559, Acc:0.796416, Semantic loss: 0.774919, BCE loss: 0.541041, SB loss: 0.749598
2023-10-30 06:41:57,584 Epoch: [136/484] Iter:[350/495], Time: 0.37, lr: [0.007417636069250667], Loss: 2.068644, Acc:0.796371, Semantic loss: 0.776330, BCE loss: 0.542446, SB loss: 0.749868
2023-10-30 06:42:01,317 Epoch: [136/484] Iter:[360/495], Time: 0.37, lr: [0.007417247732802555], Loss: 2.066807, Acc:0.795706, Semantic loss: 0.776184, BCE loss: 0.540974, SB loss: 0.749649
2023-10-30 06:42:04,898 Epoch: [136/484] Iter:[370/495], Time: 0.37, lr: [0.007416859394095352], Loss: 2.068738, Acc:0.794415, Semantic loss: 0.776983, BCE loss: 0.542073, SB loss: 0.749682
2023-10-30 06:42:08,539 Epoch: [136/484] Iter:[380/495], Time: 0.37, lr: [0.007416471053128916], Loss: 2.066011, Acc:0.793946, Semantic loss: 0.775317, BCE loss: 0.541564, SB loss: 0.749130
2023-10-30 06:42:12,205 Epoch: [136/484] Iter:[390/495], Time: 0.37, lr: [0.007416082709903099], Loss: 2.068640, Acc:0.793645, Semantic loss: 0.776424, BCE loss: 0.543248, SB loss: 0.748969
2023-10-30 06:42:15,835 Epoch: [136/484] Iter:[400/495], Time: 0.37, lr: [0.007415694364417759], Loss: 2.068870, Acc:0.793646, Semantic loss: 0.777402, BCE loss: 0.543032, SB loss: 0.748435
2023-10-30 06:42:19,492 Epoch: [136/484] Iter:[410/495], Time: 0.37, lr: [0.007415306016672749], Loss: 2.066399, Acc:0.793561, Semantic loss: 0.775439, BCE loss: 0.543235, SB loss: 0.747726
2023-10-30 06:42:23,268 Epoch: [136/484] Iter:[420/495], Time: 0.37, lr: [0.0074149176666679275], Loss: 2.072224, Acc:0.794479, Semantic loss: 0.778700, BCE loss: 0.545211, SB loss: 0.748313
2023-10-30 06:42:27,001 Epoch: [136/484] Iter:[430/495], Time: 0.37, lr: [0.007414529314403148], Loss: 2.072248, Acc:0.794986, Semantic loss: 0.778658, BCE loss: 0.545050, SB loss: 0.748539
2023-10-30 06:42:30,692 Epoch: [136/484] Iter:[440/495], Time: 0.37, lr: [0.007414140959878266], Loss: 2.070006, Acc:0.794787, Semantic loss: 0.777056, BCE loss: 0.544551, SB loss: 0.748400
2023-10-30 06:42:34,275 Epoch: [136/484] Iter:[450/495], Time: 0.37, lr: [0.007413752603093137], Loss: 2.071063, Acc:0.794236, Semantic loss: 0.777949, BCE loss: 0.544282, SB loss: 0.748832
2023-10-30 06:42:37,918 Epoch: [136/484] Iter:[460/495], Time: 0.37, lr: [0.007413364244047617], Loss: 2.075436, Acc:0.793822, Semantic loss: 0.780550, BCE loss: 0.545021, SB loss: 0.749866
2023-10-30 06:42:41,508 Epoch: [136/484] Iter:[470/495], Time: 0.37, lr: [0.007412975882741559], Loss: 2.075088, Acc:0.793005, Semantic loss: 0.780091, BCE loss: 0.544758, SB loss: 0.750240
2023-10-30 06:42:45,253 Epoch: [136/484] Iter:[480/495], Time: 0.37, lr: [0.00741258751917482], Loss: 2.080452, Acc:0.792082, Semantic loss: 0.783860, BCE loss: 0.545120, SB loss: 0.751472
2023-10-30 06:42:48,684 Epoch: [136/484] Iter:[490/495], Time: 0.37, lr: [0.007412199153347255], Loss: 2.080359, Acc:0.792264, Semantic loss: 0.784388, BCE loss: 0.544361, SB loss: 0.751610
2023-10-30 06:42:50,058 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:42:50,302 Loss: 2.110, MeanIU:  0.6390, Best_mIoU:  0.6907
2023-10-30 06:42:50,302 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094]
2023-10-30 06:42:52,465 Epoch: [137/484] Iter:[0/495], Time: 2.13, lr: [0.007412004969585618], Loss: 2.074967, Acc:0.865305, Semantic loss: 0.783851, BCE loss: 0.460015, SB loss: 0.831102
2023-10-30 06:42:56,330 Epoch: [137/484] Iter:[10/495], Time: 0.54, lr: [0.007411616600366543], Loss: 2.078562, Acc:0.775776, Semantic loss: 0.755042, BCE loss: 0.588709, SB loss: 0.734810
2023-10-30 06:43:00,068 Epoch: [137/484] Iter:[20/495], Time: 0.46, lr: [0.007411228228886279], Loss: 2.050328, Acc:0.789146, Semantic loss: 0.742972, BCE loss: 0.577277, SB loss: 0.730079
2023-10-30 06:43:03,909 Epoch: [137/484] Iter:[30/495], Time: 0.44, lr: [0.007410839855144683], Loss: 2.031863, Acc:0.794415, Semantic loss: 0.732640, BCE loss: 0.555078, SB loss: 0.744144
2023-10-30 06:43:07,481 Epoch: [137/484] Iter:[40/495], Time: 0.42, lr: [0.00741045147914161], Loss: 2.073607, Acc:0.804325, Semantic loss: 0.770198, BCE loss: 0.550921, SB loss: 0.752489
2023-10-30 06:43:11,182 Epoch: [137/484] Iter:[50/495], Time: 0.41, lr: [0.007410063100876913], Loss: 2.047823, Acc:0.803479, Semantic loss: 0.762084, BCE loss: 0.538747, SB loss: 0.746992
2023-10-30 06:43:14,813 Epoch: [137/484] Iter:[60/495], Time: 0.40, lr: [0.00740967472035045], Loss: 2.027687, Acc:0.804350, Semantic loss: 0.752278, BCE loss: 0.533446, SB loss: 0.741963
2023-10-30 06:43:18,460 Epoch: [137/484] Iter:[70/495], Time: 0.40, lr: [0.007409286337562073], Loss: 2.045144, Acc:0.797451, Semantic loss: 0.764044, BCE loss: 0.538573, SB loss: 0.742527
2023-10-30 06:43:22,054 Epoch: [137/484] Iter:[80/495], Time: 0.39, lr: [0.007408897952511639], Loss: 2.048375, Acc:0.801123, Semantic loss: 0.763814, BCE loss: 0.539765, SB loss: 0.744796
2023-10-30 06:43:25,685 Epoch: [137/484] Iter:[90/495], Time: 0.39, lr: [0.007408509565199003], Loss: 2.083181, Acc:0.799883, Semantic loss: 0.788599, BCE loss: 0.543776, SB loss: 0.750806
2023-10-30 06:43:29,288 Epoch: [137/484] Iter:[100/495], Time: 0.39, lr: [0.007408121175624021], Loss: 2.083712, Acc:0.799175, Semantic loss: 0.788534, BCE loss: 0.543860, SB loss: 0.751319
2023-10-30 06:43:33,097 Epoch: [137/484] Iter:[110/495], Time: 0.39, lr: [0.007407732783786546], Loss: 2.125042, Acc:0.797169, Semantic loss: 0.815036, BCE loss: 0.543524, SB loss: 0.766482
2023-10-30 06:43:36,736 Epoch: [137/484] Iter:[120/495], Time: 0.38, lr: [0.007407344389686435], Loss: 2.139184, Acc:0.796179, Semantic loss: 0.820648, BCE loss: 0.547389, SB loss: 0.771147
2023-10-30 06:43:40,348 Epoch: [137/484] Iter:[130/495], Time: 0.38, lr: [0.007406955993323541], Loss: 2.134900, Acc:0.795510, Semantic loss: 0.817887, BCE loss: 0.547414, SB loss: 0.769599
2023-10-30 06:43:44,004 Epoch: [137/484] Iter:[140/495], Time: 0.38, lr: [0.007406567594697721], Loss: 2.138195, Acc:0.795951, Semantic loss: 0.819843, BCE loss: 0.547765, SB loss: 0.770586
2023-10-30 06:43:47,610 Epoch: [137/484] Iter:[150/495], Time: 0.38, lr: [0.007406179193808826], Loss: 2.127635, Acc:0.794712, Semantic loss: 0.814007, BCE loss: 0.544417, SB loss: 0.769212
2023-10-30 06:43:51,205 Epoch: [137/484] Iter:[160/495], Time: 0.38, lr: [0.007405790790656716], Loss: 2.127293, Acc:0.793276, Semantic loss: 0.812262, BCE loss: 0.547278, SB loss: 0.767753
2023-10-30 06:43:54,835 Epoch: [137/484] Iter:[170/495], Time: 0.38, lr: [0.007405402385241242], Loss: 2.127125, Acc:0.791649, Semantic loss: 0.811976, BCE loss: 0.545362, SB loss: 0.769787
2023-10-30 06:43:58,552 Epoch: [137/484] Iter:[180/495], Time: 0.38, lr: [0.007405013977562262], Loss: 2.129038, Acc:0.791713, Semantic loss: 0.813559, BCE loss: 0.544235, SB loss: 0.771244
2023-10-30 06:44:02,160 Epoch: [137/484] Iter:[190/495], Time: 0.38, lr: [0.007404625567619631], Loss: 2.119494, Acc:0.791309, Semantic loss: 0.807867, BCE loss: 0.542478, SB loss: 0.769149
2023-10-30 06:44:05,832 Epoch: [137/484] Iter:[200/495], Time: 0.38, lr: [0.007404237155413201], Loss: 2.130915, Acc:0.791696, Semantic loss: 0.819192, BCE loss: 0.540830, SB loss: 0.770893
2023-10-30 06:44:09,501 Epoch: [137/484] Iter:[210/495], Time: 0.38, lr: [0.007403848740942828], Loss: 2.129556, Acc:0.791973, Semantic loss: 0.815727, BCE loss: 0.542026, SB loss: 0.771804
2023-10-30 06:44:13,250 Epoch: [137/484] Iter:[220/495], Time: 0.38, lr: [0.0074034603242083665], Loss: 2.143525, Acc:0.792327, Semantic loss: 0.823964, BCE loss: 0.545347, SB loss: 0.774214
2023-10-30 06:44:17,006 Epoch: [137/484] Iter:[230/495], Time: 0.38, lr: [0.007403071905209672], Loss: 2.138415, Acc:0.792301, Semantic loss: 0.819032, BCE loss: 0.546299, SB loss: 0.773084
2023-10-30 06:44:20,817 Epoch: [137/484] Iter:[240/495], Time: 0.38, lr: [0.007402683483946601], Loss: 2.135593, Acc:0.793202, Semantic loss: 0.818363, BCE loss: 0.543544, SB loss: 0.773687
2023-10-30 06:44:24,564 Epoch: [137/484] Iter:[250/495], Time: 0.38, lr: [0.007402295060419003], Loss: 2.138124, Acc:0.793787, Semantic loss: 0.819090, BCE loss: 0.544236, SB loss: 0.774798
2023-10-30 06:44:28,186 Epoch: [137/484] Iter:[260/495], Time: 0.37, lr: [0.00740190663462674], Loss: 2.140231, Acc:0.793674, Semantic loss: 0.817077, BCE loss: 0.547665, SB loss: 0.775489
2023-10-30 06:44:31,800 Epoch: [137/484] Iter:[270/495], Time: 0.37, lr: [0.007401518206569661], Loss: 2.138484, Acc:0.794131, Semantic loss: 0.815143, BCE loss: 0.548347, SB loss: 0.774994
2023-10-30 06:44:35,568 Epoch: [137/484] Iter:[280/495], Time: 0.37, lr: [0.007401129776247624], Loss: 2.140048, Acc:0.793015, Semantic loss: 0.816971, BCE loss: 0.547897, SB loss: 0.775181
2023-10-30 06:44:39,250 Epoch: [137/484] Iter:[290/495], Time: 0.37, lr: [0.007400741343660481], Loss: 2.140207, Acc:0.794029, Semantic loss: 0.816290, BCE loss: 0.547647, SB loss: 0.776270
2023-10-30 06:44:42,988 Epoch: [137/484] Iter:[300/495], Time: 0.37, lr: [0.007400352908808089], Loss: 2.139165, Acc:0.794587, Semantic loss: 0.814174, BCE loss: 0.550178, SB loss: 0.774814
2023-10-30 06:44:46,619 Epoch: [137/484] Iter:[310/495], Time: 0.37, lr: [0.007399964471690302], Loss: 2.136374, Acc:0.795037, Semantic loss: 0.813359, BCE loss: 0.549506, SB loss: 0.773508
2023-10-30 06:44:50,225 Epoch: [137/484] Iter:[320/495], Time: 0.37, lr: [0.007399576032306974], Loss: 2.132433, Acc:0.794635, Semantic loss: 0.810906, BCE loss: 0.548942, SB loss: 0.772585
2023-10-30 06:44:53,997 Epoch: [137/484] Iter:[330/495], Time: 0.37, lr: [0.007399187590657959], Loss: 2.131949, Acc:0.794500, Semantic loss: 0.811032, BCE loss: 0.547979, SB loss: 0.772938
2023-10-30 06:44:57,832 Epoch: [137/484] Iter:[340/495], Time: 0.37, lr: [0.0073987991467431135], Loss: 2.133200, Acc:0.793380, Semantic loss: 0.812626, BCE loss: 0.546701, SB loss: 0.773873
2023-10-30 06:45:01,507 Epoch: [137/484] Iter:[350/495], Time: 0.37, lr: [0.0073984107005622924], Loss: 2.140563, Acc:0.793090, Semantic loss: 0.817228, BCE loss: 0.547940, SB loss: 0.775395
2023-10-30 06:45:05,354 Epoch: [137/484] Iter:[360/495], Time: 0.37, lr: [0.007398022252115349], Loss: 2.139158, Acc:0.792619, Semantic loss: 0.815447, BCE loss: 0.548410, SB loss: 0.775301
2023-10-30 06:45:08,916 Epoch: [137/484] Iter:[370/495], Time: 0.37, lr: [0.007397633801402138], Loss: 2.136253, Acc:0.792121, Semantic loss: 0.813519, BCE loss: 0.548531, SB loss: 0.774203
2023-10-30 06:45:12,533 Epoch: [137/484] Iter:[380/495], Time: 0.37, lr: [0.007397245348422514], Loss: 2.138396, Acc:0.791087, Semantic loss: 0.815933, BCE loss: 0.547617, SB loss: 0.774845
2023-10-30 06:45:16,148 Epoch: [137/484] Iter:[390/495], Time: 0.37, lr: [0.00739685689317633], Loss: 2.136649, Acc:0.791577, Semantic loss: 0.813511, BCE loss: 0.548435, SB loss: 0.774703
2023-10-30 06:45:19,840 Epoch: [137/484] Iter:[400/495], Time: 0.37, lr: [0.007396468435663445], Loss: 2.140368, Acc:0.791063, Semantic loss: 0.815637, BCE loss: 0.549421, SB loss: 0.775310
2023-10-30 06:45:23,473 Epoch: [137/484] Iter:[410/495], Time: 0.37, lr: [0.007396079975883707], Loss: 2.138478, Acc:0.791258, Semantic loss: 0.813538, BCE loss: 0.550173, SB loss: 0.774768
2023-10-30 06:45:27,139 Epoch: [137/484] Iter:[420/495], Time: 0.37, lr: [0.0073956915138369776], Loss: 2.137590, Acc:0.791262, Semantic loss: 0.812576, BCE loss: 0.550060, SB loss: 0.774954
2023-10-30 06:45:30,839 Epoch: [137/484] Iter:[430/495], Time: 0.37, lr: [0.007395303049523106], Loss: 2.138321, Acc:0.791721, Semantic loss: 0.813352, BCE loss: 0.550902, SB loss: 0.774067
2023-10-30 06:45:34,525 Epoch: [137/484] Iter:[440/495], Time: 0.37, lr: [0.007394914582941948], Loss: 2.138043, Acc:0.791665, Semantic loss: 0.812556, BCE loss: 0.550769, SB loss: 0.774719
2023-10-30 06:45:38,234 Epoch: [137/484] Iter:[450/495], Time: 0.37, lr: [0.007394526114093361], Loss: 2.139557, Acc:0.792241, Semantic loss: 0.813413, BCE loss: 0.550795, SB loss: 0.775349
2023-10-30 06:45:41,905 Epoch: [137/484] Iter:[460/495], Time: 0.37, lr: [0.007394137642977194], Loss: 2.143095, Acc:0.791354, Semantic loss: 0.816571, BCE loss: 0.550049, SB loss: 0.776475
2023-10-30 06:45:45,671 Epoch: [137/484] Iter:[470/495], Time: 0.37, lr: [0.0073937491695933045], Loss: 2.142415, Acc:0.790861, Semantic loss: 0.815967, BCE loss: 0.549534, SB loss: 0.776914
2023-10-30 06:45:49,341 Epoch: [137/484] Iter:[480/495], Time: 0.37, lr: [0.007393360693941547], Loss: 2.146645, Acc:0.790778, Semantic loss: 0.819329, BCE loss: 0.549993, SB loss: 0.777323
2023-10-30 06:45:52,881 Epoch: [137/484] Iter:[490/495], Time: 0.37, lr: [0.007392972216021776], Loss: 2.149076, Acc:0.790379, Semantic loss: 0.820865, BCE loss: 0.549953, SB loss: 0.778258
2023-10-30 06:45:54,279 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:45:54,511 Loss: 2.110, MeanIU:  0.6390, Best_mIoU:  0.6907
2023-10-30 06:45:54,512 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094]
2023-10-30 06:45:56,714 Epoch: [138/484] Iter:[0/495], Time: 2.17, lr: [0.00739277797621134], Loss: 1.947232, Acc:0.648187, Semantic loss: 0.634793, BCE loss: 0.637799, SB loss: 0.674641
2023-10-30 06:46:00,564 Epoch: [138/484] Iter:[10/495], Time: 0.55, lr: [0.007392389494889275], Loss: 2.035706, Acc:0.797780, Semantic loss: 0.728607, BCE loss: 0.575648, SB loss: 0.731451
2023-10-30 06:46:04,220 Epoch: [138/484] Iter:[20/495], Time: 0.46, lr: [0.007392001011298831], Loss: 2.095811, Acc:0.778200, Semantic loss: 0.779293, BCE loss: 0.545660, SB loss: 0.770858
2023-10-30 06:46:07,870 Epoch: [138/484] Iter:[30/495], Time: 0.43, lr: [0.007391612525439864], Loss: 2.083345, Acc:0.784871, Semantic loss: 0.764978, BCE loss: 0.562687, SB loss: 0.755680
2023-10-30 06:46:11,541 Epoch: [138/484] Iter:[40/495], Time: 0.41, lr: [0.007391224037312226], Loss: 2.020193, Acc:0.799989, Semantic loss: 0.735127, BCE loss: 0.545466, SB loss: 0.739600
2023-10-30 06:46:15,241 Epoch: [138/484] Iter:[50/495], Time: 0.41, lr: [0.007390835546915773], Loss: 2.044557, Acc:0.800588, Semantic loss: 0.752602, BCE loss: 0.539867, SB loss: 0.752088
2023-10-30 06:46:19,182 Epoch: [138/484] Iter:[60/495], Time: 0.40, lr: [0.007390447054250359], Loss: 2.065247, Acc:0.803610, Semantic loss: 0.764507, BCE loss: 0.542980, SB loss: 0.757759
2023-10-30 06:46:22,947 Epoch: [138/484] Iter:[70/495], Time: 0.40, lr: [0.007390058559315837], Loss: 2.071281, Acc:0.797231, Semantic loss: 0.771331, BCE loss: 0.541949, SB loss: 0.758001
2023-10-30 06:46:26,647 Epoch: [138/484] Iter:[80/495], Time: 0.40, lr: [0.007389670062112064], Loss: 2.060159, Acc:0.800167, Semantic loss: 0.761602, BCE loss: 0.547481, SB loss: 0.751076
2023-10-30 06:46:30,396 Epoch: [138/484] Iter:[90/495], Time: 0.39, lr: [0.007389281562638892], Loss: 2.057748, Acc:0.799050, Semantic loss: 0.763419, BCE loss: 0.543478, SB loss: 0.750851
2023-10-30 06:46:34,060 Epoch: [138/484] Iter:[100/495], Time: 0.39, lr: [0.007388893060896176], Loss: 2.076727, Acc:0.797807, Semantic loss: 0.773464, BCE loss: 0.547094, SB loss: 0.756169
2023-10-30 06:46:37,715 Epoch: [138/484] Iter:[110/495], Time: 0.39, lr: [0.00738850455688377], Loss: 2.080366, Acc:0.795356, Semantic loss: 0.777342, BCE loss: 0.546644, SB loss: 0.756380
2023-10-30 06:46:41,440 Epoch: [138/484] Iter:[120/495], Time: 0.39, lr: [0.007388116050601527], Loss: 2.091167, Acc:0.792721, Semantic loss: 0.783635, BCE loss: 0.545722, SB loss: 0.761809
2023-10-30 06:46:45,143 Epoch: [138/484] Iter:[130/495], Time: 0.39, lr: [0.0073877275420493015], Loss: 2.084172, Acc:0.794710, Semantic loss: 0.779476, BCE loss: 0.544980, SB loss: 0.759715
2023-10-30 06:46:48,816 Epoch: [138/484] Iter:[140/495], Time: 0.38, lr: [0.0073873390312269496], Loss: 2.087561, Acc:0.795101, Semantic loss: 0.781560, BCE loss: 0.544300, SB loss: 0.761701
2023-10-30 06:46:52,518 Epoch: [138/484] Iter:[150/495], Time: 0.38, lr: [0.0073869505181343225], Loss: 2.073951, Acc:0.793631, Semantic loss: 0.775359, BCE loss: 0.540931, SB loss: 0.757661
2023-10-30 06:46:56,216 Epoch: [138/484] Iter:[160/495], Time: 0.38, lr: [0.0073865620027712756], Loss: 2.070240, Acc:0.793306, Semantic loss: 0.775337, BCE loss: 0.538186, SB loss: 0.756717
2023-10-30 06:46:59,821 Epoch: [138/484] Iter:[170/495], Time: 0.38, lr: [0.007386173485137664], Loss: 2.077279, Acc:0.793188, Semantic loss: 0.777257, BCE loss: 0.540118, SB loss: 0.759905
2023-10-30 06:47:03,505 Epoch: [138/484] Iter:[180/495], Time: 0.38, lr: [0.007385784965233341], Loss: 2.077352, Acc:0.793094, Semantic loss: 0.775996, BCE loss: 0.541150, SB loss: 0.760206
2023-10-30 06:47:07,128 Epoch: [138/484] Iter:[190/495], Time: 0.38, lr: [0.0073853964430581585], Loss: 2.081726, Acc:0.793067, Semantic loss: 0.776672, BCE loss: 0.544089, SB loss: 0.760965
2023-10-30 06:47:10,800 Epoch: [138/484] Iter:[200/495], Time: 0.38, lr: [0.0073850079186119745], Loss: 2.088073, Acc:0.794298, Semantic loss: 0.778430, BCE loss: 0.547450, SB loss: 0.762194
2023-10-30 06:47:14,466 Epoch: [138/484] Iter:[210/495], Time: 0.38, lr: [0.007384619391894639], Loss: 2.083135, Acc:0.793868, Semantic loss: 0.775765, BCE loss: 0.546970, SB loss: 0.760400
2023-10-30 06:47:18,205 Epoch: [138/484] Iter:[220/495], Time: 0.38, lr: [0.007384230862906008], Loss: 2.084054, Acc:0.792551, Semantic loss: 0.777096, BCE loss: 0.547768, SB loss: 0.759190
2023-10-30 06:47:21,822 Epoch: [138/484] Iter:[230/495], Time: 0.38, lr: [0.007383842331645935], Loss: 2.077009, Acc:0.792320, Semantic loss: 0.774950, BCE loss: 0.545138, SB loss: 0.756921
2023-10-30 06:47:25,440 Epoch: [138/484] Iter:[240/495], Time: 0.38, lr: [0.007383453798114276], Loss: 2.076037, Acc:0.793082, Semantic loss: 0.776513, BCE loss: 0.542652, SB loss: 0.756872
2023-10-30 06:47:29,080 Epoch: [138/484] Iter:[250/495], Time: 0.38, lr: [0.007383065262310882], Loss: 2.078674, Acc:0.793206, Semantic loss: 0.778789, BCE loss: 0.543062, SB loss: 0.756823
2023-10-30 06:47:32,780 Epoch: [138/484] Iter:[260/495], Time: 0.38, lr: [0.007382676724235608], Loss: 2.078896, Acc:0.791600, Semantic loss: 0.778894, BCE loss: 0.541559, SB loss: 0.758443
2023-10-30 06:47:36,500 Epoch: [138/484] Iter:[270/495], Time: 0.38, lr: [0.007382288183888307], Loss: 2.080187, Acc:0.791441, Semantic loss: 0.779292, BCE loss: 0.542666, SB loss: 0.758229
2023-10-30 06:47:40,056 Epoch: [138/484] Iter:[280/495], Time: 0.38, lr: [0.007381899641268834], Loss: 2.082148, Acc:0.791996, Semantic loss: 0.780291, BCE loss: 0.543715, SB loss: 0.758143
2023-10-30 06:47:43,748 Epoch: [138/484] Iter:[290/495], Time: 0.38, lr: [0.007381511096377041], Loss: 2.078895, Acc:0.791622, Semantic loss: 0.778834, BCE loss: 0.543686, SB loss: 0.756375
2023-10-30 06:47:47,320 Epoch: [138/484] Iter:[300/495], Time: 0.37, lr: [0.007381122549212785], Loss: 2.080796, Acc:0.791298, Semantic loss: 0.781406, BCE loss: 0.542568, SB loss: 0.756822
2023-10-30 06:47:51,152 Epoch: [138/484] Iter:[310/495], Time: 0.37, lr: [0.007380733999775917], Loss: 2.079022, Acc:0.790822, Semantic loss: 0.780482, BCE loss: 0.541022, SB loss: 0.757518
2023-10-30 06:47:54,956 Epoch: [138/484] Iter:[320/495], Time: 0.38, lr: [0.007380345448066292], Loss: 2.083931, Acc:0.791172, Semantic loss: 0.781683, BCE loss: 0.544921, SB loss: 0.757326
2023-10-30 06:47:58,654 Epoch: [138/484] Iter:[330/495], Time: 0.37, lr: [0.0073799568940837645], Loss: 2.084975, Acc:0.790785, Semantic loss: 0.782735, BCE loss: 0.544340, SB loss: 0.757900
2023-10-30 06:48:02,398 Epoch: [138/484] Iter:[340/495], Time: 0.37, lr: [0.007379568337828188], Loss: 2.083639, Acc:0.791226, Semantic loss: 0.781729, BCE loss: 0.544117, SB loss: 0.757793
2023-10-30 06:48:06,076 Epoch: [138/484] Iter:[350/495], Time: 0.37, lr: [0.007379179779299413], Loss: 2.080157, Acc:0.792103, Semantic loss: 0.779767, BCE loss: 0.542808, SB loss: 0.757583
2023-10-30 06:48:09,808 Epoch: [138/484] Iter:[360/495], Time: 0.37, lr: [0.0073787912184972975], Loss: 2.083568, Acc:0.792573, Semantic loss: 0.781906, BCE loss: 0.542943, SB loss: 0.758719
2023-10-30 06:48:13,437 Epoch: [138/484] Iter:[370/495], Time: 0.37, lr: [0.007378402655421692], Loss: 2.082488, Acc:0.792354, Semantic loss: 0.781023, BCE loss: 0.542675, SB loss: 0.758790
2023-10-30 06:48:17,139 Epoch: [138/484] Iter:[380/495], Time: 0.37, lr: [0.0073780140900724525], Loss: 2.080984, Acc:0.792792, Semantic loss: 0.780370, BCE loss: 0.542134, SB loss: 0.758480
2023-10-30 06:48:20,868 Epoch: [138/484] Iter:[390/495], Time: 0.37, lr: [0.007377625522449431], Loss: 2.080806, Acc:0.792902, Semantic loss: 0.781401, BCE loss: 0.540443, SB loss: 0.758963
2023-10-30 06:48:24,551 Epoch: [138/484] Iter:[400/495], Time: 0.37, lr: [0.007377236952552482], Loss: 2.084152, Acc:0.792950, Semantic loss: 0.783144, BCE loss: 0.540763, SB loss: 0.760245
2023-10-30 06:48:28,249 Epoch: [138/484] Iter:[410/495], Time: 0.37, lr: [0.00737684838038146], Loss: 2.081578, Acc:0.793308, Semantic loss: 0.782292, BCE loss: 0.539288, SB loss: 0.759999
2023-10-30 06:48:31,874 Epoch: [138/484] Iter:[420/495], Time: 0.37, lr: [0.007376459805936216], Loss: 2.084916, Acc:0.792990, Semantic loss: 0.783881, BCE loss: 0.540096, SB loss: 0.760939
2023-10-30 06:48:35,495 Epoch: [138/484] Iter:[430/495], Time: 0.37, lr: [0.007376071229216606], Loss: 2.084640, Acc:0.792879, Semantic loss: 0.782918, BCE loss: 0.540285, SB loss: 0.761437
2023-10-30 06:48:39,198 Epoch: [138/484] Iter:[440/495], Time: 0.37, lr: [0.007375682650222484], Loss: 2.080541, Acc:0.793185, Semantic loss: 0.780953, BCE loss: 0.539259, SB loss: 0.760328
2023-10-30 06:48:42,833 Epoch: [138/484] Iter:[450/495], Time: 0.37, lr: [0.0073752940689537], Loss: 2.079105, Acc:0.793776, Semantic loss: 0.780032, BCE loss: 0.539921, SB loss: 0.759152
2023-10-30 06:48:46,503 Epoch: [138/484] Iter:[460/495], Time: 0.37, lr: [0.007374905485410111], Loss: 2.079159, Acc:0.794158, Semantic loss: 0.779070, BCE loss: 0.540392, SB loss: 0.759697
2023-10-30 06:48:50,221 Epoch: [138/484] Iter:[470/495], Time: 0.37, lr: [0.007374516899591568], Loss: 2.079189, Acc:0.794731, Semantic loss: 0.779018, BCE loss: 0.540345, SB loss: 0.759826
2023-10-30 06:48:53,906 Epoch: [138/484] Iter:[480/495], Time: 0.37, lr: [0.007374128311497926], Loss: 2.078267, Acc:0.795216, Semantic loss: 0.778370, BCE loss: 0.540666, SB loss: 0.759232
2023-10-30 06:48:57,415 Epoch: [138/484] Iter:[490/495], Time: 0.37, lr: [0.007373739721129039], Loss: 2.079586, Acc:0.795485, Semantic loss: 0.779920, BCE loss: 0.540269, SB loss: 0.759397
2023-10-30 06:48:58,812 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:48:59,051 Loss: 2.110, MeanIU:  0.6390, Best_mIoU:  0.6907
2023-10-30 06:48:59,051 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094]
2023-10-30 06:49:01,107 Epoch: [139/484] Iter:[0/495], Time: 2.02, lr: [0.007373545425091332], Loss: 2.147324, Acc:0.714457, Semantic loss: 0.802393, BCE loss: 0.539126, SB loss: 0.805804
2023-10-30 06:49:05,041 Epoch: [139/484] Iter:[10/495], Time: 0.54, lr: [0.007373156831309302], Loss: 2.157970, Acc:0.784920, Semantic loss: 0.777575, BCE loss: 0.613306, SB loss: 0.767090
2023-10-30 06:49:08,691 Epoch: [139/484] Iter:[20/495], Time: 0.46, lr: [0.007372768235251659], Loss: 2.112131, Acc:0.793269, Semantic loss: 0.788118, BCE loss: 0.571360, SB loss: 0.752653
2023-10-30 06:49:12,300 Epoch: [139/484] Iter:[30/495], Time: 0.43, lr: [0.007372379636918257], Loss: 2.039020, Acc:0.790037, Semantic loss: 0.758972, BCE loss: 0.539047, SB loss: 0.741001
2023-10-30 06:49:15,859 Epoch: [139/484] Iter:[40/495], Time: 0.41, lr: [0.007371991036308949], Loss: 2.029527, Acc:0.782747, Semantic loss: 0.762711, BCE loss: 0.524152, SB loss: 0.742664
2023-10-30 06:49:19,479 Epoch: [139/484] Iter:[50/495], Time: 0.40, lr: [0.00737160243342359], Loss: 2.051847, Acc:0.781918, Semantic loss: 0.771971, BCE loss: 0.529394, SB loss: 0.750483
2023-10-30 06:49:23,186 Epoch: [139/484] Iter:[60/495], Time: 0.40, lr: [0.0073712138282620325], Loss: 2.075660, Acc:0.787093, Semantic loss: 0.781632, BCE loss: 0.540997, SB loss: 0.753031
2023-10-30 06:49:26,801 Epoch: [139/484] Iter:[70/495], Time: 0.39, lr: [0.007370825220824129], Loss: 2.084830, Acc:0.785776, Semantic loss: 0.782697, BCE loss: 0.542388, SB loss: 0.759746
2023-10-30 06:49:30,396 Epoch: [139/484] Iter:[80/495], Time: 0.39, lr: [0.007370436611109733], Loss: 2.097704, Acc:0.782825, Semantic loss: 0.795817, BCE loss: 0.539416, SB loss: 0.762470
2023-10-30 06:49:34,077 Epoch: [139/484] Iter:[90/495], Time: 0.38, lr: [0.0073700479991186995], Loss: 2.106193, Acc:0.786390, Semantic loss: 0.803437, BCE loss: 0.537236, SB loss: 0.765519
2023-10-30 06:49:37,730 Epoch: [139/484] Iter:[100/495], Time: 0.38, lr: [0.00736965938485088], Loss: 2.095861, Acc:0.786389, Semantic loss: 0.794063, BCE loss: 0.538785, SB loss: 0.763013
2023-10-30 06:49:41,407 Epoch: [139/484] Iter:[110/495], Time: 0.38, lr: [0.007369270768306128], Loss: 2.098173, Acc:0.788932, Semantic loss: 0.795935, BCE loss: 0.538061, SB loss: 0.764177
2023-10-30 06:49:45,010 Epoch: [139/484] Iter:[120/495], Time: 0.38, lr: [0.007368882149484296], Loss: 2.091833, Acc:0.790767, Semantic loss: 0.793151, BCE loss: 0.533679, SB loss: 0.765003
2023-10-30 06:49:48,740 Epoch: [139/484] Iter:[130/495], Time: 0.38, lr: [0.0073684935283852395], Loss: 2.082396, Acc:0.790063, Semantic loss: 0.786566, BCE loss: 0.533812, SB loss: 0.762018
2023-10-30 06:49:52,353 Epoch: [139/484] Iter:[140/495], Time: 0.38, lr: [0.00736810490500881], Loss: 2.075368, Acc:0.791266, Semantic loss: 0.781292, BCE loss: 0.532979, SB loss: 0.761098
2023-10-30 06:49:56,054 Epoch: [139/484] Iter:[150/495], Time: 0.38, lr: [0.007367716279354862], Loss: 2.075020, Acc:0.790483, Semantic loss: 0.782099, BCE loss: 0.532404, SB loss: 0.760517
2023-10-30 06:49:59,803 Epoch: [139/484] Iter:[160/495], Time: 0.38, lr: [0.007367327651423248], Loss: 2.071340, Acc:0.791199, Semantic loss: 0.780999, BCE loss: 0.532655, SB loss: 0.757687
2023-10-30 06:50:03,602 Epoch: [139/484] Iter:[170/495], Time: 0.38, lr: [0.00736693902121382], Loss: 2.076468, Acc:0.792642, Semantic loss: 0.783855, BCE loss: 0.532716, SB loss: 0.759897
2023-10-30 06:50:07,277 Epoch: [139/484] Iter:[180/495], Time: 0.38, lr: [0.0073665503887264325], Loss: 2.072184, Acc:0.793347, Semantic loss: 0.780794, BCE loss: 0.533721, SB loss: 0.757669
2023-10-30 06:50:11,029 Epoch: [139/484] Iter:[190/495], Time: 0.38, lr: [0.0073661617539609375], Loss: 2.070480, Acc:0.794500, Semantic loss: 0.780378, BCE loss: 0.533047, SB loss: 0.757056
2023-10-30 06:50:14,694 Epoch: [139/484] Iter:[200/495], Time: 0.38, lr: [0.007365773116917189], Loss: 2.079038, Acc:0.795509, Semantic loss: 0.784531, BCE loss: 0.537298, SB loss: 0.757209
2023-10-30 06:50:18,360 Epoch: [139/484] Iter:[210/495], Time: 0.38, lr: [0.00736538447759504], Loss: 2.072936, Acc:0.795796, Semantic loss: 0.782540, BCE loss: 0.534767, SB loss: 0.755628
2023-10-30 06:50:22,002 Epoch: [139/484] Iter:[220/495], Time: 0.38, lr: [0.007364995835994343], Loss: 2.070956, Acc:0.797692, Semantic loss: 0.780606, BCE loss: 0.535368, SB loss: 0.754981
2023-10-30 06:50:25,619 Epoch: [139/484] Iter:[230/495], Time: 0.37, lr: [0.007364607192114954], Loss: 2.074050, Acc:0.794900, Semantic loss: 0.783713, BCE loss: 0.533931, SB loss: 0.756406
2023-10-30 06:50:29,257 Epoch: [139/484] Iter:[240/495], Time: 0.37, lr: [0.007364218545956721], Loss: 2.075351, Acc:0.793801, Semantic loss: 0.784063, BCE loss: 0.533853, SB loss: 0.757436
2023-10-30 06:50:32,842 Epoch: [139/484] Iter:[250/495], Time: 0.37, lr: [0.0073638298975195], Loss: 2.092519, Acc:0.792922, Semantic loss: 0.797147, BCE loss: 0.535237, SB loss: 0.760136
2023-10-30 06:50:36,538 Epoch: [139/484] Iter:[260/495], Time: 0.37, lr: [0.007363441246803146], Loss: 2.089912, Acc:0.791476, Semantic loss: 0.795024, BCE loss: 0.535191, SB loss: 0.759697
2023-10-30 06:50:40,351 Epoch: [139/484] Iter:[270/495], Time: 0.37, lr: [0.007363052593807505], Loss: 2.086226, Acc:0.792717, Semantic loss: 0.791742, BCE loss: 0.536371, SB loss: 0.758113
2023-10-30 06:50:44,004 Epoch: [139/484] Iter:[280/495], Time: 0.37, lr: [0.007362663938532438], Loss: 2.093172, Acc:0.793484, Semantic loss: 0.794551, BCE loss: 0.539007, SB loss: 0.759614
2023-10-30 06:50:47,637 Epoch: [139/484] Iter:[290/495], Time: 0.37, lr: [0.007362275280977791], Loss: 2.091163, Acc:0.793857, Semantic loss: 0.794353, BCE loss: 0.536611, SB loss: 0.760198
2023-10-30 06:50:51,421 Epoch: [139/484] Iter:[300/495], Time: 0.37, lr: [0.007361886621143423], Loss: 2.091529, Acc:0.794002, Semantic loss: 0.793520, BCE loss: 0.537686, SB loss: 0.760323
2023-10-30 06:50:55,034 Epoch: [139/484] Iter:[310/495], Time: 0.37, lr: [0.007361497959029184], Loss: 2.090061, Acc:0.794857, Semantic loss: 0.792220, BCE loss: 0.538085, SB loss: 0.759756
2023-10-30 06:50:58,712 Epoch: [139/484] Iter:[320/495], Time: 0.37, lr: [0.007361109294634928], Loss: 2.090953, Acc:0.794958, Semantic loss: 0.792746, BCE loss: 0.537741, SB loss: 0.760465
2023-10-30 06:51:02,389 Epoch: [139/484] Iter:[330/495], Time: 0.37, lr: [0.007360720627960505], Loss: 2.086453, Acc:0.794658, Semantic loss: 0.790616, BCE loss: 0.536158, SB loss: 0.759678
2023-10-30 06:51:06,060 Epoch: [139/484] Iter:[340/495], Time: 0.37, lr: [0.00736033195900577], Loss: 2.089105, Acc:0.794147, Semantic loss: 0.791308, BCE loss: 0.537730, SB loss: 0.760067
2023-10-30 06:51:09,695 Epoch: [139/484] Iter:[350/495], Time: 0.37, lr: [0.007359943287770576], Loss: 2.090486, Acc:0.794127, Semantic loss: 0.792127, BCE loss: 0.538081, SB loss: 0.760278
2023-10-30 06:51:13,380 Epoch: [139/484] Iter:[360/495], Time: 0.37, lr: [0.0073595546142547754], Loss: 2.089300, Acc:0.794387, Semantic loss: 0.791439, BCE loss: 0.538154, SB loss: 0.759708
2023-10-30 06:51:17,065 Epoch: [139/484] Iter:[370/495], Time: 0.37, lr: [0.007359165938458221], Loss: 2.094075, Acc:0.794415, Semantic loss: 0.794749, BCE loss: 0.538874, SB loss: 0.760452
2023-10-30 06:51:20,820 Epoch: [139/484] Iter:[380/495], Time: 0.37, lr: [0.007358777260380766], Loss: 2.092176, Acc:0.795150, Semantic loss: 0.793119, BCE loss: 0.539384, SB loss: 0.759673
2023-10-30 06:51:24,528 Epoch: [139/484] Iter:[390/495], Time: 0.37, lr: [0.007358388580022262], Loss: 2.092586, Acc:0.795667, Semantic loss: 0.792484, BCE loss: 0.540218, SB loss: 0.759884
2023-10-30 06:51:28,109 Epoch: [139/484] Iter:[400/495], Time: 0.37, lr: [0.007357999897382564], Loss: 2.097647, Acc:0.795559, Semantic loss: 0.795700, BCE loss: 0.539965, SB loss: 0.761982
2023-10-30 06:51:31,827 Epoch: [139/484] Iter:[410/495], Time: 0.37, lr: [0.007357611212461522], Loss: 2.097046, Acc:0.795409, Semantic loss: 0.794279, BCE loss: 0.541132, SB loss: 0.761634
2023-10-30 06:51:35,693 Epoch: [139/484] Iter:[420/495], Time: 0.37, lr: [0.00735722252525899], Loss: 2.098448, Acc:0.795514, Semantic loss: 0.794184, BCE loss: 0.542099, SB loss: 0.762164
2023-10-30 06:51:39,417 Epoch: [139/484] Iter:[430/495], Time: 0.37, lr: [0.00735683383577482], Loss: 2.098221, Acc:0.795977, Semantic loss: 0.793836, BCE loss: 0.542011, SB loss: 0.762374
2023-10-30 06:51:43,096 Epoch: [139/484] Iter:[440/495], Time: 0.37, lr: [0.007356445144008865], Loss: 2.097496, Acc:0.796694, Semantic loss: 0.793610, BCE loss: 0.542274, SB loss: 0.761612
2023-10-30 06:51:46,721 Epoch: [139/484] Iter:[450/495], Time: 0.37, lr: [0.00735605644996098], Loss: 2.096437, Acc:0.796953, Semantic loss: 0.792926, BCE loss: 0.542680, SB loss: 0.760831
2023-10-30 06:51:50,344 Epoch: [139/484] Iter:[460/495], Time: 0.37, lr: [0.007355667753631013], Loss: 2.096411, Acc:0.796437, Semantic loss: 0.792799, BCE loss: 0.542969, SB loss: 0.760643
2023-10-30 06:51:53,952 Epoch: [139/484] Iter:[470/495], Time: 0.37, lr: [0.007355279055018821], Loss: 2.098406, Acc:0.796113, Semantic loss: 0.792875, BCE loss: 0.544634, SB loss: 0.760897
2023-10-30 06:51:57,591 Epoch: [139/484] Iter:[480/495], Time: 0.37, lr: [0.007354890354124254], Loss: 2.096726, Acc:0.795932, Semantic loss: 0.791697, BCE loss: 0.544582, SB loss: 0.760447
2023-10-30 06:52:01,122 Epoch: [139/484] Iter:[490/495], Time: 0.37, lr: [0.007354501650947166], Loss: 2.096289, Acc:0.795845, Semantic loss: 0.791516, BCE loss: 0.544667, SB loss: 0.760107
2023-10-30 06:52:02,527 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:52:02,767 Loss: 2.110, MeanIU:  0.6390, Best_mIoU:  0.6907
2023-10-30 06:52:02,767 [0.97183322 0.79547831 0.89762184 0.44271296 0.50019912 0.55978801
 0.57320322 0.72187375 0.90475354 0.55535963 0.92279426 0.72050065
 0.42903385 0.91255192 0.45248916 0.58395267 0.23797284 0.24124276
 0.71820094]
2023-10-30 06:52:04,996 Epoch: [140/484] Iter:[0/495], Time: 2.20, lr: [0.007354307298502631], Loss: 2.285249, Acc:0.780623, Semantic loss: 0.810569, BCE loss: 0.628864, SB loss: 0.845816
2023-10-30 06:52:08,973 Epoch: [140/484] Iter:[10/495], Time: 0.56, lr: [0.007353918591901482], Loss: 2.203052, Acc:0.801130, Semantic loss: 0.895389, BCE loss: 0.532113, SB loss: 0.775550
2023-10-30 06:52:12,753 Epoch: [140/484] Iter:[20/495], Time: 0.47, lr: [0.007353529883017443], Loss: 2.090898, Acc:0.772285, Semantic loss: 0.805091, BCE loss: 0.528230, SB loss: 0.757577
2023-10-30 06:52:16,313 Epoch: [140/484] Iter:[30/495], Time: 0.44, lr: [0.007353141171850367], Loss: 2.114365, Acc:0.778373, Semantic loss: 0.810211, BCE loss: 0.522369, SB loss: 0.781784
2023-10-30 06:52:20,011 Epoch: [140/484] Iter:[40/495], Time: 0.42, lr: [0.007352752458400106], Loss: 2.120643, Acc:0.785695, Semantic loss: 0.801974, BCE loss: 0.543360, SB loss: 0.775308
2023-10-30 06:52:23,670 Epoch: [140/484] Iter:[50/495], Time: 0.41, lr: [0.007352363742666511], Loss: 2.105594, Acc:0.795258, Semantic loss: 0.793821, BCE loss: 0.540855, SB loss: 0.770917
2023-10-30 06:52:27,297 Epoch: [140/484] Iter:[60/495], Time: 0.40, lr: [0.007351975024649438], Loss: 2.070574, Acc:0.791356, Semantic loss: 0.781366, BCE loss: 0.524801, SB loss: 0.764407
2023-10-30 06:52:30,981 Epoch: [140/484] Iter:[70/495], Time: 0.40, lr: [0.007351586304348735], Loss: 2.056129, Acc:0.791272, Semantic loss: 0.775246, BCE loss: 0.520913, SB loss: 0.759971
2023-10-30 06:52:34,654 Epoch: [140/484] Iter:[80/495], Time: 0.39, lr: [0.007351197581764258], Loss: 2.052367, Acc:0.798209, Semantic loss: 0.776617, BCE loss: 0.519878, SB loss: 0.755872
2023-10-30 06:52:38,366 Epoch: [140/484] Iter:[90/495], Time: 0.39, lr: [0.007350808856895854], Loss: 2.067804, Acc:0.800127, Semantic loss: 0.787023, BCE loss: 0.525744, SB loss: 0.755038
2023-10-30 06:52:41,949 Epoch: [140/484] Iter:[100/495], Time: 0.39, lr: [0.007350420129743383], Loss: 2.086698, Acc:0.799431, Semantic loss: 0.799649, BCE loss: 0.529018, SB loss: 0.758031
2023-10-30 06:52:45,595 Epoch: [140/484] Iter:[110/495], Time: 0.39, lr: [0.007350031400306691], Loss: 2.077046, Acc:0.796320, Semantic loss: 0.793332, BCE loss: 0.524185, SB loss: 0.759529
2023-10-30 06:52:49,192 Epoch: [140/484] Iter:[120/495], Time: 0.38, lr: [0.007349642668585635], Loss: 2.073874, Acc:0.794443, Semantic loss: 0.792725, BCE loss: 0.521445, SB loss: 0.759704
2023-10-30 06:52:52,931 Epoch: [140/484] Iter:[130/495], Time: 0.38, lr: [0.007349253934580064], Loss: 2.077300, Acc:0.791422, Semantic loss: 0.798543, BCE loss: 0.520636, SB loss: 0.758121
2023-10-30 06:52:56,561 Epoch: [140/484] Iter:[140/495], Time: 0.38, lr: [0.007348865198289832], Loss: 2.083749, Acc:0.787248, Semantic loss: 0.800106, BCE loss: 0.520650, SB loss: 0.762994
2023-10-30 06:53:00,240 Epoch: [140/484] Iter:[150/495], Time: 0.38, lr: [0.007348476459714791], Loss: 2.082653, Acc:0.786798, Semantic loss: 0.796847, BCE loss: 0.521891, SB loss: 0.763915
2023-10-30 06:53:03,946 Epoch: [140/484] Iter:[160/495], Time: 0.38, lr: [0.007348087718854793], Loss: 2.085512, Acc:0.785343, Semantic loss: 0.797003, BCE loss: 0.523552, SB loss: 0.764957
2023-10-30 06:53:07,641 Epoch: [140/484] Iter:[170/495], Time: 0.38, lr: [0.00734769897570969], Loss: 2.093343, Acc:0.784750, Semantic loss: 0.799980, BCE loss: 0.527097, SB loss: 0.766266
2023-10-30 06:53:11,397 Epoch: [140/484] Iter:[180/495], Time: 0.38, lr: [0.007347310230279335], Loss: 2.091514, Acc:0.784849, Semantic loss: 0.798365, BCE loss: 0.526913, SB loss: 0.766236
2023-10-30 06:53:15,010 Epoch: [140/484] Iter:[190/495], Time: 0.38, lr: [0.007346921482563579], Loss: 2.095283, Acc:0.785658, Semantic loss: 0.798401, BCE loss: 0.530051, SB loss: 0.766831
2023-10-30 06:53:18,666 Epoch: [140/484] Iter:[200/495], Time: 0.38, lr: [0.007346532732562276], Loss: 2.098530, Acc:0.785202, Semantic loss: 0.800458, BCE loss: 0.531539, SB loss: 0.766534
2023-10-30 06:53:22,382 Epoch: [140/484] Iter:[210/495], Time: 0.38, lr: [0.007346143980275277], Loss: 2.097300, Acc:0.787604, Semantic loss: 0.798844, BCE loss: 0.533099, SB loss: 0.765356
2023-10-30 06:53:26,206 Epoch: [140/484] Iter:[220/495], Time: 0.38, lr: [0.007345755225702434], Loss: 2.101216, Acc:0.788459, Semantic loss: 0.799163, BCE loss: 0.536997, SB loss: 0.765056
2023-10-30 06:53:29,898 Epoch: [140/484] Iter:[230/495], Time: 0.38, lr: [0.007345366468843601], Loss: 2.102883, Acc:0.789217, Semantic loss: 0.799998, BCE loss: 0.536949, SB loss: 0.765936
2023-10-30 06:53:33,610 Epoch: [140/484] Iter:[240/495], Time: 0.38, lr: [0.007344977709698626], Loss: 2.106315, Acc:0.789292, Semantic loss: 0.799442, BCE loss: 0.538814, SB loss: 0.768060
2023-10-30 06:53:37,289 Epoch: [140/484] Iter:[250/495], Time: 0.38, lr: [0.007344588948267366], Loss: 2.109765, Acc:0.790222, Semantic loss: 0.800205, BCE loss: 0.540911, SB loss: 0.768650
2023-10-30 06:53:40,909 Epoch: [140/484] Iter:[260/495], Time: 0.38, lr: [0.0073442001845496685], Loss: 2.105123, Acc:0.788642, Semantic loss: 0.797539, BCE loss: 0.540090, SB loss: 0.767493
2023-10-30 06:53:44,526 Epoch: [140/484] Iter:[270/495], Time: 0.38, lr: [0.007343811418545389], Loss: 2.110461, Acc:0.789233, Semantic loss: 0.801356, BCE loss: 0.542052, SB loss: 0.767053
2023-10-30 06:53:48,159 Epoch: [140/484] Iter:[280/495], Time: 0.37, lr: [0.007343422650254379], Loss: 2.107090, Acc:0.788739, Semantic loss: 0.799350, BCE loss: 0.540977, SB loss: 0.766762
2023-10-30 06:53:51,877 Epoch: [140/484] Iter:[290/495], Time: 0.37, lr: [0.007343033879676489], Loss: 2.100643, Acc:0.788623, Semantic loss: 0.795802, BCE loss: 0.540076, SB loss: 0.764766
2023-10-30 06:53:55,557 Epoch: [140/484] Iter:[300/495], Time: 0.37, lr: [0.007342645106811574], Loss: 2.101730, Acc:0.788808, Semantic loss: 0.796320, BCE loss: 0.540768, SB loss: 0.764642
2023-10-30 06:53:59,225 Epoch: [140/484] Iter:[310/495], Time: 0.37, lr: [0.007342256331659483], Loss: 2.101696, Acc:0.789350, Semantic loss: 0.796583, BCE loss: 0.540079, SB loss: 0.765034
2023-10-30 06:54:02,948 Epoch: [140/484] Iter:[320/495], Time: 0.37, lr: [0.007341867554220068], Loss: 2.101462, Acc:0.788976, Semantic loss: 0.797733, BCE loss: 0.537507, SB loss: 0.766222
2023-10-30 06:54:06,576 Epoch: [140/484] Iter:[330/495], Time: 0.37, lr: [0.0073414787744931825], Loss: 2.097348, Acc:0.788808, Semantic loss: 0.795252, BCE loss: 0.537488, SB loss: 0.764607
2023-10-30 06:54:10,275 Epoch: [140/484] Iter:[340/495], Time: 0.37, lr: [0.007341089992478677], Loss: 2.101150, Acc:0.789218, Semantic loss: 0.798507, BCE loss: 0.537307, SB loss: 0.765336
2023-10-30 06:54:14,013 Epoch: [140/484] Iter:[350/495], Time: 0.37, lr: [0.007340701208176405], Loss: 2.103822, Acc:0.789901, Semantic loss: 0.801757, BCE loss: 0.537307, SB loss: 0.764758
2023-10-30 06:54:17,670 Epoch: [140/484] Iter:[360/495], Time: 0.37, lr: [0.007340312421586218], Loss: 2.108854, Acc:0.789513, Semantic loss: 0.803034, BCE loss: 0.539610, SB loss: 0.766209
2023-10-30 06:54:21,279 Epoch: [140/484] Iter:[370/495], Time: 0.37, lr: [0.0073399236327079675], Loss: 2.117012, Acc:0.789666, Semantic loss: 0.807043, BCE loss: 0.542106, SB loss: 0.767863
2023-10-30 06:54:24,956 Epoch: [140/484] Iter:[380/495], Time: 0.37, lr: [0.007339534841541505], Loss: 2.116347, Acc:0.789187, Semantic loss: 0.807067, BCE loss: 0.541974, SB loss: 0.767306
2023-10-30 06:54:28,624 Epoch: [140/484] Iter:[390/495], Time: 0.37, lr: [0.007339146048086684], Loss: 2.119263, Acc:0.788498, Semantic loss: 0.808631, BCE loss: 0.543096, SB loss: 0.767536
2023-10-30 06:54:32,316 Epoch: [140/484] Iter:[400/495], Time: 0.37, lr: [0.007338757252343354], Loss: 2.121834, Acc:0.789162, Semantic loss: 0.809959, BCE loss: 0.543492, SB loss: 0.768383
2023-10-30 06:54:35,990 Epoch: [140/484] Iter:[410/495], Time: 0.37, lr: [0.0073383684543113685], Loss: 2.118380, Acc:0.790370, Semantic loss: 0.807257, BCE loss: 0.544248, SB loss: 0.766875
2023-10-30 06:54:39,677 Epoch: [140/484] Iter:[420/495], Time: 0.37, lr: [0.0073379796539905775], Loss: 2.117407, Acc:0.789260, Semantic loss: 0.806208, BCE loss: 0.544613, SB loss: 0.766586
2023-10-30 06:54:43,355 Epoch: [140/484] Iter:[430/495], Time: 0.37, lr: [0.007337590851380835], Loss: 2.118397, Acc:0.789291, Semantic loss: 0.807141, BCE loss: 0.544599, SB loss: 0.766658
2023-10-30 06:54:47,118 Epoch: [140/484] Iter:[440/495], Time: 0.37, lr: [0.007337202046481992], Loss: 2.113155, Acc:0.789672, Semantic loss: 0.804371, BCE loss: 0.543584, SB loss: 0.765200
2023-10-30 06:54:50,776 Epoch: [140/484] Iter:[450/495], Time: 0.37, lr: [0.007336813239293902], Loss: 2.113927, Acc:0.789100, Semantic loss: 0.804326, BCE loss: 0.543901, SB loss: 0.765701
2023-10-30 06:54:54,400 Epoch: [140/484] Iter:[460/495], Time: 0.37, lr: [0.007336424429816412], Loss: 2.115166, Acc:0.789707, Semantic loss: 0.804500, BCE loss: 0.545174, SB loss: 0.765492
2023-10-30 06:54:58,015 Epoch: [140/484] Iter:[470/495], Time: 0.37, lr: [0.007336035618049377], Loss: 2.114000, Acc:0.788870, Semantic loss: 0.803971, BCE loss: 0.544499, SB loss: 0.765530
2023-10-30 06:55:01,721 Epoch: [140/484] Iter:[480/495], Time: 0.37, lr: [0.007335646803992648], Loss: 2.114551, Acc:0.789340, Semantic loss: 0.804863, BCE loss: 0.544559, SB loss: 0.765129
2023-10-30 06:55:05,243 Epoch: [140/484] Iter:[490/495], Time: 0.37, lr: [0.0073352579876460764], Loss: 2.112553, Acc:0.789305, Semantic loss: 0.803915, BCE loss: 0.544280, SB loss: 0.764358
2023-10-30 06:58:01,781 0 [9.41223135e-01 6.68751508e-01 8.26655620e-01 1.22512494e-01
 2.52917865e-01 4.19845211e-01 3.94760392e-01 5.55920515e-01
 8.78408747e-01 3.88699103e-01 8.71919897e-01 5.47900016e-01
 5.03276737e-03 8.01386461e-01 1.05063556e-05 5.18510870e-02
 4.83475090e-02 3.14183365e-02 5.64635572e-01] 0.44064193384558675
2023-10-30 06:58:01,781 1 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354] 0.6485473763538798
2023-10-30 06:58:01,785 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 06:58:02,030 Loss: 2.070, MeanIU:  0.6485, Best_mIoU:  0.6907
2023-10-30 06:58:02,031 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354]
2023-10-30 06:58:04,533 Epoch: [141/484] Iter:[0/495], Time: 2.47, lr: [0.007335063578614055], Loss: 2.051242, Acc:0.830830, Semantic loss: 0.710174, BCE loss: 0.674358, SB loss: 0.666710
2023-10-30 06:58:08,185 Epoch: [141/484] Iter:[10/495], Time: 0.56, lr: [0.0073346747588324416], Loss: 2.105414, Acc:0.787588, Semantic loss: 0.799889, BCE loss: 0.533823, SB loss: 0.771703
2023-10-30 06:58:11,646 Epoch: [141/484] Iter:[20/495], Time: 0.46, lr: [0.007334285936760616], Loss: 2.091626, Acc:0.774580, Semantic loss: 0.793225, BCE loss: 0.529472, SB loss: 0.768930
2023-10-30 06:58:15,137 Epoch: [141/484] Iter:[30/495], Time: 0.42, lr: [0.00733389711239843], Loss: 2.060749, Acc:0.779079, Semantic loss: 0.779947, BCE loss: 0.525389, SB loss: 0.755413
2023-10-30 06:58:18,615 Epoch: [141/484] Iter:[40/495], Time: 0.40, lr: [0.007333508285745733], Loss: 2.041865, Acc:0.782325, Semantic loss: 0.773586, BCE loss: 0.520623, SB loss: 0.747656
2023-10-30 06:58:22,104 Epoch: [141/484] Iter:[50/495], Time: 0.39, lr: [0.007333119456802379], Loss: 2.056891, Acc:0.791391, Semantic loss: 0.767747, BCE loss: 0.538524, SB loss: 0.750619
2023-10-30 06:58:25,691 Epoch: [141/484] Iter:[60/495], Time: 0.39, lr: [0.007332730625568216], Loss: 2.080128, Acc:0.792189, Semantic loss: 0.780533, BCE loss: 0.543670, SB loss: 0.755925
2023-10-30 06:58:29,235 Epoch: [141/484] Iter:[70/495], Time: 0.38, lr: [0.007332341792043099], Loss: 2.087991, Acc:0.791099, Semantic loss: 0.791513, BCE loss: 0.536971, SB loss: 0.759507
2023-10-30 06:58:32,767 Epoch: [141/484] Iter:[80/495], Time: 0.38, lr: [0.007331952956226877], Loss: 2.072299, Acc:0.794808, Semantic loss: 0.780293, BCE loss: 0.537354, SB loss: 0.754652
2023-10-30 06:58:36,230 Epoch: [141/484] Iter:[90/495], Time: 0.38, lr: [0.0073315641181194045], Loss: 2.059862, Acc:0.794342, Semantic loss: 0.771281, BCE loss: 0.536637, SB loss: 0.751944
2023-10-30 06:58:39,808 Epoch: [141/484] Iter:[100/495], Time: 0.37, lr: [0.007331175277720531], Loss: 2.079144, Acc:0.792942, Semantic loss: 0.782360, BCE loss: 0.539119, SB loss: 0.757664
2023-10-30 06:58:43,383 Epoch: [141/484] Iter:[110/495], Time: 0.37, lr: [0.007330786435030108], Loss: 2.078007, Acc:0.791310, Semantic loss: 0.781866, BCE loss: 0.538005, SB loss: 0.758137
2023-10-30 06:58:47,030 Epoch: [141/484] Iter:[120/495], Time: 0.37, lr: [0.007330397590047987], Loss: 2.074750, Acc:0.791076, Semantic loss: 0.777912, BCE loss: 0.538458, SB loss: 0.758381
2023-10-30 06:58:50,568 Epoch: [141/484] Iter:[130/495], Time: 0.37, lr: [0.00733000874277402], Loss: 2.063341, Acc:0.791015, Semantic loss: 0.771855, BCE loss: 0.536255, SB loss: 0.755230
2023-10-30 06:58:54,204 Epoch: [141/484] Iter:[140/495], Time: 0.37, lr: [0.007329619893208057], Loss: 2.059610, Acc:0.789904, Semantic loss: 0.771851, BCE loss: 0.533395, SB loss: 0.754364
2023-10-30 06:58:57,806 Epoch: [141/484] Iter:[150/495], Time: 0.37, lr: [0.007329231041349951], Loss: 2.054944, Acc:0.792105, Semantic loss: 0.771881, BCE loss: 0.529858, SB loss: 0.753205
2023-10-30 06:59:01,451 Epoch: [141/484] Iter:[160/495], Time: 0.37, lr: [0.007328842187199551], Loss: 2.053044, Acc:0.790443, Semantic loss: 0.772052, BCE loss: 0.528675, SB loss: 0.752317
2023-10-30 06:59:05,124 Epoch: [141/484] Iter:[170/495], Time: 0.37, lr: [0.007328453330756712], Loss: 2.051808, Acc:0.790149, Semantic loss: 0.772460, BCE loss: 0.527786, SB loss: 0.751562
2023-10-30 06:59:08,768 Epoch: [141/484] Iter:[180/495], Time: 0.37, lr: [0.007328064472021283], Loss: 2.058675, Acc:0.789571, Semantic loss: 0.775732, BCE loss: 0.530326, SB loss: 0.752617
2023-10-30 06:59:12,455 Epoch: [141/484] Iter:[190/495], Time: 0.37, lr: [0.007327675610993116], Loss: 2.059575, Acc:0.789008, Semantic loss: 0.777187, BCE loss: 0.532583, SB loss: 0.749805
2023-10-30 06:59:16,014 Epoch: [141/484] Iter:[200/495], Time: 0.37, lr: [0.007327286747672062], Loss: 2.061712, Acc:0.789544, Semantic loss: 0.776303, BCE loss: 0.534240, SB loss: 0.751169
2023-10-30 06:59:19,469 Epoch: [141/484] Iter:[210/495], Time: 0.37, lr: [0.007326897882057972], Loss: 2.057967, Acc:0.786903, Semantic loss: 0.772619, BCE loss: 0.534365, SB loss: 0.750984
2023-10-30 06:59:23,134 Epoch: [141/484] Iter:[220/495], Time: 0.37, lr: [0.007326509014150696], Loss: 2.056029, Acc:0.787565, Semantic loss: 0.770294, BCE loss: 0.534316, SB loss: 0.751419
2023-10-30 06:59:26,743 Epoch: [141/484] Iter:[230/495], Time: 0.37, lr: [0.007326120143950089], Loss: 2.056899, Acc:0.788386, Semantic loss: 0.771954, BCE loss: 0.532720, SB loss: 0.752225
2023-10-30 06:59:30,374 Epoch: [141/484] Iter:[240/495], Time: 0.37, lr: [0.0073257312714559986], Loss: 2.056645, Acc:0.788914, Semantic loss: 0.771538, BCE loss: 0.532517, SB loss: 0.752590
2023-10-30 06:59:33,991 Epoch: [141/484] Iter:[250/495], Time: 0.37, lr: [0.0073253423966682775], Loss: 2.059647, Acc:0.788768, Semantic loss: 0.773462, BCE loss: 0.532749, SB loss: 0.753436
2023-10-30 06:59:37,568 Epoch: [141/484] Iter:[260/495], Time: 0.37, lr: [0.007324953519586778], Loss: 2.065499, Acc:0.787954, Semantic loss: 0.775687, BCE loss: 0.534665, SB loss: 0.755148
2023-10-30 06:59:41,130 Epoch: [141/484] Iter:[270/495], Time: 0.37, lr: [0.007324564640211349], Loss: 2.070658, Acc:0.788562, Semantic loss: 0.777938, BCE loss: 0.537093, SB loss: 0.755627
2023-10-30 06:59:44,728 Epoch: [141/484] Iter:[280/495], Time: 0.37, lr: [0.007324175758541843], Loss: 2.073624, Acc:0.789351, Semantic loss: 0.779356, BCE loss: 0.537067, SB loss: 0.757202
2023-10-30 06:59:48,519 Epoch: [141/484] Iter:[290/495], Time: 0.37, lr: [0.00732378687457811], Loss: 2.080790, Acc:0.789626, Semantic loss: 0.781833, BCE loss: 0.539551, SB loss: 0.759406
2023-10-30 06:59:52,187 Epoch: [141/484] Iter:[300/495], Time: 0.37, lr: [0.007323397988320002], Loss: 2.091468, Acc:0.790914, Semantic loss: 0.786498, BCE loss: 0.543342, SB loss: 0.761628
2023-10-30 06:59:55,712 Epoch: [141/484] Iter:[310/495], Time: 0.37, lr: [0.007323009099767371], Loss: 2.095851, Acc:0.790283, Semantic loss: 0.789103, BCE loss: 0.543422, SB loss: 0.763327
2023-10-30 06:59:59,400 Epoch: [141/484] Iter:[320/495], Time: 0.37, lr: [0.007322620208920065], Loss: 2.092639, Acc:0.791209, Semantic loss: 0.785984, BCE loss: 0.544121, SB loss: 0.762534
2023-10-30 07:00:03,096 Epoch: [141/484] Iter:[330/495], Time: 0.37, lr: [0.007322231315777939], Loss: 2.092188, Acc:0.791817, Semantic loss: 0.785683, BCE loss: 0.544425, SB loss: 0.762080
2023-10-30 07:00:06,774 Epoch: [141/484] Iter:[340/495], Time: 0.37, lr: [0.007321842420340841], Loss: 2.094412, Acc:0.792207, Semantic loss: 0.786684, BCE loss: 0.545101, SB loss: 0.762627
2023-10-30 07:00:10,438 Epoch: [141/484] Iter:[350/495], Time: 0.37, lr: [0.007321453522608624], Loss: 2.092693, Acc:0.792355, Semantic loss: 0.787539, BCE loss: 0.543018, SB loss: 0.762136
2023-10-30 07:00:14,201 Epoch: [141/484] Iter:[360/495], Time: 0.37, lr: [0.007321064622581138], Loss: 2.099040, Acc:0.792899, Semantic loss: 0.791023, BCE loss: 0.545372, SB loss: 0.762645
2023-10-30 07:00:17,970 Epoch: [141/484] Iter:[370/495], Time: 0.37, lr: [0.007320675720258234], Loss: 2.099676, Acc:0.793152, Semantic loss: 0.791369, BCE loss: 0.545370, SB loss: 0.762937
2023-10-30 07:00:21,716 Epoch: [141/484] Iter:[380/495], Time: 0.37, lr: [0.007320286815639763], Loss: 2.099555, Acc:0.793300, Semantic loss: 0.791457, BCE loss: 0.545662, SB loss: 0.762436
2023-10-30 07:00:25,328 Epoch: [141/484] Iter:[390/495], Time: 0.37, lr: [0.007319897908725575], Loss: 2.101686, Acc:0.793615, Semantic loss: 0.793295, BCE loss: 0.545369, SB loss: 0.763023
2023-10-30 07:00:28,928 Epoch: [141/484] Iter:[400/495], Time: 0.37, lr: [0.007319508999515523], Loss: 2.103177, Acc:0.793357, Semantic loss: 0.794255, BCE loss: 0.545726, SB loss: 0.763196
2023-10-30 07:00:32,625 Epoch: [141/484] Iter:[410/495], Time: 0.37, lr: [0.007319120088009457], Loss: 2.107166, Acc:0.792186, Semantic loss: 0.797798, BCE loss: 0.544792, SB loss: 0.764576
2023-10-30 07:00:36,247 Epoch: [141/484] Iter:[420/495], Time: 0.37, lr: [0.007318731174207228], Loss: 2.112892, Acc:0.792488, Semantic loss: 0.800961, BCE loss: 0.544823, SB loss: 0.767109
2023-10-30 07:00:39,877 Epoch: [141/484] Iter:[430/495], Time: 0.37, lr: [0.007318342258108687], Loss: 2.114580, Acc:0.792075, Semantic loss: 0.801716, BCE loss: 0.544259, SB loss: 0.768604
2023-10-30 07:00:43,594 Epoch: [141/484] Iter:[440/495], Time: 0.37, lr: [0.007317953339713683], Loss: 2.115777, Acc:0.791471, Semantic loss: 0.802489, BCE loss: 0.544384, SB loss: 0.768904
2023-10-30 07:00:47,236 Epoch: [141/484] Iter:[450/495], Time: 0.37, lr: [0.007317564419022069], Loss: 2.115561, Acc:0.791209, Semantic loss: 0.801459, BCE loss: 0.545062, SB loss: 0.769039
2023-10-30 07:00:50,769 Epoch: [141/484] Iter:[460/495], Time: 0.37, lr: [0.007317175496033695], Loss: 2.112248, Acc:0.791672, Semantic loss: 0.800362, BCE loss: 0.543568, SB loss: 0.768318
2023-10-30 07:00:54,444 Epoch: [141/484] Iter:[470/495], Time: 0.37, lr: [0.007316786570748412], Loss: 2.111885, Acc:0.791960, Semantic loss: 0.799200, BCE loss: 0.545028, SB loss: 0.767657
2023-10-30 07:00:58,078 Epoch: [141/484] Iter:[480/495], Time: 0.37, lr: [0.007316397643166069], Loss: 2.110422, Acc:0.791885, Semantic loss: 0.798202, BCE loss: 0.544708, SB loss: 0.767511
2023-10-30 07:01:01,605 Epoch: [141/484] Iter:[490/495], Time: 0.37, lr: [0.007316008713286521], Loss: 2.108628, Acc:0.791925, Semantic loss: 0.797196, BCE loss: 0.544602, SB loss: 0.766830
2023-10-30 07:01:02,988 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:01:03,229 Loss: 2.070, MeanIU:  0.6485, Best_mIoU:  0.6907
2023-10-30 07:01:03,229 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354]
2023-10-30 07:01:05,328 Epoch: [142/484] Iter:[0/495], Time: 2.07, lr: [0.007315814247485246], Loss: 2.616119, Acc:0.817921, Semantic loss: 0.940670, BCE loss: 0.771893, SB loss: 0.903555
2023-10-30 07:01:09,362 Epoch: [142/484] Iter:[10/495], Time: 0.55, lr: [0.007315425314159606], Loss: 2.004085, Acc:0.786455, Semantic loss: 0.740819, BCE loss: 0.532157, SB loss: 0.731109
2023-10-30 07:01:13,111 Epoch: [142/484] Iter:[20/495], Time: 0.47, lr: [0.007315036378536385], Loss: 2.060341, Acc:0.782808, Semantic loss: 0.768757, BCE loss: 0.537733, SB loss: 0.753851
2023-10-30 07:01:16,813 Epoch: [142/484] Iter:[30/495], Time: 0.44, lr: [0.0073146474406154335], Loss: 2.098255, Acc:0.780637, Semantic loss: 0.795240, BCE loss: 0.544775, SB loss: 0.758240
2023-10-30 07:01:20,434 Epoch: [142/484] Iter:[40/495], Time: 0.42, lr: [0.007314258500396602], Loss: 2.050264, Acc:0.778075, Semantic loss: 0.766723, BCE loss: 0.532945, SB loss: 0.750595
2023-10-30 07:01:24,009 Epoch: [142/484] Iter:[50/495], Time: 0.41, lr: [0.007313869557879743], Loss: 2.046489, Acc:0.782527, Semantic loss: 0.755896, BCE loss: 0.539240, SB loss: 0.751353
2023-10-30 07:01:27,634 Epoch: [142/484] Iter:[60/495], Time: 0.40, lr: [0.007313480613064705], Loss: 2.034013, Acc:0.785642, Semantic loss: 0.752472, BCE loss: 0.534473, SB loss: 0.747068
2023-10-30 07:01:31,273 Epoch: [142/484] Iter:[70/495], Time: 0.39, lr: [0.00731309166595134], Loss: 2.055300, Acc:0.791845, Semantic loss: 0.770120, BCE loss: 0.533793, SB loss: 0.751387
2023-10-30 07:01:34,866 Epoch: [142/484] Iter:[80/495], Time: 0.39, lr: [0.007312702716539498], Loss: 2.072127, Acc:0.786744, Semantic loss: 0.785798, BCE loss: 0.530435, SB loss: 0.755894
2023-10-30 07:01:38,521 Epoch: [142/484] Iter:[90/495], Time: 0.39, lr: [0.007312313764829031], Loss: 2.057187, Acc:0.783782, Semantic loss: 0.772788, BCE loss: 0.529114, SB loss: 0.755285
2023-10-30 07:01:42,196 Epoch: [142/484] Iter:[100/495], Time: 0.39, lr: [0.007311924810819786], Loss: 2.061769, Acc:0.787955, Semantic loss: 0.774973, BCE loss: 0.530118, SB loss: 0.756678
2023-10-30 07:01:45,817 Epoch: [142/484] Iter:[110/495], Time: 0.38, lr: [0.007311535854511617], Loss: 2.073630, Acc:0.790263, Semantic loss: 0.782033, BCE loss: 0.532896, SB loss: 0.758702
2023-10-30 07:01:49,540 Epoch: [142/484] Iter:[120/495], Time: 0.38, lr: [0.0073111468959043725], Loss: 2.064241, Acc:0.793495, Semantic loss: 0.774519, BCE loss: 0.532798, SB loss: 0.756925
2023-10-30 07:01:53,194 Epoch: [142/484] Iter:[130/495], Time: 0.38, lr: [0.007310757934997905], Loss: 2.059750, Acc:0.793964, Semantic loss: 0.770701, BCE loss: 0.532473, SB loss: 0.756577
2023-10-30 07:01:56,868 Epoch: [142/484] Iter:[140/495], Time: 0.38, lr: [0.007310368971792062], Loss: 2.056694, Acc:0.792931, Semantic loss: 0.771121, BCE loss: 0.529118, SB loss: 0.756454
2023-10-30 07:02:00,531 Epoch: [142/484] Iter:[150/495], Time: 0.38, lr: [0.0073099800062866975], Loss: 2.073751, Acc:0.795091, Semantic loss: 0.780460, BCE loss: 0.535295, SB loss: 0.757996
2023-10-30 07:02:04,183 Epoch: [142/484] Iter:[160/495], Time: 0.38, lr: [0.007309591038481659], Loss: 2.063432, Acc:0.797502, Semantic loss: 0.774200, BCE loss: 0.534248, SB loss: 0.754983
2023-10-30 07:02:07,782 Epoch: [142/484] Iter:[170/495], Time: 0.38, lr: [0.007309202068376799], Loss: 2.060636, Acc:0.797603, Semantic loss: 0.771785, BCE loss: 0.533307, SB loss: 0.755544
2023-10-30 07:02:11,392 Epoch: [142/484] Iter:[180/495], Time: 0.38, lr: [0.007308813095971966], Loss: 2.064908, Acc:0.798358, Semantic loss: 0.775160, BCE loss: 0.533520, SB loss: 0.756229
2023-10-30 07:02:15,147 Epoch: [142/484] Iter:[190/495], Time: 0.38, lr: [0.007308424121267013], Loss: 2.056762, Acc:0.797121, Semantic loss: 0.771371, BCE loss: 0.531869, SB loss: 0.753521
2023-10-30 07:02:18,761 Epoch: [142/484] Iter:[200/495], Time: 0.38, lr: [0.0073080351442617875], Loss: 2.061986, Acc:0.798261, Semantic loss: 0.774105, BCE loss: 0.532929, SB loss: 0.754953
2023-10-30 07:02:22,459 Epoch: [142/484] Iter:[210/495], Time: 0.38, lr: [0.007307646164956142], Loss: 2.067021, Acc:0.798482, Semantic loss: 0.777006, BCE loss: 0.533055, SB loss: 0.756960
2023-10-30 07:02:26,145 Epoch: [142/484] Iter:[220/495], Time: 0.38, lr: [0.007307257183349925], Loss: 2.062194, Acc:0.798571, Semantic loss: 0.774168, BCE loss: 0.532476, SB loss: 0.755549
2023-10-30 07:02:29,860 Epoch: [142/484] Iter:[230/495], Time: 0.37, lr: [0.007306868199442988], Loss: 2.061213, Acc:0.798873, Semantic loss: 0.774466, BCE loss: 0.531136, SB loss: 0.755611
2023-10-30 07:02:33,487 Epoch: [142/484] Iter:[240/495], Time: 0.37, lr: [0.007306479213235183], Loss: 2.063196, Acc:0.799650, Semantic loss: 0.774561, BCE loss: 0.533004, SB loss: 0.755630
2023-10-30 07:02:37,054 Epoch: [142/484] Iter:[250/495], Time: 0.37, lr: [0.007306090224726357], Loss: 2.062814, Acc:0.800566, Semantic loss: 0.774543, BCE loss: 0.533857, SB loss: 0.754414
2023-10-30 07:02:40,744 Epoch: [142/484] Iter:[260/495], Time: 0.37, lr: [0.007305701233916362], Loss: 2.062857, Acc:0.800646, Semantic loss: 0.776372, BCE loss: 0.532460, SB loss: 0.754026
2023-10-30 07:02:44,360 Epoch: [142/484] Iter:[270/495], Time: 0.37, lr: [0.007305312240805047], Loss: 2.061356, Acc:0.798964, Semantic loss: 0.776335, BCE loss: 0.530768, SB loss: 0.754253
2023-10-30 07:02:47,925 Epoch: [142/484] Iter:[280/495], Time: 0.37, lr: [0.007304923245392264], Loss: 2.066456, Acc:0.797697, Semantic loss: 0.779141, BCE loss: 0.530976, SB loss: 0.756339
2023-10-30 07:02:51,605 Epoch: [142/484] Iter:[290/495], Time: 0.37, lr: [0.007304534247677863], Loss: 2.067284, Acc:0.797318, Semantic loss: 0.779576, BCE loss: 0.531435, SB loss: 0.756273
2023-10-30 07:02:55,264 Epoch: [142/484] Iter:[300/495], Time: 0.37, lr: [0.007304145247661692], Loss: 2.064221, Acc:0.797571, Semantic loss: 0.778801, BCE loss: 0.529970, SB loss: 0.755450
2023-10-30 07:02:58,874 Epoch: [142/484] Iter:[310/495], Time: 0.37, lr: [0.007303756245343604], Loss: 2.062857, Acc:0.796778, Semantic loss: 0.778404, BCE loss: 0.529309, SB loss: 0.755143
2023-10-30 07:03:02,494 Epoch: [142/484] Iter:[320/495], Time: 0.37, lr: [0.007303367240723447], Loss: 2.065962, Acc:0.795728, Semantic loss: 0.780338, BCE loss: 0.529759, SB loss: 0.755865
2023-10-30 07:03:06,138 Epoch: [142/484] Iter:[330/495], Time: 0.37, lr: [0.007302978233801073], Loss: 2.069169, Acc:0.795781, Semantic loss: 0.781426, BCE loss: 0.531254, SB loss: 0.756489
2023-10-30 07:03:09,790 Epoch: [142/484] Iter:[340/495], Time: 0.37, lr: [0.0073025892245763314], Loss: 2.072503, Acc:0.795066, Semantic loss: 0.784284, BCE loss: 0.531896, SB loss: 0.756324
2023-10-30 07:03:13,518 Epoch: [142/484] Iter:[350/495], Time: 0.37, lr: [0.0073022002130490715], Loss: 2.071885, Acc:0.794576, Semantic loss: 0.783968, BCE loss: 0.531030, SB loss: 0.756888
2023-10-30 07:03:17,173 Epoch: [142/484] Iter:[360/495], Time: 0.37, lr: [0.007301811199219143], Loss: 2.073668, Acc:0.794804, Semantic loss: 0.783840, BCE loss: 0.532800, SB loss: 0.757028
2023-10-30 07:03:20,883 Epoch: [142/484] Iter:[370/495], Time: 0.37, lr: [0.007301422183086398], Loss: 2.077573, Acc:0.794259, Semantic loss: 0.785415, BCE loss: 0.534328, SB loss: 0.757831
2023-10-30 07:03:24,565 Epoch: [142/484] Iter:[380/495], Time: 0.37, lr: [0.007301033164650683], Loss: 2.079501, Acc:0.793475, Semantic loss: 0.784768, BCE loss: 0.536476, SB loss: 0.758257
2023-10-30 07:03:28,259 Epoch: [142/484] Iter:[390/495], Time: 0.37, lr: [0.007300644143911853], Loss: 2.081425, Acc:0.794178, Semantic loss: 0.785081, BCE loss: 0.537468, SB loss: 0.758876
2023-10-30 07:03:31,935 Epoch: [142/484] Iter:[400/495], Time: 0.37, lr: [0.0073002551208697555], Loss: 2.086861, Acc:0.794875, Semantic loss: 0.788336, BCE loss: 0.538419, SB loss: 0.760106
2023-10-30 07:03:35,601 Epoch: [142/484] Iter:[410/495], Time: 0.37, lr: [0.00729986609552424], Loss: 2.089138, Acc:0.795141, Semantic loss: 0.789222, BCE loss: 0.539866, SB loss: 0.760051
2023-10-30 07:03:39,310 Epoch: [142/484] Iter:[420/495], Time: 0.37, lr: [0.007299477067875157], Loss: 2.088954, Acc:0.794735, Semantic loss: 0.788777, BCE loss: 0.540032, SB loss: 0.760145
2023-10-30 07:03:42,897 Epoch: [142/484] Iter:[430/495], Time: 0.37, lr: [0.007299088037922357], Loss: 2.087862, Acc:0.794496, Semantic loss: 0.787992, BCE loss: 0.540306, SB loss: 0.759564
2023-10-30 07:03:46,628 Epoch: [142/484] Iter:[440/495], Time: 0.37, lr: [0.007298699005665686], Loss: 2.085282, Acc:0.794771, Semantic loss: 0.786385, BCE loss: 0.540248, SB loss: 0.758649
2023-10-30 07:03:50,344 Epoch: [142/484] Iter:[450/495], Time: 0.37, lr: [0.0072983099711050005], Loss: 2.086600, Acc:0.794662, Semantic loss: 0.786886, BCE loss: 0.540899, SB loss: 0.758815
2023-10-30 07:03:53,994 Epoch: [142/484] Iter:[460/495], Time: 0.37, lr: [0.007297920934240146], Loss: 2.088810, Acc:0.794572, Semantic loss: 0.788489, BCE loss: 0.541168, SB loss: 0.759153
2023-10-30 07:03:57,681 Epoch: [142/484] Iter:[470/495], Time: 0.37, lr: [0.007297531895070973], Loss: 2.086081, Acc:0.794772, Semantic loss: 0.786756, BCE loss: 0.540724, SB loss: 0.758602
2023-10-30 07:04:01,388 Epoch: [142/484] Iter:[480/495], Time: 0.37, lr: [0.007297142853597333], Loss: 2.084360, Acc:0.795124, Semantic loss: 0.785942, BCE loss: 0.540429, SB loss: 0.757989
2023-10-30 07:04:04,928 Epoch: [142/484] Iter:[490/495], Time: 0.37, lr: [0.007296753809819074], Loss: 2.086885, Acc:0.794572, Semantic loss: 0.787116, BCE loss: 0.541396, SB loss: 0.758373
2023-10-30 07:04:06,324 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:04:06,563 Loss: 2.070, MeanIU:  0.6485, Best_mIoU:  0.6907
2023-10-30 07:04:06,563 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354]
2023-10-30 07:04:08,851 Epoch: [143/484] Iter:[0/495], Time: 2.25, lr: [0.007296559287065666], Loss: 2.522181, Acc:0.794751, Semantic loss: 1.185034, BCE loss: 0.503229, SB loss: 0.833917
2023-10-30 07:04:12,871 Epoch: [143/484] Iter:[10/495], Time: 0.57, lr: [0.007296170239830198], Loss: 1.973831, Acc:0.775843, Semantic loss: 0.745646, BCE loss: 0.507066, SB loss: 0.721119
2023-10-30 07:04:16,601 Epoch: [143/484] Iter:[20/495], Time: 0.48, lr: [0.007295781190289736], Loss: 2.011018, Acc:0.798832, Semantic loss: 0.768153, BCE loss: 0.517571, SB loss: 0.725293
2023-10-30 07:04:20,201 Epoch: [143/484] Iter:[30/495], Time: 0.44, lr: [0.007295392138444129], Loss: 2.028825, Acc:0.797744, Semantic loss: 0.771611, BCE loss: 0.530617, SB loss: 0.726598
2023-10-30 07:04:23,795 Epoch: [143/484] Iter:[40/495], Time: 0.42, lr: [0.007295003084293228], Loss: 2.035021, Acc:0.796765, Semantic loss: 0.765936, BCE loss: 0.541016, SB loss: 0.728069
2023-10-30 07:04:27,645 Epoch: [143/484] Iter:[50/495], Time: 0.41, lr: [0.0072946140278368835], Loss: 2.022871, Acc:0.797550, Semantic loss: 0.754337, BCE loss: 0.540471, SB loss: 0.728063
2023-10-30 07:04:31,325 Epoch: [143/484] Iter:[60/495], Time: 0.41, lr: [0.007294224969074943], Loss: 2.037312, Acc:0.805812, Semantic loss: 0.758141, BCE loss: 0.548558, SB loss: 0.730613
2023-10-30 07:04:35,020 Epoch: [143/484] Iter:[70/495], Time: 0.40, lr: [0.007293835908007258], Loss: 2.042544, Acc:0.804295, Semantic loss: 0.760102, BCE loss: 0.552039, SB loss: 0.730403
2023-10-30 07:04:38,618 Epoch: [143/484] Iter:[80/495], Time: 0.40, lr: [0.0072934468446336775], Loss: 2.034038, Acc:0.804579, Semantic loss: 0.748657, BCE loss: 0.557527, SB loss: 0.727854
2023-10-30 07:04:42,352 Epoch: [143/484] Iter:[90/495], Time: 0.39, lr: [0.007293057778954052], Loss: 2.030166, Acc:0.801219, Semantic loss: 0.749898, BCE loss: 0.553329, SB loss: 0.726938
2023-10-30 07:04:46,099 Epoch: [143/484] Iter:[100/495], Time: 0.39, lr: [0.007292668710968227], Loss: 2.046778, Acc:0.798328, Semantic loss: 0.760350, BCE loss: 0.552705, SB loss: 0.733722
2023-10-30 07:04:49,798 Epoch: [143/484] Iter:[110/495], Time: 0.39, lr: [0.0072922796406760595], Loss: 2.046309, Acc:0.801738, Semantic loss: 0.759585, BCE loss: 0.550171, SB loss: 0.736553
2023-10-30 07:04:53,522 Epoch: [143/484] Iter:[120/495], Time: 0.39, lr: [0.007291890568077392], Loss: 2.030611, Acc:0.801311, Semantic loss: 0.752662, BCE loss: 0.544894, SB loss: 0.733056
2023-10-30 07:04:57,332 Epoch: [143/484] Iter:[130/495], Time: 0.39, lr: [0.007291501493172078], Loss: 2.042268, Acc:0.802116, Semantic loss: 0.756476, BCE loss: 0.549134, SB loss: 0.736658
2023-10-30 07:05:00,996 Epoch: [143/484] Iter:[140/495], Time: 0.39, lr: [0.007291112415959968], Loss: 2.052612, Acc:0.801172, Semantic loss: 0.758307, BCE loss: 0.556841, SB loss: 0.737464
2023-10-30 07:05:04,688 Epoch: [143/484] Iter:[150/495], Time: 0.38, lr: [0.007290723336440908], Loss: 2.044664, Acc:0.800926, Semantic loss: 0.757193, BCE loss: 0.551493, SB loss: 0.735978
2023-10-30 07:05:08,331 Epoch: [143/484] Iter:[160/495], Time: 0.38, lr: [0.007290334254614748], Loss: 2.046115, Acc:0.801345, Semantic loss: 0.758118, BCE loss: 0.550243, SB loss: 0.737754
2023-10-30 07:05:11,996 Epoch: [143/484] Iter:[170/495], Time: 0.38, lr: [0.007289945170481342], Loss: 2.045691, Acc:0.802015, Semantic loss: 0.757446, BCE loss: 0.550032, SB loss: 0.738213
2023-10-30 07:05:15,650 Epoch: [143/484] Iter:[180/495], Time: 0.38, lr: [0.007289556084040533], Loss: 2.049985, Acc:0.800294, Semantic loss: 0.759551, BCE loss: 0.551735, SB loss: 0.738700
2023-10-30 07:05:19,299 Epoch: [143/484] Iter:[190/495], Time: 0.38, lr: [0.007289166995292175], Loss: 2.050463, Acc:0.799973, Semantic loss: 0.759058, BCE loss: 0.552597, SB loss: 0.738808
2023-10-30 07:05:23,109 Epoch: [143/484] Iter:[200/495], Time: 0.38, lr: [0.0072887779042361146], Loss: 2.064615, Acc:0.800880, Semantic loss: 0.770070, BCE loss: 0.552097, SB loss: 0.742447
2023-10-30 07:05:26,733 Epoch: [143/484] Iter:[210/495], Time: 0.38, lr: [0.007288388810872205], Loss: 2.064987, Acc:0.802275, Semantic loss: 0.769113, BCE loss: 0.551959, SB loss: 0.743915
2023-10-30 07:05:30,301 Epoch: [143/484] Iter:[220/495], Time: 0.38, lr: [0.007287999715200293], Loss: 2.066605, Acc:0.802761, Semantic loss: 0.771022, BCE loss: 0.551184, SB loss: 0.744398
2023-10-30 07:05:34,089 Epoch: [143/484] Iter:[230/495], Time: 0.38, lr: [0.007287610617220228], Loss: 2.063324, Acc:0.802025, Semantic loss: 0.768831, BCE loss: 0.549311, SB loss: 0.745182
2023-10-30 07:05:37,804 Epoch: [143/484] Iter:[240/495], Time: 0.38, lr: [0.00728722151693186], Loss: 2.061249, Acc:0.802569, Semantic loss: 0.767119, BCE loss: 0.549620, SB loss: 0.744510
2023-10-30 07:05:41,408 Epoch: [143/484] Iter:[250/495], Time: 0.38, lr: [0.0072868324143350385], Loss: 2.068084, Acc:0.801915, Semantic loss: 0.770003, BCE loss: 0.551625, SB loss: 0.746456
2023-10-30 07:05:45,084 Epoch: [143/484] Iter:[260/495], Time: 0.38, lr: [0.007286443309429611], Loss: 2.068454, Acc:0.802092, Semantic loss: 0.771736, BCE loss: 0.550397, SB loss: 0.746321
2023-10-30 07:05:48,867 Epoch: [143/484] Iter:[270/495], Time: 0.38, lr: [0.0072860542022154294], Loss: 2.068457, Acc:0.803637, Semantic loss: 0.771446, BCE loss: 0.550132, SB loss: 0.746879
2023-10-30 07:05:52,543 Epoch: [143/484] Iter:[280/495], Time: 0.38, lr: [0.007285665092692342], Loss: 2.070883, Acc:0.804381, Semantic loss: 0.773184, BCE loss: 0.550335, SB loss: 0.747365
2023-10-30 07:05:56,190 Epoch: [143/484] Iter:[290/495], Time: 0.38, lr: [0.007285275980860198], Loss: 2.069539, Acc:0.804562, Semantic loss: 0.772692, BCE loss: 0.550769, SB loss: 0.746077
2023-10-30 07:05:59,910 Epoch: [143/484] Iter:[300/495], Time: 0.38, lr: [0.007284886866718846], Loss: 2.073402, Acc:0.805302, Semantic loss: 0.773789, BCE loss: 0.553534, SB loss: 0.746079
2023-10-30 07:06:03,697 Epoch: [143/484] Iter:[310/495], Time: 0.38, lr: [0.007284497750268137], Loss: 2.076173, Acc:0.803943, Semantic loss: 0.775369, BCE loss: 0.553373, SB loss: 0.747430
2023-10-30 07:06:07,313 Epoch: [143/484] Iter:[320/495], Time: 0.38, lr: [0.007284108631507917], Loss: 2.076066, Acc:0.803689, Semantic loss: 0.775371, BCE loss: 0.551753, SB loss: 0.748941
2023-10-30 07:06:10,901 Epoch: [143/484] Iter:[330/495], Time: 0.38, lr: [0.007283719510438039], Loss: 2.071353, Acc:0.803128, Semantic loss: 0.773694, BCE loss: 0.549752, SB loss: 0.747907
2023-10-30 07:06:14,585 Epoch: [143/484] Iter:[340/495], Time: 0.38, lr: [0.00728333038705835], Loss: 2.067871, Acc:0.803551, Semantic loss: 0.772830, BCE loss: 0.547220, SB loss: 0.747820
2023-10-30 07:06:18,340 Epoch: [143/484] Iter:[350/495], Time: 0.38, lr: [0.0072829412613686995], Loss: 2.067401, Acc:0.803409, Semantic loss: 0.773556, BCE loss: 0.545610, SB loss: 0.748235
2023-10-30 07:06:21,974 Epoch: [143/484] Iter:[360/495], Time: 0.37, lr: [0.007282552133368937], Loss: 2.068398, Acc:0.803332, Semantic loss: 0.773242, BCE loss: 0.546872, SB loss: 0.748284
2023-10-30 07:06:25,618 Epoch: [143/484] Iter:[370/495], Time: 0.37, lr: [0.007282163003058911], Loss: 2.072132, Acc:0.802920, Semantic loss: 0.775614, BCE loss: 0.547178, SB loss: 0.749340
2023-10-30 07:06:29,326 Epoch: [143/484] Iter:[380/495], Time: 0.37, lr: [0.007281773870438473], Loss: 2.070298, Acc:0.803293, Semantic loss: 0.774000, BCE loss: 0.546939, SB loss: 0.749358
2023-10-30 07:06:32,969 Epoch: [143/484] Iter:[390/495], Time: 0.37, lr: [0.007281384735507469], Loss: 2.067875, Acc:0.802350, Semantic loss: 0.773967, BCE loss: 0.545110, SB loss: 0.748799
2023-10-30 07:06:36,696 Epoch: [143/484] Iter:[400/495], Time: 0.37, lr: [0.00728099559826575], Loss: 2.069479, Acc:0.802785, Semantic loss: 0.775320, BCE loss: 0.545321, SB loss: 0.748838
2023-10-30 07:06:40,452 Epoch: [143/484] Iter:[410/495], Time: 0.37, lr: [0.0072806064587131614], Loss: 2.065966, Acc:0.802918, Semantic loss: 0.772989, BCE loss: 0.544939, SB loss: 0.748039
2023-10-30 07:06:44,204 Epoch: [143/484] Iter:[420/495], Time: 0.37, lr: [0.007280217316849558], Loss: 2.062380, Acc:0.802709, Semantic loss: 0.771582, BCE loss: 0.543339, SB loss: 0.747459
2023-10-30 07:06:47,869 Epoch: [143/484] Iter:[430/495], Time: 0.37, lr: [0.007279828172674784], Loss: 2.063145, Acc:0.803478, Semantic loss: 0.771544, BCE loss: 0.544925, SB loss: 0.746675
2023-10-30 07:06:51,500 Epoch: [143/484] Iter:[440/495], Time: 0.37, lr: [0.007279439026188691], Loss: 2.064867, Acc:0.802561, Semantic loss: 0.772741, BCE loss: 0.544821, SB loss: 0.747305
2023-10-30 07:06:55,116 Epoch: [143/484] Iter:[450/495], Time: 0.37, lr: [0.007279049877391129], Loss: 2.065324, Acc:0.801418, Semantic loss: 0.773963, BCE loss: 0.543372, SB loss: 0.747989
2023-10-30 07:06:58,795 Epoch: [143/484] Iter:[460/495], Time: 0.37, lr: [0.007278660726281944], Loss: 2.066284, Acc:0.801321, Semantic loss: 0.775096, BCE loss: 0.543021, SB loss: 0.748167
2023-10-30 07:07:02,488 Epoch: [143/484] Iter:[470/495], Time: 0.37, lr: [0.007278271572860986], Loss: 2.069108, Acc:0.800861, Semantic loss: 0.776019, BCE loss: 0.543503, SB loss: 0.749586
2023-10-30 07:07:06,173 Epoch: [143/484] Iter:[480/495], Time: 0.37, lr: [0.007277882417128106], Loss: 2.064339, Acc:0.801127, Semantic loss: 0.772869, BCE loss: 0.542488, SB loss: 0.748982
2023-10-30 07:07:09,716 Epoch: [143/484] Iter:[490/495], Time: 0.37, lr: [0.007277493259083148], Loss: 2.063764, Acc:0.800679, Semantic loss: 0.773111, BCE loss: 0.541687, SB loss: 0.748966
2023-10-30 07:07:11,126 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:07:11,366 Loss: 2.070, MeanIU:  0.6485, Best_mIoU:  0.6907
2023-10-30 07:07:11,366 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354]
2023-10-30 07:07:13,476 Epoch: [144/484] Iter:[0/495], Time: 2.08, lr: [0.007277298679193594], Loss: 1.935503, Acc:0.806051, Semantic loss: 0.826383, BCE loss: 0.406492, SB loss: 0.702627
2023-10-30 07:07:17,402 Epoch: [144/484] Iter:[10/495], Time: 0.55, lr: [0.007276909517680242], Loss: 2.010588, Acc:0.827978, Semantic loss: 0.766686, BCE loss: 0.508820, SB loss: 0.735082
2023-10-30 07:07:21,021 Epoch: [144/484] Iter:[20/495], Time: 0.46, lr: [0.007276520353854438], Loss: 2.029629, Acc:0.804901, Semantic loss: 0.771175, BCE loss: 0.517191, SB loss: 0.741263
2023-10-30 07:07:24,718 Epoch: [144/484] Iter:[30/495], Time: 0.43, lr: [0.007276131187716028], Loss: 2.052201, Acc:0.778540, Semantic loss: 0.772969, BCE loss: 0.531900, SB loss: 0.747332
2023-10-30 07:07:28,317 Epoch: [144/484] Iter:[40/495], Time: 0.41, lr: [0.007275742019264865], Loss: 2.059471, Acc:0.781087, Semantic loss: 0.782151, BCE loss: 0.533786, SB loss: 0.743534
2023-10-30 07:07:32,083 Epoch: [144/484] Iter:[50/495], Time: 0.41, lr: [0.007275352848500796], Loss: 2.051155, Acc:0.789196, Semantic loss: 0.774129, BCE loss: 0.534778, SB loss: 0.742247
2023-10-30 07:07:35,724 Epoch: [144/484] Iter:[60/495], Time: 0.40, lr: [0.007274963675423668], Loss: 2.056506, Acc:0.792716, Semantic loss: 0.771260, BCE loss: 0.537933, SB loss: 0.747313
2023-10-30 07:07:39,357 Epoch: [144/484] Iter:[70/495], Time: 0.39, lr: [0.007274574500033332], Loss: 2.049736, Acc:0.798894, Semantic loss: 0.766795, BCE loss: 0.536404, SB loss: 0.746537
2023-10-30 07:07:43,009 Epoch: [144/484] Iter:[80/495], Time: 0.39, lr: [0.007274185322329635], Loss: 2.061609, Acc:0.793337, Semantic loss: 0.775021, BCE loss: 0.542183, SB loss: 0.744406
2023-10-30 07:07:46,704 Epoch: [144/484] Iter:[90/495], Time: 0.39, lr: [0.007273796142312427], Loss: 2.052553, Acc:0.792983, Semantic loss: 0.773426, BCE loss: 0.536475, SB loss: 0.742652
2023-10-30 07:07:50,325 Epoch: [144/484] Iter:[100/495], Time: 0.39, lr: [0.007273406959981557], Loss: 2.066392, Acc:0.793569, Semantic loss: 0.775283, BCE loss: 0.543185, SB loss: 0.747924
2023-10-30 07:07:53,972 Epoch: [144/484] Iter:[110/495], Time: 0.38, lr: [0.007273017775336873], Loss: 2.065981, Acc:0.795600, Semantic loss: 0.774240, BCE loss: 0.542183, SB loss: 0.749557
2023-10-30 07:07:57,659 Epoch: [144/484] Iter:[120/495], Time: 0.38, lr: [0.007272628588378225], Loss: 2.055673, Acc:0.794513, Semantic loss: 0.765989, BCE loss: 0.543149, SB loss: 0.746535
2023-10-30 07:08:01,386 Epoch: [144/484] Iter:[130/495], Time: 0.38, lr: [0.007272239399105459], Loss: 2.065333, Acc:0.793103, Semantic loss: 0.769688, BCE loss: 0.545669, SB loss: 0.749976
2023-10-30 07:08:05,059 Epoch: [144/484] Iter:[140/495], Time: 0.38, lr: [0.007271850207518427], Loss: 2.068898, Acc:0.793975, Semantic loss: 0.773503, BCE loss: 0.543472, SB loss: 0.751924
2023-10-30 07:08:08,717 Epoch: [144/484] Iter:[150/495], Time: 0.38, lr: [0.007271461013616975], Loss: 2.074743, Acc:0.794236, Semantic loss: 0.774308, BCE loss: 0.545985, SB loss: 0.754450
2023-10-30 07:08:12,445 Epoch: [144/484] Iter:[160/495], Time: 0.38, lr: [0.00727107181740095], Loss: 2.078196, Acc:0.794303, Semantic loss: 0.776162, BCE loss: 0.548073, SB loss: 0.753962
2023-10-30 07:08:16,153 Epoch: [144/484] Iter:[170/495], Time: 0.38, lr: [0.007270682618870205], Loss: 2.072891, Acc:0.794951, Semantic loss: 0.772190, BCE loss: 0.547663, SB loss: 0.753038
2023-10-30 07:08:19,925 Epoch: [144/484] Iter:[180/495], Time: 0.38, lr: [0.007270293418024585], Loss: 2.081009, Acc:0.795425, Semantic loss: 0.777754, BCE loss: 0.547425, SB loss: 0.755831
2023-10-30 07:08:23,597 Epoch: [144/484] Iter:[190/495], Time: 0.38, lr: [0.0072699042148639415], Loss: 2.090713, Acc:0.795985, Semantic loss: 0.784180, BCE loss: 0.551093, SB loss: 0.755441
2023-10-30 07:08:27,205 Epoch: [144/484] Iter:[200/495], Time: 0.38, lr: [0.007269515009388121], Loss: 2.086830, Acc:0.795296, Semantic loss: 0.782038, BCE loss: 0.550141, SB loss: 0.754652
2023-10-30 07:08:30,811 Epoch: [144/484] Iter:[210/495], Time: 0.38, lr: [0.007269125801596973], Loss: 2.075980, Acc:0.795177, Semantic loss: 0.777078, BCE loss: 0.546179, SB loss: 0.752722
2023-10-30 07:08:34,423 Epoch: [144/484] Iter:[220/495], Time: 0.38, lr: [0.007268736591490345], Loss: 2.074335, Acc:0.796083, Semantic loss: 0.776563, BCE loss: 0.545023, SB loss: 0.752749
2023-10-30 07:08:38,127 Epoch: [144/484] Iter:[230/495], Time: 0.38, lr: [0.007268347379068086], Loss: 2.071144, Acc:0.796822, Semantic loss: 0.774777, BCE loss: 0.543574, SB loss: 0.752793
2023-10-30 07:08:41,813 Epoch: [144/484] Iter:[240/495], Time: 0.38, lr: [0.007267958164330044], Loss: 2.064238, Acc:0.797140, Semantic loss: 0.771983, BCE loss: 0.540986, SB loss: 0.751269
2023-10-30 07:08:45,581 Epoch: [144/484] Iter:[250/495], Time: 0.38, lr: [0.007267568947276068], Loss: 2.075934, Acc:0.797299, Semantic loss: 0.779738, BCE loss: 0.543513, SB loss: 0.752683
2023-10-30 07:08:49,260 Epoch: [144/484] Iter:[260/495], Time: 0.37, lr: [0.007267179727906006], Loss: 2.080759, Acc:0.797446, Semantic loss: 0.780388, BCE loss: 0.545297, SB loss: 0.755074
2023-10-30 07:08:52,955 Epoch: [144/484] Iter:[270/495], Time: 0.37, lr: [0.007266790506219708], Loss: 2.080754, Acc:0.797832, Semantic loss: 0.779287, BCE loss: 0.546227, SB loss: 0.755241
2023-10-30 07:08:56,577 Epoch: [144/484] Iter:[280/495], Time: 0.37, lr: [0.00726640128221702], Loss: 2.078537, Acc:0.796597, Semantic loss: 0.778840, BCE loss: 0.544498, SB loss: 0.755199
2023-10-30 07:09:00,317 Epoch: [144/484] Iter:[290/495], Time: 0.37, lr: [0.007266012055897791], Loss: 2.075800, Acc:0.796647, Semantic loss: 0.777398, BCE loss: 0.543986, SB loss: 0.754417
2023-10-30 07:09:04,114 Epoch: [144/484] Iter:[300/495], Time: 0.37, lr: [0.00726562282726187], Loss: 2.073104, Acc:0.796676, Semantic loss: 0.777151, BCE loss: 0.541916, SB loss: 0.754038
2023-10-30 07:09:07,697 Epoch: [144/484] Iter:[310/495], Time: 0.37, lr: [0.007265233596309106], Loss: 2.076612, Acc:0.797183, Semantic loss: 0.778650, BCE loss: 0.543289, SB loss: 0.754674
2023-10-30 07:09:11,401 Epoch: [144/484] Iter:[320/495], Time: 0.37, lr: [0.0072648443630393454], Loss: 2.073182, Acc:0.795894, Semantic loss: 0.777632, BCE loss: 0.541731, SB loss: 0.753819
2023-10-30 07:09:15,070 Epoch: [144/484] Iter:[330/495], Time: 0.37, lr: [0.007264455127452436], Loss: 2.073367, Acc:0.797337, Semantic loss: 0.778185, BCE loss: 0.541307, SB loss: 0.753875
2023-10-30 07:09:18,780 Epoch: [144/484] Iter:[340/495], Time: 0.37, lr: [0.0072640658895482295], Loss: 2.075717, Acc:0.796483, Semantic loss: 0.779383, BCE loss: 0.542535, SB loss: 0.753799
2023-10-30 07:09:22,445 Epoch: [144/484] Iter:[350/495], Time: 0.37, lr: [0.007263676649326572], Loss: 2.076974, Acc:0.797932, Semantic loss: 0.779599, BCE loss: 0.543739, SB loss: 0.753637
2023-10-30 07:09:26,178 Epoch: [144/484] Iter:[360/495], Time: 0.37, lr: [0.0072632874067873115], Loss: 2.079441, Acc:0.798300, Semantic loss: 0.780611, BCE loss: 0.544718, SB loss: 0.754111
2023-10-30 07:09:29,829 Epoch: [144/484] Iter:[370/495], Time: 0.37, lr: [0.007262898161930296], Loss: 2.078369, Acc:0.798082, Semantic loss: 0.780134, BCE loss: 0.544587, SB loss: 0.753648
2023-10-30 07:09:33,533 Epoch: [144/484] Iter:[380/495], Time: 0.37, lr: [0.007262508914755374], Loss: 2.081059, Acc:0.797964, Semantic loss: 0.781378, BCE loss: 0.546372, SB loss: 0.753309
2023-10-30 07:09:37,250 Epoch: [144/484] Iter:[390/495], Time: 0.37, lr: [0.007262119665262393], Loss: 2.080621, Acc:0.797358, Semantic loss: 0.782474, BCE loss: 0.545048, SB loss: 0.753098
2023-10-30 07:09:41,069 Epoch: [144/484] Iter:[400/495], Time: 0.37, lr: [0.007261730413451203], Loss: 2.086179, Acc:0.797166, Semantic loss: 0.786910, BCE loss: 0.545238, SB loss: 0.754031
2023-10-30 07:09:44,706 Epoch: [144/484] Iter:[410/495], Time: 0.37, lr: [0.007261341159321651], Loss: 2.085151, Acc:0.797371, Semantic loss: 0.786260, BCE loss: 0.544858, SB loss: 0.754033
2023-10-30 07:09:48,485 Epoch: [144/484] Iter:[420/495], Time: 0.37, lr: [0.007260951902873585], Loss: 2.083090, Acc:0.798051, Semantic loss: 0.785578, BCE loss: 0.543766, SB loss: 0.753746
2023-10-30 07:09:52,136 Epoch: [144/484] Iter:[430/495], Time: 0.37, lr: [0.007260562644106853], Loss: 2.089123, Acc:0.797836, Semantic loss: 0.790352, BCE loss: 0.544728, SB loss: 0.754043
2023-10-30 07:09:55,765 Epoch: [144/484] Iter:[440/495], Time: 0.37, lr: [0.007260173383021305], Loss: 2.087714, Acc:0.797491, Semantic loss: 0.788743, BCE loss: 0.545470, SB loss: 0.753502
2023-10-30 07:09:59,461 Epoch: [144/484] Iter:[450/495], Time: 0.37, lr: [0.007259784119616786], Loss: 2.086223, Acc:0.797307, Semantic loss: 0.787994, BCE loss: 0.544868, SB loss: 0.753361
2023-10-30 07:10:03,129 Epoch: [144/484] Iter:[460/495], Time: 0.37, lr: [0.007259394853893145], Loss: 2.087468, Acc:0.797259, Semantic loss: 0.787387, BCE loss: 0.546158, SB loss: 0.753923
2023-10-30 07:10:06,741 Epoch: [144/484] Iter:[470/495], Time: 0.37, lr: [0.00725900558585023], Loss: 2.086314, Acc:0.797068, Semantic loss: 0.787079, BCE loss: 0.545867, SB loss: 0.753368
2023-10-30 07:10:10,567 Epoch: [144/484] Iter:[480/495], Time: 0.37, lr: [0.00725861631548789], Loss: 2.087283, Acc:0.797500, Semantic loss: 0.787253, BCE loss: 0.546844, SB loss: 0.753186
2023-10-30 07:10:13,997 Epoch: [144/484] Iter:[490/495], Time: 0.37, lr: [0.007258227042805971], Loss: 2.090355, Acc:0.796652, Semantic loss: 0.789481, BCE loss: 0.546676, SB loss: 0.754199
2023-10-30 07:10:15,382 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:10:15,625 Loss: 2.070, MeanIU:  0.6485, Best_mIoU:  0.6907
2023-10-30 07:10:15,625 [0.970555   0.77849018 0.8993609  0.4610278  0.49611344 0.583461
 0.63700615 0.71732953 0.90335303 0.54053126 0.93167986 0.71877463
 0.55710177 0.92176507 0.09238459 0.62956659 0.43081037 0.33531544
 0.71777354]
2023-10-30 07:10:17,705 Epoch: [145/484] Iter:[0/495], Time: 2.04, lr: [0.0072580324055951245], Loss: 1.881252, Acc:0.845037, Semantic loss: 0.757659, BCE loss: 0.272576, SB loss: 0.851017
2023-10-30 07:10:21,771 Epoch: [145/484] Iter:[10/495], Time: 0.56, lr: [0.007257643129433555], Loss: 2.096096, Acc:0.813654, Semantic loss: 0.852870, BCE loss: 0.467803, SB loss: 0.775422
2023-10-30 07:10:25,512 Epoch: [145/484] Iter:[20/495], Time: 0.47, lr: [0.007257253850952028], Loss: 2.140234, Acc:0.794717, Semantic loss: 0.854964, BCE loss: 0.504787, SB loss: 0.780483
2023-10-30 07:10:29,075 Epoch: [145/484] Iter:[30/495], Time: 0.43, lr: [0.007256864570150392], Loss: 2.093807, Acc:0.794060, Semantic loss: 0.821377, BCE loss: 0.505653, SB loss: 0.766776
2023-10-30 07:10:32,685 Epoch: [145/484] Iter:[40/495], Time: 0.42, lr: [0.007256475287028493], Loss: 2.075478, Acc:0.785930, Semantic loss: 0.799835, BCE loss: 0.507850, SB loss: 0.767792
2023-10-30 07:10:36,314 Epoch: [145/484] Iter:[50/495], Time: 0.40, lr: [0.007256086001586179], Loss: 2.047557, Acc:0.785219, Semantic loss: 0.778623, BCE loss: 0.509864, SB loss: 0.759070
2023-10-30 07:10:39,993 Epoch: [145/484] Iter:[60/495], Time: 0.40, lr: [0.0072556967138233], Loss: 2.097347, Acc:0.777261, Semantic loss: 0.816123, BCE loss: 0.508834, SB loss: 0.772390
2023-10-30 07:10:43,734 Epoch: [145/484] Iter:[70/495], Time: 0.40, lr: [0.007255307423739702], Loss: 2.093340, Acc:0.781383, Semantic loss: 0.809789, BCE loss: 0.512316, SB loss: 0.771235
2023-10-30 07:10:47,450 Epoch: [145/484] Iter:[80/495], Time: 0.39, lr: [0.0072549181313352334], Loss: 2.082020, Acc:0.785913, Semantic loss: 0.800662, BCE loss: 0.514959, SB loss: 0.766400
2023-10-30 07:10:51,059 Epoch: [145/484] Iter:[90/495], Time: 0.39, lr: [0.007254528836609742], Loss: 2.072071, Acc:0.785129, Semantic loss: 0.794719, BCE loss: 0.514673, SB loss: 0.762679
2023-10-30 07:10:54,812 Epoch: [145/484] Iter:[100/495], Time: 0.39, lr: [0.007254139539563076], Loss: 2.077712, Acc:0.788502, Semantic loss: 0.794229, BCE loss: 0.522300, SB loss: 0.761183
2023-10-30 07:10:58,538 Epoch: [145/484] Iter:[110/495], Time: 0.39, lr: [0.0072537502401950815], Loss: 2.079772, Acc:0.789004, Semantic loss: 0.794895, BCE loss: 0.525401, SB loss: 0.759476
2023-10-30 07:11:02,206 Epoch: [145/484] Iter:[120/495], Time: 0.38, lr: [0.007253360938505609], Loss: 2.084085, Acc:0.790047, Semantic loss: 0.794925, BCE loss: 0.530050, SB loss: 0.759109
2023-10-30 07:11:05,941 Epoch: [145/484] Iter:[130/495], Time: 0.38, lr: [0.0072529716344945025], Loss: 2.078794, Acc:0.790998, Semantic loss: 0.791082, BCE loss: 0.530516, SB loss: 0.757196
2023-10-30 07:11:09,587 Epoch: [145/484] Iter:[140/495], Time: 0.38, lr: [0.007252582328161613], Loss: 2.077112, Acc:0.792289, Semantic loss: 0.790456, BCE loss: 0.527655, SB loss: 0.759001
2023-10-30 07:11:13,346 Epoch: [145/484] Iter:[150/495], Time: 0.38, lr: [0.007252193019506786], Loss: 2.076319, Acc:0.794485, Semantic loss: 0.790375, BCE loss: 0.527878, SB loss: 0.758066
2023-10-30 07:11:17,126 Epoch: [145/484] Iter:[160/495], Time: 0.38, lr: [0.00725180370852987], Loss: 2.067818, Acc:0.795632, Semantic loss: 0.786639, BCE loss: 0.527243, SB loss: 0.753937
2023-10-30 07:11:20,705 Epoch: [145/484] Iter:[170/495], Time: 0.38, lr: [0.007251414395230714], Loss: 2.073012, Acc:0.795724, Semantic loss: 0.789963, BCE loss: 0.527984, SB loss: 0.755066
2023-10-30 07:11:24,555 Epoch: [145/484] Iter:[180/495], Time: 0.38, lr: [0.007251025079609165], Loss: 2.065761, Acc:0.795233, Semantic loss: 0.785728, BCE loss: 0.526142, SB loss: 0.753891
2023-10-30 07:11:28,219 Epoch: [145/484] Iter:[190/495], Time: 0.38, lr: [0.007250635761665069], Loss: 2.061835, Acc:0.795427, Semantic loss: 0.784048, BCE loss: 0.525375, SB loss: 0.752412
2023-10-30 07:11:31,923 Epoch: [145/484] Iter:[200/495], Time: 0.38, lr: [0.007250246441398274], Loss: 2.062657, Acc:0.796527, Semantic loss: 0.783172, BCE loss: 0.526803, SB loss: 0.752682
2023-10-30 07:11:35,558 Epoch: [145/484] Iter:[210/495], Time: 0.38, lr: [0.007249857118808628], Loss: 2.061424, Acc:0.795933, Semantic loss: 0.782259, BCE loss: 0.527476, SB loss: 0.751689
2023-10-30 07:11:39,209 Epoch: [145/484] Iter:[220/495], Time: 0.38, lr: [0.007249467793895978], Loss: 2.067339, Acc:0.795283, Semantic loss: 0.782575, BCE loss: 0.532051, SB loss: 0.752713
2023-10-30 07:11:42,942 Epoch: [145/484] Iter:[230/495], Time: 0.38, lr: [0.007249078466660174], Loss: 2.068278, Acc:0.795158, Semantic loss: 0.782219, BCE loss: 0.532624, SB loss: 0.753435
2023-10-30 07:11:46,579 Epoch: [145/484] Iter:[240/495], Time: 0.38, lr: [0.00724868913710106], Loss: 2.067105, Acc:0.794207, Semantic loss: 0.780956, BCE loss: 0.533515, SB loss: 0.752634
2023-10-30 07:11:50,397 Epoch: [145/484] Iter:[250/495], Time: 0.38, lr: [0.007248299805218487], Loss: 2.061842, Acc:0.794232, Semantic loss: 0.779842, BCE loss: 0.530848, SB loss: 0.751151
2023-10-30 07:11:54,218 Epoch: [145/484] Iter:[260/495], Time: 0.38, lr: [0.007247910471012299], Loss: 2.062605, Acc:0.793899, Semantic loss: 0.780389, BCE loss: 0.530926, SB loss: 0.751289
2023-10-30 07:11:57,846 Epoch: [145/484] Iter:[270/495], Time: 0.38, lr: [0.007247521134482347], Loss: 2.065750, Acc:0.794273, Semantic loss: 0.781150, BCE loss: 0.533177, SB loss: 0.751423
2023-10-30 07:12:01,463 Epoch: [145/484] Iter:[280/495], Time: 0.38, lr: [0.007247131795628474], Loss: 2.063884, Acc:0.793624, Semantic loss: 0.779336, BCE loss: 0.533797, SB loss: 0.750752
2023-10-30 07:12:05,146 Epoch: [145/484] Iter:[290/495], Time: 0.38, lr: [0.00724674245445053], Loss: 2.064775, Acc:0.793757, Semantic loss: 0.779485, BCE loss: 0.534875, SB loss: 0.750415
2023-10-30 07:12:08,846 Epoch: [145/484] Iter:[300/495], Time: 0.38, lr: [0.007246353110948364], Loss: 2.067876, Acc:0.794458, Semantic loss: 0.781853, BCE loss: 0.535107, SB loss: 0.750916
2023-10-30 07:12:12,526 Epoch: [145/484] Iter:[310/495], Time: 0.38, lr: [0.00724596376512182], Loss: 2.070100, Acc:0.794465, Semantic loss: 0.785997, BCE loss: 0.533187, SB loss: 0.750916
2023-10-30 07:12:16,171 Epoch: [145/484] Iter:[320/495], Time: 0.38, lr: [0.007245574416970748], Loss: 2.071209, Acc:0.795771, Semantic loss: 0.785491, BCE loss: 0.534409, SB loss: 0.751309
2023-10-30 07:12:19,801 Epoch: [145/484] Iter:[330/495], Time: 0.38, lr: [0.007245185066494994], Loss: 2.075537, Acc:0.795855, Semantic loss: 0.788846, BCE loss: 0.534481, SB loss: 0.752210
2023-10-30 07:12:23,431 Epoch: [145/484] Iter:[340/495], Time: 0.37, lr: [0.007244795713694407], Loss: 2.078229, Acc:0.794818, Semantic loss: 0.790557, BCE loss: 0.534471, SB loss: 0.753201
2023-10-30 07:12:27,149 Epoch: [145/484] Iter:[350/495], Time: 0.37, lr: [0.007244406358568831], Loss: 2.075462, Acc:0.794477, Semantic loss: 0.789325, BCE loss: 0.533378, SB loss: 0.752759
2023-10-30 07:12:30,819 Epoch: [145/484] Iter:[360/495], Time: 0.37, lr: [0.007244017001118116], Loss: 2.074725, Acc:0.795341, Semantic loss: 0.788936, BCE loss: 0.533615, SB loss: 0.752174
2023-10-30 07:12:34,519 Epoch: [145/484] Iter:[370/495], Time: 0.37, lr: [0.007243627641342108], Loss: 2.074118, Acc:0.795459, Semantic loss: 0.788294, BCE loss: 0.532768, SB loss: 0.753056
2023-10-30 07:12:38,218 Epoch: [145/484] Iter:[380/495], Time: 0.37, lr: [0.007243238279240655], Loss: 2.078695, Acc:0.794371, Semantic loss: 0.791788, BCE loss: 0.532852, SB loss: 0.754055
2023-10-30 07:12:41,976 Epoch: [145/484] Iter:[390/495], Time: 0.37, lr: [0.007242848914813602], Loss: 2.087409, Acc:0.793983, Semantic loss: 0.796091, BCE loss: 0.535154, SB loss: 0.756165
2023-10-30 07:12:45,716 Epoch: [145/484] Iter:[400/495], Time: 0.37, lr: [0.0072424595480608004], Loss: 2.089528, Acc:0.793664, Semantic loss: 0.797077, BCE loss: 0.535836, SB loss: 0.756615
2023-10-30 07:12:49,367 Epoch: [145/484] Iter:[410/495], Time: 0.37, lr: [0.0072420701789820945], Loss: 2.090735, Acc:0.794647, Semantic loss: 0.796318, BCE loss: 0.537868, SB loss: 0.756549
2023-10-30 07:12:52,979 Epoch: [145/484] Iter:[420/495], Time: 0.37, lr: [0.007241680807577332], Loss: 2.090379, Acc:0.794810, Semantic loss: 0.795119, BCE loss: 0.539041, SB loss: 0.756219
2023-10-30 07:12:56,662 Epoch: [145/484] Iter:[430/495], Time: 0.37, lr: [0.007241291433846361], Loss: 2.087663, Acc:0.794421, Semantic loss: 0.793522, BCE loss: 0.538665, SB loss: 0.755476
2023-10-30 07:13:00,291 Epoch: [145/484] Iter:[440/495], Time: 0.37, lr: [0.007240902057789026], Loss: 2.093114, Acc:0.793576, Semantic loss: 0.797517, BCE loss: 0.538769, SB loss: 0.756828
2023-10-30 07:13:04,004 Epoch: [145/484] Iter:[450/495], Time: 0.37, lr: [0.007240512679405176], Loss: 2.094824, Acc:0.792634, Semantic loss: 0.798490, BCE loss: 0.538486, SB loss: 0.757847
2023-10-30 07:13:07,727 Epoch: [145/484] Iter:[460/495], Time: 0.37, lr: [0.007240123298694659], Loss: 2.096574, Acc:0.791696, Semantic loss: 0.798595, BCE loss: 0.539022, SB loss: 0.758957
2023-10-30 07:13:11,344 Epoch: [145/484] Iter:[470/495], Time: 0.37, lr: [0.007239733915657319], Loss: 2.100727, Acc:0.791256, Semantic loss: 0.801797, BCE loss: 0.538644, SB loss: 0.760285
2023-10-30 07:13:14,992 Epoch: [145/484] Iter:[480/495], Time: 0.37, lr: [0.007239344530293007], Loss: 2.099265, Acc:0.791144, Semantic loss: 0.800623, BCE loss: 0.538692, SB loss: 0.759950
2023-10-30 07:13:18,504 Epoch: [145/484] Iter:[490/495], Time: 0.37, lr: [0.007238955142601568], Loss: 2.102583, Acc:0.790986, Semantic loss: 0.801948, BCE loss: 0.539602, SB loss: 0.761033
2023-10-30 07:16:14,997 0 [9.34279661e-01 6.24959901e-01 8.07927725e-01 1.01080620e-01
 2.47698929e-01 4.12934510e-01 4.22240199e-01 5.39478936e-01
 8.76804648e-01 4.11950036e-01 8.37027490e-01 5.10298815e-01
 2.38551204e-03 7.85648058e-01 5.57516719e-05 4.45681278e-02
 6.47040649e-02 1.88413394e-02 5.49283582e-01] 0.43116673183915155
2023-10-30 07:16:14,998 1 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561] 0.6463245492584194
2023-10-30 07:16:15,001 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:16:15,237 Loss: 2.106, MeanIU:  0.6463, Best_mIoU:  0.6907
2023-10-30 07:16:15,237 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561]
2023-10-30 07:16:17,336 Epoch: [146/484] Iter:[0/495], Time: 2.07, lr: [0.007238760447883127], Loss: 1.891920, Acc:0.839873, Semantic loss: 0.622402, BCE loss: 0.579349, SB loss: 0.690170
2023-10-30 07:16:21,322 Epoch: [146/484] Iter:[10/495], Time: 0.55, lr: [0.00723837105670071], Loss: 1.899925, Acc:0.811756, Semantic loss: 0.674809, BCE loss: 0.521371, SB loss: 0.703745
2023-10-30 07:16:24,796 Epoch: [146/484] Iter:[20/495], Time: 0.45, lr: [0.007237981663190784], Loss: 1.991676, Acc:0.800307, Semantic loss: 0.727647, BCE loss: 0.530036, SB loss: 0.733994
2023-10-30 07:16:28,265 Epoch: [146/484] Iter:[30/495], Time: 0.42, lr: [0.0072375922673531936], Loss: 1.969378, Acc:0.802715, Semantic loss: 0.724097, BCE loss: 0.509803, SB loss: 0.735479
2023-10-30 07:16:31,734 Epoch: [146/484] Iter:[40/495], Time: 0.40, lr: [0.007237202869187789], Loss: 1.969904, Acc:0.797321, Semantic loss: 0.728433, BCE loss: 0.507223, SB loss: 0.734248
2023-10-30 07:16:35,170 Epoch: [146/484] Iter:[50/495], Time: 0.39, lr: [0.007236813468694414], Loss: 2.007916, Acc:0.796383, Semantic loss: 0.756227, BCE loss: 0.505485, SB loss: 0.746204
2023-10-30 07:16:38,756 Epoch: [146/484] Iter:[60/495], Time: 0.39, lr: [0.007236424065872918], Loss: 2.016979, Acc:0.792401, Semantic loss: 0.779518, BCE loss: 0.496143, SB loss: 0.741318
2023-10-30 07:16:42,295 Epoch: [146/484] Iter:[70/495], Time: 0.38, lr: [0.007236034660723149], Loss: 2.033187, Acc:0.792912, Semantic loss: 0.774562, BCE loss: 0.516809, SB loss: 0.741816
2023-10-30 07:16:45,920 Epoch: [146/484] Iter:[80/495], Time: 0.38, lr: [0.00723564525324495], Loss: 2.065380, Acc:0.795416, Semantic loss: 0.791465, BCE loss: 0.524353, SB loss: 0.749562
2023-10-30 07:16:49,412 Epoch: [146/484] Iter:[90/495], Time: 0.38, lr: [0.007235255843438171], Loss: 2.108313, Acc:0.795272, Semantic loss: 0.821275, BCE loss: 0.524361, SB loss: 0.762677
2023-10-30 07:16:53,127 Epoch: [146/484] Iter:[100/495], Time: 0.37, lr: [0.007234866431302657], Loss: 2.106596, Acc:0.795678, Semantic loss: 0.817601, BCE loss: 0.526887, SB loss: 0.762107
2023-10-30 07:16:56,647 Epoch: [146/484] Iter:[110/495], Time: 0.37, lr: [0.007234477016838254], Loss: 2.138628, Acc:0.796246, Semantic loss: 0.833011, BCE loss: 0.535825, SB loss: 0.769793
2023-10-30 07:17:00,191 Epoch: [146/484] Iter:[120/495], Time: 0.37, lr: [0.007234087600044812], Loss: 2.129983, Acc:0.796652, Semantic loss: 0.822947, BCE loss: 0.538665, SB loss: 0.768371
2023-10-30 07:17:03,779 Epoch: [146/484] Iter:[130/495], Time: 0.37, lr: [0.007233698180922173], Loss: 2.132786, Acc:0.796891, Semantic loss: 0.822136, BCE loss: 0.540929, SB loss: 0.769721
2023-10-30 07:17:07,387 Epoch: [146/484] Iter:[140/495], Time: 0.37, lr: [0.00723330875947019], Loss: 2.128571, Acc:0.795469, Semantic loss: 0.820549, BCE loss: 0.541490, SB loss: 0.766531
2023-10-30 07:17:10,932 Epoch: [146/484] Iter:[150/495], Time: 0.37, lr: [0.007232919335688706], Loss: 2.117610, Acc:0.794610, Semantic loss: 0.812826, BCE loss: 0.539187, SB loss: 0.765597
2023-10-30 07:17:14,550 Epoch: [146/484] Iter:[160/495], Time: 0.37, lr: [0.007232529909577567], Loss: 2.115654, Acc:0.792686, Semantic loss: 0.812152, BCE loss: 0.537819, SB loss: 0.765683
2023-10-30 07:17:18,095 Epoch: [146/484] Iter:[170/495], Time: 0.37, lr: [0.007232140481136621], Loss: 2.111809, Acc:0.789596, Semantic loss: 0.808825, BCE loss: 0.538468, SB loss: 0.764515
2023-10-30 07:17:21,597 Epoch: [146/484] Iter:[180/495], Time: 0.37, lr: [0.007231751050365716], Loss: 2.112473, Acc:0.788963, Semantic loss: 0.807758, BCE loss: 0.539287, SB loss: 0.765428
2023-10-30 07:17:25,150 Epoch: [146/484] Iter:[190/495], Time: 0.37, lr: [0.007231361617264695], Loss: 2.105902, Acc:0.787977, Semantic loss: 0.804958, BCE loss: 0.536609, SB loss: 0.764335
2023-10-30 07:17:28,867 Epoch: [146/484] Iter:[200/495], Time: 0.37, lr: [0.007230972181833406], Loss: 2.104306, Acc:0.787965, Semantic loss: 0.805523, BCE loss: 0.535204, SB loss: 0.763578
2023-10-30 07:17:32,387 Epoch: [146/484] Iter:[210/495], Time: 0.37, lr: [0.007230582744071698], Loss: 2.101624, Acc:0.788249, Semantic loss: 0.802920, BCE loss: 0.535215, SB loss: 0.763489
2023-10-30 07:17:36,021 Epoch: [146/484] Iter:[220/495], Time: 0.37, lr: [0.007230193303979416], Loss: 2.097341, Acc:0.787297, Semantic loss: 0.800462, BCE loss: 0.534521, SB loss: 0.762358
2023-10-30 07:17:39,790 Epoch: [146/484] Iter:[230/495], Time: 0.37, lr: [0.007229803861556405], Loss: 2.094124, Acc:0.786829, Semantic loss: 0.797914, BCE loss: 0.535537, SB loss: 0.760673
2023-10-30 07:17:43,384 Epoch: [146/484] Iter:[240/495], Time: 0.37, lr: [0.007229414416802515], Loss: 2.091839, Acc:0.788182, Semantic loss: 0.796136, BCE loss: 0.535374, SB loss: 0.760330
2023-10-30 07:17:46,992 Epoch: [146/484] Iter:[250/495], Time: 0.37, lr: [0.007229024969717591], Loss: 2.095573, Acc:0.789116, Semantic loss: 0.796512, BCE loss: 0.538306, SB loss: 0.760755
2023-10-30 07:17:50,644 Epoch: [146/484] Iter:[260/495], Time: 0.37, lr: [0.007228635520301478], Loss: 2.092040, Acc:0.789619, Semantic loss: 0.794237, BCE loss: 0.538292, SB loss: 0.759511
2023-10-30 07:17:54,358 Epoch: [146/484] Iter:[270/495], Time: 0.37, lr: [0.007228246068554022], Loss: 2.093769, Acc:0.790085, Semantic loss: 0.794068, BCE loss: 0.540461, SB loss: 0.759240
2023-10-30 07:17:58,281 Epoch: [146/484] Iter:[280/495], Time: 0.37, lr: [0.007227856614475074], Loss: 2.088317, Acc:0.791035, Semantic loss: 0.791150, BCE loss: 0.539209, SB loss: 0.757958
2023-10-30 07:18:01,944 Epoch: [146/484] Iter:[290/495], Time: 0.37, lr: [0.007227467158064474], Loss: 2.090713, Acc:0.791428, Semantic loss: 0.790911, BCE loss: 0.540278, SB loss: 0.759525
2023-10-30 07:18:05,556 Epoch: [146/484] Iter:[300/495], Time: 0.37, lr: [0.007227077699322074], Loss: 2.092187, Acc:0.792354, Semantic loss: 0.790033, BCE loss: 0.543026, SB loss: 0.759129
2023-10-30 07:18:09,182 Epoch: [146/484] Iter:[310/495], Time: 0.37, lr: [0.0072266882382477195], Loss: 2.091955, Acc:0.792876, Semantic loss: 0.790092, BCE loss: 0.543099, SB loss: 0.758763
2023-10-30 07:18:12,806 Epoch: [146/484] Iter:[320/495], Time: 0.37, lr: [0.0072262987748412544], Loss: 2.094801, Acc:0.792770, Semantic loss: 0.791573, BCE loss: 0.543407, SB loss: 0.759821
2023-10-30 07:18:16,439 Epoch: [146/484] Iter:[330/495], Time: 0.37, lr: [0.007225909309102527], Loss: 2.098109, Acc:0.792256, Semantic loss: 0.792045, BCE loss: 0.545903, SB loss: 0.760161
2023-10-30 07:18:20,187 Epoch: [146/484] Iter:[340/495], Time: 0.37, lr: [0.007225519841031384], Loss: 2.096065, Acc:0.791662, Semantic loss: 0.792250, BCE loss: 0.543580, SB loss: 0.760235
2023-10-30 07:18:23,949 Epoch: [146/484] Iter:[350/495], Time: 0.37, lr: [0.007225130370627668], Loss: 2.099086, Acc:0.790849, Semantic loss: 0.793384, BCE loss: 0.545014, SB loss: 0.760688
2023-10-30 07:18:27,536 Epoch: [146/484] Iter:[360/495], Time: 0.37, lr: [0.007224740897891231], Loss: 2.098223, Acc:0.790826, Semantic loss: 0.791930, BCE loss: 0.546404, SB loss: 0.759889
2023-10-30 07:18:31,094 Epoch: [146/484] Iter:[370/495], Time: 0.37, lr: [0.007224351422821914], Loss: 2.099598, Acc:0.791334, Semantic loss: 0.791524, BCE loss: 0.548048, SB loss: 0.760026
2023-10-30 07:18:34,776 Epoch: [146/484] Iter:[380/495], Time: 0.37, lr: [0.007223961945419567], Loss: 2.096306, Acc:0.792177, Semantic loss: 0.789231, BCE loss: 0.548122, SB loss: 0.758954
2023-10-30 07:18:38,407 Epoch: [146/484] Iter:[390/495], Time: 0.37, lr: [0.007223572465684037], Loss: 2.099727, Acc:0.791968, Semantic loss: 0.792870, BCE loss: 0.547059, SB loss: 0.759798
2023-10-30 07:18:42,072 Epoch: [146/484] Iter:[400/495], Time: 0.37, lr: [0.007223182983615165], Loss: 2.096546, Acc:0.792464, Semantic loss: 0.789527, BCE loss: 0.548298, SB loss: 0.758720
2023-10-30 07:18:45,842 Epoch: [146/484] Iter:[410/495], Time: 0.37, lr: [0.007222793499212803], Loss: 2.100543, Acc:0.792189, Semantic loss: 0.790873, BCE loss: 0.549128, SB loss: 0.760542
2023-10-30 07:18:49,419 Epoch: [146/484] Iter:[420/495], Time: 0.37, lr: [0.007222404012476793], Loss: 2.103524, Acc:0.792548, Semantic loss: 0.792407, BCE loss: 0.549847, SB loss: 0.761269
2023-10-30 07:18:53,159 Epoch: [146/484] Iter:[430/495], Time: 0.37, lr: [0.007222014523406983], Loss: 2.096473, Acc:0.792895, Semantic loss: 0.788616, BCE loss: 0.548700, SB loss: 0.759157
2023-10-30 07:18:56,846 Epoch: [146/484] Iter:[440/495], Time: 0.37, lr: [0.007221625032003219], Loss: 2.093755, Acc:0.793323, Semantic loss: 0.786824, BCE loss: 0.548461, SB loss: 0.758470
2023-10-30 07:19:00,629 Epoch: [146/484] Iter:[450/495], Time: 0.37, lr: [0.0072212355382653476], Loss: 2.096241, Acc:0.793443, Semantic loss: 0.789075, BCE loss: 0.548113, SB loss: 0.759054
2023-10-30 07:19:04,330 Epoch: [146/484] Iter:[460/495], Time: 0.37, lr: [0.0072208460421932154], Loss: 2.098050, Acc:0.793335, Semantic loss: 0.790480, BCE loss: 0.547574, SB loss: 0.759997
2023-10-30 07:19:07,976 Epoch: [146/484] Iter:[470/495], Time: 0.37, lr: [0.007220456543786667], Loss: 2.096696, Acc:0.793203, Semantic loss: 0.790164, BCE loss: 0.546989, SB loss: 0.759543
2023-10-30 07:19:11,520 Epoch: [146/484] Iter:[480/495], Time: 0.37, lr: [0.007220067043045548], Loss: 2.096210, Acc:0.793222, Semantic loss: 0.789831, BCE loss: 0.546831, SB loss: 0.759548
2023-10-30 07:19:15,002 Epoch: [146/484] Iter:[490/495], Time: 0.37, lr: [0.007219677539969708], Loss: 2.092510, Acc:0.794111, Semantic loss: 0.787409, BCE loss: 0.546814, SB loss: 0.758286
2023-10-30 07:19:16,401 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:19:16,656 Loss: 2.106, MeanIU:  0.6463, Best_mIoU:  0.6907
2023-10-30 07:19:16,656 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561]
2023-10-30 07:19:18,870 Epoch: [147/484] Iter:[0/495], Time: 2.18, lr: [0.0072194827875562174], Loss: 3.192377, Acc:0.737150, Semantic loss: 1.298416, BCE loss: 0.727425, SB loss: 1.166536
2023-10-30 07:19:22,830 Epoch: [147/484] Iter:[10/495], Time: 0.56, lr: [0.007219093280978001], Loss: 2.247134, Acc:0.803432, Semantic loss: 0.875214, BCE loss: 0.560568, SB loss: 0.811352
2023-10-30 07:19:26,480 Epoch: [147/484] Iter:[20/495], Time: 0.47, lr: [0.007218703772064678], Loss: 2.115281, Acc:0.803232, Semantic loss: 0.795746, BCE loss: 0.546241, SB loss: 0.773295
2023-10-30 07:19:30,130 Epoch: [147/484] Iter:[30/495], Time: 0.43, lr: [0.007218314260816091], Loss: 2.098885, Acc:0.793973, Semantic loss: 0.782328, BCE loss: 0.545107, SB loss: 0.771450
2023-10-30 07:19:33,840 Epoch: [147/484] Iter:[40/495], Time: 0.42, lr: [0.007217924747232088], Loss: 2.106054, Acc:0.797859, Semantic loss: 0.801948, BCE loss: 0.539332, SB loss: 0.764774
2023-10-30 07:19:37,499 Epoch: [147/484] Iter:[50/495], Time: 0.41, lr: [0.007217535231312517], Loss: 2.129740, Acc:0.801351, Semantic loss: 0.812646, BCE loss: 0.548277, SB loss: 0.768816
2023-10-30 07:19:41,088 Epoch: [147/484] Iter:[60/495], Time: 0.40, lr: [0.0072171457130572195], Loss: 2.132618, Acc:0.798372, Semantic loss: 0.807358, BCE loss: 0.556313, SB loss: 0.768947
2023-10-30 07:19:44,761 Epoch: [147/484] Iter:[70/495], Time: 0.40, lr: [0.007216756192466044], Loss: 2.120845, Acc:0.793598, Semantic loss: 0.804553, BCE loss: 0.547570, SB loss: 0.768722
2023-10-30 07:19:48,350 Epoch: [147/484] Iter:[80/495], Time: 0.39, lr: [0.007216366669538836], Loss: 2.128653, Acc:0.786749, Semantic loss: 0.815972, BCE loss: 0.543540, SB loss: 0.769141
2023-10-30 07:19:51,991 Epoch: [147/484] Iter:[90/495], Time: 0.39, lr: [0.00721597714427544], Loss: 2.129329, Acc:0.786917, Semantic loss: 0.816057, BCE loss: 0.545046, SB loss: 0.768226
2023-10-30 07:19:55,615 Epoch: [147/484] Iter:[100/495], Time: 0.39, lr: [0.007215587616675704], Loss: 2.121560, Acc:0.792007, Semantic loss: 0.807627, BCE loss: 0.546142, SB loss: 0.767791
2023-10-30 07:19:59,284 Epoch: [147/484] Iter:[110/495], Time: 0.38, lr: [0.007215198086739473], Loss: 2.119491, Acc:0.792903, Semantic loss: 0.804021, BCE loss: 0.548759, SB loss: 0.766711
2023-10-30 07:20:02,891 Epoch: [147/484] Iter:[120/495], Time: 0.38, lr: [0.007214808554466593], Loss: 2.115197, Acc:0.796162, Semantic loss: 0.799938, BCE loss: 0.550575, SB loss: 0.764684
2023-10-30 07:20:06,596 Epoch: [147/484] Iter:[130/495], Time: 0.38, lr: [0.007214419019856909], Loss: 2.117222, Acc:0.793605, Semantic loss: 0.801671, BCE loss: 0.548122, SB loss: 0.767428
2023-10-30 07:20:10,357 Epoch: [147/484] Iter:[140/495], Time: 0.38, lr: [0.0072140294829102685], Loss: 2.120912, Acc:0.793569, Semantic loss: 0.805009, BCE loss: 0.548844, SB loss: 0.767060
2023-10-30 07:20:13,921 Epoch: [147/484] Iter:[150/495], Time: 0.38, lr: [0.0072136399436265155], Loss: 2.113043, Acc:0.792633, Semantic loss: 0.802037, BCE loss: 0.545124, SB loss: 0.765882
2023-10-30 07:20:17,487 Epoch: [147/484] Iter:[160/495], Time: 0.38, lr: [0.007213250402005497], Loss: 2.098567, Acc:0.793165, Semantic loss: 0.794067, BCE loss: 0.542144, SB loss: 0.762357
2023-10-30 07:20:21,083 Epoch: [147/484] Iter:[170/495], Time: 0.38, lr: [0.007212860858047057], Loss: 2.094535, Acc:0.792482, Semantic loss: 0.792156, BCE loss: 0.540943, SB loss: 0.761435
2023-10-30 07:20:24,689 Epoch: [147/484] Iter:[180/495], Time: 0.38, lr: [0.007212471311751043], Loss: 2.097067, Acc:0.791369, Semantic loss: 0.795753, BCE loss: 0.539552, SB loss: 0.761762
2023-10-30 07:20:28,435 Epoch: [147/484] Iter:[190/495], Time: 0.38, lr: [0.007212081763117299], Loss: 2.093991, Acc:0.790576, Semantic loss: 0.793725, BCE loss: 0.539144, SB loss: 0.761122
2023-10-30 07:20:32,176 Epoch: [147/484] Iter:[200/495], Time: 0.38, lr: [0.007211692212145673], Loss: 2.093586, Acc:0.792029, Semantic loss: 0.794631, BCE loss: 0.538430, SB loss: 0.760526
2023-10-30 07:20:35,791 Epoch: [147/484] Iter:[210/495], Time: 0.37, lr: [0.0072113026588360085], Loss: 2.103860, Acc:0.793068, Semantic loss: 0.797747, BCE loss: 0.543317, SB loss: 0.762796
2023-10-30 07:20:39,603 Epoch: [147/484] Iter:[220/495], Time: 0.38, lr: [0.0072109131031881536], Loss: 2.102168, Acc:0.793806, Semantic loss: 0.796454, BCE loss: 0.544038, SB loss: 0.761676
2023-10-30 07:20:43,417 Epoch: [147/484] Iter:[230/495], Time: 0.38, lr: [0.007210523545201951], Loss: 2.097809, Acc:0.793903, Semantic loss: 0.792997, BCE loss: 0.545383, SB loss: 0.759429
2023-10-30 07:20:47,033 Epoch: [147/484] Iter:[240/495], Time: 0.37, lr: [0.007210133984877249], Loss: 2.091867, Acc:0.794069, Semantic loss: 0.790664, BCE loss: 0.542553, SB loss: 0.758651
2023-10-30 07:20:50,681 Epoch: [147/484] Iter:[250/495], Time: 0.37, lr: [0.0072097444222138886], Loss: 2.087693, Acc:0.794436, Semantic loss: 0.788457, BCE loss: 0.542046, SB loss: 0.757190
2023-10-30 07:20:54,416 Epoch: [147/484] Iter:[260/495], Time: 0.37, lr: [0.00720935485721172], Loss: 2.081583, Acc:0.795629, Semantic loss: 0.785968, BCE loss: 0.539824, SB loss: 0.755790
2023-10-30 07:20:58,093 Epoch: [147/484] Iter:[270/495], Time: 0.37, lr: [0.007208965289870588], Loss: 2.088684, Acc:0.795256, Semantic loss: 0.788250, BCE loss: 0.543219, SB loss: 0.757215
2023-10-30 07:21:01,714 Epoch: [147/484] Iter:[280/495], Time: 0.37, lr: [0.007208575720190338], Loss: 2.085076, Acc:0.795511, Semantic loss: 0.785937, BCE loss: 0.544035, SB loss: 0.755104
2023-10-30 07:21:05,273 Epoch: [147/484] Iter:[290/495], Time: 0.37, lr: [0.007208186148170814], Loss: 2.086377, Acc:0.794473, Semantic loss: 0.786179, BCE loss: 0.544792, SB loss: 0.755405
2023-10-30 07:21:08,850 Epoch: [147/484] Iter:[300/495], Time: 0.37, lr: [0.007207796573811862], Loss: 2.088555, Acc:0.793476, Semantic loss: 0.788942, BCE loss: 0.543040, SB loss: 0.756574
2023-10-30 07:21:12,489 Epoch: [147/484] Iter:[310/495], Time: 0.37, lr: [0.007207406997113329], Loss: 2.087831, Acc:0.791631, Semantic loss: 0.789986, BCE loss: 0.541457, SB loss: 0.756389
2023-10-30 07:21:16,068 Epoch: [147/484] Iter:[320/495], Time: 0.37, lr: [0.007207017418075059], Loss: 2.088481, Acc:0.791157, Semantic loss: 0.790243, BCE loss: 0.540760, SB loss: 0.757478
2023-10-30 07:21:19,679 Epoch: [147/484] Iter:[330/495], Time: 0.37, lr: [0.007206627836696896], Loss: 2.085989, Acc:0.791621, Semantic loss: 0.789457, BCE loss: 0.540385, SB loss: 0.756147
2023-10-30 07:21:23,405 Epoch: [147/484] Iter:[340/495], Time: 0.37, lr: [0.007206238252978689], Loss: 2.085999, Acc:0.791131, Semantic loss: 0.788564, BCE loss: 0.540896, SB loss: 0.756538
2023-10-30 07:21:27,108 Epoch: [147/484] Iter:[350/495], Time: 0.37, lr: [0.007205848666920279], Loss: 2.080568, Acc:0.791491, Semantic loss: 0.784964, BCE loss: 0.539562, SB loss: 0.756042
2023-10-30 07:21:30,793 Epoch: [147/484] Iter:[360/495], Time: 0.37, lr: [0.007205459078521516], Loss: 2.082559, Acc:0.791281, Semantic loss: 0.786262, BCE loss: 0.539897, SB loss: 0.756400
2023-10-30 07:21:34,483 Epoch: [147/484] Iter:[370/495], Time: 0.37, lr: [0.007205069487782242], Loss: 2.081688, Acc:0.791322, Semantic loss: 0.785105, BCE loss: 0.539663, SB loss: 0.756920
2023-10-30 07:21:38,139 Epoch: [147/484] Iter:[380/495], Time: 0.37, lr: [0.007204679894702305], Loss: 2.077567, Acc:0.791169, Semantic loss: 0.783368, BCE loss: 0.537924, SB loss: 0.756275
2023-10-30 07:21:41,759 Epoch: [147/484] Iter:[390/495], Time: 0.37, lr: [0.007204290299281547], Loss: 2.077199, Acc:0.790986, Semantic loss: 0.784108, BCE loss: 0.536429, SB loss: 0.756661
2023-10-30 07:21:45,416 Epoch: [147/484] Iter:[400/495], Time: 0.37, lr: [0.007203900701519815], Loss: 2.080989, Acc:0.790978, Semantic loss: 0.787958, BCE loss: 0.535048, SB loss: 0.757983
2023-10-30 07:21:49,063 Epoch: [147/484] Iter:[410/495], Time: 0.37, lr: [0.0072035111014169565], Loss: 2.080351, Acc:0.791864, Semantic loss: 0.787169, BCE loss: 0.535455, SB loss: 0.757727
2023-10-30 07:21:52,776 Epoch: [147/484] Iter:[420/495], Time: 0.37, lr: [0.0072031214989728126], Loss: 2.077883, Acc:0.790978, Semantic loss: 0.785395, BCE loss: 0.535144, SB loss: 0.757344
2023-10-30 07:21:56,495 Epoch: [147/484] Iter:[430/495], Time: 0.37, lr: [0.007202731894187231], Loss: 2.081162, Acc:0.791240, Semantic loss: 0.786454, BCE loss: 0.536982, SB loss: 0.757726
2023-10-30 07:22:00,123 Epoch: [147/484] Iter:[440/495], Time: 0.37, lr: [0.007202342287060057], Loss: 2.080103, Acc:0.791056, Semantic loss: 0.785801, BCE loss: 0.536469, SB loss: 0.757834
2023-10-30 07:22:03,800 Epoch: [147/484] Iter:[450/495], Time: 0.37, lr: [0.0072019526775911336], Loss: 2.079333, Acc:0.792064, Semantic loss: 0.784876, BCE loss: 0.537390, SB loss: 0.757066
2023-10-30 07:22:07,478 Epoch: [147/484] Iter:[460/495], Time: 0.37, lr: [0.0072015630657803085], Loss: 2.082312, Acc:0.792591, Semantic loss: 0.786195, BCE loss: 0.537719, SB loss: 0.758399
2023-10-30 07:22:11,187 Epoch: [147/484] Iter:[470/495], Time: 0.37, lr: [0.007201173451627426], Loss: 2.081659, Acc:0.792585, Semantic loss: 0.785864, BCE loss: 0.537666, SB loss: 0.758129
2023-10-30 07:22:14,874 Epoch: [147/484] Iter:[480/495], Time: 0.37, lr: [0.007200783835132331], Loss: 2.081777, Acc:0.792540, Semantic loss: 0.785657, BCE loss: 0.537739, SB loss: 0.758380
2023-10-30 07:22:18,403 Epoch: [147/484] Iter:[490/495], Time: 0.37, lr: [0.007200394216294869], Loss: 2.081380, Acc:0.792797, Semantic loss: 0.785739, BCE loss: 0.537951, SB loss: 0.757690
2023-10-30 07:22:19,807 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:22:20,048 Loss: 2.106, MeanIU:  0.6463, Best_mIoU:  0.6907
2023-10-30 07:22:20,048 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561]
2023-10-30 07:22:22,088 Epoch: [148/484] Iter:[0/495], Time: 2.01, lr: [0.007200199405997702], Loss: 2.667553, Acc:0.835726, Semantic loss: 0.920596, BCE loss: 0.889390, SB loss: 0.857567
2023-10-30 07:22:26,058 Epoch: [148/484] Iter:[10/495], Time: 0.54, lr: [0.007199809783646396], Loss: 2.128888, Acc:0.782708, Semantic loss: 0.770540, BCE loss: 0.607252, SB loss: 0.751096
2023-10-30 07:22:30,014 Epoch: [148/484] Iter:[20/495], Time: 0.47, lr: [0.007199420158952338], Loss: 2.072573, Acc:0.788587, Semantic loss: 0.758041, BCE loss: 0.565489, SB loss: 0.749043
2023-10-30 07:22:33,830 Epoch: [148/484] Iter:[30/495], Time: 0.44, lr: [0.007199030531915371], Loss: 2.099852, Acc:0.793767, Semantic loss: 0.764455, BCE loss: 0.588186, SB loss: 0.747211
2023-10-30 07:22:37,412 Epoch: [148/484] Iter:[40/495], Time: 0.42, lr: [0.007198640902535338], Loss: 2.142543, Acc:0.800643, Semantic loss: 0.787176, BCE loss: 0.598804, SB loss: 0.756563
2023-10-30 07:22:41,014 Epoch: [148/484] Iter:[50/495], Time: 0.41, lr: [0.007198251270812086], Loss: 2.104738, Acc:0.797221, Semantic loss: 0.772584, BCE loss: 0.582416, SB loss: 0.749738
2023-10-30 07:22:44,718 Epoch: [148/484] Iter:[60/495], Time: 0.40, lr: [0.00719786163674546], Loss: 2.110270, Acc:0.797227, Semantic loss: 0.784078, BCE loss: 0.571597, SB loss: 0.754596
2023-10-30 07:22:48,439 Epoch: [148/484] Iter:[70/495], Time: 0.40, lr: [0.007197472000335302], Loss: 2.121342, Acc:0.800243, Semantic loss: 0.790962, BCE loss: 0.575848, SB loss: 0.754532
2023-10-30 07:22:52,131 Epoch: [148/484] Iter:[80/495], Time: 0.40, lr: [0.0071970823615814606], Loss: 2.146822, Acc:0.803493, Semantic loss: 0.804987, BCE loss: 0.584106, SB loss: 0.757728
2023-10-30 07:22:55,924 Epoch: [148/484] Iter:[90/495], Time: 0.39, lr: [0.00719669272048378], Loss: 2.160028, Acc:0.804549, Semantic loss: 0.812931, BCE loss: 0.580008, SB loss: 0.767088
2023-10-30 07:22:59,541 Epoch: [148/484] Iter:[100/495], Time: 0.39, lr: [0.007196303077042103], Loss: 2.175449, Acc:0.801945, Semantic loss: 0.825651, BCE loss: 0.578240, SB loss: 0.771558
2023-10-30 07:23:03,264 Epoch: [148/484] Iter:[110/495], Time: 0.39, lr: [0.007195913431256278], Loss: 2.180706, Acc:0.799662, Semantic loss: 0.827871, BCE loss: 0.579232, SB loss: 0.773602
2023-10-30 07:23:06,903 Epoch: [148/484] Iter:[120/495], Time: 0.39, lr: [0.007195523783126147], Loss: 2.172523, Acc:0.800502, Semantic loss: 0.818781, BCE loss: 0.577383, SB loss: 0.776360
2023-10-30 07:23:10,566 Epoch: [148/484] Iter:[130/495], Time: 0.39, lr: [0.007195134132651556], Loss: 2.181480, Acc:0.798686, Semantic loss: 0.823958, BCE loss: 0.580198, SB loss: 0.777323
2023-10-30 07:23:14,172 Epoch: [148/484] Iter:[140/495], Time: 0.38, lr: [0.0071947444798323495], Loss: 2.191532, Acc:0.794453, Semantic loss: 0.834146, BCE loss: 0.578609, SB loss: 0.778777
2023-10-30 07:23:17,791 Epoch: [148/484] Iter:[150/495], Time: 0.38, lr: [0.007194354824668371], Loss: 2.188588, Acc:0.789212, Semantic loss: 0.833566, BCE loss: 0.577104, SB loss: 0.777918
2023-10-30 07:23:21,550 Epoch: [148/484] Iter:[160/495], Time: 0.38, lr: [0.007193965167159468], Loss: 2.184522, Acc:0.791757, Semantic loss: 0.828478, BCE loss: 0.578440, SB loss: 0.777605
2023-10-30 07:23:25,212 Epoch: [148/484] Iter:[170/495], Time: 0.38, lr: [0.007193575507305482], Loss: 2.185230, Acc:0.790802, Semantic loss: 0.826987, BCE loss: 0.580472, SB loss: 0.777770
2023-10-30 07:23:28,892 Epoch: [148/484] Iter:[180/495], Time: 0.38, lr: [0.007193185845106261], Loss: 2.180782, Acc:0.790273, Semantic loss: 0.823927, BCE loss: 0.578715, SB loss: 0.778140
2023-10-30 07:23:32,582 Epoch: [148/484] Iter:[190/495], Time: 0.38, lr: [0.007192796180561649], Loss: 2.184194, Acc:0.793622, Semantic loss: 0.824934, BCE loss: 0.581569, SB loss: 0.777690
2023-10-30 07:23:36,388 Epoch: [148/484] Iter:[200/495], Time: 0.38, lr: [0.00719240651367149], Loss: 2.191715, Acc:0.793058, Semantic loss: 0.827105, BCE loss: 0.581493, SB loss: 0.783117
2023-10-30 07:23:40,091 Epoch: [148/484] Iter:[210/495], Time: 0.38, lr: [0.007192016844435628], Loss: 2.182320, Acc:0.793170, Semantic loss: 0.824121, BCE loss: 0.577339, SB loss: 0.780860
2023-10-30 07:23:43,787 Epoch: [148/484] Iter:[220/495], Time: 0.38, lr: [0.007191627172853908], Loss: 2.173984, Acc:0.792002, Semantic loss: 0.820636, BCE loss: 0.573992, SB loss: 0.779355
2023-10-30 07:23:47,437 Epoch: [148/484] Iter:[230/495], Time: 0.38, lr: [0.007191237498926176], Loss: 2.173237, Acc:0.793337, Semantic loss: 0.818805, BCE loss: 0.575600, SB loss: 0.778832
2023-10-30 07:23:51,079 Epoch: [148/484] Iter:[240/495], Time: 0.38, lr: [0.007190847822652275], Loss: 2.177012, Acc:0.793263, Semantic loss: 0.820742, BCE loss: 0.575153, SB loss: 0.781117
2023-10-30 07:23:55,003 Epoch: [148/484] Iter:[250/495], Time: 0.38, lr: [0.0071904581440320504], Loss: 2.177966, Acc:0.792191, Semantic loss: 0.824151, BCE loss: 0.572616, SB loss: 0.781199
2023-10-30 07:23:58,695 Epoch: [148/484] Iter:[260/495], Time: 0.38, lr: [0.0071900684630653465], Loss: 2.179477, Acc:0.792297, Semantic loss: 0.822620, BCE loss: 0.575887, SB loss: 0.780970
2023-10-30 07:24:02,348 Epoch: [148/484] Iter:[270/495], Time: 0.38, lr: [0.007189678779752009], Loss: 2.173868, Acc:0.791225, Semantic loss: 0.819937, BCE loss: 0.573644, SB loss: 0.780286
2023-10-30 07:24:06,073 Epoch: [148/484] Iter:[280/495], Time: 0.38, lr: [0.007189289094091881], Loss: 2.168514, Acc:0.791569, Semantic loss: 0.817279, BCE loss: 0.571953, SB loss: 0.779283
2023-10-30 07:24:09,850 Epoch: [148/484] Iter:[290/495], Time: 0.38, lr: [0.007188899406084807], Loss: 2.168582, Acc:0.791712, Semantic loss: 0.817630, BCE loss: 0.572270, SB loss: 0.778681
2023-10-30 07:24:13,539 Epoch: [148/484] Iter:[300/495], Time: 0.38, lr: [0.007188509715730631], Loss: 2.171634, Acc:0.792298, Semantic loss: 0.819026, BCE loss: 0.573093, SB loss: 0.779516
2023-10-30 07:24:17,227 Epoch: [148/484] Iter:[310/495], Time: 0.38, lr: [0.0071881200230292], Loss: 2.168120, Acc:0.791968, Semantic loss: 0.818117, BCE loss: 0.570736, SB loss: 0.779266
2023-10-30 07:24:20,870 Epoch: [148/484] Iter:[320/495], Time: 0.38, lr: [0.007187730327980356], Loss: 2.166901, Acc:0.792046, Semantic loss: 0.816728, BCE loss: 0.570703, SB loss: 0.779470
2023-10-30 07:24:24,504 Epoch: [148/484] Iter:[330/495], Time: 0.38, lr: [0.007187340630583945], Loss: 2.163193, Acc:0.793030, Semantic loss: 0.814567, BCE loss: 0.570787, SB loss: 0.777839
2023-10-30 07:24:28,151 Epoch: [148/484] Iter:[340/495], Time: 0.38, lr: [0.007186950930839811], Loss: 2.159923, Acc:0.793259, Semantic loss: 0.812946, BCE loss: 0.570453, SB loss: 0.776524
2023-10-30 07:24:31,703 Epoch: [148/484] Iter:[350/495], Time: 0.37, lr: [0.007186561228747799], Loss: 2.159018, Acc:0.793063, Semantic loss: 0.813632, BCE loss: 0.568941, SB loss: 0.776445
2023-10-30 07:24:35,323 Epoch: [148/484] Iter:[360/495], Time: 0.37, lr: [0.007186171524307751], Loss: 2.156535, Acc:0.792446, Semantic loss: 0.812887, BCE loss: 0.567809, SB loss: 0.775840
2023-10-30 07:24:39,003 Epoch: [148/484] Iter:[370/495], Time: 0.37, lr: [0.007185781817519514], Loss: 2.154056, Acc:0.791985, Semantic loss: 0.812310, BCE loss: 0.566039, SB loss: 0.775707
2023-10-30 07:24:42,660 Epoch: [148/484] Iter:[380/495], Time: 0.37, lr: [0.00718539210838293], Loss: 2.152770, Acc:0.792755, Semantic loss: 0.810355, BCE loss: 0.566617, SB loss: 0.775798
2023-10-30 07:24:46,437 Epoch: [148/484] Iter:[390/495], Time: 0.37, lr: [0.007185002396897846], Loss: 2.144494, Acc:0.792225, Semantic loss: 0.806824, BCE loss: 0.563853, SB loss: 0.773817
2023-10-30 07:24:50,076 Epoch: [148/484] Iter:[400/495], Time: 0.37, lr: [0.0071846126830641035], Loss: 2.144249, Acc:0.792021, Semantic loss: 0.806757, BCE loss: 0.563505, SB loss: 0.773988
2023-10-30 07:24:53,861 Epoch: [148/484] Iter:[410/495], Time: 0.37, lr: [0.007184222966881549], Loss: 2.139131, Acc:0.792125, Semantic loss: 0.805021, BCE loss: 0.561526, SB loss: 0.772584
2023-10-30 07:24:57,504 Epoch: [148/484] Iter:[420/495], Time: 0.37, lr: [0.007183833248350028], Loss: 2.142517, Acc:0.792939, Semantic loss: 0.806923, BCE loss: 0.563075, SB loss: 0.772519
2023-10-30 07:25:01,140 Epoch: [148/484] Iter:[430/495], Time: 0.37, lr: [0.007183443527469381], Loss: 2.138401, Acc:0.792924, Semantic loss: 0.804903, BCE loss: 0.562683, SB loss: 0.770815
2023-10-30 07:25:04,746 Epoch: [148/484] Iter:[440/495], Time: 0.37, lr: [0.0071830538042394546], Loss: 2.137624, Acc:0.792658, Semantic loss: 0.804759, BCE loss: 0.562027, SB loss: 0.770838
2023-10-30 07:25:08,442 Epoch: [148/484] Iter:[450/495], Time: 0.37, lr: [0.0071826640786600915], Loss: 2.133982, Acc:0.792059, Semantic loss: 0.803933, BCE loss: 0.560133, SB loss: 0.769916
2023-10-30 07:25:12,161 Epoch: [148/484] Iter:[460/495], Time: 0.37, lr: [0.0071822743507311375], Loss: 2.132496, Acc:0.792131, Semantic loss: 0.804698, BCE loss: 0.558779, SB loss: 0.769019
2023-10-30 07:25:15,802 Epoch: [148/484] Iter:[470/495], Time: 0.37, lr: [0.0071818846204524354], Loss: 2.130612, Acc:0.792272, Semantic loss: 0.804213, BCE loss: 0.557762, SB loss: 0.768637
2023-10-30 07:25:19,484 Epoch: [148/484] Iter:[480/495], Time: 0.37, lr: [0.007181494887823831], Loss: 2.129141, Acc:0.792191, Semantic loss: 0.802939, BCE loss: 0.557271, SB loss: 0.768931
2023-10-30 07:25:22,963 Epoch: [148/484] Iter:[490/495], Time: 0.37, lr: [0.007181105152845166], Loss: 2.128413, Acc:0.792839, Semantic loss: 0.801839, BCE loss: 0.558109, SB loss: 0.768465
2023-10-30 07:25:24,361 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:25:24,598 Loss: 2.106, MeanIU:  0.6463, Best_mIoU:  0.6907
2023-10-30 07:25:24,598 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561]
2023-10-30 07:25:26,700 Epoch: [149/484] Iter:[0/495], Time: 2.07, lr: [0.007180910284474515], Loss: 1.968833, Acc:0.809304, Semantic loss: 0.696771, BCE loss: 0.495382, SB loss: 0.776681
2023-10-30 07:25:30,856 Epoch: [149/484] Iter:[10/495], Time: 0.57, lr: [0.0071805205459704695], Loss: 2.040304, Acc:0.785708, Semantic loss: 0.737699, BCE loss: 0.560971, SB loss: 0.741634
2023-10-30 07:25:34,571 Epoch: [149/484] Iter:[20/495], Time: 0.47, lr: [0.0071801308051159755], Loss: 2.010354, Acc:0.782029, Semantic loss: 0.739697, BCE loss: 0.525296, SB loss: 0.745362
2023-10-30 07:25:38,167 Epoch: [149/484] Iter:[30/495], Time: 0.44, lr: [0.007179741061910877], Loss: 2.055546, Acc:0.791744, Semantic loss: 0.768242, BCE loss: 0.533648, SB loss: 0.753656
2023-10-30 07:25:41,879 Epoch: [149/484] Iter:[40/495], Time: 0.42, lr: [0.007179351316355017], Loss: 2.067474, Acc:0.791313, Semantic loss: 0.779266, BCE loss: 0.531348, SB loss: 0.756860
2023-10-30 07:25:45,496 Epoch: [149/484] Iter:[50/495], Time: 0.41, lr: [0.007178961568448241], Loss: 2.094944, Acc:0.799411, Semantic loss: 0.792832, BCE loss: 0.546365, SB loss: 0.755746
2023-10-30 07:25:49,140 Epoch: [149/484] Iter:[60/495], Time: 0.40, lr: [0.007178571818190392], Loss: 2.088006, Acc:0.796290, Semantic loss: 0.787214, BCE loss: 0.544350, SB loss: 0.756441
2023-10-30 07:25:52,796 Epoch: [149/484] Iter:[70/495], Time: 0.40, lr: [0.007178182065581315], Loss: 2.081891, Acc:0.797265, Semantic loss: 0.781159, BCE loss: 0.545112, SB loss: 0.755621
2023-10-30 07:25:56,405 Epoch: [149/484] Iter:[80/495], Time: 0.39, lr: [0.007177792310620853], Loss: 2.097190, Acc:0.794863, Semantic loss: 0.792084, BCE loss: 0.543332, SB loss: 0.761774
2023-10-30 07:26:00,057 Epoch: [149/484] Iter:[90/495], Time: 0.39, lr: [0.0071774025533088495], Loss: 2.096174, Acc:0.795884, Semantic loss: 0.791369, BCE loss: 0.544078, SB loss: 0.760727
2023-10-30 07:26:03,657 Epoch: [149/484] Iter:[100/495], Time: 0.39, lr: [0.0071770127936451504], Loss: 2.088356, Acc:0.794924, Semantic loss: 0.787857, BCE loss: 0.541851, SB loss: 0.758649
2023-10-30 07:26:07,312 Epoch: [149/484] Iter:[110/495], Time: 0.38, lr: [0.0071766230316295965], Loss: 2.084881, Acc:0.790764, Semantic loss: 0.784453, BCE loss: 0.539983, SB loss: 0.760445
2023-10-30 07:26:10,970 Epoch: [149/484] Iter:[120/495], Time: 0.38, lr: [0.007176233267262034], Loss: 2.088730, Acc:0.786325, Semantic loss: 0.786094, BCE loss: 0.540811, SB loss: 0.761826
2023-10-30 07:26:14,614 Epoch: [149/484] Iter:[130/495], Time: 0.38, lr: [0.007175843500542308], Loss: 2.111693, Acc:0.785766, Semantic loss: 0.803992, BCE loss: 0.540900, SB loss: 0.766801
2023-10-30 07:26:18,285 Epoch: [149/484] Iter:[140/495], Time: 0.38, lr: [0.007175453731470258], Loss: 2.110212, Acc:0.784970, Semantic loss: 0.801925, BCE loss: 0.541245, SB loss: 0.767043
2023-10-30 07:26:21,929 Epoch: [149/484] Iter:[150/495], Time: 0.38, lr: [0.007175063960045731], Loss: 2.101977, Acc:0.783705, Semantic loss: 0.797150, BCE loss: 0.540370, SB loss: 0.764458
2023-10-30 07:26:25,573 Epoch: [149/484] Iter:[160/495], Time: 0.38, lr: [0.007174674186268571], Loss: 2.099302, Acc:0.785226, Semantic loss: 0.795534, BCE loss: 0.538311, SB loss: 0.765457
2023-10-30 07:26:29,279 Epoch: [149/484] Iter:[170/495], Time: 0.38, lr: [0.0071742844101386205], Loss: 2.105884, Acc:0.787245, Semantic loss: 0.800130, BCE loss: 0.537179, SB loss: 0.768576
2023-10-30 07:26:32,923 Epoch: [149/484] Iter:[180/495], Time: 0.38, lr: [0.007173894631655725], Loss: 2.116208, Acc:0.787205, Semantic loss: 0.804467, BCE loss: 0.541590, SB loss: 0.770151
2023-10-30 07:26:36,593 Epoch: [149/484] Iter:[190/495], Time: 0.38, lr: [0.007173504850819726], Loss: 2.112704, Acc:0.786316, Semantic loss: 0.802441, BCE loss: 0.541080, SB loss: 0.769183
2023-10-30 07:26:40,275 Epoch: [149/484] Iter:[200/495], Time: 0.38, lr: [0.007173115067630468], Loss: 2.122261, Acc:0.787450, Semantic loss: 0.807563, BCE loss: 0.544118, SB loss: 0.770580
2023-10-30 07:26:43,992 Epoch: [149/484] Iter:[210/495], Time: 0.38, lr: [0.007172725282087795], Loss: 2.124091, Acc:0.789254, Semantic loss: 0.806786, BCE loss: 0.546527, SB loss: 0.770778
2023-10-30 07:26:47,680 Epoch: [149/484] Iter:[220/495], Time: 0.38, lr: [0.00717233549419155], Loss: 2.144346, Acc:0.788046, Semantic loss: 0.823027, BCE loss: 0.544648, SB loss: 0.776671
2023-10-30 07:26:51,334 Epoch: [149/484] Iter:[230/495], Time: 0.38, lr: [0.007171945703941579], Loss: 2.134256, Acc:0.788450, Semantic loss: 0.816876, BCE loss: 0.543521, SB loss: 0.773859
2023-10-30 07:26:54,956 Epoch: [149/484] Iter:[240/495], Time: 0.37, lr: [0.007171555911337723], Loss: 2.134683, Acc:0.788795, Semantic loss: 0.819261, BCE loss: 0.542838, SB loss: 0.772585
2023-10-30 07:26:58,668 Epoch: [149/484] Iter:[250/495], Time: 0.37, lr: [0.007171166116379827], Loss: 2.140060, Acc:0.788405, Semantic loss: 0.821268, BCE loss: 0.545574, SB loss: 0.773219
2023-10-30 07:27:02,244 Epoch: [149/484] Iter:[260/495], Time: 0.37, lr: [0.007170776319067734], Loss: 2.138678, Acc:0.789831, Semantic loss: 0.819563, BCE loss: 0.546081, SB loss: 0.773034
2023-10-30 07:27:05,898 Epoch: [149/484] Iter:[270/495], Time: 0.37, lr: [0.007170386519401288], Loss: 2.132169, Acc:0.788691, Semantic loss: 0.816614, BCE loss: 0.544034, SB loss: 0.771520
2023-10-30 07:27:09,609 Epoch: [149/484] Iter:[280/495], Time: 0.37, lr: [0.007169996717380332], Loss: 2.139562, Acc:0.789245, Semantic loss: 0.820901, BCE loss: 0.545011, SB loss: 0.773649
2023-10-30 07:27:13,273 Epoch: [149/484] Iter:[290/495], Time: 0.37, lr: [0.00716960691300471], Loss: 2.140316, Acc:0.789877, Semantic loss: 0.819299, BCE loss: 0.547115, SB loss: 0.773903
2023-10-30 07:27:16,923 Epoch: [149/484] Iter:[300/495], Time: 0.37, lr: [0.007169217106274265], Loss: 2.139740, Acc:0.789738, Semantic loss: 0.818554, BCE loss: 0.547958, SB loss: 0.773228
2023-10-30 07:27:20,720 Epoch: [149/484] Iter:[310/495], Time: 0.37, lr: [0.007168827297188841], Loss: 2.139642, Acc:0.789064, Semantic loss: 0.818518, BCE loss: 0.548522, SB loss: 0.772602
2023-10-30 07:27:24,396 Epoch: [149/484] Iter:[320/495], Time: 0.37, lr: [0.0071684374857482825], Loss: 2.141325, Acc:0.790896, Semantic loss: 0.820734, BCE loss: 0.548517, SB loss: 0.772075
2023-10-30 07:27:28,038 Epoch: [149/484] Iter:[330/495], Time: 0.37, lr: [0.0071680476719524315], Loss: 2.138684, Acc:0.790827, Semantic loss: 0.818523, BCE loss: 0.548693, SB loss: 0.771467
2023-10-30 07:27:31,811 Epoch: [149/484] Iter:[340/495], Time: 0.37, lr: [0.007167657855801132], Loss: 2.136904, Acc:0.791061, Semantic loss: 0.816675, BCE loss: 0.549474, SB loss: 0.770755
2023-10-30 07:27:35,428 Epoch: [149/484] Iter:[350/495], Time: 0.37, lr: [0.007167268037294227], Loss: 2.134322, Acc:0.792405, Semantic loss: 0.817104, BCE loss: 0.548120, SB loss: 0.769098
2023-10-30 07:27:39,208 Epoch: [149/484] Iter:[360/495], Time: 0.37, lr: [0.007166878216431559], Loss: 2.132910, Acc:0.792513, Semantic loss: 0.816070, BCE loss: 0.548561, SB loss: 0.768279
2023-10-30 07:27:42,785 Epoch: [149/484] Iter:[370/495], Time: 0.37, lr: [0.007166488393212975], Loss: 2.133215, Acc:0.792345, Semantic loss: 0.816650, BCE loss: 0.548364, SB loss: 0.768201
2023-10-30 07:27:46,457 Epoch: [149/484] Iter:[380/495], Time: 0.37, lr: [0.007166098567638313], Loss: 2.129059, Acc:0.792178, Semantic loss: 0.814360, BCE loss: 0.546617, SB loss: 0.768083
2023-10-30 07:27:50,224 Epoch: [149/484] Iter:[390/495], Time: 0.37, lr: [0.007165708739707422], Loss: 2.124952, Acc:0.792171, Semantic loss: 0.812307, BCE loss: 0.546405, SB loss: 0.766239
2023-10-30 07:27:53,925 Epoch: [149/484] Iter:[400/495], Time: 0.37, lr: [0.007165318909420141], Loss: 2.123071, Acc:0.792252, Semantic loss: 0.810137, BCE loss: 0.547716, SB loss: 0.765218
2023-10-30 07:27:57,593 Epoch: [149/484] Iter:[410/495], Time: 0.37, lr: [0.007164929076776317], Loss: 2.121542, Acc:0.792557, Semantic loss: 0.808992, BCE loss: 0.548382, SB loss: 0.764169
2023-10-30 07:28:01,257 Epoch: [149/484] Iter:[420/495], Time: 0.37, lr: [0.00716453924177579], Loss: 2.123249, Acc:0.792242, Semantic loss: 0.809683, BCE loss: 0.548824, SB loss: 0.764742
2023-10-30 07:28:04,909 Epoch: [149/484] Iter:[430/495], Time: 0.37, lr: [0.007164149404418403], Loss: 2.124990, Acc:0.792875, Semantic loss: 0.808502, BCE loss: 0.551549, SB loss: 0.764939
2023-10-30 07:28:08,663 Epoch: [149/484] Iter:[440/495], Time: 0.37, lr: [0.007163759564704002], Loss: 2.131330, Acc:0.792309, Semantic loss: 0.812589, BCE loss: 0.552991, SB loss: 0.765751
2023-10-30 07:28:12,510 Epoch: [149/484] Iter:[450/495], Time: 0.37, lr: [0.007163369722632429], Loss: 2.129354, Acc:0.792092, Semantic loss: 0.811062, BCE loss: 0.553002, SB loss: 0.765290
2023-10-30 07:28:16,167 Epoch: [149/484] Iter:[460/495], Time: 0.37, lr: [0.007162979878203526], Loss: 2.132616, Acc:0.791533, Semantic loss: 0.812357, BCE loss: 0.553482, SB loss: 0.766776
2023-10-30 07:28:19,857 Epoch: [149/484] Iter:[470/495], Time: 0.37, lr: [0.007162590031417139], Loss: 2.130192, Acc:0.791346, Semantic loss: 0.810910, BCE loss: 0.552893, SB loss: 0.766389
2023-10-30 07:28:23,852 Epoch: [149/484] Iter:[480/495], Time: 0.37, lr: [0.0071622001822731094], Loss: 2.130175, Acc:0.791278, Semantic loss: 0.811499, BCE loss: 0.551906, SB loss: 0.766770
2023-10-30 07:28:27,338 Epoch: [149/484] Iter:[490/495], Time: 0.37, lr: [0.00716181033077128], Loss: 2.130649, Acc:0.791918, Semantic loss: 0.810874, BCE loss: 0.552933, SB loss: 0.766841
2023-10-30 07:28:28,739 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:28:28,981 Loss: 2.106, MeanIU:  0.6463, Best_mIoU:  0.6907
2023-10-30 07:28:28,981 [0.9730529  0.79591874 0.89446212 0.42784615 0.51194282 0.56098149
 0.6276927  0.69014812 0.90519824 0.54623358 0.93188163 0.73640495
 0.48315389 0.92231576 0.59451137 0.44924684 0.33142043 0.2639191
 0.63383561]
2023-10-30 07:28:31,115 Epoch: [150/484] Iter:[0/495], Time: 2.10, lr: [0.007161615404136143], Loss: 1.859596, Acc:0.781502, Semantic loss: 0.613591, BCE loss: 0.543138, SB loss: 0.702867
2023-10-30 07:28:35,100 Epoch: [150/484] Iter:[10/495], Time: 0.55, lr: [0.00716122554909732], Loss: 2.107533, Acc:0.824270, Semantic loss: 0.805244, BCE loss: 0.548476, SB loss: 0.753813
2023-10-30 07:28:38,879 Epoch: [150/484] Iter:[20/495], Time: 0.47, lr: [0.0071608356917003055], Loss: 2.105660, Acc:0.827659, Semantic loss: 0.790717, BCE loss: 0.555759, SB loss: 0.759185
2023-10-30 07:28:42,568 Epoch: [150/484] Iter:[30/495], Time: 0.44, lr: [0.007160445831944944], Loss: 2.061339, Acc:0.819131, Semantic loss: 0.769774, BCE loss: 0.547337, SB loss: 0.744229
2023-10-30 07:28:46,204 Epoch: [150/484] Iter:[40/495], Time: 0.42, lr: [0.007160055969831076], Loss: 2.043424, Acc:0.816546, Semantic loss: 0.758141, BCE loss: 0.542229, SB loss: 0.743054
2023-10-30 07:28:49,817 Epoch: [150/484] Iter:[50/495], Time: 0.41, lr: [0.007159666105358547], Loss: 2.059991, Acc:0.807899, Semantic loss: 0.777271, BCE loss: 0.544884, SB loss: 0.737836
2023-10-30 07:28:53,440 Epoch: [150/484] Iter:[60/495], Time: 0.40, lr: [0.007159276238527197], Loss: 2.040509, Acc:0.803878, Semantic loss: 0.768017, BCE loss: 0.538018, SB loss: 0.734473
2023-10-30 07:28:57,169 Epoch: [150/484] Iter:[70/495], Time: 0.40, lr: [0.0071588863693368724], Loss: 2.088867, Acc:0.803397, Semantic loss: 0.793788, BCE loss: 0.542530, SB loss: 0.752550
2023-10-30 07:29:00,899 Epoch: [150/484] Iter:[80/495], Time: 0.39, lr: [0.007158496497787413], Loss: 2.086922, Acc:0.801942, Semantic loss: 0.791569, BCE loss: 0.545276, SB loss: 0.750078
2023-10-30 07:29:04,697 Epoch: [150/484] Iter:[90/495], Time: 0.39, lr: [0.007158106623878665], Loss: 2.086020, Acc:0.799383, Semantic loss: 0.787159, BCE loss: 0.549386, SB loss: 0.749475
2023-10-30 07:29:08,472 Epoch: [150/484] Iter:[100/495], Time: 0.39, lr: [0.007157716747610468], Loss: 2.080142, Acc:0.801945, Semantic loss: 0.782261, BCE loss: 0.547736, SB loss: 0.750145
2023-10-30 07:29:12,136 Epoch: [150/484] Iter:[110/495], Time: 0.39, lr: [0.007157326868982667], Loss: 2.073559, Acc:0.801374, Semantic loss: 0.778578, BCE loss: 0.546064, SB loss: 0.748917
2023-10-30 07:29:15,817 Epoch: [150/484] Iter:[120/495], Time: 0.39, lr: [0.007156936987995104], Loss: 2.062577, Acc:0.803833, Semantic loss: 0.773621, BCE loss: 0.542911, SB loss: 0.746045
2023-10-30 07:29:19,466 Epoch: [150/484] Iter:[130/495], Time: 0.39, lr: [0.007156547104647623], Loss: 2.062308, Acc:0.804369, Semantic loss: 0.776065, BCE loss: 0.540217, SB loss: 0.746027
2023-10-30 07:29:23,132 Epoch: [150/484] Iter:[140/495], Time: 0.38, lr: [0.0071561572189400655], Loss: 2.071677, Acc:0.802317, Semantic loss: 0.782225, BCE loss: 0.539850, SB loss: 0.749603
2023-10-30 07:29:26,780 Epoch: [150/484] Iter:[150/495], Time: 0.38, lr: [0.007155767330872277], Loss: 2.079626, Acc:0.799277, Semantic loss: 0.788271, BCE loss: 0.539840, SB loss: 0.751515
2023-10-30 07:29:30,551 Epoch: [150/484] Iter:[160/495], Time: 0.38, lr: [0.007155377440444096], Loss: 2.083035, Acc:0.799542, Semantic loss: 0.792455, BCE loss: 0.538258, SB loss: 0.752322
2023-10-30 07:29:34,256 Epoch: [150/484] Iter:[170/495], Time: 0.38, lr: [0.00715498754765537], Loss: 2.076621, Acc:0.798181, Semantic loss: 0.787838, BCE loss: 0.538305, SB loss: 0.750477
2023-10-30 07:29:37,951 Epoch: [150/484] Iter:[180/495], Time: 0.38, lr: [0.007154597652505937], Loss: 2.082264, Acc:0.799051, Semantic loss: 0.790546, BCE loss: 0.539929, SB loss: 0.751789
2023-10-30 07:29:41,546 Epoch: [150/484] Iter:[190/495], Time: 0.38, lr: [0.007154207754995643], Loss: 2.082837, Acc:0.796632, Semantic loss: 0.791002, BCE loss: 0.540609, SB loss: 0.751226
2023-10-30 07:29:45,133 Epoch: [150/484] Iter:[200/495], Time: 0.38, lr: [0.00715381785512433], Loss: 2.079829, Acc:0.797401, Semantic loss: 0.787461, BCE loss: 0.542005, SB loss: 0.750362
2023-10-30 07:29:48,799 Epoch: [150/484] Iter:[210/495], Time: 0.38, lr: [0.00715342795289184], Loss: 2.077736, Acc:0.796765, Semantic loss: 0.788489, BCE loss: 0.538679, SB loss: 0.750567
2023-10-30 07:29:52,451 Epoch: [150/484] Iter:[220/495], Time: 0.38, lr: [0.007153038048298017], Loss: 2.078288, Acc:0.796568, Semantic loss: 0.789220, BCE loss: 0.537828, SB loss: 0.751240
2023-10-30 07:29:56,196 Epoch: [150/484] Iter:[230/495], Time: 0.38, lr: [0.007152648141342703], Loss: 2.079783, Acc:0.794360, Semantic loss: 0.788397, BCE loss: 0.538356, SB loss: 0.753030
2023-10-30 07:29:59,919 Epoch: [150/484] Iter:[240/495], Time: 0.38, lr: [0.007152258232025741], Loss: 2.079144, Acc:0.794905, Semantic loss: 0.785204, BCE loss: 0.540316, SB loss: 0.753625
2023-10-30 07:30:03,556 Epoch: [150/484] Iter:[250/495], Time: 0.38, lr: [0.007151868320346973], Loss: 2.077855, Acc:0.794370, Semantic loss: 0.785113, BCE loss: 0.539312, SB loss: 0.753429
2023-10-30 07:30:07,308 Epoch: [150/484] Iter:[260/495], Time: 0.38, lr: [0.007151478406306242], Loss: 2.075507, Acc:0.794959, Semantic loss: 0.783510, BCE loss: 0.539452, SB loss: 0.752544
2023-10-30 07:30:10,915 Epoch: [150/484] Iter:[270/495], Time: 0.38, lr: [0.00715108848990339], Loss: 2.076600, Acc:0.793483, Semantic loss: 0.785627, BCE loss: 0.537421, SB loss: 0.753552
2023-10-30 07:30:14,545 Epoch: [150/484] Iter:[280/495], Time: 0.38, lr: [0.0071506985711382596], Loss: 2.073675, Acc:0.794041, Semantic loss: 0.784283, BCE loss: 0.536563, SB loss: 0.752828
2023-10-30 07:30:18,303 Epoch: [150/484] Iter:[290/495], Time: 0.38, lr: [0.0071503086500106965], Loss: 2.071324, Acc:0.795359, Semantic loss: 0.783190, BCE loss: 0.535428, SB loss: 0.752706
2023-10-30 07:30:21,972 Epoch: [150/484] Iter:[300/495], Time: 0.38, lr: [0.007149918726520539], Loss: 2.070959, Acc:0.795322, Semantic loss: 0.783452, BCE loss: 0.534070, SB loss: 0.753436
2023-10-30 07:30:25,623 Epoch: [150/484] Iter:[310/495], Time: 0.37, lr: [0.007149528800667632], Loss: 2.070583, Acc:0.795096, Semantic loss: 0.783427, BCE loss: 0.533549, SB loss: 0.753607
2023-10-30 07:30:29,288 Epoch: [150/484] Iter:[320/495], Time: 0.37, lr: [0.007149138872451816], Loss: 2.067893, Acc:0.794457, Semantic loss: 0.782110, BCE loss: 0.533715, SB loss: 0.752069
2023-10-30 07:30:32,964 Epoch: [150/484] Iter:[330/495], Time: 0.37, lr: [0.0071487489418729355], Loss: 2.071187, Acc:0.795274, Semantic loss: 0.783368, BCE loss: 0.536384, SB loss: 0.751435
2023-10-30 07:30:36,752 Epoch: [150/484] Iter:[340/495], Time: 0.37, lr: [0.007148359008930832], Loss: 2.071597, Acc:0.795701, Semantic loss: 0.784004, BCE loss: 0.536504, SB loss: 0.751089
2023-10-30 07:30:40,408 Epoch: [150/484] Iter:[350/495], Time: 0.37, lr: [0.007147969073625348], Loss: 2.069705, Acc:0.796502, Semantic loss: 0.781673, BCE loss: 0.537661, SB loss: 0.750371
2023-10-30 07:30:44,143 Epoch: [150/484] Iter:[360/495], Time: 0.37, lr: [0.0071475791359563254], Loss: 2.070003, Acc:0.794940, Semantic loss: 0.781822, BCE loss: 0.537745, SB loss: 0.750436
2023-10-30 07:30:47,922 Epoch: [150/484] Iter:[370/495], Time: 0.37, lr: [0.007147189195923609], Loss: 2.067653, Acc:0.795410, Semantic loss: 0.780266, BCE loss: 0.537442, SB loss: 0.749945
2023-10-30 07:30:51,575 Epoch: [150/484] Iter:[380/495], Time: 0.37, lr: [0.0071467992535270385], Loss: 2.070470, Acc:0.795830, Semantic loss: 0.781748, BCE loss: 0.537505, SB loss: 0.751216
2023-10-30 07:30:55,266 Epoch: [150/484] Iter:[390/495], Time: 0.37, lr: [0.007146409308766457], Loss: 2.071453, Acc:0.796725, Semantic loss: 0.782401, BCE loss: 0.538103, SB loss: 0.750949
2023-10-30 07:30:58,973 Epoch: [150/484] Iter:[400/495], Time: 0.37, lr: [0.007146019361641708], Loss: 2.075177, Acc:0.796041, Semantic loss: 0.784044, BCE loss: 0.539130, SB loss: 0.752003
2023-10-30 07:31:02,633 Epoch: [150/484] Iter:[410/495], Time: 0.37, lr: [0.007145629412152632], Loss: 2.075841, Acc:0.796154, Semantic loss: 0.784183, BCE loss: 0.540000, SB loss: 0.751659
2023-10-30 07:31:06,404 Epoch: [150/484] Iter:[420/495], Time: 0.37, lr: [0.007145239460299073], Loss: 2.071217, Acc:0.796430, Semantic loss: 0.781684, BCE loss: 0.539192, SB loss: 0.750341
2023-10-30 07:31:10,158 Epoch: [150/484] Iter:[430/495], Time: 0.37, lr: [0.007144849506080872], Loss: 2.069499, Acc:0.797030, Semantic loss: 0.780197, BCE loss: 0.539875, SB loss: 0.749427
2023-10-30 07:31:13,825 Epoch: [150/484] Iter:[440/495], Time: 0.37, lr: [0.0071444595494978705], Loss: 2.071709, Acc:0.796692, Semantic loss: 0.782670, BCE loss: 0.539627, SB loss: 0.749412
2023-10-30 07:31:17,486 Epoch: [150/484] Iter:[450/495], Time: 0.37, lr: [0.007144069590549913], Loss: 2.072024, Acc:0.796500, Semantic loss: 0.782397, BCE loss: 0.539805, SB loss: 0.749822
2023-10-30 07:31:21,102 Epoch: [150/484] Iter:[460/495], Time: 0.37, lr: [0.0071436796292368415], Loss: 2.075180, Acc:0.796574, Semantic loss: 0.784836, BCE loss: 0.539664, SB loss: 0.750680
2023-10-30 07:31:24,708 Epoch: [150/484] Iter:[470/495], Time: 0.37, lr: [0.007143289665558497], Loss: 2.074994, Acc:0.796618, Semantic loss: 0.784164, BCE loss: 0.539416, SB loss: 0.751414
2023-10-30 07:31:28,346 Epoch: [150/484] Iter:[480/495], Time: 0.37, lr: [0.007142899699514721], Loss: 2.074521, Acc:0.796116, Semantic loss: 0.784491, BCE loss: 0.538145, SB loss: 0.751884
2023-10-30 07:31:31,868 Epoch: [150/484] Iter:[490/495], Time: 0.37, lr: [0.007142509731105358], Loss: 2.071108, Acc:0.795541, Semantic loss: 0.782988, BCE loss: 0.536729, SB loss: 0.751391
2023-10-30 07:34:27,945 0 [0.93361011 0.59815225 0.80829945 0.15476398 0.23081613 0.39466748
 0.41623002 0.58808137 0.88221861 0.37546347 0.81735878 0.60181381
 0.01260897 0.80033749 0.00367282 0.04899341 0.04442091 0.01670075
 0.60076903] 0.4383673066697681
2023-10-30 07:34:27,946 1 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634] 0.6774301230729785
2023-10-30 07:34:27,949 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:34:28,180 Loss: 2.027, MeanIU:  0.6774, Best_mIoU:  0.6907
2023-10-30 07:34:28,180 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634]
2023-10-30 07:34:30,237 Epoch: [151/484] Iter:[0/495], Time: 2.02, lr: [0.007142314746013531], Loss: 2.060547, Acc:0.781403, Semantic loss: 0.760972, BCE loss: 0.570275, SB loss: 0.729299
2023-10-30 07:34:33,866 Epoch: [151/484] Iter:[10/495], Time: 0.51, lr: [0.007141924774055489], Loss: 1.922657, Acc:0.788465, Semantic loss: 0.736337, BCE loss: 0.469542, SB loss: 0.716778
2023-10-30 07:34:37,407 Epoch: [151/484] Iter:[20/495], Time: 0.44, lr: [0.007141534799731463], Loss: 1.946394, Acc:0.788822, Semantic loss: 0.723152, BCE loss: 0.498673, SB loss: 0.724570
2023-10-30 07:34:40,838 Epoch: [151/484] Iter:[30/495], Time: 0.41, lr: [0.007141144823041298], Loss: 2.011837, Acc:0.791469, Semantic loss: 0.748742, BCE loss: 0.520109, SB loss: 0.742986
2023-10-30 07:34:44,351 Epoch: [151/484] Iter:[40/495], Time: 0.39, lr: [0.0071407548439848334], Loss: 2.006190, Acc:0.795517, Semantic loss: 0.753276, BCE loss: 0.517025, SB loss: 0.735888
2023-10-30 07:34:47,852 Epoch: [151/484] Iter:[50/495], Time: 0.39, lr: [0.007140364862561912], Loss: 2.013596, Acc:0.796112, Semantic loss: 0.752155, BCE loss: 0.527772, SB loss: 0.733669
2023-10-30 07:34:51,327 Epoch: [151/484] Iter:[60/495], Time: 0.38, lr: [0.007139974878772376], Loss: 2.045143, Acc:0.796569, Semantic loss: 0.763854, BCE loss: 0.542007, SB loss: 0.739281
2023-10-30 07:34:54,907 Epoch: [151/484] Iter:[70/495], Time: 0.38, lr: [0.007139584892616068], Loss: 2.060521, Acc:0.794258, Semantic loss: 0.774428, BCE loss: 0.540174, SB loss: 0.745920
2023-10-30 07:34:58,514 Epoch: [151/484] Iter:[80/495], Time: 0.37, lr: [0.007139194904092827], Loss: 2.066909, Acc:0.793988, Semantic loss: 0.778086, BCE loss: 0.542004, SB loss: 0.746819
2023-10-30 07:35:02,055 Epoch: [151/484] Iter:[90/495], Time: 0.37, lr: [0.0071388049132025], Loss: 2.087025, Acc:0.795878, Semantic loss: 0.787315, BCE loss: 0.548518, SB loss: 0.751193
2023-10-30 07:35:05,701 Epoch: [151/484] Iter:[100/495], Time: 0.37, lr: [0.007138414919944924], Loss: 2.072061, Acc:0.796656, Semantic loss: 0.779437, BCE loss: 0.546508, SB loss: 0.746116
2023-10-30 07:35:09,241 Epoch: [151/484] Iter:[110/495], Time: 0.37, lr: [0.007138024924319945], Loss: 2.083581, Acc:0.795005, Semantic loss: 0.787260, BCE loss: 0.547639, SB loss: 0.748682
2023-10-30 07:35:12,854 Epoch: [151/484] Iter:[120/495], Time: 0.37, lr: [0.007137634926327402], Loss: 2.070343, Acc:0.792818, Semantic loss: 0.779654, BCE loss: 0.543978, SB loss: 0.746711
2023-10-30 07:35:16,567 Epoch: [151/484] Iter:[130/495], Time: 0.37, lr: [0.007137244925967138], Loss: 2.070952, Acc:0.794247, Semantic loss: 0.778135, BCE loss: 0.542724, SB loss: 0.750093
2023-10-30 07:35:20,084 Epoch: [151/484] Iter:[140/495], Time: 0.37, lr: [0.0071368549232389954], Loss: 2.056951, Acc:0.794941, Semantic loss: 0.771964, BCE loss: 0.539238, SB loss: 0.745749
2023-10-30 07:35:23,687 Epoch: [151/484] Iter:[150/495], Time: 0.37, lr: [0.007136464918142816], Loss: 2.064620, Acc:0.796402, Semantic loss: 0.777081, BCE loss: 0.540326, SB loss: 0.747212
2023-10-30 07:35:27,354 Epoch: [151/484] Iter:[160/495], Time: 0.37, lr: [0.007136074910678438], Loss: 2.064014, Acc:0.796280, Semantic loss: 0.775217, BCE loss: 0.540388, SB loss: 0.748409
2023-10-30 07:35:30,941 Epoch: [151/484] Iter:[170/495], Time: 0.37, lr: [0.007135684900845708], Loss: 2.075855, Acc:0.796332, Semantic loss: 0.779221, BCE loss: 0.543597, SB loss: 0.753037
2023-10-30 07:35:34,511 Epoch: [151/484] Iter:[180/495], Time: 0.37, lr: [0.007135294888644466], Loss: 2.071578, Acc:0.795043, Semantic loss: 0.776542, BCE loss: 0.542883, SB loss: 0.752153
2023-10-30 07:35:38,123 Epoch: [151/484] Iter:[190/495], Time: 0.37, lr: [0.007134904874074555], Loss: 2.078776, Acc:0.794632, Semantic loss: 0.781543, BCE loss: 0.543898, SB loss: 0.753335
2023-10-30 07:35:41,838 Epoch: [151/484] Iter:[200/495], Time: 0.37, lr: [0.007134514857135814], Loss: 2.075486, Acc:0.795032, Semantic loss: 0.780245, BCE loss: 0.541444, SB loss: 0.753798
2023-10-30 07:35:45,347 Epoch: [151/484] Iter:[210/495], Time: 0.37, lr: [0.007134124837828088], Loss: 2.080936, Acc:0.795184, Semantic loss: 0.785052, BCE loss: 0.539640, SB loss: 0.756244
2023-10-30 07:35:48,937 Epoch: [151/484] Iter:[220/495], Time: 0.37, lr: [0.007133734816151216], Loss: 2.078293, Acc:0.794370, Semantic loss: 0.786223, BCE loss: 0.535599, SB loss: 0.756472
2023-10-30 07:35:52,569 Epoch: [151/484] Iter:[230/495], Time: 0.37, lr: [0.007133344792105041], Loss: 2.076479, Acc:0.794131, Semantic loss: 0.786677, BCE loss: 0.533366, SB loss: 0.756436
2023-10-30 07:35:56,216 Epoch: [151/484] Iter:[240/495], Time: 0.37, lr: [0.007132954765689404], Loss: 2.078433, Acc:0.794031, Semantic loss: 0.785527, BCE loss: 0.535313, SB loss: 0.757593
2023-10-30 07:35:59,885 Epoch: [151/484] Iter:[250/495], Time: 0.37, lr: [0.007132564736904147], Loss: 2.077889, Acc:0.794629, Semantic loss: 0.784406, BCE loss: 0.536428, SB loss: 0.757056
2023-10-30 07:36:03,620 Epoch: [151/484] Iter:[260/495], Time: 0.37, lr: [0.007132174705749112], Loss: 2.077514, Acc:0.793193, Semantic loss: 0.783965, BCE loss: 0.537134, SB loss: 0.756414
2023-10-30 07:36:07,271 Epoch: [151/484] Iter:[270/495], Time: 0.37, lr: [0.00713178467222414], Loss: 2.083439, Acc:0.792884, Semantic loss: 0.786434, BCE loss: 0.539530, SB loss: 0.757476
2023-10-30 07:36:10,933 Epoch: [151/484] Iter:[280/495], Time: 0.37, lr: [0.007131394636329073], Loss: 2.087274, Acc:0.792111, Semantic loss: 0.787846, BCE loss: 0.540101, SB loss: 0.759326
2023-10-30 07:36:14,554 Epoch: [151/484] Iter:[290/495], Time: 0.37, lr: [0.007131004598063752], Loss: 2.085814, Acc:0.793585, Semantic loss: 0.786855, BCE loss: 0.540534, SB loss: 0.758424
2023-10-30 07:36:18,262 Epoch: [151/484] Iter:[300/495], Time: 0.37, lr: [0.00713061455742802], Loss: 2.087846, Acc:0.793459, Semantic loss: 0.787633, BCE loss: 0.541715, SB loss: 0.758498
2023-10-30 07:36:21,939 Epoch: [151/484] Iter:[310/495], Time: 0.37, lr: [0.007130224514421717], Loss: 2.084383, Acc:0.792092, Semantic loss: 0.785937, BCE loss: 0.540444, SB loss: 0.758002
2023-10-30 07:36:25,512 Epoch: [151/484] Iter:[320/495], Time: 0.37, lr: [0.007129834469044684], Loss: 2.087417, Acc:0.791925, Semantic loss: 0.787956, BCE loss: 0.540695, SB loss: 0.758766
2023-10-30 07:36:29,039 Epoch: [151/484] Iter:[330/495], Time: 0.37, lr: [0.0071294444212967635], Loss: 2.084165, Acc:0.792380, Semantic loss: 0.785391, BCE loss: 0.541102, SB loss: 0.757671
2023-10-30 07:36:32,668 Epoch: [151/484] Iter:[340/495], Time: 0.36, lr: [0.007129054371177798], Loss: 2.080694, Acc:0.792306, Semantic loss: 0.784142, BCE loss: 0.539846, SB loss: 0.756706
2023-10-30 07:36:36,301 Epoch: [151/484] Iter:[350/495], Time: 0.36, lr: [0.0071286643186876265], Loss: 2.078630, Acc:0.792521, Semantic loss: 0.783192, BCE loss: 0.540008, SB loss: 0.755430
2023-10-30 07:36:40,043 Epoch: [151/484] Iter:[360/495], Time: 0.37, lr: [0.007128274263826093], Loss: 2.079026, Acc:0.793420, Semantic loss: 0.782515, BCE loss: 0.541436, SB loss: 0.755075
2023-10-30 07:36:43,658 Epoch: [151/484] Iter:[370/495], Time: 0.37, lr: [0.007127884206593038], Loss: 2.078884, Acc:0.793520, Semantic loss: 0.782510, BCE loss: 0.541724, SB loss: 0.754650
2023-10-30 07:36:47,292 Epoch: [151/484] Iter:[380/495], Time: 0.37, lr: [0.0071274941469883024], Loss: 2.080788, Acc:0.794033, Semantic loss: 0.783276, BCE loss: 0.541529, SB loss: 0.755984
2023-10-30 07:36:50,893 Epoch: [151/484] Iter:[390/495], Time: 0.36, lr: [0.007127104085011726], Loss: 2.081516, Acc:0.794587, Semantic loss: 0.784201, BCE loss: 0.540804, SB loss: 0.756512
2023-10-30 07:36:54,624 Epoch: [151/484] Iter:[400/495], Time: 0.37, lr: [0.0071267140206631545], Loss: 2.083047, Acc:0.795125, Semantic loss: 0.784776, BCE loss: 0.541684, SB loss: 0.756588
2023-10-30 07:36:58,289 Epoch: [151/484] Iter:[410/495], Time: 0.37, lr: [0.007126323953942425], Loss: 2.085502, Acc:0.794815, Semantic loss: 0.785466, BCE loss: 0.543833, SB loss: 0.756203
2023-10-30 07:37:01,986 Epoch: [151/484] Iter:[420/495], Time: 0.37, lr: [0.0071259338848493805], Loss: 2.088904, Acc:0.794830, Semantic loss: 0.787650, BCE loss: 0.544334, SB loss: 0.756920
2023-10-30 07:37:05,720 Epoch: [151/484] Iter:[430/495], Time: 0.37, lr: [0.0071255438133838635], Loss: 2.087699, Acc:0.795532, Semantic loss: 0.786844, BCE loss: 0.544113, SB loss: 0.756743
2023-10-30 07:37:09,448 Epoch: [151/484] Iter:[440/495], Time: 0.37, lr: [0.007125153739545713], Loss: 2.093027, Acc:0.795180, Semantic loss: 0.789627, BCE loss: 0.545219, SB loss: 0.758181
2023-10-30 07:37:13,141 Epoch: [151/484] Iter:[450/495], Time: 0.37, lr: [0.007124763663334771], Loss: 2.093371, Acc:0.794889, Semantic loss: 0.790569, BCE loss: 0.544796, SB loss: 0.758005
2023-10-30 07:37:16,830 Epoch: [151/484] Iter:[460/495], Time: 0.37, lr: [0.0071243735847508795], Loss: 2.088969, Acc:0.794860, Semantic loss: 0.788355, BCE loss: 0.543068, SB loss: 0.757546
2023-10-30 07:37:20,509 Epoch: [151/484] Iter:[470/495], Time: 0.37, lr: [0.0071239835037938785], Loss: 2.090392, Acc:0.794653, Semantic loss: 0.789010, BCE loss: 0.543581, SB loss: 0.757802
2023-10-30 07:37:24,202 Epoch: [151/484] Iter:[480/495], Time: 0.37, lr: [0.00712359342046361], Loss: 2.092960, Acc:0.794759, Semantic loss: 0.789708, BCE loss: 0.544256, SB loss: 0.758997
2023-10-30 07:37:27,673 Epoch: [151/484] Iter:[490/495], Time: 0.37, lr: [0.007123203334759915], Loss: 2.092947, Acc:0.794087, Semantic loss: 0.789736, BCE loss: 0.543977, SB loss: 0.759233
2023-10-30 07:37:29,073 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:37:29,313 Loss: 2.027, MeanIU:  0.6774, Best_mIoU:  0.6907
2023-10-30 07:37:29,313 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634]
2023-10-30 07:37:31,504 Epoch: [152/484] Iter:[0/495], Time: 2.16, lr: [0.007123008291017982], Loss: 1.712907, Acc:0.884210, Semantic loss: 0.569601, BCE loss: 0.477581, SB loss: 0.665724
2023-10-30 07:37:35,455 Epoch: [152/484] Iter:[10/495], Time: 0.56, lr: [0.00712261820175385], Loss: 2.420262, Acc:0.787822, Semantic loss: 0.991633, BCE loss: 0.603609, SB loss: 0.825020
2023-10-30 07:37:39,097 Epoch: [152/484] Iter:[20/495], Time: 0.46, lr: [0.007122228110115893], Loss: 2.249545, Acc:0.791994, Semantic loss: 0.876765, BCE loss: 0.561297, SB loss: 0.811483
2023-10-30 07:37:42,775 Epoch: [152/484] Iter:[30/495], Time: 0.43, lr: [0.007121838016103955], Loss: 2.168901, Acc:0.788255, Semantic loss: 0.835061, BCE loss: 0.547656, SB loss: 0.786184
2023-10-30 07:37:46,427 Epoch: [152/484] Iter:[40/495], Time: 0.42, lr: [0.007121447919717875], Loss: 2.193996, Acc:0.799048, Semantic loss: 0.850929, BCE loss: 0.564207, SB loss: 0.778860
2023-10-30 07:37:50,061 Epoch: [152/484] Iter:[50/495], Time: 0.41, lr: [0.007121057820957494], Loss: 2.199996, Acc:0.795664, Semantic loss: 0.848553, BCE loss: 0.562540, SB loss: 0.788903
2023-10-30 07:37:53,659 Epoch: [152/484] Iter:[60/495], Time: 0.40, lr: [0.0071206677198226535], Loss: 2.162878, Acc:0.799375, Semantic loss: 0.825504, BCE loss: 0.555231, SB loss: 0.782144
2023-10-30 07:37:57,394 Epoch: [152/484] Iter:[70/495], Time: 0.40, lr: [0.007120277616313194], Loss: 2.143617, Acc:0.799836, Semantic loss: 0.815970, BCE loss: 0.550291, SB loss: 0.777357
2023-10-30 07:38:01,004 Epoch: [152/484] Iter:[80/495], Time: 0.39, lr: [0.007119887510428957], Loss: 2.140506, Acc:0.800435, Semantic loss: 0.814253, BCE loss: 0.550371, SB loss: 0.775881
2023-10-30 07:38:04,754 Epoch: [152/484] Iter:[90/495], Time: 0.39, lr: [0.007119497402169784], Loss: 2.133059, Acc:0.797459, Semantic loss: 0.808469, BCE loss: 0.549458, SB loss: 0.775131
2023-10-30 07:38:08,307 Epoch: [152/484] Iter:[100/495], Time: 0.39, lr: [0.007119107291535516], Loss: 2.131493, Acc:0.797385, Semantic loss: 0.807989, BCE loss: 0.548604, SB loss: 0.774900
2023-10-30 07:38:11,925 Epoch: [152/484] Iter:[110/495], Time: 0.38, lr: [0.007118717178525993], Loss: 2.128962, Acc:0.797060, Semantic loss: 0.807921, BCE loss: 0.549786, SB loss: 0.771255
2023-10-30 07:38:15,628 Epoch: [152/484] Iter:[120/495], Time: 0.38, lr: [0.007118327063141056], Loss: 2.134314, Acc:0.795888, Semantic loss: 0.809562, BCE loss: 0.553097, SB loss: 0.771655
2023-10-30 07:38:19,295 Epoch: [152/484] Iter:[130/495], Time: 0.38, lr: [0.007117936945380547], Loss: 2.136319, Acc:0.796789, Semantic loss: 0.806918, BCE loss: 0.556862, SB loss: 0.772539
2023-10-30 07:38:23,054 Epoch: [152/484] Iter:[140/495], Time: 0.38, lr: [0.007117546825244304], Loss: 2.121819, Acc:0.794875, Semantic loss: 0.800194, BCE loss: 0.551753, SB loss: 0.769872
2023-10-30 07:38:26,665 Epoch: [152/484] Iter:[150/495], Time: 0.38, lr: [0.007117156702732171], Loss: 2.120980, Acc:0.792213, Semantic loss: 0.799111, BCE loss: 0.550400, SB loss: 0.771469
2023-10-30 07:38:30,394 Epoch: [152/484] Iter:[160/495], Time: 0.38, lr: [0.007116766577843988], Loss: 2.118446, Acc:0.792100, Semantic loss: 0.796158, BCE loss: 0.551038, SB loss: 0.771249
2023-10-30 07:38:33,979 Epoch: [152/484] Iter:[170/495], Time: 0.38, lr: [0.007116376450579596], Loss: 2.118518, Acc:0.790391, Semantic loss: 0.796642, BCE loss: 0.549810, SB loss: 0.772067
2023-10-30 07:38:37,602 Epoch: [152/484] Iter:[180/495], Time: 0.38, lr: [0.007115986320938834], Loss: 2.114566, Acc:0.791286, Semantic loss: 0.793983, BCE loss: 0.550235, SB loss: 0.770348
2023-10-30 07:38:41,317 Epoch: [152/484] Iter:[190/495], Time: 0.38, lr: [0.007115596188921546], Loss: 2.115904, Acc:0.791833, Semantic loss: 0.797173, BCE loss: 0.549476, SB loss: 0.769255
2023-10-30 07:38:44,933 Epoch: [152/484] Iter:[200/495], Time: 0.38, lr: [0.007115206054527569], Loss: 2.116988, Acc:0.792793, Semantic loss: 0.796792, BCE loss: 0.552433, SB loss: 0.767763
2023-10-30 07:38:48,635 Epoch: [152/484] Iter:[210/495], Time: 0.38, lr: [0.007114815917756745], Loss: 2.105337, Acc:0.791066, Semantic loss: 0.792505, BCE loss: 0.547686, SB loss: 0.765146
2023-10-30 07:38:52,259 Epoch: [152/484] Iter:[220/495], Time: 0.38, lr: [0.0071144257786089175], Loss: 2.098785, Acc:0.791359, Semantic loss: 0.788961, BCE loss: 0.546401, SB loss: 0.763422
2023-10-30 07:38:55,941 Epoch: [152/484] Iter:[230/495], Time: 0.37, lr: [0.007114035637083922], Loss: 2.104302, Acc:0.791645, Semantic loss: 0.795345, BCE loss: 0.543455, SB loss: 0.765502
2023-10-30 07:38:59,687 Epoch: [152/484] Iter:[240/495], Time: 0.37, lr: [0.007113645493181604], Loss: 2.100186, Acc:0.790915, Semantic loss: 0.794370, BCE loss: 0.540047, SB loss: 0.765769
2023-10-30 07:39:03,326 Epoch: [152/484] Iter:[250/495], Time: 0.37, lr: [0.007113255346901802], Loss: 2.097504, Acc:0.791179, Semantic loss: 0.795056, BCE loss: 0.538027, SB loss: 0.764422
2023-10-30 07:39:06,958 Epoch: [152/484] Iter:[260/495], Time: 0.37, lr: [0.007112865198244357], Loss: 2.097069, Acc:0.791372, Semantic loss: 0.794052, BCE loss: 0.539930, SB loss: 0.763086
2023-10-30 07:39:10,574 Epoch: [152/484] Iter:[270/495], Time: 0.37, lr: [0.007112475047209109], Loss: 2.095508, Acc:0.791493, Semantic loss: 0.792832, BCE loss: 0.540677, SB loss: 0.761999
2023-10-30 07:39:14,114 Epoch: [152/484] Iter:[280/495], Time: 0.37, lr: [0.0071120848937958996], Loss: 2.090468, Acc:0.790833, Semantic loss: 0.790531, BCE loss: 0.537794, SB loss: 0.762143
2023-10-30 07:39:17,766 Epoch: [152/484] Iter:[290/495], Time: 0.37, lr: [0.007111694738004567], Loss: 2.090509, Acc:0.791334, Semantic loss: 0.790991, BCE loss: 0.537342, SB loss: 0.762177
2023-10-30 07:39:21,412 Epoch: [152/484] Iter:[300/495], Time: 0.37, lr: [0.007111304579834955], Loss: 2.087381, Acc:0.791200, Semantic loss: 0.790438, BCE loss: 0.536426, SB loss: 0.760517
2023-10-30 07:39:25,199 Epoch: [152/484] Iter:[310/495], Time: 0.37, lr: [0.007110914419286902], Loss: 2.085858, Acc:0.791882, Semantic loss: 0.789373, BCE loss: 0.536320, SB loss: 0.760166
2023-10-30 07:39:28,967 Epoch: [152/484] Iter:[320/495], Time: 0.37, lr: [0.00711052425636025], Loss: 2.091064, Acc:0.793185, Semantic loss: 0.791539, BCE loss: 0.537018, SB loss: 0.762508
2023-10-30 07:39:32,620 Epoch: [152/484] Iter:[330/495], Time: 0.37, lr: [0.007110134091054839], Loss: 2.087991, Acc:0.792804, Semantic loss: 0.791482, BCE loss: 0.534472, SB loss: 0.762038
2023-10-30 07:39:36,294 Epoch: [152/484] Iter:[340/495], Time: 0.37, lr: [0.007109743923370508], Loss: 2.088446, Acc:0.793003, Semantic loss: 0.789635, BCE loss: 0.536594, SB loss: 0.762217
2023-10-30 07:39:40,009 Epoch: [152/484] Iter:[350/495], Time: 0.37, lr: [0.007109353753307099], Loss: 2.095612, Acc:0.792239, Semantic loss: 0.794729, BCE loss: 0.537476, SB loss: 0.763407
2023-10-30 07:39:43,798 Epoch: [152/484] Iter:[360/495], Time: 0.37, lr: [0.007108963580864451], Loss: 2.099431, Acc:0.792697, Semantic loss: 0.796123, BCE loss: 0.539674, SB loss: 0.763635
2023-10-30 07:39:47,586 Epoch: [152/484] Iter:[370/495], Time: 0.37, lr: [0.007108573406042405], Loss: 2.098135, Acc:0.792770, Semantic loss: 0.794573, BCE loss: 0.540663, SB loss: 0.762899
2023-10-30 07:39:51,385 Epoch: [152/484] Iter:[380/495], Time: 0.37, lr: [0.007108183228840804], Loss: 2.095548, Acc:0.793541, Semantic loss: 0.793579, BCE loss: 0.539589, SB loss: 0.762380
2023-10-30 07:39:55,079 Epoch: [152/484] Iter:[390/495], Time: 0.37, lr: [0.007107793049259483], Loss: 2.096456, Acc:0.793873, Semantic loss: 0.793517, BCE loss: 0.540915, SB loss: 0.762023
2023-10-30 07:39:58,797 Epoch: [152/484] Iter:[400/495], Time: 0.37, lr: [0.0071074028672982875], Loss: 2.101266, Acc:0.793430, Semantic loss: 0.795417, BCE loss: 0.543111, SB loss: 0.762738
2023-10-30 07:40:02,476 Epoch: [152/484] Iter:[410/495], Time: 0.37, lr: [0.007107012682957055], Loss: 2.098535, Acc:0.793885, Semantic loss: 0.794417, BCE loss: 0.541967, SB loss: 0.762150
2023-10-30 07:40:06,190 Epoch: [152/484] Iter:[420/495], Time: 0.37, lr: [0.007106622496235627], Loss: 2.097984, Acc:0.794498, Semantic loss: 0.793912, BCE loss: 0.542007, SB loss: 0.762065
2023-10-30 07:40:09,799 Epoch: [152/484] Iter:[430/495], Time: 0.37, lr: [0.007106232307133843], Loss: 2.100955, Acc:0.794580, Semantic loss: 0.795116, BCE loss: 0.543360, SB loss: 0.762479
2023-10-30 07:40:13,490 Epoch: [152/484] Iter:[440/495], Time: 0.37, lr: [0.007105842115651544], Loss: 2.102818, Acc:0.794420, Semantic loss: 0.796052, BCE loss: 0.543547, SB loss: 0.763219
2023-10-30 07:40:17,082 Epoch: [152/484] Iter:[450/495], Time: 0.37, lr: [0.007105451921788568], Loss: 2.103283, Acc:0.793562, Semantic loss: 0.796130, BCE loss: 0.543599, SB loss: 0.763554
2023-10-30 07:40:20,849 Epoch: [152/484] Iter:[460/495], Time: 0.37, lr: [0.007105061725544759], Loss: 2.107479, Acc:0.793609, Semantic loss: 0.800419, BCE loss: 0.543286, SB loss: 0.763774
2023-10-30 07:40:24,398 Epoch: [152/484] Iter:[470/495], Time: 0.37, lr: [0.007104671526919954], Loss: 2.103723, Acc:0.793604, Semantic loss: 0.798513, BCE loss: 0.542133, SB loss: 0.763077
2023-10-30 07:40:28,077 Epoch: [152/484] Iter:[480/495], Time: 0.37, lr: [0.007104281325913995], Loss: 2.101822, Acc:0.793512, Semantic loss: 0.797559, BCE loss: 0.541640, SB loss: 0.762622
2023-10-30 07:40:31,581 Epoch: [152/484] Iter:[490/495], Time: 0.37, lr: [0.007103891122526721], Loss: 2.102146, Acc:0.792739, Semantic loss: 0.798152, BCE loss: 0.540579, SB loss: 0.763415
2023-10-30 07:40:32,981 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:40:33,218 Loss: 2.027, MeanIU:  0.6774, Best_mIoU:  0.6907
2023-10-30 07:40:33,219 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634]
2023-10-30 07:40:35,303 Epoch: [153/484] Iter:[0/495], Time: 2.05, lr: [0.007103696019940041], Loss: 1.941057, Acc:0.886543, Semantic loss: 0.665249, BCE loss: 0.586415, SB loss: 0.689393
2023-10-30 07:40:39,364 Epoch: [153/484] Iter:[10/495], Time: 0.56, lr: [0.007103305812980496], Loss: 2.116748, Acc:0.807285, Semantic loss: 0.798111, BCE loss: 0.538686, SB loss: 0.779950
2023-10-30 07:40:42,998 Epoch: [153/484] Iter:[20/495], Time: 0.46, lr: [0.007102915603639237], Loss: 2.074318, Acc:0.791104, Semantic loss: 0.763495, BCE loss: 0.540611, SB loss: 0.770212
2023-10-30 07:40:46,624 Epoch: [153/484] Iter:[30/495], Time: 0.43, lr: [0.007102525391916104], Loss: 2.043470, Acc:0.789860, Semantic loss: 0.741942, BCE loss: 0.548142, SB loss: 0.753385
2023-10-30 07:40:50,360 Epoch: [153/484] Iter:[40/495], Time: 0.42, lr: [0.007102135177810934], Loss: 2.011178, Acc:0.794099, Semantic loss: 0.738937, BCE loss: 0.532837, SB loss: 0.739404
2023-10-30 07:40:53,999 Epoch: [153/484] Iter:[50/495], Time: 0.41, lr: [0.007101744961323572], Loss: 2.010127, Acc:0.793650, Semantic loss: 0.746658, BCE loss: 0.524371, SB loss: 0.739098
2023-10-30 07:40:57,591 Epoch: [153/484] Iter:[60/495], Time: 0.40, lr: [0.007101354742453856], Loss: 2.015281, Acc:0.794510, Semantic loss: 0.752936, BCE loss: 0.526205, SB loss: 0.736140
2023-10-30 07:41:01,208 Epoch: [153/484] Iter:[70/495], Time: 0.39, lr: [0.007100964521201627], Loss: 2.023875, Acc:0.791701, Semantic loss: 0.761944, BCE loss: 0.527783, SB loss: 0.734147
2023-10-30 07:41:04,846 Epoch: [153/484] Iter:[80/495], Time: 0.39, lr: [0.007100574297566723], Loss: 2.045549, Acc:0.788442, Semantic loss: 0.772651, BCE loss: 0.533230, SB loss: 0.739667
2023-10-30 07:41:08,436 Epoch: [153/484] Iter:[90/495], Time: 0.39, lr: [0.007100184071548985], Loss: 2.049968, Acc:0.789291, Semantic loss: 0.775708, BCE loss: 0.536167, SB loss: 0.738094
2023-10-30 07:41:12,069 Epoch: [153/484] Iter:[100/495], Time: 0.38, lr: [0.0070997938431482535], Loss: 2.054850, Acc:0.789356, Semantic loss: 0.774853, BCE loss: 0.538075, SB loss: 0.741922
2023-10-30 07:41:15,820 Epoch: [153/484] Iter:[110/495], Time: 0.38, lr: [0.007099403612364366], Loss: 2.046883, Acc:0.793265, Semantic loss: 0.775902, BCE loss: 0.531386, SB loss: 0.739595
2023-10-30 07:41:19,466 Epoch: [153/484] Iter:[120/495], Time: 0.38, lr: [0.007099013379197165], Loss: 2.064951, Acc:0.796444, Semantic loss: 0.785393, BCE loss: 0.532041, SB loss: 0.747516
2023-10-30 07:41:23,082 Epoch: [153/484] Iter:[130/495], Time: 0.38, lr: [0.007098623143646489], Loss: 2.078790, Acc:0.795861, Semantic loss: 0.790660, BCE loss: 0.540424, SB loss: 0.747706
2023-10-30 07:41:26,737 Epoch: [153/484] Iter:[140/495], Time: 0.38, lr: [0.00709823290571218], Loss: 2.082802, Acc:0.793857, Semantic loss: 0.793836, BCE loss: 0.538870, SB loss: 0.750097
2023-10-30 07:41:30,454 Epoch: [153/484] Iter:[150/495], Time: 0.38, lr: [0.007097842665394075], Loss: 2.073669, Acc:0.795123, Semantic loss: 0.786669, BCE loss: 0.537863, SB loss: 0.749137
2023-10-30 07:41:34,062 Epoch: [153/484] Iter:[160/495], Time: 0.38, lr: [0.007097452422692016], Loss: 2.080166, Acc:0.794959, Semantic loss: 0.791144, BCE loss: 0.539899, SB loss: 0.749123
2023-10-30 07:41:37,680 Epoch: [153/484] Iter:[170/495], Time: 0.38, lr: [0.007097062177605841], Loss: 2.086185, Acc:0.795607, Semantic loss: 0.794443, BCE loss: 0.539324, SB loss: 0.752419
2023-10-30 07:41:41,355 Epoch: [153/484] Iter:[180/495], Time: 0.38, lr: [0.007096671930135391], Loss: 2.084332, Acc:0.797250, Semantic loss: 0.792477, BCE loss: 0.541299, SB loss: 0.750556
2023-10-30 07:41:44,977 Epoch: [153/484] Iter:[190/495], Time: 0.38, lr: [0.007096281680280504], Loss: 2.083392, Acc:0.796785, Semantic loss: 0.790225, BCE loss: 0.542168, SB loss: 0.750999
2023-10-30 07:41:48,597 Epoch: [153/484] Iter:[200/495], Time: 0.37, lr: [0.007095891428041023], Loss: 2.080095, Acc:0.796128, Semantic loss: 0.788636, BCE loss: 0.541871, SB loss: 0.749588
2023-10-30 07:41:52,281 Epoch: [153/484] Iter:[210/495], Time: 0.37, lr: [0.007095501173416783], Loss: 2.079762, Acc:0.796949, Semantic loss: 0.789054, BCE loss: 0.541831, SB loss: 0.748878
2023-10-30 07:41:55,989 Epoch: [153/484] Iter:[220/495], Time: 0.37, lr: [0.0070951109164076286], Loss: 2.080390, Acc:0.794492, Semantic loss: 0.788217, BCE loss: 0.543206, SB loss: 0.748967
2023-10-30 07:41:59,723 Epoch: [153/484] Iter:[230/495], Time: 0.37, lr: [0.007094720657013397], Loss: 2.083093, Acc:0.793772, Semantic loss: 0.789855, BCE loss: 0.543182, SB loss: 0.750056
2023-10-30 07:42:03,339 Epoch: [153/484] Iter:[240/495], Time: 0.37, lr: [0.007094330395233929], Loss: 2.080632, Acc:0.794716, Semantic loss: 0.787385, BCE loss: 0.542979, SB loss: 0.750268
2023-10-30 07:42:07,038 Epoch: [153/484] Iter:[250/495], Time: 0.37, lr: [0.0070939401310690636], Loss: 2.074582, Acc:0.794548, Semantic loss: 0.784773, BCE loss: 0.540482, SB loss: 0.749327
2023-10-30 07:42:10,697 Epoch: [153/484] Iter:[260/495], Time: 0.37, lr: [0.007093549864518638], Loss: 2.074711, Acc:0.794293, Semantic loss: 0.785435, BCE loss: 0.540189, SB loss: 0.749086
2023-10-30 07:42:14,397 Epoch: [153/484] Iter:[270/495], Time: 0.37, lr: [0.007093159595582495], Loss: 2.081003, Acc:0.793987, Semantic loss: 0.789453, BCE loss: 0.541070, SB loss: 0.750480
2023-10-30 07:42:18,091 Epoch: [153/484] Iter:[280/495], Time: 0.37, lr: [0.007092769324260474], Loss: 2.090459, Acc:0.794121, Semantic loss: 0.794396, BCE loss: 0.543075, SB loss: 0.752988
2023-10-30 07:42:21,713 Epoch: [153/484] Iter:[290/495], Time: 0.37, lr: [0.007092379050552412], Loss: 2.092698, Acc:0.794655, Semantic loss: 0.795046, BCE loss: 0.544207, SB loss: 0.753446
2023-10-30 07:42:25,267 Epoch: [153/484] Iter:[300/495], Time: 0.37, lr: [0.007091988774458151], Loss: 2.091199, Acc:0.795010, Semantic loss: 0.793630, BCE loss: 0.543278, SB loss: 0.754290
2023-10-30 07:42:28,990 Epoch: [153/484] Iter:[310/495], Time: 0.37, lr: [0.007091598495977532], Loss: 2.090285, Acc:0.793758, Semantic loss: 0.792350, BCE loss: 0.542340, SB loss: 0.755595
2023-10-30 07:42:32,609 Epoch: [153/484] Iter:[320/495], Time: 0.37, lr: [0.0070912082151103895], Loss: 2.096582, Acc:0.793806, Semantic loss: 0.797083, BCE loss: 0.541990, SB loss: 0.757508
2023-10-30 07:42:36,279 Epoch: [153/484] Iter:[330/495], Time: 0.37, lr: [0.007090817931856567], Loss: 2.100559, Acc:0.792196, Semantic loss: 0.799570, BCE loss: 0.541398, SB loss: 0.759591
2023-10-30 07:42:39,986 Epoch: [153/484] Iter:[340/495], Time: 0.37, lr: [0.007090427646215903], Loss: 2.093376, Acc:0.792854, Semantic loss: 0.794422, BCE loss: 0.540384, SB loss: 0.758571
2023-10-30 07:42:43,648 Epoch: [153/484] Iter:[350/495], Time: 0.37, lr: [0.007090037358188235], Loss: 2.094739, Acc:0.792467, Semantic loss: 0.793786, BCE loss: 0.541475, SB loss: 0.759477
2023-10-30 07:42:47,314 Epoch: [153/484] Iter:[360/495], Time: 0.37, lr: [0.007089647067773405], Loss: 2.093607, Acc:0.793667, Semantic loss: 0.792571, BCE loss: 0.542239, SB loss: 0.758798
2023-10-30 07:42:50,987 Epoch: [153/484] Iter:[370/495], Time: 0.37, lr: [0.00708925677497125], Loss: 2.096438, Acc:0.794699, Semantic loss: 0.792756, BCE loss: 0.544215, SB loss: 0.759467
2023-10-30 07:42:54,597 Epoch: [153/484] Iter:[380/495], Time: 0.37, lr: [0.007088866479781611], Loss: 2.094399, Acc:0.795427, Semantic loss: 0.791598, BCE loss: 0.544244, SB loss: 0.758557
2023-10-30 07:42:58,344 Epoch: [153/484] Iter:[390/495], Time: 0.37, lr: [0.007088476182204329], Loss: 2.092600, Acc:0.795552, Semantic loss: 0.791012, BCE loss: 0.544266, SB loss: 0.757322
2023-10-30 07:43:02,064 Epoch: [153/484] Iter:[400/495], Time: 0.37, lr: [0.00708808588223924], Loss: 2.094477, Acc:0.795954, Semantic loss: 0.792225, BCE loss: 0.544339, SB loss: 0.757913
2023-10-30 07:43:05,612 Epoch: [153/484] Iter:[410/495], Time: 0.37, lr: [0.007087695579886186], Loss: 2.099381, Acc:0.796254, Semantic loss: 0.795376, BCE loss: 0.544859, SB loss: 0.759147
2023-10-30 07:43:09,287 Epoch: [153/484] Iter:[420/495], Time: 0.37, lr: [0.007087305275145003], Loss: 2.101107, Acc:0.796420, Semantic loss: 0.795329, BCE loss: 0.544940, SB loss: 0.760838
2023-10-30 07:43:12,910 Epoch: [153/484] Iter:[430/495], Time: 0.37, lr: [0.007086914968015532], Loss: 2.097806, Acc:0.796084, Semantic loss: 0.792720, BCE loss: 0.544907, SB loss: 0.760179
2023-10-30 07:43:16,607 Epoch: [153/484] Iter:[440/495], Time: 0.37, lr: [0.007086524658497614], Loss: 2.095490, Acc:0.796033, Semantic loss: 0.790475, BCE loss: 0.545383, SB loss: 0.759632
2023-10-30 07:43:20,336 Epoch: [153/484] Iter:[450/495], Time: 0.37, lr: [0.007086134346591086], Loss: 2.094381, Acc:0.796372, Semantic loss: 0.789725, BCE loss: 0.544654, SB loss: 0.760001
2023-10-30 07:43:24,031 Epoch: [153/484] Iter:[460/495], Time: 0.37, lr: [0.007085744032295786], Loss: 2.095954, Acc:0.796264, Semantic loss: 0.790287, BCE loss: 0.546274, SB loss: 0.759393
2023-10-30 07:43:27,717 Epoch: [153/484] Iter:[470/495], Time: 0.37, lr: [0.007085353715611558], Loss: 2.097379, Acc:0.796557, Semantic loss: 0.791412, BCE loss: 0.546098, SB loss: 0.759870
2023-10-30 07:43:31,337 Epoch: [153/484] Iter:[480/495], Time: 0.37, lr: [0.007084963396538238], Loss: 2.098793, Acc:0.796338, Semantic loss: 0.792632, BCE loss: 0.546540, SB loss: 0.759622
2023-10-30 07:43:34,877 Epoch: [153/484] Iter:[490/495], Time: 0.37, lr: [0.007084573075075665], Loss: 2.095488, Acc:0.796979, Semantic loss: 0.790745, BCE loss: 0.546117, SB loss: 0.758626
2023-10-30 07:43:36,278 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:43:36,515 Loss: 2.027, MeanIU:  0.6774, Best_mIoU:  0.6907
2023-10-30 07:43:36,515 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634]
2023-10-30 07:43:38,820 Epoch: [154/484] Iter:[0/495], Time: 2.27, lr: [0.007084377913448356], Loss: 2.705694, Acc:0.732151, Semantic loss: 1.303768, BCE loss: 0.459738, SB loss: 0.942188
2023-10-30 07:43:42,842 Epoch: [154/484] Iter:[10/495], Time: 0.57, lr: [0.007083987588401602], Loss: 1.961712, Acc:0.841282, Semantic loss: 0.711599, BCE loss: 0.496793, SB loss: 0.753321
2023-10-30 07:43:46,476 Epoch: [154/484] Iter:[20/495], Time: 0.47, lr: [0.007083597260965192], Loss: 2.035732, Acc:0.825846, Semantic loss: 0.748975, BCE loss: 0.528207, SB loss: 0.758551
2023-10-30 07:43:50,011 Epoch: [154/484] Iter:[30/495], Time: 0.43, lr: [0.007083206931138967], Loss: 1.991463, Acc:0.809453, Semantic loss: 0.728019, BCE loss: 0.518454, SB loss: 0.744989
2023-10-30 07:43:53,650 Epoch: [154/484] Iter:[40/495], Time: 0.42, lr: [0.007082816598922764], Loss: 2.003005, Acc:0.801717, Semantic loss: 0.730657, BCE loss: 0.526654, SB loss: 0.745694
2023-10-30 07:43:57,263 Epoch: [154/484] Iter:[50/495], Time: 0.41, lr: [0.007082426264316425], Loss: 2.034172, Acc:0.801507, Semantic loss: 0.738094, BCE loss: 0.548512, SB loss: 0.747566
2023-10-30 07:44:01,029 Epoch: [154/484] Iter:[60/495], Time: 0.40, lr: [0.0070820359273197865], Loss: 2.056535, Acc:0.800743, Semantic loss: 0.754172, BCE loss: 0.555072, SB loss: 0.747291
2023-10-30 07:44:04,709 Epoch: [154/484] Iter:[70/495], Time: 0.40, lr: [0.007081645587932688], Loss: 2.064598, Acc:0.799237, Semantic loss: 0.765726, BCE loss: 0.549009, SB loss: 0.749862
2023-10-30 07:44:08,337 Epoch: [154/484] Iter:[80/495], Time: 0.39, lr: [0.007081255246154969], Loss: 2.081478, Acc:0.799192, Semantic loss: 0.778428, BCE loss: 0.552141, SB loss: 0.750909
2023-10-30 07:44:11,989 Epoch: [154/484] Iter:[90/495], Time: 0.39, lr: [0.007080864901986466], Loss: 2.078225, Acc:0.794417, Semantic loss: 0.776466, BCE loss: 0.549004, SB loss: 0.752755
2023-10-30 07:44:15,596 Epoch: [154/484] Iter:[100/495], Time: 0.39, lr: [0.007080474555427021], Loss: 2.071808, Acc:0.792754, Semantic loss: 0.772919, BCE loss: 0.550405, SB loss: 0.748483
2023-10-30 07:44:19,339 Epoch: [154/484] Iter:[110/495], Time: 0.39, lr: [0.007080084206476472], Loss: 2.078120, Acc:0.794352, Semantic loss: 0.777773, BCE loss: 0.550687, SB loss: 0.749659
2023-10-30 07:44:22,963 Epoch: [154/484] Iter:[120/495], Time: 0.38, lr: [0.007079693855134658], Loss: 2.069584, Acc:0.795281, Semantic loss: 0.772860, BCE loss: 0.546974, SB loss: 0.749750
2023-10-30 07:44:26,592 Epoch: [154/484] Iter:[130/495], Time: 0.38, lr: [0.007079303501401417], Loss: 2.068642, Acc:0.792292, Semantic loss: 0.774542, BCE loss: 0.543081, SB loss: 0.751019
2023-10-30 07:44:30,281 Epoch: [154/484] Iter:[140/495], Time: 0.38, lr: [0.007078913145276589], Loss: 2.067848, Acc:0.793743, Semantic loss: 0.770262, BCE loss: 0.547946, SB loss: 0.749640
2023-10-30 07:44:34,006 Epoch: [154/484] Iter:[150/495], Time: 0.38, lr: [0.007078522786760013], Loss: 2.063015, Acc:0.793725, Semantic loss: 0.770581, BCE loss: 0.543453, SB loss: 0.748980
2023-10-30 07:44:37,740 Epoch: [154/484] Iter:[160/495], Time: 0.38, lr: [0.007078132425851526], Loss: 2.058608, Acc:0.796979, Semantic loss: 0.766492, BCE loss: 0.544029, SB loss: 0.748087
2023-10-30 07:44:41,445 Epoch: [154/484] Iter:[170/495], Time: 0.38, lr: [0.007077742062550967], Loss: 2.055668, Acc:0.797643, Semantic loss: 0.765915, BCE loss: 0.541040, SB loss: 0.748714
2023-10-30 07:44:45,235 Epoch: [154/484] Iter:[180/495], Time: 0.38, lr: [0.007077351696858176], Loss: 2.062253, Acc:0.797891, Semantic loss: 0.769667, BCE loss: 0.541772, SB loss: 0.750814
2023-10-30 07:44:48,958 Epoch: [154/484] Iter:[190/495], Time: 0.38, lr: [0.007076961328772992], Loss: 2.055894, Acc:0.798773, Semantic loss: 0.766647, BCE loss: 0.539480, SB loss: 0.749768
2023-10-30 07:44:52,644 Epoch: [154/484] Iter:[200/495], Time: 0.38, lr: [0.007076570958295252], Loss: 2.052738, Acc:0.798605, Semantic loss: 0.765299, BCE loss: 0.537644, SB loss: 0.749794
2023-10-30 07:44:56,441 Epoch: [154/484] Iter:[210/495], Time: 0.38, lr: [0.007076180585424796], Loss: 2.050197, Acc:0.797012, Semantic loss: 0.764564, BCE loss: 0.536469, SB loss: 0.749164
2023-10-30 07:45:00,031 Epoch: [154/484] Iter:[220/495], Time: 0.38, lr: [0.007075790210161463], Loss: 2.051441, Acc:0.799499, Semantic loss: 0.763921, BCE loss: 0.538099, SB loss: 0.749421
2023-10-30 07:45:03,704 Epoch: [154/484] Iter:[230/495], Time: 0.38, lr: [0.0070753998325050905], Loss: 2.054054, Acc:0.798436, Semantic loss: 0.764870, BCE loss: 0.538286, SB loss: 0.750898
2023-10-30 07:45:07,405 Epoch: [154/484] Iter:[240/495], Time: 0.38, lr: [0.007075009452455518], Loss: 2.046889, Acc:0.799103, Semantic loss: 0.761591, BCE loss: 0.535620, SB loss: 0.749678
2023-10-30 07:45:11,156 Epoch: [154/484] Iter:[250/495], Time: 0.38, lr: [0.007074619070012582], Loss: 2.044778, Acc:0.800014, Semantic loss: 0.760756, BCE loss: 0.535473, SB loss: 0.748549
2023-10-30 07:45:14,775 Epoch: [154/484] Iter:[260/495], Time: 0.38, lr: [0.007074228685176124], Loss: 2.051990, Acc:0.798472, Semantic loss: 0.765117, BCE loss: 0.536593, SB loss: 0.750279
2023-10-30 07:45:18,454 Epoch: [154/484] Iter:[270/495], Time: 0.38, lr: [0.00707383829794598], Loss: 2.049554, Acc:0.798731, Semantic loss: 0.762681, BCE loss: 0.536659, SB loss: 0.750214
2023-10-30 07:45:22,065 Epoch: [154/484] Iter:[280/495], Time: 0.38, lr: [0.0070734479083219915], Loss: 2.046552, Acc:0.797906, Semantic loss: 0.761299, BCE loss: 0.536164, SB loss: 0.749090
2023-10-30 07:45:25,636 Epoch: [154/484] Iter:[290/495], Time: 0.37, lr: [0.007073057516303996], Loss: 2.045443, Acc:0.798969, Semantic loss: 0.759786, BCE loss: 0.536527, SB loss: 0.749129
2023-10-30 07:45:29,401 Epoch: [154/484] Iter:[300/495], Time: 0.37, lr: [0.00707266712189183], Loss: 2.042093, Acc:0.798914, Semantic loss: 0.758832, BCE loss: 0.534993, SB loss: 0.748268
2023-10-30 07:45:33,095 Epoch: [154/484] Iter:[310/495], Time: 0.37, lr: [0.007072276725085334], Loss: 2.042215, Acc:0.799928, Semantic loss: 0.759261, BCE loss: 0.534908, SB loss: 0.748046
2023-10-30 07:45:36,713 Epoch: [154/484] Iter:[320/495], Time: 0.37, lr: [0.007071886325884346], Loss: 2.040376, Acc:0.799386, Semantic loss: 0.759125, BCE loss: 0.533407, SB loss: 0.747844
2023-10-30 07:45:40,413 Epoch: [154/484] Iter:[330/495], Time: 0.37, lr: [0.007071495924288703], Loss: 2.040064, Acc:0.800396, Semantic loss: 0.759000, BCE loss: 0.533743, SB loss: 0.747322
2023-10-30 07:45:44,199 Epoch: [154/484] Iter:[340/495], Time: 0.37, lr: [0.007071105520298246], Loss: 2.041289, Acc:0.801095, Semantic loss: 0.759026, BCE loss: 0.535686, SB loss: 0.746577
2023-10-30 07:45:47,893 Epoch: [154/484] Iter:[350/495], Time: 0.37, lr: [0.00707071511391281], Loss: 2.040969, Acc:0.801897, Semantic loss: 0.759204, BCE loss: 0.535439, SB loss: 0.746326
2023-10-30 07:45:51,559 Epoch: [154/484] Iter:[360/495], Time: 0.37, lr: [0.007070324705132238], Loss: 2.041259, Acc:0.801131, Semantic loss: 0.759588, BCE loss: 0.534246, SB loss: 0.747426
2023-10-30 07:45:55,223 Epoch: [154/484] Iter:[370/495], Time: 0.37, lr: [0.007069934293956365], Loss: 2.044474, Acc:0.801512, Semantic loss: 0.761614, BCE loss: 0.534260, SB loss: 0.748600
2023-10-30 07:45:58,854 Epoch: [154/484] Iter:[380/495], Time: 0.37, lr: [0.00706954388038503], Loss: 2.045042, Acc:0.801506, Semantic loss: 0.763178, BCE loss: 0.532977, SB loss: 0.748886
2023-10-30 07:46:02,548 Epoch: [154/484] Iter:[390/495], Time: 0.37, lr: [0.0070691534644180725], Loss: 2.050724, Acc:0.800750, Semantic loss: 0.766279, BCE loss: 0.534355, SB loss: 0.750091
2023-10-30 07:46:06,382 Epoch: [154/484] Iter:[400/495], Time: 0.37, lr: [0.007068763046055328], Loss: 2.056244, Acc:0.799342, Semantic loss: 0.768229, BCE loss: 0.536510, SB loss: 0.751504
2023-10-30 07:46:10,059 Epoch: [154/484] Iter:[410/495], Time: 0.37, lr: [0.007068372625296636], Loss: 2.054193, Acc:0.799251, Semantic loss: 0.766395, BCE loss: 0.537250, SB loss: 0.750547
2023-10-30 07:46:13,706 Epoch: [154/484] Iter:[420/495], Time: 0.37, lr: [0.0070679822021418376], Loss: 2.052121, Acc:0.798883, Semantic loss: 0.764521, BCE loss: 0.537551, SB loss: 0.750049
2023-10-30 07:46:17,379 Epoch: [154/484] Iter:[430/495], Time: 0.37, lr: [0.007067591776590766], Loss: 2.060626, Acc:0.798851, Semantic loss: 0.769379, BCE loss: 0.538888, SB loss: 0.752359
2023-10-30 07:46:21,106 Epoch: [154/484] Iter:[440/495], Time: 0.37, lr: [0.007067201348643264], Loss: 2.061703, Acc:0.799014, Semantic loss: 0.769489, BCE loss: 0.539285, SB loss: 0.752929
2023-10-30 07:46:24,752 Epoch: [154/484] Iter:[450/495], Time: 0.37, lr: [0.007066810918299168], Loss: 2.061595, Acc:0.799054, Semantic loss: 0.770623, BCE loss: 0.537805, SB loss: 0.753167
2023-10-30 07:46:28,370 Epoch: [154/484] Iter:[460/495], Time: 0.37, lr: [0.007066420485558316], Loss: 2.078026, Acc:0.798143, Semantic loss: 0.781081, BCE loss: 0.539015, SB loss: 0.757930
2023-10-30 07:46:32,011 Epoch: [154/484] Iter:[470/495], Time: 0.37, lr: [0.007066030050420546], Loss: 2.079217, Acc:0.797347, Semantic loss: 0.781562, BCE loss: 0.538525, SB loss: 0.759129
2023-10-30 07:46:35,654 Epoch: [154/484] Iter:[480/495], Time: 0.37, lr: [0.007065639612885697], Loss: 2.081850, Acc:0.797778, Semantic loss: 0.782013, BCE loss: 0.539931, SB loss: 0.759906
2023-10-30 07:46:39,127 Epoch: [154/484] Iter:[490/495], Time: 0.37, lr: [0.007065249172953604], Loss: 2.082987, Acc:0.797572, Semantic loss: 0.783344, BCE loss: 0.539397, SB loss: 0.760246
2023-10-30 07:46:40,536 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:46:40,779 Loss: 2.027, MeanIU:  0.6774, Best_mIoU:  0.6907
2023-10-30 07:46:40,779 [0.9719123  0.79278158 0.8947808  0.45760063 0.5238593  0.57049676
 0.64866249 0.74036384 0.90771968 0.55319678 0.89119583 0.76911889
 0.56417766 0.92811373 0.65681475 0.66457143 0.25155191 0.36510761
 0.71914634]
2023-10-30 07:46:42,798 Epoch: [155/484] Iter:[0/495], Time: 1.98, lr: [0.0070650539520885425], Loss: 2.343111, Acc:0.788425, Semantic loss: 0.972738, BCE loss: 0.519794, SB loss: 0.850578
2023-10-30 07:46:46,805 Epoch: [155/484] Iter:[10/495], Time: 0.55, lr: [0.007064663508560284], Loss: 2.022826, Acc:0.785719, Semantic loss: 0.736506, BCE loss: 0.549919, SB loss: 0.736401
2023-10-30 07:46:50,474 Epoch: [155/484] Iter:[20/495], Time: 0.46, lr: [0.007064273062634381], Loss: 2.127914, Acc:0.794316, Semantic loss: 0.815698, BCE loss: 0.569144, SB loss: 0.743072
2023-10-30 07:46:54,236 Epoch: [155/484] Iter:[30/495], Time: 0.43, lr: [0.00706388261431067], Loss: 2.092873, Acc:0.796112, Semantic loss: 0.796879, BCE loss: 0.550636, SB loss: 0.745358
2023-10-30 07:46:57,826 Epoch: [155/484] Iter:[40/495], Time: 0.41, lr: [0.007063492163588987], Loss: 2.100129, Acc:0.798900, Semantic loss: 0.798126, BCE loss: 0.541437, SB loss: 0.760565
2023-10-30 07:47:01,439 Epoch: [155/484] Iter:[50/495], Time: 0.40, lr: [0.007063101710469172], Loss: 2.090806, Acc:0.798785, Semantic loss: 0.790346, BCE loss: 0.540905, SB loss: 0.759555
2023-10-30 07:47:05,147 Epoch: [155/484] Iter:[60/495], Time: 0.40, lr: [0.007062711254951063], Loss: 2.118605, Acc:0.797941, Semantic loss: 0.813640, BCE loss: 0.542109, SB loss: 0.762856
2023-10-30 07:47:08,824 Epoch: [155/484] Iter:[70/495], Time: 0.39, lr: [0.007062320797034497], Loss: 2.098793, Acc:0.799474, Semantic loss: 0.804860, BCE loss: 0.535877, SB loss: 0.758056
2023-10-30 07:47:12,502 Epoch: [155/484] Iter:[80/495], Time: 0.39, lr: [0.007061930336719312], Loss: 2.103653, Acc:0.793027, Semantic loss: 0.816364, BCE loss: 0.530880, SB loss: 0.756410
2023-10-30 07:47:16,180 Epoch: [155/484] Iter:[90/495], Time: 0.39, lr: [0.007061539874005347], Loss: 2.124179, Acc:0.788007, Semantic loss: 0.826683, BCE loss: 0.539950, SB loss: 0.757545
2023-10-30 07:47:19,782 Epoch: [155/484] Iter:[100/495], Time: 0.39, lr: [0.00706114940889244], Loss: 2.166303, Acc:0.782823, Semantic loss: 0.853419, BCE loss: 0.539556, SB loss: 0.773328
2023-10-30 07:47:23,508 Epoch: [155/484] Iter:[110/495], Time: 0.38, lr: [0.007060758941380427], Loss: 2.148819, Acc:0.782811, Semantic loss: 0.841993, BCE loss: 0.535421, SB loss: 0.771405
2023-10-30 07:47:27,094 Epoch: [155/484] Iter:[120/495], Time: 0.38, lr: [0.0070603684714691485], Loss: 2.159109, Acc:0.781703, Semantic loss: 0.841563, BCE loss: 0.537860, SB loss: 0.779686
2023-10-30 07:47:30,781 Epoch: [155/484] Iter:[130/495], Time: 0.38, lr: [0.00705997799915844], Loss: 2.165451, Acc:0.781579, Semantic loss: 0.845231, BCE loss: 0.537364, SB loss: 0.782856
2023-10-30 07:47:34,378 Epoch: [155/484] Iter:[140/495], Time: 0.38, lr: [0.00705958752444814], Loss: 2.167789, Acc:0.781565, Semantic loss: 0.847541, BCE loss: 0.536643, SB loss: 0.783605
2023-10-30 07:47:37,969 Epoch: [155/484] Iter:[150/495], Time: 0.38, lr: [0.007059197047338085], Loss: 2.170790, Acc:0.781809, Semantic loss: 0.847649, BCE loss: 0.539653, SB loss: 0.783488
2023-10-30 07:47:41,675 Epoch: [155/484] Iter:[160/495], Time: 0.38, lr: [0.007058806567828117], Loss: 2.158243, Acc:0.783332, Semantic loss: 0.837046, BCE loss: 0.541174, SB loss: 0.780023
2023-10-30 07:47:45,336 Epoch: [155/484] Iter:[170/495], Time: 0.38, lr: [0.007058416085918068], Loss: 2.157538, Acc:0.784018, Semantic loss: 0.835053, BCE loss: 0.542095, SB loss: 0.780391
2023-10-30 07:47:48,977 Epoch: [155/484] Iter:[180/495], Time: 0.38, lr: [0.00705802560160778], Loss: 2.164425, Acc:0.785089, Semantic loss: 0.836946, BCE loss: 0.546629, SB loss: 0.780850
2023-10-30 07:47:52,657 Epoch: [155/484] Iter:[190/495], Time: 0.38, lr: [0.00705763511489709], Loss: 2.168094, Acc:0.785231, Semantic loss: 0.836853, BCE loss: 0.548968, SB loss: 0.782272
2023-10-30 07:47:56,342 Epoch: [155/484] Iter:[200/495], Time: 0.38, lr: [0.007057244625785834], Loss: 2.160684, Acc:0.784737, Semantic loss: 0.831045, BCE loss: 0.547521, SB loss: 0.782118
2023-10-30 07:47:59,941 Epoch: [155/484] Iter:[210/495], Time: 0.38, lr: [0.007056854134273851], Loss: 2.161507, Acc:0.784721, Semantic loss: 0.830667, BCE loss: 0.548620, SB loss: 0.782221
2023-10-30 07:48:03,505 Epoch: [155/484] Iter:[220/495], Time: 0.37, lr: [0.0070564636403609785], Loss: 2.154877, Acc:0.785880, Semantic loss: 0.826571, BCE loss: 0.547955, SB loss: 0.780351
2023-10-30 07:48:07,133 Epoch: [155/484] Iter:[230/495], Time: 0.37, lr: [0.0070560731440470524], Loss: 2.147924, Acc:0.787040, Semantic loss: 0.821357, BCE loss: 0.549231, SB loss: 0.777336
2023-10-30 07:48:10,800 Epoch: [155/484] Iter:[240/495], Time: 0.37, lr: [0.0070556826453319135], Loss: 2.145885, Acc:0.787205, Semantic loss: 0.820927, BCE loss: 0.547169, SB loss: 0.777790
2023-10-30 07:48:14,448 Epoch: [155/484] Iter:[250/495], Time: 0.37, lr: [0.007055292144215396], Loss: 2.148984, Acc:0.787032, Semantic loss: 0.821662, BCE loss: 0.549647, SB loss: 0.777675
2023-10-30 07:48:18,068 Epoch: [155/484] Iter:[260/495], Time: 0.37, lr: [0.0070549016406973395], Loss: 2.152496, Acc:0.788846, Semantic loss: 0.822861, BCE loss: 0.551610, SB loss: 0.778026
2023-10-30 07:48:21,811 Epoch: [155/484] Iter:[270/495], Time: 0.37, lr: [0.007054511134777583], Loss: 2.150697, Acc:0.788558, Semantic loss: 0.822505, BCE loss: 0.549969, SB loss: 0.778223
2023-10-30 07:48:25,492 Epoch: [155/484] Iter:[280/495], Time: 0.37, lr: [0.00705412062645596], Loss: 2.146751, Acc:0.788969, Semantic loss: 0.819446, BCE loss: 0.549651, SB loss: 0.777654
2023-10-30 07:48:29,185 Epoch: [155/484] Iter:[290/495], Time: 0.37, lr: [0.007053730115732311], Loss: 2.150565, Acc:0.789356, Semantic loss: 0.821280, BCE loss: 0.551230, SB loss: 0.778055
2023-10-30 07:48:32,843 Epoch: [155/484] Iter:[300/495], Time: 0.37, lr: [0.007053339602606473], Loss: 2.151342, Acc:0.789011, Semantic loss: 0.822090, BCE loss: 0.550197, SB loss: 0.779054
2023-10-30 07:48:36,484 Epoch: [155/484] Iter:[310/495], Time: 0.37, lr: [0.007052949087078282], Loss: 2.155756, Acc:0.788429, Semantic loss: 0.825494, BCE loss: 0.550136, SB loss: 0.780126
2023-10-30 07:48:40,137 Epoch: [155/484] Iter:[320/495], Time: 0.37, lr: [0.007052558569147577], Loss: 2.152766, Acc:0.789109, Semantic loss: 0.823026, BCE loss: 0.550197, SB loss: 0.779543
2023-10-30 07:48:43,849 Epoch: [155/484] Iter:[330/495], Time: 0.37, lr: [0.007052168048814193], Loss: 2.148518, Acc:0.789537, Semantic loss: 0.821174, BCE loss: 0.549553, SB loss: 0.777791
2023-10-30 07:48:47,538 Epoch: [155/484] Iter:[340/495], Time: 0.37, lr: [0.0070517775260779715], Loss: 2.147144, Acc:0.790590, Semantic loss: 0.819897, BCE loss: 0.549864, SB loss: 0.777383
2023-10-30 07:48:51,162 Epoch: [155/484] Iter:[350/495], Time: 0.37, lr: [0.0070513870009387474], Loss: 2.144310, Acc:0.790405, Semantic loss: 0.818565, BCE loss: 0.549742, SB loss: 0.776003
2023-10-30 07:48:54,814 Epoch: [155/484] Iter:[360/495], Time: 0.37, lr: [0.007050996473396358], Loss: 2.143696, Acc:0.790925, Semantic loss: 0.818504, BCE loss: 0.549516, SB loss: 0.775676
2023-10-30 07:48:58,484 Epoch: [155/484] Iter:[370/495], Time: 0.37, lr: [0.007050605943450641], Loss: 2.144527, Acc:0.790722, Semantic loss: 0.819421, BCE loss: 0.549623, SB loss: 0.775484
2023-10-30 07:49:02,216 Epoch: [155/484] Iter:[380/495], Time: 0.37, lr: [0.007050215411101433], Loss: 2.142885, Acc:0.790094, Semantic loss: 0.817919, BCE loss: 0.548842, SB loss: 0.776125
2023-10-30 07:49:05,847 Epoch: [155/484] Iter:[390/495], Time: 0.37, lr: [0.0070498248763485715], Loss: 2.140371, Acc:0.790570, Semantic loss: 0.816505, BCE loss: 0.548594, SB loss: 0.775272
2023-10-30 07:49:09,534 Epoch: [155/484] Iter:[400/495], Time: 0.37, lr: [0.007049434339191894], Loss: 2.136070, Acc:0.790737, Semantic loss: 0.813951, BCE loss: 0.547828, SB loss: 0.774291
2023-10-30 07:49:13,240 Epoch: [155/484] Iter:[410/495], Time: 0.37, lr: [0.0070490437996312385], Loss: 2.136036, Acc:0.791287, Semantic loss: 0.813539, BCE loss: 0.548108, SB loss: 0.774389
2023-10-30 07:49:16,899 Epoch: [155/484] Iter:[420/495], Time: 0.37, lr: [0.007048653257666442], Loss: 2.135795, Acc:0.791811, Semantic loss: 0.813710, BCE loss: 0.547813, SB loss: 0.774273
2023-10-30 07:49:20,586 Epoch: [155/484] Iter:[430/495], Time: 0.37, lr: [0.00704826271329734], Loss: 2.137919, Acc:0.792069, Semantic loss: 0.814329, BCE loss: 0.549242, SB loss: 0.774347
2023-10-30 07:49:24,258 Epoch: [155/484] Iter:[440/495], Time: 0.37, lr: [0.007047872166523772], Loss: 2.136979, Acc:0.791884, Semantic loss: 0.813877, BCE loss: 0.549072, SB loss: 0.774030
2023-10-30 07:49:28,064 Epoch: [155/484] Iter:[450/495], Time: 0.37, lr: [0.0070474816173455735], Loss: 2.135278, Acc:0.792472, Semantic loss: 0.812217, BCE loss: 0.549801, SB loss: 0.773260
2023-10-30 07:49:31,737 Epoch: [155/484] Iter:[460/495], Time: 0.37, lr: [0.007047091065762582], Loss: 2.135086, Acc:0.792537, Semantic loss: 0.812014, BCE loss: 0.549611, SB loss: 0.773461
2023-10-30 07:49:35,368 Epoch: [155/484] Iter:[470/495], Time: 0.37, lr: [0.007046700511774635], Loss: 2.133810, Acc:0.792588, Semantic loss: 0.810908, BCE loss: 0.550048, SB loss: 0.772853
2023-10-30 07:49:39,082 Epoch: [155/484] Iter:[480/495], Time: 0.37, lr: [0.007046309955381568], Loss: 2.130398, Acc:0.792614, Semantic loss: 0.809521, BCE loss: 0.548684, SB loss: 0.772193
2023-10-30 07:49:42,596 Epoch: [155/484] Iter:[490/495], Time: 0.37, lr: [0.0070459193965832214], Loss: 2.129965, Acc:0.793150, Semantic loss: 0.808339, BCE loss: 0.549640, SB loss: 0.771985
2023-10-30 07:52:39,809 0 [0.94321826 0.66175889 0.82277518 0.09317268 0.21211975 0.38492845
 0.43752792 0.48637409 0.88390922 0.46373494 0.87156766 0.6072771
 0.01524865 0.79844789 0.         0.05478817 0.05225564 0.05350948
 0.57598654] 0.443084238063355
2023-10-30 07:52:39,810 1 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272] 0.6983867653473611
2023-10-30 07:52:39,814 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:52:40,169 Loss: 2.047, MeanIU:  0.6984, Best_mIoU:  0.6984
2023-10-30 07:52:40,170 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272]
2023-10-30 07:52:42,210 Epoch: [156/484] Iter:[0/495], Time: 2.01, lr: [0.007045724116282016], Loss: 2.565687, Acc:0.848420, Semantic loss: 0.945696, BCE loss: 0.694799, SB loss: 0.925193
2023-10-30 07:52:46,086 Epoch: [156/484] Iter:[10/495], Time: 0.53, lr: [0.007045333553875441], Loss: 2.186649, Acc:0.797157, Semantic loss: 0.843096, BCE loss: 0.539119, SB loss: 0.804434
2023-10-30 07:52:49,618 Epoch: [156/484] Iter:[20/495], Time: 0.45, lr: [0.007044942989063178], Loss: 2.170719, Acc:0.802185, Semantic loss: 0.848954, BCE loss: 0.549115, SB loss: 0.772649
2023-10-30 07:52:53,134 Epoch: [156/484] Iter:[30/495], Time: 0.42, lr: [0.007044552421845061], Loss: 2.118471, Acc:0.805999, Semantic loss: 0.805360, BCE loss: 0.554218, SB loss: 0.758893
2023-10-30 07:52:56,637 Epoch: [156/484] Iter:[40/495], Time: 0.40, lr: [0.00704416185222093], Loss: 2.091896, Acc:0.807603, Semantic loss: 0.788609, BCE loss: 0.545486, SB loss: 0.757801
2023-10-30 07:53:00,045 Epoch: [156/484] Iter:[50/495], Time: 0.39, lr: [0.007043771280190621], Loss: 2.052203, Acc:0.813553, Semantic loss: 0.771554, BCE loss: 0.533726, SB loss: 0.746924
2023-10-30 07:53:03,480 Epoch: [156/484] Iter:[60/495], Time: 0.38, lr: [0.00704338070575397], Loss: 2.035828, Acc:0.812039, Semantic loss: 0.766164, BCE loss: 0.524788, SB loss: 0.744876
2023-10-30 07:53:06,983 Epoch: [156/484] Iter:[70/495], Time: 0.38, lr: [0.007042990128910814], Loss: 2.040054, Acc:0.809976, Semantic loss: 0.768558, BCE loss: 0.520995, SB loss: 0.750501
2023-10-30 07:53:10,519 Epoch: [156/484] Iter:[80/495], Time: 0.37, lr: [0.007042599549660993], Loss: 2.063233, Acc:0.813521, Semantic loss: 0.777948, BCE loss: 0.530899, SB loss: 0.754386
2023-10-30 07:53:14,157 Epoch: [156/484] Iter:[90/495], Time: 0.37, lr: [0.00704220896800434], Loss: 2.068931, Acc:0.810691, Semantic loss: 0.781388, BCE loss: 0.529313, SB loss: 0.758231
2023-10-30 07:53:17,722 Epoch: [156/484] Iter:[100/495], Time: 0.37, lr: [0.007041818383940694], Loss: 2.074698, Acc:0.808442, Semantic loss: 0.784812, BCE loss: 0.532630, SB loss: 0.757256
2023-10-30 07:53:21,237 Epoch: [156/484] Iter:[110/495], Time: 0.37, lr: [0.007041427797469892], Loss: 2.066905, Acc:0.807468, Semantic loss: 0.777674, BCE loss: 0.536151, SB loss: 0.753080
2023-10-30 07:53:24,818 Epoch: [156/484] Iter:[120/495], Time: 0.37, lr: [0.007041037208591769], Loss: 2.072497, Acc:0.805443, Semantic loss: 0.785364, BCE loss: 0.531820, SB loss: 0.755313
2023-10-30 07:53:28,348 Epoch: [156/484] Iter:[130/495], Time: 0.37, lr: [0.007040646617306161], Loss: 2.078271, Acc:0.802761, Semantic loss: 0.786821, BCE loss: 0.535648, SB loss: 0.755803
2023-10-30 07:53:31,936 Epoch: [156/484] Iter:[140/495], Time: 0.37, lr: [0.0070402560236129084], Loss: 2.077382, Acc:0.803786, Semantic loss: 0.786837, BCE loss: 0.531740, SB loss: 0.758806
2023-10-30 07:53:35,489 Epoch: [156/484] Iter:[150/495], Time: 0.37, lr: [0.0070398654275118456], Loss: 2.073820, Acc:0.798677, Semantic loss: 0.783737, BCE loss: 0.532254, SB loss: 0.757829
2023-10-30 07:53:39,231 Epoch: [156/484] Iter:[160/495], Time: 0.37, lr: [0.0070394748290028095], Loss: 2.067358, Acc:0.798998, Semantic loss: 0.780319, BCE loss: 0.530888, SB loss: 0.756152
2023-10-30 07:53:42,826 Epoch: [156/484] Iter:[170/495], Time: 0.37, lr: [0.007039084228085638], Loss: 2.070660, Acc:0.799018, Semantic loss: 0.781009, BCE loss: 0.532976, SB loss: 0.756676
2023-10-30 07:53:46,498 Epoch: [156/484] Iter:[180/495], Time: 0.37, lr: [0.007038693624760168], Loss: 2.073706, Acc:0.800381, Semantic loss: 0.782707, BCE loss: 0.536756, SB loss: 0.754243
2023-10-30 07:53:50,065 Epoch: [156/484] Iter:[190/495], Time: 0.37, lr: [0.007038303019026232], Loss: 2.070791, Acc:0.803200, Semantic loss: 0.780024, BCE loss: 0.536107, SB loss: 0.754660
2023-10-30 07:53:53,781 Epoch: [156/484] Iter:[200/495], Time: 0.37, lr: [0.007037912410883671], Loss: 2.078161, Acc:0.802775, Semantic loss: 0.784077, BCE loss: 0.535749, SB loss: 0.758335
2023-10-30 07:53:57,358 Epoch: [156/484] Iter:[210/495], Time: 0.37, lr: [0.00703752180033232], Loss: 2.077463, Acc:0.803637, Semantic loss: 0.783771, BCE loss: 0.535231, SB loss: 0.758461
2023-10-30 07:54:00,903 Epoch: [156/484] Iter:[220/495], Time: 0.37, lr: [0.007037131187372016], Loss: 2.089058, Acc:0.801911, Semantic loss: 0.788465, BCE loss: 0.540311, SB loss: 0.760282
2023-10-30 07:54:04,534 Epoch: [156/484] Iter:[230/495], Time: 0.37, lr: [0.007036740572002596], Loss: 2.087630, Acc:0.801342, Semantic loss: 0.785576, BCE loss: 0.542016, SB loss: 0.760038
2023-10-30 07:54:08,237 Epoch: [156/484] Iter:[240/495], Time: 0.37, lr: [0.007036349954223895], Loss: 2.088521, Acc:0.801684, Semantic loss: 0.788629, BCE loss: 0.540749, SB loss: 0.759142
2023-10-30 07:54:11,885 Epoch: [156/484] Iter:[250/495], Time: 0.37, lr: [0.007035959334035751], Loss: 2.082618, Acc:0.802379, Semantic loss: 0.783270, BCE loss: 0.541976, SB loss: 0.757371
2023-10-30 07:54:15,565 Epoch: [156/484] Iter:[260/495], Time: 0.37, lr: [0.0070355687114379995], Loss: 2.080146, Acc:0.801167, Semantic loss: 0.781700, BCE loss: 0.541706, SB loss: 0.756740
2023-10-30 07:54:19,176 Epoch: [156/484] Iter:[270/495], Time: 0.37, lr: [0.007035178086430478], Loss: 2.086119, Acc:0.802617, Semantic loss: 0.782737, BCE loss: 0.544937, SB loss: 0.758445
2023-10-30 07:54:22,820 Epoch: [156/484] Iter:[280/495], Time: 0.37, lr: [0.007034787459013023], Loss: 2.082607, Acc:0.802438, Semantic loss: 0.780253, BCE loss: 0.544701, SB loss: 0.757653
2023-10-30 07:54:26,432 Epoch: [156/484] Iter:[290/495], Time: 0.37, lr: [0.007034396829185469], Loss: 2.079411, Acc:0.800228, Semantic loss: 0.778572, BCE loss: 0.544336, SB loss: 0.756503
2023-10-30 07:54:30,141 Epoch: [156/484] Iter:[300/495], Time: 0.37, lr: [0.007034006196947654], Loss: 2.077972, Acc:0.801294, Semantic loss: 0.778332, BCE loss: 0.543060, SB loss: 0.756580
2023-10-30 07:54:33,797 Epoch: [156/484] Iter:[310/495], Time: 0.37, lr: [0.0070336155622994145], Loss: 2.078355, Acc:0.800511, Semantic loss: 0.780068, BCE loss: 0.541311, SB loss: 0.756977
2023-10-30 07:54:37,421 Epoch: [156/484] Iter:[320/495], Time: 0.37, lr: [0.007033224925240587], Loss: 2.073638, Acc:0.800634, Semantic loss: 0.777301, BCE loss: 0.540309, SB loss: 0.756028
2023-10-30 07:54:41,059 Epoch: [156/484] Iter:[330/495], Time: 0.37, lr: [0.007032834285771008], Loss: 2.071334, Acc:0.799529, Semantic loss: 0.777991, BCE loss: 0.537508, SB loss: 0.755835
2023-10-30 07:54:44,725 Epoch: [156/484] Iter:[340/495], Time: 0.37, lr: [0.007032443643890512], Loss: 2.076094, Acc:0.800177, Semantic loss: 0.780105, BCE loss: 0.539313, SB loss: 0.756676
2023-10-30 07:54:48,307 Epoch: [156/484] Iter:[350/495], Time: 0.36, lr: [0.007032052999598938], Loss: 2.074870, Acc:0.800183, Semantic loss: 0.780363, BCE loss: 0.538041, SB loss: 0.756466
2023-10-30 07:54:51,898 Epoch: [156/484] Iter:[360/495], Time: 0.36, lr: [0.007031662352896119], Loss: 2.078468, Acc:0.799496, Semantic loss: 0.783202, BCE loss: 0.537875, SB loss: 0.757391
2023-10-30 07:54:55,546 Epoch: [156/484] Iter:[370/495], Time: 0.36, lr: [0.007031271703781894], Loss: 2.078260, Acc:0.799842, Semantic loss: 0.784860, BCE loss: 0.536303, SB loss: 0.757097
2023-10-30 07:54:59,289 Epoch: [156/484] Iter:[380/495], Time: 0.37, lr: [0.007030881052256097], Loss: 2.078546, Acc:0.799432, Semantic loss: 0.784221, BCE loss: 0.537420, SB loss: 0.756906
2023-10-30 07:55:03,046 Epoch: [156/484] Iter:[390/495], Time: 0.37, lr: [0.007030490398318569], Loss: 2.078956, Acc:0.799325, Semantic loss: 0.782093, BCE loss: 0.540100, SB loss: 0.756763
2023-10-30 07:55:06,705 Epoch: [156/484] Iter:[400/495], Time: 0.37, lr: [0.00703009974196914], Loss: 2.080349, Acc:0.799693, Semantic loss: 0.781157, BCE loss: 0.542410, SB loss: 0.756782
2023-10-30 07:55:10,384 Epoch: [156/484] Iter:[410/495], Time: 0.37, lr: [0.00702970908320765], Loss: 2.083369, Acc:0.800107, Semantic loss: 0.782786, BCE loss: 0.543069, SB loss: 0.757514
2023-10-30 07:55:13,979 Epoch: [156/484] Iter:[420/495], Time: 0.37, lr: [0.007029318422033934], Loss: 2.079429, Acc:0.799298, Semantic loss: 0.781456, BCE loss: 0.541483, SB loss: 0.756490
2023-10-30 07:55:17,625 Epoch: [156/484] Iter:[430/495], Time: 0.37, lr: [0.00702892775844783], Loss: 2.087397, Acc:0.798863, Semantic loss: 0.787203, BCE loss: 0.542044, SB loss: 0.758150
2023-10-30 07:55:21,338 Epoch: [156/484] Iter:[440/495], Time: 0.37, lr: [0.0070285370924491695], Loss: 2.091403, Acc:0.798282, Semantic loss: 0.789106, BCE loss: 0.543275, SB loss: 0.759023
2023-10-30 07:55:25,022 Epoch: [156/484] Iter:[450/495], Time: 0.37, lr: [0.0070281464240377935], Loss: 2.090190, Acc:0.798778, Semantic loss: 0.787811, BCE loss: 0.543637, SB loss: 0.758743
2023-10-30 07:55:28,744 Epoch: [156/484] Iter:[460/495], Time: 0.37, lr: [0.007027755753213535], Loss: 2.090623, Acc:0.799345, Semantic loss: 0.787327, BCE loss: 0.544612, SB loss: 0.758684
2023-10-30 07:55:32,381 Epoch: [156/484] Iter:[470/495], Time: 0.37, lr: [0.007027365079976232], Loss: 2.089479, Acc:0.799133, Semantic loss: 0.786646, BCE loss: 0.544214, SB loss: 0.758618
2023-10-30 07:55:36,053 Epoch: [156/484] Iter:[480/495], Time: 0.37, lr: [0.007026974404325721], Loss: 2.094627, Acc:0.799115, Semantic loss: 0.791039, BCE loss: 0.544321, SB loss: 0.759267
2023-10-30 07:55:39,589 Epoch: [156/484] Iter:[490/495], Time: 0.37, lr: [0.007026583726261835], Loss: 2.093050, Acc:0.798276, Semantic loss: 0.789821, BCE loss: 0.544378, SB loss: 0.758850
2023-10-30 07:55:40,965 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:55:41,207 Loss: 2.047, MeanIU:  0.6984, Best_mIoU:  0.6984
2023-10-30 07:55:41,208 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272]
2023-10-30 07:55:43,274 Epoch: [157/484] Iter:[0/495], Time: 2.03, lr: [0.007026388386324827], Loss: 2.166942, Acc:0.822438, Semantic loss: 0.737505, BCE loss: 0.489863, SB loss: 0.939575
2023-10-30 07:55:47,179 Epoch: [157/484] Iter:[10/495], Time: 0.54, lr: [0.007025997704640574], Loss: 2.120492, Acc:0.789138, Semantic loss: 0.800255, BCE loss: 0.529157, SB loss: 0.791079
2023-10-30 07:55:50,940 Epoch: [157/484] Iter:[20/495], Time: 0.46, lr: [0.007025607020542538], Loss: 2.097400, Acc:0.796252, Semantic loss: 0.774339, BCE loss: 0.558012, SB loss: 0.765049
2023-10-30 07:55:54,639 Epoch: [157/484] Iter:[30/495], Time: 0.43, lr: [0.007025216334030554], Loss: 2.133718, Acc:0.796434, Semantic loss: 0.804191, BCE loss: 0.562456, SB loss: 0.767071
2023-10-30 07:55:58,389 Epoch: [157/484] Iter:[40/495], Time: 0.42, lr: [0.007024825645104459], Loss: 2.117494, Acc:0.803827, Semantic loss: 0.791335, BCE loss: 0.569302, SB loss: 0.756857
2023-10-30 07:56:01,993 Epoch: [157/484] Iter:[50/495], Time: 0.41, lr: [0.007024434953764088], Loss: 2.110914, Acc:0.801664, Semantic loss: 0.797385, BCE loss: 0.548028, SB loss: 0.765501
2023-10-30 07:56:05,756 Epoch: [157/484] Iter:[60/495], Time: 0.40, lr: [0.007024044260009278], Loss: 2.096405, Acc:0.797493, Semantic loss: 0.789514, BCE loss: 0.542114, SB loss: 0.764777
2023-10-30 07:56:09,428 Epoch: [157/484] Iter:[70/495], Time: 0.40, lr: [0.007023653563839865], Loss: 2.099425, Acc:0.799844, Semantic loss: 0.786017, BCE loss: 0.545426, SB loss: 0.767983
2023-10-30 07:56:13,085 Epoch: [157/484] Iter:[80/495], Time: 0.39, lr: [0.007023262865255684], Loss: 2.102523, Acc:0.798846, Semantic loss: 0.793840, BCE loss: 0.540422, SB loss: 0.768260
2023-10-30 07:56:16,886 Epoch: [157/484] Iter:[90/495], Time: 0.39, lr: [0.00702287216425657], Loss: 2.089547, Acc:0.798264, Semantic loss: 0.785804, BCE loss: 0.538497, SB loss: 0.765246
2023-10-30 07:56:20,465 Epoch: [157/484] Iter:[100/495], Time: 0.39, lr: [0.00702248146084236], Loss: 2.098933, Acc:0.802442, Semantic loss: 0.789560, BCE loss: 0.541050, SB loss: 0.768323
2023-10-30 07:56:24,082 Epoch: [157/484] Iter:[110/495], Time: 0.39, lr: [0.007022090755012889], Loss: 2.096561, Acc:0.801034, Semantic loss: 0.791575, BCE loss: 0.539089, SB loss: 0.765897
2023-10-30 07:56:27,740 Epoch: [157/484] Iter:[120/495], Time: 0.38, lr: [0.007021700046767993], Loss: 2.090572, Acc:0.802543, Semantic loss: 0.786427, BCE loss: 0.538871, SB loss: 0.765274
2023-10-30 07:56:31,403 Epoch: [157/484] Iter:[130/495], Time: 0.38, lr: [0.007021309336107509], Loss: 2.096425, Acc:0.801171, Semantic loss: 0.788454, BCE loss: 0.540499, SB loss: 0.767472
2023-10-30 07:56:34,992 Epoch: [157/484] Iter:[140/495], Time: 0.38, lr: [0.007020918623031271], Loss: 2.108471, Acc:0.802105, Semantic loss: 0.794788, BCE loss: 0.543981, SB loss: 0.769702
2023-10-30 07:56:38,667 Epoch: [157/484] Iter:[150/495], Time: 0.38, lr: [0.007020527907539116], Loss: 2.116020, Acc:0.799079, Semantic loss: 0.802224, BCE loss: 0.541919, SB loss: 0.771876
2023-10-30 07:56:42,247 Epoch: [157/484] Iter:[160/495], Time: 0.38, lr: [0.007020137189630879], Loss: 2.119946, Acc:0.798214, Semantic loss: 0.802378, BCE loss: 0.545272, SB loss: 0.772296
2023-10-30 07:56:45,860 Epoch: [157/484] Iter:[170/495], Time: 0.38, lr: [0.007019746469306395], Loss: 2.118797, Acc:0.797533, Semantic loss: 0.803226, BCE loss: 0.545664, SB loss: 0.769907
2023-10-30 07:56:49,487 Epoch: [157/484] Iter:[180/495], Time: 0.38, lr: [0.007019355746565499], Loss: 2.120010, Acc:0.797958, Semantic loss: 0.804773, BCE loss: 0.546502, SB loss: 0.768736
2023-10-30 07:56:53,192 Epoch: [157/484] Iter:[190/495], Time: 0.38, lr: [0.007018965021408029], Loss: 2.126826, Acc:0.798091, Semantic loss: 0.806536, BCE loss: 0.551492, SB loss: 0.768798
2023-10-30 07:56:56,847 Epoch: [157/484] Iter:[200/495], Time: 0.38, lr: [0.007018574293833819], Loss: 2.123793, Acc:0.800165, Semantic loss: 0.804108, BCE loss: 0.550147, SB loss: 0.769537
2023-10-30 07:57:00,564 Epoch: [157/484] Iter:[210/495], Time: 0.38, lr: [0.007018183563842706], Loss: 2.125383, Acc:0.800894, Semantic loss: 0.804880, BCE loss: 0.551285, SB loss: 0.769218
2023-10-30 07:57:04,181 Epoch: [157/484] Iter:[220/495], Time: 0.38, lr: [0.0070177928314345255], Loss: 2.122666, Acc:0.801291, Semantic loss: 0.801486, BCE loss: 0.553232, SB loss: 0.767948
2023-10-30 07:57:07,790 Epoch: [157/484] Iter:[230/495], Time: 0.37, lr: [0.007017402096609111], Loss: 2.119751, Acc:0.800067, Semantic loss: 0.802464, BCE loss: 0.549331, SB loss: 0.767956
2023-10-30 07:57:11,447 Epoch: [157/484] Iter:[240/495], Time: 0.37, lr: [0.007017011359366299], Loss: 2.121257, Acc:0.800665, Semantic loss: 0.803546, BCE loss: 0.549657, SB loss: 0.768054
2023-10-30 07:57:15,136 Epoch: [157/484] Iter:[250/495], Time: 0.37, lr: [0.007016620619705926], Loss: 2.122647, Acc:0.800360, Semantic loss: 0.803993, BCE loss: 0.549798, SB loss: 0.768857
2023-10-30 07:57:18,776 Epoch: [157/484] Iter:[260/495], Time: 0.37, lr: [0.007016229877627824], Loss: 2.121437, Acc:0.799404, Semantic loss: 0.804097, BCE loss: 0.549113, SB loss: 0.768227
2023-10-30 07:57:22,408 Epoch: [157/484] Iter:[270/495], Time: 0.37, lr: [0.007015839133131833], Loss: 2.123004, Acc:0.799277, Semantic loss: 0.804371, BCE loss: 0.550645, SB loss: 0.767988
2023-10-30 07:57:26,167 Epoch: [157/484] Iter:[280/495], Time: 0.37, lr: [0.007015448386217784], Loss: 2.119208, Acc:0.799055, Semantic loss: 0.802165, BCE loss: 0.549673, SB loss: 0.767370
2023-10-30 07:57:29,815 Epoch: [157/484] Iter:[290/495], Time: 0.37, lr: [0.0070150576368855164], Loss: 2.118147, Acc:0.799617, Semantic loss: 0.800722, BCE loss: 0.551089, SB loss: 0.766336
2023-10-30 07:57:33,485 Epoch: [157/484] Iter:[300/495], Time: 0.37, lr: [0.007014666885134865], Loss: 2.120721, Acc:0.799519, Semantic loss: 0.801344, BCE loss: 0.551896, SB loss: 0.767480
2023-10-30 07:57:37,176 Epoch: [157/484] Iter:[310/495], Time: 0.37, lr: [0.0070142761309656635], Loss: 2.121426, Acc:0.800022, Semantic loss: 0.802893, BCE loss: 0.551560, SB loss: 0.766973
2023-10-30 07:57:40,848 Epoch: [157/484] Iter:[320/495], Time: 0.37, lr: [0.007013885374377748], Loss: 2.119881, Acc:0.800127, Semantic loss: 0.801727, BCE loss: 0.552212, SB loss: 0.765941
2023-10-30 07:57:44,432 Epoch: [157/484] Iter:[330/495], Time: 0.37, lr: [0.0070134946153709524], Loss: 2.126808, Acc:0.799326, Semantic loss: 0.804944, BCE loss: 0.554577, SB loss: 0.767286
2023-10-30 07:57:48,098 Epoch: [157/484] Iter:[340/495], Time: 0.37, lr: [0.007013103853945112], Loss: 2.127532, Acc:0.798798, Semantic loss: 0.805013, BCE loss: 0.554519, SB loss: 0.768000
2023-10-30 07:57:51,688 Epoch: [157/484] Iter:[350/495], Time: 0.37, lr: [0.007012713090100066], Loss: 2.124354, Acc:0.797685, Semantic loss: 0.804088, BCE loss: 0.552345, SB loss: 0.767922
2023-10-30 07:57:55,267 Epoch: [157/484] Iter:[360/495], Time: 0.37, lr: [0.007012322323835645], Loss: 2.120722, Acc:0.797346, Semantic loss: 0.802016, BCE loss: 0.551199, SB loss: 0.767507
2023-10-30 07:57:58,981 Epoch: [157/484] Iter:[370/495], Time: 0.37, lr: [0.007011931555151686], Loss: 2.119565, Acc:0.797405, Semantic loss: 0.801736, BCE loss: 0.550471, SB loss: 0.767358
2023-10-30 07:58:02,591 Epoch: [157/484] Iter:[380/495], Time: 0.37, lr: [0.0070115407840480246], Loss: 2.114659, Acc:0.797755, Semantic loss: 0.798651, BCE loss: 0.550060, SB loss: 0.765948
2023-10-30 07:58:06,289 Epoch: [157/484] Iter:[390/495], Time: 0.37, lr: [0.007011150010524498], Loss: 2.117072, Acc:0.797778, Semantic loss: 0.800385, BCE loss: 0.550076, SB loss: 0.766611
2023-10-30 07:58:09,886 Epoch: [157/484] Iter:[400/495], Time: 0.37, lr: [0.0070107592345809355], Loss: 2.116431, Acc:0.797508, Semantic loss: 0.800399, BCE loss: 0.549356, SB loss: 0.766676
2023-10-30 07:58:13,530 Epoch: [157/484] Iter:[410/495], Time: 0.37, lr: [0.007010368456217178], Loss: 2.113692, Acc:0.797628, Semantic loss: 0.799789, BCE loss: 0.548140, SB loss: 0.765763
2023-10-30 07:58:17,192 Epoch: [157/484] Iter:[420/495], Time: 0.37, lr: [0.007009977675433057], Loss: 2.111848, Acc:0.797086, Semantic loss: 0.799291, BCE loss: 0.546971, SB loss: 0.765586
2023-10-30 07:58:20,910 Epoch: [157/484] Iter:[430/495], Time: 0.37, lr: [0.007009586892228409], Loss: 2.111556, Acc:0.796824, Semantic loss: 0.799178, BCE loss: 0.547998, SB loss: 0.764380
2023-10-30 07:58:24,526 Epoch: [157/484] Iter:[440/495], Time: 0.37, lr: [0.00700919610660307], Loss: 2.108755, Acc:0.796361, Semantic loss: 0.797489, BCE loss: 0.547016, SB loss: 0.764249
2023-10-30 07:58:28,140 Epoch: [157/484] Iter:[450/495], Time: 0.37, lr: [0.007008805318556873], Loss: 2.106665, Acc:0.796310, Semantic loss: 0.796392, BCE loss: 0.546460, SB loss: 0.763812
2023-10-30 07:58:31,815 Epoch: [157/484] Iter:[460/495], Time: 0.37, lr: [0.007008414528089655], Loss: 2.107422, Acc:0.796206, Semantic loss: 0.797047, BCE loss: 0.545974, SB loss: 0.764400
2023-10-30 07:58:35,405 Epoch: [157/484] Iter:[470/495], Time: 0.37, lr: [0.007008023735201249], Loss: 2.109546, Acc:0.796680, Semantic loss: 0.797832, BCE loss: 0.547356, SB loss: 0.764358
2023-10-30 07:58:39,157 Epoch: [157/484] Iter:[480/495], Time: 0.37, lr: [0.007007632939891492], Loss: 2.107227, Acc:0.797144, Semantic loss: 0.795785, BCE loss: 0.547673, SB loss: 0.763769
2023-10-30 07:58:42,702 Epoch: [157/484] Iter:[490/495], Time: 0.37, lr: [0.007007242142160218], Loss: 2.108851, Acc:0.796868, Semantic loss: 0.796540, BCE loss: 0.548203, SB loss: 0.764108
2023-10-30 07:58:44,127 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 07:58:44,373 Loss: 2.047, MeanIU:  0.6984, Best_mIoU:  0.6984
2023-10-30 07:58:44,374 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272]
2023-10-30 07:58:46,823 Epoch: [158/484] Iter:[0/495], Time: 2.42, lr: [0.007007046742386459], Loss: 1.738391, Acc:0.888936, Semantic loss: 0.567677, BCE loss: 0.511680, SB loss: 0.659034
2023-10-30 07:58:50,758 Epoch: [158/484] Iter:[10/495], Time: 0.58, lr: [0.007006655941022601], Loss: 2.000546, Acc:0.782195, Semantic loss: 0.753991, BCE loss: 0.524292, SB loss: 0.722263
2023-10-30 07:58:54,390 Epoch: [158/484] Iter:[20/495], Time: 0.48, lr: [0.00700626513723681], Loss: 2.044080, Acc:0.768783, Semantic loss: 0.782845, BCE loss: 0.515163, SB loss: 0.746072
2023-10-30 07:58:58,064 Epoch: [158/484] Iter:[30/495], Time: 0.44, lr: [0.007005874331028926], Loss: 2.029509, Acc:0.782613, Semantic loss: 0.773592, BCE loss: 0.504632, SB loss: 0.751284
2023-10-30 07:59:01,840 Epoch: [158/484] Iter:[40/495], Time: 0.43, lr: [0.007005483522398784], Loss: 2.008521, Acc:0.790174, Semantic loss: 0.761965, BCE loss: 0.496927, SB loss: 0.749629
2023-10-30 07:59:05,520 Epoch: [158/484] Iter:[50/495], Time: 0.41, lr: [0.007005092711346215], Loss: 2.055004, Acc:0.792846, Semantic loss: 0.778821, BCE loss: 0.515488, SB loss: 0.760695
2023-10-30 07:59:09,328 Epoch: [158/484] Iter:[60/495], Time: 0.41, lr: [0.007004701897871056], Loss: 2.057547, Acc:0.799007, Semantic loss: 0.775885, BCE loss: 0.529880, SB loss: 0.751783
2023-10-30 07:59:13,017 Epoch: [158/484] Iter:[70/495], Time: 0.40, lr: [0.007004311081973142], Loss: 2.054418, Acc:0.800834, Semantic loss: 0.776370, BCE loss: 0.529335, SB loss: 0.748714
2023-10-30 07:59:16,713 Epoch: [158/484] Iter:[80/495], Time: 0.40, lr: [0.007003920263652305], Loss: 2.050498, Acc:0.805497, Semantic loss: 0.773282, BCE loss: 0.530688, SB loss: 0.746529
2023-10-30 07:59:20,356 Epoch: [158/484] Iter:[90/495], Time: 0.40, lr: [0.007003529442908384], Loss: 2.047148, Acc:0.809858, Semantic loss: 0.767766, BCE loss: 0.533034, SB loss: 0.746347
2023-10-30 07:59:23,999 Epoch: [158/484] Iter:[100/495], Time: 0.39, lr: [0.0070031386197412105], Loss: 2.039840, Acc:0.806998, Semantic loss: 0.764205, BCE loss: 0.528223, SB loss: 0.747412
2023-10-30 07:59:27,632 Epoch: [158/484] Iter:[110/495], Time: 0.39, lr: [0.007002747794150621], Loss: 2.039903, Acc:0.805880, Semantic loss: 0.771956, BCE loss: 0.522991, SB loss: 0.744956
2023-10-30 07:59:31,240 Epoch: [158/484] Iter:[120/495], Time: 0.39, lr: [0.007002356966136451], Loss: 2.050272, Acc:0.807862, Semantic loss: 0.772667, BCE loss: 0.528410, SB loss: 0.749195
2023-10-30 07:59:34,940 Epoch: [158/484] Iter:[130/495], Time: 0.39, lr: [0.007001966135698533], Loss: 2.053556, Acc:0.807214, Semantic loss: 0.772908, BCE loss: 0.528012, SB loss: 0.752636
2023-10-30 07:59:38,550 Epoch: [158/484] Iter:[140/495], Time: 0.38, lr: [0.007001575302836702], Loss: 2.056348, Acc:0.805708, Semantic loss: 0.772045, BCE loss: 0.531677, SB loss: 0.752626
2023-10-30 07:59:42,295 Epoch: [158/484] Iter:[150/495], Time: 0.38, lr: [0.007001184467550794], Loss: 2.059827, Acc:0.808390, Semantic loss: 0.775409, BCE loss: 0.531970, SB loss: 0.752448
2023-10-30 07:59:45,942 Epoch: [158/484] Iter:[160/495], Time: 0.38, lr: [0.007000793629840641], Loss: 2.063433, Acc:0.807077, Semantic loss: 0.779326, BCE loss: 0.531401, SB loss: 0.752705
2023-10-30 07:59:49,548 Epoch: [158/484] Iter:[170/495], Time: 0.38, lr: [0.007000402789706082], Loss: 2.066750, Acc:0.804865, Semantic loss: 0.783236, BCE loss: 0.528190, SB loss: 0.755324
2023-10-30 07:59:53,202 Epoch: [158/484] Iter:[180/495], Time: 0.38, lr: [0.007000011947146947], Loss: 2.067971, Acc:0.802379, Semantic loss: 0.782124, BCE loss: 0.529088, SB loss: 0.756759
2023-10-30 07:59:56,784 Epoch: [158/484] Iter:[190/495], Time: 0.38, lr: [0.006999621102163073], Loss: 2.083992, Acc:0.801168, Semantic loss: 0.795537, BCE loss: 0.529344, SB loss: 0.759110
2023-10-30 08:00:00,350 Epoch: [158/484] Iter:[200/495], Time: 0.38, lr: [0.006999230254754294], Loss: 2.083152, Acc:0.799490, Semantic loss: 0.795728, BCE loss: 0.528753, SB loss: 0.758671
2023-10-30 08:00:03,959 Epoch: [158/484] Iter:[210/495], Time: 0.38, lr: [0.006998839404920445], Loss: 2.084973, Acc:0.799276, Semantic loss: 0.796973, BCE loss: 0.529927, SB loss: 0.758073
2023-10-30 08:00:07,579 Epoch: [158/484] Iter:[220/495], Time: 0.38, lr: [0.006998448552661359], Loss: 2.086524, Acc:0.797374, Semantic loss: 0.797963, BCE loss: 0.530670, SB loss: 0.757891
2023-10-30 08:00:11,270 Epoch: [158/484] Iter:[230/495], Time: 0.38, lr: [0.006998057697976873], Loss: 2.092973, Acc:0.796699, Semantic loss: 0.801530, BCE loss: 0.533311, SB loss: 0.758132
2023-10-30 08:00:14,943 Epoch: [158/484] Iter:[240/495], Time: 0.38, lr: [0.006997666840866818], Loss: 2.090266, Acc:0.796812, Semantic loss: 0.799305, BCE loss: 0.532955, SB loss: 0.758005
2023-10-30 08:00:18,656 Epoch: [158/484] Iter:[250/495], Time: 0.38, lr: [0.00699727598133103], Loss: 2.098627, Acc:0.797412, Semantic loss: 0.803301, BCE loss: 0.534349, SB loss: 0.760977
2023-10-30 08:00:22,344 Epoch: [158/484] Iter:[260/495], Time: 0.38, lr: [0.006996885119369344], Loss: 2.098356, Acc:0.796518, Semantic loss: 0.802083, BCE loss: 0.535579, SB loss: 0.760694
2023-10-30 08:00:26,022 Epoch: [158/484] Iter:[270/495], Time: 0.37, lr: [0.006996494254981594], Loss: 2.097783, Acc:0.796147, Semantic loss: 0.801734, BCE loss: 0.536009, SB loss: 0.760040
2023-10-30 08:00:29,733 Epoch: [158/484] Iter:[280/495], Time: 0.37, lr: [0.006996103388167615], Loss: 2.100375, Acc:0.797525, Semantic loss: 0.804465, BCE loss: 0.537269, SB loss: 0.758641
2023-10-30 08:00:33,336 Epoch: [158/484] Iter:[290/495], Time: 0.37, lr: [0.006995712518927241], Loss: 2.097815, Acc:0.797257, Semantic loss: 0.802544, BCE loss: 0.536930, SB loss: 0.758340
2023-10-30 08:00:37,059 Epoch: [158/484] Iter:[300/495], Time: 0.37, lr: [0.006995321647260306], Loss: 2.098108, Acc:0.796882, Semantic loss: 0.802312, BCE loss: 0.536178, SB loss: 0.759618
2023-10-30 08:00:40,617 Epoch: [158/484] Iter:[310/495], Time: 0.37, lr: [0.006994930773166643], Loss: 2.099750, Acc:0.796660, Semantic loss: 0.802791, BCE loss: 0.537221, SB loss: 0.759738
2023-10-30 08:00:44,292 Epoch: [158/484] Iter:[320/495], Time: 0.37, lr: [0.006994539896646087], Loss: 2.100500, Acc:0.796040, Semantic loss: 0.801809, BCE loss: 0.538395, SB loss: 0.760297
2023-10-30 08:00:47,918 Epoch: [158/484] Iter:[330/495], Time: 0.37, lr: [0.006994149017698474], Loss: 2.100024, Acc:0.796998, Semantic loss: 0.801270, BCE loss: 0.539120, SB loss: 0.759635
2023-10-30 08:00:51,624 Epoch: [158/484] Iter:[340/495], Time: 0.37, lr: [0.006993758136323636], Loss: 2.099284, Acc:0.797050, Semantic loss: 0.800035, BCE loss: 0.539934, SB loss: 0.759316
2023-10-30 08:00:55,430 Epoch: [158/484] Iter:[350/495], Time: 0.37, lr: [0.006993367252521409], Loss: 2.097330, Acc:0.796951, Semantic loss: 0.798191, BCE loss: 0.539760, SB loss: 0.759378
2023-10-30 08:00:59,066 Epoch: [158/484] Iter:[360/495], Time: 0.37, lr: [0.006992976366291626], Loss: 2.096676, Acc:0.797464, Semantic loss: 0.796912, BCE loss: 0.541173, SB loss: 0.758591
2023-10-30 08:01:02,694 Epoch: [158/484] Iter:[370/495], Time: 0.37, lr: [0.0069925854776341214], Loss: 2.095727, Acc:0.797763, Semantic loss: 0.796918, BCE loss: 0.541277, SB loss: 0.757532
2023-10-30 08:01:06,372 Epoch: [158/484] Iter:[380/495], Time: 0.37, lr: [0.00699219458654873], Loss: 2.100354, Acc:0.796877, Semantic loss: 0.800446, BCE loss: 0.539906, SB loss: 0.760002
2023-10-30 08:01:09,994 Epoch: [158/484] Iter:[390/495], Time: 0.37, lr: [0.006991803693035285], Loss: 2.096503, Acc:0.797813, Semantic loss: 0.797482, BCE loss: 0.540103, SB loss: 0.758918
2023-10-30 08:01:13,605 Epoch: [158/484] Iter:[400/495], Time: 0.37, lr: [0.006991412797093619], Loss: 2.098676, Acc:0.797797, Semantic loss: 0.798309, BCE loss: 0.540829, SB loss: 0.759538
2023-10-30 08:01:17,274 Epoch: [158/484] Iter:[410/495], Time: 0.37, lr: [0.00699102189872357], Loss: 2.100011, Acc:0.798004, Semantic loss: 0.799871, BCE loss: 0.540430, SB loss: 0.759710
2023-10-30 08:01:21,048 Epoch: [158/484] Iter:[420/495], Time: 0.37, lr: [0.0069906309979249695], Loss: 2.098809, Acc:0.798060, Semantic loss: 0.797865, BCE loss: 0.542002, SB loss: 0.758941
2023-10-30 08:01:24,668 Epoch: [158/484] Iter:[430/495], Time: 0.37, lr: [0.006990240094697652], Loss: 2.097049, Acc:0.798193, Semantic loss: 0.795760, BCE loss: 0.542947, SB loss: 0.758343
2023-10-30 08:01:28,292 Epoch: [158/484] Iter:[440/495], Time: 0.37, lr: [0.00698984918904145], Loss: 2.097476, Acc:0.797772, Semantic loss: 0.795747, BCE loss: 0.542829, SB loss: 0.758900
2023-10-30 08:01:31,930 Epoch: [158/484] Iter:[450/495], Time: 0.37, lr: [0.0069894582809562015], Loss: 2.096084, Acc:0.798041, Semantic loss: 0.794839, BCE loss: 0.542644, SB loss: 0.758601
2023-10-30 08:01:35,648 Epoch: [158/484] Iter:[460/495], Time: 0.37, lr: [0.006989067370441737], Loss: 2.097548, Acc:0.798145, Semantic loss: 0.795247, BCE loss: 0.543167, SB loss: 0.759134
2023-10-30 08:01:39,328 Epoch: [158/484] Iter:[470/495], Time: 0.37, lr: [0.006988676457497891], Loss: 2.102027, Acc:0.798412, Semantic loss: 0.796698, BCE loss: 0.546097, SB loss: 0.759232
2023-10-30 08:01:42,965 Epoch: [158/484] Iter:[480/495], Time: 0.37, lr: [0.006988285542124496], Loss: 2.100282, Acc:0.798765, Semantic loss: 0.795546, BCE loss: 0.546106, SB loss: 0.758630
2023-10-30 08:01:46,419 Epoch: [158/484] Iter:[490/495], Time: 0.37, lr: [0.00698789462432139], Loss: 2.101115, Acc:0.799190, Semantic loss: 0.796601, BCE loss: 0.546060, SB loss: 0.758453
2023-10-30 08:01:47,823 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:01:48,064 Loss: 2.047, MeanIU:  0.6984, Best_mIoU:  0.6984
2023-10-30 08:01:48,064 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272]
2023-10-30 08:01:50,201 Epoch: [159/484] Iter:[0/495], Time: 2.10, lr: [0.006987699164508641], Loss: 2.842292, Acc:0.634848, Semantic loss: 1.299238, BCE loss: 0.477796, SB loss: 1.065258
2023-10-30 08:01:54,272 Epoch: [159/484] Iter:[10/495], Time: 0.56, lr: [0.006987308243060653], Loss: 2.076749, Acc:0.777160, Semantic loss: 0.814122, BCE loss: 0.485801, SB loss: 0.776827
2023-10-30 08:01:58,139 Epoch: [159/484] Iter:[20/495], Time: 0.48, lr: [0.006986917319182537], Loss: 2.078956, Acc:0.785079, Semantic loss: 0.793251, BCE loss: 0.513519, SB loss: 0.772186
2023-10-30 08:02:01,812 Epoch: [159/484] Iter:[30/495], Time: 0.44, lr: [0.006986526392874124], Loss: 2.071050, Acc:0.794187, Semantic loss: 0.774723, BCE loss: 0.532524, SB loss: 0.763803
2023-10-30 08:02:05,411 Epoch: [159/484] Iter:[40/495], Time: 0.42, lr: [0.00698613546413525], Loss: 2.062303, Acc:0.796913, Semantic loss: 0.774321, BCE loss: 0.532787, SB loss: 0.755194
2023-10-30 08:02:08,980 Epoch: [159/484] Iter:[50/495], Time: 0.41, lr: [0.00698574453296575], Loss: 2.079883, Acc:0.794724, Semantic loss: 0.805039, BCE loss: 0.519142, SB loss: 0.755702
2023-10-30 08:02:12,651 Epoch: [159/484] Iter:[60/495], Time: 0.40, lr: [0.0069853535993654545], Loss: 2.063069, Acc:0.788027, Semantic loss: 0.791208, BCE loss: 0.519417, SB loss: 0.752444
2023-10-30 08:02:16,291 Epoch: [159/484] Iter:[70/495], Time: 0.40, lr: [0.006984962663334201], Loss: 2.060828, Acc:0.787398, Semantic loss: 0.786905, BCE loss: 0.521370, SB loss: 0.752553
2023-10-30 08:02:19,933 Epoch: [159/484] Iter:[80/495], Time: 0.39, lr: [0.00698457172487182], Loss: 2.062461, Acc:0.787786, Semantic loss: 0.786283, BCE loss: 0.524500, SB loss: 0.751677
2023-10-30 08:02:23,560 Epoch: [159/484] Iter:[90/495], Time: 0.39, lr: [0.006984180783978147], Loss: 2.061417, Acc:0.787876, Semantic loss: 0.788266, BCE loss: 0.521248, SB loss: 0.751903
2023-10-30 08:02:27,150 Epoch: [159/484] Iter:[100/495], Time: 0.39, lr: [0.006983789840653016], Loss: 2.038984, Acc:0.789609, Semantic loss: 0.777698, BCE loss: 0.516125, SB loss: 0.745161
2023-10-30 08:02:30,735 Epoch: [159/484] Iter:[110/495], Time: 0.38, lr: [0.006983398894896259], Loss: 2.046789, Acc:0.788168, Semantic loss: 0.783502, BCE loss: 0.512786, SB loss: 0.750501
2023-10-30 08:02:34,383 Epoch: [159/484] Iter:[120/495], Time: 0.38, lr: [0.006983007946707712], Loss: 2.045006, Acc:0.786976, Semantic loss: 0.782955, BCE loss: 0.512050, SB loss: 0.750001
2023-10-30 08:02:38,157 Epoch: [159/484] Iter:[130/495], Time: 0.38, lr: [0.0069826169960872046], Loss: 2.054404, Acc:0.786745, Semantic loss: 0.784035, BCE loss: 0.518252, SB loss: 0.752118
2023-10-30 08:02:41,743 Epoch: [159/484] Iter:[140/495], Time: 0.38, lr: [0.006982226043034573], Loss: 2.066302, Acc:0.786202, Semantic loss: 0.789258, BCE loss: 0.522272, SB loss: 0.754772
2023-10-30 08:02:45,357 Epoch: [159/484] Iter:[150/495], Time: 0.38, lr: [0.006981835087549652], Loss: 2.060056, Acc:0.785294, Semantic loss: 0.782523, BCE loss: 0.523768, SB loss: 0.753766
2023-10-30 08:02:49,031 Epoch: [159/484] Iter:[160/495], Time: 0.38, lr: [0.006981444129632272], Loss: 2.060558, Acc:0.786328, Semantic loss: 0.784300, BCE loss: 0.523214, SB loss: 0.753044
2023-10-30 08:02:52,747 Epoch: [159/484] Iter:[170/495], Time: 0.38, lr: [0.006981053169282269], Loss: 2.059244, Acc:0.784218, Semantic loss: 0.783154, BCE loss: 0.522846, SB loss: 0.753243
2023-10-30 08:02:56,394 Epoch: [159/484] Iter:[180/495], Time: 0.38, lr: [0.006980662206499476], Loss: 2.051897, Acc:0.785245, Semantic loss: 0.777154, BCE loss: 0.523245, SB loss: 0.751498
2023-10-30 08:02:59,987 Epoch: [159/484] Iter:[190/495], Time: 0.38, lr: [0.006980271241283725], Loss: 2.052380, Acc:0.787792, Semantic loss: 0.776401, BCE loss: 0.526033, SB loss: 0.749946
2023-10-30 08:03:03,702 Epoch: [159/484] Iter:[200/495], Time: 0.38, lr: [0.006979880273634853], Loss: 2.049766, Acc:0.787252, Semantic loss: 0.776632, BCE loss: 0.522884, SB loss: 0.750249
2023-10-30 08:03:07,382 Epoch: [159/484] Iter:[210/495], Time: 0.38, lr: [0.006979489303552689], Loss: 2.052380, Acc:0.787367, Semantic loss: 0.776674, BCE loss: 0.523678, SB loss: 0.752028
2023-10-30 08:03:11,038 Epoch: [159/484] Iter:[220/495], Time: 0.38, lr: [0.006979098331037069], Loss: 2.051082, Acc:0.787646, Semantic loss: 0.777318, BCE loss: 0.522558, SB loss: 0.751205
2023-10-30 08:03:14,749 Epoch: [159/484] Iter:[230/495], Time: 0.38, lr: [0.006978707356087826], Loss: 2.049818, Acc:0.788371, Semantic loss: 0.775351, BCE loss: 0.524595, SB loss: 0.749871
2023-10-30 08:03:18,424 Epoch: [159/484] Iter:[240/495], Time: 0.37, lr: [0.006978316378704792], Loss: 2.051627, Acc:0.788097, Semantic loss: 0.775692, BCE loss: 0.525558, SB loss: 0.750378
2023-10-30 08:03:22,133 Epoch: [159/484] Iter:[250/495], Time: 0.37, lr: [0.006977925398887803], Loss: 2.051213, Acc:0.788917, Semantic loss: 0.777221, BCE loss: 0.523583, SB loss: 0.750409
2023-10-30 08:03:25,768 Epoch: [159/484] Iter:[260/495], Time: 0.37, lr: [0.006977534416636691], Loss: 2.051276, Acc:0.790053, Semantic loss: 0.775675, BCE loss: 0.526355, SB loss: 0.749245
2023-10-30 08:03:29,499 Epoch: [159/484] Iter:[270/495], Time: 0.37, lr: [0.006977143431951288], Loss: 2.055026, Acc:0.790253, Semantic loss: 0.777088, BCE loss: 0.527771, SB loss: 0.750167
2023-10-30 08:03:33,167 Epoch: [159/484] Iter:[280/495], Time: 0.37, lr: [0.006976752444831429], Loss: 2.060892, Acc:0.789274, Semantic loss: 0.779904, BCE loss: 0.527527, SB loss: 0.753461
2023-10-30 08:03:36,974 Epoch: [159/484] Iter:[290/495], Time: 0.37, lr: [0.006976361455276948], Loss: 2.068045, Acc:0.788692, Semantic loss: 0.784036, BCE loss: 0.529469, SB loss: 0.754540
2023-10-30 08:03:40,623 Epoch: [159/484] Iter:[300/495], Time: 0.37, lr: [0.0069759704632876745], Loss: 2.068542, Acc:0.788853, Semantic loss: 0.784136, BCE loss: 0.530491, SB loss: 0.753915
2023-10-30 08:03:44,218 Epoch: [159/484] Iter:[310/495], Time: 0.37, lr: [0.006975579468863445], Loss: 2.067985, Acc:0.788851, Semantic loss: 0.784238, BCE loss: 0.528632, SB loss: 0.755116
2023-10-30 08:03:47,876 Epoch: [159/484] Iter:[320/495], Time: 0.37, lr: [0.0069751884720040905], Loss: 2.065309, Acc:0.787994, Semantic loss: 0.782846, BCE loss: 0.527495, SB loss: 0.754968
2023-10-30 08:03:51,549 Epoch: [159/484] Iter:[330/495], Time: 0.37, lr: [0.006974797472709447], Loss: 2.062377, Acc:0.787602, Semantic loss: 0.781183, BCE loss: 0.526683, SB loss: 0.754511
2023-10-30 08:03:55,181 Epoch: [159/484] Iter:[340/495], Time: 0.37, lr: [0.0069744064709793465], Loss: 2.066333, Acc:0.787717, Semantic loss: 0.782465, BCE loss: 0.528663, SB loss: 0.755205
2023-10-30 08:03:58,848 Epoch: [159/484] Iter:[350/495], Time: 0.37, lr: [0.00697401546681362], Loss: 2.073130, Acc:0.787334, Semantic loss: 0.786384, BCE loss: 0.528658, SB loss: 0.758088
2023-10-30 08:04:02,657 Epoch: [159/484] Iter:[360/495], Time: 0.37, lr: [0.006973624460212105], Loss: 2.074069, Acc:0.787156, Semantic loss: 0.785732, BCE loss: 0.530401, SB loss: 0.757936
2023-10-30 08:04:06,337 Epoch: [159/484] Iter:[370/495], Time: 0.37, lr: [0.0069732334511746295], Loss: 2.071668, Acc:0.785962, Semantic loss: 0.784107, BCE loss: 0.529501, SB loss: 0.758060
2023-10-30 08:04:10,057 Epoch: [159/484] Iter:[380/495], Time: 0.37, lr: [0.006972842439701029], Loss: 2.075596, Acc:0.786368, Semantic loss: 0.784591, BCE loss: 0.533202, SB loss: 0.757803
2023-10-30 08:04:13,781 Epoch: [159/484] Iter:[390/495], Time: 0.37, lr: [0.006972451425791136], Loss: 2.078474, Acc:0.786841, Semantic loss: 0.786163, BCE loss: 0.534662, SB loss: 0.757649
2023-10-30 08:04:17,452 Epoch: [159/484] Iter:[400/495], Time: 0.37, lr: [0.006972060409444785], Loss: 2.076823, Acc:0.787894, Semantic loss: 0.784144, BCE loss: 0.535895, SB loss: 0.756785
2023-10-30 08:04:21,205 Epoch: [159/484] Iter:[410/495], Time: 0.37, lr: [0.006971669390661808], Loss: 2.077423, Acc:0.788392, Semantic loss: 0.783818, BCE loss: 0.536603, SB loss: 0.757002
2023-10-30 08:04:24,887 Epoch: [159/484] Iter:[420/495], Time: 0.37, lr: [0.006971278369442038], Loss: 2.075873, Acc:0.788907, Semantic loss: 0.782375, BCE loss: 0.537028, SB loss: 0.756470
2023-10-30 08:04:28,682 Epoch: [159/484] Iter:[430/495], Time: 0.37, lr: [0.006970887345785309], Loss: 2.079790, Acc:0.788893, Semantic loss: 0.784889, BCE loss: 0.536944, SB loss: 0.757957
2023-10-30 08:04:32,378 Epoch: [159/484] Iter:[440/495], Time: 0.37, lr: [0.006970496319691451], Loss: 2.080366, Acc:0.788739, Semantic loss: 0.784857, BCE loss: 0.537247, SB loss: 0.758262
2023-10-30 08:04:36,058 Epoch: [159/484] Iter:[450/495], Time: 0.37, lr: [0.006970105291160298], Loss: 2.086055, Acc:0.789132, Semantic loss: 0.787909, BCE loss: 0.538105, SB loss: 0.760041
2023-10-30 08:04:39,715 Epoch: [159/484] Iter:[460/495], Time: 0.37, lr: [0.006969714260191685], Loss: 2.087193, Acc:0.789254, Semantic loss: 0.787929, BCE loss: 0.539291, SB loss: 0.759973
2023-10-30 08:04:43,308 Epoch: [159/484] Iter:[470/495], Time: 0.37, lr: [0.006969323226785442], Loss: 2.089824, Acc:0.788133, Semantic loss: 0.790866, BCE loss: 0.537859, SB loss: 0.761098
2023-10-30 08:04:47,033 Epoch: [159/484] Iter:[480/495], Time: 0.37, lr: [0.006968932190941405], Loss: 2.086769, Acc:0.787466, Semantic loss: 0.790110, BCE loss: 0.536283, SB loss: 0.760376
2023-10-30 08:04:50,527 Epoch: [159/484] Iter:[490/495], Time: 0.37, lr: [0.006968541152659406], Loss: 2.090107, Acc:0.787914, Semantic loss: 0.792407, BCE loss: 0.536790, SB loss: 0.760910
2023-10-30 08:04:51,939 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:04:52,180 Loss: 2.047, MeanIU:  0.6984, Best_mIoU:  0.6984
2023-10-30 08:04:52,180 [0.97387837 0.8070412  0.90674758 0.41221838 0.55177574 0.57958621
 0.65141578 0.69464209 0.91198566 0.59867446 0.9298688  0.78267622
 0.56076611 0.92032722 0.50767694 0.75171452 0.53897457 0.46806596
 0.72131272]
2023-10-30 08:04:54,195 Epoch: [160/484] Iter:[0/495], Time: 1.98, lr: [0.006968345632604116], Loss: 2.298424, Acc:0.905756, Semantic loss: 0.800983, BCE loss: 0.678667, SB loss: 0.818773
2023-10-30 08:04:58,277 Epoch: [160/484] Iter:[10/495], Time: 0.55, lr: [0.006967954590664859], Loss: 2.194472, Acc:0.814077, Semantic loss: 0.834610, BCE loss: 0.604660, SB loss: 0.755201
2023-10-30 08:05:01,950 Epoch: [160/484] Iter:[20/495], Time: 0.46, lr: [0.006967563546287219], Loss: 2.156023, Acc:0.812507, Semantic loss: 0.808851, BCE loss: 0.587668, SB loss: 0.759503
2023-10-30 08:05:05,578 Epoch: [160/484] Iter:[30/495], Time: 0.43, lr: [0.006967172499471032], Loss: 2.200543, Acc:0.804824, Semantic loss: 0.834277, BCE loss: 0.569640, SB loss: 0.796626
2023-10-30 08:05:09,349 Epoch: [160/484] Iter:[40/495], Time: 0.42, lr: [0.006966781450216127], Loss: 2.175690, Acc:0.783100, Semantic loss: 0.820487, BCE loss: 0.564556, SB loss: 0.790647
2023-10-30 08:05:12,952 Epoch: [160/484] Iter:[50/495], Time: 0.41, lr: [0.006966390398522342], Loss: 2.157307, Acc:0.790244, Semantic loss: 0.800368, BCE loss: 0.573986, SB loss: 0.782954
2023-10-30 08:05:16,755 Epoch: [160/484] Iter:[60/495], Time: 0.40, lr: [0.006965999344389505], Loss: 2.155441, Acc:0.787715, Semantic loss: 0.805560, BCE loss: 0.571422, SB loss: 0.778459
2023-10-30 08:05:20,501 Epoch: [160/484] Iter:[70/495], Time: 0.40, lr: [0.006965608287817452], Loss: 2.151126, Acc:0.790604, Semantic loss: 0.801369, BCE loss: 0.571261, SB loss: 0.778496
2023-10-30 08:05:24,273 Epoch: [160/484] Iter:[80/495], Time: 0.40, lr: [0.006965217228806013], Loss: 2.152909, Acc:0.793409, Semantic loss: 0.806995, BCE loss: 0.569944, SB loss: 0.775970
2023-10-30 08:05:27,970 Epoch: [160/484] Iter:[90/495], Time: 0.39, lr: [0.0069648261673550226], Loss: 2.163187, Acc:0.795612, Semantic loss: 0.815224, BCE loss: 0.568782, SB loss: 0.779180
2023-10-30 08:05:31,575 Epoch: [160/484] Iter:[100/495], Time: 0.39, lr: [0.006964435103464312], Loss: 2.143935, Acc:0.795095, Semantic loss: 0.807560, BCE loss: 0.558676, SB loss: 0.777699
2023-10-30 08:05:35,195 Epoch: [160/484] Iter:[110/495], Time: 0.39, lr: [0.0069640440371337145], Loss: 2.148768, Acc:0.792696, Semantic loss: 0.808099, BCE loss: 0.563008, SB loss: 0.777662
2023-10-30 08:05:38,862 Epoch: [160/484] Iter:[120/495], Time: 0.39, lr: [0.006963652968363062], Loss: 2.141209, Acc:0.792813, Semantic loss: 0.805921, BCE loss: 0.560238, SB loss: 0.775050
2023-10-30 08:05:42,584 Epoch: [160/484] Iter:[130/495], Time: 0.38, lr: [0.006963261897152188], Loss: 2.132573, Acc:0.790792, Semantic loss: 0.803871, BCE loss: 0.554181, SB loss: 0.774521
2023-10-30 08:05:46,291 Epoch: [160/484] Iter:[140/495], Time: 0.38, lr: [0.006962870823500923], Loss: 2.130240, Acc:0.792186, Semantic loss: 0.805129, BCE loss: 0.553259, SB loss: 0.771852
2023-10-30 08:05:49,995 Epoch: [160/484] Iter:[150/495], Time: 0.38, lr: [0.006962479747409101], Loss: 2.126262, Acc:0.794184, Semantic loss: 0.801057, BCE loss: 0.555458, SB loss: 0.769748
2023-10-30 08:05:53,663 Epoch: [160/484] Iter:[160/495], Time: 0.38, lr: [0.0069620886688765565], Loss: 2.126932, Acc:0.793530, Semantic loss: 0.803726, BCE loss: 0.554260, SB loss: 0.768946
2023-10-30 08:05:57,208 Epoch: [160/484] Iter:[170/495], Time: 0.38, lr: [0.006961697587903119], Loss: 2.121914, Acc:0.790927, Semantic loss: 0.801650, BCE loss: 0.551077, SB loss: 0.769187
2023-10-30 08:06:00,945 Epoch: [160/484] Iter:[180/495], Time: 0.38, lr: [0.0069613065044886215], Loss: 2.125897, Acc:0.788865, Semantic loss: 0.805668, BCE loss: 0.550724, SB loss: 0.769505
2023-10-30 08:06:04,681 Epoch: [160/484] Iter:[190/495], Time: 0.38, lr: [0.006960915418632896], Loss: 2.137754, Acc:0.788597, Semantic loss: 0.811565, BCE loss: 0.555965, SB loss: 0.770225
2023-10-30 08:06:08,302 Epoch: [160/484] Iter:[200/495], Time: 0.38, lr: [0.006960524330335774], Loss: 2.132574, Acc:0.788225, Semantic loss: 0.807054, BCE loss: 0.555392, SB loss: 0.770129
2023-10-30 08:06:12,041 Epoch: [160/484] Iter:[210/495], Time: 0.38, lr: [0.006960133239597092], Loss: 2.130698, Acc:0.788276, Semantic loss: 0.805262, BCE loss: 0.555940, SB loss: 0.769496
2023-10-30 08:06:15,672 Epoch: [160/484] Iter:[220/495], Time: 0.38, lr: [0.006959742146416678], Loss: 2.128603, Acc:0.788912, Semantic loss: 0.804829, BCE loss: 0.554636, SB loss: 0.769139
2023-10-30 08:06:19,344 Epoch: [160/484] Iter:[230/495], Time: 0.38, lr: [0.006959351050794367], Loss: 2.125532, Acc:0.788220, Semantic loss: 0.802982, BCE loss: 0.555199, SB loss: 0.767351
2023-10-30 08:06:22,968 Epoch: [160/484] Iter:[240/495], Time: 0.38, lr: [0.006958959952729989], Loss: 2.128143, Acc:0.788385, Semantic loss: 0.805803, BCE loss: 0.554583, SB loss: 0.767758
2023-10-30 08:06:26,686 Epoch: [160/484] Iter:[250/495], Time: 0.38, lr: [0.006958568852223378], Loss: 2.129206, Acc:0.788210, Semantic loss: 0.806049, BCE loss: 0.554619, SB loss: 0.768538
2023-10-30 08:06:30,335 Epoch: [160/484] Iter:[260/495], Time: 0.38, lr: [0.006958177749274366], Loss: 2.122676, Acc:0.789412, Semantic loss: 0.803081, BCE loss: 0.552534, SB loss: 0.767061
2023-10-30 08:06:33,985 Epoch: [160/484] Iter:[270/495], Time: 0.38, lr: [0.006957786643882784], Loss: 2.116599, Acc:0.789615, Semantic loss: 0.800217, BCE loss: 0.550947, SB loss: 0.765435
2023-10-30 08:06:37,641 Epoch: [160/484] Iter:[280/495], Time: 0.38, lr: [0.006957395536048467], Loss: 2.126540, Acc:0.790127, Semantic loss: 0.805150, BCE loss: 0.553891, SB loss: 0.767498
2023-10-30 08:06:41,528 Epoch: [160/484] Iter:[290/495], Time: 0.38, lr: [0.006957004425771241], Loss: 2.124730, Acc:0.790870, Semantic loss: 0.803155, BCE loss: 0.554809, SB loss: 0.766766
2023-10-30 08:06:45,182 Epoch: [160/484] Iter:[300/495], Time: 0.38, lr: [0.006956613313050946], Loss: 2.124529, Acc:0.790613, Semantic loss: 0.803025, BCE loss: 0.554918, SB loss: 0.766586
2023-10-30 08:06:48,867 Epoch: [160/484] Iter:[310/495], Time: 0.38, lr: [0.006956222197887409], Loss: 2.122776, Acc:0.788943, Semantic loss: 0.802016, BCE loss: 0.554128, SB loss: 0.766632
2023-10-30 08:06:52,488 Epoch: [160/484] Iter:[320/495], Time: 0.37, lr: [0.006955831080280465], Loss: 2.120089, Acc:0.789732, Semantic loss: 0.801072, BCE loss: 0.553410, SB loss: 0.765607
2023-10-30 08:06:56,200 Epoch: [160/484] Iter:[330/495], Time: 0.37, lr: [0.006955439960229945], Loss: 2.121482, Acc:0.790671, Semantic loss: 0.801171, BCE loss: 0.554179, SB loss: 0.766133
2023-10-30 08:06:59,919 Epoch: [160/484] Iter:[340/495], Time: 0.37, lr: [0.006955048837735679], Loss: 2.117980, Acc:0.790282, Semantic loss: 0.799016, BCE loss: 0.553530, SB loss: 0.765433
2023-10-30 08:07:03,622 Epoch: [160/484] Iter:[350/495], Time: 0.37, lr: [0.006954657712797501], Loss: 2.114713, Acc:0.790332, Semantic loss: 0.797725, BCE loss: 0.552185, SB loss: 0.764802
2023-10-30 08:07:07,283 Epoch: [160/484] Iter:[360/495], Time: 0.37, lr: [0.006954266585415243], Loss: 2.117131, Acc:0.790515, Semantic loss: 0.798772, BCE loss: 0.552683, SB loss: 0.765676
2023-10-30 08:07:10,965 Epoch: [160/484] Iter:[370/495], Time: 0.37, lr: [0.006953875455588736], Loss: 2.114607, Acc:0.790319, Semantic loss: 0.798169, BCE loss: 0.551481, SB loss: 0.764957
2023-10-30 08:07:14,594 Epoch: [160/484] Iter:[380/495], Time: 0.37, lr: [0.006953484323317814], Loss: 2.111936, Acc:0.790398, Semantic loss: 0.796342, BCE loss: 0.551887, SB loss: 0.763707
2023-10-30 08:07:18,252 Epoch: [160/484] Iter:[390/495], Time: 0.37, lr: [0.006953093188602308], Loss: 2.107690, Acc:0.790886, Semantic loss: 0.794376, BCE loss: 0.551146, SB loss: 0.762167
2023-10-30 08:07:21,904 Epoch: [160/484] Iter:[400/495], Time: 0.37, lr: [0.006952702051442048], Loss: 2.108756, Acc:0.792007, Semantic loss: 0.794066, BCE loss: 0.552581, SB loss: 0.762109
2023-10-30 08:07:25,618 Epoch: [160/484] Iter:[410/495], Time: 0.37, lr: [0.006952310911836869], Loss: 2.106454, Acc:0.792505, Semantic loss: 0.793169, BCE loss: 0.551827, SB loss: 0.761458
2023-10-30 08:07:29,384 Epoch: [160/484] Iter:[420/495], Time: 0.37, lr: [0.006951919769786601], Loss: 2.107815, Acc:0.792646, Semantic loss: 0.793724, BCE loss: 0.552649, SB loss: 0.761442
2023-10-30 08:07:33,011 Epoch: [160/484] Iter:[430/495], Time: 0.37, lr: [0.006951528625291074], Loss: 2.105083, Acc:0.793188, Semantic loss: 0.791982, BCE loss: 0.552264, SB loss: 0.760837
2023-10-30 08:07:36,715 Epoch: [160/484] Iter:[440/495], Time: 0.37, lr: [0.006951137478350126], Loss: 2.106888, Acc:0.793752, Semantic loss: 0.792680, BCE loss: 0.552868, SB loss: 0.761340
2023-10-30 08:07:40,508 Epoch: [160/484] Iter:[450/495], Time: 0.37, lr: [0.006950746328963581], Loss: 2.108921, Acc:0.793939, Semantic loss: 0.793071, BCE loss: 0.554713, SB loss: 0.761137
2023-10-30 08:07:44,134 Epoch: [160/484] Iter:[460/495], Time: 0.37, lr: [0.006950355177131277], Loss: 2.111266, Acc:0.793828, Semantic loss: 0.794796, BCE loss: 0.555052, SB loss: 0.761418
2023-10-30 08:07:47,802 Epoch: [160/484] Iter:[470/495], Time: 0.37, lr: [0.0069499640228530436], Loss: 2.116037, Acc:0.793014, Semantic loss: 0.799275, BCE loss: 0.555025, SB loss: 0.761737
2023-10-30 08:07:51,486 Epoch: [160/484] Iter:[480/495], Time: 0.37, lr: [0.0069495728661287115], Loss: 2.119114, Acc:0.792832, Semantic loss: 0.803475, BCE loss: 0.554060, SB loss: 0.761579
2023-10-30 08:07:54,998 Epoch: [160/484] Iter:[490/495], Time: 0.37, lr: [0.006949181706958114], Loss: 2.119732, Acc:0.792689, Semantic loss: 0.803996, BCE loss: 0.553323, SB loss: 0.762413
2023-10-30 08:10:51,940 0 [0.91361362 0.61436577 0.79792488 0.08852379 0.23500906 0.39945781
 0.42764587 0.54380071 0.87300138 0.44667851 0.81983081 0.58157796
 0.02751033 0.7684382  0.00737138 0.05304103 0.08164589 0.04393741
 0.55610454] 0.4357620492417143
2023-10-30 08:10:51,941 1 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539] 0.6310689413389643
2023-10-30 08:10:51,944 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:10:52,183 Loss: 2.152, MeanIU:  0.6311, Best_mIoU:  0.6984
2023-10-30 08:10:52,183 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539]
2023-10-30 08:10:54,120 Epoch: [161/484] Iter:[0/495], Time: 1.90, lr: [0.006948986126455412], Loss: 1.935970, Acc:0.822411, Semantic loss: 0.684259, BCE loss: 0.541799, SB loss: 0.709912
2023-10-30 08:10:57,869 Epoch: [161/484] Iter:[10/495], Time: 0.51, lr: [0.0069485949636151], Loss: 2.071969, Acc:0.798715, Semantic loss: 0.762734, BCE loss: 0.503309, SB loss: 0.805927
2023-10-30 08:11:01,340 Epoch: [161/484] Iter:[20/495], Time: 0.43, lr: [0.0069482037983281], Loss: 2.036638, Acc:0.795496, Semantic loss: 0.749792, BCE loss: 0.512082, SB loss: 0.774764
2023-10-30 08:11:04,886 Epoch: [161/484] Iter:[30/495], Time: 0.41, lr: [0.0069478126305942455], Loss: 2.031002, Acc:0.797042, Semantic loss: 0.756313, BCE loss: 0.510080, SB loss: 0.764609
2023-10-30 08:11:08,328 Epoch: [161/484] Iter:[40/495], Time: 0.39, lr: [0.006947421460413367], Loss: 2.048033, Acc:0.796738, Semantic loss: 0.762953, BCE loss: 0.524739, SB loss: 0.760341
2023-10-30 08:11:11,757 Epoch: [161/484] Iter:[50/495], Time: 0.38, lr: [0.006947030287785296], Loss: 2.037684, Acc:0.798924, Semantic loss: 0.762515, BCE loss: 0.518096, SB loss: 0.757073
2023-10-30 08:11:15,254 Epoch: [161/484] Iter:[60/495], Time: 0.38, lr: [0.006946639112709866], Loss: 2.034545, Acc:0.792282, Semantic loss: 0.764593, BCE loss: 0.511354, SB loss: 0.758599
2023-10-30 08:11:18,831 Epoch: [161/484] Iter:[70/495], Time: 0.37, lr: [0.006946247935186907], Loss: 2.052390, Acc:0.790926, Semantic loss: 0.771832, BCE loss: 0.520746, SB loss: 0.759813
2023-10-30 08:11:22,308 Epoch: [161/484] Iter:[80/495], Time: 0.37, lr: [0.00694585675521625], Loss: 2.054843, Acc:0.789509, Semantic loss: 0.768107, BCE loss: 0.528575, SB loss: 0.758161
2023-10-30 08:11:25,845 Epoch: [161/484] Iter:[90/495], Time: 0.37, lr: [0.0069454655727977255], Loss: 2.042737, Acc:0.792794, Semantic loss: 0.760145, BCE loss: 0.530761, SB loss: 0.751832
2023-10-30 08:11:29,472 Epoch: [161/484] Iter:[100/495], Time: 0.37, lr: [0.00694507438793117], Loss: 2.055082, Acc:0.791532, Semantic loss: 0.766896, BCE loss: 0.534548, SB loss: 0.753638
2023-10-30 08:11:33,111 Epoch: [161/484] Iter:[110/495], Time: 0.37, lr: [0.006944683200616408], Loss: 2.051804, Acc:0.793193, Semantic loss: 0.765553, BCE loss: 0.531471, SB loss: 0.754780
2023-10-30 08:11:36,805 Epoch: [161/484] Iter:[120/495], Time: 0.37, lr: [0.006944292010853277], Loss: 2.069714, Acc:0.793117, Semantic loss: 0.772233, BCE loss: 0.534267, SB loss: 0.763214
2023-10-30 08:11:40,431 Epoch: [161/484] Iter:[130/495], Time: 0.37, lr: [0.006943900818641606], Loss: 2.075491, Acc:0.796496, Semantic loss: 0.772477, BCE loss: 0.540478, SB loss: 0.762536
2023-10-30 08:11:44,026 Epoch: [161/484] Iter:[140/495], Time: 0.37, lr: [0.0069435096239812266], Loss: 2.087646, Acc:0.796444, Semantic loss: 0.781644, BCE loss: 0.537770, SB loss: 0.768232
2023-10-30 08:11:47,568 Epoch: [161/484] Iter:[150/495], Time: 0.37, lr: [0.006943118426871971], Loss: 2.092430, Acc:0.796306, Semantic loss: 0.784939, BCE loss: 0.537184, SB loss: 0.770307
2023-10-30 08:11:51,166 Epoch: [161/484] Iter:[160/495], Time: 0.37, lr: [0.006942727227313668], Loss: 2.082266, Acc:0.798540, Semantic loss: 0.782085, BCE loss: 0.533844, SB loss: 0.766337
2023-10-30 08:11:54,708 Epoch: [161/484] Iter:[170/495], Time: 0.37, lr: [0.00694233602530615], Loss: 2.079143, Acc:0.798782, Semantic loss: 0.781746, BCE loss: 0.531204, SB loss: 0.766192
2023-10-30 08:11:58,349 Epoch: [161/484] Iter:[180/495], Time: 0.37, lr: [0.00694194482084925], Loss: 2.081051, Acc:0.799340, Semantic loss: 0.784027, BCE loss: 0.532221, SB loss: 0.764803
2023-10-30 08:12:01,926 Epoch: [161/484] Iter:[190/495], Time: 0.36, lr: [0.0069415536139427955], Loss: 2.076902, Acc:0.801375, Semantic loss: 0.780614, BCE loss: 0.534187, SB loss: 0.762102
2023-10-30 08:12:05,522 Epoch: [161/484] Iter:[200/495], Time: 0.36, lr: [0.006941162404586623], Loss: 2.081616, Acc:0.801851, Semantic loss: 0.781362, BCE loss: 0.537206, SB loss: 0.763047
2023-10-30 08:12:09,088 Epoch: [161/484] Iter:[210/495], Time: 0.36, lr: [0.006940771192780562], Loss: 2.075707, Acc:0.800762, Semantic loss: 0.779324, BCE loss: 0.535224, SB loss: 0.761159
2023-10-30 08:12:12,643 Epoch: [161/484] Iter:[220/495], Time: 0.36, lr: [0.006940379978524441], Loss: 2.079607, Acc:0.799377, Semantic loss: 0.783335, BCE loss: 0.534006, SB loss: 0.762265
2023-10-30 08:12:16,255 Epoch: [161/484] Iter:[230/495], Time: 0.36, lr: [0.006939988761818093], Loss: 2.076744, Acc:0.797850, Semantic loss: 0.781939, BCE loss: 0.532722, SB loss: 0.762083
2023-10-30 08:12:19,907 Epoch: [161/484] Iter:[240/495], Time: 0.36, lr: [0.006939597542661351], Loss: 2.084139, Acc:0.797282, Semantic loss: 0.785627, BCE loss: 0.535879, SB loss: 0.762633
2023-10-30 08:12:23,439 Epoch: [161/484] Iter:[250/495], Time: 0.36, lr: [0.006939206321054043], Loss: 2.079013, Acc:0.797546, Semantic loss: 0.782179, BCE loss: 0.535821, SB loss: 0.761013
2023-10-30 08:12:27,080 Epoch: [161/484] Iter:[260/495], Time: 0.36, lr: [0.006938815096996002], Loss: 2.076812, Acc:0.797927, Semantic loss: 0.779723, BCE loss: 0.536694, SB loss: 0.760396
2023-10-30 08:12:30,746 Epoch: [161/484] Iter:[270/495], Time: 0.36, lr: [0.006938423870487057], Loss: 2.079687, Acc:0.798769, Semantic loss: 0.779336, BCE loss: 0.539621, SB loss: 0.760730
2023-10-30 08:12:34,398 Epoch: [161/484] Iter:[280/495], Time: 0.36, lr: [0.0069380326415270435], Loss: 2.078965, Acc:0.797391, Semantic loss: 0.778907, BCE loss: 0.539805, SB loss: 0.760253
2023-10-30 08:12:38,071 Epoch: [161/484] Iter:[290/495], Time: 0.36, lr: [0.006937641410115788], Loss: 2.077215, Acc:0.796570, Semantic loss: 0.778191, BCE loss: 0.538798, SB loss: 0.760226
2023-10-30 08:12:41,723 Epoch: [161/484] Iter:[300/495], Time: 0.36, lr: [0.006937250176253125], Loss: 2.075382, Acc:0.795789, Semantic loss: 0.777687, BCE loss: 0.538788, SB loss: 0.758907
2023-10-30 08:12:45,484 Epoch: [161/484] Iter:[310/495], Time: 0.36, lr: [0.0069368589399388825], Loss: 2.076555, Acc:0.795551, Semantic loss: 0.777417, BCE loss: 0.540272, SB loss: 0.758866
2023-10-30 08:12:49,154 Epoch: [161/484] Iter:[320/495], Time: 0.36, lr: [0.006936467701172894], Loss: 2.077060, Acc:0.796345, Semantic loss: 0.777143, BCE loss: 0.541608, SB loss: 0.758309
2023-10-30 08:12:52,827 Epoch: [161/484] Iter:[330/495], Time: 0.36, lr: [0.006936076459954988], Loss: 2.082334, Acc:0.796380, Semantic loss: 0.779064, BCE loss: 0.543231, SB loss: 0.760039
2023-10-30 08:12:56,408 Epoch: [161/484] Iter:[340/495], Time: 0.36, lr: [0.006935685216284998], Loss: 2.078275, Acc:0.796852, Semantic loss: 0.777164, BCE loss: 0.542663, SB loss: 0.758448
2023-10-30 08:13:00,095 Epoch: [161/484] Iter:[350/495], Time: 0.36, lr: [0.006935293970162753], Loss: 2.075725, Acc:0.796417, Semantic loss: 0.775443, BCE loss: 0.542973, SB loss: 0.757309
2023-10-30 08:13:03,724 Epoch: [161/484] Iter:[360/495], Time: 0.36, lr: [0.006934902721588086], Loss: 2.077053, Acc:0.796040, Semantic loss: 0.777676, BCE loss: 0.542461, SB loss: 0.756917
2023-10-30 08:13:07,450 Epoch: [161/484] Iter:[370/495], Time: 0.36, lr: [0.006934511470560825], Loss: 2.076313, Acc:0.797014, Semantic loss: 0.777334, BCE loss: 0.542793, SB loss: 0.756186
2023-10-30 08:13:11,106 Epoch: [161/484] Iter:[380/495], Time: 0.36, lr: [0.006934120217080804], Loss: 2.073909, Acc:0.797651, Semantic loss: 0.776302, BCE loss: 0.541977, SB loss: 0.755629
2023-10-30 08:13:14,712 Epoch: [161/484] Iter:[390/495], Time: 0.36, lr: [0.0069337289611478515], Loss: 2.074481, Acc:0.798088, Semantic loss: 0.776928, BCE loss: 0.542202, SB loss: 0.755350
2023-10-30 08:13:18,369 Epoch: [161/484] Iter:[400/495], Time: 0.36, lr: [0.0069333377027618], Loss: 2.074757, Acc:0.798493, Semantic loss: 0.778015, BCE loss: 0.541710, SB loss: 0.755031
2023-10-30 08:13:22,104 Epoch: [161/484] Iter:[410/495], Time: 0.36, lr: [0.0069329464419224775], Loss: 2.070626, Acc:0.798548, Semantic loss: 0.776664, BCE loss: 0.539525, SB loss: 0.754437
2023-10-30 08:13:25,721 Epoch: [161/484] Iter:[420/495], Time: 0.36, lr: [0.006932555178629718], Loss: 2.069066, Acc:0.799758, Semantic loss: 0.775975, BCE loss: 0.539251, SB loss: 0.753840
2023-10-30 08:13:29,336 Epoch: [161/484] Iter:[430/495], Time: 0.36, lr: [0.00693216391288335], Loss: 2.070977, Acc:0.799923, Semantic loss: 0.776896, BCE loss: 0.540156, SB loss: 0.753925
2023-10-30 08:13:33,034 Epoch: [161/484] Iter:[440/495], Time: 0.36, lr: [0.006931772644683206], Loss: 2.071131, Acc:0.799972, Semantic loss: 0.777892, BCE loss: 0.539688, SB loss: 0.753551
2023-10-30 08:13:36,823 Epoch: [161/484] Iter:[450/495], Time: 0.36, lr: [0.006931381374029118], Loss: 2.074731, Acc:0.800131, Semantic loss: 0.779086, BCE loss: 0.541918, SB loss: 0.753727
2023-10-30 08:13:40,595 Epoch: [161/484] Iter:[460/495], Time: 0.37, lr: [0.006930990100920912], Loss: 2.078996, Acc:0.800420, Semantic loss: 0.781049, BCE loss: 0.543097, SB loss: 0.754849
2023-10-30 08:13:44,266 Epoch: [161/484] Iter:[470/495], Time: 0.37, lr: [0.006930598825358423], Loss: 2.081349, Acc:0.800410, Semantic loss: 0.782576, BCE loss: 0.544085, SB loss: 0.754689
2023-10-30 08:13:47,922 Epoch: [161/484] Iter:[480/495], Time: 0.37, lr: [0.006930207547341478], Loss: 2.080228, Acc:0.801116, Semantic loss: 0.781774, BCE loss: 0.544159, SB loss: 0.754295
2023-10-30 08:13:51,351 Epoch: [161/484] Iter:[490/495], Time: 0.36, lr: [0.006929816266869911], Loss: 2.076650, Acc:0.800866, Semantic loss: 0.779803, BCE loss: 0.543201, SB loss: 0.753647
2023-10-30 08:13:52,741 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:13:52,987 Loss: 2.152, MeanIU:  0.6311, Best_mIoU:  0.6984
2023-10-30 08:13:52,987 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539]
2023-10-30 08:13:55,059 Epoch: [162/484] Iter:[0/495], Time: 2.04, lr: [0.00692962062571359], Loss: 1.674101, Acc:0.652583, Semantic loss: 0.639590, BCE loss: 0.295079, SB loss: 0.739433
2023-10-30 08:13:59,064 Epoch: [162/484] Iter:[10/495], Time: 0.55, lr: [0.0069292293415597695], Loss: 2.022994, Acc:0.803703, Semantic loss: 0.760022, BCE loss: 0.510573, SB loss: 0.752399
2023-10-30 08:14:02,713 Epoch: [162/484] Iter:[20/495], Time: 0.46, lr: [0.006928838054950902], Loss: 2.075821, Acc:0.796283, Semantic loss: 0.784885, BCE loss: 0.538277, SB loss: 0.752658
2023-10-30 08:14:06,368 Epoch: [162/484] Iter:[30/495], Time: 0.43, lr: [0.00692844676588682], Loss: 2.060407, Acc:0.795351, Semantic loss: 0.774531, BCE loss: 0.540056, SB loss: 0.745820
2023-10-30 08:14:10,163 Epoch: [162/484] Iter:[40/495], Time: 0.42, lr: [0.006928055474367351], Loss: 2.048988, Acc:0.802534, Semantic loss: 0.758672, BCE loss: 0.550730, SB loss: 0.739586
2023-10-30 08:14:13,797 Epoch: [162/484] Iter:[50/495], Time: 0.41, lr: [0.006927664180392326], Loss: 2.050832, Acc:0.805696, Semantic loss: 0.760109, BCE loss: 0.551708, SB loss: 0.739015
2023-10-30 08:14:17,473 Epoch: [162/484] Iter:[60/495], Time: 0.40, lr: [0.0069272728839615775], Loss: 2.094436, Acc:0.800940, Semantic loss: 0.796485, BCE loss: 0.557095, SB loss: 0.740856
2023-10-30 08:14:21,137 Epoch: [162/484] Iter:[70/495], Time: 0.40, lr: [0.006926881585074932], Loss: 2.101703, Acc:0.799326, Semantic loss: 0.803132, BCE loss: 0.554917, SB loss: 0.743653
2023-10-30 08:14:24,742 Epoch: [162/484] Iter:[80/495], Time: 0.39, lr: [0.006926490283732224], Loss: 2.103291, Acc:0.801726, Semantic loss: 0.796500, BCE loss: 0.562461, SB loss: 0.744330
2023-10-30 08:14:28,416 Epoch: [162/484] Iter:[90/495], Time: 0.39, lr: [0.0069260989799332815], Loss: 2.088764, Acc:0.798663, Semantic loss: 0.789204, BCE loss: 0.559745, SB loss: 0.739815
2023-10-30 08:14:32,086 Epoch: [162/484] Iter:[100/495], Time: 0.39, lr: [0.006925707673677938], Loss: 2.092339, Acc:0.796278, Semantic loss: 0.789638, BCE loss: 0.559756, SB loss: 0.742945
2023-10-30 08:14:35,732 Epoch: [162/484] Iter:[110/495], Time: 0.38, lr: [0.00692531636496602], Loss: 2.087475, Acc:0.796451, Semantic loss: 0.784626, BCE loss: 0.559651, SB loss: 0.743199
2023-10-30 08:14:39,403 Epoch: [162/484] Iter:[120/495], Time: 0.38, lr: [0.006924925053797361], Loss: 2.083086, Acc:0.796866, Semantic loss: 0.782324, BCE loss: 0.557752, SB loss: 0.743009
2023-10-30 08:14:43,036 Epoch: [162/484] Iter:[130/495], Time: 0.38, lr: [0.0069245337401717885], Loss: 2.067484, Acc:0.798081, Semantic loss: 0.772896, BCE loss: 0.554035, SB loss: 0.740552
2023-10-30 08:14:46,772 Epoch: [162/484] Iter:[140/495], Time: 0.38, lr: [0.006924142424089135], Loss: 2.065803, Acc:0.798354, Semantic loss: 0.772957, BCE loss: 0.553356, SB loss: 0.739490
2023-10-30 08:14:50,468 Epoch: [162/484] Iter:[150/495], Time: 0.38, lr: [0.006923751105549229], Loss: 2.067297, Acc:0.798570, Semantic loss: 0.774232, BCE loss: 0.552706, SB loss: 0.740359
2023-10-30 08:14:54,205 Epoch: [162/484] Iter:[160/495], Time: 0.38, lr: [0.006923359784551901], Loss: 2.063701, Acc:0.799095, Semantic loss: 0.775493, BCE loss: 0.548417, SB loss: 0.739791
2023-10-30 08:14:57,832 Epoch: [162/484] Iter:[170/495], Time: 0.38, lr: [0.006922968461096983], Loss: 2.058234, Acc:0.801284, Semantic loss: 0.772344, BCE loss: 0.548084, SB loss: 0.737807
2023-10-30 08:15:01,451 Epoch: [162/484] Iter:[180/495], Time: 0.38, lr: [0.006922577135184305], Loss: 2.054715, Acc:0.801534, Semantic loss: 0.773320, BCE loss: 0.543840, SB loss: 0.737555
2023-10-30 08:15:05,127 Epoch: [162/484] Iter:[190/495], Time: 0.38, lr: [0.006922185806813696], Loss: 2.047941, Acc:0.801172, Semantic loss: 0.769513, BCE loss: 0.542037, SB loss: 0.736391
2023-10-30 08:15:08,796 Epoch: [162/484] Iter:[200/495], Time: 0.38, lr: [0.006921794475984986], Loss: 2.048550, Acc:0.799412, Semantic loss: 0.771224, BCE loss: 0.538491, SB loss: 0.738836
2023-10-30 08:15:12,401 Epoch: [162/484] Iter:[210/495], Time: 0.38, lr: [0.006921403142698005], Loss: 2.053429, Acc:0.798688, Semantic loss: 0.776115, BCE loss: 0.536991, SB loss: 0.740323
2023-10-30 08:15:16,010 Epoch: [162/484] Iter:[220/495], Time: 0.38, lr: [0.006921011806952585], Loss: 2.056035, Acc:0.794894, Semantic loss: 0.778062, BCE loss: 0.536633, SB loss: 0.741339
2023-10-30 08:15:19,635 Epoch: [162/484] Iter:[230/495], Time: 0.37, lr: [0.0069206204687485545], Loss: 2.049723, Acc:0.794447, Semantic loss: 0.773487, BCE loss: 0.535891, SB loss: 0.740346
2023-10-30 08:15:23,408 Epoch: [162/484] Iter:[240/495], Time: 0.38, lr: [0.006920229128085743], Loss: 2.052751, Acc:0.793903, Semantic loss: 0.775491, BCE loss: 0.535449, SB loss: 0.741811
2023-10-30 08:15:27,096 Epoch: [162/484] Iter:[250/495], Time: 0.37, lr: [0.006919837784963982], Loss: 2.056079, Acc:0.792732, Semantic loss: 0.776404, BCE loss: 0.536430, SB loss: 0.743245
2023-10-30 08:15:30,795 Epoch: [162/484] Iter:[260/495], Time: 0.37, lr: [0.006919446439383101], Loss: 2.056551, Acc:0.791804, Semantic loss: 0.775228, BCE loss: 0.536512, SB loss: 0.744811
2023-10-30 08:15:34,411 Epoch: [162/484] Iter:[270/495], Time: 0.37, lr: [0.006919055091342931], Loss: 2.058580, Acc:0.791051, Semantic loss: 0.775722, BCE loss: 0.537540, SB loss: 0.745318
2023-10-30 08:15:38,012 Epoch: [162/484] Iter:[280/495], Time: 0.37, lr: [0.006918663740843301], Loss: 2.056472, Acc:0.788472, Semantic loss: 0.775722, BCE loss: 0.535528, SB loss: 0.745222
2023-10-30 08:15:41,666 Epoch: [162/484] Iter:[290/495], Time: 0.37, lr: [0.0069182723878840405], Loss: 2.061702, Acc:0.788428, Semantic loss: 0.779683, BCE loss: 0.534974, SB loss: 0.747046
2023-10-30 08:15:45,359 Epoch: [162/484] Iter:[300/495], Time: 0.37, lr: [0.00691788103246498], Loss: 2.066636, Acc:0.788000, Semantic loss: 0.780531, BCE loss: 0.537051, SB loss: 0.749053
2023-10-30 08:15:49,003 Epoch: [162/484] Iter:[310/495], Time: 0.37, lr: [0.0069174896745859485], Loss: 2.066178, Acc:0.786550, Semantic loss: 0.781120, BCE loss: 0.534428, SB loss: 0.750631
2023-10-30 08:15:52,685 Epoch: [162/484] Iter:[320/495], Time: 0.37, lr: [0.006917098314246777], Loss: 2.065516, Acc:0.786888, Semantic loss: 0.780538, BCE loss: 0.534948, SB loss: 0.750031
2023-10-30 08:15:56,333 Epoch: [162/484] Iter:[330/495], Time: 0.37, lr: [0.006916706951447295], Loss: 2.063001, Acc:0.787487, Semantic loss: 0.778329, BCE loss: 0.535199, SB loss: 0.749473
2023-10-30 08:15:59,890 Epoch: [162/484] Iter:[340/495], Time: 0.37, lr: [0.006916315586187333], Loss: 2.068693, Acc:0.788607, Semantic loss: 0.780953, BCE loss: 0.537136, SB loss: 0.750604
2023-10-30 08:16:03,543 Epoch: [162/484] Iter:[350/495], Time: 0.37, lr: [0.006915924218466721], Loss: 2.069732, Acc:0.787905, Semantic loss: 0.781312, BCE loss: 0.536796, SB loss: 0.751624
2023-10-30 08:16:07,269 Epoch: [162/484] Iter:[360/495], Time: 0.37, lr: [0.006915532848285288], Loss: 2.069071, Acc:0.789832, Semantic loss: 0.779572, BCE loss: 0.537784, SB loss: 0.751714
2023-10-30 08:16:10,923 Epoch: [162/484] Iter:[370/495], Time: 0.37, lr: [0.006915141475642863], Loss: 2.069656, Acc:0.789843, Semantic loss: 0.780569, BCE loss: 0.538163, SB loss: 0.750925
2023-10-30 08:16:14,499 Epoch: [162/484] Iter:[380/495], Time: 0.37, lr: [0.006914750100539277], Loss: 2.067560, Acc:0.790594, Semantic loss: 0.779766, BCE loss: 0.537535, SB loss: 0.750259
2023-10-30 08:16:18,247 Epoch: [162/484] Iter:[390/495], Time: 0.37, lr: [0.006914358722974359], Loss: 2.066934, Acc:0.791056, Semantic loss: 0.778587, BCE loss: 0.538646, SB loss: 0.749700
2023-10-30 08:16:21,881 Epoch: [162/484] Iter:[400/495], Time: 0.37, lr: [0.00691396734294794], Loss: 2.066942, Acc:0.791815, Semantic loss: 0.778276, BCE loss: 0.538489, SB loss: 0.750176
2023-10-30 08:16:25,492 Epoch: [162/484] Iter:[410/495], Time: 0.37, lr: [0.006913575960459848], Loss: 2.068061, Acc:0.792184, Semantic loss: 0.778453, BCE loss: 0.540111, SB loss: 0.749497
2023-10-30 08:16:29,199 Epoch: [162/484] Iter:[420/495], Time: 0.37, lr: [0.006913184575509914], Loss: 2.066721, Acc:0.792777, Semantic loss: 0.778491, BCE loss: 0.539184, SB loss: 0.749047
2023-10-30 08:16:32,886 Epoch: [162/484] Iter:[430/495], Time: 0.37, lr: [0.006912793188097968], Loss: 2.070972, Acc:0.793359, Semantic loss: 0.780265, BCE loss: 0.542362, SB loss: 0.748345
2023-10-30 08:16:36,546 Epoch: [162/484] Iter:[440/495], Time: 0.37, lr: [0.006912401798223837], Loss: 2.070548, Acc:0.792719, Semantic loss: 0.779353, BCE loss: 0.543573, SB loss: 0.747622
2023-10-30 08:16:40,245 Epoch: [162/484] Iter:[450/495], Time: 0.37, lr: [0.006912010405887355], Loss: 2.069044, Acc:0.792930, Semantic loss: 0.779472, BCE loss: 0.541400, SB loss: 0.748172
2023-10-30 08:16:43,945 Epoch: [162/484] Iter:[460/495], Time: 0.37, lr: [0.006911619011088347], Loss: 2.069150, Acc:0.792995, Semantic loss: 0.779416, BCE loss: 0.540904, SB loss: 0.748831
2023-10-30 08:16:47,596 Epoch: [162/484] Iter:[470/495], Time: 0.37, lr: [0.006911227613826644], Loss: 2.075041, Acc:0.793582, Semantic loss: 0.780724, BCE loss: 0.544445, SB loss: 0.749871
2023-10-30 08:16:51,138 Epoch: [162/484] Iter:[480/495], Time: 0.37, lr: [0.006910836214102077], Loss: 2.074180, Acc:0.792905, Semantic loss: 0.780449, BCE loss: 0.543855, SB loss: 0.749876
2023-10-30 08:16:54,644 Epoch: [162/484] Iter:[490/495], Time: 0.37, lr: [0.006910444811914474], Loss: 2.072009, Acc:0.793170, Semantic loss: 0.779278, BCE loss: 0.543213, SB loss: 0.749518
2023-10-30 08:16:56,038 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:16:56,276 Loss: 2.152, MeanIU:  0.6311, Best_mIoU:  0.6984
2023-10-30 08:16:56,276 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539]
2023-10-30 08:16:58,200 Epoch: [163/484] Iter:[0/495], Time: 1.89, lr: [0.006910249109896981], Loss: 2.099046, Acc:0.759056, Semantic loss: 0.770934, BCE loss: 0.592016, SB loss: 0.736096
2023-10-30 08:17:02,273 Epoch: [163/484] Iter:[10/495], Time: 0.54, lr: [0.006909857704014506], Loss: 2.089662, Acc:0.792508, Semantic loss: 0.768122, BCE loss: 0.592591, SB loss: 0.728948
2023-10-30 08:17:06,011 Epoch: [163/484] Iter:[20/495], Time: 0.46, lr: [0.006909466295668569], Loss: 2.095088, Acc:0.792881, Semantic loss: 0.781174, BCE loss: 0.555840, SB loss: 0.758073
2023-10-30 08:17:09,674 Epoch: [163/484] Iter:[30/495], Time: 0.43, lr: [0.006909074884859], Loss: 2.059174, Acc:0.802023, Semantic loss: 0.766071, BCE loss: 0.547630, SB loss: 0.745474
2023-10-30 08:17:13,308 Epoch: [163/484] Iter:[40/495], Time: 0.41, lr: [0.006908683471585629], Loss: 2.061566, Acc:0.802004, Semantic loss: 0.771472, BCE loss: 0.546710, SB loss: 0.743383
2023-10-30 08:17:17,069 Epoch: [163/484] Iter:[50/495], Time: 0.41, lr: [0.006908292055848282], Loss: 2.058879, Acc:0.801421, Semantic loss: 0.772387, BCE loss: 0.540280, SB loss: 0.746213
2023-10-30 08:17:20,803 Epoch: [163/484] Iter:[60/495], Time: 0.40, lr: [0.006907900637646792], Loss: 2.060359, Acc:0.801958, Semantic loss: 0.768791, BCE loss: 0.546360, SB loss: 0.745208
2023-10-30 08:17:24,379 Epoch: [163/484] Iter:[70/495], Time: 0.40, lr: [0.006907509216980987], Loss: 2.067484, Acc:0.801943, Semantic loss: 0.776969, BCE loss: 0.545947, SB loss: 0.744568
2023-10-30 08:17:27,998 Epoch: [163/484] Iter:[80/495], Time: 0.39, lr: [0.006907117793850698], Loss: 2.034431, Acc:0.797164, Semantic loss: 0.762254, BCE loss: 0.534164, SB loss: 0.738013
2023-10-30 08:17:31,639 Epoch: [163/484] Iter:[90/495], Time: 0.39, lr: [0.006906726368255752], Loss: 2.032460, Acc:0.796950, Semantic loss: 0.761002, BCE loss: 0.532691, SB loss: 0.738767
2023-10-30 08:17:35,332 Epoch: [163/484] Iter:[100/495], Time: 0.39, lr: [0.0069063349401959784], Loss: 2.026016, Acc:0.798396, Semantic loss: 0.759480, BCE loss: 0.530948, SB loss: 0.735588
2023-10-30 08:17:38,941 Epoch: [163/484] Iter:[110/495], Time: 0.38, lr: [0.006905943509671208], Loss: 2.028840, Acc:0.798224, Semantic loss: 0.758909, BCE loss: 0.532264, SB loss: 0.737667
2023-10-30 08:17:42,568 Epoch: [163/484] Iter:[120/495], Time: 0.38, lr: [0.00690555207668127], Loss: 2.033923, Acc:0.797045, Semantic loss: 0.762974, BCE loss: 0.532510, SB loss: 0.738439
2023-10-30 08:17:46,178 Epoch: [163/484] Iter:[130/495], Time: 0.38, lr: [0.006905160641225991], Loss: 2.031152, Acc:0.795252, Semantic loss: 0.759366, BCE loss: 0.534265, SB loss: 0.737521
2023-10-30 08:17:49,870 Epoch: [163/484] Iter:[140/495], Time: 0.38, lr: [0.006904769203305203], Loss: 2.027744, Acc:0.797250, Semantic loss: 0.756724, BCE loss: 0.533704, SB loss: 0.737316
2023-10-30 08:17:53,486 Epoch: [163/484] Iter:[150/495], Time: 0.38, lr: [0.006904377762918734], Loss: 2.028264, Acc:0.797369, Semantic loss: 0.756435, BCE loss: 0.533468, SB loss: 0.738361
2023-10-30 08:17:57,166 Epoch: [163/484] Iter:[160/495], Time: 0.38, lr: [0.006903986320066414], Loss: 2.029823, Acc:0.797465, Semantic loss: 0.758367, BCE loss: 0.532682, SB loss: 0.738773
2023-10-30 08:18:00,716 Epoch: [163/484] Iter:[170/495], Time: 0.38, lr: [0.006903594874748072], Loss: 2.024611, Acc:0.798792, Semantic loss: 0.756296, BCE loss: 0.530559, SB loss: 0.737756
2023-10-30 08:18:04,378 Epoch: [163/484] Iter:[180/495], Time: 0.38, lr: [0.006903203426963536], Loss: 2.032117, Acc:0.799692, Semantic loss: 0.760226, BCE loss: 0.531443, SB loss: 0.740447
2023-10-30 08:18:08,103 Epoch: [163/484] Iter:[190/495], Time: 0.38, lr: [0.006902811976712635], Loss: 2.038108, Acc:0.798208, Semantic loss: 0.765183, BCE loss: 0.529632, SB loss: 0.743293
2023-10-30 08:18:11,725 Epoch: [163/484] Iter:[200/495], Time: 0.38, lr: [0.0069024205239952], Loss: 2.045613, Acc:0.798397, Semantic loss: 0.766500, BCE loss: 0.534522, SB loss: 0.744590
2023-10-30 08:18:15,421 Epoch: [163/484] Iter:[210/495], Time: 0.37, lr: [0.006902029068811056], Loss: 2.042865, Acc:0.798982, Semantic loss: 0.765027, BCE loss: 0.533754, SB loss: 0.744083
2023-10-30 08:18:19,064 Epoch: [163/484] Iter:[220/495], Time: 0.37, lr: [0.006901637611160036], Loss: 2.046926, Acc:0.799798, Semantic loss: 0.766946, BCE loss: 0.535191, SB loss: 0.744788
2023-10-30 08:18:22,647 Epoch: [163/484] Iter:[230/495], Time: 0.37, lr: [0.006901246151041969], Loss: 2.056904, Acc:0.798933, Semantic loss: 0.772675, BCE loss: 0.536122, SB loss: 0.748107
2023-10-30 08:18:26,319 Epoch: [163/484] Iter:[240/495], Time: 0.37, lr: [0.006900854688456681], Loss: 2.056554, Acc:0.798908, Semantic loss: 0.771204, BCE loss: 0.537228, SB loss: 0.748123
2023-10-30 08:18:29,990 Epoch: [163/484] Iter:[250/495], Time: 0.37, lr: [0.006900463223404004], Loss: 2.053269, Acc:0.798634, Semantic loss: 0.769054, BCE loss: 0.536400, SB loss: 0.747815
2023-10-30 08:18:33,562 Epoch: [163/484] Iter:[260/495], Time: 0.37, lr: [0.006900071755883766], Loss: 2.053938, Acc:0.798469, Semantic loss: 0.768454, BCE loss: 0.537589, SB loss: 0.747896
2023-10-30 08:18:37,202 Epoch: [163/484] Iter:[270/495], Time: 0.37, lr: [0.006899680285895794], Loss: 2.058973, Acc:0.799285, Semantic loss: 0.772002, BCE loss: 0.538238, SB loss: 0.748733
2023-10-30 08:18:40,925 Epoch: [163/484] Iter:[280/495], Time: 0.37, lr: [0.00689928881343992], Loss: 2.060355, Acc:0.800017, Semantic loss: 0.770102, BCE loss: 0.541435, SB loss: 0.748818
2023-10-30 08:18:44,556 Epoch: [163/484] Iter:[290/495], Time: 0.37, lr: [0.006898897338515969], Loss: 2.058214, Acc:0.800310, Semantic loss: 0.769018, BCE loss: 0.540900, SB loss: 0.748296
2023-10-30 08:18:48,252 Epoch: [163/484] Iter:[300/495], Time: 0.37, lr: [0.006898505861123773], Loss: 2.061907, Acc:0.800960, Semantic loss: 0.771011, BCE loss: 0.541691, SB loss: 0.749204
2023-10-30 08:18:51,909 Epoch: [163/484] Iter:[310/495], Time: 0.37, lr: [0.006898114381263159], Loss: 2.059455, Acc:0.800168, Semantic loss: 0.770238, BCE loss: 0.540665, SB loss: 0.748552
2023-10-30 08:18:55,440 Epoch: [163/484] Iter:[320/495], Time: 0.37, lr: [0.006897722898933958], Loss: 2.058415, Acc:0.800506, Semantic loss: 0.769517, BCE loss: 0.541252, SB loss: 0.747647
2023-10-30 08:18:59,164 Epoch: [163/484] Iter:[330/495], Time: 0.37, lr: [0.006897331414135997], Loss: 2.056924, Acc:0.799606, Semantic loss: 0.769441, BCE loss: 0.540043, SB loss: 0.747440
2023-10-30 08:19:02,842 Epoch: [163/484] Iter:[340/495], Time: 0.37, lr: [0.006896939926869104], Loss: 2.062588, Acc:0.800729, Semantic loss: 0.772698, BCE loss: 0.541132, SB loss: 0.748758
2023-10-30 08:19:06,455 Epoch: [163/484] Iter:[350/495], Time: 0.37, lr: [0.006896548437133111], Loss: 2.068252, Acc:0.800287, Semantic loss: 0.776763, BCE loss: 0.541665, SB loss: 0.749824
2023-10-30 08:19:10,091 Epoch: [163/484] Iter:[360/495], Time: 0.37, lr: [0.006896156944927843], Loss: 2.065661, Acc:0.800536, Semantic loss: 0.774913, BCE loss: 0.541884, SB loss: 0.748864
2023-10-30 08:19:13,800 Epoch: [163/484] Iter:[370/495], Time: 0.37, lr: [0.00689576545025313], Loss: 2.067024, Acc:0.799832, Semantic loss: 0.777148, BCE loss: 0.540865, SB loss: 0.749011
2023-10-30 08:19:17,482 Epoch: [163/484] Iter:[380/495], Time: 0.37, lr: [0.0068953739531088], Loss: 2.066329, Acc:0.800094, Semantic loss: 0.776139, BCE loss: 0.541221, SB loss: 0.748969
2023-10-30 08:19:21,088 Epoch: [163/484] Iter:[390/495], Time: 0.37, lr: [0.006894982453494684], Loss: 2.064153, Acc:0.800892, Semantic loss: 0.775290, BCE loss: 0.540375, SB loss: 0.748488
2023-10-30 08:19:24,635 Epoch: [163/484] Iter:[400/495], Time: 0.37, lr: [0.006894590951410607], Loss: 2.063920, Acc:0.800605, Semantic loss: 0.775365, BCE loss: 0.540013, SB loss: 0.748542
2023-10-30 08:19:28,297 Epoch: [163/484] Iter:[410/495], Time: 0.37, lr: [0.006894199446856402], Loss: 2.061670, Acc:0.800670, Semantic loss: 0.773703, BCE loss: 0.540104, SB loss: 0.747862
2023-10-30 08:19:31,990 Epoch: [163/484] Iter:[420/495], Time: 0.37, lr: [0.006893807939831895], Loss: 2.065240, Acc:0.800687, Semantic loss: 0.776099, BCE loss: 0.539612, SB loss: 0.749529
2023-10-30 08:19:35,721 Epoch: [163/484] Iter:[430/495], Time: 0.37, lr: [0.006893416430336914], Loss: 2.067833, Acc:0.801220, Semantic loss: 0.776576, BCE loss: 0.541350, SB loss: 0.749908
2023-10-30 08:19:39,380 Epoch: [163/484] Iter:[440/495], Time: 0.37, lr: [0.006893024918371286], Loss: 2.067926, Acc:0.801857, Semantic loss: 0.777046, BCE loss: 0.541425, SB loss: 0.749456
2023-10-30 08:19:43,076 Epoch: [163/484] Iter:[450/495], Time: 0.37, lr: [0.006892633403934845], Loss: 2.068846, Acc:0.801540, Semantic loss: 0.777398, BCE loss: 0.542034, SB loss: 0.749413
2023-10-30 08:19:46,685 Epoch: [163/484] Iter:[460/495], Time: 0.37, lr: [0.006892241887027414], Loss: 2.068095, Acc:0.801271, Semantic loss: 0.777450, BCE loss: 0.541371, SB loss: 0.749274
2023-10-30 08:19:50,336 Epoch: [163/484] Iter:[470/495], Time: 0.37, lr: [0.006891850367648824], Loss: 2.064620, Acc:0.802355, Semantic loss: 0.774759, BCE loss: 0.541534, SB loss: 0.748327
2023-10-30 08:19:53,980 Epoch: [163/484] Iter:[480/495], Time: 0.37, lr: [0.006891458845798904], Loss: 2.065678, Acc:0.802906, Semantic loss: 0.775405, BCE loss: 0.542389, SB loss: 0.747884
2023-10-30 08:19:57,513 Epoch: [163/484] Iter:[490/495], Time: 0.37, lr: [0.006891067321477481], Loss: 2.067607, Acc:0.802998, Semantic loss: 0.776239, BCE loss: 0.543340, SB loss: 0.748028
2023-10-30 08:19:58,914 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:19:59,149 Loss: 2.152, MeanIU:  0.6311, Best_mIoU:  0.6984
2023-10-30 08:19:59,149 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539]
2023-10-30 08:20:01,384 Epoch: [164/484] Iter:[0/495], Time: 2.20, lr: [0.006890871558389902], Loss: 2.082962, Acc:0.844175, Semantic loss: 0.655194, BCE loss: 0.570953, SB loss: 0.856815
2023-10-30 08:20:05,255 Epoch: [164/484] Iter:[10/495], Time: 0.55, lr: [0.006890480030360904], Loss: 1.947626, Acc:0.777571, Semantic loss: 0.715198, BCE loss: 0.501140, SB loss: 0.731287
2023-10-30 08:20:09,000 Epoch: [164/484] Iter:[20/495], Time: 0.47, lr: [0.006890088499859974], Loss: 1.975596, Acc:0.780568, Semantic loss: 0.701241, BCE loss: 0.539995, SB loss: 0.734360
2023-10-30 08:20:12,570 Epoch: [164/484] Iter:[30/495], Time: 0.43, lr: [0.006889696966886938], Loss: 1.983734, Acc:0.784708, Semantic loss: 0.716379, BCE loss: 0.537846, SB loss: 0.729509
2023-10-30 08:20:16,252 Epoch: [164/484] Iter:[40/495], Time: 0.42, lr: [0.006889305431441629], Loss: 1.963637, Acc:0.792850, Semantic loss: 0.717985, BCE loss: 0.517582, SB loss: 0.728070
2023-10-30 08:20:19,925 Epoch: [164/484] Iter:[50/495], Time: 0.41, lr: [0.006888913893523873], Loss: 1.969499, Acc:0.791212, Semantic loss: 0.720274, BCE loss: 0.517231, SB loss: 0.731994
2023-10-30 08:20:23,547 Epoch: [164/484] Iter:[60/495], Time: 0.40, lr: [0.006888522353133498], Loss: 1.971953, Acc:0.794378, Semantic loss: 0.724129, BCE loss: 0.516779, SB loss: 0.731046
2023-10-30 08:20:27,153 Epoch: [164/484] Iter:[70/495], Time: 0.39, lr: [0.006888130810270334], Loss: 1.992060, Acc:0.793255, Semantic loss: 0.732584, BCE loss: 0.526496, SB loss: 0.732980
2023-10-30 08:20:30,840 Epoch: [164/484] Iter:[80/495], Time: 0.39, lr: [0.006887739264934206], Loss: 1.996648, Acc:0.792106, Semantic loss: 0.736199, BCE loss: 0.526374, SB loss: 0.734075
2023-10-30 08:20:34,475 Epoch: [164/484] Iter:[90/495], Time: 0.39, lr: [0.006887347717124946], Loss: 2.009136, Acc:0.794679, Semantic loss: 0.742319, BCE loss: 0.529985, SB loss: 0.736831
2023-10-30 08:20:38,122 Epoch: [164/484] Iter:[100/495], Time: 0.39, lr: [0.006886956166842379], Loss: 1.998954, Acc:0.794748, Semantic loss: 0.739042, BCE loss: 0.524981, SB loss: 0.734931
2023-10-30 08:20:41,805 Epoch: [164/484] Iter:[110/495], Time: 0.38, lr: [0.006886564614086333], Loss: 2.005404, Acc:0.797325, Semantic loss: 0.741784, BCE loss: 0.527688, SB loss: 0.735932
2023-10-30 08:20:45,397 Epoch: [164/484] Iter:[120/495], Time: 0.38, lr: [0.00688617305885664], Loss: 2.012083, Acc:0.796096, Semantic loss: 0.747956, BCE loss: 0.525214, SB loss: 0.738914
2023-10-30 08:20:49,019 Epoch: [164/484] Iter:[130/495], Time: 0.38, lr: [0.006885781501153122], Loss: 2.013476, Acc:0.794759, Semantic loss: 0.749330, BCE loss: 0.523779, SB loss: 0.740367
2023-10-30 08:20:52,674 Epoch: [164/484] Iter:[140/495], Time: 0.38, lr: [0.006885389940975614], Loss: 2.025673, Acc:0.794856, Semantic loss: 0.758816, BCE loss: 0.521763, SB loss: 0.745094
2023-10-30 08:20:56,277 Epoch: [164/484] Iter:[150/495], Time: 0.38, lr: [0.006884998378323939], Loss: 2.027652, Acc:0.795751, Semantic loss: 0.757401, BCE loss: 0.523401, SB loss: 0.746850
2023-10-30 08:20:59,999 Epoch: [164/484] Iter:[160/495], Time: 0.38, lr: [0.006884606813197928], Loss: 2.045942, Acc:0.794071, Semantic loss: 0.771862, BCE loss: 0.525375, SB loss: 0.748704
2023-10-30 08:21:03,671 Epoch: [164/484] Iter:[170/495], Time: 0.38, lr: [0.006884215245597406], Loss: 2.050496, Acc:0.790729, Semantic loss: 0.774305, BCE loss: 0.525440, SB loss: 0.750751
2023-10-30 08:21:07,351 Epoch: [164/484] Iter:[180/495], Time: 0.38, lr: [0.006883823675522204], Loss: 2.049762, Acc:0.793457, Semantic loss: 0.771889, BCE loss: 0.526935, SB loss: 0.750938
2023-10-30 08:21:11,015 Epoch: [164/484] Iter:[190/495], Time: 0.38, lr: [0.0068834321029721465], Loss: 2.046604, Acc:0.792074, Semantic loss: 0.770811, BCE loss: 0.525480, SB loss: 0.750313
2023-10-30 08:21:14,657 Epoch: [164/484] Iter:[200/495], Time: 0.38, lr: [0.006883040527947065], Loss: 2.051412, Acc:0.792100, Semantic loss: 0.772880, BCE loss: 0.526687, SB loss: 0.751846
2023-10-30 08:21:18,321 Epoch: [164/484] Iter:[210/495], Time: 0.38, lr: [0.006882648950446786], Loss: 2.047796, Acc:0.792921, Semantic loss: 0.768864, BCE loss: 0.528188, SB loss: 0.750744
2023-10-30 08:21:22,100 Epoch: [164/484] Iter:[220/495], Time: 0.38, lr: [0.0068822573704711365], Loss: 2.039850, Acc:0.795030, Semantic loss: 0.764268, BCE loss: 0.526880, SB loss: 0.748701
2023-10-30 08:21:25,751 Epoch: [164/484] Iter:[230/495], Time: 0.37, lr: [0.006881865788019946], Loss: 2.051973, Acc:0.797370, Semantic loss: 0.772137, BCE loss: 0.529064, SB loss: 0.750772
2023-10-30 08:21:29,563 Epoch: [164/484] Iter:[240/495], Time: 0.38, lr: [0.006881474203093041], Loss: 2.048499, Acc:0.797286, Semantic loss: 0.770011, BCE loss: 0.528973, SB loss: 0.749515
2023-10-30 08:21:33,321 Epoch: [164/484] Iter:[250/495], Time: 0.38, lr: [0.006881082615690251], Loss: 2.054200, Acc:0.797040, Semantic loss: 0.773002, BCE loss: 0.530183, SB loss: 0.751014
2023-10-30 08:21:37,185 Epoch: [164/484] Iter:[260/495], Time: 0.38, lr: [0.0068806910258113994], Loss: 2.054623, Acc:0.797440, Semantic loss: 0.773818, BCE loss: 0.530748, SB loss: 0.750058
2023-10-30 08:21:40,838 Epoch: [164/484] Iter:[270/495], Time: 0.38, lr: [0.00688029943345632], Loss: 2.054672, Acc:0.797110, Semantic loss: 0.773543, BCE loss: 0.530721, SB loss: 0.750408
2023-10-30 08:21:44,553 Epoch: [164/484] Iter:[280/495], Time: 0.37, lr: [0.006879907838624836], Loss: 2.055730, Acc:0.797670, Semantic loss: 0.773731, BCE loss: 0.531776, SB loss: 0.750224
2023-10-30 08:21:48,220 Epoch: [164/484] Iter:[290/495], Time: 0.37, lr: [0.006879516241316778], Loss: 2.054542, Acc:0.796532, Semantic loss: 0.772830, BCE loss: 0.531905, SB loss: 0.749807
2023-10-30 08:21:51,852 Epoch: [164/484] Iter:[300/495], Time: 0.37, lr: [0.006879124641531972], Loss: 2.051455, Acc:0.796273, Semantic loss: 0.771798, BCE loss: 0.531241, SB loss: 0.748416
2023-10-30 08:21:55,565 Epoch: [164/484] Iter:[310/495], Time: 0.37, lr: [0.0068787330392702465], Loss: 2.054516, Acc:0.796162, Semantic loss: 0.774419, BCE loss: 0.530898, SB loss: 0.749198
2023-10-30 08:21:59,168 Epoch: [164/484] Iter:[320/495], Time: 0.37, lr: [0.006878341434531429], Loss: 2.058739, Acc:0.795662, Semantic loss: 0.776259, BCE loss: 0.531620, SB loss: 0.750860
2023-10-30 08:22:02,883 Epoch: [164/484] Iter:[330/495], Time: 0.37, lr: [0.006877949827315346], Loss: 2.059851, Acc:0.794473, Semantic loss: 0.775827, BCE loss: 0.532974, SB loss: 0.751051
2023-10-30 08:22:06,551 Epoch: [164/484] Iter:[340/495], Time: 0.37, lr: [0.006877558217621827], Loss: 2.058347, Acc:0.794137, Semantic loss: 0.775746, BCE loss: 0.531583, SB loss: 0.751019
2023-10-30 08:22:10,182 Epoch: [164/484] Iter:[350/495], Time: 0.37, lr: [0.006877166605450698], Loss: 2.056070, Acc:0.793865, Semantic loss: 0.774487, BCE loss: 0.531115, SB loss: 0.750469
2023-10-30 08:22:13,816 Epoch: [164/484] Iter:[360/495], Time: 0.37, lr: [0.006876774990801787], Loss: 2.057260, Acc:0.793330, Semantic loss: 0.776941, BCE loss: 0.529669, SB loss: 0.750650
2023-10-30 08:22:17,463 Epoch: [164/484] Iter:[370/495], Time: 0.37, lr: [0.006876383373674922], Loss: 2.054236, Acc:0.792453, Semantic loss: 0.776028, BCE loss: 0.528802, SB loss: 0.749406
2023-10-30 08:22:21,049 Epoch: [164/484] Iter:[380/495], Time: 0.37, lr: [0.006875991754069931], Loss: 2.056342, Acc:0.791733, Semantic loss: 0.777421, BCE loss: 0.528912, SB loss: 0.750010
2023-10-30 08:22:24,757 Epoch: [164/484] Iter:[390/495], Time: 0.37, lr: [0.006875600131986641], Loss: 2.054771, Acc:0.792266, Semantic loss: 0.775855, BCE loss: 0.529218, SB loss: 0.749698
2023-10-30 08:22:28,577 Epoch: [164/484] Iter:[400/495], Time: 0.37, lr: [0.006875208507424878], Loss: 2.055198, Acc:0.792342, Semantic loss: 0.776944, BCE loss: 0.528016, SB loss: 0.750238
2023-10-30 08:22:32,276 Epoch: [164/484] Iter:[410/495], Time: 0.37, lr: [0.0068748168803844725], Loss: 2.060424, Acc:0.792677, Semantic loss: 0.780261, BCE loss: 0.528950, SB loss: 0.751213
2023-10-30 08:22:35,900 Epoch: [164/484] Iter:[420/495], Time: 0.37, lr: [0.006874425250865247], Loss: 2.062461, Acc:0.793076, Semantic loss: 0.780460, BCE loss: 0.530020, SB loss: 0.751981
2023-10-30 08:22:39,593 Epoch: [164/484] Iter:[430/495], Time: 0.37, lr: [0.006874033618867035], Loss: 2.062440, Acc:0.793861, Semantic loss: 0.779697, BCE loss: 0.531181, SB loss: 0.751562
2023-10-30 08:22:43,148 Epoch: [164/484] Iter:[440/495], Time: 0.37, lr: [0.006873641984389659], Loss: 2.063883, Acc:0.793325, Semantic loss: 0.779446, BCE loss: 0.532461, SB loss: 0.751975
2023-10-30 08:22:46,842 Epoch: [164/484] Iter:[450/495], Time: 0.37, lr: [0.006873250347432949], Loss: 2.062986, Acc:0.793633, Semantic loss: 0.778008, BCE loss: 0.532923, SB loss: 0.752055
2023-10-30 08:22:50,542 Epoch: [164/484] Iter:[460/495], Time: 0.37, lr: [0.006872858707996732], Loss: 2.063159, Acc:0.793344, Semantic loss: 0.777370, BCE loss: 0.533784, SB loss: 0.752004
2023-10-30 08:22:54,203 Epoch: [164/484] Iter:[470/495], Time: 0.37, lr: [0.0068724670660808345], Loss: 2.064389, Acc:0.793205, Semantic loss: 0.778245, BCE loss: 0.533948, SB loss: 0.752196
2023-10-30 08:22:57,832 Epoch: [164/484] Iter:[480/495], Time: 0.37, lr: [0.0068720754216850845], Loss: 2.067116, Acc:0.792649, Semantic loss: 0.779978, BCE loss: 0.534136, SB loss: 0.753003
2023-10-30 08:23:01,370 Epoch: [164/484] Iter:[490/495], Time: 0.37, lr: [0.006871683774809309], Loss: 2.064801, Acc:0.792788, Semantic loss: 0.778591, BCE loss: 0.533911, SB loss: 0.752299
2023-10-30 08:23:02,784 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:23:03,018 Loss: 2.152, MeanIU:  0.6311, Best_mIoU:  0.6984
2023-10-30 08:23:03,018 [0.96339872 0.77308779 0.89474481 0.21867522 0.47215374 0.54060222
 0.64542868 0.66970224 0.89850943 0.58601184 0.92662812 0.7602483
 0.5295215  0.90443866 0.23472616 0.60762793 0.17576239 0.48034676
 0.70869539]
2023-10-30 08:23:05,066 Epoch: [165/484] Iter:[0/495], Time: 2.01, lr: [0.0068714879504413575], Loss: 1.928765, Acc:0.799059, Semantic loss: 0.693392, BCE loss: 0.525727, SB loss: 0.709646
2023-10-30 08:23:09,080 Epoch: [165/484] Iter:[10/495], Time: 0.55, lr: [0.006871096299845218], Loss: 2.218623, Acc:0.810388, Semantic loss: 0.801761, BCE loss: 0.656332, SB loss: 0.760530
2023-10-30 08:23:12,784 Epoch: [165/484] Iter:[20/495], Time: 0.46, lr: [0.006870704646768623], Loss: 2.084671, Acc:0.803198, Semantic loss: 0.752765, BCE loss: 0.584858, SB loss: 0.747048
2023-10-30 08:23:16,326 Epoch: [165/484] Iter:[30/495], Time: 0.43, lr: [0.006870312991211396], Loss: 2.075489, Acc:0.806107, Semantic loss: 0.755181, BCE loss: 0.572800, SB loss: 0.747508
2023-10-30 08:23:19,980 Epoch: [165/484] Iter:[40/495], Time: 0.41, lr: [0.0068699213331733676], Loss: 2.093570, Acc:0.794852, Semantic loss: 0.779070, BCE loss: 0.562338, SB loss: 0.752162
2023-10-30 08:23:23,643 Epoch: [165/484] Iter:[50/495], Time: 0.40, lr: [0.006869529672654362], Loss: 2.069946, Acc:0.791912, Semantic loss: 0.771036, BCE loss: 0.553936, SB loss: 0.744975
2023-10-30 08:23:27,322 Epoch: [165/484] Iter:[60/495], Time: 0.40, lr: [0.006869138009654209], Loss: 2.090325, Acc:0.795615, Semantic loss: 0.779444, BCE loss: 0.555538, SB loss: 0.755343
2023-10-30 08:23:31,022 Epoch: [165/484] Iter:[70/495], Time: 0.39, lr: [0.006868746344172733], Loss: 2.088207, Acc:0.798001, Semantic loss: 0.776564, BCE loss: 0.558429, SB loss: 0.753215
2023-10-30 08:23:34,764 Epoch: [165/484] Iter:[80/495], Time: 0.39, lr: [0.006868354676209762], Loss: 2.105851, Acc:0.799760, Semantic loss: 0.787408, BCE loss: 0.560706, SB loss: 0.757737
2023-10-30 08:23:38,570 Epoch: [165/484] Iter:[90/495], Time: 0.39, lr: [0.006867963005765124], Loss: 2.104264, Acc:0.799445, Semantic loss: 0.785330, BCE loss: 0.557236, SB loss: 0.761699
2023-10-30 08:23:42,271 Epoch: [165/484] Iter:[100/495], Time: 0.39, lr: [0.006867571332838643], Loss: 2.105576, Acc:0.801029, Semantic loss: 0.786748, BCE loss: 0.555162, SB loss: 0.763666
2023-10-30 08:23:46,001 Epoch: [165/484] Iter:[110/495], Time: 0.39, lr: [0.006867179657430151], Loss: 2.092014, Acc:0.804291, Semantic loss: 0.783196, BCE loss: 0.547189, SB loss: 0.761628
2023-10-30 08:23:49,679 Epoch: [165/484] Iter:[120/495], Time: 0.39, lr: [0.006866787979539473], Loss: 2.086333, Acc:0.803644, Semantic loss: 0.783079, BCE loss: 0.542422, SB loss: 0.760833
2023-10-30 08:23:53,356 Epoch: [165/484] Iter:[130/495], Time: 0.38, lr: [0.006866396299166434], Loss: 2.100314, Acc:0.804790, Semantic loss: 0.793239, BCE loss: 0.545800, SB loss: 0.761274
2023-10-30 08:23:57,030 Epoch: [165/484] Iter:[140/495], Time: 0.38, lr: [0.006866004616310863], Loss: 2.084041, Acc:0.802848, Semantic loss: 0.784906, BCE loss: 0.542113, SB loss: 0.757022
2023-10-30 08:24:00,716 Epoch: [165/484] Iter:[150/495], Time: 0.38, lr: [0.006865612930972585], Loss: 2.085073, Acc:0.803404, Semantic loss: 0.784030, BCE loss: 0.543005, SB loss: 0.758037
2023-10-30 08:24:04,409 Epoch: [165/484] Iter:[160/495], Time: 0.38, lr: [0.006865221243151427], Loss: 2.080699, Acc:0.802765, Semantic loss: 0.783512, BCE loss: 0.540907, SB loss: 0.756280
2023-10-30 08:24:08,143 Epoch: [165/484] Iter:[170/495], Time: 0.38, lr: [0.006864829552847218], Loss: 2.080111, Acc:0.803714, Semantic loss: 0.784220, BCE loss: 0.540241, SB loss: 0.755650
2023-10-30 08:24:11,807 Epoch: [165/484] Iter:[180/495], Time: 0.38, lr: [0.006864437860059783], Loss: 2.075837, Acc:0.804250, Semantic loss: 0.780444, BCE loss: 0.542075, SB loss: 0.753318
2023-10-30 08:24:15,447 Epoch: [165/484] Iter:[190/495], Time: 0.38, lr: [0.006864046164788951], Loss: 2.083872, Acc:0.803888, Semantic loss: 0.787308, BCE loss: 0.542885, SB loss: 0.753679
2023-10-30 08:24:19,095 Epoch: [165/484] Iter:[200/495], Time: 0.38, lr: [0.006863654467034547], Loss: 2.079989, Acc:0.802614, Semantic loss: 0.783344, BCE loss: 0.542608, SB loss: 0.754037
2023-10-30 08:24:22,819 Epoch: [165/484] Iter:[210/495], Time: 0.38, lr: [0.006863262766796397], Loss: 2.084130, Acc:0.804395, Semantic loss: 0.784228, BCE loss: 0.544237, SB loss: 0.755666
2023-10-30 08:24:26,498 Epoch: [165/484] Iter:[220/495], Time: 0.38, lr: [0.00686287106407433], Loss: 2.083557, Acc:0.802987, Semantic loss: 0.784402, BCE loss: 0.542224, SB loss: 0.756930
2023-10-30 08:24:30,257 Epoch: [165/484] Iter:[230/495], Time: 0.38, lr: [0.006862479358868171], Loss: 2.080068, Acc:0.802345, Semantic loss: 0.782076, BCE loss: 0.541747, SB loss: 0.756245
2023-10-30 08:24:33,898 Epoch: [165/484] Iter:[240/495], Time: 0.38, lr: [0.0068620876511777465], Loss: 2.091032, Acc:0.801147, Semantic loss: 0.786604, BCE loss: 0.545831, SB loss: 0.758596
2023-10-30 08:24:37,591 Epoch: [165/484] Iter:[250/495], Time: 0.38, lr: [0.006861695941002884], Loss: 2.094670, Acc:0.801035, Semantic loss: 0.789021, BCE loss: 0.544967, SB loss: 0.760682
2023-10-30 08:24:41,314 Epoch: [165/484] Iter:[260/495], Time: 0.38, lr: [0.0068613042283434105], Loss: 2.096809, Acc:0.801506, Semantic loss: 0.788813, BCE loss: 0.547510, SB loss: 0.760486
2023-10-30 08:24:45,111 Epoch: [165/484] Iter:[270/495], Time: 0.38, lr: [0.006860912513199153], Loss: 2.109275, Acc:0.801654, Semantic loss: 0.798522, BCE loss: 0.549123, SB loss: 0.761630
2023-10-30 08:24:48,823 Epoch: [165/484] Iter:[280/495], Time: 0.38, lr: [0.006860520795569936], Loss: 2.103830, Acc:0.801762, Semantic loss: 0.795000, BCE loss: 0.548312, SB loss: 0.760517
2023-10-30 08:24:52,451 Epoch: [165/484] Iter:[290/495], Time: 0.38, lr: [0.0068601290754555875], Loss: 2.105754, Acc:0.800069, Semantic loss: 0.795121, BCE loss: 0.550074, SB loss: 0.760559
2023-10-30 08:24:56,106 Epoch: [165/484] Iter:[300/495], Time: 0.38, lr: [0.006859737352855935], Loss: 2.107240, Acc:0.799767, Semantic loss: 0.794238, BCE loss: 0.552737, SB loss: 0.760264
2023-10-30 08:24:59,765 Epoch: [165/484] Iter:[310/495], Time: 0.38, lr: [0.006859345627770803], Loss: 2.108162, Acc:0.798151, Semantic loss: 0.796164, BCE loss: 0.551538, SB loss: 0.760461
2023-10-30 08:25:03,443 Epoch: [165/484] Iter:[320/495], Time: 0.38, lr: [0.006858953900200019], Loss: 2.106137, Acc:0.797861, Semantic loss: 0.795861, BCE loss: 0.550450, SB loss: 0.759826
2023-10-30 08:25:07,185 Epoch: [165/484] Iter:[330/495], Time: 0.38, lr: [0.00685856217014341], Loss: 2.104287, Acc:0.798134, Semantic loss: 0.794043, BCE loss: 0.550498, SB loss: 0.759746
2023-10-30 08:25:10,868 Epoch: [165/484] Iter:[340/495], Time: 0.37, lr: [0.006858170437600801], Loss: 2.101576, Acc:0.799240, Semantic loss: 0.792752, BCE loss: 0.548944, SB loss: 0.759881
2023-10-30 08:25:14,660 Epoch: [165/484] Iter:[350/495], Time: 0.37, lr: [0.006857778702572021], Loss: 2.099266, Acc:0.798813, Semantic loss: 0.791690, BCE loss: 0.548253, SB loss: 0.759323
2023-10-30 08:25:18,341 Epoch: [165/484] Iter:[360/495], Time: 0.37, lr: [0.006857386965056895], Loss: 2.102217, Acc:0.798320, Semantic loss: 0.793870, BCE loss: 0.549173, SB loss: 0.759174
2023-10-30 08:25:21,953 Epoch: [165/484] Iter:[370/495], Time: 0.37, lr: [0.006856995225055247], Loss: 2.100420, Acc:0.797488, Semantic loss: 0.793072, BCE loss: 0.548382, SB loss: 0.758965
2023-10-30 08:25:25,602 Epoch: [165/484] Iter:[380/495], Time: 0.37, lr: [0.006856603482566908], Loss: 2.100614, Acc:0.797282, Semantic loss: 0.793014, BCE loss: 0.548073, SB loss: 0.759526
2023-10-30 08:25:29,245 Epoch: [165/484] Iter:[390/495], Time: 0.37, lr: [0.0068562117375917], Loss: 2.098952, Acc:0.796732, Semantic loss: 0.792513, BCE loss: 0.547369, SB loss: 0.759070
2023-10-30 08:25:32,899 Epoch: [165/484] Iter:[400/495], Time: 0.37, lr: [0.0068558199901294515], Loss: 2.100282, Acc:0.796437, Semantic loss: 0.793341, BCE loss: 0.547813, SB loss: 0.759129
2023-10-30 08:25:36,591 Epoch: [165/484] Iter:[410/495], Time: 0.37, lr: [0.00685542824017999], Loss: 2.097050, Acc:0.795565, Semantic loss: 0.792085, BCE loss: 0.546250, SB loss: 0.758716
2023-10-30 08:25:40,262 Epoch: [165/484] Iter:[420/495], Time: 0.37, lr: [0.0068550364877431385], Loss: 2.094314, Acc:0.796111, Semantic loss: 0.791095, BCE loss: 0.545443, SB loss: 0.757775
2023-10-30 08:25:43,937 Epoch: [165/484] Iter:[430/495], Time: 0.37, lr: [0.006854644732818726], Loss: 2.093556, Acc:0.796365, Semantic loss: 0.790646, BCE loss: 0.544901, SB loss: 0.758008
2023-10-30 08:25:47,612 Epoch: [165/484] Iter:[440/495], Time: 0.37, lr: [0.006854252975406578], Loss: 2.096044, Acc:0.796193, Semantic loss: 0.793477, BCE loss: 0.544173, SB loss: 0.758394
2023-10-30 08:25:51,272 Epoch: [165/484] Iter:[450/495], Time: 0.37, lr: [0.006853861215506521], Loss: 2.096587, Acc:0.796436, Semantic loss: 0.793955, BCE loss: 0.544227, SB loss: 0.758405
2023-10-30 08:25:54,846 Epoch: [165/484] Iter:[460/495], Time: 0.37, lr: [0.0068534694531183805], Loss: 2.100107, Acc:0.796797, Semantic loss: 0.796499, BCE loss: 0.544328, SB loss: 0.759281
2023-10-30 08:25:58,459 Epoch: [165/484] Iter:[470/495], Time: 0.37, lr: [0.006853077688241983], Loss: 2.103363, Acc:0.798075, Semantic loss: 0.798050, BCE loss: 0.545686, SB loss: 0.759626
2023-10-30 08:26:02,152 Epoch: [165/484] Iter:[480/495], Time: 0.37, lr: [0.006852685920877153], Loss: 2.106465, Acc:0.796926, Semantic loss: 0.802036, BCE loss: 0.544068, SB loss: 0.760361
2023-10-30 08:26:05,757 Epoch: [165/484] Iter:[490/495], Time: 0.37, lr: [0.0068522941510237205], Loss: 2.112242, Acc:0.796223, Semantic loss: 0.804820, BCE loss: 0.545632, SB loss: 0.761789
2023-10-30 08:29:01,992 0 [0.91953865 0.6000801  0.80087411 0.09655067 0.24442052 0.3838972
 0.37291498 0.53506591 0.86039925 0.41772649 0.85141684 0.59028716
 0.01540527 0.76817875 0.00138655 0.02105603 0.0083696  0.02196009
 0.40350057] 0.4164751961842519
2023-10-30 08:29:01,992 1 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828] 0.6042644092953962
2023-10-30 08:29:01,996 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:29:02,233 Loss: 2.281, MeanIU:  0.6043, Best_mIoU:  0.6984
2023-10-30 08:29:02,233 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828]
2023-10-30 08:29:04,278 Epoch: [166/484] Iter:[0/495], Time: 2.02, lr: [0.006852098265163722], Loss: 2.262177, Acc:0.805892, Semantic loss: 0.875021, BCE loss: 0.599933, SB loss: 0.787223
2023-10-30 08:29:08,022 Epoch: [166/484] Iter:[10/495], Time: 0.52, lr: [0.006851706491577056], Loss: 2.199882, Acc:0.781196, Semantic loss: 0.821896, BCE loss: 0.542259, SB loss: 0.835727
2023-10-30 08:29:11,643 Epoch: [166/484] Iter:[20/495], Time: 0.45, lr: [0.006851314715501349], Loss: 2.124557, Acc:0.786627, Semantic loss: 0.790553, BCE loss: 0.541646, SB loss: 0.792359
2023-10-30 08:29:15,150 Epoch: [166/484] Iter:[30/495], Time: 0.42, lr: [0.006850922936936429], Loss: 2.151074, Acc:0.790456, Semantic loss: 0.805651, BCE loss: 0.558524, SB loss: 0.786899
2023-10-30 08:29:18,590 Epoch: [166/484] Iter:[40/495], Time: 0.40, lr: [0.006850531155882122], Loss: 2.112721, Acc:0.798219, Semantic loss: 0.790522, BCE loss: 0.544344, SB loss: 0.777855
2023-10-30 08:29:22,068 Epoch: [166/484] Iter:[50/495], Time: 0.39, lr: [0.006850139372338253], Loss: 2.104920, Acc:0.801769, Semantic loss: 0.792431, BCE loss: 0.545166, SB loss: 0.767323
2023-10-30 08:29:25,593 Epoch: [166/484] Iter:[60/495], Time: 0.38, lr: [0.006849747586304649], Loss: 2.113478, Acc:0.798072, Semantic loss: 0.803268, BCE loss: 0.540238, SB loss: 0.769973
2023-10-30 08:29:29,126 Epoch: [166/484] Iter:[70/495], Time: 0.38, lr: [0.006849355797781135], Loss: 2.120570, Acc:0.795461, Semantic loss: 0.801571, BCE loss: 0.540070, SB loss: 0.778928
2023-10-30 08:29:32,697 Epoch: [166/484] Iter:[80/495], Time: 0.38, lr: [0.006848964006767536], Loss: 2.122740, Acc:0.792710, Semantic loss: 0.808102, BCE loss: 0.537290, SB loss: 0.777347
2023-10-30 08:29:36,262 Epoch: [166/484] Iter:[90/495], Time: 0.37, lr: [0.006848572213263681], Loss: 2.109347, Acc:0.796668, Semantic loss: 0.794876, BCE loss: 0.542056, SB loss: 0.772415
2023-10-30 08:29:39,793 Epoch: [166/484] Iter:[100/495], Time: 0.37, lr: [0.006848180417269393], Loss: 2.095738, Acc:0.796324, Semantic loss: 0.790133, BCE loss: 0.535716, SB loss: 0.769889
2023-10-30 08:29:43,389 Epoch: [166/484] Iter:[110/495], Time: 0.37, lr: [0.0068477886187845], Loss: 2.098375, Acc:0.797255, Semantic loss: 0.794803, BCE loss: 0.534914, SB loss: 0.768658
2023-10-30 08:29:46,962 Epoch: [166/484] Iter:[120/495], Time: 0.37, lr: [0.006847396817808826], Loss: 2.082287, Acc:0.797186, Semantic loss: 0.785705, BCE loss: 0.531073, SB loss: 0.765509
2023-10-30 08:29:50,649 Epoch: [166/484] Iter:[130/495], Time: 0.37, lr: [0.006847005014342198], Loss: 2.092270, Acc:0.795322, Semantic loss: 0.794493, BCE loss: 0.529644, SB loss: 0.768133
2023-10-30 08:29:54,228 Epoch: [166/484] Iter:[140/495], Time: 0.37, lr: [0.006846613208384441], Loss: 2.096499, Acc:0.793813, Semantic loss: 0.796590, BCE loss: 0.532624, SB loss: 0.767285
2023-10-30 08:29:57,884 Epoch: [166/484] Iter:[150/495], Time: 0.37, lr: [0.006846221399935382], Loss: 2.096034, Acc:0.789824, Semantic loss: 0.797824, BCE loss: 0.530886, SB loss: 0.767324
2023-10-30 08:30:01,490 Epoch: [166/484] Iter:[160/495], Time: 0.37, lr: [0.006845829588994844], Loss: 2.089163, Acc:0.788655, Semantic loss: 0.792395, BCE loss: 0.531849, SB loss: 0.764919
2023-10-30 08:30:05,238 Epoch: [166/484] Iter:[170/495], Time: 0.37, lr: [0.006845437775562655], Loss: 2.090624, Acc:0.789713, Semantic loss: 0.791745, BCE loss: 0.534885, SB loss: 0.763994
2023-10-30 08:30:08,869 Epoch: [166/484] Iter:[180/495], Time: 0.37, lr: [0.006845045959638641], Loss: 2.090932, Acc:0.792985, Semantic loss: 0.791126, BCE loss: 0.538188, SB loss: 0.761618
2023-10-30 08:30:12,568 Epoch: [166/484] Iter:[190/495], Time: 0.37, lr: [0.006844654141222629], Loss: 2.087588, Acc:0.793455, Semantic loss: 0.790229, BCE loss: 0.537857, SB loss: 0.759501
2023-10-30 08:30:16,250 Epoch: [166/484] Iter:[200/495], Time: 0.37, lr: [0.006844262320314439], Loss: 2.085652, Acc:0.792884, Semantic loss: 0.791297, BCE loss: 0.536282, SB loss: 0.758074
2023-10-30 08:30:19,871 Epoch: [166/484] Iter:[210/495], Time: 0.37, lr: [0.006843870496913902], Loss: 2.083069, Acc:0.791858, Semantic loss: 0.790261, BCE loss: 0.535054, SB loss: 0.757755
2023-10-30 08:30:23,505 Epoch: [166/484] Iter:[220/495], Time: 0.37, lr: [0.0068434786710208405], Loss: 2.079964, Acc:0.791450, Semantic loss: 0.788648, BCE loss: 0.532958, SB loss: 0.758358
2023-10-30 08:30:27,144 Epoch: [166/484] Iter:[230/495], Time: 0.37, lr: [0.006843086842635083], Loss: 2.079010, Acc:0.791915, Semantic loss: 0.788209, BCE loss: 0.532870, SB loss: 0.757931
2023-10-30 08:30:30,930 Epoch: [166/484] Iter:[240/495], Time: 0.37, lr: [0.006842695011756453], Loss: 2.084218, Acc:0.792531, Semantic loss: 0.790095, BCE loss: 0.537377, SB loss: 0.756746
2023-10-30 08:30:34,552 Epoch: [166/484] Iter:[250/495], Time: 0.37, lr: [0.006842303178384776], Loss: 2.080452, Acc:0.792396, Semantic loss: 0.787778, BCE loss: 0.537904, SB loss: 0.754770
2023-10-30 08:30:38,144 Epoch: [166/484] Iter:[260/495], Time: 0.37, lr: [0.006841911342519879], Loss: 2.082866, Acc:0.792069, Semantic loss: 0.789636, BCE loss: 0.538905, SB loss: 0.754325
2023-10-30 08:30:41,742 Epoch: [166/484] Iter:[270/495], Time: 0.37, lr: [0.006841519504161585], Loss: 2.078375, Acc:0.792144, Semantic loss: 0.786874, BCE loss: 0.537930, SB loss: 0.753571
2023-10-30 08:30:45,365 Epoch: [166/484] Iter:[280/495], Time: 0.37, lr: [0.006841127663309722], Loss: 2.077860, Acc:0.792213, Semantic loss: 0.786552, BCE loss: 0.538152, SB loss: 0.753156
2023-10-30 08:30:48,987 Epoch: [166/484] Iter:[290/495], Time: 0.37, lr: [0.006840735819964114], Loss: 2.073840, Acc:0.791714, Semantic loss: 0.784249, BCE loss: 0.537008, SB loss: 0.752584
2023-10-30 08:30:52,671 Epoch: [166/484] Iter:[300/495], Time: 0.37, lr: [0.006840343974124585], Loss: 2.074290, Acc:0.791770, Semantic loss: 0.784121, BCE loss: 0.538363, SB loss: 0.751806
2023-10-30 08:30:56,439 Epoch: [166/484] Iter:[310/495], Time: 0.37, lr: [0.006839952125790964], Loss: 2.077420, Acc:0.791971, Semantic loss: 0.785935, BCE loss: 0.539012, SB loss: 0.752473
2023-10-30 08:31:00,085 Epoch: [166/484] Iter:[320/495], Time: 0.37, lr: [0.006839560274963075], Loss: 2.076026, Acc:0.792934, Semantic loss: 0.784935, BCE loss: 0.538455, SB loss: 0.752636
2023-10-30 08:31:03,684 Epoch: [166/484] Iter:[330/495], Time: 0.37, lr: [0.006839168421640741], Loss: 2.077439, Acc:0.792418, Semantic loss: 0.786210, BCE loss: 0.537288, SB loss: 0.753941
2023-10-30 08:31:07,545 Epoch: [166/484] Iter:[340/495], Time: 0.37, lr: [0.006838776565823791], Loss: 2.074614, Acc:0.791479, Semantic loss: 0.784493, BCE loss: 0.537306, SB loss: 0.752815
2023-10-30 08:31:11,205 Epoch: [166/484] Iter:[350/495], Time: 0.37, lr: [0.0068383847075120475], Loss: 2.075979, Acc:0.792989, Semantic loss: 0.783413, BCE loss: 0.540714, SB loss: 0.751852
2023-10-30 08:31:14,881 Epoch: [166/484] Iter:[360/495], Time: 0.37, lr: [0.006837992846705338], Loss: 2.073558, Acc:0.792758, Semantic loss: 0.781822, BCE loss: 0.540760, SB loss: 0.750977
2023-10-30 08:31:18,608 Epoch: [166/484] Iter:[370/495], Time: 0.37, lr: [0.0068376009834034855], Loss: 2.070150, Acc:0.792635, Semantic loss: 0.780416, BCE loss: 0.539015, SB loss: 0.750719
2023-10-30 08:31:22,311 Epoch: [166/484] Iter:[380/495], Time: 0.37, lr: [0.006837209117606316], Loss: 2.073171, Acc:0.792754, Semantic loss: 0.781852, BCE loss: 0.539771, SB loss: 0.751547
2023-10-30 08:31:26,007 Epoch: [166/484] Iter:[390/495], Time: 0.37, lr: [0.006836817249313655], Loss: 2.070457, Acc:0.793207, Semantic loss: 0.780519, BCE loss: 0.539193, SB loss: 0.750745
2023-10-30 08:31:29,627 Epoch: [166/484] Iter:[400/495], Time: 0.37, lr: [0.006836425378525326], Loss: 2.067823, Acc:0.793109, Semantic loss: 0.778905, BCE loss: 0.538882, SB loss: 0.750036
2023-10-30 08:31:33,247 Epoch: [166/484] Iter:[410/495], Time: 0.37, lr: [0.006836033505241158], Loss: 2.066229, Acc:0.793747, Semantic loss: 0.777707, BCE loss: 0.539381, SB loss: 0.749141
2023-10-30 08:31:36,972 Epoch: [166/484] Iter:[420/495], Time: 0.37, lr: [0.006835641629460974], Loss: 2.065268, Acc:0.792991, Semantic loss: 0.777999, BCE loss: 0.538172, SB loss: 0.749097
2023-10-30 08:31:40,693 Epoch: [166/484] Iter:[430/495], Time: 0.37, lr: [0.006835249751184598], Loss: 2.066025, Acc:0.793108, Semantic loss: 0.777371, BCE loss: 0.539669, SB loss: 0.748985
2023-10-30 08:31:44,396 Epoch: [166/484] Iter:[440/495], Time: 0.37, lr: [0.006834857870411857], Loss: 2.066001, Acc:0.793203, Semantic loss: 0.777050, BCE loss: 0.540130, SB loss: 0.748820
2023-10-30 08:31:48,064 Epoch: [166/484] Iter:[450/495], Time: 0.37, lr: [0.006834465987142574], Loss: 2.063928, Acc:0.793013, Semantic loss: 0.775696, BCE loss: 0.539975, SB loss: 0.748257
2023-10-30 08:31:51,780 Epoch: [166/484] Iter:[460/495], Time: 0.37, lr: [0.006834074101376575], Loss: 2.063000, Acc:0.793148, Semantic loss: 0.775026, BCE loss: 0.540171, SB loss: 0.747803
2023-10-30 08:31:55,536 Epoch: [166/484] Iter:[470/495], Time: 0.37, lr: [0.006833682213113685], Loss: 2.064134, Acc:0.793285, Semantic loss: 0.777178, BCE loss: 0.539711, SB loss: 0.747244
2023-10-30 08:31:59,159 Epoch: [166/484] Iter:[480/495], Time: 0.37, lr: [0.00683329032235373], Loss: 2.064763, Acc:0.792319, Semantic loss: 0.777791, BCE loss: 0.539111, SB loss: 0.747860
2023-10-30 08:32:02,691 Epoch: [166/484] Iter:[490/495], Time: 0.37, lr: [0.006832898429096535], Loss: 2.066111, Acc:0.791966, Semantic loss: 0.779097, BCE loss: 0.538489, SB loss: 0.748524
2023-10-30 08:32:04,090 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:32:04,357 Loss: 2.281, MeanIU:  0.6043, Best_mIoU:  0.6984
2023-10-30 08:32:04,357 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828]
2023-10-30 08:32:06,585 Epoch: [167/484] Iter:[0/495], Time: 2.19, lr: [0.006832702481531417], Loss: 2.098564, Acc:0.815996, Semantic loss: 0.780441, BCE loss: 0.530547, SB loss: 0.787576
2023-10-30 08:32:10,459 Epoch: [167/484] Iter:[10/495], Time: 0.55, lr: [0.006832310584528031], Loss: 2.177062, Acc:0.768021, Semantic loss: 0.877566, BCE loss: 0.505140, SB loss: 0.794356
2023-10-30 08:32:14,160 Epoch: [167/484] Iter:[20/495], Time: 0.47, lr: [0.006831918685026968], Loss: 2.100884, Acc:0.775741, Semantic loss: 0.796451, BCE loss: 0.538938, SB loss: 0.765496
2023-10-30 08:32:17,907 Epoch: [167/484] Iter:[30/495], Time: 0.44, lr: [0.00683152678302805], Loss: 2.106572, Acc:0.780310, Semantic loss: 0.797015, BCE loss: 0.548334, SB loss: 0.761223
2023-10-30 08:32:21,656 Epoch: [167/484] Iter:[40/495], Time: 0.42, lr: [0.006831134878531102], Loss: 2.081399, Acc:0.783479, Semantic loss: 0.782770, BCE loss: 0.539693, SB loss: 0.758937
2023-10-30 08:32:25,344 Epoch: [167/484] Iter:[50/495], Time: 0.41, lr: [0.006830742971535952], Loss: 2.065607, Acc:0.794412, Semantic loss: 0.774785, BCE loss: 0.532392, SB loss: 0.758430
2023-10-30 08:32:29,010 Epoch: [167/484] Iter:[60/495], Time: 0.40, lr: [0.006830351062042422], Loss: 2.061289, Acc:0.793509, Semantic loss: 0.772023, BCE loss: 0.528208, SB loss: 0.761058
2023-10-30 08:32:32,685 Epoch: [167/484] Iter:[70/495], Time: 0.40, lr: [0.006829959150050338], Loss: 2.050957, Acc:0.786589, Semantic loss: 0.768399, BCE loss: 0.523481, SB loss: 0.759077
2023-10-30 08:32:36,412 Epoch: [167/484] Iter:[80/495], Time: 0.40, lr: [0.006829567235559525], Loss: 2.056275, Acc:0.787300, Semantic loss: 0.770903, BCE loss: 0.524076, SB loss: 0.761296
2023-10-30 08:32:40,065 Epoch: [167/484] Iter:[90/495], Time: 0.39, lr: [0.006829175318569807], Loss: 2.049553, Acc:0.791371, Semantic loss: 0.766997, BCE loss: 0.525696, SB loss: 0.756859
2023-10-30 08:32:43,742 Epoch: [167/484] Iter:[100/495], Time: 0.39, lr: [0.0068287833990810076], Loss: 2.058091, Acc:0.788623, Semantic loss: 0.771177, BCE loss: 0.529201, SB loss: 0.757712
2023-10-30 08:32:47,405 Epoch: [167/484] Iter:[110/495], Time: 0.39, lr: [0.006828391477092954], Loss: 2.050511, Acc:0.789599, Semantic loss: 0.768037, BCE loss: 0.529028, SB loss: 0.753445
2023-10-30 08:32:51,149 Epoch: [167/484] Iter:[120/495], Time: 0.39, lr: [0.00682799955260547], Loss: 2.049826, Acc:0.791406, Semantic loss: 0.769018, BCE loss: 0.528608, SB loss: 0.752201
2023-10-30 08:32:54,878 Epoch: [167/484] Iter:[130/495], Time: 0.39, lr: [0.006827607625618379], Loss: 2.051077, Acc:0.794323, Semantic loss: 0.774264, BCE loss: 0.524118, SB loss: 0.752696
2023-10-30 08:32:58,476 Epoch: [167/484] Iter:[140/495], Time: 0.38, lr: [0.006827215696131506], Loss: 2.059876, Acc:0.795698, Semantic loss: 0.779875, BCE loss: 0.527809, SB loss: 0.752192
2023-10-30 08:33:02,184 Epoch: [167/484] Iter:[150/495], Time: 0.38, lr: [0.0068268237641446764], Loss: 2.071431, Acc:0.792890, Semantic loss: 0.785688, BCE loss: 0.531573, SB loss: 0.754170
2023-10-30 08:33:05,938 Epoch: [167/484] Iter:[160/495], Time: 0.38, lr: [0.006826431829657716], Loss: 2.060297, Acc:0.795767, Semantic loss: 0.778679, BCE loss: 0.530608, SB loss: 0.751011
2023-10-30 08:33:09,755 Epoch: [167/484] Iter:[170/495], Time: 0.38, lr: [0.006826039892670447], Loss: 2.058206, Acc:0.797273, Semantic loss: 0.775648, BCE loss: 0.531613, SB loss: 0.750944
2023-10-30 08:33:13,470 Epoch: [167/484] Iter:[180/495], Time: 0.38, lr: [0.006825647953182694], Loss: 2.059493, Acc:0.798369, Semantic loss: 0.777426, BCE loss: 0.530733, SB loss: 0.751334
2023-10-30 08:33:17,095 Epoch: [167/484] Iter:[190/495], Time: 0.38, lr: [0.006825256011194284], Loss: 2.080102, Acc:0.796194, Semantic loss: 0.793094, BCE loss: 0.531662, SB loss: 0.755346
2023-10-30 08:33:20,772 Epoch: [167/484] Iter:[200/495], Time: 0.38, lr: [0.006824864066705037], Loss: 2.071619, Acc:0.795350, Semantic loss: 0.787081, BCE loss: 0.530440, SB loss: 0.754098
2023-10-30 08:33:24,429 Epoch: [167/484] Iter:[210/495], Time: 0.38, lr: [0.006824472119714783], Loss: 2.075119, Acc:0.796532, Semantic loss: 0.786519, BCE loss: 0.532346, SB loss: 0.756254
2023-10-30 08:33:28,075 Epoch: [167/484] Iter:[220/495], Time: 0.38, lr: [0.006824080170223342], Loss: 2.075624, Acc:0.796371, Semantic loss: 0.785967, BCE loss: 0.534911, SB loss: 0.754745
2023-10-30 08:33:31,762 Epoch: [167/484] Iter:[230/495], Time: 0.38, lr: [0.006823688218230542], Loss: 2.076733, Acc:0.796292, Semantic loss: 0.785327, BCE loss: 0.535049, SB loss: 0.756357
2023-10-30 08:33:35,550 Epoch: [167/484] Iter:[240/495], Time: 0.38, lr: [0.006823296263736204], Loss: 2.076174, Acc:0.797766, Semantic loss: 0.784056, BCE loss: 0.536213, SB loss: 0.755905
2023-10-30 08:33:39,261 Epoch: [167/484] Iter:[250/495], Time: 0.38, lr: [0.006822904306740155], Loss: 2.077300, Acc:0.797755, Semantic loss: 0.784283, BCE loss: 0.538043, SB loss: 0.754974
2023-10-30 08:33:43,044 Epoch: [167/484] Iter:[260/495], Time: 0.38, lr: [0.006822512347242218], Loss: 2.076544, Acc:0.798108, Semantic loss: 0.783978, BCE loss: 0.537139, SB loss: 0.755427
2023-10-30 08:33:46,617 Epoch: [167/484] Iter:[270/495], Time: 0.38, lr: [0.006822120385242217], Loss: 2.073768, Acc:0.798387, Semantic loss: 0.781514, BCE loss: 0.538083, SB loss: 0.754171
2023-10-30 08:33:50,326 Epoch: [167/484] Iter:[280/495], Time: 0.38, lr: [0.006821728420739977], Loss: 2.081137, Acc:0.798969, Semantic loss: 0.787878, BCE loss: 0.537680, SB loss: 0.755579
2023-10-30 08:33:54,023 Epoch: [167/484] Iter:[290/495], Time: 0.38, lr: [0.006821336453735322], Loss: 2.086113, Acc:0.799547, Semantic loss: 0.789765, BCE loss: 0.540600, SB loss: 0.755748
2023-10-30 08:33:57,748 Epoch: [167/484] Iter:[300/495], Time: 0.38, lr: [0.006820944484228076], Loss: 2.081361, Acc:0.798620, Semantic loss: 0.785573, BCE loss: 0.541311, SB loss: 0.754477
2023-10-30 08:34:01,507 Epoch: [167/484] Iter:[310/495], Time: 0.38, lr: [0.006820552512218064], Loss: 2.085552, Acc:0.799353, Semantic loss: 0.787225, BCE loss: 0.542600, SB loss: 0.755727
2023-10-30 08:34:05,161 Epoch: [167/484] Iter:[320/495], Time: 0.38, lr: [0.006820160537705109], Loss: 2.083787, Acc:0.798989, Semantic loss: 0.786883, BCE loss: 0.541695, SB loss: 0.755209
2023-10-30 08:34:08,758 Epoch: [167/484] Iter:[330/495], Time: 0.38, lr: [0.006819768560689038], Loss: 2.081048, Acc:0.799243, Semantic loss: 0.784648, BCE loss: 0.542823, SB loss: 0.753576
2023-10-30 08:34:12,449 Epoch: [167/484] Iter:[340/495], Time: 0.38, lr: [0.006819376581169672], Loss: 2.080313, Acc:0.800128, Semantic loss: 0.783811, BCE loss: 0.542985, SB loss: 0.753518
2023-10-30 08:34:16,135 Epoch: [167/484] Iter:[350/495], Time: 0.38, lr: [0.0068189845991468365], Loss: 2.079325, Acc:0.799480, Semantic loss: 0.784257, BCE loss: 0.542111, SB loss: 0.752957
2023-10-30 08:34:19,792 Epoch: [167/484] Iter:[360/495], Time: 0.38, lr: [0.006818592614620355], Loss: 2.081050, Acc:0.799879, Semantic loss: 0.784993, BCE loss: 0.542832, SB loss: 0.753226
2023-10-30 08:34:23,569 Epoch: [167/484] Iter:[370/495], Time: 0.38, lr: [0.006818200627590052], Loss: 2.081463, Acc:0.799009, Semantic loss: 0.785511, BCE loss: 0.541866, SB loss: 0.754086
2023-10-30 08:34:27,105 Epoch: [167/484] Iter:[380/495], Time: 0.37, lr: [0.0068178086380557505], Loss: 2.085918, Acc:0.799150, Semantic loss: 0.790045, BCE loss: 0.541681, SB loss: 0.754193
2023-10-30 08:34:30,683 Epoch: [167/484] Iter:[390/495], Time: 0.37, lr: [0.006817416646017277], Loss: 2.084045, Acc:0.798672, Semantic loss: 0.788464, BCE loss: 0.542550, SB loss: 0.753031
2023-10-30 08:34:34,343 Epoch: [167/484] Iter:[400/495], Time: 0.37, lr: [0.006817024651474454], Loss: 2.085467, Acc:0.798317, Semantic loss: 0.789900, BCE loss: 0.541767, SB loss: 0.753800
2023-10-30 08:34:37,986 Epoch: [167/484] Iter:[410/495], Time: 0.37, lr: [0.006816632654427106], Loss: 2.087116, Acc:0.797786, Semantic loss: 0.790229, BCE loss: 0.541883, SB loss: 0.755004
2023-10-30 08:34:41,581 Epoch: [167/484] Iter:[420/495], Time: 0.37, lr: [0.006816240654875056], Loss: 2.084737, Acc:0.797605, Semantic loss: 0.788597, BCE loss: 0.542024, SB loss: 0.754116
2023-10-30 08:34:45,263 Epoch: [167/484] Iter:[430/495], Time: 0.37, lr: [0.006815848652818129], Loss: 2.084928, Acc:0.797214, Semantic loss: 0.788551, BCE loss: 0.542307, SB loss: 0.754069
2023-10-30 08:34:48,968 Epoch: [167/484] Iter:[440/495], Time: 0.37, lr: [0.006815456648256148], Loss: 2.086065, Acc:0.796955, Semantic loss: 0.788504, BCE loss: 0.543487, SB loss: 0.754074
2023-10-30 08:34:52,782 Epoch: [167/484] Iter:[450/495], Time: 0.37, lr: [0.006815064641188936], Loss: 2.085272, Acc:0.796858, Semantic loss: 0.788020, BCE loss: 0.543241, SB loss: 0.754011
2023-10-30 08:34:56,406 Epoch: [167/484] Iter:[460/495], Time: 0.37, lr: [0.00681467263161632], Loss: 2.087591, Acc:0.797126, Semantic loss: 0.788927, BCE loss: 0.544470, SB loss: 0.754195
2023-10-30 08:35:00,104 Epoch: [167/484] Iter:[470/495], Time: 0.37, lr: [0.006814280619538121], Loss: 2.084122, Acc:0.797013, Semantic loss: 0.786336, BCE loss: 0.544053, SB loss: 0.753733
2023-10-30 08:35:03,808 Epoch: [167/484] Iter:[480/495], Time: 0.37, lr: [0.006813888604954165], Loss: 2.083985, Acc:0.797701, Semantic loss: 0.785824, BCE loss: 0.544313, SB loss: 0.753848
2023-10-30 08:35:07,304 Epoch: [167/484] Iter:[490/495], Time: 0.37, lr: [0.006813496587864274], Loss: 2.084258, Acc:0.797878, Semantic loss: 0.786742, BCE loss: 0.543664, SB loss: 0.753851
2023-10-30 08:35:08,692 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:35:08,934 Loss: 2.281, MeanIU:  0.6043, Best_mIoU:  0.6984
2023-10-30 08:35:08,934 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828]
2023-10-30 08:35:10,893 Epoch: [168/484] Iter:[0/495], Time: 1.92, lr: [0.006813300578379548], Loss: 2.349390, Acc:0.749686, Semantic loss: 0.978965, BCE loss: 0.551683, SB loss: 0.818742
2023-10-30 08:35:14,933 Epoch: [168/484] Iter:[10/495], Time: 0.54, lr: [0.006812908557530425], Loss: 2.317192, Acc:0.752428, Semantic loss: 0.942018, BCE loss: 0.574643, SB loss: 0.800531
2023-10-30 08:35:18,727 Epoch: [168/484] Iter:[20/495], Time: 0.46, lr: [0.006812516534174928], Loss: 2.178755, Acc:0.765503, Semantic loss: 0.846271, BCE loss: 0.552924, SB loss: 0.779561
2023-10-30 08:35:22,331 Epoch: [168/484] Iter:[30/495], Time: 0.43, lr: [0.006812124508312878], Loss: 2.142297, Acc:0.776654, Semantic loss: 0.809398, BCE loss: 0.565624, SB loss: 0.767274
2023-10-30 08:35:26,039 Epoch: [168/484] Iter:[40/495], Time: 0.42, lr: [0.0068117324799441], Loss: 2.153908, Acc:0.786759, Semantic loss: 0.814673, BCE loss: 0.570504, SB loss: 0.768730
2023-10-30 08:35:29,827 Epoch: [168/484] Iter:[50/495], Time: 0.41, lr: [0.00681134044906842], Loss: 2.169356, Acc:0.784824, Semantic loss: 0.822163, BCE loss: 0.578585, SB loss: 0.768608
2023-10-30 08:35:33,464 Epoch: [168/484] Iter:[60/495], Time: 0.40, lr: [0.00681094841568566], Loss: 2.156243, Acc:0.788442, Semantic loss: 0.811394, BCE loss: 0.580688, SB loss: 0.764161
2023-10-30 08:35:37,136 Epoch: [168/484] Iter:[70/495], Time: 0.40, lr: [0.006810556379795643], Loss: 2.120951, Acc:0.794034, Semantic loss: 0.794465, BCE loss: 0.564370, SB loss: 0.762116
2023-10-30 08:35:40,854 Epoch: [168/484] Iter:[80/495], Time: 0.39, lr: [0.006810164341398193], Loss: 2.126872, Acc:0.793454, Semantic loss: 0.797421, BCE loss: 0.565991, SB loss: 0.763459
2023-10-30 08:35:44,451 Epoch: [168/484] Iter:[90/495], Time: 0.39, lr: [0.006809772300493134], Loss: 2.140649, Acc:0.793884, Semantic loss: 0.803661, BCE loss: 0.571516, SB loss: 0.765473
2023-10-30 08:35:48,251 Epoch: [168/484] Iter:[100/495], Time: 0.39, lr: [0.006809380257080288], Loss: 2.143229, Acc:0.791217, Semantic loss: 0.807254, BCE loss: 0.570095, SB loss: 0.765879
2023-10-30 08:35:52,041 Epoch: [168/484] Iter:[110/495], Time: 0.39, lr: [0.006808988211159481], Loss: 2.138061, Acc:0.792803, Semantic loss: 0.804456, BCE loss: 0.569061, SB loss: 0.764543
2023-10-30 08:35:55,704 Epoch: [168/484] Iter:[120/495], Time: 0.39, lr: [0.006808596162730534], Loss: 2.137567, Acc:0.792688, Semantic loss: 0.806948, BCE loss: 0.565570, SB loss: 0.765050
2023-10-30 08:35:59,408 Epoch: [168/484] Iter:[130/495], Time: 0.39, lr: [0.006808204111793272], Loss: 2.121568, Acc:0.794964, Semantic loss: 0.799590, BCE loss: 0.561081, SB loss: 0.760897
2023-10-30 08:36:03,180 Epoch: [168/484] Iter:[140/495], Time: 0.38, lr: [0.0068078120583475185], Loss: 2.126213, Acc:0.796522, Semantic loss: 0.800863, BCE loss: 0.560850, SB loss: 0.764500
2023-10-30 08:36:06,853 Epoch: [168/484] Iter:[150/495], Time: 0.38, lr: [0.006807420002393097], Loss: 2.121479, Acc:0.794870, Semantic loss: 0.802038, BCE loss: 0.557727, SB loss: 0.761714
2023-10-30 08:36:10,622 Epoch: [168/484] Iter:[160/495], Time: 0.38, lr: [0.00680702794392983], Loss: 2.121967, Acc:0.794610, Semantic loss: 0.802162, BCE loss: 0.557075, SB loss: 0.762730
2023-10-30 08:36:14,264 Epoch: [168/484] Iter:[170/495], Time: 0.38, lr: [0.006806635882957541], Loss: 2.124294, Acc:0.793886, Semantic loss: 0.802925, BCE loss: 0.556417, SB loss: 0.764952
2023-10-30 08:36:17,916 Epoch: [168/484] Iter:[180/495], Time: 0.38, lr: [0.006806243819476053], Loss: 2.120358, Acc:0.794805, Semantic loss: 0.800183, BCE loss: 0.553969, SB loss: 0.766206
2023-10-30 08:36:21,635 Epoch: [168/484] Iter:[190/495], Time: 0.38, lr: [0.0068058517534851926], Loss: 2.114785, Acc:0.795747, Semantic loss: 0.794653, BCE loss: 0.556313, SB loss: 0.763819
2023-10-30 08:36:25,284 Epoch: [168/484] Iter:[200/495], Time: 0.38, lr: [0.006805459684984778], Loss: 2.113005, Acc:0.795495, Semantic loss: 0.794743, BCE loss: 0.555387, SB loss: 0.762875
2023-10-30 08:36:28,956 Epoch: [168/484] Iter:[210/495], Time: 0.38, lr: [0.006805067613974637], Loss: 2.114501, Acc:0.795840, Semantic loss: 0.795914, BCE loss: 0.555220, SB loss: 0.763368
2023-10-30 08:36:32,681 Epoch: [168/484] Iter:[220/495], Time: 0.38, lr: [0.00680467554045459], Loss: 2.111938, Acc:0.797279, Semantic loss: 0.795738, BCE loss: 0.554532, SB loss: 0.761668
2023-10-30 08:36:36,278 Epoch: [168/484] Iter:[230/495], Time: 0.38, lr: [0.006804283464424462], Loss: 2.107504, Acc:0.797840, Semantic loss: 0.792792, BCE loss: 0.553693, SB loss: 0.761018
2023-10-30 08:36:39,987 Epoch: [168/484] Iter:[240/495], Time: 0.38, lr: [0.006803891385884074], Loss: 2.107434, Acc:0.799685, Semantic loss: 0.791697, BCE loss: 0.555660, SB loss: 0.760077
2023-10-30 08:36:43,654 Epoch: [168/484] Iter:[250/495], Time: 0.38, lr: [0.006803499304833252], Loss: 2.111778, Acc:0.800795, Semantic loss: 0.795889, BCE loss: 0.554874, SB loss: 0.761014
2023-10-30 08:36:47,255 Epoch: [168/484] Iter:[260/495], Time: 0.38, lr: [0.006803107221271817], Loss: 2.113179, Acc:0.799177, Semantic loss: 0.796519, BCE loss: 0.556099, SB loss: 0.760562
2023-10-30 08:36:50,986 Epoch: [168/484] Iter:[270/495], Time: 0.38, lr: [0.006802715135199593], Loss: 2.113304, Acc:0.797806, Semantic loss: 0.797770, BCE loss: 0.554949, SB loss: 0.760584
2023-10-30 08:36:54,710 Epoch: [168/484] Iter:[280/495], Time: 0.38, lr: [0.006802323046616403], Loss: 2.109620, Acc:0.797276, Semantic loss: 0.794768, BCE loss: 0.554789, SB loss: 0.760064
2023-10-30 08:36:58,375 Epoch: [168/484] Iter:[290/495], Time: 0.38, lr: [0.006801930955522071], Loss: 2.109276, Acc:0.797231, Semantic loss: 0.793948, BCE loss: 0.555705, SB loss: 0.759622
2023-10-30 08:37:02,061 Epoch: [168/484] Iter:[300/495], Time: 0.38, lr: [0.006801538861916419], Loss: 2.104672, Acc:0.797901, Semantic loss: 0.791200, BCE loss: 0.554787, SB loss: 0.758684
2023-10-30 08:37:05,652 Epoch: [168/484] Iter:[310/495], Time: 0.38, lr: [0.006801146765799271], Loss: 2.104192, Acc:0.798055, Semantic loss: 0.789574, BCE loss: 0.556297, SB loss: 0.758321
2023-10-30 08:37:09,379 Epoch: [168/484] Iter:[320/495], Time: 0.38, lr: [0.006800754667170448], Loss: 2.103299, Acc:0.798802, Semantic loss: 0.788529, BCE loss: 0.557105, SB loss: 0.757666
2023-10-30 08:37:13,091 Epoch: [168/484] Iter:[330/495], Time: 0.37, lr: [0.006800362566029774], Loss: 2.103952, Acc:0.798798, Semantic loss: 0.790244, BCE loss: 0.556002, SB loss: 0.757706
2023-10-30 08:37:16,796 Epoch: [168/484] Iter:[340/495], Time: 0.37, lr: [0.006799970462377074], Loss: 2.101772, Acc:0.797678, Semantic loss: 0.788972, BCE loss: 0.555375, SB loss: 0.757425
2023-10-30 08:37:20,517 Epoch: [168/484] Iter:[350/495], Time: 0.37, lr: [0.006799578356212167], Loss: 2.104127, Acc:0.797998, Semantic loss: 0.789089, BCE loss: 0.557387, SB loss: 0.757650
2023-10-30 08:37:24,185 Epoch: [168/484] Iter:[360/495], Time: 0.37, lr: [0.006799186247534881], Loss: 2.101003, Acc:0.797541, Semantic loss: 0.788545, BCE loss: 0.555077, SB loss: 0.757382
2023-10-30 08:37:27,893 Epoch: [168/484] Iter:[370/495], Time: 0.37, lr: [0.006798794136345035], Loss: 2.102720, Acc:0.797304, Semantic loss: 0.789387, BCE loss: 0.555971, SB loss: 0.757362
2023-10-30 08:37:31,567 Epoch: [168/484] Iter:[380/495], Time: 0.37, lr: [0.006798402022642452], Loss: 2.101430, Acc:0.797195, Semantic loss: 0.788408, BCE loss: 0.556010, SB loss: 0.757012
2023-10-30 08:37:35,331 Epoch: [168/484] Iter:[390/495], Time: 0.37, lr: [0.006798009906426958], Loss: 2.099531, Acc:0.795425, Semantic loss: 0.788385, BCE loss: 0.554346, SB loss: 0.756800
2023-10-30 08:37:39,025 Epoch: [168/484] Iter:[400/495], Time: 0.37, lr: [0.006797617787698372], Loss: 2.096937, Acc:0.795609, Semantic loss: 0.785615, BCE loss: 0.555178, SB loss: 0.756144
2023-10-30 08:37:42,665 Epoch: [168/484] Iter:[410/495], Time: 0.37, lr: [0.006797225666456519], Loss: 2.100481, Acc:0.795817, Semantic loss: 0.787066, BCE loss: 0.556719, SB loss: 0.756696
2023-10-30 08:37:46,270 Epoch: [168/484] Iter:[420/495], Time: 0.37, lr: [0.006796833542701222], Loss: 2.100059, Acc:0.795612, Semantic loss: 0.787000, BCE loss: 0.556220, SB loss: 0.756839
2023-10-30 08:37:50,058 Epoch: [168/484] Iter:[430/495], Time: 0.37, lr: [0.006796441416432302], Loss: 2.095798, Acc:0.796294, Semantic loss: 0.784668, BCE loss: 0.555125, SB loss: 0.756005
2023-10-30 08:37:53,768 Epoch: [168/484] Iter:[440/495], Time: 0.37, lr: [0.006796049287649583], Loss: 2.097358, Acc:0.796909, Semantic loss: 0.786228, BCE loss: 0.555067, SB loss: 0.756063
2023-10-30 08:37:57,365 Epoch: [168/484] Iter:[450/495], Time: 0.37, lr: [0.006795657156352889], Loss: 2.097081, Acc:0.796865, Semantic loss: 0.786122, BCE loss: 0.555205, SB loss: 0.755755
2023-10-30 08:38:01,057 Epoch: [168/484] Iter:[460/495], Time: 0.37, lr: [0.006795265022542039], Loss: 2.095002, Acc:0.796629, Semantic loss: 0.785684, BCE loss: 0.554069, SB loss: 0.755249
2023-10-30 08:38:04,785 Epoch: [168/484] Iter:[470/495], Time: 0.37, lr: [0.006794872886216861], Loss: 2.091680, Acc:0.796721, Semantic loss: 0.784215, BCE loss: 0.553049, SB loss: 0.754416
2023-10-30 08:38:08,519 Epoch: [168/484] Iter:[480/495], Time: 0.37, lr: [0.006794480747377173], Loss: 2.090386, Acc:0.796491, Semantic loss: 0.784131, BCE loss: 0.551613, SB loss: 0.754643
2023-10-30 08:38:11,992 Epoch: [168/484] Iter:[490/495], Time: 0.37, lr: [0.006794088606022798], Loss: 2.091941, Acc:0.795886, Semantic loss: 0.785251, BCE loss: 0.551791, SB loss: 0.754900
2023-10-30 08:38:13,397 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:38:13,646 Loss: 2.281, MeanIU:  0.6043, Best_mIoU:  0.6984
2023-10-30 08:38:13,646 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828]
2023-10-30 08:38:15,752 Epoch: [169/484] Iter:[0/495], Time: 2.07, lr: [0.006793892534402549], Loss: 2.326587, Acc:0.769802, Semantic loss: 1.099533, BCE loss: 0.415228, SB loss: 0.811827
2023-10-30 08:38:19,735 Epoch: [169/484] Iter:[10/495], Time: 0.55, lr: [0.006793500389275814], Loss: 2.098778, Acc:0.791545, Semantic loss: 0.799239, BCE loss: 0.517514, SB loss: 0.782025
2023-10-30 08:38:23,528 Epoch: [169/484] Iter:[20/495], Time: 0.47, lr: [0.00679310824163395], Loss: 2.148755, Acc:0.789943, Semantic loss: 0.807349, BCE loss: 0.540108, SB loss: 0.801298
2023-10-30 08:38:27,187 Epoch: [169/484] Iter:[30/495], Time: 0.44, lr: [0.006792716091476778], Loss: 2.158985, Acc:0.793632, Semantic loss: 0.811800, BCE loss: 0.553016, SB loss: 0.794169
2023-10-30 08:38:30,759 Epoch: [169/484] Iter:[40/495], Time: 0.42, lr: [0.006792323938804123], Loss: 2.164193, Acc:0.791163, Semantic loss: 0.830527, BCE loss: 0.551322, SB loss: 0.782344
2023-10-30 08:38:34,483 Epoch: [169/484] Iter:[50/495], Time: 0.41, lr: [0.006791931783615807], Loss: 2.117866, Acc:0.793197, Semantic loss: 0.808533, BCE loss: 0.539100, SB loss: 0.770233
2023-10-30 08:38:38,081 Epoch: [169/484] Iter:[60/495], Time: 0.40, lr: [0.00679153962591165], Loss: 2.090973, Acc:0.795728, Semantic loss: 0.791315, BCE loss: 0.537223, SB loss: 0.762436
2023-10-30 08:38:41,872 Epoch: [169/484] Iter:[70/495], Time: 0.40, lr: [0.006791147465691476], Loss: 2.053550, Acc:0.793406, Semantic loss: 0.777263, BCE loss: 0.523445, SB loss: 0.752841
2023-10-30 08:38:45,653 Epoch: [169/484] Iter:[80/495], Time: 0.39, lr: [0.006790755302955108], Loss: 2.058271, Acc:0.790024, Semantic loss: 0.779749, BCE loss: 0.524005, SB loss: 0.754516
2023-10-30 08:38:49,360 Epoch: [169/484] Iter:[90/495], Time: 0.39, lr: [0.0067903631377023675], Loss: 2.064173, Acc:0.788306, Semantic loss: 0.780955, BCE loss: 0.525857, SB loss: 0.757361
2023-10-30 08:38:53,054 Epoch: [169/484] Iter:[100/495], Time: 0.39, lr: [0.006789970969933079], Loss: 2.061835, Acc:0.785766, Semantic loss: 0.782243, BCE loss: 0.519735, SB loss: 0.759858
2023-10-30 08:38:56,774 Epoch: [169/484] Iter:[110/495], Time: 0.39, lr: [0.006789578799647062], Loss: 2.053640, Acc:0.789743, Semantic loss: 0.774833, BCE loss: 0.521586, SB loss: 0.757222
2023-10-30 08:39:00,559 Epoch: [169/484] Iter:[120/495], Time: 0.39, lr: [0.006789186626844142], Loss: 2.064579, Acc:0.790440, Semantic loss: 0.781997, BCE loss: 0.524949, SB loss: 0.757633
2023-10-30 08:39:04,320 Epoch: [169/484] Iter:[130/495], Time: 0.39, lr: [0.006788794451524138], Loss: 2.059993, Acc:0.789300, Semantic loss: 0.779349, BCE loss: 0.524486, SB loss: 0.756158
2023-10-30 08:39:08,032 Epoch: [169/484] Iter:[140/495], Time: 0.39, lr: [0.006788402273686873], Loss: 2.062792, Acc:0.791505, Semantic loss: 0.778437, BCE loss: 0.526427, SB loss: 0.757928
2023-10-30 08:39:11,859 Epoch: [169/484] Iter:[150/495], Time: 0.39, lr: [0.006788010093332171], Loss: 2.074879, Acc:0.789061, Semantic loss: 0.781852, BCE loss: 0.533157, SB loss: 0.759869
2023-10-30 08:39:15,650 Epoch: [169/484] Iter:[160/495], Time: 0.38, lr: [0.006787617910459853], Loss: 2.066641, Acc:0.790277, Semantic loss: 0.777022, BCE loss: 0.531910, SB loss: 0.757709
2023-10-30 08:39:19,282 Epoch: [169/484] Iter:[170/495], Time: 0.38, lr: [0.006787225725069739], Loss: 2.061716, Acc:0.790926, Semantic loss: 0.774573, BCE loss: 0.531943, SB loss: 0.755200
2023-10-30 08:39:22,902 Epoch: [169/484] Iter:[180/495], Time: 0.38, lr: [0.006786833537161656], Loss: 2.059883, Acc:0.791443, Semantic loss: 0.772559, BCE loss: 0.532305, SB loss: 0.755019
2023-10-30 08:39:26,651 Epoch: [169/484] Iter:[190/495], Time: 0.38, lr: [0.006786441346735423], Loss: 2.056767, Acc:0.790669, Semantic loss: 0.771420, BCE loss: 0.530155, SB loss: 0.755192
2023-10-30 08:39:30,460 Epoch: [169/484] Iter:[200/495], Time: 0.38, lr: [0.0067860491537908635], Loss: 2.064629, Acc:0.792030, Semantic loss: 0.773318, BCE loss: 0.533217, SB loss: 0.758095
2023-10-30 08:39:34,264 Epoch: [169/484] Iter:[210/495], Time: 0.38, lr: [0.006785656958327798], Loss: 2.071865, Acc:0.793001, Semantic loss: 0.775458, BCE loss: 0.537591, SB loss: 0.758815
2023-10-30 08:39:37,943 Epoch: [169/484] Iter:[220/495], Time: 0.38, lr: [0.00678526476034605], Loss: 2.071101, Acc:0.794491, Semantic loss: 0.774564, BCE loss: 0.537930, SB loss: 0.758607
2023-10-30 08:39:41,706 Epoch: [169/484] Iter:[230/495], Time: 0.38, lr: [0.006784872559845441], Loss: 2.067581, Acc:0.794220, Semantic loss: 0.772361, BCE loss: 0.537554, SB loss: 0.757666
2023-10-30 08:39:45,474 Epoch: [169/484] Iter:[240/495], Time: 0.38, lr: [0.006784480356825793], Loss: 2.059520, Acc:0.794345, Semantic loss: 0.768013, BCE loss: 0.536240, SB loss: 0.755268
2023-10-30 08:39:49,111 Epoch: [169/484] Iter:[250/495], Time: 0.38, lr: [0.006784088151286927], Loss: 2.057403, Acc:0.794113, Semantic loss: 0.766843, BCE loss: 0.535748, SB loss: 0.754811
2023-10-30 08:39:52,720 Epoch: [169/484] Iter:[260/495], Time: 0.38, lr: [0.006783695943228667], Loss: 2.054040, Acc:0.792661, Semantic loss: 0.767156, BCE loss: 0.533539, SB loss: 0.753345
2023-10-30 08:39:56,496 Epoch: [169/484] Iter:[270/495], Time: 0.38, lr: [0.006783303732650835], Loss: 2.062464, Acc:0.792737, Semantic loss: 0.773487, BCE loss: 0.533764, SB loss: 0.755212
2023-10-30 08:40:00,244 Epoch: [169/484] Iter:[280/495], Time: 0.38, lr: [0.006782911519553251], Loss: 2.061605, Acc:0.792480, Semantic loss: 0.772896, BCE loss: 0.533388, SB loss: 0.755320
2023-10-30 08:40:03,944 Epoch: [169/484] Iter:[290/495], Time: 0.38, lr: [0.006782519303935739], Loss: 2.060692, Acc:0.791939, Semantic loss: 0.773576, BCE loss: 0.530722, SB loss: 0.756394
2023-10-30 08:40:07,729 Epoch: [169/484] Iter:[300/495], Time: 0.38, lr: [0.006782127085798118], Loss: 2.063170, Acc:0.792717, Semantic loss: 0.775042, BCE loss: 0.530477, SB loss: 0.757651
2023-10-30 08:40:11,498 Epoch: [169/484] Iter:[310/495], Time: 0.38, lr: [0.006781734865140213], Loss: 2.066536, Acc:0.792513, Semantic loss: 0.781203, BCE loss: 0.527884, SB loss: 0.757449
2023-10-30 08:40:15,163 Epoch: [169/484] Iter:[320/495], Time: 0.38, lr: [0.006781342641961844], Loss: 2.068814, Acc:0.792155, Semantic loss: 0.781312, BCE loss: 0.528912, SB loss: 0.758589
2023-10-30 08:40:18,772 Epoch: [169/484] Iter:[330/495], Time: 0.38, lr: [0.006780950416262833], Loss: 2.067097, Acc:0.791008, Semantic loss: 0.781108, BCE loss: 0.526996, SB loss: 0.758993
2023-10-30 08:40:22,582 Epoch: [169/484] Iter:[340/495], Time: 0.38, lr: [0.006780558188043004], Loss: 2.070153, Acc:0.790560, Semantic loss: 0.782935, BCE loss: 0.526982, SB loss: 0.760236
2023-10-30 08:40:26,446 Epoch: [169/484] Iter:[350/495], Time: 0.38, lr: [0.006780165957302175], Loss: 2.068969, Acc:0.790293, Semantic loss: 0.781843, BCE loss: 0.527274, SB loss: 0.759853
2023-10-30 08:40:30,233 Epoch: [169/484] Iter:[360/495], Time: 0.38, lr: [0.006779773724040171], Loss: 2.078904, Acc:0.789879, Semantic loss: 0.786800, BCE loss: 0.531280, SB loss: 0.760824
2023-10-30 08:40:33,865 Epoch: [169/484] Iter:[370/495], Time: 0.38, lr: [0.006779381488256813], Loss: 2.077631, Acc:0.789123, Semantic loss: 0.785416, BCE loss: 0.531827, SB loss: 0.760388
2023-10-30 08:40:37,605 Epoch: [169/484] Iter:[380/495], Time: 0.38, lr: [0.006778989249951921], Loss: 2.079560, Acc:0.789735, Semantic loss: 0.785377, BCE loss: 0.534043, SB loss: 0.760139
2023-10-30 08:40:41,472 Epoch: [169/484] Iter:[390/495], Time: 0.38, lr: [0.006778597009125317], Loss: 2.082124, Acc:0.789332, Semantic loss: 0.786931, BCE loss: 0.533301, SB loss: 0.761892
2023-10-30 08:40:45,210 Epoch: [169/484] Iter:[400/495], Time: 0.38, lr: [0.006778204765776825], Loss: 2.079803, Acc:0.789624, Semantic loss: 0.785823, BCE loss: 0.532777, SB loss: 0.761203
2023-10-30 08:40:48,907 Epoch: [169/484] Iter:[410/495], Time: 0.38, lr: [0.006777812519906263], Loss: 2.078153, Acc:0.789928, Semantic loss: 0.785693, BCE loss: 0.531626, SB loss: 0.760834
2023-10-30 08:40:52,666 Epoch: [169/484] Iter:[420/495], Time: 0.38, lr: [0.006777420271513457], Loss: 2.080081, Acc:0.789341, Semantic loss: 0.785468, BCE loss: 0.533334, SB loss: 0.761279
2023-10-30 08:40:56,336 Epoch: [169/484] Iter:[430/495], Time: 0.38, lr: [0.006777028020598226], Loss: 2.083583, Acc:0.788417, Semantic loss: 0.788337, BCE loss: 0.532213, SB loss: 0.763033
2023-10-30 08:41:00,033 Epoch: [169/484] Iter:[440/495], Time: 0.38, lr: [0.006776635767160392], Loss: 2.084964, Acc:0.788460, Semantic loss: 0.789390, BCE loss: 0.532786, SB loss: 0.762788
2023-10-30 08:41:03,784 Epoch: [169/484] Iter:[450/495], Time: 0.38, lr: [0.006776243511199776], Loss: 2.085438, Acc:0.788984, Semantic loss: 0.789350, BCE loss: 0.533101, SB loss: 0.762986
2023-10-30 08:41:07,523 Epoch: [169/484] Iter:[460/495], Time: 0.38, lr: [0.0067758512527162], Loss: 2.089610, Acc:0.788947, Semantic loss: 0.790530, BCE loss: 0.536068, SB loss: 0.763012
2023-10-30 08:41:11,144 Epoch: [169/484] Iter:[470/495], Time: 0.38, lr: [0.0067754589917094835], Loss: 2.094682, Acc:0.789367, Semantic loss: 0.793110, BCE loss: 0.537258, SB loss: 0.764313
2023-10-30 08:41:14,853 Epoch: [169/484] Iter:[480/495], Time: 0.38, lr: [0.006775066728179452], Loss: 2.095486, Acc:0.789284, Semantic loss: 0.794914, BCE loss: 0.536458, SB loss: 0.764113
2023-10-30 08:41:18,360 Epoch: [169/484] Iter:[490/495], Time: 0.38, lr: [0.006774674462125924], Loss: 2.094859, Acc:0.788778, Semantic loss: 0.794351, BCE loss: 0.535726, SB loss: 0.764782
2023-10-30 08:41:19,779 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:41:20,013 Loss: 2.281, MeanIU:  0.6043, Best_mIoU:  0.6984
2023-10-30 08:41:20,013 [0.96539727 0.77725572 0.88656904 0.20145919 0.5185353  0.50682238
 0.58685705 0.68518839 0.88170304 0.45623862 0.92984605 0.73037337
 0.51695754 0.8830999  0.53011644 0.51014423 0.01163561 0.27777636
 0.62504828]
2023-10-30 08:41:22,198 Epoch: [170/484] Iter:[0/495], Time: 2.15, lr: [0.006774478328152794], Loss: 2.167469, Acc:0.899042, Semantic loss: 0.669774, BCE loss: 0.691963, SB loss: 0.805732
2023-10-30 08:41:26,037 Epoch: [170/484] Iter:[10/495], Time: 0.54, lr: [0.006774086058313687], Loss: 2.008133, Acc:0.801013, Semantic loss: 0.736722, BCE loss: 0.531764, SB loss: 0.739648
2023-10-30 08:41:29,729 Epoch: [170/484] Iter:[20/495], Time: 0.46, lr: [0.006773693785950639], Loss: 2.086375, Acc:0.783591, Semantic loss: 0.790606, BCE loss: 0.535903, SB loss: 0.759867
2023-10-30 08:41:33,389 Epoch: [170/484] Iter:[30/495], Time: 0.43, lr: [0.00677330151106347], Loss: 2.068812, Acc:0.791500, Semantic loss: 0.765378, BCE loss: 0.558776, SB loss: 0.744659
2023-10-30 08:41:37,038 Epoch: [170/484] Iter:[40/495], Time: 0.41, lr: [0.006772909233652], Loss: 2.082163, Acc:0.794734, Semantic loss: 0.771949, BCE loss: 0.560504, SB loss: 0.749711
2023-10-30 08:41:40,784 Epoch: [170/484] Iter:[50/495], Time: 0.41, lr: [0.0067725169537160524], Loss: 2.067439, Acc:0.795441, Semantic loss: 0.767912, BCE loss: 0.552263, SB loss: 0.747264
2023-10-30 08:41:44,529 Epoch: [170/484] Iter:[60/495], Time: 0.40, lr: [0.006772124671255449], Loss: 2.069430, Acc:0.804904, Semantic loss: 0.764565, BCE loss: 0.556955, SB loss: 0.747909
2023-10-30 08:41:48,114 Epoch: [170/484] Iter:[70/495], Time: 0.40, lr: [0.006771732386270009], Loss: 2.076579, Acc:0.800834, Semantic loss: 0.773197, BCE loss: 0.555122, SB loss: 0.748259
2023-10-30 08:41:51,781 Epoch: [170/484] Iter:[80/495], Time: 0.39, lr: [0.006771340098759554], Loss: 2.083989, Acc:0.799807, Semantic loss: 0.776261, BCE loss: 0.555719, SB loss: 0.752008
2023-10-30 08:41:55,500 Epoch: [170/484] Iter:[90/495], Time: 0.39, lr: [0.0067709478087239075], Loss: 2.082173, Acc:0.800834, Semantic loss: 0.771383, BCE loss: 0.561230, SB loss: 0.749559
2023-10-30 08:41:59,213 Epoch: [170/484] Iter:[100/495], Time: 0.39, lr: [0.006770555516162888], Loss: 2.103580, Acc:0.798455, Semantic loss: 0.785735, BCE loss: 0.559358, SB loss: 0.758488
2023-10-30 08:42:02,897 Epoch: [170/484] Iter:[110/495], Time: 0.39, lr: [0.006770163221076318], Loss: 2.097876, Acc:0.802027, Semantic loss: 0.779139, BCE loss: 0.560988, SB loss: 0.757749
2023-10-30 08:42:06,581 Epoch: [170/484] Iter:[120/495], Time: 0.38, lr: [0.006769770923464017], Loss: 2.096969, Acc:0.802212, Semantic loss: 0.778630, BCE loss: 0.559104, SB loss: 0.759235
2023-10-30 08:42:10,232 Epoch: [170/484] Iter:[130/495], Time: 0.38, lr: [0.006769378623325807], Loss: 2.094624, Acc:0.802235, Semantic loss: 0.777351, BCE loss: 0.558831, SB loss: 0.758442
2023-10-30 08:42:13,894 Epoch: [170/484] Iter:[140/495], Time: 0.38, lr: [0.006768986320661511], Loss: 2.093941, Acc:0.803639, Semantic loss: 0.777781, BCE loss: 0.559668, SB loss: 0.756493
2023-10-30 08:42:17,554 Epoch: [170/484] Iter:[150/495], Time: 0.38, lr: [0.006768594015470947], Loss: 2.088148, Acc:0.803572, Semantic loss: 0.778142, BCE loss: 0.554369, SB loss: 0.755637
2023-10-30 08:42:21,205 Epoch: [170/484] Iter:[160/495], Time: 0.38, lr: [0.0067682017077539385], Loss: 2.093218, Acc:0.800933, Semantic loss: 0.785454, BCE loss: 0.551046, SB loss: 0.756717
2023-10-30 08:42:24,898 Epoch: [170/484] Iter:[170/495], Time: 0.38, lr: [0.006767809397510306], Loss: 2.093456, Acc:0.800076, Semantic loss: 0.786432, BCE loss: 0.549443, SB loss: 0.757580
2023-10-30 08:42:28,560 Epoch: [170/484] Iter:[180/495], Time: 0.38, lr: [0.00676741708473987], Loss: 2.090653, Acc:0.800130, Semantic loss: 0.782861, BCE loss: 0.551438, SB loss: 0.756354
2023-10-30 08:42:32,197 Epoch: [170/484] Iter:[190/495], Time: 0.38, lr: [0.006767024769442451], Loss: 2.082892, Acc:0.800693, Semantic loss: 0.778815, BCE loss: 0.549563, SB loss: 0.754515
2023-10-30 08:42:35,815 Epoch: [170/484] Iter:[200/495], Time: 0.38, lr: [0.00676663245161787], Loss: 2.074560, Acc:0.801534, Semantic loss: 0.776307, BCE loss: 0.544880, SB loss: 0.753373
2023-10-30 08:42:39,413 Epoch: [170/484] Iter:[210/495], Time: 0.38, lr: [0.006766240131265948], Loss: 2.083249, Acc:0.801204, Semantic loss: 0.781863, BCE loss: 0.545037, SB loss: 0.756349
2023-10-30 08:42:43,006 Epoch: [170/484] Iter:[220/495], Time: 0.38, lr: [0.006765847808386507], Loss: 2.088825, Acc:0.799603, Semantic loss: 0.783986, BCE loss: 0.547213, SB loss: 0.757627
2023-10-30 08:42:46,727 Epoch: [170/484] Iter:[230/495], Time: 0.38, lr: [0.006765455482979367], Loss: 2.095003, Acc:0.800375, Semantic loss: 0.784702, BCE loss: 0.550123, SB loss: 0.760178
2023-10-30 08:42:50,413 Epoch: [170/484] Iter:[240/495], Time: 0.37, lr: [0.00676506315504435], Loss: 2.092971, Acc:0.801212, Semantic loss: 0.784038, BCE loss: 0.548973, SB loss: 0.759959
2023-10-30 08:42:54,030 Epoch: [170/484] Iter:[250/495], Time: 0.37, lr: [0.0067646708245812735], Loss: 2.087641, Acc:0.800455, Semantic loss: 0.781028, BCE loss: 0.548245, SB loss: 0.758368
2023-10-30 08:42:57,730 Epoch: [170/484] Iter:[260/495], Time: 0.37, lr: [0.0067642784915899635], Loss: 2.085675, Acc:0.801479, Semantic loss: 0.780352, BCE loss: 0.547636, SB loss: 0.757687
2023-10-30 08:43:01,502 Epoch: [170/484] Iter:[270/495], Time: 0.37, lr: [0.006763886156070236], Loss: 2.094124, Acc:0.800620, Semantic loss: 0.787301, BCE loss: 0.548018, SB loss: 0.758805
2023-10-30 08:43:05,260 Epoch: [170/484] Iter:[280/495], Time: 0.37, lr: [0.006763493818021914], Loss: 2.100607, Acc:0.800330, Semantic loss: 0.789617, BCE loss: 0.550479, SB loss: 0.760512
2023-10-30 08:43:08,986 Epoch: [170/484] Iter:[290/495], Time: 0.37, lr: [0.006763101477444818], Loss: 2.100539, Acc:0.801609, Semantic loss: 0.788792, BCE loss: 0.551358, SB loss: 0.760389
2023-10-30 08:43:12,661 Epoch: [170/484] Iter:[300/495], Time: 0.37, lr: [0.006762709134338768], Loss: 2.100672, Acc:0.801245, Semantic loss: 0.788594, BCE loss: 0.551561, SB loss: 0.760518
2023-10-30 08:43:16,406 Epoch: [170/484] Iter:[310/495], Time: 0.37, lr: [0.006762316788703584], Loss: 2.101091, Acc:0.801393, Semantic loss: 0.788829, BCE loss: 0.551442, SB loss: 0.760820
2023-10-30 08:43:20,042 Epoch: [170/484] Iter:[320/495], Time: 0.37, lr: [0.00676192444053909], Loss: 2.104010, Acc:0.801544, Semantic loss: 0.790124, BCE loss: 0.551954, SB loss: 0.761932
2023-10-30 08:43:23,715 Epoch: [170/484] Iter:[330/495], Time: 0.37, lr: [0.006761532089845104], Loss: 2.107759, Acc:0.801825, Semantic loss: 0.792688, BCE loss: 0.553562, SB loss: 0.761509
2023-10-30 08:43:27,386 Epoch: [170/484] Iter:[340/495], Time: 0.37, lr: [0.006761139736621446], Loss: 2.107221, Acc:0.801739, Semantic loss: 0.791953, BCE loss: 0.552695, SB loss: 0.762574
2023-10-30 08:43:31,151 Epoch: [170/484] Iter:[350/495], Time: 0.37, lr: [0.00676074738086794], Loss: 2.103243, Acc:0.800648, Semantic loss: 0.790067, BCE loss: 0.551857, SB loss: 0.761319
2023-10-30 08:43:34,778 Epoch: [170/484] Iter:[360/495], Time: 0.37, lr: [0.006760355022584402], Loss: 2.101628, Acc:0.800642, Semantic loss: 0.789197, BCE loss: 0.551309, SB loss: 0.761122
2023-10-30 08:43:38,514 Epoch: [170/484] Iter:[370/495], Time: 0.37, lr: [0.006759962661770655], Loss: 2.096058, Acc:0.800408, Semantic loss: 0.785683, BCE loss: 0.550499, SB loss: 0.759877
2023-10-30 08:43:42,258 Epoch: [170/484] Iter:[380/495], Time: 0.37, lr: [0.006759570298426521], Loss: 2.096791, Acc:0.800217, Semantic loss: 0.786422, BCE loss: 0.549762, SB loss: 0.760607
2023-10-30 08:43:45,942 Epoch: [170/484] Iter:[390/495], Time: 0.37, lr: [0.006759177932551817], Loss: 2.093725, Acc:0.799868, Semantic loss: 0.785702, BCE loss: 0.548509, SB loss: 0.759515
2023-10-30 08:43:49,535 Epoch: [170/484] Iter:[400/495], Time: 0.37, lr: [0.006758785564146365], Loss: 2.090926, Acc:0.799782, Semantic loss: 0.784698, BCE loss: 0.547063, SB loss: 0.759165
2023-10-30 08:43:53,193 Epoch: [170/484] Iter:[410/495], Time: 0.37, lr: [0.006758393193209986], Loss: 2.089489, Acc:0.799816, Semantic loss: 0.783645, BCE loss: 0.546279, SB loss: 0.759566
2023-10-30 08:43:56,853 Epoch: [170/484] Iter:[420/495], Time: 0.37, lr: [0.006758000819742501], Loss: 2.086404, Acc:0.799906, Semantic loss: 0.782693, BCE loss: 0.544824, SB loss: 0.758887
2023-10-30 08:44:00,494 Epoch: [170/484] Iter:[430/495], Time: 0.37, lr: [0.006757608443743729], Loss: 2.085910, Acc:0.799168, Semantic loss: 0.782789, BCE loss: 0.544987, SB loss: 0.758135
2023-10-30 08:44:04,255 Epoch: [170/484] Iter:[440/495], Time: 0.37, lr: [0.006757216065213491], Loss: 2.083472, Acc:0.798660, Semantic loss: 0.782515, BCE loss: 0.543343, SB loss: 0.757614
2023-10-30 08:44:07,927 Epoch: [170/484] Iter:[450/495], Time: 0.37, lr: [0.006756823684151606], Loss: 2.084351, Acc:0.798218, Semantic loss: 0.783034, BCE loss: 0.543836, SB loss: 0.757481
2023-10-30 08:44:11,582 Epoch: [170/484] Iter:[460/495], Time: 0.37, lr: [0.006756431300557896], Loss: 2.083650, Acc:0.798798, Semantic loss: 0.782360, BCE loss: 0.544315, SB loss: 0.756975
2023-10-30 08:44:15,246 Epoch: [170/484] Iter:[470/495], Time: 0.37, lr: [0.00675603891443218], Loss: 2.080915, Acc:0.798935, Semantic loss: 0.780474, BCE loss: 0.543045, SB loss: 0.757396
2023-10-30 08:44:18,907 Epoch: [170/484] Iter:[480/495], Time: 0.37, lr: [0.006755646525774281], Loss: 2.079749, Acc:0.799643, Semantic loss: 0.780166, BCE loss: 0.542468, SB loss: 0.757115
2023-10-30 08:44:22,443 Epoch: [170/484] Iter:[490/495], Time: 0.37, lr: [0.006755254134584015], Loss: 2.078386, Acc:0.799894, Semantic loss: 0.779511, BCE loss: 0.542694, SB loss: 0.756181
2023-10-30 08:47:19,369 0 [0.9273679  0.60009908 0.82459601 0.121829   0.1716387  0.39657393
 0.45817883 0.58963539 0.88424992 0.44911566 0.85272971 0.58853835
 0.02148704 0.7924825  0.002511   0.05351392 0.02601929 0.06860045
 0.59632258] 0.4434468037845456
2023-10-30 08:47:19,369 1 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542] 0.6721650229372822
2023-10-30 08:47:19,373 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:47:19,610 Loss: 2.071, MeanIU:  0.6722, Best_mIoU:  0.6984
2023-10-30 08:47:19,610 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542]
2023-10-30 08:47:21,964 Epoch: [171/484] Iter:[0/495], Time: 2.33, lr: [0.00675505793803919], Loss: 2.099155, Acc:0.879703, Semantic loss: 0.734310, BCE loss: 0.664099, SB loss: 0.700746
2023-10-30 08:47:25,823 Epoch: [171/484] Iter:[10/495], Time: 0.56, lr: [0.006754665543050041], Loss: 2.122658, Acc:0.832097, Semantic loss: 0.793768, BCE loss: 0.589152, SB loss: 0.739738
2023-10-30 08:47:29,334 Epoch: [171/484] Iter:[20/495], Time: 0.46, lr: [0.006754273145528077], Loss: 2.079158, Acc:0.813099, Semantic loss: 0.758331, BCE loss: 0.594196, SB loss: 0.726630
2023-10-30 08:47:32,921 Epoch: [171/484] Iter:[30/495], Time: 0.43, lr: [0.006753880745473118], Loss: 2.093409, Acc:0.803761, Semantic loss: 0.787473, BCE loss: 0.567966, SB loss: 0.737969
2023-10-30 08:47:36,526 Epoch: [171/484] Iter:[40/495], Time: 0.41, lr: [0.006753488342884987], Loss: 2.055407, Acc:0.809856, Semantic loss: 0.767721, BCE loss: 0.563409, SB loss: 0.724278
2023-10-30 08:47:40,086 Epoch: [171/484] Iter:[50/495], Time: 0.40, lr: [0.0067530959377635], Loss: 2.111419, Acc:0.810763, Semantic loss: 0.785142, BCE loss: 0.586112, SB loss: 0.740165
2023-10-30 08:47:43,675 Epoch: [171/484] Iter:[60/495], Time: 0.39, lr: [0.006752703530108482], Loss: 2.113315, Acc:0.805375, Semantic loss: 0.787249, BCE loss: 0.578909, SB loss: 0.747157
2023-10-30 08:47:47,297 Epoch: [171/484] Iter:[70/495], Time: 0.39, lr: [0.006752311119919748], Loss: 2.111057, Acc:0.806491, Semantic loss: 0.790682, BCE loss: 0.575390, SB loss: 0.744986
2023-10-30 08:47:50,895 Epoch: [171/484] Iter:[80/495], Time: 0.39, lr: [0.006751918707197121], Loss: 2.085178, Acc:0.801395, Semantic loss: 0.784465, BCE loss: 0.559475, SB loss: 0.741238
2023-10-30 08:47:54,363 Epoch: [171/484] Iter:[90/495], Time: 0.38, lr: [0.0067515262919404205], Loss: 2.080382, Acc:0.800794, Semantic loss: 0.783243, BCE loss: 0.556077, SB loss: 0.741062
2023-10-30 08:47:57,951 Epoch: [171/484] Iter:[100/495], Time: 0.38, lr: [0.006751133874149467], Loss: 2.075230, Acc:0.797009, Semantic loss: 0.781931, BCE loss: 0.552656, SB loss: 0.740643
2023-10-30 08:48:01,586 Epoch: [171/484] Iter:[110/495], Time: 0.38, lr: [0.0067507414538240775], Loss: 2.072562, Acc:0.798610, Semantic loss: 0.778594, BCE loss: 0.554045, SB loss: 0.739924
2023-10-30 08:48:05,198 Epoch: [171/484] Iter:[120/495], Time: 0.38, lr: [0.006750349030964074], Loss: 2.072256, Acc:0.797267, Semantic loss: 0.779650, BCE loss: 0.553290, SB loss: 0.739316
2023-10-30 08:48:08,771 Epoch: [171/484] Iter:[130/495], Time: 0.38, lr: [0.006749956605569278], Loss: 2.073234, Acc:0.798072, Semantic loss: 0.778419, BCE loss: 0.554325, SB loss: 0.740490
2023-10-30 08:48:12,413 Epoch: [171/484] Iter:[140/495], Time: 0.37, lr: [0.006749564177639508], Loss: 2.080012, Acc:0.795515, Semantic loss: 0.781269, BCE loss: 0.555021, SB loss: 0.743721
2023-10-30 08:48:16,029 Epoch: [171/484] Iter:[150/495], Time: 0.37, lr: [0.006749171747174584], Loss: 2.078923, Acc:0.795868, Semantic loss: 0.780857, BCE loss: 0.554407, SB loss: 0.743658
2023-10-30 08:48:19,716 Epoch: [171/484] Iter:[160/495], Time: 0.37, lr: [0.0067487793141743245], Loss: 2.078228, Acc:0.797386, Semantic loss: 0.779114, BCE loss: 0.554894, SB loss: 0.744220
2023-10-30 08:48:23,340 Epoch: [171/484] Iter:[170/495], Time: 0.37, lr: [0.006748386878638552], Loss: 2.074018, Acc:0.798337, Semantic loss: 0.776455, BCE loss: 0.556169, SB loss: 0.741394
2023-10-30 08:48:26,954 Epoch: [171/484] Iter:[180/495], Time: 0.37, lr: [0.006747994440567083], Loss: 2.065895, Acc:0.797090, Semantic loss: 0.773823, BCE loss: 0.551138, SB loss: 0.740934
2023-10-30 08:48:30,577 Epoch: [171/484] Iter:[190/495], Time: 0.37, lr: [0.006747601999959739], Loss: 2.074985, Acc:0.794838, Semantic loss: 0.782539, BCE loss: 0.547935, SB loss: 0.744512
2023-10-30 08:48:34,290 Epoch: [171/484] Iter:[200/495], Time: 0.37, lr: [0.00674720955681634], Loss: 2.071147, Acc:0.795704, Semantic loss: 0.781386, BCE loss: 0.545444, SB loss: 0.744316
2023-10-30 08:48:37,908 Epoch: [171/484] Iter:[210/495], Time: 0.37, lr: [0.006746817111136706], Loss: 2.077762, Acc:0.796138, Semantic loss: 0.784228, BCE loss: 0.546740, SB loss: 0.746794
2023-10-30 08:48:41,522 Epoch: [171/484] Iter:[220/495], Time: 0.37, lr: [0.006746424662920656], Loss: 2.076276, Acc:0.795819, Semantic loss: 0.782709, BCE loss: 0.548163, SB loss: 0.745404
2023-10-30 08:48:45,244 Epoch: [171/484] Iter:[230/495], Time: 0.37, lr: [0.00674603221216801], Loss: 2.074432, Acc:0.796287, Semantic loss: 0.781615, BCE loss: 0.548487, SB loss: 0.744329
2023-10-30 08:48:48,874 Epoch: [171/484] Iter:[240/495], Time: 0.37, lr: [0.006745639758878588], Loss: 2.082183, Acc:0.796187, Semantic loss: 0.784344, BCE loss: 0.549511, SB loss: 0.748328
2023-10-30 08:48:52,465 Epoch: [171/484] Iter:[250/495], Time: 0.37, lr: [0.006745247303052208], Loss: 2.085099, Acc:0.796272, Semantic loss: 0.786280, BCE loss: 0.548798, SB loss: 0.750021
2023-10-30 08:48:56,082 Epoch: [171/484] Iter:[260/495], Time: 0.37, lr: [0.00674485484468869], Loss: 2.083745, Acc:0.796763, Semantic loss: 0.785864, BCE loss: 0.548542, SB loss: 0.749339
2023-10-30 08:48:59,764 Epoch: [171/484] Iter:[270/495], Time: 0.37, lr: [0.006744462383787855], Loss: 2.082632, Acc:0.796306, Semantic loss: 0.786106, BCE loss: 0.546664, SB loss: 0.749862
2023-10-30 08:49:03,411 Epoch: [171/484] Iter:[280/495], Time: 0.37, lr: [0.0067440699203495215], Loss: 2.082888, Acc:0.797053, Semantic loss: 0.785326, BCE loss: 0.547603, SB loss: 0.749958
2023-10-30 08:49:07,036 Epoch: [171/484] Iter:[290/495], Time: 0.37, lr: [0.006743677454373509], Loss: 2.087495, Acc:0.797265, Semantic loss: 0.788105, BCE loss: 0.548666, SB loss: 0.750724
2023-10-30 08:49:10,722 Epoch: [171/484] Iter:[300/495], Time: 0.37, lr: [0.006743284985859638], Loss: 2.081192, Acc:0.797049, Semantic loss: 0.784036, BCE loss: 0.546622, SB loss: 0.750534
2023-10-30 08:49:14,372 Epoch: [171/484] Iter:[310/495], Time: 0.37, lr: [0.006742892514807727], Loss: 2.081821, Acc:0.797263, Semantic loss: 0.784447, BCE loss: 0.546674, SB loss: 0.750700
2023-10-30 08:49:17,947 Epoch: [171/484] Iter:[320/495], Time: 0.37, lr: [0.0067425000412175955], Loss: 2.076791, Acc:0.796735, Semantic loss: 0.781664, BCE loss: 0.545154, SB loss: 0.749973
2023-10-30 08:49:21,588 Epoch: [171/484] Iter:[330/495], Time: 0.37, lr: [0.006742107565089064], Loss: 2.078068, Acc:0.797614, Semantic loss: 0.781413, BCE loss: 0.545375, SB loss: 0.751280
2023-10-30 08:49:25,253 Epoch: [171/484] Iter:[340/495], Time: 0.37, lr: [0.00674171508642195], Loss: 2.081333, Acc:0.796534, Semantic loss: 0.784641, BCE loss: 0.543894, SB loss: 0.752798
2023-10-30 08:49:28,916 Epoch: [171/484] Iter:[350/495], Time: 0.37, lr: [0.006741322605216073], Loss: 2.073715, Acc:0.797896, Semantic loss: 0.779721, BCE loss: 0.542775, SB loss: 0.751220
2023-10-30 08:49:32,509 Epoch: [171/484] Iter:[360/495], Time: 0.37, lr: [0.006740930121471254], Loss: 2.072122, Acc:0.797821, Semantic loss: 0.779752, BCE loss: 0.541583, SB loss: 0.750787
2023-10-30 08:49:36,160 Epoch: [171/484] Iter:[370/495], Time: 0.37, lr: [0.00674053763518731], Loss: 2.066792, Acc:0.797521, Semantic loss: 0.778045, BCE loss: 0.539244, SB loss: 0.749502
2023-10-30 08:49:39,936 Epoch: [171/484] Iter:[380/495], Time: 0.37, lr: [0.006740145146364065], Loss: 2.066912, Acc:0.797234, Semantic loss: 0.779623, BCE loss: 0.537386, SB loss: 0.749903
2023-10-30 08:49:43,606 Epoch: [171/484] Iter:[390/495], Time: 0.37, lr: [0.0067397526550013334], Loss: 2.065635, Acc:0.797145, Semantic loss: 0.779088, BCE loss: 0.537067, SB loss: 0.749479
2023-10-30 08:49:47,256 Epoch: [171/484] Iter:[400/495], Time: 0.37, lr: [0.006739360161098936], Loss: 2.064641, Acc:0.795707, Semantic loss: 0.778705, BCE loss: 0.536419, SB loss: 0.749518
2023-10-30 08:49:50,936 Epoch: [171/484] Iter:[410/495], Time: 0.37, lr: [0.006738967664656694], Loss: 2.061294, Acc:0.795855, Semantic loss: 0.777701, BCE loss: 0.535116, SB loss: 0.748478
2023-10-30 08:49:54,644 Epoch: [171/484] Iter:[420/495], Time: 0.37, lr: [0.006738575165674421], Loss: 2.061957, Acc:0.795584, Semantic loss: 0.777835, BCE loss: 0.535693, SB loss: 0.748429
2023-10-30 08:49:58,362 Epoch: [171/484] Iter:[430/495], Time: 0.37, lr: [0.0067381826641519415], Loss: 2.063991, Acc:0.796435, Semantic loss: 0.777474, BCE loss: 0.537792, SB loss: 0.748725
2023-10-30 08:50:02,099 Epoch: [171/484] Iter:[440/495], Time: 0.37, lr: [0.0067377901600890735], Loss: 2.062016, Acc:0.795717, Semantic loss: 0.775982, BCE loss: 0.537071, SB loss: 0.748962
2023-10-30 08:50:05,716 Epoch: [171/484] Iter:[450/495], Time: 0.37, lr: [0.006737397653485636], Loss: 2.062517, Acc:0.796698, Semantic loss: 0.775952, BCE loss: 0.537977, SB loss: 0.748588
2023-10-30 08:50:09,340 Epoch: [171/484] Iter:[460/495], Time: 0.37, lr: [0.006737005144341448], Loss: 2.065827, Acc:0.796174, Semantic loss: 0.777106, BCE loss: 0.539484, SB loss: 0.749238
2023-10-30 08:50:13,022 Epoch: [171/484] Iter:[470/495], Time: 0.37, lr: [0.006736612632656328], Loss: 2.066214, Acc:0.796428, Semantic loss: 0.777151, BCE loss: 0.539114, SB loss: 0.749950
2023-10-30 08:50:16,785 Epoch: [171/484] Iter:[480/495], Time: 0.37, lr: [0.006736220118430095], Loss: 2.070373, Acc:0.796403, Semantic loss: 0.778267, BCE loss: 0.541297, SB loss: 0.750809
2023-10-30 08:50:20,293 Epoch: [171/484] Iter:[490/495], Time: 0.37, lr: [0.006735827601662569], Loss: 2.070202, Acc:0.796304, Semantic loss: 0.777748, BCE loss: 0.541578, SB loss: 0.750876
2023-10-30 08:50:21,683 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:50:21,925 Loss: 2.071, MeanIU:  0.6722, Best_mIoU:  0.6984
2023-10-30 08:50:21,925 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542]
2023-10-30 08:50:24,088 Epoch: [172/484] Iter:[0/495], Time: 2.13, lr: [0.006735631342325764], Loss: 2.256021, Acc:0.884290, Semantic loss: 0.717852, BCE loss: 0.772597, SB loss: 0.765572
2023-10-30 08:50:28,255 Epoch: [172/484] Iter:[10/495], Time: 0.57, lr: [0.006735238821745958], Loss: 2.215401, Acc:0.750658, Semantic loss: 0.842694, BCE loss: 0.588852, SB loss: 0.783855
2023-10-30 08:50:32,066 Epoch: [172/484] Iter:[20/495], Time: 0.48, lr: [0.006734846298624406], Loss: 2.123705, Acc:0.775194, Semantic loss: 0.804725, BCE loss: 0.567171, SB loss: 0.751810
2023-10-30 08:50:35,734 Epoch: [172/484] Iter:[30/495], Time: 0.44, lr: [0.006734453772960926], Loss: 2.140752, Acc:0.795891, Semantic loss: 0.805856, BCE loss: 0.574905, SB loss: 0.759991
2023-10-30 08:50:39,402 Epoch: [172/484] Iter:[40/495], Time: 0.43, lr: [0.006734061244755339], Loss: 2.107845, Acc:0.803277, Semantic loss: 0.791335, BCE loss: 0.566222, SB loss: 0.750289
2023-10-30 08:50:43,068 Epoch: [172/484] Iter:[50/495], Time: 0.41, lr: [0.006733668714007462], Loss: 2.126477, Acc:0.804405, Semantic loss: 0.808507, BCE loss: 0.569038, SB loss: 0.748932
2023-10-30 08:50:46,885 Epoch: [172/484] Iter:[60/495], Time: 0.41, lr: [0.006733276180717115], Loss: 2.137919, Acc:0.804565, Semantic loss: 0.809806, BCE loss: 0.573332, SB loss: 0.754782
2023-10-30 08:50:50,510 Epoch: [172/484] Iter:[70/495], Time: 0.40, lr: [0.006732883644884116], Loss: 2.135506, Acc:0.799774, Semantic loss: 0.801131, BCE loss: 0.575843, SB loss: 0.758531
2023-10-30 08:50:54,133 Epoch: [172/484] Iter:[80/495], Time: 0.40, lr: [0.006732491106508284], Loss: 2.134651, Acc:0.798952, Semantic loss: 0.802646, BCE loss: 0.572993, SB loss: 0.759013
2023-10-30 08:50:57,792 Epoch: [172/484] Iter:[90/495], Time: 0.39, lr: [0.006732098565589437], Loss: 2.132532, Acc:0.800236, Semantic loss: 0.803335, BCE loss: 0.571382, SB loss: 0.757816
2023-10-30 08:51:01,407 Epoch: [172/484] Iter:[100/495], Time: 0.39, lr: [0.006731706022127396], Loss: 2.115000, Acc:0.798983, Semantic loss: 0.794321, BCE loss: 0.565766, SB loss: 0.754913
2023-10-30 08:51:05,080 Epoch: [172/484] Iter:[110/495], Time: 0.39, lr: [0.006731313476121978], Loss: 2.110289, Acc:0.800753, Semantic loss: 0.791217, BCE loss: 0.566562, SB loss: 0.752511
2023-10-30 08:51:08,713 Epoch: [172/484] Iter:[120/495], Time: 0.39, lr: [0.006730920927573002], Loss: 2.098651, Acc:0.797045, Semantic loss: 0.786396, BCE loss: 0.561115, SB loss: 0.751140
2023-10-30 08:51:12,384 Epoch: [172/484] Iter:[130/495], Time: 0.38, lr: [0.006730528376480288], Loss: 2.095265, Acc:0.798328, Semantic loss: 0.785597, BCE loss: 0.557418, SB loss: 0.752250
2023-10-30 08:51:16,230 Epoch: [172/484] Iter:[140/495], Time: 0.38, lr: [0.006730135822843653], Loss: 2.086137, Acc:0.797784, Semantic loss: 0.783760, BCE loss: 0.551414, SB loss: 0.750963
2023-10-30 08:51:19,848 Epoch: [172/484] Iter:[150/495], Time: 0.38, lr: [0.006729743266662916], Loss: 2.076758, Acc:0.796978, Semantic loss: 0.777073, BCE loss: 0.550843, SB loss: 0.748842
2023-10-30 08:51:23,536 Epoch: [172/484] Iter:[160/495], Time: 0.38, lr: [0.006729350707937897], Loss: 2.080707, Acc:0.795935, Semantic loss: 0.777719, BCE loss: 0.551611, SB loss: 0.751376
2023-10-30 08:51:27,230 Epoch: [172/484] Iter:[170/495], Time: 0.38, lr: [0.006728958146668411], Loss: 2.082448, Acc:0.797533, Semantic loss: 0.782077, BCE loss: 0.549717, SB loss: 0.750654
2023-10-30 08:51:30,913 Epoch: [172/484] Iter:[180/495], Time: 0.38, lr: [0.00672856558285428], Loss: 2.083845, Acc:0.795850, Semantic loss: 0.781877, BCE loss: 0.551310, SB loss: 0.750657
2023-10-30 08:51:34,676 Epoch: [172/484] Iter:[190/495], Time: 0.38, lr: [0.006728173016495321], Loss: 2.077445, Acc:0.794890, Semantic loss: 0.779428, BCE loss: 0.546847, SB loss: 0.751170
2023-10-30 08:51:38,296 Epoch: [172/484] Iter:[200/495], Time: 0.38, lr: [0.0067277804475913555], Loss: 2.076175, Acc:0.793789, Semantic loss: 0.779927, BCE loss: 0.544147, SB loss: 0.752101
2023-10-30 08:51:41,988 Epoch: [172/484] Iter:[210/495], Time: 0.38, lr: [0.006727387876142197], Loss: 2.077937, Acc:0.795219, Semantic loss: 0.780746, BCE loss: 0.544850, SB loss: 0.752342
2023-10-30 08:51:45,744 Epoch: [172/484] Iter:[220/495], Time: 0.38, lr: [0.006726995302147668], Loss: 2.074414, Acc:0.794374, Semantic loss: 0.779727, BCE loss: 0.542335, SB loss: 0.752352
2023-10-30 08:51:49,489 Epoch: [172/484] Iter:[230/495], Time: 0.38, lr: [0.006726602725607584], Loss: 2.076838, Acc:0.793876, Semantic loss: 0.780725, BCE loss: 0.544236, SB loss: 0.751877
2023-10-30 08:51:53,162 Epoch: [172/484] Iter:[240/495], Time: 0.38, lr: [0.006726210146521766], Loss: 2.073526, Acc:0.792994, Semantic loss: 0.779567, BCE loss: 0.542304, SB loss: 0.751655
2023-10-30 08:51:56,850 Epoch: [172/484] Iter:[250/495], Time: 0.38, lr: [0.006725817564890031], Loss: 2.073944, Acc:0.793580, Semantic loss: 0.778647, BCE loss: 0.544567, SB loss: 0.750730
2023-10-30 08:52:00,577 Epoch: [172/484] Iter:[260/495], Time: 0.38, lr: [0.006725424980712197], Loss: 2.072723, Acc:0.794336, Semantic loss: 0.778590, BCE loss: 0.543512, SB loss: 0.750621
2023-10-30 08:52:04,159 Epoch: [172/484] Iter:[270/495], Time: 0.38, lr: [0.006725032393988084], Loss: 2.074336, Acc:0.792981, Semantic loss: 0.780507, BCE loss: 0.543698, SB loss: 0.750131
2023-10-30 08:52:07,989 Epoch: [172/484] Iter:[280/495], Time: 0.38, lr: [0.00672463980471751], Loss: 2.069325, Acc:0.792512, Semantic loss: 0.778756, BCE loss: 0.542016, SB loss: 0.748553
2023-10-30 08:52:11,667 Epoch: [172/484] Iter:[290/495], Time: 0.38, lr: [0.00672424721290029], Loss: 2.069344, Acc:0.792826, Semantic loss: 0.779043, BCE loss: 0.541519, SB loss: 0.748782
2023-10-30 08:52:15,262 Epoch: [172/484] Iter:[300/495], Time: 0.38, lr: [0.006723854618536247], Loss: 2.071054, Acc:0.793074, Semantic loss: 0.780087, BCE loss: 0.540728, SB loss: 0.750239
2023-10-30 08:52:19,000 Epoch: [172/484] Iter:[310/495], Time: 0.38, lr: [0.006723462021625198], Loss: 2.068639, Acc:0.794174, Semantic loss: 0.777886, BCE loss: 0.540743, SB loss: 0.750010
2023-10-30 08:52:22,634 Epoch: [172/484] Iter:[320/495], Time: 0.38, lr: [0.0067230694221669576], Loss: 2.070147, Acc:0.794003, Semantic loss: 0.779123, BCE loss: 0.541073, SB loss: 0.749951
2023-10-30 08:52:26,388 Epoch: [172/484] Iter:[330/495], Time: 0.38, lr: [0.006722676820161349], Loss: 2.070341, Acc:0.794034, Semantic loss: 0.780057, BCE loss: 0.540308, SB loss: 0.749976
2023-10-30 08:52:30,092 Epoch: [172/484] Iter:[340/495], Time: 0.38, lr: [0.006722284215608185], Loss: 2.077516, Acc:0.794147, Semantic loss: 0.783704, BCE loss: 0.541829, SB loss: 0.751983
2023-10-30 08:52:33,768 Epoch: [172/484] Iter:[350/495], Time: 0.38, lr: [0.00672189160850729], Loss: 2.075705, Acc:0.794668, Semantic loss: 0.783133, BCE loss: 0.541111, SB loss: 0.751461
2023-10-30 08:52:37,533 Epoch: [172/484] Iter:[360/495], Time: 0.38, lr: [0.006721498998858479], Loss: 2.074897, Acc:0.795161, Semantic loss: 0.782216, BCE loss: 0.541060, SB loss: 0.751621
2023-10-30 08:52:41,188 Epoch: [172/484] Iter:[370/495], Time: 0.38, lr: [0.006721106386661568], Loss: 2.073598, Acc:0.795021, Semantic loss: 0.782333, BCE loss: 0.539954, SB loss: 0.751312
2023-10-30 08:52:44,860 Epoch: [172/484] Iter:[380/495], Time: 0.38, lr: [0.0067207137719163795], Loss: 2.078320, Acc:0.793927, Semantic loss: 0.784505, BCE loss: 0.541414, SB loss: 0.752401
2023-10-30 08:52:48,572 Epoch: [172/484] Iter:[390/495], Time: 0.37, lr: [0.006720321154622728], Loss: 2.083671, Acc:0.794480, Semantic loss: 0.786256, BCE loss: 0.543656, SB loss: 0.753759
2023-10-30 08:52:52,238 Epoch: [172/484] Iter:[400/495], Time: 0.37, lr: [0.006719928534780433], Loss: 2.081944, Acc:0.792644, Semantic loss: 0.786169, BCE loss: 0.542155, SB loss: 0.753620
2023-10-30 08:52:55,982 Epoch: [172/484] Iter:[410/495], Time: 0.37, lr: [0.006719535912389312], Loss: 2.086212, Acc:0.792742, Semantic loss: 0.786897, BCE loss: 0.544747, SB loss: 0.754568
2023-10-30 08:52:59,807 Epoch: [172/484] Iter:[420/495], Time: 0.37, lr: [0.006719143287449183], Loss: 2.081955, Acc:0.793845, Semantic loss: 0.783724, BCE loss: 0.545493, SB loss: 0.752738
2023-10-30 08:53:03,501 Epoch: [172/484] Iter:[430/495], Time: 0.37, lr: [0.006718750659959864], Loss: 2.086510, Acc:0.794269, Semantic loss: 0.787627, BCE loss: 0.544500, SB loss: 0.754383
2023-10-30 08:53:07,260 Epoch: [172/484] Iter:[440/495], Time: 0.37, lr: [0.006718358029921175], Loss: 2.090906, Acc:0.793688, Semantic loss: 0.791360, BCE loss: 0.544061, SB loss: 0.755485
2023-10-30 08:53:10,986 Epoch: [172/484] Iter:[450/495], Time: 0.37, lr: [0.00671796539733293], Loss: 2.096186, Acc:0.793346, Semantic loss: 0.794721, BCE loss: 0.544380, SB loss: 0.757085
2023-10-30 08:53:14,729 Epoch: [172/484] Iter:[460/495], Time: 0.37, lr: [0.00671757276219495], Loss: 2.099678, Acc:0.792986, Semantic loss: 0.797167, BCE loss: 0.544109, SB loss: 0.758402
2023-10-30 08:53:18,392 Epoch: [172/484] Iter:[470/495], Time: 0.37, lr: [0.006717180124507052], Loss: 2.103064, Acc:0.792207, Semantic loss: 0.800148, BCE loss: 0.543862, SB loss: 0.759055
2023-10-30 08:53:22,102 Epoch: [172/484] Iter:[480/495], Time: 0.37, lr: [0.006716787484269052], Loss: 2.098701, Acc:0.791760, Semantic loss: 0.797557, BCE loss: 0.542911, SB loss: 0.758233
2023-10-30 08:53:25,634 Epoch: [172/484] Iter:[490/495], Time: 0.37, lr: [0.006716394841480771], Loss: 2.099201, Acc:0.792175, Semantic loss: 0.796312, BCE loss: 0.544800, SB loss: 0.758088
2023-10-30 08:53:27,030 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:53:27,267 Loss: 2.071, MeanIU:  0.6722, Best_mIoU:  0.6984
2023-10-30 08:53:27,268 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542]
2023-10-30 08:53:29,359 Epoch: [173/484] Iter:[0/495], Time: 2.06, lr: [0.006716198519130217], Loss: 1.897775, Acc:0.823498, Semantic loss: 0.688889, BCE loss: 0.558632, SB loss: 0.650254
2023-10-30 08:53:33,338 Epoch: [173/484] Iter:[10/495], Time: 0.55, lr: [0.006715805872516169], Loss: 2.031822, Acc:0.820470, Semantic loss: 0.744537, BCE loss: 0.551552, SB loss: 0.735732
2023-10-30 08:53:37,135 Epoch: [173/484] Iter:[20/495], Time: 0.47, lr: [0.006715413223351383], Loss: 2.022054, Acc:0.815697, Semantic loss: 0.768227, BCE loss: 0.522851, SB loss: 0.730975
2023-10-30 08:53:40,822 Epoch: [173/484] Iter:[30/495], Time: 0.44, lr: [0.0067150205716356775], Loss: 2.048549, Acc:0.812078, Semantic loss: 0.781379, BCE loss: 0.526638, SB loss: 0.740532
2023-10-30 08:53:44,533 Epoch: [173/484] Iter:[40/495], Time: 0.42, lr: [0.006714627917368868], Loss: 2.059136, Acc:0.815783, Semantic loss: 0.772939, BCE loss: 0.542752, SB loss: 0.743445
2023-10-30 08:53:48,161 Epoch: [173/484] Iter:[50/495], Time: 0.41, lr: [0.006714235260550775], Loss: 2.068098, Acc:0.810468, Semantic loss: 0.779214, BCE loss: 0.538751, SB loss: 0.750133
2023-10-30 08:53:51,846 Epoch: [173/484] Iter:[60/495], Time: 0.40, lr: [0.0067138426011812136], Loss: 2.060769, Acc:0.808644, Semantic loss: 0.780242, BCE loss: 0.533969, SB loss: 0.746558
2023-10-30 08:53:55,492 Epoch: [173/484] Iter:[70/495], Time: 0.40, lr: [0.006713449939260001], Loss: 2.052264, Acc:0.808082, Semantic loss: 0.773836, BCE loss: 0.535180, SB loss: 0.743249
2023-10-30 08:53:59,165 Epoch: [173/484] Iter:[80/495], Time: 0.39, lr: [0.006713057274786957], Loss: 2.056467, Acc:0.807365, Semantic loss: 0.776604, BCE loss: 0.534539, SB loss: 0.745324
2023-10-30 08:54:02,943 Epoch: [173/484] Iter:[90/495], Time: 0.39, lr: [0.006712664607761899], Loss: 2.045499, Acc:0.803884, Semantic loss: 0.771448, BCE loss: 0.530931, SB loss: 0.743120
2023-10-30 08:54:06,613 Epoch: [173/484] Iter:[100/495], Time: 0.39, lr: [0.006712271938184643], Loss: 2.051141, Acc:0.802281, Semantic loss: 0.769805, BCE loss: 0.537451, SB loss: 0.743885
2023-10-30 08:54:10,401 Epoch: [173/484] Iter:[110/495], Time: 0.39, lr: [0.0067118792660550075], Loss: 2.050456, Acc:0.801061, Semantic loss: 0.768196, BCE loss: 0.536963, SB loss: 0.745297
2023-10-30 08:54:14,155 Epoch: [173/484] Iter:[120/495], Time: 0.39, lr: [0.006711486591372811], Loss: 2.044938, Acc:0.802264, Semantic loss: 0.765031, BCE loss: 0.536255, SB loss: 0.743651
2023-10-30 08:54:17,814 Epoch: [173/484] Iter:[130/495], Time: 0.39, lr: [0.006711093914137868], Loss: 2.050619, Acc:0.801705, Semantic loss: 0.773137, BCE loss: 0.531693, SB loss: 0.745789
2023-10-30 08:54:21,584 Epoch: [173/484] Iter:[140/495], Time: 0.38, lr: [0.006710701234349998], Loss: 2.043969, Acc:0.801984, Semantic loss: 0.771213, BCE loss: 0.528792, SB loss: 0.743964
2023-10-30 08:54:25,358 Epoch: [173/484] Iter:[150/495], Time: 0.38, lr: [0.006710308552009019], Loss: 2.044404, Acc:0.802877, Semantic loss: 0.768462, BCE loss: 0.533419, SB loss: 0.742523
2023-10-30 08:54:29,200 Epoch: [173/484] Iter:[160/495], Time: 0.38, lr: [0.006709915867114745], Loss: 2.046810, Acc:0.804624, Semantic loss: 0.768915, BCE loss: 0.535716, SB loss: 0.742179
2023-10-30 08:54:32,862 Epoch: [173/484] Iter:[170/495], Time: 0.38, lr: [0.0067095231796669985], Loss: 2.041932, Acc:0.802126, Semantic loss: 0.768588, BCE loss: 0.532077, SB loss: 0.741266
2023-10-30 08:54:36,564 Epoch: [173/484] Iter:[180/495], Time: 0.38, lr: [0.006709130489665594], Loss: 2.038223, Acc:0.803495, Semantic loss: 0.766472, BCE loss: 0.531534, SB loss: 0.740218
2023-10-30 08:54:40,262 Epoch: [173/484] Iter:[190/495], Time: 0.38, lr: [0.006708737797110349], Loss: 2.042170, Acc:0.803225, Semantic loss: 0.769226, BCE loss: 0.531815, SB loss: 0.741129
2023-10-30 08:54:43,905 Epoch: [173/484] Iter:[200/495], Time: 0.38, lr: [0.006708345102001081], Loss: 2.042930, Acc:0.803733, Semantic loss: 0.768346, BCE loss: 0.534150, SB loss: 0.740435
2023-10-30 08:54:47,663 Epoch: [173/484] Iter:[210/495], Time: 0.38, lr: [0.0067079524043376065], Loss: 2.041027, Acc:0.801176, Semantic loss: 0.767616, BCE loss: 0.533431, SB loss: 0.739979
2023-10-30 08:54:51,409 Epoch: [173/484] Iter:[220/495], Time: 0.38, lr: [0.006707559704119743], Loss: 2.040298, Acc:0.802036, Semantic loss: 0.766391, BCE loss: 0.533713, SB loss: 0.740194
2023-10-30 08:54:55,125 Epoch: [173/484] Iter:[230/495], Time: 0.38, lr: [0.0067071670013473085], Loss: 2.042906, Acc:0.801858, Semantic loss: 0.769214, BCE loss: 0.534165, SB loss: 0.739528
2023-10-30 08:54:58,911 Epoch: [173/484] Iter:[240/495], Time: 0.38, lr: [0.0067067742960201186], Loss: 2.049396, Acc:0.800653, Semantic loss: 0.770291, BCE loss: 0.538764, SB loss: 0.740341
2023-10-30 08:55:02,581 Epoch: [173/484] Iter:[250/495], Time: 0.38, lr: [0.006706381588137993], Loss: 2.043550, Acc:0.800352, Semantic loss: 0.768039, BCE loss: 0.535841, SB loss: 0.739670
2023-10-30 08:55:06,227 Epoch: [173/484] Iter:[260/495], Time: 0.38, lr: [0.0067059888777007476], Loss: 2.041130, Acc:0.799632, Semantic loss: 0.767072, BCE loss: 0.534601, SB loss: 0.739457
2023-10-30 08:55:09,928 Epoch: [173/484] Iter:[270/495], Time: 0.38, lr: [0.006705596164708199], Loss: 2.043339, Acc:0.800692, Semantic loss: 0.767440, BCE loss: 0.535578, SB loss: 0.740321
2023-10-30 08:55:13,527 Epoch: [173/484] Iter:[280/495], Time: 0.38, lr: [0.006705203449160165], Loss: 2.046975, Acc:0.801012, Semantic loss: 0.769365, BCE loss: 0.535650, SB loss: 0.741959
2023-10-30 08:55:17,202 Epoch: [173/484] Iter:[290/495], Time: 0.38, lr: [0.006704810731056462], Loss: 2.043351, Acc:0.800409, Semantic loss: 0.766971, BCE loss: 0.535003, SB loss: 0.741378
2023-10-30 08:55:20,902 Epoch: [173/484] Iter:[300/495], Time: 0.38, lr: [0.006704418010396907], Loss: 2.044939, Acc:0.800924, Semantic loss: 0.767640, BCE loss: 0.536150, SB loss: 0.741149
2023-10-30 08:55:24,661 Epoch: [173/484] Iter:[310/495], Time: 0.38, lr: [0.006704025287181317], Loss: 2.052692, Acc:0.801240, Semantic loss: 0.770787, BCE loss: 0.539048, SB loss: 0.742857
2023-10-30 08:55:28,555 Epoch: [173/484] Iter:[320/495], Time: 0.38, lr: [0.006703632561409509], Loss: 2.056382, Acc:0.800733, Semantic loss: 0.772197, BCE loss: 0.540756, SB loss: 0.743428
2023-10-30 08:55:32,222 Epoch: [173/484] Iter:[330/495], Time: 0.38, lr: [0.006703239833081302], Loss: 2.056519, Acc:0.801125, Semantic loss: 0.770899, BCE loss: 0.542292, SB loss: 0.743327
2023-10-30 08:55:35,967 Epoch: [173/484] Iter:[340/495], Time: 0.38, lr: [0.006702847102196511], Loss: 2.054314, Acc:0.801186, Semantic loss: 0.769583, BCE loss: 0.541539, SB loss: 0.743191
2023-10-30 08:55:39,790 Epoch: [173/484] Iter:[350/495], Time: 0.38, lr: [0.006702454368754954], Loss: 2.052149, Acc:0.801402, Semantic loss: 0.768151, BCE loss: 0.541351, SB loss: 0.742647
2023-10-30 08:55:43,497 Epoch: [173/484] Iter:[360/495], Time: 0.38, lr: [0.006702061632756446], Loss: 2.055942, Acc:0.801827, Semantic loss: 0.769809, BCE loss: 0.542619, SB loss: 0.743514
2023-10-30 08:55:47,201 Epoch: [173/484] Iter:[370/495], Time: 0.38, lr: [0.006701668894200805], Loss: 2.055851, Acc:0.801981, Semantic loss: 0.770047, BCE loss: 0.541868, SB loss: 0.743937
2023-10-30 08:55:50,892 Epoch: [173/484] Iter:[380/495], Time: 0.38, lr: [0.006701276153087846], Loss: 2.056298, Acc:0.801786, Semantic loss: 0.771149, BCE loss: 0.541602, SB loss: 0.743547
2023-10-30 08:55:54,575 Epoch: [173/484] Iter:[390/495], Time: 0.38, lr: [0.00670088340941739], Loss: 2.055600, Acc:0.801431, Semantic loss: 0.771042, BCE loss: 0.540902, SB loss: 0.743656
2023-10-30 08:55:58,277 Epoch: [173/484] Iter:[400/495], Time: 0.38, lr: [0.00670049066318925], Loss: 2.058940, Acc:0.801204, Semantic loss: 0.773932, BCE loss: 0.540010, SB loss: 0.744998
2023-10-30 08:56:01,946 Epoch: [173/484] Iter:[410/495], Time: 0.38, lr: [0.0067000979144032444], Loss: 2.060682, Acc:0.801600, Semantic loss: 0.774149, BCE loss: 0.540792, SB loss: 0.745741
2023-10-30 08:56:05,690 Epoch: [173/484] Iter:[420/495], Time: 0.38, lr: [0.006699705163059191], Loss: 2.056852, Acc:0.801653, Semantic loss: 0.771951, BCE loss: 0.540117, SB loss: 0.744784
2023-10-30 08:56:09,322 Epoch: [173/484] Iter:[430/495], Time: 0.38, lr: [0.006699312409156906], Loss: 2.055220, Acc:0.802457, Semantic loss: 0.770734, BCE loss: 0.539442, SB loss: 0.745044
2023-10-30 08:56:13,040 Epoch: [173/484] Iter:[440/495], Time: 0.38, lr: [0.006698919652696204], Loss: 2.054558, Acc:0.803055, Semantic loss: 0.769478, BCE loss: 0.540008, SB loss: 0.745072
2023-10-30 08:56:16,788 Epoch: [173/484] Iter:[450/495], Time: 0.38, lr: [0.006698526893676903], Loss: 2.056950, Acc:0.802829, Semantic loss: 0.771181, BCE loss: 0.540083, SB loss: 0.745685
2023-10-30 08:56:20,364 Epoch: [173/484] Iter:[460/495], Time: 0.38, lr: [0.006698134132098818], Loss: 2.057266, Acc:0.802449, Semantic loss: 0.771848, BCE loss: 0.539181, SB loss: 0.746237
2023-10-30 08:56:23,963 Epoch: [173/484] Iter:[470/495], Time: 0.38, lr: [0.00669774136796177], Loss: 2.058129, Acc:0.801296, Semantic loss: 0.773332, BCE loss: 0.538051, SB loss: 0.746746
2023-10-30 08:56:27,552 Epoch: [173/484] Iter:[480/495], Time: 0.37, lr: [0.006697348601265569], Loss: 2.058192, Acc:0.801469, Semantic loss: 0.773796, BCE loss: 0.537791, SB loss: 0.746605
2023-10-30 08:56:31,017 Epoch: [173/484] Iter:[490/495], Time: 0.37, lr: [0.006696955832010039], Loss: 2.056179, Acc:0.800721, Semantic loss: 0.773130, BCE loss: 0.536491, SB loss: 0.746558
2023-10-30 08:56:32,427 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:56:32,664 Loss: 2.071, MeanIU:  0.6722, Best_mIoU:  0.6984
2023-10-30 08:56:32,664 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542]
2023-10-30 08:56:34,672 Epoch: [174/484] Iter:[0/495], Time: 1.97, lr: [0.006696759446422467], Loss: 1.826048, Acc:0.852047, Semantic loss: 0.659426, BCE loss: 0.501185, SB loss: 0.665438
2023-10-30 08:56:38,758 Epoch: [174/484] Iter:[10/495], Time: 0.55, lr: [0.006696366673327593], Loss: 2.165569, Acc:0.796908, Semantic loss: 0.803657, BCE loss: 0.595983, SB loss: 0.765929
2023-10-30 08:56:42,445 Epoch: [174/484] Iter:[20/495], Time: 0.46, lr: [0.006695973897672928], Loss: 2.127703, Acc:0.800236, Semantic loss: 0.798658, BCE loss: 0.575411, SB loss: 0.753634
2023-10-30 08:56:46,145 Epoch: [174/484] Iter:[30/495], Time: 0.43, lr: [0.006695581119458289], Loss: 2.123019, Acc:0.805059, Semantic loss: 0.801536, BCE loss: 0.572006, SB loss: 0.749478
2023-10-30 08:56:49,890 Epoch: [174/484] Iter:[40/495], Time: 0.42, lr: [0.006695188338683489], Loss: 2.090838, Acc:0.800878, Semantic loss: 0.794212, BCE loss: 0.556200, SB loss: 0.740427
2023-10-30 08:56:53,520 Epoch: [174/484] Iter:[50/495], Time: 0.41, lr: [0.006694795555348349], Loss: 2.095098, Acc:0.800056, Semantic loss: 0.793993, BCE loss: 0.556264, SB loss: 0.744841
2023-10-30 08:56:57,215 Epoch: [174/484] Iter:[60/495], Time: 0.40, lr: [0.0066944027694526825], Loss: 2.144449, Acc:0.802210, Semantic loss: 0.833288, BCE loss: 0.561525, SB loss: 0.749637
2023-10-30 08:57:00,885 Epoch: [174/484] Iter:[70/495], Time: 0.40, lr: [0.0066940099809963075], Loss: 2.154539, Acc:0.797222, Semantic loss: 0.833011, BCE loss: 0.563149, SB loss: 0.758380
2023-10-30 08:57:04,529 Epoch: [174/484] Iter:[80/495], Time: 0.39, lr: [0.00669361718997904], Loss: 2.162943, Acc:0.799401, Semantic loss: 0.834260, BCE loss: 0.566879, SB loss: 0.761804
2023-10-30 08:57:08,236 Epoch: [174/484] Iter:[90/495], Time: 0.39, lr: [0.006693224396400696], Loss: 2.159045, Acc:0.797286, Semantic loss: 0.833215, BCE loss: 0.565532, SB loss: 0.760298
2023-10-30 08:57:11,880 Epoch: [174/484] Iter:[100/495], Time: 0.39, lr: [0.006692831600261092], Loss: 2.166303, Acc:0.798922, Semantic loss: 0.831206, BCE loss: 0.573585, SB loss: 0.761513
2023-10-30 08:57:15,572 Epoch: [174/484] Iter:[110/495], Time: 0.39, lr: [0.006692438801560044], Loss: 2.149575, Acc:0.796367, Semantic loss: 0.823416, BCE loss: 0.565160, SB loss: 0.760999
2023-10-30 08:57:19,178 Epoch: [174/484] Iter:[120/495], Time: 0.38, lr: [0.006692046000297367], Loss: 2.145490, Acc:0.797857, Semantic loss: 0.821778, BCE loss: 0.564896, SB loss: 0.758815
2023-10-30 08:57:22,877 Epoch: [174/484] Iter:[130/495], Time: 0.38, lr: [0.00669165319647288], Loss: 2.141019, Acc:0.794615, Semantic loss: 0.821568, BCE loss: 0.560584, SB loss: 0.758867
2023-10-30 08:57:26,633 Epoch: [174/484] Iter:[140/495], Time: 0.38, lr: [0.0066912603900863964], Loss: 2.138916, Acc:0.794988, Semantic loss: 0.820650, BCE loss: 0.558750, SB loss: 0.759516
2023-10-30 08:57:30,324 Epoch: [174/484] Iter:[150/495], Time: 0.38, lr: [0.0066908675811377365], Loss: 2.126193, Acc:0.794700, Semantic loss: 0.813187, BCE loss: 0.554895, SB loss: 0.758111
2023-10-30 08:57:33,914 Epoch: [174/484] Iter:[160/495], Time: 0.38, lr: [0.006690474769626711], Loss: 2.118543, Acc:0.795315, Semantic loss: 0.808715, BCE loss: 0.554679, SB loss: 0.755148
2023-10-30 08:57:37,522 Epoch: [174/484] Iter:[170/495], Time: 0.38, lr: [0.00669008195555314], Loss: 2.118720, Acc:0.796073, Semantic loss: 0.810110, BCE loss: 0.553183, SB loss: 0.755426
2023-10-30 08:57:41,187 Epoch: [174/484] Iter:[180/495], Time: 0.38, lr: [0.006689689138916839], Loss: 2.118781, Acc:0.794882, Semantic loss: 0.811903, BCE loss: 0.550438, SB loss: 0.756439
2023-10-30 08:57:44,939 Epoch: [174/484] Iter:[190/495], Time: 0.38, lr: [0.006689296319717623], Loss: 2.109716, Acc:0.794358, Semantic loss: 0.807091, BCE loss: 0.548076, SB loss: 0.754549
2023-10-30 08:57:48,598 Epoch: [174/484] Iter:[200/495], Time: 0.38, lr: [0.006688903497955307], Loss: 2.103665, Acc:0.793721, Semantic loss: 0.803365, BCE loss: 0.546643, SB loss: 0.753658
2023-10-30 08:57:52,278 Epoch: [174/484] Iter:[210/495], Time: 0.38, lr: [0.006688510673629709], Loss: 2.102226, Acc:0.795152, Semantic loss: 0.801341, BCE loss: 0.548382, SB loss: 0.752503
2023-10-30 08:57:55,988 Epoch: [174/484] Iter:[220/495], Time: 0.38, lr: [0.006688117846740644], Loss: 2.112172, Acc:0.794610, Semantic loss: 0.808709, BCE loss: 0.547701, SB loss: 0.755761
2023-10-30 08:57:59,696 Epoch: [174/484] Iter:[230/495], Time: 0.38, lr: [0.00668772501728793], Loss: 2.111756, Acc:0.794904, Semantic loss: 0.807638, BCE loss: 0.548321, SB loss: 0.755797
2023-10-30 08:58:03,351 Epoch: [174/484] Iter:[240/495], Time: 0.38, lr: [0.006687332185271382], Loss: 2.113993, Acc:0.796411, Semantic loss: 0.806559, BCE loss: 0.551344, SB loss: 0.756089
2023-10-30 08:58:07,043 Epoch: [174/484] Iter:[250/495], Time: 0.38, lr: [0.0066869393506908134], Loss: 2.112016, Acc:0.796651, Semantic loss: 0.805166, BCE loss: 0.551849, SB loss: 0.755002
2023-10-30 08:58:10,751 Epoch: [174/484] Iter:[260/495], Time: 0.38, lr: [0.006686546513546043], Loss: 2.115186, Acc:0.795777, Semantic loss: 0.806804, BCE loss: 0.551861, SB loss: 0.756521
2023-10-30 08:58:14,524 Epoch: [174/484] Iter:[270/495], Time: 0.38, lr: [0.006686153673836887], Loss: 2.111698, Acc:0.796276, Semantic loss: 0.804356, BCE loss: 0.550826, SB loss: 0.756515
2023-10-30 08:58:18,185 Epoch: [174/484] Iter:[280/495], Time: 0.38, lr: [0.006685760831563157], Loss: 2.105741, Acc:0.797654, Semantic loss: 0.801239, BCE loss: 0.548045, SB loss: 0.756456
2023-10-30 08:58:21,814 Epoch: [174/484] Iter:[290/495], Time: 0.37, lr: [0.006685367986724674], Loss: 2.106988, Acc:0.799005, Semantic loss: 0.799740, BCE loss: 0.550528, SB loss: 0.756719
2023-10-30 08:58:25,456 Epoch: [174/484] Iter:[300/495], Time: 0.37, lr: [0.00668497513932125], Loss: 2.103977, Acc:0.799022, Semantic loss: 0.799008, BCE loss: 0.550103, SB loss: 0.754866
2023-10-30 08:58:29,084 Epoch: [174/484] Iter:[310/495], Time: 0.37, lr: [0.006684582289352703], Loss: 2.102993, Acc:0.797872, Semantic loss: 0.798787, BCE loss: 0.548496, SB loss: 0.755710
2023-10-30 08:58:32,766 Epoch: [174/484] Iter:[320/495], Time: 0.37, lr: [0.006684189436818849], Loss: 2.100711, Acc:0.797041, Semantic loss: 0.797469, BCE loss: 0.547588, SB loss: 0.755653
2023-10-30 08:58:36,388 Epoch: [174/484] Iter:[330/495], Time: 0.37, lr: [0.006683796581719502], Loss: 2.100948, Acc:0.797725, Semantic loss: 0.796643, BCE loss: 0.548862, SB loss: 0.755443
2023-10-30 08:58:40,154 Epoch: [174/484] Iter:[340/495], Time: 0.37, lr: [0.00668340372405448], Loss: 2.098322, Acc:0.798190, Semantic loss: 0.795008, BCE loss: 0.548773, SB loss: 0.754541
2023-10-30 08:58:43,905 Epoch: [174/484] Iter:[350/495], Time: 0.37, lr: [0.006683010863823596], Loss: 2.097034, Acc:0.798235, Semantic loss: 0.794808, BCE loss: 0.548039, SB loss: 0.754187
2023-10-30 08:58:47,610 Epoch: [174/484] Iter:[360/495], Time: 0.37, lr: [0.006682618001026666], Loss: 2.096142, Acc:0.798931, Semantic loss: 0.794648, BCE loss: 0.547283, SB loss: 0.754211
2023-10-30 08:58:51,328 Epoch: [174/484] Iter:[370/495], Time: 0.37, lr: [0.0066822251356635064], Loss: 2.101075, Acc:0.797782, Semantic loss: 0.799838, BCE loss: 0.546095, SB loss: 0.755142
2023-10-30 08:58:54,987 Epoch: [174/484] Iter:[380/495], Time: 0.37, lr: [0.0066818322677339335], Loss: 2.098508, Acc:0.797956, Semantic loss: 0.796170, BCE loss: 0.547703, SB loss: 0.754635
2023-10-30 08:58:58,600 Epoch: [174/484] Iter:[390/495], Time: 0.37, lr: [0.006681439397237763], Loss: 2.096660, Acc:0.798124, Semantic loss: 0.795152, BCE loss: 0.547090, SB loss: 0.754418
2023-10-30 08:59:02,284 Epoch: [174/484] Iter:[400/495], Time: 0.37, lr: [0.006681046524174809], Loss: 2.104445, Acc:0.798486, Semantic loss: 0.801534, BCE loss: 0.547713, SB loss: 0.755198
2023-10-30 08:59:06,004 Epoch: [174/484] Iter:[410/495], Time: 0.37, lr: [0.006680653648544888], Loss: 2.106219, Acc:0.797346, Semantic loss: 0.802339, BCE loss: 0.547943, SB loss: 0.755938
2023-10-30 08:59:09,741 Epoch: [174/484] Iter:[420/495], Time: 0.37, lr: [0.0066802607703478145], Loss: 2.113282, Acc:0.797002, Semantic loss: 0.806337, BCE loss: 0.549032, SB loss: 0.757914
2023-10-30 08:59:13,363 Epoch: [174/484] Iter:[430/495], Time: 0.37, lr: [0.006679867889583405], Loss: 2.115294, Acc:0.796099, Semantic loss: 0.808191, BCE loss: 0.548278, SB loss: 0.758824
2023-10-30 08:59:17,135 Epoch: [174/484] Iter:[440/495], Time: 0.37, lr: [0.006679475006251474], Loss: 2.116936, Acc:0.796176, Semantic loss: 0.809337, BCE loss: 0.548306, SB loss: 0.759293
2023-10-30 08:59:20,807 Epoch: [174/484] Iter:[450/495], Time: 0.37, lr: [0.006679082120351839], Loss: 2.116190, Acc:0.796474, Semantic loss: 0.808137, BCE loss: 0.548799, SB loss: 0.759253
2023-10-30 08:59:24,515 Epoch: [174/484] Iter:[460/495], Time: 0.37, lr: [0.006678689231884313], Loss: 2.113484, Acc:0.796232, Semantic loss: 0.806287, BCE loss: 0.548017, SB loss: 0.759181
2023-10-30 08:59:28,215 Epoch: [174/484] Iter:[470/495], Time: 0.37, lr: [0.0066782963408487115], Loss: 2.112807, Acc:0.796465, Semantic loss: 0.805523, BCE loss: 0.547648, SB loss: 0.759636
2023-10-30 08:59:31,910 Epoch: [174/484] Iter:[480/495], Time: 0.37, lr: [0.006677903447244852], Loss: 2.113659, Acc:0.796575, Semantic loss: 0.805990, BCE loss: 0.548136, SB loss: 0.759532
2023-10-30 08:59:35,395 Epoch: [174/484] Iter:[490/495], Time: 0.37, lr: [0.006677510551072549], Loss: 2.110078, Acc:0.796688, Semantic loss: 0.803998, BCE loss: 0.547751, SB loss: 0.758330
2023-10-30 08:59:36,829 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 08:59:37,066 Loss: 2.071, MeanIU:  0.6722, Best_mIoU:  0.6984
2023-10-30 08:59:37,067 [0.97456121 0.80905978 0.90465824 0.44217801 0.51389925 0.58542037
 0.63864689 0.73318758 0.91263524 0.59468351 0.94211163 0.76650886
 0.57744096 0.89509975 0.45459938 0.4851789  0.37648301 0.44419745
 0.72058542]
2023-10-30 08:59:39,123 Epoch: [175/484] Iter:[0/495], Time: 2.02, lr: [0.006677314102023172], Loss: 2.208031, Acc:0.763805, Semantic loss: 0.842066, BCE loss: 0.564574, SB loss: 0.801391
2023-10-30 08:59:43,019 Epoch: [175/484] Iter:[10/495], Time: 0.54, lr: [0.0066769212019978565], Loss: 2.177756, Acc:0.736637, Semantic loss: 0.872148, BCE loss: 0.480839, SB loss: 0.824769
2023-10-30 08:59:46,572 Epoch: [175/484] Iter:[20/495], Time: 0.45, lr: [0.006676528299403632], Loss: 2.087840, Acc:0.764437, Semantic loss: 0.821370, BCE loss: 0.474020, SB loss: 0.792450
2023-10-30 08:59:50,180 Epoch: [175/484] Iter:[30/495], Time: 0.42, lr: [0.006676135394240321], Loss: 2.034405, Acc:0.782360, Semantic loss: 0.782551, BCE loss: 0.481562, SB loss: 0.770291
2023-10-30 08:59:53,810 Epoch: [175/484] Iter:[40/495], Time: 0.41, lr: [0.006675742486507731], Loss: 2.059357, Acc:0.781273, Semantic loss: 0.787902, BCE loss: 0.498581, SB loss: 0.772874
2023-10-30 08:59:57,526 Epoch: [175/484] Iter:[50/495], Time: 0.40, lr: [0.006675349576205683], Loss: 2.067117, Acc:0.789642, Semantic loss: 0.796483, BCE loss: 0.494915, SB loss: 0.775719
2023-10-30 09:00:01,303 Epoch: [175/484] Iter:[60/495], Time: 0.40, lr: [0.0066749566633339886], Loss: 2.083400, Acc:0.787988, Semantic loss: 0.803426, BCE loss: 0.505708, SB loss: 0.774265
2023-10-30 09:00:04,981 Epoch: [175/484] Iter:[70/495], Time: 0.39, lr: [0.006674563747892465], Loss: 2.075926, Acc:0.792376, Semantic loss: 0.793262, BCE loss: 0.513775, SB loss: 0.768888
2023-10-30 09:00:08,652 Epoch: [175/484] Iter:[80/495], Time: 0.39, lr: [0.006674170829880927], Loss: 2.066857, Acc:0.794045, Semantic loss: 0.793659, BCE loss: 0.509106, SB loss: 0.764092
2023-10-30 09:00:12,324 Epoch: [175/484] Iter:[90/495], Time: 0.39, lr: [0.006673777909299188], Loss: 2.053027, Acc:0.793628, Semantic loss: 0.782231, BCE loss: 0.508389, SB loss: 0.762407
2023-10-30 09:00:16,101 Epoch: [175/484] Iter:[100/495], Time: 0.39, lr: [0.006673384986147064], Loss: 2.062495, Acc:0.797084, Semantic loss: 0.783600, BCE loss: 0.515013, SB loss: 0.763882
2023-10-30 09:00:19,812 Epoch: [175/484] Iter:[110/495], Time: 0.38, lr: [0.006672992060424371], Loss: 2.068262, Acc:0.795629, Semantic loss: 0.787782, BCE loss: 0.517462, SB loss: 0.763018
2023-10-30 09:00:23,559 Epoch: [175/484] Iter:[120/495], Time: 0.38, lr: [0.006672599132130922], Loss: 2.070424, Acc:0.792626, Semantic loss: 0.788785, BCE loss: 0.518304, SB loss: 0.763335
2023-10-30 09:00:27,291 Epoch: [175/484] Iter:[130/495], Time: 0.38, lr: [0.0066722062012665355], Loss: 2.096215, Acc:0.794070, Semantic loss: 0.807434, BCE loss: 0.518671, SB loss: 0.770109
2023-10-30 09:00:30,992 Epoch: [175/484] Iter:[140/495], Time: 0.38, lr: [0.0066718132678310225], Loss: 2.103889, Acc:0.791485, Semantic loss: 0.813897, BCE loss: 0.520749, SB loss: 0.769243
2023-10-30 09:00:34,627 Epoch: [175/484] Iter:[150/495], Time: 0.38, lr: [0.006671420331824201], Loss: 2.115343, Acc:0.790498, Semantic loss: 0.822039, BCE loss: 0.521602, SB loss: 0.771701
2023-10-30 09:00:38,450 Epoch: [175/484] Iter:[160/495], Time: 0.38, lr: [0.006671027393245884], Loss: 2.109211, Acc:0.788835, Semantic loss: 0.816425, BCE loss: 0.520022, SB loss: 0.772764
2023-10-30 09:00:42,120 Epoch: [175/484] Iter:[170/495], Time: 0.38, lr: [0.006670634452095888], Loss: 2.109308, Acc:0.790773, Semantic loss: 0.814704, BCE loss: 0.521158, SB loss: 0.773446
2023-10-30 09:00:45,740 Epoch: [175/484] Iter:[180/495], Time: 0.38, lr: [0.006670241508374023], Loss: 2.115197, Acc:0.793590, Semantic loss: 0.816230, BCE loss: 0.526197, SB loss: 0.772771
2023-10-30 09:00:49,395 Epoch: [175/484] Iter:[190/495], Time: 0.38, lr: [0.006669848562080111], Loss: 2.111637, Acc:0.793591, Semantic loss: 0.812514, BCE loss: 0.527416, SB loss: 0.771707
2023-10-30 09:00:53,128 Epoch: [175/484] Iter:[200/495], Time: 0.38, lr: [0.006669455613213961], Loss: 2.106270, Acc:0.792445, Semantic loss: 0.811249, BCE loss: 0.524945, SB loss: 0.770075
2023-10-30 09:00:56,749 Epoch: [175/484] Iter:[210/495], Time: 0.38, lr: [0.006669062661775391], Loss: 2.106257, Acc:0.793004, Semantic loss: 0.811162, BCE loss: 0.524463, SB loss: 0.770631
2023-10-30 09:01:00,568 Epoch: [175/484] Iter:[220/495], Time: 0.38, lr: [0.006668669707764216], Loss: 2.101719, Acc:0.791854, Semantic loss: 0.807622, BCE loss: 0.524309, SB loss: 0.769789
2023-10-30 09:01:04,218 Epoch: [175/484] Iter:[230/495], Time: 0.38, lr: [0.006668276751180249], Loss: 2.105959, Acc:0.793403, Semantic loss: 0.809273, BCE loss: 0.525549, SB loss: 0.771137
2023-10-30 09:01:07,862 Epoch: [175/484] Iter:[240/495], Time: 0.38, lr: [0.006667883792023305], Loss: 2.110982, Acc:0.794113, Semantic loss: 0.809849, BCE loss: 0.528380, SB loss: 0.772753
2023-10-30 09:01:11,489 Epoch: [175/484] Iter:[250/495], Time: 0.38, lr: [0.0066674908302931995], Loss: 2.104826, Acc:0.794471, Semantic loss: 0.805600, BCE loss: 0.528217, SB loss: 0.771009
2023-10-30 09:01:15,308 Epoch: [175/484] Iter:[260/495], Time: 0.38, lr: [0.0066670978659897455], Loss: 2.107535, Acc:0.793961, Semantic loss: 0.808371, BCE loss: 0.528014, SB loss: 0.771150
2023-10-30 09:01:19,022 Epoch: [175/484] Iter:[270/495], Time: 0.38, lr: [0.006666704899112759], Loss: 2.103068, Acc:0.795610, Semantic loss: 0.805060, BCE loss: 0.529125, SB loss: 0.768882
2023-10-30 09:01:22,739 Epoch: [175/484] Iter:[280/495], Time: 0.38, lr: [0.006666311929662053], Loss: 2.097152, Acc:0.795057, Semantic loss: 0.803023, BCE loss: 0.527642, SB loss: 0.766487
2023-10-30 09:01:26,384 Epoch: [175/484] Iter:[290/495], Time: 0.38, lr: [0.006665918957637446], Loss: 2.096963, Acc:0.795395, Semantic loss: 0.803337, BCE loss: 0.526463, SB loss: 0.767164
2023-10-30 09:01:30,138 Epoch: [175/484] Iter:[300/495], Time: 0.38, lr: [0.006665525983038748], Loss: 2.090412, Acc:0.796305, Semantic loss: 0.799350, BCE loss: 0.524943, SB loss: 0.766119
2023-10-30 09:01:33,850 Epoch: [175/484] Iter:[310/495], Time: 0.38, lr: [0.006665133005865777], Loss: 2.091202, Acc:0.797246, Semantic loss: 0.799760, BCE loss: 0.525002, SB loss: 0.766440
2023-10-30 09:01:37,564 Epoch: [175/484] Iter:[320/495], Time: 0.38, lr: [0.006664740026118346], Loss: 2.085297, Acc:0.797113, Semantic loss: 0.797184, BCE loss: 0.522942, SB loss: 0.765171
2023-10-30 09:01:41,240 Epoch: [175/484] Iter:[330/495], Time: 0.38, lr: [0.006664347043796268], Loss: 2.083373, Acc:0.797315, Semantic loss: 0.794822, BCE loss: 0.524306, SB loss: 0.764245
2023-10-30 09:01:44,970 Epoch: [175/484] Iter:[340/495], Time: 0.37, lr: [0.006663954058899358], Loss: 2.084898, Acc:0.798385, Semantic loss: 0.794376, BCE loss: 0.527095, SB loss: 0.763427
2023-10-30 09:01:48,640 Epoch: [175/484] Iter:[350/495], Time: 0.37, lr: [0.006663561071427433], Loss: 2.082158, Acc:0.798898, Semantic loss: 0.792930, BCE loss: 0.527193, SB loss: 0.762036
2023-10-30 09:01:52,435 Epoch: [175/484] Iter:[360/495], Time: 0.37, lr: [0.006663168081380305], Loss: 2.079579, Acc:0.799716, Semantic loss: 0.791716, BCE loss: 0.526503, SB loss: 0.761360
2023-10-30 09:01:56,140 Epoch: [175/484] Iter:[370/495], Time: 0.37, lr: [0.0066627750887577894], Loss: 2.077073, Acc:0.799642, Semantic loss: 0.790399, BCE loss: 0.526859, SB loss: 0.759814
2023-10-30 09:01:59,961 Epoch: [175/484] Iter:[380/495], Time: 0.37, lr: [0.0066623820935597005], Loss: 2.076586, Acc:0.799452, Semantic loss: 0.790500, BCE loss: 0.526799, SB loss: 0.759287
2023-10-30 09:02:03,661 Epoch: [175/484] Iter:[390/495], Time: 0.37, lr: [0.006661989095785851], Loss: 2.076349, Acc:0.799699, Semantic loss: 0.789299, BCE loss: 0.527896, SB loss: 0.759154
2023-10-30 09:02:07,339 Epoch: [175/484] Iter:[400/495], Time: 0.37, lr: [0.006661596095436058], Loss: 2.078531, Acc:0.799227, Semantic loss: 0.791858, BCE loss: 0.527354, SB loss: 0.759318
2023-10-30 09:02:11,050 Epoch: [175/484] Iter:[410/495], Time: 0.37, lr: [0.006661203092510132], Loss: 2.078571, Acc:0.799266, Semantic loss: 0.790397, BCE loss: 0.529290, SB loss: 0.758884
2023-10-30 09:02:14,730 Epoch: [175/484] Iter:[420/495], Time: 0.37, lr: [0.00666081008700789], Loss: 2.080677, Acc:0.798858, Semantic loss: 0.791167, BCE loss: 0.530323, SB loss: 0.759188
2023-10-30 09:02:18,381 Epoch: [175/484] Iter:[430/495], Time: 0.37, lr: [0.006660417078929146], Loss: 2.079257, Acc:0.798373, Semantic loss: 0.790132, BCE loss: 0.530282, SB loss: 0.758842
2023-10-30 09:02:22,072 Epoch: [175/484] Iter:[440/495], Time: 0.37, lr: [0.0066600240682737144], Loss: 2.077395, Acc:0.798156, Semantic loss: 0.788487, BCE loss: 0.531215, SB loss: 0.757693
2023-10-30 09:02:25,835 Epoch: [175/484] Iter:[450/495], Time: 0.37, lr: [0.006659631055041408], Loss: 2.080482, Acc:0.797613, Semantic loss: 0.790267, BCE loss: 0.532800, SB loss: 0.757416
2023-10-30 09:02:29,627 Epoch: [175/484] Iter:[460/495], Time: 0.37, lr: [0.006659238039232043], Loss: 2.078179, Acc:0.797656, Semantic loss: 0.788509, BCE loss: 0.532981, SB loss: 0.756690
2023-10-30 09:02:33,280 Epoch: [175/484] Iter:[470/495], Time: 0.37, lr: [0.006658845020845431], Loss: 2.076470, Acc:0.797545, Semantic loss: 0.787483, BCE loss: 0.532830, SB loss: 0.756157
2023-10-30 09:02:37,033 Epoch: [175/484] Iter:[480/495], Time: 0.37, lr: [0.006658451999881389], Loss: 2.073849, Acc:0.797044, Semantic loss: 0.786101, BCE loss: 0.532492, SB loss: 0.755256
2023-10-30 09:02:40,511 Epoch: [175/484] Iter:[490/495], Time: 0.37, lr: [0.006658058976339726], Loss: 2.073434, Acc:0.797280, Semantic loss: 0.785355, BCE loss: 0.532644, SB loss: 0.755435
2023-10-30 09:05:36,720 0 [9.42062256e-01 6.62741684e-01 8.28118929e-01 1.14374629e-01
 2.45434904e-01 4.12720444e-01 4.75914521e-01 5.99318877e-01
 8.80287735e-01 4.54048548e-01 8.69117680e-01 5.88410754e-01
 1.17054993e-02 7.99958667e-01 1.23168726e-05 8.88637240e-02
 3.67844480e-02 5.29714357e-02 5.67941461e-01] 0.45425202685739063
2023-10-30 09:05:36,720 1 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437] 0.6744496123976521
2023-10-30 09:05:36,724 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:05:36,964 Loss: 2.059, MeanIU:  0.6744, Best_mIoU:  0.6984
2023-10-30 09:05:36,964 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437]
2023-10-30 09:05:39,357 Epoch: [176/484] Iter:[0/495], Time: 2.35, lr: [0.006657862463602231], Loss: 2.566547, Acc:0.727958, Semantic loss: 1.275867, BCE loss: 0.480037, SB loss: 0.810643
2023-10-30 09:05:43,171 Epoch: [176/484] Iter:[10/495], Time: 0.56, lr: [0.006657469436193795], Loss: 2.040174, Acc:0.828463, Semantic loss: 0.755512, BCE loss: 0.553320, SB loss: 0.731341
2023-10-30 09:05:46,647 Epoch: [176/484] Iter:[20/495], Time: 0.46, lr: [0.006657076406207275], Loss: 2.094858, Acc:0.806739, Semantic loss: 0.794654, BCE loss: 0.555420, SB loss: 0.744783
2023-10-30 09:05:50,250 Epoch: [176/484] Iter:[30/495], Time: 0.43, lr: [0.0066566833736424885], Loss: 2.132535, Acc:0.791036, Semantic loss: 0.829539, BCE loss: 0.547618, SB loss: 0.755379
2023-10-30 09:05:53,661 Epoch: [176/484] Iter:[40/495], Time: 0.41, lr: [0.006656290338499246], Loss: 2.194459, Acc:0.789090, Semantic loss: 0.847945, BCE loss: 0.579240, SB loss: 0.767274
2023-10-30 09:05:57,111 Epoch: [176/484] Iter:[50/495], Time: 0.39, lr: [0.006655897300777362], Loss: 2.186163, Acc:0.778174, Semantic loss: 0.840452, BCE loss: 0.573146, SB loss: 0.772566
2023-10-30 09:06:00,749 Epoch: [176/484] Iter:[60/495], Time: 0.39, lr: [0.006655504260476653], Loss: 2.140991, Acc:0.779555, Semantic loss: 0.812649, BCE loss: 0.559223, SB loss: 0.769119
2023-10-30 09:06:04,290 Epoch: [176/484] Iter:[70/495], Time: 0.38, lr: [0.00665511121759693], Loss: 2.135642, Acc:0.784330, Semantic loss: 0.805580, BCE loss: 0.564938, SB loss: 0.765125
2023-10-30 09:06:07,829 Epoch: [176/484] Iter:[80/495], Time: 0.38, lr: [0.0066547181721380065], Loss: 2.123036, Acc:0.783371, Semantic loss: 0.801194, BCE loss: 0.557760, SB loss: 0.764082
2023-10-30 09:06:11,467 Epoch: [176/484] Iter:[90/495], Time: 0.38, lr: [0.006654325124099699], Loss: 2.117555, Acc:0.784078, Semantic loss: 0.800184, BCE loss: 0.553353, SB loss: 0.764018
2023-10-30 09:06:15,125 Epoch: [176/484] Iter:[100/495], Time: 0.38, lr: [0.006653932073481819], Loss: 2.112210, Acc:0.782680, Semantic loss: 0.796847, BCE loss: 0.552895, SB loss: 0.762469
2023-10-30 09:06:18,707 Epoch: [176/484] Iter:[110/495], Time: 0.38, lr: [0.006653539020284181], Loss: 2.108683, Acc:0.784175, Semantic loss: 0.792546, BCE loss: 0.554783, SB loss: 0.761354
2023-10-30 09:06:22,283 Epoch: [176/484] Iter:[120/495], Time: 0.37, lr: [0.0066531459645066005], Loss: 2.109963, Acc:0.783837, Semantic loss: 0.792339, BCE loss: 0.557825, SB loss: 0.759799
2023-10-30 09:06:25,985 Epoch: [176/484] Iter:[130/495], Time: 0.37, lr: [0.006652752906148889], Loss: 2.100867, Acc:0.784283, Semantic loss: 0.789779, BCE loss: 0.552961, SB loss: 0.758127
2023-10-30 09:06:29,516 Epoch: [176/484] Iter:[140/495], Time: 0.37, lr: [0.006652359845210861], Loss: 2.106836, Acc:0.784145, Semantic loss: 0.791676, BCE loss: 0.555463, SB loss: 0.759697
2023-10-30 09:06:33,113 Epoch: [176/484] Iter:[150/495], Time: 0.37, lr: [0.006651966781692329], Loss: 2.095977, Acc:0.786908, Semantic loss: 0.787057, BCE loss: 0.553986, SB loss: 0.754935
2023-10-30 09:06:36,759 Epoch: [176/484] Iter:[160/495], Time: 0.37, lr: [0.006651573715593107], Loss: 2.093592, Acc:0.787843, Semantic loss: 0.786214, BCE loss: 0.552535, SB loss: 0.754844
2023-10-30 09:06:40,382 Epoch: [176/484] Iter:[170/495], Time: 0.37, lr: [0.006651180646913011], Loss: 2.089114, Acc:0.788619, Semantic loss: 0.784196, BCE loss: 0.550463, SB loss: 0.754455
2023-10-30 09:06:43,920 Epoch: [176/484] Iter:[180/495], Time: 0.37, lr: [0.006650787575651851], Loss: 2.086508, Acc:0.791235, Semantic loss: 0.784063, BCE loss: 0.549691, SB loss: 0.752754
2023-10-30 09:06:47,551 Epoch: [176/484] Iter:[190/495], Time: 0.37, lr: [0.006650394501809443], Loss: 2.093965, Acc:0.792057, Semantic loss: 0.792259, BCE loss: 0.547249, SB loss: 0.754456
2023-10-30 09:06:51,195 Epoch: [176/484] Iter:[200/495], Time: 0.37, lr: [0.0066500014253856], Loss: 2.094948, Acc:0.791853, Semantic loss: 0.792271, BCE loss: 0.546691, SB loss: 0.755986
2023-10-30 09:06:54,905 Epoch: [176/484] Iter:[210/495], Time: 0.37, lr: [0.006649608346380136], Loss: 2.088760, Acc:0.791668, Semantic loss: 0.790130, BCE loss: 0.543867, SB loss: 0.754763
2023-10-30 09:06:58,650 Epoch: [176/484] Iter:[220/495], Time: 0.37, lr: [0.006649215264792863], Loss: 2.092377, Acc:0.793510, Semantic loss: 0.792083, BCE loss: 0.545141, SB loss: 0.755152
2023-10-30 09:07:02,280 Epoch: [176/484] Iter:[230/495], Time: 0.37, lr: [0.006648822180623596], Loss: 2.096250, Acc:0.792815, Semantic loss: 0.795001, BCE loss: 0.545329, SB loss: 0.755919
2023-10-30 09:07:05,932 Epoch: [176/484] Iter:[240/495], Time: 0.37, lr: [0.006648429093872146], Loss: 2.094561, Acc:0.793224, Semantic loss: 0.792956, BCE loss: 0.545379, SB loss: 0.756225
2023-10-30 09:07:09,559 Epoch: [176/484] Iter:[250/495], Time: 0.37, lr: [0.0066480360045383284], Loss: 2.097187, Acc:0.792625, Semantic loss: 0.793837, BCE loss: 0.546259, SB loss: 0.757091
2023-10-30 09:07:13,197 Epoch: [176/484] Iter:[260/495], Time: 0.37, lr: [0.006647642912621958], Loss: 2.101267, Acc:0.791898, Semantic loss: 0.797090, BCE loss: 0.544900, SB loss: 0.759277
2023-10-30 09:07:16,890 Epoch: [176/484] Iter:[270/495], Time: 0.37, lr: [0.006647249818122845], Loss: 2.109973, Acc:0.790669, Semantic loss: 0.803206, BCE loss: 0.545283, SB loss: 0.761484
2023-10-30 09:07:20,632 Epoch: [176/484] Iter:[280/495], Time: 0.37, lr: [0.006646856721040805], Loss: 2.112123, Acc:0.789883, Semantic loss: 0.804567, BCE loss: 0.544449, SB loss: 0.763108
2023-10-30 09:07:24,226 Epoch: [176/484] Iter:[290/495], Time: 0.37, lr: [0.006646463621375651], Loss: 2.107743, Acc:0.791082, Semantic loss: 0.801048, BCE loss: 0.544288, SB loss: 0.762407
2023-10-30 09:07:27,916 Epoch: [176/484] Iter:[300/495], Time: 0.37, lr: [0.006646070519127194], Loss: 2.105865, Acc:0.790437, Semantic loss: 0.798895, BCE loss: 0.544634, SB loss: 0.762336
2023-10-30 09:07:31,693 Epoch: [176/484] Iter:[310/495], Time: 0.37, lr: [0.006645677414295249], Loss: 2.104217, Acc:0.789721, Semantic loss: 0.798819, BCE loss: 0.542718, SB loss: 0.762681
2023-10-30 09:07:35,324 Epoch: [176/484] Iter:[320/495], Time: 0.37, lr: [0.00664528430687963], Loss: 2.107440, Acc:0.789969, Semantic loss: 0.799410, BCE loss: 0.544475, SB loss: 0.763555
2023-10-30 09:07:39,033 Epoch: [176/484] Iter:[330/495], Time: 0.37, lr: [0.0066448911968801485], Loss: 2.107937, Acc:0.789946, Semantic loss: 0.799259, BCE loss: 0.544848, SB loss: 0.763829
2023-10-30 09:07:42,681 Epoch: [176/484] Iter:[340/495], Time: 0.37, lr: [0.00664449808429662], Loss: 2.110550, Acc:0.790017, Semantic loss: 0.801259, BCE loss: 0.544018, SB loss: 0.765273
2023-10-30 09:07:46,403 Epoch: [176/484] Iter:[350/495], Time: 0.37, lr: [0.006644104969128855], Loss: 2.105943, Acc:0.790613, Semantic loss: 0.799553, BCE loss: 0.542156, SB loss: 0.764235
2023-10-30 09:07:50,160 Epoch: [176/484] Iter:[360/495], Time: 0.37, lr: [0.006643711851376668], Loss: 2.102168, Acc:0.791334, Semantic loss: 0.796807, BCE loss: 0.543495, SB loss: 0.761866
2023-10-30 09:07:53,844 Epoch: [176/484] Iter:[370/495], Time: 0.37, lr: [0.006643318731039873], Loss: 2.107126, Acc:0.791490, Semantic loss: 0.798489, BCE loss: 0.544610, SB loss: 0.764027
2023-10-30 09:07:57,478 Epoch: [176/484] Iter:[380/495], Time: 0.37, lr: [0.006642925608118281], Loss: 2.101851, Acc:0.791338, Semantic loss: 0.796365, BCE loss: 0.542812, SB loss: 0.762674
2023-10-30 09:08:01,204 Epoch: [176/484] Iter:[390/495], Time: 0.37, lr: [0.006642532482611706], Loss: 2.098694, Acc:0.791974, Semantic loss: 0.793494, BCE loss: 0.543202, SB loss: 0.761999
2023-10-30 09:08:04,876 Epoch: [176/484] Iter:[400/495], Time: 0.37, lr: [0.006642139354519961], Loss: 2.099659, Acc:0.792710, Semantic loss: 0.794148, BCE loss: 0.543308, SB loss: 0.762203
2023-10-30 09:08:08,556 Epoch: [176/484] Iter:[410/495], Time: 0.37, lr: [0.006641746223842858], Loss: 2.099050, Acc:0.791880, Semantic loss: 0.794340, BCE loss: 0.542126, SB loss: 0.762584
2023-10-30 09:08:12,381 Epoch: [176/484] Iter:[420/495], Time: 0.37, lr: [0.0066413530905802135], Loss: 2.096868, Acc:0.792668, Semantic loss: 0.793054, BCE loss: 0.542147, SB loss: 0.761667
2023-10-30 09:08:16,130 Epoch: [176/484] Iter:[430/495], Time: 0.37, lr: [0.006640959954731835], Loss: 2.098740, Acc:0.792503, Semantic loss: 0.793549, BCE loss: 0.542315, SB loss: 0.762877
2023-10-30 09:08:19,841 Epoch: [176/484] Iter:[440/495], Time: 0.37, lr: [0.0066405668162975405], Loss: 2.102180, Acc:0.791766, Semantic loss: 0.795017, BCE loss: 0.542741, SB loss: 0.764423
2023-10-30 09:08:23,489 Epoch: [176/484] Iter:[450/495], Time: 0.37, lr: [0.006640173675277142], Loss: 2.101941, Acc:0.791977, Semantic loss: 0.794795, BCE loss: 0.543251, SB loss: 0.763895
2023-10-30 09:08:27,210 Epoch: [176/484] Iter:[460/495], Time: 0.37, lr: [0.006639780531670449], Loss: 2.103854, Acc:0.791919, Semantic loss: 0.796123, BCE loss: 0.544329, SB loss: 0.763402
2023-10-30 09:08:30,924 Epoch: [176/484] Iter:[470/495], Time: 0.37, lr: [0.006639387385477274], Loss: 2.104855, Acc:0.791028, Semantic loss: 0.797043, BCE loss: 0.544867, SB loss: 0.762944
2023-10-30 09:08:34,669 Epoch: [176/484] Iter:[480/495], Time: 0.37, lr: [0.006638994236697436], Loss: 2.102763, Acc:0.790914, Semantic loss: 0.795524, BCE loss: 0.544325, SB loss: 0.762913
2023-10-30 09:08:38,218 Epoch: [176/484] Iter:[490/495], Time: 0.37, lr: [0.0066386010853307425], Loss: 2.102428, Acc:0.791268, Semantic loss: 0.795605, BCE loss: 0.544171, SB loss: 0.762652
2023-10-30 09:08:39,626 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:08:39,865 Loss: 2.059, MeanIU:  0.6744, Best_mIoU:  0.6984
2023-10-30 09:08:39,865 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437]
2023-10-30 09:08:42,049 Epoch: [177/484] Iter:[0/495], Time: 2.15, lr: [0.006638404508677266], Loss: 1.914559, Acc:0.846406, Semantic loss: 0.687226, BCE loss: 0.464046, SB loss: 0.763286
2023-10-30 09:08:46,172 Epoch: [177/484] Iter:[10/495], Time: 0.57, lr: [0.006638011353429942], Loss: 2.254667, Acc:0.765996, Semantic loss: 0.894866, BCE loss: 0.539998, SB loss: 0.819803
2023-10-30 09:08:49,939 Epoch: [177/484] Iter:[20/495], Time: 0.48, lr: [0.006637618195595294], Loss: 2.112732, Acc:0.789978, Semantic loss: 0.792112, BCE loss: 0.543859, SB loss: 0.776762
2023-10-30 09:08:53,707 Epoch: [177/484] Iter:[30/495], Time: 0.45, lr: [0.006637225035173137], Loss: 2.145150, Acc:0.796401, Semantic loss: 0.799221, BCE loss: 0.566330, SB loss: 0.779600
2023-10-30 09:08:57,402 Epoch: [177/484] Iter:[40/495], Time: 0.43, lr: [0.006636831872163284], Loss: 2.151193, Acc:0.795379, Semantic loss: 0.812768, BCE loss: 0.565714, SB loss: 0.772711
2023-10-30 09:09:01,020 Epoch: [177/484] Iter:[50/495], Time: 0.41, lr: [0.006636438706565545], Loss: 2.147082, Acc:0.804273, Semantic loss: 0.805568, BCE loss: 0.573928, SB loss: 0.767586
2023-10-30 09:09:04,657 Epoch: [177/484] Iter:[60/495], Time: 0.41, lr: [0.006636045538379735], Loss: 2.135243, Acc:0.799865, Semantic loss: 0.798295, BCE loss: 0.574315, SB loss: 0.762633
2023-10-30 09:09:08,396 Epoch: [177/484] Iter:[70/495], Time: 0.40, lr: [0.006635652367605667], Loss: 2.122838, Acc:0.795888, Semantic loss: 0.793885, BCE loss: 0.568185, SB loss: 0.760768
2023-10-30 09:09:12,082 Epoch: [177/484] Iter:[80/495], Time: 0.40, lr: [0.00663525919424315], Loss: 2.106430, Acc:0.793921, Semantic loss: 0.786737, BCE loss: 0.563281, SB loss: 0.756411
2023-10-30 09:09:15,706 Epoch: [177/484] Iter:[90/495], Time: 0.39, lr: [0.006634866018292002], Loss: 2.109615, Acc:0.794424, Semantic loss: 0.795921, BCE loss: 0.559320, SB loss: 0.754374
2023-10-30 09:09:19,429 Epoch: [177/484] Iter:[100/495], Time: 0.39, lr: [0.0066344728397520316], Loss: 2.103669, Acc:0.796118, Semantic loss: 0.794785, BCE loss: 0.556591, SB loss: 0.752293
2023-10-30 09:09:23,075 Epoch: [177/484] Iter:[110/495], Time: 0.39, lr: [0.006634079658623053], Loss: 2.097140, Acc:0.795441, Semantic loss: 0.792213, BCE loss: 0.554041, SB loss: 0.750886
2023-10-30 09:09:26,758 Epoch: [177/484] Iter:[120/495], Time: 0.39, lr: [0.006633686474904877], Loss: 2.090657, Acc:0.795549, Semantic loss: 0.787366, BCE loss: 0.553233, SB loss: 0.750057
2023-10-30 09:09:30,442 Epoch: [177/484] Iter:[130/495], Time: 0.39, lr: [0.006633293288597317], Loss: 2.110547, Acc:0.796179, Semantic loss: 0.796252, BCE loss: 0.558580, SB loss: 0.755715
2023-10-30 09:09:34,193 Epoch: [177/484] Iter:[140/495], Time: 0.39, lr: [0.006632900099700186], Loss: 2.094845, Acc:0.794628, Semantic loss: 0.790568, BCE loss: 0.551015, SB loss: 0.753261
2023-10-30 09:09:37,988 Epoch: [177/484] Iter:[150/495], Time: 0.38, lr: [0.006632506908213295], Loss: 2.088150, Acc:0.793440, Semantic loss: 0.786452, BCE loss: 0.549292, SB loss: 0.752406
2023-10-30 09:09:41,749 Epoch: [177/484] Iter:[160/495], Time: 0.38, lr: [0.006632113714136458], Loss: 2.101761, Acc:0.796918, Semantic loss: 0.795927, BCE loss: 0.550498, SB loss: 0.755336
2023-10-30 09:09:45,368 Epoch: [177/484] Iter:[170/495], Time: 0.38, lr: [0.006631720517469486], Loss: 2.107672, Acc:0.798912, Semantic loss: 0.798448, BCE loss: 0.552944, SB loss: 0.756279
2023-10-30 09:09:49,171 Epoch: [177/484] Iter:[180/495], Time: 0.38, lr: [0.006631327318212192], Loss: 2.102513, Acc:0.798437, Semantic loss: 0.794443, BCE loss: 0.552851, SB loss: 0.755219
2023-10-30 09:09:52,912 Epoch: [177/484] Iter:[190/495], Time: 0.38, lr: [0.006630934116364388], Loss: 2.102361, Acc:0.799244, Semantic loss: 0.794111, BCE loss: 0.553213, SB loss: 0.755037
2023-10-30 09:09:56,572 Epoch: [177/484] Iter:[200/495], Time: 0.38, lr: [0.006630540911925887], Loss: 2.098572, Acc:0.799291, Semantic loss: 0.792132, BCE loss: 0.552086, SB loss: 0.754353
2023-10-30 09:10:00,220 Epoch: [177/484] Iter:[210/495], Time: 0.38, lr: [0.006630147704896498], Loss: 2.101154, Acc:0.799420, Semantic loss: 0.793020, BCE loss: 0.551474, SB loss: 0.756660
2023-10-30 09:10:04,007 Epoch: [177/484] Iter:[220/495], Time: 0.38, lr: [0.006629754495276039], Loss: 2.099162, Acc:0.799036, Semantic loss: 0.789297, BCE loss: 0.554708, SB loss: 0.755157
2023-10-30 09:10:07,753 Epoch: [177/484] Iter:[230/495], Time: 0.38, lr: [0.006629361283064317], Loss: 2.087031, Acc:0.799197, Semantic loss: 0.784743, BCE loss: 0.551411, SB loss: 0.750877
2023-10-30 09:10:11,461 Epoch: [177/484] Iter:[240/495], Time: 0.38, lr: [0.006628968068261147], Loss: 2.087659, Acc:0.798192, Semantic loss: 0.786331, BCE loss: 0.549273, SB loss: 0.752055
2023-10-30 09:10:15,126 Epoch: [177/484] Iter:[250/495], Time: 0.38, lr: [0.006628574850866339], Loss: 2.094893, Acc:0.798562, Semantic loss: 0.788459, BCE loss: 0.553430, SB loss: 0.753004
2023-10-30 09:10:18,751 Epoch: [177/484] Iter:[260/495], Time: 0.38, lr: [0.006628181630879707], Loss: 2.097614, Acc:0.798685, Semantic loss: 0.790113, BCE loss: 0.553965, SB loss: 0.753536
2023-10-30 09:10:22,493 Epoch: [177/484] Iter:[270/495], Time: 0.38, lr: [0.006627788408301063], Loss: 2.098761, Acc:0.799504, Semantic loss: 0.788723, BCE loss: 0.556534, SB loss: 0.753504
2023-10-30 09:10:26,142 Epoch: [177/484] Iter:[280/495], Time: 0.38, lr: [0.006627395183130217], Loss: 2.100149, Acc:0.800151, Semantic loss: 0.788179, BCE loss: 0.558899, SB loss: 0.753070
2023-10-30 09:10:29,884 Epoch: [177/484] Iter:[290/495], Time: 0.38, lr: [0.006627001955366982], Loss: 2.096223, Acc:0.800210, Semantic loss: 0.786682, BCE loss: 0.557297, SB loss: 0.752244
2023-10-30 09:10:33,560 Epoch: [177/484] Iter:[300/495], Time: 0.38, lr: [0.006626608725011172], Loss: 2.090349, Acc:0.800586, Semantic loss: 0.783563, BCE loss: 0.556325, SB loss: 0.750462
2023-10-30 09:10:37,252 Epoch: [177/484] Iter:[310/495], Time: 0.38, lr: [0.006626215492062596], Loss: 2.090312, Acc:0.801340, Semantic loss: 0.783504, BCE loss: 0.556046, SB loss: 0.750763
2023-10-30 09:10:40,953 Epoch: [177/484] Iter:[320/495], Time: 0.38, lr: [0.006625822256521068], Loss: 2.087001, Acc:0.801035, Semantic loss: 0.782844, BCE loss: 0.553441, SB loss: 0.750717
2023-10-30 09:10:44,650 Epoch: [177/484] Iter:[330/495], Time: 0.38, lr: [0.0066254290183863996], Loss: 2.081945, Acc:0.801246, Semantic loss: 0.779448, BCE loss: 0.552937, SB loss: 0.749560
2023-10-30 09:10:48,437 Epoch: [177/484] Iter:[340/495], Time: 0.38, lr: [0.0066250357776584026], Loss: 2.079475, Acc:0.801737, Semantic loss: 0.777572, BCE loss: 0.552158, SB loss: 0.749745
2023-10-30 09:10:52,013 Epoch: [177/484] Iter:[350/495], Time: 0.38, lr: [0.006624642534336887], Loss: 2.077779, Acc:0.801955, Semantic loss: 0.776974, BCE loss: 0.552215, SB loss: 0.748590
2023-10-30 09:10:55,739 Epoch: [177/484] Iter:[360/495], Time: 0.38, lr: [0.006624249288421667], Loss: 2.077676, Acc:0.800795, Semantic loss: 0.776946, BCE loss: 0.551723, SB loss: 0.749007
2023-10-30 09:10:59,534 Epoch: [177/484] Iter:[370/495], Time: 0.38, lr: [0.006623856039912553], Loss: 2.082160, Acc:0.800973, Semantic loss: 0.779365, BCE loss: 0.552794, SB loss: 0.750002
2023-10-30 09:11:03,222 Epoch: [177/484] Iter:[380/495], Time: 0.38, lr: [0.006623462788809358], Loss: 2.081042, Acc:0.801724, Semantic loss: 0.778320, BCE loss: 0.553136, SB loss: 0.749586
2023-10-30 09:11:06,908 Epoch: [177/484] Iter:[390/495], Time: 0.38, lr: [0.006623069535111893], Loss: 2.078495, Acc:0.801406, Semantic loss: 0.777352, BCE loss: 0.551887, SB loss: 0.749256
2023-10-30 09:11:10,605 Epoch: [177/484] Iter:[400/495], Time: 0.38, lr: [0.00662267627881997], Loss: 2.079135, Acc:0.800726, Semantic loss: 0.778371, BCE loss: 0.550805, SB loss: 0.749960
2023-10-30 09:11:14,256 Epoch: [177/484] Iter:[410/495], Time: 0.38, lr: [0.006622283019933401], Loss: 2.075994, Acc:0.800152, Semantic loss: 0.777091, BCE loss: 0.549811, SB loss: 0.749092
2023-10-30 09:11:17,951 Epoch: [177/484] Iter:[420/495], Time: 0.38, lr: [0.006621889758451996], Loss: 2.076276, Acc:0.799574, Semantic loss: 0.777508, BCE loss: 0.549612, SB loss: 0.749155
2023-10-30 09:11:21,653 Epoch: [177/484] Iter:[430/495], Time: 0.38, lr: [0.006621496494375568], Loss: 2.074827, Acc:0.799055, Semantic loss: 0.776722, BCE loss: 0.549377, SB loss: 0.748728
2023-10-30 09:11:25,323 Epoch: [177/484] Iter:[440/495], Time: 0.38, lr: [0.006621103227703929], Loss: 2.075914, Acc:0.799798, Semantic loss: 0.777698, BCE loss: 0.549256, SB loss: 0.748961
2023-10-30 09:11:29,007 Epoch: [177/484] Iter:[450/495], Time: 0.37, lr: [0.00662070995843689], Loss: 2.072635, Acc:0.798671, Semantic loss: 0.775896, BCE loss: 0.547873, SB loss: 0.748866
2023-10-30 09:11:32,622 Epoch: [177/484] Iter:[460/495], Time: 0.37, lr: [0.006620316686574264], Loss: 2.074755, Acc:0.798322, Semantic loss: 0.777266, BCE loss: 0.548115, SB loss: 0.749374
2023-10-30 09:11:36,333 Epoch: [177/484] Iter:[470/495], Time: 0.37, lr: [0.006619923412115858], Loss: 2.074689, Acc:0.798212, Semantic loss: 0.777262, BCE loss: 0.547961, SB loss: 0.749466
2023-10-30 09:11:40,149 Epoch: [177/484] Iter:[480/495], Time: 0.37, lr: [0.006619530135061489], Loss: 2.079772, Acc:0.798303, Semantic loss: 0.780100, BCE loss: 0.549092, SB loss: 0.750580
2023-10-30 09:11:43,633 Epoch: [177/484] Iter:[490/495], Time: 0.37, lr: [0.006619136855410966], Loss: 2.076629, Acc:0.798582, Semantic loss: 0.778749, BCE loss: 0.547630, SB loss: 0.750250
2023-10-30 09:11:45,038 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:11:45,280 Loss: 2.059, MeanIU:  0.6744, Best_mIoU:  0.6984
2023-10-30 09:11:45,281 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437]
2023-10-30 09:11:47,076 Epoch: [178/484] Iter:[0/495], Time: 1.76, lr: [0.006618940214612088], Loss: 2.208994, Acc:0.700275, Semantic loss: 0.902611, BCE loss: 0.519592, SB loss: 0.786791
2023-10-30 09:11:51,023 Epoch: [178/484] Iter:[10/495], Time: 0.52, lr: [0.006618546931066981], Loss: 2.102685, Acc:0.747355, Semantic loss: 0.798661, BCE loss: 0.542579, SB loss: 0.761445
2023-10-30 09:11:54,770 Epoch: [178/484] Iter:[20/495], Time: 0.45, lr: [0.00661815364492525], Loss: 2.016199, Acc:0.771069, Semantic loss: 0.759851, BCE loss: 0.518379, SB loss: 0.737968
2023-10-30 09:11:58,493 Epoch: [178/484] Iter:[30/495], Time: 0.43, lr: [0.006617760356186703], Loss: 2.023144, Acc:0.778920, Semantic loss: 0.774766, BCE loss: 0.514345, SB loss: 0.734033
2023-10-30 09:12:02,054 Epoch: [178/484] Iter:[40/495], Time: 0.41, lr: [0.006617367064851154], Loss: 2.017733, Acc:0.786806, Semantic loss: 0.766003, BCE loss: 0.519580, SB loss: 0.732150
2023-10-30 09:12:05,754 Epoch: [178/484] Iter:[50/495], Time: 0.40, lr: [0.006616973770918414], Loss: 1.989914, Acc:0.786052, Semantic loss: 0.744543, BCE loss: 0.512086, SB loss: 0.733286
2023-10-30 09:12:09,364 Epoch: [178/484] Iter:[60/495], Time: 0.39, lr: [0.0066165804743882955], Loss: 2.027519, Acc:0.784511, Semantic loss: 0.763822, BCE loss: 0.522337, SB loss: 0.741360
2023-10-30 09:12:13,122 Epoch: [178/484] Iter:[70/495], Time: 0.39, lr: [0.006616187175260608], Loss: 2.044061, Acc:0.781040, Semantic loss: 0.766314, BCE loss: 0.533783, SB loss: 0.743964
2023-10-30 09:12:16,737 Epoch: [178/484] Iter:[80/495], Time: 0.39, lr: [0.006615793873535163], Loss: 2.051147, Acc:0.784697, Semantic loss: 0.768495, BCE loss: 0.533260, SB loss: 0.749393
2023-10-30 09:12:20,494 Epoch: [178/484] Iter:[90/495], Time: 0.39, lr: [0.006615400569211774], Loss: 2.060020, Acc:0.781355, Semantic loss: 0.777327, BCE loss: 0.528696, SB loss: 0.753997
2023-10-30 09:12:24,150 Epoch: [178/484] Iter:[100/495], Time: 0.38, lr: [0.006615007262290248], Loss: 2.052331, Acc:0.783071, Semantic loss: 0.772821, BCE loss: 0.530287, SB loss: 0.749223
2023-10-30 09:12:27,848 Epoch: [178/484] Iter:[110/495], Time: 0.38, lr: [0.006614613952770398], Loss: 2.046402, Acc:0.783625, Semantic loss: 0.767783, BCE loss: 0.529020, SB loss: 0.749598
2023-10-30 09:12:31,533 Epoch: [178/484] Iter:[120/495], Time: 0.38, lr: [0.006614220640652038], Loss: 2.032742, Acc:0.784602, Semantic loss: 0.761412, BCE loss: 0.525083, SB loss: 0.746247
2023-10-30 09:12:35,192 Epoch: [178/484] Iter:[130/495], Time: 0.38, lr: [0.006613827325934976], Loss: 2.038573, Acc:0.787769, Semantic loss: 0.767136, BCE loss: 0.526494, SB loss: 0.744942
2023-10-30 09:12:38,915 Epoch: [178/484] Iter:[140/495], Time: 0.38, lr: [0.0066134340086190235], Loss: 2.041936, Acc:0.788153, Semantic loss: 0.770382, BCE loss: 0.528118, SB loss: 0.743435
2023-10-30 09:12:42,554 Epoch: [178/484] Iter:[150/495], Time: 0.38, lr: [0.006613040688703993], Loss: 2.043593, Acc:0.788441, Semantic loss: 0.768798, BCE loss: 0.529929, SB loss: 0.744866
2023-10-30 09:12:46,189 Epoch: [178/484] Iter:[160/495], Time: 0.38, lr: [0.006612647366189695], Loss: 2.048012, Acc:0.790589, Semantic loss: 0.766730, BCE loss: 0.537678, SB loss: 0.743604
2023-10-30 09:12:49,873 Epoch: [178/484] Iter:[170/495], Time: 0.38, lr: [0.006612254041075939], Loss: 2.039296, Acc:0.791361, Semantic loss: 0.762219, BCE loss: 0.536952, SB loss: 0.740125
2023-10-30 09:12:53,489 Epoch: [178/484] Iter:[180/495], Time: 0.38, lr: [0.006611860713362537], Loss: 2.044594, Acc:0.790770, Semantic loss: 0.766469, BCE loss: 0.535320, SB loss: 0.742805
2023-10-30 09:12:57,180 Epoch: [178/484] Iter:[190/495], Time: 0.38, lr: [0.0066114673830493], Loss: 2.044117, Acc:0.793038, Semantic loss: 0.766442, BCE loss: 0.535064, SB loss: 0.742610
2023-10-30 09:13:00,899 Epoch: [178/484] Iter:[200/495], Time: 0.38, lr: [0.00661107405013604], Loss: 2.046490, Acc:0.793402, Semantic loss: 0.768186, BCE loss: 0.535071, SB loss: 0.743233
2023-10-30 09:13:04,723 Epoch: [178/484] Iter:[210/495], Time: 0.38, lr: [0.006610680714622567], Loss: 2.047000, Acc:0.793900, Semantic loss: 0.767558, BCE loss: 0.535932, SB loss: 0.743510
2023-10-30 09:13:08,369 Epoch: [178/484] Iter:[220/495], Time: 0.38, lr: [0.006610287376508692], Loss: 2.045087, Acc:0.792868, Semantic loss: 0.767784, BCE loss: 0.534150, SB loss: 0.743154
2023-10-30 09:13:12,079 Epoch: [178/484] Iter:[230/495], Time: 0.38, lr: [0.006609894035794225], Loss: 2.049984, Acc:0.794003, Semantic loss: 0.770151, BCE loss: 0.535888, SB loss: 0.743945
2023-10-30 09:13:15,727 Epoch: [178/484] Iter:[240/495], Time: 0.38, lr: [0.006609500692478978], Loss: 2.050595, Acc:0.795309, Semantic loss: 0.769761, BCE loss: 0.537421, SB loss: 0.743414
2023-10-30 09:13:19,469 Epoch: [178/484] Iter:[250/495], Time: 0.38, lr: [0.006609107346562762], Loss: 2.051773, Acc:0.795548, Semantic loss: 0.770117, BCE loss: 0.538355, SB loss: 0.743301
2023-10-30 09:13:23,260 Epoch: [178/484] Iter:[260/495], Time: 0.38, lr: [0.006608713998045388], Loss: 2.049385, Acc:0.795246, Semantic loss: 0.768139, BCE loss: 0.538558, SB loss: 0.742688
2023-10-30 09:13:27,014 Epoch: [178/484] Iter:[270/495], Time: 0.38, lr: [0.006608320646926664], Loss: 2.056088, Acc:0.793736, Semantic loss: 0.772700, BCE loss: 0.538611, SB loss: 0.744777
2023-10-30 09:13:30,703 Epoch: [178/484] Iter:[280/495], Time: 0.38, lr: [0.006607927293206404], Loss: 2.050580, Acc:0.794829, Semantic loss: 0.768501, BCE loss: 0.539673, SB loss: 0.742406
2023-10-30 09:13:34,307 Epoch: [178/484] Iter:[290/495], Time: 0.37, lr: [0.006607533936884417], Loss: 2.052749, Acc:0.795597, Semantic loss: 0.769368, BCE loss: 0.539854, SB loss: 0.743527
2023-10-30 09:13:38,025 Epoch: [178/484] Iter:[300/495], Time: 0.37, lr: [0.0066071405779605154], Loss: 2.046660, Acc:0.795579, Semantic loss: 0.767396, BCE loss: 0.537273, SB loss: 0.741991
2023-10-30 09:13:41,692 Epoch: [178/484] Iter:[310/495], Time: 0.37, lr: [0.006606747216434508], Loss: 2.045798, Acc:0.795929, Semantic loss: 0.766722, BCE loss: 0.537100, SB loss: 0.741976
2023-10-30 09:13:45,387 Epoch: [178/484] Iter:[320/495], Time: 0.37, lr: [0.006606353852306206], Loss: 2.043329, Acc:0.795366, Semantic loss: 0.766843, BCE loss: 0.534871, SB loss: 0.741615
2023-10-30 09:13:49,000 Epoch: [178/484] Iter:[330/495], Time: 0.37, lr: [0.006605960485575421], Loss: 2.042164, Acc:0.796538, Semantic loss: 0.766514, BCE loss: 0.534136, SB loss: 0.741514
2023-10-30 09:13:52,721 Epoch: [178/484] Iter:[340/495], Time: 0.37, lr: [0.006605567116241963], Loss: 2.042084, Acc:0.797968, Semantic loss: 0.765654, BCE loss: 0.535364, SB loss: 0.741067
2023-10-30 09:13:56,461 Epoch: [178/484] Iter:[350/495], Time: 0.37, lr: [0.00660517374430564], Loss: 2.042946, Acc:0.798746, Semantic loss: 0.765863, BCE loss: 0.536746, SB loss: 0.740338
2023-10-30 09:14:00,239 Epoch: [178/484] Iter:[360/495], Time: 0.37, lr: [0.006604780369766266], Loss: 2.042324, Acc:0.799641, Semantic loss: 0.764492, BCE loss: 0.537247, SB loss: 0.740585
2023-10-30 09:14:03,916 Epoch: [178/484] Iter:[370/495], Time: 0.37, lr: [0.006604386992623651], Loss: 2.044533, Acc:0.800043, Semantic loss: 0.766457, BCE loss: 0.537615, SB loss: 0.740461
2023-10-30 09:14:07,610 Epoch: [178/484] Iter:[380/495], Time: 0.37, lr: [0.006603993612877604], Loss: 2.045137, Acc:0.799908, Semantic loss: 0.766969, BCE loss: 0.537733, SB loss: 0.740436
2023-10-30 09:14:11,337 Epoch: [178/484] Iter:[390/495], Time: 0.37, lr: [0.006603600230527938], Loss: 2.043312, Acc:0.799986, Semantic loss: 0.765168, BCE loss: 0.537761, SB loss: 0.740384
2023-10-30 09:14:14,936 Epoch: [178/484] Iter:[400/495], Time: 0.37, lr: [0.006603206845574461], Loss: 2.048165, Acc:0.799198, Semantic loss: 0.769458, BCE loss: 0.536691, SB loss: 0.742016
2023-10-30 09:14:18,698 Epoch: [178/484] Iter:[410/495], Time: 0.37, lr: [0.0066028134580169845], Loss: 2.048098, Acc:0.799634, Semantic loss: 0.768195, BCE loss: 0.537512, SB loss: 0.742390
2023-10-30 09:14:22,313 Epoch: [178/484] Iter:[420/495], Time: 0.37, lr: [0.006602420067855318], Loss: 2.050870, Acc:0.799954, Semantic loss: 0.769060, BCE loss: 0.538184, SB loss: 0.743626
2023-10-30 09:14:26,241 Epoch: [178/484] Iter:[430/495], Time: 0.37, lr: [0.006602026675089271], Loss: 2.050163, Acc:0.799207, Semantic loss: 0.769350, BCE loss: 0.537937, SB loss: 0.742876
2023-10-30 09:14:29,933 Epoch: [178/484] Iter:[440/495], Time: 0.37, lr: [0.006601633279718657], Loss: 2.050046, Acc:0.800085, Semantic loss: 0.767913, BCE loss: 0.539226, SB loss: 0.742907
2023-10-30 09:14:33,635 Epoch: [178/484] Iter:[450/495], Time: 0.37, lr: [0.006601239881743283], Loss: 2.051867, Acc:0.800354, Semantic loss: 0.768914, BCE loss: 0.539468, SB loss: 0.743485
2023-10-30 09:14:37,308 Epoch: [178/484] Iter:[460/495], Time: 0.37, lr: [0.006600846481162962], Loss: 2.052182, Acc:0.800573, Semantic loss: 0.769419, BCE loss: 0.539348, SB loss: 0.743414
2023-10-30 09:14:40,987 Epoch: [178/484] Iter:[470/495], Time: 0.37, lr: [0.006600453077977504], Loss: 2.052872, Acc:0.800637, Semantic loss: 0.770207, BCE loss: 0.539478, SB loss: 0.743187
2023-10-30 09:14:44,672 Epoch: [178/484] Iter:[480/495], Time: 0.37, lr: [0.006600059672186717], Loss: 2.052999, Acc:0.799920, Semantic loss: 0.770479, BCE loss: 0.539206, SB loss: 0.743313
2023-10-30 09:14:48,358 Epoch: [178/484] Iter:[490/495], Time: 0.37, lr: [0.006599666263790413], Loss: 2.053097, Acc:0.800375, Semantic loss: 0.770466, BCE loss: 0.539153, SB loss: 0.743477
2023-10-30 09:14:49,780 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:14:50,019 Loss: 2.059, MeanIU:  0.6744, Best_mIoU:  0.6984
2023-10-30 09:14:50,020 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437]
2023-10-30 09:14:52,057 Epoch: [179/484] Iter:[0/495], Time: 2.00, lr: [0.006599469558615132], Loss: 2.133789, Acc:0.808743, Semantic loss: 1.032475, BCE loss: 0.293673, SB loss: 0.807640
2023-10-30 09:14:56,069 Epoch: [179/484] Iter:[10/495], Time: 0.55, lr: [0.006599076146310195], Loss: 2.108698, Acc:0.810297, Semantic loss: 0.808526, BCE loss: 0.550470, SB loss: 0.749702
2023-10-30 09:14:59,811 Epoch: [179/484] Iter:[20/495], Time: 0.46, lr: [0.006598682731399266], Loss: 2.057509, Acc:0.812346, Semantic loss: 0.771129, BCE loss: 0.566186, SB loss: 0.720195
2023-10-30 09:15:03,588 Epoch: [179/484] Iter:[30/495], Time: 0.44, lr: [0.006598289313882154], Loss: 2.089692, Acc:0.810815, Semantic loss: 0.804630, BCE loss: 0.551083, SB loss: 0.733979
2023-10-30 09:15:07,269 Epoch: [179/484] Iter:[40/495], Time: 0.42, lr: [0.0065978958937586716], Loss: 2.081160, Acc:0.811804, Semantic loss: 0.790068, BCE loss: 0.553458, SB loss: 0.737633
2023-10-30 09:15:10,934 Epoch: [179/484] Iter:[50/495], Time: 0.41, lr: [0.006597502471028627], Loss: 2.093197, Acc:0.813571, Semantic loss: 0.788508, BCE loss: 0.566839, SB loss: 0.737851
2023-10-30 09:15:14,555 Epoch: [179/484] Iter:[60/495], Time: 0.40, lr: [0.00659710904569183], Loss: 2.072204, Acc:0.808616, Semantic loss: 0.778443, BCE loss: 0.558152, SB loss: 0.735609
2023-10-30 09:15:18,198 Epoch: [179/484] Iter:[70/495], Time: 0.40, lr: [0.006596715617748093], Loss: 2.056197, Acc:0.808595, Semantic loss: 0.771662, BCE loss: 0.551690, SB loss: 0.732846
2023-10-30 09:15:21,913 Epoch: [179/484] Iter:[80/495], Time: 0.39, lr: [0.006596322187197222], Loss: 2.075619, Acc:0.808450, Semantic loss: 0.784166, BCE loss: 0.551429, SB loss: 0.740023
2023-10-30 09:15:25,548 Epoch: [179/484] Iter:[90/495], Time: 0.39, lr: [0.006595928754039029], Loss: 2.069247, Acc:0.803085, Semantic loss: 0.782703, BCE loss: 0.543329, SB loss: 0.743215
2023-10-30 09:15:29,308 Epoch: [179/484] Iter:[100/495], Time: 0.39, lr: [0.006595535318273324], Loss: 2.095017, Acc:0.804939, Semantic loss: 0.799864, BCE loss: 0.544623, SB loss: 0.750530
2023-10-30 09:15:32,941 Epoch: [179/484] Iter:[110/495], Time: 0.39, lr: [0.0065951418798999165], Loss: 2.082444, Acc:0.804650, Semantic loss: 0.791952, BCE loss: 0.542603, SB loss: 0.747889
2023-10-30 09:15:36,526 Epoch: [179/484] Iter:[120/495], Time: 0.38, lr: [0.006594748438918618], Loss: 2.078416, Acc:0.802356, Semantic loss: 0.790824, BCE loss: 0.540212, SB loss: 0.747381
2023-10-30 09:15:40,202 Epoch: [179/484] Iter:[130/495], Time: 0.38, lr: [0.006594354995329236], Loss: 2.081249, Acc:0.801116, Semantic loss: 0.792867, BCE loss: 0.539589, SB loss: 0.748794
2023-10-30 09:15:43,922 Epoch: [179/484] Iter:[140/495], Time: 0.38, lr: [0.006593961549131582], Loss: 2.069623, Acc:0.800582, Semantic loss: 0.786252, BCE loss: 0.536308, SB loss: 0.747063
2023-10-30 09:15:47,549 Epoch: [179/484] Iter:[150/495], Time: 0.38, lr: [0.006593568100325464], Loss: 2.076154, Acc:0.800899, Semantic loss: 0.790148, BCE loss: 0.536193, SB loss: 0.749813
2023-10-30 09:15:51,288 Epoch: [179/484] Iter:[160/495], Time: 0.38, lr: [0.006593174648910694], Loss: 2.065828, Acc:0.798479, Semantic loss: 0.782674, BCE loss: 0.533792, SB loss: 0.749362
2023-10-30 09:15:54,906 Epoch: [179/484] Iter:[170/495], Time: 0.38, lr: [0.006592781194887079], Loss: 2.067678, Acc:0.795302, Semantic loss: 0.785102, BCE loss: 0.531137, SB loss: 0.751438
2023-10-30 09:15:58,592 Epoch: [179/484] Iter:[180/495], Time: 0.38, lr: [0.0065923877382544314], Loss: 2.080277, Acc:0.795182, Semantic loss: 0.792903, BCE loss: 0.532390, SB loss: 0.754984
2023-10-30 09:16:02,213 Epoch: [179/484] Iter:[190/495], Time: 0.38, lr: [0.00659199427901256], Loss: 2.076711, Acc:0.796833, Semantic loss: 0.789443, BCE loss: 0.533086, SB loss: 0.754183
2023-10-30 09:16:05,933 Epoch: [179/484] Iter:[200/495], Time: 0.38, lr: [0.006591600817161274], Loss: 2.064266, Acc:0.794636, Semantic loss: 0.784476, BCE loss: 0.529293, SB loss: 0.750497
2023-10-30 09:16:09,601 Epoch: [179/484] Iter:[210/495], Time: 0.38, lr: [0.006591207352700384], Loss: 2.064920, Acc:0.794978, Semantic loss: 0.784296, BCE loss: 0.529861, SB loss: 0.750762
2023-10-30 09:16:13,236 Epoch: [179/484] Iter:[220/495], Time: 0.38, lr: [0.006590813885629697], Loss: 2.064355, Acc:0.795937, Semantic loss: 0.781954, BCE loss: 0.531799, SB loss: 0.750602
2023-10-30 09:16:16,978 Epoch: [179/484] Iter:[230/495], Time: 0.38, lr: [0.006590420415949027], Loss: 2.063461, Acc:0.796057, Semantic loss: 0.780990, BCE loss: 0.532218, SB loss: 0.750253
2023-10-30 09:16:20,724 Epoch: [179/484] Iter:[240/495], Time: 0.38, lr: [0.006590026943658178], Loss: 2.056940, Acc:0.795176, Semantic loss: 0.777463, BCE loss: 0.531115, SB loss: 0.748362
2023-10-30 09:16:24,409 Epoch: [179/484] Iter:[250/495], Time: 0.38, lr: [0.006589633468756964], Loss: 2.060153, Acc:0.794522, Semantic loss: 0.779352, BCE loss: 0.533170, SB loss: 0.747632
2023-10-30 09:16:28,077 Epoch: [179/484] Iter:[260/495], Time: 0.38, lr: [0.006589239991245193], Loss: 2.063606, Acc:0.794372, Semantic loss: 0.781056, BCE loss: 0.532716, SB loss: 0.749835
2023-10-30 09:16:31,943 Epoch: [179/484] Iter:[270/495], Time: 0.38, lr: [0.0065888465111226735], Loss: 2.064128, Acc:0.795487, Semantic loss: 0.779464, BCE loss: 0.535245, SB loss: 0.749419
2023-10-30 09:16:35,669 Epoch: [179/484] Iter:[280/495], Time: 0.38, lr: [0.006588453028389217], Loss: 2.067492, Acc:0.796409, Semantic loss: 0.779223, BCE loss: 0.537943, SB loss: 0.750327
2023-10-30 09:16:39,375 Epoch: [179/484] Iter:[290/495], Time: 0.38, lr: [0.006588059543044632], Loss: 2.068808, Acc:0.796255, Semantic loss: 0.779204, BCE loss: 0.539711, SB loss: 0.749893
2023-10-30 09:16:43,113 Epoch: [179/484] Iter:[300/495], Time: 0.38, lr: [0.006587666055088727], Loss: 2.071010, Acc:0.797361, Semantic loss: 0.779976, BCE loss: 0.541107, SB loss: 0.749928
2023-10-30 09:16:46,808 Epoch: [179/484] Iter:[310/495], Time: 0.38, lr: [0.006587272564521312], Loss: 2.067487, Acc:0.798495, Semantic loss: 0.777732, BCE loss: 0.541039, SB loss: 0.748715
2023-10-30 09:16:50,525 Epoch: [179/484] Iter:[320/495], Time: 0.38, lr: [0.006586879071342198], Loss: 2.069381, Acc:0.798961, Semantic loss: 0.778180, BCE loss: 0.543190, SB loss: 0.748011
2023-10-30 09:16:54,217 Epoch: [179/484] Iter:[330/495], Time: 0.38, lr: [0.00658648557555119], Loss: 2.071199, Acc:0.798752, Semantic loss: 0.779644, BCE loss: 0.543531, SB loss: 0.748024
2023-10-30 09:16:57,967 Epoch: [179/484] Iter:[340/495], Time: 0.38, lr: [0.006586092077148101], Loss: 2.074468, Acc:0.798505, Semantic loss: 0.780163, BCE loss: 0.545076, SB loss: 0.749230
2023-10-30 09:17:01,616 Epoch: [179/484] Iter:[350/495], Time: 0.37, lr: [0.00658569857613274], Loss: 2.082489, Acc:0.797147, Semantic loss: 0.785233, BCE loss: 0.546698, SB loss: 0.750557
2023-10-30 09:17:05,275 Epoch: [179/484] Iter:[360/495], Time: 0.37, lr: [0.006585305072504915], Loss: 2.084595, Acc:0.797121, Semantic loss: 0.786454, BCE loss: 0.547260, SB loss: 0.750881
2023-10-30 09:17:08,974 Epoch: [179/484] Iter:[370/495], Time: 0.37, lr: [0.006584911566264435], Loss: 2.089501, Acc:0.796354, Semantic loss: 0.788384, BCE loss: 0.548573, SB loss: 0.752544
2023-10-30 09:17:12,570 Epoch: [179/484] Iter:[380/495], Time: 0.37, lr: [0.006584518057411112], Loss: 2.093907, Acc:0.795453, Semantic loss: 0.790636, BCE loss: 0.549136, SB loss: 0.754135
2023-10-30 09:17:16,231 Epoch: [179/484] Iter:[390/495], Time: 0.37, lr: [0.006584124545944751], Loss: 2.095307, Acc:0.794268, Semantic loss: 0.792014, BCE loss: 0.547971, SB loss: 0.755322
2023-10-30 09:17:19,881 Epoch: [179/484] Iter:[400/495], Time: 0.37, lr: [0.006583731031865165], Loss: 2.095779, Acc:0.793437, Semantic loss: 0.791715, BCE loss: 0.548914, SB loss: 0.755150
2023-10-30 09:17:23,680 Epoch: [179/484] Iter:[410/495], Time: 0.37, lr: [0.006583337515172157], Loss: 2.095088, Acc:0.793856, Semantic loss: 0.791669, BCE loss: 0.548687, SB loss: 0.754733
2023-10-30 09:17:27,359 Epoch: [179/484] Iter:[420/495], Time: 0.37, lr: [0.006582943995865544], Loss: 2.098933, Acc:0.794592, Semantic loss: 0.793174, BCE loss: 0.549879, SB loss: 0.755880
2023-10-30 09:17:31,107 Epoch: [179/484] Iter:[430/495], Time: 0.37, lr: [0.006582550473945129], Loss: 2.098447, Acc:0.794900, Semantic loss: 0.791902, BCE loss: 0.550800, SB loss: 0.755744
2023-10-30 09:17:34,756 Epoch: [179/484] Iter:[440/495], Time: 0.37, lr: [0.006582156949410726], Loss: 2.099767, Acc:0.795194, Semantic loss: 0.792361, BCE loss: 0.551388, SB loss: 0.756018
2023-10-30 09:17:38,437 Epoch: [179/484] Iter:[450/495], Time: 0.37, lr: [0.006581763422262139], Loss: 2.098337, Acc:0.795767, Semantic loss: 0.791550, BCE loss: 0.551060, SB loss: 0.755728
2023-10-30 09:17:42,189 Epoch: [179/484] Iter:[460/495], Time: 0.37, lr: [0.006581369892499181], Loss: 2.100567, Acc:0.795410, Semantic loss: 0.792040, BCE loss: 0.551980, SB loss: 0.756547
2023-10-30 09:17:45,924 Epoch: [179/484] Iter:[470/495], Time: 0.37, lr: [0.006580976360121659], Loss: 2.102563, Acc:0.794628, Semantic loss: 0.793072, BCE loss: 0.552362, SB loss: 0.757129
2023-10-30 09:17:49,553 Epoch: [179/484] Iter:[480/495], Time: 0.37, lr: [0.0065805828251293795], Loss: 2.103819, Acc:0.794460, Semantic loss: 0.793032, BCE loss: 0.553560, SB loss: 0.757227
2023-10-30 09:17:53,168 Epoch: [179/484] Iter:[490/495], Time: 0.37, lr: [0.006580189287522157], Loss: 2.105018, Acc:0.794398, Semantic loss: 0.793636, BCE loss: 0.553922, SB loss: 0.757460
2023-10-30 09:17:54,570 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:17:54,807 Loss: 2.059, MeanIU:  0.6744, Best_mIoU:  0.6984
2023-10-30 09:17:54,807 [0.97392919 0.79864222 0.90749736 0.33820461 0.53089753 0.57761451
 0.65376511 0.74494033 0.90952306 0.59774521 0.93466919 0.71536056
 0.31219133 0.92291696 0.61987948 0.72408479 0.3818228  0.46806401
 0.70279437]
2023-10-30 09:17:56,990 Epoch: [180/484] Iter:[0/495], Time: 2.15, lr: [0.00657999251773788], Loss: 2.607971, Acc:0.741435, Semantic loss: 1.033005, BCE loss: 0.723044, SB loss: 0.851923
2023-10-30 09:18:01,038 Epoch: [180/484] Iter:[10/495], Time: 0.56, lr: [0.006579598976207879], Loss: 1.962157, Acc:0.792945, Semantic loss: 0.739701, BCE loss: 0.501530, SB loss: 0.720925
2023-10-30 09:18:04,763 Epoch: [180/484] Iter:[20/495], Time: 0.47, lr: [0.006579205432062455], Loss: 2.033348, Acc:0.820070, Semantic loss: 0.756674, BCE loss: 0.547690, SB loss: 0.728984
2023-10-30 09:18:08,404 Epoch: [180/484] Iter:[30/495], Time: 0.44, lr: [0.006578811885301414], Loss: 2.069378, Acc:0.805873, Semantic loss: 0.774654, BCE loss: 0.550059, SB loss: 0.744665
2023-10-30 09:18:12,096 Epoch: [180/484] Iter:[40/495], Time: 0.42, lr: [0.0065784183359245685], Loss: 2.057747, Acc:0.795865, Semantic loss: 0.772088, BCE loss: 0.537159, SB loss: 0.748500
2023-10-30 09:18:15,835 Epoch: [180/484] Iter:[50/495], Time: 0.41, lr: [0.006578024783931725], Loss: 2.038053, Acc:0.793044, Semantic loss: 0.755839, BCE loss: 0.532744, SB loss: 0.749470
2023-10-30 09:18:19,595 Epoch: [180/484] Iter:[60/495], Time: 0.41, lr: [0.006577631229322692], Loss: 2.058801, Acc:0.793687, Semantic loss: 0.768527, BCE loss: 0.541295, SB loss: 0.748980
2023-10-30 09:18:23,312 Epoch: [180/484] Iter:[70/495], Time: 0.40, lr: [0.0065772376720972785], Loss: 2.063931, Acc:0.792692, Semantic loss: 0.771806, BCE loss: 0.540949, SB loss: 0.751176
2023-10-30 09:18:26,963 Epoch: [180/484] Iter:[80/495], Time: 0.40, lr: [0.006576844112255294], Loss: 2.058309, Acc:0.790954, Semantic loss: 0.766540, BCE loss: 0.544347, SB loss: 0.747422
2023-10-30 09:18:30,746 Epoch: [180/484] Iter:[90/495], Time: 0.39, lr: [0.006576450549796545], Loss: 2.052298, Acc:0.790232, Semantic loss: 0.765566, BCE loss: 0.542880, SB loss: 0.743851
2023-10-30 09:18:34,473 Epoch: [180/484] Iter:[100/495], Time: 0.39, lr: [0.006576056984720843], Loss: 2.044851, Acc:0.796087, Semantic loss: 0.764381, BCE loss: 0.536968, SB loss: 0.743502
2023-10-30 09:18:38,211 Epoch: [180/484] Iter:[110/495], Time: 0.39, lr: [0.006575663417027995], Loss: 2.048586, Acc:0.797199, Semantic loss: 0.767930, BCE loss: 0.536162, SB loss: 0.744494
2023-10-30 09:18:41,873 Epoch: [180/484] Iter:[120/495], Time: 0.39, lr: [0.00657526984671781], Loss: 2.064230, Acc:0.798798, Semantic loss: 0.777200, BCE loss: 0.539749, SB loss: 0.747281
2023-10-30 09:18:45,623 Epoch: [180/484] Iter:[130/495], Time: 0.39, lr: [0.006574876273790097], Loss: 2.059539, Acc:0.795556, Semantic loss: 0.773158, BCE loss: 0.539400, SB loss: 0.746982
2023-10-30 09:18:49,341 Epoch: [180/484] Iter:[140/495], Time: 0.39, lr: [0.006574482698244663], Loss: 2.063416, Acc:0.794637, Semantic loss: 0.775023, BCE loss: 0.538665, SB loss: 0.749728
2023-10-30 09:18:52,993 Epoch: [180/484] Iter:[150/495], Time: 0.39, lr: [0.0065740891200813155], Loss: 2.081433, Acc:0.794706, Semantic loss: 0.786354, BCE loss: 0.540447, SB loss: 0.754633
2023-10-30 09:18:56,695 Epoch: [180/484] Iter:[160/495], Time: 0.38, lr: [0.006573695539299866], Loss: 2.088813, Acc:0.795231, Semantic loss: 0.793039, BCE loss: 0.542118, SB loss: 0.753656
2023-10-30 09:19:00,362 Epoch: [180/484] Iter:[170/495], Time: 0.38, lr: [0.006573301955900121], Loss: 2.079851, Acc:0.797065, Semantic loss: 0.784046, BCE loss: 0.541658, SB loss: 0.754147
2023-10-30 09:19:04,166 Epoch: [180/484] Iter:[180/495], Time: 0.38, lr: [0.006572908369881891], Loss: 2.072604, Acc:0.796225, Semantic loss: 0.779866, BCE loss: 0.538702, SB loss: 0.754036
2023-10-30 09:19:07,927 Epoch: [180/484] Iter:[190/495], Time: 0.38, lr: [0.0065725147812449826], Loss: 2.071317, Acc:0.797038, Semantic loss: 0.779311, BCE loss: 0.539467, SB loss: 0.752539
2023-10-30 09:19:11,694 Epoch: [180/484] Iter:[200/495], Time: 0.38, lr: [0.006572121189989204], Loss: 2.074008, Acc:0.796766, Semantic loss: 0.780219, BCE loss: 0.540466, SB loss: 0.753323
2023-10-30 09:19:15,341 Epoch: [180/484] Iter:[210/495], Time: 0.38, lr: [0.006571727596114364], Loss: 2.072720, Acc:0.796552, Semantic loss: 0.779490, BCE loss: 0.539466, SB loss: 0.753764
2023-10-30 09:19:18,986 Epoch: [180/484] Iter:[220/495], Time: 0.38, lr: [0.0065713339996202715], Loss: 2.074796, Acc:0.798476, Semantic loss: 0.779448, BCE loss: 0.542587, SB loss: 0.752761
2023-10-30 09:19:22,680 Epoch: [180/484] Iter:[230/495], Time: 0.38, lr: [0.006570940400506732], Loss: 2.071221, Acc:0.798255, Semantic loss: 0.779693, BCE loss: 0.539961, SB loss: 0.751566
2023-10-30 09:19:26,287 Epoch: [180/484] Iter:[240/495], Time: 0.38, lr: [0.006570546798773557], Loss: 2.072921, Acc:0.797336, Semantic loss: 0.781275, BCE loss: 0.539377, SB loss: 0.752269
2023-10-30 09:19:30,149 Epoch: [180/484] Iter:[250/495], Time: 0.38, lr: [0.006570153194420553], Loss: 2.068919, Acc:0.797905, Semantic loss: 0.778939, BCE loss: 0.538567, SB loss: 0.751414
2023-10-30 09:19:33,862 Epoch: [180/484] Iter:[260/495], Time: 0.38, lr: [0.0065697595874475295], Loss: 2.061155, Acc:0.797596, Semantic loss: 0.776264, BCE loss: 0.534295, SB loss: 0.750595
2023-10-30 09:19:37,611 Epoch: [180/484] Iter:[270/495], Time: 0.38, lr: [0.006569365977854292], Loss: 2.070357, Acc:0.796716, Semantic loss: 0.782345, BCE loss: 0.535111, SB loss: 0.752900
2023-10-30 09:19:41,400 Epoch: [180/484] Iter:[280/495], Time: 0.38, lr: [0.006568972365640652], Loss: 2.068025, Acc:0.796779, Semantic loss: 0.779648, BCE loss: 0.536300, SB loss: 0.752077
2023-10-30 09:19:45,179 Epoch: [180/484] Iter:[290/495], Time: 0.38, lr: [0.0065685787508064164], Loss: 2.070144, Acc:0.797072, Semantic loss: 0.781745, BCE loss: 0.535803, SB loss: 0.752595
2023-10-30 09:19:48,796 Epoch: [180/484] Iter:[300/495], Time: 0.38, lr: [0.0065681851333513905], Loss: 2.076723, Acc:0.796524, Semantic loss: 0.785466, BCE loss: 0.536090, SB loss: 0.755167
2023-10-30 09:19:52,407 Epoch: [180/484] Iter:[310/495], Time: 0.38, lr: [0.0065677915132753865], Loss: 2.069359, Acc:0.797655, Semantic loss: 0.781280, BCE loss: 0.534833, SB loss: 0.753246
2023-10-30 09:19:56,121 Epoch: [180/484] Iter:[320/495], Time: 0.38, lr: [0.006567397890578209], Loss: 2.070912, Acc:0.797731, Semantic loss: 0.783297, BCE loss: 0.533823, SB loss: 0.753792
2023-10-30 09:19:59,787 Epoch: [180/484] Iter:[330/495], Time: 0.38, lr: [0.00656700426525967], Loss: 2.073073, Acc:0.797272, Semantic loss: 0.783700, BCE loss: 0.535674, SB loss: 0.753699
2023-10-30 09:20:03,480 Epoch: [180/484] Iter:[340/495], Time: 0.38, lr: [0.0065666106373195735], Loss: 2.068108, Acc:0.797089, Semantic loss: 0.780265, BCE loss: 0.535922, SB loss: 0.751921
2023-10-30 09:20:07,160 Epoch: [180/484] Iter:[350/495], Time: 0.38, lr: [0.00656621700675773], Loss: 2.071607, Acc:0.798070, Semantic loss: 0.780958, BCE loss: 0.537732, SB loss: 0.752917
2023-10-30 09:20:11,013 Epoch: [180/484] Iter:[360/495], Time: 0.38, lr: [0.0065658233735739445], Loss: 2.067658, Acc:0.798900, Semantic loss: 0.778460, BCE loss: 0.536930, SB loss: 0.752268
2023-10-30 09:20:14,722 Epoch: [180/484] Iter:[370/495], Time: 0.38, lr: [0.006565429737768028], Loss: 2.070278, Acc:0.798499, Semantic loss: 0.780757, BCE loss: 0.537180, SB loss: 0.752341
2023-10-30 09:20:18,366 Epoch: [180/484] Iter:[380/495], Time: 0.38, lr: [0.006565036099339786], Loss: 2.070156, Acc:0.799103, Semantic loss: 0.779079, BCE loss: 0.539526, SB loss: 0.751550
2023-10-30 09:20:21,984 Epoch: [180/484] Iter:[390/495], Time: 0.38, lr: [0.00656464245828903], Loss: 2.073481, Acc:0.798214, Semantic loss: 0.780355, BCE loss: 0.539507, SB loss: 0.753619
2023-10-30 09:20:25,680 Epoch: [180/484] Iter:[400/495], Time: 0.38, lr: [0.0065642488146155625], Loss: 2.074694, Acc:0.797364, Semantic loss: 0.780402, BCE loss: 0.539397, SB loss: 0.754896
2023-10-30 09:20:29,366 Epoch: [180/484] Iter:[410/495], Time: 0.38, lr: [0.006563855168319195], Loss: 2.074205, Acc:0.796201, Semantic loss: 0.780608, BCE loss: 0.538578, SB loss: 0.755019
2023-10-30 09:20:33,115 Epoch: [180/484] Iter:[420/495], Time: 0.38, lr: [0.006563461519399734], Loss: 2.074259, Acc:0.795665, Semantic loss: 0.780555, BCE loss: 0.538972, SB loss: 0.754732
2023-10-30 09:20:36,799 Epoch: [180/484] Iter:[430/495], Time: 0.38, lr: [0.006563067867856987], Loss: 2.075687, Acc:0.795998, Semantic loss: 0.782165, BCE loss: 0.538423, SB loss: 0.755098
2023-10-30 09:20:40,491 Epoch: [180/484] Iter:[440/495], Time: 0.38, lr: [0.006562674213690764], Loss: 2.081965, Acc:0.796055, Semantic loss: 0.786524, BCE loss: 0.538598, SB loss: 0.756843
2023-10-30 09:20:44,151 Epoch: [180/484] Iter:[450/495], Time: 0.38, lr: [0.006562280556900869], Loss: 2.084613, Acc:0.796441, Semantic loss: 0.787473, BCE loss: 0.539583, SB loss: 0.757557
2023-10-30 09:20:47,822 Epoch: [180/484] Iter:[460/495], Time: 0.38, lr: [0.006561886897487112], Loss: 2.083033, Acc:0.796457, Semantic loss: 0.786441, BCE loss: 0.539369, SB loss: 0.757222
2023-10-30 09:20:51,565 Epoch: [180/484] Iter:[470/495], Time: 0.38, lr: [0.0065614932354493005], Loss: 2.086366, Acc:0.795608, Semantic loss: 0.788135, BCE loss: 0.540132, SB loss: 0.758099
2023-10-30 09:20:55,227 Epoch: [180/484] Iter:[480/495], Time: 0.38, lr: [0.00656109957078724], Loss: 2.083247, Acc:0.795144, Semantic loss: 0.786294, BCE loss: 0.539426, SB loss: 0.757527
2023-10-30 09:20:58,787 Epoch: [180/484] Iter:[490/495], Time: 0.37, lr: [0.006560705903500741], Loss: 2.086306, Acc:0.795618, Semantic loss: 0.786973, BCE loss: 0.542116, SB loss: 0.757218
2023-10-30 09:23:55,459 0 [9.28309934e-01 6.39908692e-01 7.96894240e-01 1.48425595e-01
 2.01506954e-01 3.72914186e-01 4.12292457e-01 5.02217842e-01
 8.68902734e-01 3.22428971e-01 7.60601449e-01 5.40251929e-01
 9.49102140e-03 7.71575239e-01 3.11323036e-05 4.36305287e-02
 2.06858369e-02 3.67614492e-02 5.75362036e-01] 0.418536433009408
2023-10-30 09:23:55,459 1 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524] 0.6486621531993946
2023-10-30 09:23:55,463 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:23:55,700 Loss: 2.136, MeanIU:  0.6487, Best_mIoU:  0.6984
2023-10-30 09:23:55,700 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524]
2023-10-30 09:23:57,801 Epoch: [181/484] Iter:[0/495], Time: 2.07, lr: [0.006560509068873266], Loss: 1.867240, Acc:0.877104, Semantic loss: 0.604706, BCE loss: 0.605573, SB loss: 0.656962
2023-10-30 09:24:01,585 Epoch: [181/484] Iter:[10/495], Time: 0.53, lr: [0.006560115397649747], Loss: 2.149742, Acc:0.797406, Semantic loss: 0.820477, BCE loss: 0.549057, SB loss: 0.780208
2023-10-30 09:24:05,217 Epoch: [181/484] Iter:[20/495], Time: 0.45, lr: [0.006559721723801306], Loss: 2.166818, Acc:0.788343, Semantic loss: 0.860483, BCE loss: 0.538147, SB loss: 0.768189
2023-10-30 09:24:08,753 Epoch: [181/484] Iter:[30/495], Time: 0.42, lr: [0.006559328047327752], Loss: 2.260385, Acc:0.796063, Semantic loss: 0.912099, BCE loss: 0.559971, SB loss: 0.788315
2023-10-30 09:24:12,309 Epoch: [181/484] Iter:[40/495], Time: 0.40, lr: [0.006558934368228892], Loss: 2.246928, Acc:0.798573, Semantic loss: 0.889534, BCE loss: 0.564178, SB loss: 0.793217
2023-10-30 09:24:15,865 Epoch: [181/484] Iter:[50/495], Time: 0.39, lr: [0.006558540686504532], Loss: 2.281136, Acc:0.797641, Semantic loss: 0.897793, BCE loss: 0.574379, SB loss: 0.808963
2023-10-30 09:24:19,432 Epoch: [181/484] Iter:[60/495], Time: 0.39, lr: [0.006558147002154481], Loss: 2.263045, Acc:0.791148, Semantic loss: 0.882884, BCE loss: 0.571360, SB loss: 0.808800
2023-10-30 09:24:22,976 Epoch: [181/484] Iter:[70/495], Time: 0.38, lr: [0.006557753315178545], Loss: 2.246932, Acc:0.792364, Semantic loss: 0.877504, BCE loss: 0.561283, SB loss: 0.808144
2023-10-30 09:24:26,612 Epoch: [181/484] Iter:[80/495], Time: 0.38, lr: [0.006557359625576534], Loss: 2.226444, Acc:0.796908, Semantic loss: 0.862586, BCE loss: 0.560957, SB loss: 0.802901
2023-10-30 09:24:30,176 Epoch: [181/484] Iter:[90/495], Time: 0.38, lr: [0.006556965933348253], Loss: 2.236521, Acc:0.798000, Semantic loss: 0.864907, BCE loss: 0.570487, SB loss: 0.801128
2023-10-30 09:24:33,769 Epoch: [181/484] Iter:[100/495], Time: 0.38, lr: [0.00655657223849351], Loss: 2.205156, Acc:0.797026, Semantic loss: 0.846939, BCE loss: 0.564511, SB loss: 0.793706
2023-10-30 09:24:37,312 Epoch: [181/484] Iter:[110/495], Time: 0.37, lr: [0.006556178541012112], Loss: 2.189780, Acc:0.796292, Semantic loss: 0.839699, BCE loss: 0.559130, SB loss: 0.790952
2023-10-30 09:24:41,011 Epoch: [181/484] Iter:[120/495], Time: 0.37, lr: [0.006555784840903866], Loss: 2.179180, Acc:0.794338, Semantic loss: 0.832466, BCE loss: 0.559711, SB loss: 0.787003
2023-10-30 09:24:44,580 Epoch: [181/484] Iter:[130/495], Time: 0.37, lr: [0.0065553911381685806], Loss: 2.168262, Acc:0.794138, Semantic loss: 0.827846, BCE loss: 0.556628, SB loss: 0.783788
2023-10-30 09:24:48,291 Epoch: [181/484] Iter:[140/495], Time: 0.37, lr: [0.00655499743280606], Loss: 2.174974, Acc:0.794104, Semantic loss: 0.832915, BCE loss: 0.555489, SB loss: 0.786571
2023-10-30 09:24:51,884 Epoch: [181/484] Iter:[150/495], Time: 0.37, lr: [0.006554603724816114], Loss: 2.175953, Acc:0.792410, Semantic loss: 0.832964, BCE loss: 0.555091, SB loss: 0.787898
2023-10-30 09:24:55,435 Epoch: [181/484] Iter:[160/495], Time: 0.37, lr: [0.00655421001419855], Loss: 2.168755, Acc:0.795252, Semantic loss: 0.826408, BCE loss: 0.558069, SB loss: 0.784278
2023-10-30 09:24:58,942 Epoch: [181/484] Iter:[170/495], Time: 0.37, lr: [0.0065538163009531735], Loss: 2.161729, Acc:0.794827, Semantic loss: 0.823102, BCE loss: 0.557087, SB loss: 0.781540
2023-10-30 09:25:02,516 Epoch: [181/484] Iter:[180/495], Time: 0.37, lr: [0.0065534225850797925], Loss: 2.160579, Acc:0.794415, Semantic loss: 0.824259, BCE loss: 0.552274, SB loss: 0.784047
2023-10-30 09:25:06,192 Epoch: [181/484] Iter:[190/495], Time: 0.37, lr: [0.006553028866578213], Loss: 2.152321, Acc:0.794499, Semantic loss: 0.820148, BCE loss: 0.550056, SB loss: 0.782116
2023-10-30 09:25:09,861 Epoch: [181/484] Iter:[200/495], Time: 0.37, lr: [0.006552635145448241], Loss: 2.149540, Acc:0.795486, Semantic loss: 0.817711, BCE loss: 0.551333, SB loss: 0.780496
2023-10-30 09:25:13,563 Epoch: [181/484] Iter:[210/495], Time: 0.37, lr: [0.006552241421689688], Loss: 2.146740, Acc:0.795824, Semantic loss: 0.818219, BCE loss: 0.549966, SB loss: 0.778555
2023-10-30 09:25:17,239 Epoch: [181/484] Iter:[220/495], Time: 0.37, lr: [0.006551847695302355], Loss: 2.140600, Acc:0.795520, Semantic loss: 0.815743, BCE loss: 0.549208, SB loss: 0.775649
2023-10-30 09:25:20,861 Epoch: [181/484] Iter:[230/495], Time: 0.37, lr: [0.006551453966286054], Loss: 2.143197, Acc:0.794364, Semantic loss: 0.819124, BCE loss: 0.548261, SB loss: 0.775812
2023-10-30 09:25:24,629 Epoch: [181/484] Iter:[240/495], Time: 0.37, lr: [0.006551060234640589], Loss: 2.141140, Acc:0.794085, Semantic loss: 0.818481, BCE loss: 0.547134, SB loss: 0.775525
2023-10-30 09:25:28,313 Epoch: [181/484] Iter:[250/495], Time: 0.37, lr: [0.006550666500365768], Loss: 2.149166, Acc:0.793921, Semantic loss: 0.824166, BCE loss: 0.546526, SB loss: 0.778475
2023-10-30 09:25:31,992 Epoch: [181/484] Iter:[260/495], Time: 0.37, lr: [0.006550272763461399], Loss: 2.154383, Acc:0.794272, Semantic loss: 0.826297, BCE loss: 0.550303, SB loss: 0.777783
2023-10-30 09:25:35,590 Epoch: [181/484] Iter:[270/495], Time: 0.37, lr: [0.006549879023927285], Loss: 2.148073, Acc:0.794000, Semantic loss: 0.822140, BCE loss: 0.549146, SB loss: 0.776787
2023-10-30 09:25:39,211 Epoch: [181/484] Iter:[280/495], Time: 0.37, lr: [0.006549485281763236], Loss: 2.144882, Acc:0.793427, Semantic loss: 0.818576, BCE loss: 0.550131, SB loss: 0.776175
2023-10-30 09:25:42,904 Epoch: [181/484] Iter:[290/495], Time: 0.37, lr: [0.006549091536969059], Loss: 2.142090, Acc:0.794139, Semantic loss: 0.815995, BCE loss: 0.551959, SB loss: 0.774135
2023-10-30 09:25:46,607 Epoch: [181/484] Iter:[300/495], Time: 0.37, lr: [0.0065486977895445565], Loss: 2.138439, Acc:0.794610, Semantic loss: 0.814584, BCE loss: 0.550270, SB loss: 0.773586
2023-10-30 09:25:50,247 Epoch: [181/484] Iter:[310/495], Time: 0.37, lr: [0.006548304039489541], Loss: 2.140271, Acc:0.793362, Semantic loss: 0.815940, BCE loss: 0.550916, SB loss: 0.773415
2023-10-30 09:25:53,963 Epoch: [181/484] Iter:[320/495], Time: 0.37, lr: [0.0065479102868038165], Loss: 2.139433, Acc:0.793538, Semantic loss: 0.814528, BCE loss: 0.551642, SB loss: 0.773263
2023-10-30 09:25:57,681 Epoch: [181/484] Iter:[330/495], Time: 0.37, lr: [0.006547516531487189], Loss: 2.135321, Acc:0.793373, Semantic loss: 0.811154, BCE loss: 0.552634, SB loss: 0.771533
2023-10-30 09:26:01,334 Epoch: [181/484] Iter:[340/495], Time: 0.37, lr: [0.006547122773539466], Loss: 2.135100, Acc:0.794742, Semantic loss: 0.810765, BCE loss: 0.553007, SB loss: 0.771328
2023-10-30 09:26:04,941 Epoch: [181/484] Iter:[350/495], Time: 0.37, lr: [0.006546729012960454], Loss: 2.135412, Acc:0.795170, Semantic loss: 0.811236, BCE loss: 0.553088, SB loss: 0.771088
2023-10-30 09:26:08,622 Epoch: [181/484] Iter:[360/495], Time: 0.37, lr: [0.006546335249749958], Loss: 2.136240, Acc:0.795559, Semantic loss: 0.810884, BCE loss: 0.553476, SB loss: 0.771880
2023-10-30 09:26:12,272 Epoch: [181/484] Iter:[370/495], Time: 0.37, lr: [0.006545941483907787], Loss: 2.142905, Acc:0.794058, Semantic loss: 0.817091, BCE loss: 0.552159, SB loss: 0.773655
2023-10-30 09:26:15,862 Epoch: [181/484] Iter:[380/495], Time: 0.37, lr: [0.006545547715433746], Loss: 2.140691, Acc:0.793750, Semantic loss: 0.817597, BCE loss: 0.549954, SB loss: 0.773141
2023-10-30 09:26:19,515 Epoch: [181/484] Iter:[390/495], Time: 0.37, lr: [0.006545153944327643], Loss: 2.138815, Acc:0.794453, Semantic loss: 0.816439, BCE loss: 0.549763, SB loss: 0.772613
2023-10-30 09:26:23,186 Epoch: [181/484] Iter:[400/495], Time: 0.37, lr: [0.0065447601705892824], Loss: 2.138718, Acc:0.793746, Semantic loss: 0.815836, BCE loss: 0.550363, SB loss: 0.772519
2023-10-30 09:26:26,936 Epoch: [181/484] Iter:[410/495], Time: 0.37, lr: [0.006544366394218473], Loss: 2.138870, Acc:0.793637, Semantic loss: 0.815765, BCE loss: 0.550740, SB loss: 0.772365
2023-10-30 09:26:30,615 Epoch: [181/484] Iter:[420/495], Time: 0.37, lr: [0.006543972615215019], Loss: 2.139330, Acc:0.793973, Semantic loss: 0.817085, BCE loss: 0.550535, SB loss: 0.771709
2023-10-30 09:26:34,278 Epoch: [181/484] Iter:[430/495], Time: 0.37, lr: [0.006543578833578728], Loss: 2.138740, Acc:0.793675, Semantic loss: 0.817106, BCE loss: 0.549794, SB loss: 0.771841
2023-10-30 09:26:37,990 Epoch: [181/484] Iter:[440/495], Time: 0.37, lr: [0.006543185049309405], Loss: 2.136344, Acc:0.793357, Semantic loss: 0.815022, BCE loss: 0.549868, SB loss: 0.771454
2023-10-30 09:26:41,658 Epoch: [181/484] Iter:[450/495], Time: 0.37, lr: [0.006542791262406858], Loss: 2.132347, Acc:0.793281, Semantic loss: 0.813042, BCE loss: 0.548768, SB loss: 0.770537
2023-10-30 09:26:45,351 Epoch: [181/484] Iter:[460/495], Time: 0.37, lr: [0.006542397472870891], Loss: 2.131887, Acc:0.793804, Semantic loss: 0.812588, BCE loss: 0.548850, SB loss: 0.770450
2023-10-30 09:26:49,023 Epoch: [181/484] Iter:[470/495], Time: 0.37, lr: [0.006542003680701314], Loss: 2.132839, Acc:0.793974, Semantic loss: 0.812981, BCE loss: 0.549063, SB loss: 0.770796
2023-10-30 09:26:52,729 Epoch: [181/484] Iter:[480/495], Time: 0.37, lr: [0.006541609885897931], Loss: 2.127654, Acc:0.793370, Semantic loss: 0.810209, BCE loss: 0.547886, SB loss: 0.769559
2023-10-30 09:26:56,222 Epoch: [181/484] Iter:[490/495], Time: 0.37, lr: [0.006541216088460548], Loss: 2.127747, Acc:0.792962, Semantic loss: 0.811067, BCE loss: 0.547576, SB loss: 0.769104
2023-10-30 09:26:57,622 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:26:57,870 Loss: 2.136, MeanIU:  0.6487, Best_mIoU:  0.6984
2023-10-30 09:26:57,870 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524]
2023-10-30 09:26:59,996 Epoch: [182/484] Iter:[0/495], Time: 2.09, lr: [0.006541019188754046], Loss: 1.622332, Acc:0.772253, Semantic loss: 0.665297, BCE loss: 0.331694, SB loss: 0.625341
2023-10-30 09:27:03,938 Epoch: [182/484] Iter:[10/495], Time: 0.55, lr: [0.0065406253873653], Loss: 2.005960, Acc:0.815121, Semantic loss: 0.766094, BCE loss: 0.500276, SB loss: 0.739591
2023-10-30 09:27:07,637 Epoch: [182/484] Iter:[20/495], Time: 0.46, lr: [0.006540231583342069], Loss: 2.084203, Acc:0.800336, Semantic loss: 0.815980, BCE loss: 0.509393, SB loss: 0.758830
2023-10-30 09:27:11,248 Epoch: [182/484] Iter:[30/495], Time: 0.43, lr: [0.006539837776684161], Loss: 2.128500, Acc:0.803023, Semantic loss: 0.822709, BCE loss: 0.535494, SB loss: 0.770297
2023-10-30 09:27:14,882 Epoch: [182/484] Iter:[40/495], Time: 0.41, lr: [0.0065394439673913795], Loss: 2.122337, Acc:0.806744, Semantic loss: 0.803618, BCE loss: 0.549600, SB loss: 0.769119
2023-10-30 09:27:18,514 Epoch: [182/484] Iter:[50/495], Time: 0.40, lr: [0.006539050155463533], Loss: 2.089718, Acc:0.808367, Semantic loss: 0.785664, BCE loss: 0.550027, SB loss: 0.754027
2023-10-30 09:27:22,245 Epoch: [182/484] Iter:[60/495], Time: 0.40, lr: [0.006538656340900427], Loss: 2.092687, Acc:0.811245, Semantic loss: 0.781398, BCE loss: 0.558207, SB loss: 0.753083
2023-10-30 09:27:25,896 Epoch: [182/484] Iter:[70/495], Time: 0.39, lr: [0.006538262523701867], Loss: 2.080812, Acc:0.811354, Semantic loss: 0.775055, BCE loss: 0.556537, SB loss: 0.749220
2023-10-30 09:27:29,589 Epoch: [182/484] Iter:[80/495], Time: 0.39, lr: [0.006537868703867659], Loss: 2.077153, Acc:0.810138, Semantic loss: 0.775405, BCE loss: 0.551668, SB loss: 0.750080
2023-10-30 09:27:33,269 Epoch: [182/484] Iter:[90/495], Time: 0.39, lr: [0.006537474881397609], Loss: 2.060713, Acc:0.806231, Semantic loss: 0.768292, BCE loss: 0.546549, SB loss: 0.745872
2023-10-30 09:27:36,956 Epoch: [182/484] Iter:[100/495], Time: 0.39, lr: [0.006537081056291522], Loss: 2.049964, Acc:0.804891, Semantic loss: 0.765497, BCE loss: 0.539200, SB loss: 0.745267
2023-10-30 09:27:40,593 Epoch: [182/484] Iter:[110/495], Time: 0.38, lr: [0.006536687228549205], Loss: 2.049507, Acc:0.804159, Semantic loss: 0.765421, BCE loss: 0.539651, SB loss: 0.744434
2023-10-30 09:27:44,268 Epoch: [182/484] Iter:[120/495], Time: 0.38, lr: [0.006536293398170464], Loss: 2.047449, Acc:0.802565, Semantic loss: 0.763642, BCE loss: 0.539523, SB loss: 0.744284
2023-10-30 09:27:47,888 Epoch: [182/484] Iter:[130/495], Time: 0.38, lr: [0.0065358995651551045], Loss: 2.048293, Acc:0.802212, Semantic loss: 0.763691, BCE loss: 0.540075, SB loss: 0.744527
2023-10-30 09:27:51,521 Epoch: [182/484] Iter:[140/495], Time: 0.38, lr: [0.006535505729502933], Loss: 2.059351, Acc:0.799770, Semantic loss: 0.769422, BCE loss: 0.542049, SB loss: 0.747879
2023-10-30 09:27:55,196 Epoch: [182/484] Iter:[150/495], Time: 0.38, lr: [0.006535111891213755], Loss: 2.058918, Acc:0.799418, Semantic loss: 0.771669, BCE loss: 0.541774, SB loss: 0.745475
2023-10-30 09:27:58,843 Epoch: [182/484] Iter:[160/495], Time: 0.38, lr: [0.006534718050287375], Loss: 2.055753, Acc:0.798324, Semantic loss: 0.769249, BCE loss: 0.540362, SB loss: 0.746142
2023-10-30 09:28:02,616 Epoch: [182/484] Iter:[170/495], Time: 0.38, lr: [0.006534324206723601], Loss: 2.051161, Acc:0.797222, Semantic loss: 0.766313, BCE loss: 0.539637, SB loss: 0.745212
2023-10-30 09:28:06,238 Epoch: [182/484] Iter:[180/495], Time: 0.38, lr: [0.006533930360522235], Loss: 2.056676, Acc:0.796490, Semantic loss: 0.771588, BCE loss: 0.538625, SB loss: 0.746463
2023-10-30 09:28:09,908 Epoch: [182/484] Iter:[190/495], Time: 0.38, lr: [0.006533536511683086], Loss: 2.051171, Acc:0.795619, Semantic loss: 0.769793, BCE loss: 0.536897, SB loss: 0.744481
2023-10-30 09:28:13,613 Epoch: [182/484] Iter:[200/495], Time: 0.38, lr: [0.006533142660205958], Loss: 2.054713, Acc:0.795999, Semantic loss: 0.770594, BCE loss: 0.537481, SB loss: 0.746638
2023-10-30 09:28:17,422 Epoch: [182/484] Iter:[210/495], Time: 0.38, lr: [0.006532748806090659], Loss: 2.058525, Acc:0.797957, Semantic loss: 0.770707, BCE loss: 0.539707, SB loss: 0.748112
2023-10-30 09:28:21,180 Epoch: [182/484] Iter:[220/495], Time: 0.38, lr: [0.0065323549493369925], Loss: 2.065242, Acc:0.798823, Semantic loss: 0.773918, BCE loss: 0.542522, SB loss: 0.748802
2023-10-30 09:28:24,865 Epoch: [182/484] Iter:[230/495], Time: 0.38, lr: [0.0065319610899447645], Loss: 2.068856, Acc:0.799082, Semantic loss: 0.776017, BCE loss: 0.542846, SB loss: 0.749993
2023-10-30 09:28:28,527 Epoch: [182/484] Iter:[240/495], Time: 0.38, lr: [0.00653156722791378], Loss: 2.062339, Acc:0.800243, Semantic loss: 0.771014, BCE loss: 0.542530, SB loss: 0.748795
2023-10-30 09:28:32,200 Epoch: [182/484] Iter:[250/495], Time: 0.38, lr: [0.006531173363243846], Loss: 2.060572, Acc:0.800751, Semantic loss: 0.769815, BCE loss: 0.543615, SB loss: 0.747142
2023-10-30 09:28:35,954 Epoch: [182/484] Iter:[260/495], Time: 0.38, lr: [0.006530779495934767], Loss: 2.059872, Acc:0.801280, Semantic loss: 0.769060, BCE loss: 0.544288, SB loss: 0.746524
2023-10-30 09:28:39,632 Epoch: [182/484] Iter:[270/495], Time: 0.38, lr: [0.006530385625986347], Loss: 2.062046, Acc:0.801900, Semantic loss: 0.769433, BCE loss: 0.546479, SB loss: 0.746135
2023-10-30 09:28:43,274 Epoch: [182/484] Iter:[280/495], Time: 0.37, lr: [0.006529991753398393], Loss: 2.058412, Acc:0.801015, Semantic loss: 0.767900, BCE loss: 0.545759, SB loss: 0.744752
2023-10-30 09:28:46,990 Epoch: [182/484] Iter:[290/495], Time: 0.37, lr: [0.006529597878170712], Loss: 2.056884, Acc:0.801366, Semantic loss: 0.768089, BCE loss: 0.544362, SB loss: 0.744433
2023-10-30 09:28:50,655 Epoch: [182/484] Iter:[300/495], Time: 0.37, lr: [0.006529204000303108], Loss: 2.052364, Acc:0.801527, Semantic loss: 0.765629, BCE loss: 0.543446, SB loss: 0.743289
2023-10-30 09:28:54,379 Epoch: [182/484] Iter:[310/495], Time: 0.37, lr: [0.006528810119795385], Loss: 2.054636, Acc:0.800556, Semantic loss: 0.766133, BCE loss: 0.545572, SB loss: 0.742931
2023-10-30 09:28:58,173 Epoch: [182/484] Iter:[320/495], Time: 0.37, lr: [0.00652841623664735], Loss: 2.053012, Acc:0.800224, Semantic loss: 0.765140, BCE loss: 0.545271, SB loss: 0.742601
2023-10-30 09:29:01,915 Epoch: [182/484] Iter:[330/495], Time: 0.37, lr: [0.006528022350858808], Loss: 2.050640, Acc:0.800985, Semantic loss: 0.763732, BCE loss: 0.544654, SB loss: 0.742253
2023-10-30 09:29:05,598 Epoch: [182/484] Iter:[340/495], Time: 0.37, lr: [0.006527628462429562], Loss: 2.051872, Acc:0.801202, Semantic loss: 0.764608, BCE loss: 0.544753, SB loss: 0.742512
2023-10-30 09:29:09,323 Epoch: [182/484] Iter:[350/495], Time: 0.37, lr: [0.006527234571359421], Loss: 2.048061, Acc:0.800231, Semantic loss: 0.763276, BCE loss: 0.543008, SB loss: 0.741777
2023-10-30 09:29:13,031 Epoch: [182/484] Iter:[360/495], Time: 0.37, lr: [0.006526840677648187], Loss: 2.047313, Acc:0.800737, Semantic loss: 0.763798, BCE loss: 0.541746, SB loss: 0.741769
2023-10-30 09:29:16,707 Epoch: [182/484] Iter:[370/495], Time: 0.37, lr: [0.006526446781295669], Loss: 2.050707, Acc:0.801127, Semantic loss: 0.765535, BCE loss: 0.542715, SB loss: 0.742458
2023-10-30 09:29:20,323 Epoch: [182/484] Iter:[380/495], Time: 0.37, lr: [0.006526052882301668], Loss: 2.055758, Acc:0.801230, Semantic loss: 0.767382, BCE loss: 0.545210, SB loss: 0.743165
2023-10-30 09:29:24,028 Epoch: [182/484] Iter:[390/495], Time: 0.37, lr: [0.006525658980665993], Loss: 2.061794, Acc:0.799776, Semantic loss: 0.770923, BCE loss: 0.546487, SB loss: 0.744383
2023-10-30 09:29:27,884 Epoch: [182/484] Iter:[400/495], Time: 0.37, lr: [0.006525265076388445], Loss: 2.071175, Acc:0.799094, Semantic loss: 0.775191, BCE loss: 0.548943, SB loss: 0.747041
2023-10-30 09:29:31,615 Epoch: [182/484] Iter:[410/495], Time: 0.37, lr: [0.006524871169468832], Loss: 2.072636, Acc:0.798849, Semantic loss: 0.774304, BCE loss: 0.550391, SB loss: 0.747942
2023-10-30 09:29:35,281 Epoch: [182/484] Iter:[420/495], Time: 0.37, lr: [0.006524477259906957], Loss: 2.072707, Acc:0.798969, Semantic loss: 0.774345, BCE loss: 0.549226, SB loss: 0.749136
2023-10-30 09:29:38,947 Epoch: [182/484] Iter:[430/495], Time: 0.37, lr: [0.006524083347702627], Loss: 2.073003, Acc:0.798436, Semantic loss: 0.774562, BCE loss: 0.548143, SB loss: 0.750298
2023-10-30 09:29:42,634 Epoch: [182/484] Iter:[440/495], Time: 0.37, lr: [0.006523689432855646], Loss: 2.071041, Acc:0.798523, Semantic loss: 0.773905, BCE loss: 0.546978, SB loss: 0.750158
2023-10-30 09:29:46,322 Epoch: [182/484] Iter:[450/495], Time: 0.37, lr: [0.0065232955153658205], Loss: 2.071432, Acc:0.798675, Semantic loss: 0.774034, BCE loss: 0.547060, SB loss: 0.750338
2023-10-30 09:29:49,968 Epoch: [182/484] Iter:[460/495], Time: 0.37, lr: [0.0065229015952329526], Loss: 2.068604, Acc:0.798658, Semantic loss: 0.772741, BCE loss: 0.546084, SB loss: 0.749779
2023-10-30 09:29:53,664 Epoch: [182/484] Iter:[470/495], Time: 0.37, lr: [0.00652250767245685], Loss: 2.072376, Acc:0.798818, Semantic loss: 0.775153, BCE loss: 0.545671, SB loss: 0.751552
2023-10-30 09:29:57,335 Epoch: [182/484] Iter:[480/495], Time: 0.37, lr: [0.006522113747037316], Loss: 2.074387, Acc:0.798853, Semantic loss: 0.775971, BCE loss: 0.546437, SB loss: 0.751980
2023-10-30 09:30:00,877 Epoch: [182/484] Iter:[490/495], Time: 0.37, lr: [0.0065217198189741555], Loss: 2.072043, Acc:0.798286, Semantic loss: 0.775195, BCE loss: 0.544807, SB loss: 0.752041
2023-10-30 09:30:02,279 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:30:02,522 Loss: 2.136, MeanIU:  0.6487, Best_mIoU:  0.6984
2023-10-30 09:30:02,522 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524]
2023-10-30 09:30:04,616 Epoch: [183/484] Iter:[0/495], Time: 2.06, lr: [0.006521522853951154], Loss: 2.291627, Acc:0.852138, Semantic loss: 0.877392, BCE loss: 0.611763, SB loss: 0.802472
2023-10-30 09:30:08,725 Epoch: [183/484] Iter:[10/495], Time: 0.56, lr: [0.006521128921922188], Loss: 2.099422, Acc:0.819724, Semantic loss: 0.800674, BCE loss: 0.524644, SB loss: 0.774104
2023-10-30 09:30:12,391 Epoch: [183/484] Iter:[20/495], Time: 0.47, lr: [0.006520734987249107], Loss: 2.123561, Acc:0.802020, Semantic loss: 0.825789, BCE loss: 0.527589, SB loss: 0.770183
2023-10-30 09:30:16,031 Epoch: [183/484] Iter:[30/495], Time: 0.44, lr: [0.006520341049931718], Loss: 2.128862, Acc:0.803534, Semantic loss: 0.805723, BCE loss: 0.549910, SB loss: 0.773229
2023-10-30 09:30:19,712 Epoch: [183/484] Iter:[40/495], Time: 0.42, lr: [0.006519947109969825], Loss: 2.134513, Acc:0.798540, Semantic loss: 0.818395, BCE loss: 0.534369, SB loss: 0.781748
2023-10-30 09:30:23,373 Epoch: [183/484] Iter:[50/495], Time: 0.41, lr: [0.00651955316736323], Loss: 2.125041, Acc:0.796212, Semantic loss: 0.811141, BCE loss: 0.536886, SB loss: 0.777014
2023-10-30 09:30:27,097 Epoch: [183/484] Iter:[60/495], Time: 0.40, lr: [0.006519159222111741], Loss: 2.097755, Acc:0.794469, Semantic loss: 0.793304, BCE loss: 0.531266, SB loss: 0.773185
2023-10-30 09:30:31,024 Epoch: [183/484] Iter:[70/495], Time: 0.40, lr: [0.006518765274215161], Loss: 2.091060, Acc:0.796478, Semantic loss: 0.787125, BCE loss: 0.535574, SB loss: 0.768361
2023-10-30 09:30:34,758 Epoch: [183/484] Iter:[80/495], Time: 0.40, lr: [0.006518371323673296], Loss: 2.081199, Acc:0.801942, Semantic loss: 0.778587, BCE loss: 0.543909, SB loss: 0.758703
2023-10-30 09:30:38,403 Epoch: [183/484] Iter:[90/495], Time: 0.39, lr: [0.006517977370485948], Loss: 2.068146, Acc:0.801248, Semantic loss: 0.775719, BCE loss: 0.536825, SB loss: 0.755603
2023-10-30 09:30:42,120 Epoch: [183/484] Iter:[100/495], Time: 0.39, lr: [0.0065175834146529235], Loss: 2.081462, Acc:0.799338, Semantic loss: 0.782987, BCE loss: 0.538417, SB loss: 0.760057
2023-10-30 09:30:45,787 Epoch: [183/484] Iter:[110/495], Time: 0.39, lr: [0.006517189456174026], Loss: 2.087250, Acc:0.799291, Semantic loss: 0.783828, BCE loss: 0.541615, SB loss: 0.761806
2023-10-30 09:30:49,348 Epoch: [183/484] Iter:[120/495], Time: 0.39, lr: [0.006516795495049063], Loss: 2.088065, Acc:0.796002, Semantic loss: 0.786704, BCE loss: 0.539790, SB loss: 0.761570
2023-10-30 09:30:53,044 Epoch: [183/484] Iter:[130/495], Time: 0.39, lr: [0.006516401531277835], Loss: 2.087531, Acc:0.796009, Semantic loss: 0.787629, BCE loss: 0.540841, SB loss: 0.759061
2023-10-30 09:30:56,714 Epoch: [183/484] Iter:[140/495], Time: 0.38, lr: [0.006516007564860149], Loss: 2.079750, Acc:0.793328, Semantic loss: 0.783385, BCE loss: 0.539767, SB loss: 0.756597
2023-10-30 09:31:00,461 Epoch: [183/484] Iter:[150/495], Time: 0.38, lr: [0.0065156135957958085], Loss: 2.086036, Acc:0.790061, Semantic loss: 0.787451, BCE loss: 0.540156, SB loss: 0.758429
2023-10-30 09:31:04,048 Epoch: [183/484] Iter:[160/495], Time: 0.38, lr: [0.0065152196240846165], Loss: 2.090109, Acc:0.790414, Semantic loss: 0.791311, BCE loss: 0.539053, SB loss: 0.759745
2023-10-30 09:31:07,933 Epoch: [183/484] Iter:[170/495], Time: 0.38, lr: [0.0065148256497263805], Loss: 2.100564, Acc:0.789614, Semantic loss: 0.801483, BCE loss: 0.535652, SB loss: 0.763430
2023-10-30 09:31:11,669 Epoch: [183/484] Iter:[180/495], Time: 0.38, lr: [0.006514431672720902], Loss: 2.104385, Acc:0.789266, Semantic loss: 0.798437, BCE loss: 0.542731, SB loss: 0.763216
2023-10-30 09:31:15,529 Epoch: [183/484] Iter:[190/495], Time: 0.38, lr: [0.006514037693067987], Loss: 2.105123, Acc:0.788867, Semantic loss: 0.798113, BCE loss: 0.544172, SB loss: 0.762837
2023-10-30 09:31:19,234 Epoch: [183/484] Iter:[200/495], Time: 0.38, lr: [0.006513643710767439], Loss: 2.103756, Acc:0.790221, Semantic loss: 0.795120, BCE loss: 0.546361, SB loss: 0.762275
2023-10-30 09:31:22,991 Epoch: [183/484] Iter:[210/495], Time: 0.38, lr: [0.006513249725819065], Loss: 2.100462, Acc:0.790989, Semantic loss: 0.794217, BCE loss: 0.544378, SB loss: 0.761867
2023-10-30 09:31:26,938 Epoch: [183/484] Iter:[220/495], Time: 0.38, lr: [0.006512855738222665], Loss: 2.102426, Acc:0.792885, Semantic loss: 0.794502, BCE loss: 0.544788, SB loss: 0.763136
2023-10-30 09:31:30,580 Epoch: [183/484] Iter:[230/495], Time: 0.38, lr: [0.006512461747978046], Loss: 2.105786, Acc:0.794761, Semantic loss: 0.794219, BCE loss: 0.548744, SB loss: 0.762823
2023-10-30 09:31:34,290 Epoch: [183/484] Iter:[240/495], Time: 0.38, lr: [0.006512067755085009], Loss: 2.101003, Acc:0.794302, Semantic loss: 0.790456, BCE loss: 0.549724, SB loss: 0.760823
2023-10-30 09:31:37,979 Epoch: [183/484] Iter:[250/495], Time: 0.38, lr: [0.006511673759543361], Loss: 2.102669, Acc:0.794093, Semantic loss: 0.792581, BCE loss: 0.549415, SB loss: 0.760672
2023-10-30 09:31:41,629 Epoch: [183/484] Iter:[260/495], Time: 0.38, lr: [0.006511279761352906], Loss: 2.097576, Acc:0.793605, Semantic loss: 0.790435, BCE loss: 0.548175, SB loss: 0.758965
2023-10-30 09:31:45,346 Epoch: [183/484] Iter:[270/495], Time: 0.38, lr: [0.006510885760513448], Loss: 2.091127, Acc:0.794536, Semantic loss: 0.787153, BCE loss: 0.546225, SB loss: 0.757749
2023-10-30 09:31:49,006 Epoch: [183/484] Iter:[280/495], Time: 0.38, lr: [0.006510491757024791], Loss: 2.088611, Acc:0.793845, Semantic loss: 0.786337, BCE loss: 0.544369, SB loss: 0.757905
2023-10-30 09:31:52,740 Epoch: [183/484] Iter:[290/495], Time: 0.38, lr: [0.00651009775088674], Loss: 2.088878, Acc:0.794531, Semantic loss: 0.786569, BCE loss: 0.544335, SB loss: 0.757974
2023-10-30 09:31:56,430 Epoch: [183/484] Iter:[300/495], Time: 0.38, lr: [0.006509703742099096], Loss: 2.086305, Acc:0.794808, Semantic loss: 0.786113, BCE loss: 0.543281, SB loss: 0.756912
2023-10-30 09:32:00,092 Epoch: [183/484] Iter:[310/495], Time: 0.38, lr: [0.006509309730661665], Loss: 2.085374, Acc:0.795566, Semantic loss: 0.784251, BCE loss: 0.544931, SB loss: 0.756192
2023-10-30 09:32:03,776 Epoch: [183/484] Iter:[320/495], Time: 0.38, lr: [0.006508915716574249], Loss: 2.081070, Acc:0.795828, Semantic loss: 0.783843, BCE loss: 0.542582, SB loss: 0.754645
2023-10-30 09:32:07,429 Epoch: [183/484] Iter:[330/495], Time: 0.38, lr: [0.006508521699836657], Loss: 2.081011, Acc:0.796362, Semantic loss: 0.783136, BCE loss: 0.544240, SB loss: 0.753636
2023-10-30 09:32:11,129 Epoch: [183/484] Iter:[340/495], Time: 0.38, lr: [0.006508127680448687], Loss: 2.084356, Acc:0.796256, Semantic loss: 0.785209, BCE loss: 0.544533, SB loss: 0.754613
2023-10-30 09:32:14,787 Epoch: [183/484] Iter:[350/495], Time: 0.38, lr: [0.006507733658410147], Loss: 2.082162, Acc:0.796336, Semantic loss: 0.784201, BCE loss: 0.543473, SB loss: 0.754488
2023-10-30 09:32:18,542 Epoch: [183/484] Iter:[360/495], Time: 0.38, lr: [0.006507339633720839], Loss: 2.078188, Acc:0.796316, Semantic loss: 0.782223, BCE loss: 0.542199, SB loss: 0.753766
2023-10-30 09:32:22,276 Epoch: [183/484] Iter:[370/495], Time: 0.38, lr: [0.0065069456063805665], Loss: 2.077433, Acc:0.795776, Semantic loss: 0.781631, BCE loss: 0.542084, SB loss: 0.753718
2023-10-30 09:32:26,041 Epoch: [183/484] Iter:[380/495], Time: 0.38, lr: [0.0065065515763891345], Loss: 2.077747, Acc:0.796560, Semantic loss: 0.781301, BCE loss: 0.543366, SB loss: 0.753080
2023-10-30 09:32:29,773 Epoch: [183/484] Iter:[390/495], Time: 0.38, lr: [0.006506157543746346], Loss: 2.078087, Acc:0.795750, Semantic loss: 0.781758, BCE loss: 0.543272, SB loss: 0.753057
2023-10-30 09:32:33,462 Epoch: [183/484] Iter:[400/495], Time: 0.38, lr: [0.006505763508452004], Loss: 2.078221, Acc:0.796299, Semantic loss: 0.782600, BCE loss: 0.544268, SB loss: 0.751353
2023-10-30 09:32:37,213 Epoch: [183/484] Iter:[410/495], Time: 0.38, lr: [0.006505369470505915], Loss: 2.072012, Acc:0.796558, Semantic loss: 0.779902, BCE loss: 0.542223, SB loss: 0.749886
2023-10-30 09:32:40,987 Epoch: [183/484] Iter:[420/495], Time: 0.38, lr: [0.006504975429907879], Loss: 2.071639, Acc:0.796089, Semantic loss: 0.779436, BCE loss: 0.542206, SB loss: 0.749997
2023-10-30 09:32:44,672 Epoch: [183/484] Iter:[430/495], Time: 0.38, lr: [0.006504581386657702], Loss: 2.071269, Acc:0.796281, Semantic loss: 0.779846, BCE loss: 0.541415, SB loss: 0.750008
2023-10-30 09:32:48,307 Epoch: [183/484] Iter:[440/495], Time: 0.38, lr: [0.006504187340755188], Loss: 2.071704, Acc:0.795418, Semantic loss: 0.779643, BCE loss: 0.541963, SB loss: 0.750098
2023-10-30 09:32:52,082 Epoch: [183/484] Iter:[450/495], Time: 0.38, lr: [0.00650379329220014], Loss: 2.071416, Acc:0.796156, Semantic loss: 0.779254, BCE loss: 0.541902, SB loss: 0.750260
2023-10-30 09:32:55,739 Epoch: [183/484] Iter:[460/495], Time: 0.38, lr: [0.006503399240992361], Loss: 2.072790, Acc:0.795835, Semantic loss: 0.780186, BCE loss: 0.541756, SB loss: 0.750847
2023-10-30 09:32:59,455 Epoch: [183/484] Iter:[470/495], Time: 0.38, lr: [0.006503005187131653], Loss: 2.073780, Acc:0.795773, Semantic loss: 0.780429, BCE loss: 0.541550, SB loss: 0.751801
2023-10-30 09:33:03,112 Epoch: [183/484] Iter:[480/495], Time: 0.38, lr: [0.006502611130617822], Loss: 2.074500, Acc:0.795034, Semantic loss: 0.781387, BCE loss: 0.541365, SB loss: 0.751748
2023-10-30 09:33:06,643 Epoch: [183/484] Iter:[490/495], Time: 0.37, lr: [0.006502217071450671], Loss: 2.075627, Acc:0.794670, Semantic loss: 0.782010, BCE loss: 0.541112, SB loss: 0.752505
2023-10-30 09:33:08,063 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:33:08,299 Loss: 2.136, MeanIU:  0.6487, Best_mIoU:  0.6984
2023-10-30 09:33:08,299 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524]
2023-10-30 09:33:10,122 Epoch: [184/484] Iter:[0/495], Time: 1.79, lr: [0.00650202004087204], Loss: 1.632692, Acc:0.816776, Semantic loss: 0.596073, BCE loss: 0.398740, SB loss: 0.637880
2023-10-30 09:33:14,213 Epoch: [184/484] Iter:[10/495], Time: 0.53, lr: [0.0065016259777245415], Loss: 1.994846, Acc:0.782619, Semantic loss: 0.781810, BCE loss: 0.497695, SB loss: 0.715341
2023-10-30 09:33:17,955 Epoch: [184/484] Iter:[20/495], Time: 0.46, lr: [0.006501231911923231], Loss: 2.130298, Acc:0.788274, Semantic loss: 0.856917, BCE loss: 0.515044, SB loss: 0.758336
2023-10-30 09:33:21,638 Epoch: [184/484] Iter:[30/495], Time: 0.43, lr: [0.0065008378434679125], Loss: 2.127963, Acc:0.783792, Semantic loss: 0.853801, BCE loss: 0.511260, SB loss: 0.762902
2023-10-30 09:33:25,271 Epoch: [184/484] Iter:[40/495], Time: 0.41, lr: [0.006500443772358389], Loss: 2.195311, Acc:0.780935, Semantic loss: 0.879903, BCE loss: 0.532973, SB loss: 0.782435
2023-10-30 09:33:29,004 Epoch: [184/484] Iter:[50/495], Time: 0.41, lr: [0.006500049698594464], Loss: 2.191448, Acc:0.783677, Semantic loss: 0.860679, BCE loss: 0.548366, SB loss: 0.782403
2023-10-30 09:33:32,748 Epoch: [184/484] Iter:[60/495], Time: 0.40, lr: [0.006499655622175941], Loss: 2.157723, Acc:0.783184, Semantic loss: 0.836945, BCE loss: 0.541919, SB loss: 0.778859
2023-10-30 09:33:36,477 Epoch: [184/484] Iter:[70/495], Time: 0.40, lr: [0.006499261543102623], Loss: 2.130810, Acc:0.787556, Semantic loss: 0.821438, BCE loss: 0.539793, SB loss: 0.769579
2023-10-30 09:33:40,207 Epoch: [184/484] Iter:[80/495], Time: 0.39, lr: [0.006498867461374312], Loss: 2.119905, Acc:0.790210, Semantic loss: 0.813950, BCE loss: 0.541050, SB loss: 0.764904
2023-10-30 09:33:43,940 Epoch: [184/484] Iter:[90/495], Time: 0.39, lr: [0.006498473376990815], Loss: 2.130780, Acc:0.794887, Semantic loss: 0.812709, BCE loss: 0.549540, SB loss: 0.768531
2023-10-30 09:33:47,613 Epoch: [184/484] Iter:[100/495], Time: 0.39, lr: [0.006498079289951932], Loss: 2.119502, Acc:0.795893, Semantic loss: 0.811349, BCE loss: 0.543489, SB loss: 0.764664
2023-10-30 09:33:51,273 Epoch: [184/484] Iter:[110/495], Time: 0.39, lr: [0.006497685200257467], Loss: 2.125399, Acc:0.795479, Semantic loss: 0.813663, BCE loss: 0.544997, SB loss: 0.766739
2023-10-30 09:33:54,925 Epoch: [184/484] Iter:[120/495], Time: 0.39, lr: [0.006497291107907223], Loss: 2.114443, Acc:0.794566, Semantic loss: 0.804441, BCE loss: 0.547276, SB loss: 0.762727
2023-10-30 09:33:58,629 Epoch: [184/484] Iter:[130/495], Time: 0.38, lr: [0.006496897012901004], Loss: 2.110805, Acc:0.794838, Semantic loss: 0.801087, BCE loss: 0.546583, SB loss: 0.763135
2023-10-30 09:34:02,322 Epoch: [184/484] Iter:[140/495], Time: 0.38, lr: [0.00649650291523861], Loss: 2.111204, Acc:0.793278, Semantic loss: 0.801775, BCE loss: 0.545525, SB loss: 0.763904
2023-10-30 09:34:06,043 Epoch: [184/484] Iter:[150/495], Time: 0.38, lr: [0.006496108814919849], Loss: 2.101905, Acc:0.794484, Semantic loss: 0.796198, BCE loss: 0.544325, SB loss: 0.761382
2023-10-30 09:34:09,685 Epoch: [184/484] Iter:[160/495], Time: 0.38, lr: [0.00649571471194452], Loss: 2.104065, Acc:0.795451, Semantic loss: 0.796226, BCE loss: 0.547009, SB loss: 0.760830
2023-10-30 09:34:13,317 Epoch: [184/484] Iter:[170/495], Time: 0.38, lr: [0.006495320606312428], Loss: 2.117864, Acc:0.797126, Semantic loss: 0.805516, BCE loss: 0.547702, SB loss: 0.764645
2023-10-30 09:34:17,048 Epoch: [184/484] Iter:[180/495], Time: 0.38, lr: [0.006494926498023376], Loss: 2.108987, Acc:0.794860, Semantic loss: 0.803210, BCE loss: 0.542141, SB loss: 0.763636
2023-10-30 09:34:20,916 Epoch: [184/484] Iter:[190/495], Time: 0.38, lr: [0.006494532387077165], Loss: 2.115475, Acc:0.795020, Semantic loss: 0.807210, BCE loss: 0.544386, SB loss: 0.763879
2023-10-30 09:34:24,621 Epoch: [184/484] Iter:[200/495], Time: 0.38, lr: [0.006494138273473601], Loss: 2.119146, Acc:0.795972, Semantic loss: 0.810129, BCE loss: 0.544390, SB loss: 0.764627
2023-10-30 09:34:28,363 Epoch: [184/484] Iter:[210/495], Time: 0.38, lr: [0.006493744157212484], Loss: 2.134746, Acc:0.794658, Semantic loss: 0.818211, BCE loss: 0.545924, SB loss: 0.770612
2023-10-30 09:34:32,063 Epoch: [184/484] Iter:[220/495], Time: 0.38, lr: [0.0064933500382936184], Loss: 2.130327, Acc:0.794528, Semantic loss: 0.815718, BCE loss: 0.545986, SB loss: 0.768624
2023-10-30 09:34:35,810 Epoch: [184/484] Iter:[230/495], Time: 0.38, lr: [0.006492955916716807], Loss: 2.136226, Acc:0.792147, Semantic loss: 0.817822, BCE loss: 0.547065, SB loss: 0.771339
2023-10-30 09:34:39,557 Epoch: [184/484] Iter:[240/495], Time: 0.38, lr: [0.006492561792481852], Loss: 2.138281, Acc:0.792519, Semantic loss: 0.817690, BCE loss: 0.547827, SB loss: 0.772764
2023-10-30 09:34:43,335 Epoch: [184/484] Iter:[250/495], Time: 0.38, lr: [0.006492167665588557], Loss: 2.140388, Acc:0.792728, Semantic loss: 0.818469, BCE loss: 0.549031, SB loss: 0.772887
2023-10-30 09:34:47,013 Epoch: [184/484] Iter:[260/495], Time: 0.38, lr: [0.006491773536036724], Loss: 2.141114, Acc:0.793549, Semantic loss: 0.817832, BCE loss: 0.550985, SB loss: 0.772297
2023-10-30 09:34:50,692 Epoch: [184/484] Iter:[270/495], Time: 0.38, lr: [0.006491379403826155], Loss: 2.139573, Acc:0.793038, Semantic loss: 0.816687, BCE loss: 0.551349, SB loss: 0.771537
2023-10-30 09:34:54,433 Epoch: [184/484] Iter:[280/495], Time: 0.38, lr: [0.006490985268956655], Loss: 2.137079, Acc:0.793206, Semantic loss: 0.815690, BCE loss: 0.550370, SB loss: 0.771019
2023-10-30 09:34:58,041 Epoch: [184/484] Iter:[290/495], Time: 0.38, lr: [0.006490591131428024], Loss: 2.132855, Acc:0.792653, Semantic loss: 0.813187, BCE loss: 0.549855, SB loss: 0.769813
2023-10-30 09:35:01,740 Epoch: [184/484] Iter:[300/495], Time: 0.38, lr: [0.006490196991240066], Loss: 2.131829, Acc:0.792749, Semantic loss: 0.813010, BCE loss: 0.548962, SB loss: 0.769857
2023-10-30 09:35:05,423 Epoch: [184/484] Iter:[310/495], Time: 0.38, lr: [0.006489802848392584], Loss: 2.131795, Acc:0.793087, Semantic loss: 0.812117, BCE loss: 0.550144, SB loss: 0.769534
2023-10-30 09:35:09,094 Epoch: [184/484] Iter:[320/495], Time: 0.38, lr: [0.006489408702885381], Loss: 2.132524, Acc:0.793144, Semantic loss: 0.812091, BCE loss: 0.551976, SB loss: 0.768457
2023-10-30 09:35:12,776 Epoch: [184/484] Iter:[330/495], Time: 0.38, lr: [0.006489014554718258], Loss: 2.127454, Acc:0.793854, Semantic loss: 0.809024, BCE loss: 0.551440, SB loss: 0.766990
2023-10-30 09:35:16,428 Epoch: [184/484] Iter:[340/495], Time: 0.38, lr: [0.006488620403891019], Loss: 2.125659, Acc:0.794227, Semantic loss: 0.807532, BCE loss: 0.552623, SB loss: 0.765504
2023-10-30 09:35:20,055 Epoch: [184/484] Iter:[350/495], Time: 0.38, lr: [0.006488226250403465], Loss: 2.120164, Acc:0.793434, Semantic loss: 0.804384, BCE loss: 0.550645, SB loss: 0.765134
2023-10-30 09:35:23,841 Epoch: [184/484] Iter:[360/495], Time: 0.38, lr: [0.0064878320942554], Loss: 2.119122, Acc:0.793563, Semantic loss: 0.803238, BCE loss: 0.551059, SB loss: 0.764825
2023-10-30 09:35:27,464 Epoch: [184/484] Iter:[370/495], Time: 0.38, lr: [0.006487437935446624], Loss: 2.116385, Acc:0.792939, Semantic loss: 0.801952, BCE loss: 0.548886, SB loss: 0.765547
2023-10-30 09:35:31,162 Epoch: [184/484] Iter:[380/495], Time: 0.37, lr: [0.006487043773976943], Loss: 2.112401, Acc:0.791848, Semantic loss: 0.800425, BCE loss: 0.547362, SB loss: 0.764614
2023-10-30 09:35:34,941 Epoch: [184/484] Iter:[390/495], Time: 0.37, lr: [0.006486649609846156], Loss: 2.107704, Acc:0.791697, Semantic loss: 0.797991, BCE loss: 0.546613, SB loss: 0.763100
2023-10-30 09:35:38,678 Epoch: [184/484] Iter:[400/495], Time: 0.37, lr: [0.006486255443054068], Loss: 2.104666, Acc:0.791171, Semantic loss: 0.796872, BCE loss: 0.546356, SB loss: 0.761437
2023-10-30 09:35:42,437 Epoch: [184/484] Iter:[410/495], Time: 0.37, lr: [0.00648586127360048], Loss: 2.105879, Acc:0.791783, Semantic loss: 0.797985, BCE loss: 0.545716, SB loss: 0.762177
2023-10-30 09:35:46,071 Epoch: [184/484] Iter:[420/495], Time: 0.37, lr: [0.006485467101485194], Loss: 2.104064, Acc:0.791243, Semantic loss: 0.797010, BCE loss: 0.545097, SB loss: 0.761957
2023-10-30 09:35:49,716 Epoch: [184/484] Iter:[430/495], Time: 0.37, lr: [0.006485072926708013], Loss: 2.100075, Acc:0.791276, Semantic loss: 0.795478, BCE loss: 0.543476, SB loss: 0.761120
2023-10-30 09:35:53,366 Epoch: [184/484] Iter:[440/495], Time: 0.37, lr: [0.006484678749268739], Loss: 2.097505, Acc:0.791840, Semantic loss: 0.794112, BCE loss: 0.542552, SB loss: 0.760841
2023-10-30 09:35:56,987 Epoch: [184/484] Iter:[450/495], Time: 0.37, lr: [0.006484284569167173], Loss: 2.096113, Acc:0.791594, Semantic loss: 0.793358, BCE loss: 0.542685, SB loss: 0.760069
2023-10-30 09:36:00,603 Epoch: [184/484] Iter:[460/495], Time: 0.37, lr: [0.00648389038640312], Loss: 2.094200, Acc:0.791800, Semantic loss: 0.792697, BCE loss: 0.542144, SB loss: 0.759359
2023-10-30 09:36:04,212 Epoch: [184/484] Iter:[470/495], Time: 0.37, lr: [0.00648349620097638], Loss: 2.091043, Acc:0.792474, Semantic loss: 0.791071, BCE loss: 0.540870, SB loss: 0.759102
2023-10-30 09:36:07,897 Epoch: [184/484] Iter:[480/495], Time: 0.37, lr: [0.006483102012886756], Loss: 2.086334, Acc:0.791935, Semantic loss: 0.788661, BCE loss: 0.539915, SB loss: 0.757758
2023-10-30 09:36:11,445 Epoch: [184/484] Iter:[490/495], Time: 0.37, lr: [0.00648270782213405], Loss: 2.084634, Acc:0.792828, Semantic loss: 0.787397, BCE loss: 0.540351, SB loss: 0.756885
2023-10-30 09:36:12,870 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:36:13,107 Loss: 2.136, MeanIU:  0.6487, Best_mIoU:  0.6984
2023-10-30 09:36:13,108 [0.96773508 0.78392799 0.89068292 0.36043195 0.48451507 0.5235467
 0.61086431 0.69943526 0.90275905 0.48916706 0.88302193 0.74130161
 0.48030163 0.9133675  0.35404659 0.66361545 0.50078057 0.375235
 0.69984524]
2023-10-30 09:36:15,144 Epoch: [185/484] Iter:[0/495], Time: 2.00, lr: [0.00648251072575898], Loss: 1.923435, Acc:0.806797, Semantic loss: 0.718902, BCE loss: 0.508536, SB loss: 0.695997
2023-10-30 09:36:19,098 Epoch: [185/484] Iter:[10/495], Time: 0.54, lr: [0.00648211653101128], Loss: 1.980424, Acc:0.813894, Semantic loss: 0.738484, BCE loss: 0.542285, SB loss: 0.699655
2023-10-30 09:36:22,980 Epoch: [185/484] Iter:[20/495], Time: 0.47, lr: [0.006481722333600002], Loss: 2.115493, Acc:0.805891, Semantic loss: 0.825609, BCE loss: 0.555233, SB loss: 0.734651
2023-10-30 09:36:26,667 Epoch: [185/484] Iter:[30/495], Time: 0.44, lr: [0.0064813281335249495], Loss: 2.111710, Acc:0.802975, Semantic loss: 0.821990, BCE loss: 0.541938, SB loss: 0.747783
2023-10-30 09:36:30,308 Epoch: [185/484] Iter:[40/495], Time: 0.42, lr: [0.006480933930785923], Loss: 2.127302, Acc:0.802473, Semantic loss: 0.829475, BCE loss: 0.544909, SB loss: 0.752918
2023-10-30 09:36:33,942 Epoch: [185/484] Iter:[50/495], Time: 0.41, lr: [0.0064805397253827265], Loss: 2.147987, Acc:0.800589, Semantic loss: 0.840081, BCE loss: 0.548842, SB loss: 0.759064
2023-10-30 09:36:37,663 Epoch: [185/484] Iter:[60/495], Time: 0.40, lr: [0.00648014551731516], Loss: 2.196169, Acc:0.794583, Semantic loss: 0.869255, BCE loss: 0.562664, SB loss: 0.764250
2023-10-30 09:36:41,352 Epoch: [185/484] Iter:[70/495], Time: 0.40, lr: [0.006479751306583027], Loss: 2.211412, Acc:0.795060, Semantic loss: 0.877576, BCE loss: 0.560404, SB loss: 0.773432
2023-10-30 09:36:45,108 Epoch: [185/484] Iter:[80/495], Time: 0.39, lr: [0.006479357093186129], Loss: 2.196457, Acc:0.797714, Semantic loss: 0.866197, BCE loss: 0.556400, SB loss: 0.773860
2023-10-30 09:36:48,745 Epoch: [185/484] Iter:[90/495], Time: 0.39, lr: [0.006478962877124268], Loss: 2.186869, Acc:0.794972, Semantic loss: 0.857084, BCE loss: 0.555124, SB loss: 0.774661
2023-10-30 09:36:52,460 Epoch: [185/484] Iter:[100/495], Time: 0.39, lr: [0.006478568658397244], Loss: 2.188700, Acc:0.792895, Semantic loss: 0.852993, BCE loss: 0.558684, SB loss: 0.777023
2023-10-30 09:36:56,155 Epoch: [185/484] Iter:[110/495], Time: 0.39, lr: [0.00647817443700486], Loss: 2.181628, Acc:0.795915, Semantic loss: 0.849204, BCE loss: 0.557765, SB loss: 0.774658
2023-10-30 09:36:59,974 Epoch: [185/484] Iter:[120/495], Time: 0.39, lr: [0.006477780212946919], Loss: 2.169385, Acc:0.796459, Semantic loss: 0.836922, BCE loss: 0.560829, SB loss: 0.771633
2023-10-30 09:37:03,697 Epoch: [185/484] Iter:[130/495], Time: 0.39, lr: [0.00647738598622322], Loss: 2.167397, Acc:0.799236, Semantic loss: 0.830393, BCE loss: 0.567315, SB loss: 0.769689
2023-10-30 09:37:07,463 Epoch: [185/484] Iter:[140/495], Time: 0.39, lr: [0.006476991756833567], Loss: 2.163796, Acc:0.799993, Semantic loss: 0.825586, BCE loss: 0.567941, SB loss: 0.770269
2023-10-30 09:37:11,153 Epoch: [185/484] Iter:[150/495], Time: 0.38, lr: [0.006476597524777761], Loss: 2.161340, Acc:0.797665, Semantic loss: 0.827653, BCE loss: 0.564757, SB loss: 0.768930
2023-10-30 09:37:14,822 Epoch: [185/484] Iter:[160/495], Time: 0.38, lr: [0.006476203290055604], Loss: 2.163033, Acc:0.796449, Semantic loss: 0.824933, BCE loss: 0.569094, SB loss: 0.769006
2023-10-30 09:37:18,482 Epoch: [185/484] Iter:[170/495], Time: 0.38, lr: [0.006475809052666897], Loss: 2.155303, Acc:0.796041, Semantic loss: 0.818930, BCE loss: 0.569686, SB loss: 0.766688
2023-10-30 09:37:22,180 Epoch: [185/484] Iter:[180/495], Time: 0.38, lr: [0.006475414812611442], Loss: 2.142972, Acc:0.795433, Semantic loss: 0.814565, BCE loss: 0.563527, SB loss: 0.764880
2023-10-30 09:37:25,888 Epoch: [185/484] Iter:[190/495], Time: 0.38, lr: [0.006475020569889039], Loss: 2.129341, Acc:0.796777, Semantic loss: 0.807936, BCE loss: 0.559248, SB loss: 0.762157
2023-10-30 09:37:29,552 Epoch: [185/484] Iter:[200/495], Time: 0.38, lr: [0.006474626324499492], Loss: 2.126834, Acc:0.798644, Semantic loss: 0.807401, BCE loss: 0.557856, SB loss: 0.761577
2023-10-30 09:37:33,174 Epoch: [185/484] Iter:[210/495], Time: 0.38, lr: [0.006474232076442601], Loss: 2.120760, Acc:0.799276, Semantic loss: 0.803561, BCE loss: 0.558364, SB loss: 0.758835
2023-10-30 09:37:36,949 Epoch: [185/484] Iter:[220/495], Time: 0.38, lr: [0.006473837825718167], Loss: 2.122883, Acc:0.799612, Semantic loss: 0.805542, BCE loss: 0.556364, SB loss: 0.760977
2023-10-30 09:37:40,618 Epoch: [185/484] Iter:[230/495], Time: 0.38, lr: [0.0064734435723259945], Loss: 2.115308, Acc:0.800477, Semantic loss: 0.802075, BCE loss: 0.553980, SB loss: 0.759253
2023-10-30 09:37:44,459 Epoch: [185/484] Iter:[240/495], Time: 0.38, lr: [0.006473049316265882], Loss: 2.116118, Acc:0.799930, Semantic loss: 0.801726, BCE loss: 0.555621, SB loss: 0.758771
2023-10-30 09:37:48,143 Epoch: [185/484] Iter:[250/495], Time: 0.38, lr: [0.006472655057537631], Loss: 2.112917, Acc:0.800106, Semantic loss: 0.800471, BCE loss: 0.554230, SB loss: 0.758216
2023-10-30 09:37:51,878 Epoch: [185/484] Iter:[260/495], Time: 0.38, lr: [0.006472260796141044], Loss: 2.109832, Acc:0.799430, Semantic loss: 0.799141, BCE loss: 0.552641, SB loss: 0.758050
2023-10-30 09:37:55,612 Epoch: [185/484] Iter:[270/495], Time: 0.38, lr: [0.00647186653207592], Loss: 2.110468, Acc:0.797851, Semantic loss: 0.799818, BCE loss: 0.551843, SB loss: 0.758807
2023-10-30 09:37:59,384 Epoch: [185/484] Iter:[280/495], Time: 0.38, lr: [0.006471472265342064], Loss: 2.109688, Acc:0.798982, Semantic loss: 0.799169, BCE loss: 0.552373, SB loss: 0.758146
2023-10-30 09:38:03,069 Epoch: [185/484] Iter:[290/495], Time: 0.38, lr: [0.006471077995939275], Loss: 2.107549, Acc:0.799939, Semantic loss: 0.796525, BCE loss: 0.554052, SB loss: 0.756971
2023-10-30 09:38:06,832 Epoch: [185/484] Iter:[300/495], Time: 0.38, lr: [0.006470683723867355], Loss: 2.100492, Acc:0.801371, Semantic loss: 0.793915, BCE loss: 0.551432, SB loss: 0.755145
2023-10-30 09:38:10,502 Epoch: [185/484] Iter:[310/495], Time: 0.38, lr: [0.006470289449126104], Loss: 2.101191, Acc:0.800309, Semantic loss: 0.795285, BCE loss: 0.550016, SB loss: 0.755890
2023-10-30 09:38:14,312 Epoch: [185/484] Iter:[320/495], Time: 0.38, lr: [0.006469895171715326], Loss: 2.102396, Acc:0.799362, Semantic loss: 0.796018, BCE loss: 0.549540, SB loss: 0.756837
2023-10-30 09:38:18,014 Epoch: [185/484] Iter:[330/495], Time: 0.38, lr: [0.0064695008916348185], Loss: 2.106132, Acc:0.799131, Semantic loss: 0.796530, BCE loss: 0.552015, SB loss: 0.757587
2023-10-30 09:38:21,716 Epoch: [185/484] Iter:[340/495], Time: 0.38, lr: [0.006469106608884385], Loss: 2.105386, Acc:0.799946, Semantic loss: 0.795342, BCE loss: 0.552618, SB loss: 0.757426
2023-10-30 09:38:25,488 Epoch: [185/484] Iter:[350/495], Time: 0.38, lr: [0.006468712323463825], Loss: 2.110571, Acc:0.799835, Semantic loss: 0.796906, BCE loss: 0.554812, SB loss: 0.758853
2023-10-30 09:38:29,166 Epoch: [185/484] Iter:[360/495], Time: 0.38, lr: [0.006468318035372941], Loss: 2.111335, Acc:0.799973, Semantic loss: 0.797573, BCE loss: 0.554142, SB loss: 0.759620
2023-10-30 09:38:32,864 Epoch: [185/484] Iter:[370/495], Time: 0.38, lr: [0.0064679237446115334], Loss: 2.108388, Acc:0.799924, Semantic loss: 0.796544, BCE loss: 0.553006, SB loss: 0.758838
2023-10-30 09:38:36,465 Epoch: [185/484] Iter:[380/495], Time: 0.38, lr: [0.006467529451179403], Loss: 2.109435, Acc:0.799529, Semantic loss: 0.796987, BCE loss: 0.553181, SB loss: 0.759267
2023-10-30 09:38:40,220 Epoch: [185/484] Iter:[390/495], Time: 0.38, lr: [0.006467135155076353], Loss: 2.107309, Acc:0.799030, Semantic loss: 0.795589, BCE loss: 0.552808, SB loss: 0.758912
2023-10-30 09:38:43,941 Epoch: [185/484] Iter:[400/495], Time: 0.38, lr: [0.006466740856302182], Loss: 2.107565, Acc:0.799901, Semantic loss: 0.795136, BCE loss: 0.552766, SB loss: 0.759663
2023-10-30 09:38:47,779 Epoch: [185/484] Iter:[410/495], Time: 0.38, lr: [0.006466346554856691], Loss: 2.110567, Acc:0.798673, Semantic loss: 0.797176, BCE loss: 0.552505, SB loss: 0.760887
2023-10-30 09:38:51,465 Epoch: [185/484] Iter:[420/495], Time: 0.38, lr: [0.006465952250739683], Loss: 2.109056, Acc:0.799035, Semantic loss: 0.795976, BCE loss: 0.553217, SB loss: 0.759863
2023-10-30 09:38:55,214 Epoch: [185/484] Iter:[430/495], Time: 0.38, lr: [0.006465557943950955], Loss: 2.108501, Acc:0.799773, Semantic loss: 0.795275, BCE loss: 0.553433, SB loss: 0.759793
2023-10-30 09:38:58,869 Epoch: [185/484] Iter:[440/495], Time: 0.38, lr: [0.0064651636344903105], Loss: 2.107517, Acc:0.799642, Semantic loss: 0.794491, BCE loss: 0.553167, SB loss: 0.759859
2023-10-30 09:39:02,601 Epoch: [185/484] Iter:[450/495], Time: 0.38, lr: [0.006464769322357551], Loss: 2.103791, Acc:0.799365, Semantic loss: 0.793149, BCE loss: 0.551461, SB loss: 0.759180
2023-10-30 09:39:06,289 Epoch: [185/484] Iter:[460/495], Time: 0.38, lr: [0.006464375007552476], Loss: 2.105582, Acc:0.799073, Semantic loss: 0.793989, BCE loss: 0.552698, SB loss: 0.758896
2023-10-30 09:39:09,988 Epoch: [185/484] Iter:[470/495], Time: 0.38, lr: [0.006463980690074886], Loss: 2.108035, Acc:0.798953, Semantic loss: 0.794986, BCE loss: 0.553743, SB loss: 0.759306
2023-10-30 09:39:13,648 Epoch: [185/484] Iter:[480/495], Time: 0.38, lr: [0.0064635863699245835], Loss: 2.106183, Acc:0.799530, Semantic loss: 0.793474, BCE loss: 0.554372, SB loss: 0.758337
2023-10-30 09:39:17,144 Epoch: [185/484] Iter:[490/495], Time: 0.37, lr: [0.0064631920471013675], Loss: 2.104541, Acc:0.799316, Semantic loss: 0.792885, BCE loss: 0.553646, SB loss: 0.758011
2023-10-30 09:42:13,673 0 [9.33118851e-01 6.30902829e-01 8.17216792e-01 1.35952334e-01
 2.40302819e-01 3.92726031e-01 4.23166980e-01 5.51587643e-01
 8.80135627e-01 4.55233645e-01 8.44838384e-01 6.06597329e-01
 1.25332601e-02 8.12615087e-01 1.73005935e-04 9.67143423e-02
 1.13336293e-02 2.33722032e-02 5.57596604e-01] 0.4434798629197124
2023-10-30 09:42:13,673 1 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765] 0.6792823521353214
2023-10-30 09:42:13,677 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:42:13,910 Loss: 2.128, MeanIU:  0.6793, Best_mIoU:  0.6984
2023-10-30 09:42:13,910 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765]
2023-10-30 09:42:15,900 Epoch: [186/484] Iter:[0/495], Time: 1.96, lr: [0.006462994884687355], Loss: 2.288786, Acc:0.727458, Semantic loss: 0.829287, BCE loss: 0.627151, SB loss: 0.832349
2023-10-30 09:42:19,670 Epoch: [186/484] Iter:[10/495], Time: 0.52, lr: [0.006462600557854394], Loss: 2.218026, Acc:0.802401, Semantic loss: 0.813155, BCE loss: 0.637618, SB loss: 0.767254
2023-10-30 09:42:23,190 Epoch: [186/484] Iter:[20/495], Time: 0.44, lr: [0.006462206228348024], Loss: 2.117672, Acc:0.794258, Semantic loss: 0.794767, BCE loss: 0.568061, SB loss: 0.754843
2023-10-30 09:42:26,625 Epoch: [186/484] Iter:[30/495], Time: 0.41, lr: [0.006461811896168043], Loss: 2.082857, Acc:0.800941, Semantic loss: 0.778667, BCE loss: 0.560870, SB loss: 0.743321
2023-10-30 09:42:30,110 Epoch: [186/484] Iter:[40/495], Time: 0.39, lr: [0.006461417561314251], Loss: 2.089282, Acc:0.808814, Semantic loss: 0.788665, BCE loss: 0.552020, SB loss: 0.748597
2023-10-30 09:42:33,729 Epoch: [186/484] Iter:[50/495], Time: 0.39, lr: [0.006461023223786451], Loss: 2.082973, Acc:0.803658, Semantic loss: 0.787245, BCE loss: 0.548657, SB loss: 0.747071
2023-10-30 09:42:37,259 Epoch: [186/484] Iter:[60/495], Time: 0.38, lr: [0.00646062888358444], Loss: 2.090455, Acc:0.803363, Semantic loss: 0.791182, BCE loss: 0.549602, SB loss: 0.749671
2023-10-30 09:42:40,858 Epoch: [186/484] Iter:[70/495], Time: 0.38, lr: [0.006460234540708022], Loss: 2.093610, Acc:0.803816, Semantic loss: 0.799698, BCE loss: 0.543257, SB loss: 0.750655
2023-10-30 09:42:44,427 Epoch: [186/484] Iter:[80/495], Time: 0.38, lr: [0.006459840195156995], Loss: 2.083109, Acc:0.802565, Semantic loss: 0.786692, BCE loss: 0.545638, SB loss: 0.750778
2023-10-30 09:42:48,060 Epoch: [186/484] Iter:[90/495], Time: 0.37, lr: [0.00645944584693116], Loss: 2.067983, Acc:0.806505, Semantic loss: 0.779807, BCE loss: 0.540810, SB loss: 0.747365
2023-10-30 09:42:51,673 Epoch: [186/484] Iter:[100/495], Time: 0.37, lr: [0.00645905149603032], Loss: 2.078676, Acc:0.804384, Semantic loss: 0.784357, BCE loss: 0.544144, SB loss: 0.750175
2023-10-30 09:42:55,270 Epoch: [186/484] Iter:[110/495], Time: 0.37, lr: [0.006458657142454269], Loss: 2.067741, Acc:0.804498, Semantic loss: 0.777544, BCE loss: 0.541508, SB loss: 0.748688
2023-10-30 09:42:58,785 Epoch: [186/484] Iter:[120/495], Time: 0.37, lr: [0.006458262786202816], Loss: 2.071920, Acc:0.800705, Semantic loss: 0.782690, BCE loss: 0.537029, SB loss: 0.752201
2023-10-30 09:43:02,395 Epoch: [186/484] Iter:[130/495], Time: 0.37, lr: [0.006457868427275755], Loss: 2.061644, Acc:0.797383, Semantic loss: 0.777319, BCE loss: 0.533584, SB loss: 0.750741
2023-10-30 09:43:05,964 Epoch: [186/484] Iter:[140/495], Time: 0.37, lr: [0.0064574740656728885], Loss: 2.057465, Acc:0.797804, Semantic loss: 0.773911, BCE loss: 0.533956, SB loss: 0.749598
2023-10-30 09:43:09,636 Epoch: [186/484] Iter:[150/495], Time: 0.37, lr: [0.006457079701394015], Loss: 2.062636, Acc:0.799772, Semantic loss: 0.772696, BCE loss: 0.539793, SB loss: 0.750146
2023-10-30 09:43:13,363 Epoch: [186/484] Iter:[160/495], Time: 0.37, lr: [0.0064566853344389386], Loss: 2.056940, Acc:0.799839, Semantic loss: 0.770008, BCE loss: 0.538650, SB loss: 0.748283
2023-10-30 09:43:17,114 Epoch: [186/484] Iter:[170/495], Time: 0.37, lr: [0.006456290964807454], Loss: 2.066647, Acc:0.799705, Semantic loss: 0.776957, BCE loss: 0.537205, SB loss: 0.752485
2023-10-30 09:43:20,681 Epoch: [186/484] Iter:[180/495], Time: 0.37, lr: [0.006455896592499367], Loss: 2.058843, Acc:0.800946, Semantic loss: 0.774119, BCE loss: 0.533068, SB loss: 0.751656
2023-10-30 09:43:24,338 Epoch: [186/484] Iter:[190/495], Time: 0.37, lr: [0.0064555022175144736], Loss: 2.063581, Acc:0.800593, Semantic loss: 0.780709, BCE loss: 0.531485, SB loss: 0.751386
2023-10-30 09:43:27,895 Epoch: [186/484] Iter:[200/495], Time: 0.37, lr: [0.006455107839852576], Loss: 2.055318, Acc:0.801052, Semantic loss: 0.777237, BCE loss: 0.527743, SB loss: 0.750337
2023-10-30 09:43:31,605 Epoch: [186/484] Iter:[210/495], Time: 0.37, lr: [0.006454713459513475], Loss: 2.049154, Acc:0.801700, Semantic loss: 0.774516, BCE loss: 0.525853, SB loss: 0.748785
2023-10-30 09:43:35,340 Epoch: [186/484] Iter:[220/495], Time: 0.37, lr: [0.006454319076496969], Loss: 2.048144, Acc:0.800448, Semantic loss: 0.773040, BCE loss: 0.525665, SB loss: 0.749440
2023-10-30 09:43:39,080 Epoch: [186/484] Iter:[230/495], Time: 0.37, lr: [0.006453924690802859], Loss: 2.051467, Acc:0.802283, Semantic loss: 0.778389, BCE loss: 0.524495, SB loss: 0.748582
2023-10-30 09:43:42,635 Epoch: [186/484] Iter:[240/495], Time: 0.37, lr: [0.006453530302430945], Loss: 2.065125, Acc:0.801713, Semantic loss: 0.785867, BCE loss: 0.528174, SB loss: 0.751084
2023-10-30 09:43:46,217 Epoch: [186/484] Iter:[250/495], Time: 0.37, lr: [0.006453135911381024], Loss: 2.062231, Acc:0.800909, Semantic loss: 0.782923, BCE loss: 0.528559, SB loss: 0.750749
2023-10-30 09:43:49,847 Epoch: [186/484] Iter:[260/495], Time: 0.37, lr: [0.0064527415176529], Loss: 2.066721, Acc:0.800590, Semantic loss: 0.785904, BCE loss: 0.528813, SB loss: 0.752003
2023-10-30 09:43:53,581 Epoch: [186/484] Iter:[270/495], Time: 0.37, lr: [0.00645234712124637], Loss: 2.069496, Acc:0.800034, Semantic loss: 0.785295, BCE loss: 0.532003, SB loss: 0.752199
2023-10-30 09:43:57,321 Epoch: [186/484] Iter:[280/495], Time: 0.37, lr: [0.0064519527221612374], Loss: 2.068805, Acc:0.800659, Semantic loss: 0.782563, BCE loss: 0.534533, SB loss: 0.751709
2023-10-30 09:44:00,992 Epoch: [186/484] Iter:[290/495], Time: 0.37, lr: [0.0064515583203973], Loss: 2.068635, Acc:0.800081, Semantic loss: 0.781810, BCE loss: 0.535054, SB loss: 0.751772
2023-10-30 09:44:04,685 Epoch: [186/484] Iter:[300/495], Time: 0.37, lr: [0.006451163915954358], Loss: 2.070599, Acc:0.799950, Semantic loss: 0.783243, BCE loss: 0.535066, SB loss: 0.752291
2023-10-30 09:44:08,367 Epoch: [186/484] Iter:[310/495], Time: 0.37, lr: [0.00645076950883221], Loss: 2.077617, Acc:0.798351, Semantic loss: 0.787720, BCE loss: 0.535262, SB loss: 0.754635
2023-10-30 09:44:12,098 Epoch: [186/484] Iter:[320/495], Time: 0.37, lr: [0.006450375099030657], Loss: 2.076028, Acc:0.798736, Semantic loss: 0.785870, BCE loss: 0.535799, SB loss: 0.754360
2023-10-30 09:44:15,715 Epoch: [186/484] Iter:[330/495], Time: 0.37, lr: [0.006449980686549497], Loss: 2.080546, Acc:0.798349, Semantic loss: 0.786565, BCE loss: 0.538919, SB loss: 0.755062
2023-10-30 09:44:19,368 Epoch: [186/484] Iter:[340/495], Time: 0.37, lr: [0.006449586271388533], Loss: 2.081067, Acc:0.798532, Semantic loss: 0.785499, BCE loss: 0.541057, SB loss: 0.754511
2023-10-30 09:44:22,938 Epoch: [186/484] Iter:[350/495], Time: 0.37, lr: [0.006449191853547562], Loss: 2.082320, Acc:0.799020, Semantic loss: 0.786454, BCE loss: 0.541268, SB loss: 0.754598
2023-10-30 09:44:26,573 Epoch: [186/484] Iter:[360/495], Time: 0.37, lr: [0.006448797433026385], Loss: 2.079735, Acc:0.797830, Semantic loss: 0.785685, BCE loss: 0.540049, SB loss: 0.754001
2023-10-30 09:44:30,219 Epoch: [186/484] Iter:[370/495], Time: 0.37, lr: [0.006448403009824802], Loss: 2.078271, Acc:0.797780, Semantic loss: 0.784738, BCE loss: 0.539666, SB loss: 0.753866
2023-10-30 09:44:33,917 Epoch: [186/484] Iter:[380/495], Time: 0.37, lr: [0.00644800858394261], Loss: 2.077895, Acc:0.797849, Semantic loss: 0.785134, BCE loss: 0.538776, SB loss: 0.753985
2023-10-30 09:44:37,546 Epoch: [186/484] Iter:[390/495], Time: 0.37, lr: [0.006447614155379612], Loss: 2.076134, Acc:0.797055, Semantic loss: 0.783842, BCE loss: 0.538856, SB loss: 0.753436
2023-10-30 09:44:41,379 Epoch: [186/484] Iter:[400/495], Time: 0.37, lr: [0.006447219724135605], Loss: 2.072972, Acc:0.796478, Semantic loss: 0.782050, BCE loss: 0.538044, SB loss: 0.752878
2023-10-30 09:44:45,083 Epoch: [186/484] Iter:[410/495], Time: 0.37, lr: [0.0064468252902103885], Loss: 2.071989, Acc:0.797063, Semantic loss: 0.781383, BCE loss: 0.538334, SB loss: 0.752272
2023-10-30 09:44:48,797 Epoch: [186/484] Iter:[420/495], Time: 0.37, lr: [0.006446430853603765], Loss: 2.072618, Acc:0.797049, Semantic loss: 0.782024, BCE loss: 0.538134, SB loss: 0.752460
2023-10-30 09:44:52,527 Epoch: [186/484] Iter:[430/495], Time: 0.37, lr: [0.00644603641431553], Loss: 2.071136, Acc:0.796190, Semantic loss: 0.780699, BCE loss: 0.537900, SB loss: 0.752538
2023-10-30 09:44:56,231 Epoch: [186/484] Iter:[440/495], Time: 0.37, lr: [0.0064456419723454865], Loss: 2.069360, Acc:0.796457, Semantic loss: 0.779372, BCE loss: 0.538522, SB loss: 0.751466
2023-10-30 09:44:59,840 Epoch: [186/484] Iter:[450/495], Time: 0.37, lr: [0.006445247527693432], Loss: 2.072255, Acc:0.797208, Semantic loss: 0.780935, BCE loss: 0.538580, SB loss: 0.752741
2023-10-30 09:45:03,503 Epoch: [186/484] Iter:[460/495], Time: 0.37, lr: [0.006444853080359167], Loss: 2.077355, Acc:0.797184, Semantic loss: 0.784454, BCE loss: 0.539004, SB loss: 0.753897
2023-10-30 09:45:07,317 Epoch: [186/484] Iter:[470/495], Time: 0.37, lr: [0.006444458630342489], Loss: 2.072285, Acc:0.796799, Semantic loss: 0.782465, BCE loss: 0.537010, SB loss: 0.752810
2023-10-30 09:45:10,957 Epoch: [186/484] Iter:[480/495], Time: 0.37, lr: [0.006444064177643198], Loss: 2.073020, Acc:0.796450, Semantic loss: 0.782455, BCE loss: 0.537355, SB loss: 0.753210
2023-10-30 09:45:14,454 Epoch: [186/484] Iter:[490/495], Time: 0.37, lr: [0.006443669722261094], Loss: 2.072315, Acc:0.795597, Semantic loss: 0.782785, BCE loss: 0.536459, SB loss: 0.753071
2023-10-30 09:45:15,848 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:45:16,109 Loss: 2.128, MeanIU:  0.6793, Best_mIoU:  0.6984
2023-10-30 09:45:16,109 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765]
2023-10-30 09:45:17,977 Epoch: [187/484] Iter:[0/495], Time: 1.83, lr: [0.0064434724935639245], Loss: 1.733553, Acc:0.839124, Semantic loss: 0.630780, BCE loss: 0.499346, SB loss: 0.603427
2023-10-30 09:45:22,129 Epoch: [187/484] Iter:[10/495], Time: 0.54, lr: [0.006443078034157224], Loss: 2.003936, Acc:0.762431, Semantic loss: 0.733337, BCE loss: 0.533155, SB loss: 0.737444
2023-10-30 09:45:25,838 Epoch: [187/484] Iter:[20/495], Time: 0.46, lr: [0.006442683572067208], Loss: 2.030387, Acc:0.774047, Semantic loss: 0.770764, BCE loss: 0.514316, SB loss: 0.745308
2023-10-30 09:45:29,491 Epoch: [187/484] Iter:[30/495], Time: 0.43, lr: [0.006442289107293678], Loss: 2.035649, Acc:0.781697, Semantic loss: 0.777603, BCE loss: 0.517914, SB loss: 0.740132
2023-10-30 09:45:33,072 Epoch: [187/484] Iter:[40/495], Time: 0.41, lr: [0.00644189463983643], Loss: 2.068973, Acc:0.780865, Semantic loss: 0.795269, BCE loss: 0.520012, SB loss: 0.753692
2023-10-30 09:45:36,782 Epoch: [187/484] Iter:[50/495], Time: 0.40, lr: [0.006441500169695263], Loss: 2.043314, Acc:0.777694, Semantic loss: 0.787905, BCE loss: 0.508595, SB loss: 0.746813
2023-10-30 09:45:40,488 Epoch: [187/484] Iter:[60/495], Time: 0.40, lr: [0.00644110569686998], Loss: 2.066379, Acc:0.787682, Semantic loss: 0.787582, BCE loss: 0.525332, SB loss: 0.753465
2023-10-30 09:45:44,101 Epoch: [187/484] Iter:[70/495], Time: 0.39, lr: [0.0064407112213603745], Loss: 2.065057, Acc:0.791771, Semantic loss: 0.784026, BCE loss: 0.528047, SB loss: 0.752985
2023-10-30 09:45:47,808 Epoch: [187/484] Iter:[80/495], Time: 0.39, lr: [0.006440316743166251], Loss: 2.072902, Acc:0.795283, Semantic loss: 0.786447, BCE loss: 0.532296, SB loss: 0.754158
2023-10-30 09:45:51,454 Epoch: [187/484] Iter:[90/495], Time: 0.39, lr: [0.006439922262287404], Loss: 2.065551, Acc:0.794240, Semantic loss: 0.779467, BCE loss: 0.532673, SB loss: 0.753411
2023-10-30 09:45:55,128 Epoch: [187/484] Iter:[100/495], Time: 0.39, lr: [0.006439527778723637], Loss: 2.075249, Acc:0.791910, Semantic loss: 0.782700, BCE loss: 0.536031, SB loss: 0.756518
2023-10-30 09:45:58,995 Epoch: [187/484] Iter:[110/495], Time: 0.39, lr: [0.0064391332924747455], Loss: 2.096781, Acc:0.791210, Semantic loss: 0.799405, BCE loss: 0.538896, SB loss: 0.758480
2023-10-30 09:46:02,655 Epoch: [187/484] Iter:[120/495], Time: 0.38, lr: [0.00643873880354053], Loss: 2.084899, Acc:0.794953, Semantic loss: 0.789685, BCE loss: 0.541414, SB loss: 0.753799
2023-10-30 09:46:06,260 Epoch: [187/484] Iter:[130/495], Time: 0.38, lr: [0.006438344311920788], Loss: 2.084542, Acc:0.792387, Semantic loss: 0.792747, BCE loss: 0.537471, SB loss: 0.754324
2023-10-30 09:46:09,908 Epoch: [187/484] Iter:[140/495], Time: 0.38, lr: [0.006437949817615321], Loss: 2.084360, Acc:0.795945, Semantic loss: 0.792983, BCE loss: 0.537183, SB loss: 0.754195
2023-10-30 09:46:13,522 Epoch: [187/484] Iter:[150/495], Time: 0.38, lr: [0.006437555320623923], Loss: 2.085456, Acc:0.796270, Semantic loss: 0.795895, BCE loss: 0.533434, SB loss: 0.756126
2023-10-30 09:46:17,184 Epoch: [187/484] Iter:[160/495], Time: 0.38, lr: [0.006437160820946399], Loss: 2.077804, Acc:0.795394, Semantic loss: 0.792656, BCE loss: 0.529975, SB loss: 0.755173
2023-10-30 09:46:20,844 Epoch: [187/484] Iter:[170/495], Time: 0.38, lr: [0.006436766318582543], Loss: 2.081438, Acc:0.794639, Semantic loss: 0.794576, BCE loss: 0.530580, SB loss: 0.756282
2023-10-30 09:46:24,582 Epoch: [187/484] Iter:[180/495], Time: 0.38, lr: [0.006436371813532157], Loss: 2.081087, Acc:0.795318, Semantic loss: 0.792061, BCE loss: 0.532057, SB loss: 0.756969
2023-10-30 09:46:28,284 Epoch: [187/484] Iter:[190/495], Time: 0.38, lr: [0.006435977305795038], Loss: 2.087383, Acc:0.796559, Semantic loss: 0.794594, BCE loss: 0.535860, SB loss: 0.756929
2023-10-30 09:46:31,929 Epoch: [187/484] Iter:[200/495], Time: 0.38, lr: [0.006435582795370985], Loss: 2.086383, Acc:0.798318, Semantic loss: 0.794049, BCE loss: 0.534811, SB loss: 0.757523
2023-10-30 09:46:35,617 Epoch: [187/484] Iter:[210/495], Time: 0.38, lr: [0.006435188282259796], Loss: 2.080305, Acc:0.796965, Semantic loss: 0.789620, BCE loss: 0.533574, SB loss: 0.757111
2023-10-30 09:46:39,283 Epoch: [187/484] Iter:[220/495], Time: 0.38, lr: [0.006434793766461272], Loss: 2.086039, Acc:0.797587, Semantic loss: 0.793723, BCE loss: 0.534260, SB loss: 0.758056
2023-10-30 09:46:42,980 Epoch: [187/484] Iter:[230/495], Time: 0.38, lr: [0.006434399247975208], Loss: 2.086812, Acc:0.795554, Semantic loss: 0.797113, BCE loss: 0.530710, SB loss: 0.758988
2023-10-30 09:46:46,656 Epoch: [187/484] Iter:[240/495], Time: 0.38, lr: [0.006434004726801406], Loss: 2.089239, Acc:0.795089, Semantic loss: 0.797752, BCE loss: 0.531216, SB loss: 0.760270
2023-10-30 09:46:50,443 Epoch: [187/484] Iter:[250/495], Time: 0.38, lr: [0.006433610202939662], Loss: 2.087221, Acc:0.794583, Semantic loss: 0.794463, BCE loss: 0.532666, SB loss: 0.760092
2023-10-30 09:46:54,186 Epoch: [187/484] Iter:[260/495], Time: 0.38, lr: [0.006433215676389776], Loss: 2.088873, Acc:0.794032, Semantic loss: 0.793142, BCE loss: 0.534745, SB loss: 0.760986
2023-10-30 09:46:57,936 Epoch: [187/484] Iter:[270/495], Time: 0.38, lr: [0.006432821147151546], Loss: 2.087733, Acc:0.794304, Semantic loss: 0.792094, BCE loss: 0.535180, SB loss: 0.760460
2023-10-30 09:47:01,777 Epoch: [187/484] Iter:[280/495], Time: 0.38, lr: [0.006432426615224771], Loss: 2.084686, Acc:0.795194, Semantic loss: 0.789325, BCE loss: 0.536002, SB loss: 0.759359
2023-10-30 09:47:05,581 Epoch: [187/484] Iter:[290/495], Time: 0.38, lr: [0.00643203208060925], Loss: 2.085453, Acc:0.794342, Semantic loss: 0.789653, BCE loss: 0.537632, SB loss: 0.758168
2023-10-30 09:47:09,269 Epoch: [187/484] Iter:[300/495], Time: 0.38, lr: [0.00643163754330478], Loss: 2.083115, Acc:0.794410, Semantic loss: 0.789793, BCE loss: 0.536533, SB loss: 0.756788
2023-10-30 09:47:12,957 Epoch: [187/484] Iter:[310/495], Time: 0.38, lr: [0.006431243003311159], Loss: 2.084509, Acc:0.795572, Semantic loss: 0.789118, BCE loss: 0.537906, SB loss: 0.757486
2023-10-30 09:47:16,633 Epoch: [187/484] Iter:[320/495], Time: 0.38, lr: [0.006430848460628187], Loss: 2.088639, Acc:0.796164, Semantic loss: 0.790719, BCE loss: 0.538575, SB loss: 0.759345
2023-10-30 09:47:20,296 Epoch: [187/484] Iter:[330/495], Time: 0.38, lr: [0.00643045391525566], Loss: 2.086435, Acc:0.796237, Semantic loss: 0.790802, BCE loss: 0.537051, SB loss: 0.758583
2023-10-30 09:47:24,006 Epoch: [187/484] Iter:[340/495], Time: 0.37, lr: [0.006430059367193382], Loss: 2.086073, Acc:0.795474, Semantic loss: 0.790639, BCE loss: 0.537241, SB loss: 0.758193
2023-10-30 09:47:27,770 Epoch: [187/484] Iter:[350/495], Time: 0.37, lr: [0.006429664816441145], Loss: 2.088570, Acc:0.794934, Semantic loss: 0.795156, BCE loss: 0.535313, SB loss: 0.758101
2023-10-30 09:47:31,449 Epoch: [187/484] Iter:[360/495], Time: 0.37, lr: [0.006429270262998749], Loss: 2.094610, Acc:0.794142, Semantic loss: 0.798296, BCE loss: 0.537224, SB loss: 0.759090
2023-10-30 09:47:35,181 Epoch: [187/484] Iter:[370/495], Time: 0.37, lr: [0.006428875706865993], Loss: 2.102589, Acc:0.793642, Semantic loss: 0.803524, BCE loss: 0.537245, SB loss: 0.761819
2023-10-30 09:47:38,923 Epoch: [187/484] Iter:[380/495], Time: 0.37, lr: [0.006428481148042675], Loss: 2.100608, Acc:0.792959, Semantic loss: 0.801223, BCE loss: 0.538156, SB loss: 0.761229
2023-10-30 09:47:42,527 Epoch: [187/484] Iter:[390/495], Time: 0.37, lr: [0.0064280865865285934], Loss: 2.101721, Acc:0.793556, Semantic loss: 0.802152, BCE loss: 0.538469, SB loss: 0.761100
2023-10-30 09:47:46,273 Epoch: [187/484] Iter:[400/495], Time: 0.37, lr: [0.006427692022323545], Loss: 2.100559, Acc:0.793422, Semantic loss: 0.801572, BCE loss: 0.538302, SB loss: 0.760685
2023-10-30 09:47:50,007 Epoch: [187/484] Iter:[410/495], Time: 0.37, lr: [0.006427297455427329], Loss: 2.103128, Acc:0.793132, Semantic loss: 0.803859, BCE loss: 0.538174, SB loss: 0.761095
2023-10-30 09:47:53,728 Epoch: [187/484] Iter:[420/495], Time: 0.37, lr: [0.006426902885839745], Loss: 2.103575, Acc:0.793719, Semantic loss: 0.802651, BCE loss: 0.540385, SB loss: 0.760539
2023-10-30 09:47:57,347 Epoch: [187/484] Iter:[430/495], Time: 0.37, lr: [0.006426508313560588], Loss: 2.099794, Acc:0.793653, Semantic loss: 0.800172, BCE loss: 0.539523, SB loss: 0.760099
2023-10-30 09:48:01,068 Epoch: [187/484] Iter:[440/495], Time: 0.37, lr: [0.006426113738589659], Loss: 2.107021, Acc:0.794001, Semantic loss: 0.805295, BCE loss: 0.540931, SB loss: 0.760796
2023-10-30 09:48:04,841 Epoch: [187/484] Iter:[450/495], Time: 0.37, lr: [0.006425719160926753], Loss: 2.106323, Acc:0.794950, Semantic loss: 0.803962, BCE loss: 0.541832, SB loss: 0.760529
2023-10-30 09:48:08,468 Epoch: [187/484] Iter:[460/495], Time: 0.37, lr: [0.0064253245805716685], Loss: 2.114309, Acc:0.794946, Semantic loss: 0.808978, BCE loss: 0.542728, SB loss: 0.762603
2023-10-30 09:48:12,151 Epoch: [187/484] Iter:[470/495], Time: 0.37, lr: [0.006424929997524206], Loss: 2.114898, Acc:0.795061, Semantic loss: 0.809002, BCE loss: 0.542571, SB loss: 0.763325
2023-10-30 09:48:15,935 Epoch: [187/484] Iter:[480/495], Time: 0.37, lr: [0.00642453541178416], Loss: 2.116193, Acc:0.795396, Semantic loss: 0.808397, BCE loss: 0.544379, SB loss: 0.763418
2023-10-30 09:48:19,532 Epoch: [187/484] Iter:[490/495], Time: 0.37, lr: [0.0064241408233513325], Loss: 2.116673, Acc:0.796383, Semantic loss: 0.807946, BCE loss: 0.545205, SB loss: 0.763522
2023-10-30 09:48:20,951 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:48:21,190 Loss: 2.128, MeanIU:  0.6793, Best_mIoU:  0.6984
2023-10-30 09:48:21,190 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765]
2023-10-30 09:48:23,135 Epoch: [188/484] Iter:[0/495], Time: 1.91, lr: [0.006423943528125062], Loss: 1.834020, Acc:0.641886, Semantic loss: 0.679757, BCE loss: 0.435392, SB loss: 0.718872
2023-10-30 09:48:27,202 Epoch: [188/484] Iter:[10/495], Time: 0.54, lr: [0.006423548935652678], Loss: 1.892477, Acc:0.801098, Semantic loss: 0.687257, BCE loss: 0.498376, SB loss: 0.706844
2023-10-30 09:48:31,000 Epoch: [188/484] Iter:[20/495], Time: 0.47, lr: [0.006423154340487005], Loss: 1.952522, Acc:0.801810, Semantic loss: 0.719488, BCE loss: 0.519957, SB loss: 0.713077
2023-10-30 09:48:34,742 Epoch: [188/484] Iter:[30/495], Time: 0.44, lr: [0.006422759742627841], Loss: 1.958671, Acc:0.805116, Semantic loss: 0.726959, BCE loss: 0.509585, SB loss: 0.722127
2023-10-30 09:48:38,436 Epoch: [188/484] Iter:[40/495], Time: 0.42, lr: [0.006422365142074983], Loss: 1.952809, Acc:0.805085, Semantic loss: 0.723785, BCE loss: 0.503149, SB loss: 0.725874
2023-10-30 09:48:42,059 Epoch: [188/484] Iter:[50/495], Time: 0.41, lr: [0.006421970538828228], Loss: 1.968658, Acc:0.798281, Semantic loss: 0.734811, BCE loss: 0.508388, SB loss: 0.725459
2023-10-30 09:48:45,824 Epoch: [188/484] Iter:[60/495], Time: 0.40, lr: [0.0064215759328873755], Loss: 1.969770, Acc:0.795912, Semantic loss: 0.736087, BCE loss: 0.509292, SB loss: 0.724391
2023-10-30 09:48:49,398 Epoch: [188/484] Iter:[70/495], Time: 0.40, lr: [0.006421181324252222], Loss: 1.967859, Acc:0.795194, Semantic loss: 0.736124, BCE loss: 0.503174, SB loss: 0.728561
2023-10-30 09:48:53,098 Epoch: [188/484] Iter:[80/495], Time: 0.39, lr: [0.006420786712922565], Loss: 1.978725, Acc:0.792921, Semantic loss: 0.743658, BCE loss: 0.503105, SB loss: 0.731963
2023-10-30 09:48:56,764 Epoch: [188/484] Iter:[90/495], Time: 0.39, lr: [0.0064203920988982035], Loss: 1.980506, Acc:0.793867, Semantic loss: 0.741534, BCE loss: 0.505728, SB loss: 0.733244
2023-10-30 09:49:00,492 Epoch: [188/484] Iter:[100/495], Time: 0.39, lr: [0.006419997482178934], Loss: 1.990365, Acc:0.797853, Semantic loss: 0.745155, BCE loss: 0.510735, SB loss: 0.734475
2023-10-30 09:49:04,147 Epoch: [188/484] Iter:[110/495], Time: 0.39, lr: [0.006419602862764554], Loss: 2.012506, Acc:0.797835, Semantic loss: 0.751813, BCE loss: 0.522717, SB loss: 0.737977
2023-10-30 09:49:07,978 Epoch: [188/484] Iter:[120/495], Time: 0.39, lr: [0.00641920824065486], Loss: 2.029656, Acc:0.800071, Semantic loss: 0.755155, BCE loss: 0.533944, SB loss: 0.740557
2023-10-30 09:49:11,727 Epoch: [188/484] Iter:[130/495], Time: 0.39, lr: [0.006418813615849651], Loss: 2.027989, Acc:0.797839, Semantic loss: 0.755504, BCE loss: 0.531605, SB loss: 0.740879
2023-10-30 09:49:15,418 Epoch: [188/484] Iter:[140/495], Time: 0.38, lr: [0.006418418988348724], Loss: 2.026192, Acc:0.798145, Semantic loss: 0.752222, BCE loss: 0.531228, SB loss: 0.742742
2023-10-30 09:49:19,205 Epoch: [188/484] Iter:[150/495], Time: 0.38, lr: [0.006418024358151876], Loss: 2.025902, Acc:0.799573, Semantic loss: 0.753702, BCE loss: 0.529535, SB loss: 0.742665
2023-10-30 09:49:22,917 Epoch: [188/484] Iter:[160/495], Time: 0.38, lr: [0.006417629725258907], Loss: 2.030530, Acc:0.796342, Semantic loss: 0.757392, BCE loss: 0.528863, SB loss: 0.744275
2023-10-30 09:49:26,597 Epoch: [188/484] Iter:[170/495], Time: 0.38, lr: [0.006417235089669611], Loss: 2.029446, Acc:0.796024, Semantic loss: 0.757934, BCE loss: 0.524981, SB loss: 0.746531
2023-10-30 09:49:30,275 Epoch: [188/484] Iter:[180/495], Time: 0.38, lr: [0.006416840451383786], Loss: 2.030850, Acc:0.793155, Semantic loss: 0.758288, BCE loss: 0.526535, SB loss: 0.746027
2023-10-30 09:49:33,940 Epoch: [188/484] Iter:[190/495], Time: 0.38, lr: [0.00641644581040123], Loss: 2.037615, Acc:0.791690, Semantic loss: 0.762438, BCE loss: 0.525446, SB loss: 0.749730
2023-10-30 09:49:37,650 Epoch: [188/484] Iter:[200/495], Time: 0.38, lr: [0.006416051166721741], Loss: 2.033158, Acc:0.791487, Semantic loss: 0.760712, BCE loss: 0.523310, SB loss: 0.749136
2023-10-30 09:49:41,416 Epoch: [188/484] Iter:[210/495], Time: 0.38, lr: [0.006415656520345115], Loss: 2.031075, Acc:0.791377, Semantic loss: 0.758515, BCE loss: 0.525735, SB loss: 0.746825
2023-10-30 09:49:45,082 Epoch: [188/484] Iter:[220/495], Time: 0.38, lr: [0.006415261871271148], Loss: 2.033506, Acc:0.790997, Semantic loss: 0.759329, BCE loss: 0.527082, SB loss: 0.747095
2023-10-30 09:49:48,821 Epoch: [188/484] Iter:[230/495], Time: 0.38, lr: [0.00641486721949964], Loss: 2.028674, Acc:0.791728, Semantic loss: 0.756973, BCE loss: 0.526628, SB loss: 0.745073
2023-10-30 09:49:52,521 Epoch: [188/484] Iter:[240/495], Time: 0.38, lr: [0.006414472565030387], Loss: 2.034622, Acc:0.792340, Semantic loss: 0.761540, BCE loss: 0.527292, SB loss: 0.745790
2023-10-30 09:49:56,185 Epoch: [188/484] Iter:[250/495], Time: 0.38, lr: [0.006414077907863187], Loss: 2.036783, Acc:0.791797, Semantic loss: 0.763021, BCE loss: 0.528064, SB loss: 0.745698
2023-10-30 09:49:59,936 Epoch: [188/484] Iter:[260/495], Time: 0.38, lr: [0.006413683247997836], Loss: 2.037245, Acc:0.791167, Semantic loss: 0.764555, BCE loss: 0.527523, SB loss: 0.745167
2023-10-30 09:50:03,592 Epoch: [188/484] Iter:[270/495], Time: 0.38, lr: [0.0064132885854341305], Loss: 2.043499, Acc:0.791482, Semantic loss: 0.765825, BCE loss: 0.531498, SB loss: 0.746176
2023-10-30 09:50:07,259 Epoch: [188/484] Iter:[280/495], Time: 0.38, lr: [0.006412893920171869], Loss: 2.047447, Acc:0.791124, Semantic loss: 0.768783, BCE loss: 0.531857, SB loss: 0.746807
2023-10-30 09:50:10,861 Epoch: [188/484] Iter:[290/495], Time: 0.38, lr: [0.006412499252210846], Loss: 2.049281, Acc:0.791327, Semantic loss: 0.769686, BCE loss: 0.532680, SB loss: 0.746915
2023-10-30 09:50:14,529 Epoch: [188/484] Iter:[300/495], Time: 0.38, lr: [0.006412104581550861], Loss: 2.049276, Acc:0.790031, Semantic loss: 0.770330, BCE loss: 0.531787, SB loss: 0.747159
2023-10-30 09:50:18,204 Epoch: [188/484] Iter:[310/495], Time: 0.38, lr: [0.006411709908191712], Loss: 2.051934, Acc:0.789517, Semantic loss: 0.770541, BCE loss: 0.533509, SB loss: 0.747885
2023-10-30 09:50:21,887 Epoch: [188/484] Iter:[320/495], Time: 0.38, lr: [0.006411315232133194], Loss: 2.052769, Acc:0.790513, Semantic loss: 0.771552, BCE loss: 0.533264, SB loss: 0.747952
2023-10-30 09:50:25,580 Epoch: [188/484] Iter:[330/495], Time: 0.38, lr: [0.006410920553375102], Loss: 2.061996, Acc:0.790490, Semantic loss: 0.776587, BCE loss: 0.534861, SB loss: 0.750548
2023-10-30 09:50:29,318 Epoch: [188/484] Iter:[340/495], Time: 0.38, lr: [0.0064105258719172374], Loss: 2.060097, Acc:0.790944, Semantic loss: 0.775616, BCE loss: 0.534568, SB loss: 0.749913
2023-10-30 09:50:32,996 Epoch: [188/484] Iter:[350/495], Time: 0.38, lr: [0.0064101311877593934], Loss: 2.060585, Acc:0.790767, Semantic loss: 0.776189, BCE loss: 0.534274, SB loss: 0.750122
2023-10-30 09:50:36,739 Epoch: [188/484] Iter:[360/495], Time: 0.38, lr: [0.006409736500901367], Loss: 2.058929, Acc:0.790290, Semantic loss: 0.774692, BCE loss: 0.534409, SB loss: 0.749829
2023-10-30 09:50:40,588 Epoch: [188/484] Iter:[370/495], Time: 0.38, lr: [0.006409341811342958], Loss: 2.054477, Acc:0.789478, Semantic loss: 0.772890, BCE loss: 0.532071, SB loss: 0.749516
2023-10-30 09:50:44,476 Epoch: [188/484] Iter:[380/495], Time: 0.38, lr: [0.00640894711908396], Loss: 2.058750, Acc:0.790498, Semantic loss: 0.776170, BCE loss: 0.532740, SB loss: 0.749840
2023-10-30 09:50:48,202 Epoch: [188/484] Iter:[390/495], Time: 0.38, lr: [0.006408552424124172], Loss: 2.058219, Acc:0.791648, Semantic loss: 0.775817, BCE loss: 0.532554, SB loss: 0.749848
2023-10-30 09:50:51,979 Epoch: [188/484] Iter:[400/495], Time: 0.38, lr: [0.00640815772646339], Loss: 2.062026, Acc:0.791876, Semantic loss: 0.777468, BCE loss: 0.534348, SB loss: 0.750210
2023-10-30 09:50:55,641 Epoch: [188/484] Iter:[410/495], Time: 0.38, lr: [0.006407763026101409], Loss: 2.060331, Acc:0.792476, Semantic loss: 0.775352, BCE loss: 0.535554, SB loss: 0.749426
2023-10-30 09:50:59,360 Epoch: [188/484] Iter:[420/495], Time: 0.38, lr: [0.006407368323038028], Loss: 2.058997, Acc:0.792530, Semantic loss: 0.774872, BCE loss: 0.535064, SB loss: 0.749061
2023-10-30 09:51:03,075 Epoch: [188/484] Iter:[430/495], Time: 0.38, lr: [0.006406973617273041], Loss: 2.062487, Acc:0.793072, Semantic loss: 0.777501, BCE loss: 0.535538, SB loss: 0.749449
2023-10-30 09:51:06,818 Epoch: [188/484] Iter:[440/495], Time: 0.38, lr: [0.006406578908806245], Loss: 2.060220, Acc:0.793511, Semantic loss: 0.776552, BCE loss: 0.534562, SB loss: 0.749106
2023-10-30 09:51:10,535 Epoch: [188/484] Iter:[450/495], Time: 0.38, lr: [0.00640618419763744], Loss: 2.060563, Acc:0.794145, Semantic loss: 0.775956, BCE loss: 0.535474, SB loss: 0.749133
2023-10-30 09:51:14,269 Epoch: [188/484] Iter:[460/495], Time: 0.38, lr: [0.0064057894837664196], Loss: 2.061684, Acc:0.794995, Semantic loss: 0.776030, BCE loss: 0.536080, SB loss: 0.749574
2023-10-30 09:51:17,905 Epoch: [188/484] Iter:[470/495], Time: 0.38, lr: [0.006405394767192981], Loss: 2.061187, Acc:0.794721, Semantic loss: 0.775955, BCE loss: 0.535484, SB loss: 0.749748
2023-10-30 09:51:21,573 Epoch: [188/484] Iter:[480/495], Time: 0.37, lr: [0.0064050000479169205], Loss: 2.061202, Acc:0.794894, Semantic loss: 0.775807, BCE loss: 0.535571, SB loss: 0.749824
2023-10-30 09:51:25,056 Epoch: [188/484] Iter:[490/495], Time: 0.37, lr: [0.006404605325938034], Loss: 2.061147, Acc:0.794952, Semantic loss: 0.776833, BCE loss: 0.534877, SB loss: 0.749438
2023-10-30 09:51:26,464 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:51:26,703 Loss: 2.128, MeanIU:  0.6793, Best_mIoU:  0.6984
2023-10-30 09:51:26,703 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765]
2023-10-30 09:51:28,714 Epoch: [189/484] Iter:[0/495], Time: 1.96, lr: [0.006404407963934968], Loss: 1.977272, Acc:0.776738, Semantic loss: 0.620276, BCE loss: 0.650032, SB loss: 0.706964
2023-10-30 09:51:32,814 Epoch: [189/484] Iter:[10/495], Time: 0.55, lr: [0.0064040132379014625], Loss: 2.098105, Acc:0.766180, Semantic loss: 0.784244, BCE loss: 0.545076, SB loss: 0.768785
2023-10-30 09:51:36,547 Epoch: [189/484] Iter:[20/495], Time: 0.47, lr: [0.006403618509164623], Loss: 2.114087, Acc:0.777204, Semantic loss: 0.796356, BCE loss: 0.538112, SB loss: 0.779618
2023-10-30 09:51:40,295 Epoch: [189/484] Iter:[30/495], Time: 0.44, lr: [0.006403223777724243], Loss: 2.120726, Acc:0.774377, Semantic loss: 0.815659, BCE loss: 0.522936, SB loss: 0.782130
2023-10-30 09:51:43,987 Epoch: [189/484] Iter:[40/495], Time: 0.42, lr: [0.006402829043580123], Loss: 2.139332, Acc:0.778805, Semantic loss: 0.809684, BCE loss: 0.547108, SB loss: 0.782540
2023-10-30 09:51:47,622 Epoch: [189/484] Iter:[50/495], Time: 0.41, lr: [0.006402434306732057], Loss: 2.124459, Acc:0.782148, Semantic loss: 0.793087, BCE loss: 0.557714, SB loss: 0.773657
2023-10-30 09:51:51,267 Epoch: [189/484] Iter:[60/495], Time: 0.40, lr: [0.006402039567179841], Loss: 2.109943, Acc:0.786197, Semantic loss: 0.784320, BCE loss: 0.558211, SB loss: 0.767412
2023-10-30 09:51:54,954 Epoch: [189/484] Iter:[70/495], Time: 0.40, lr: [0.006401644824923273], Loss: 2.126431, Acc:0.789018, Semantic loss: 0.795778, BCE loss: 0.557689, SB loss: 0.772964
2023-10-30 09:51:58,603 Epoch: [189/484] Iter:[80/495], Time: 0.39, lr: [0.006401250079962148], Loss: 2.135280, Acc:0.785458, Semantic loss: 0.808236, BCE loss: 0.553495, SB loss: 0.773549
2023-10-30 09:52:02,254 Epoch: [189/484] Iter:[90/495], Time: 0.39, lr: [0.006400855332296261], Loss: 2.130568, Acc:0.783988, Semantic loss: 0.805524, BCE loss: 0.552887, SB loss: 0.772157
2023-10-30 09:52:05,962 Epoch: [189/484] Iter:[100/495], Time: 0.39, lr: [0.00640046058192541], Loss: 2.115668, Acc:0.785437, Semantic loss: 0.794110, BCE loss: 0.548367, SB loss: 0.773191
2023-10-30 09:52:09,636 Epoch: [189/484] Iter:[110/495], Time: 0.39, lr: [0.006400065828849391], Loss: 2.110121, Acc:0.786400, Semantic loss: 0.793186, BCE loss: 0.545776, SB loss: 0.771159
2023-10-30 09:52:13,307 Epoch: [189/484] Iter:[120/495], Time: 0.38, lr: [0.006399671073067998], Loss: 2.111814, Acc:0.783082, Semantic loss: 0.790383, BCE loss: 0.548605, SB loss: 0.772826
2023-10-30 09:52:16,993 Epoch: [189/484] Iter:[130/495], Time: 0.38, lr: [0.006399276314581029], Loss: 2.102082, Acc:0.785358, Semantic loss: 0.786892, BCE loss: 0.545323, SB loss: 0.769867
2023-10-30 09:52:20,592 Epoch: [189/484] Iter:[140/495], Time: 0.38, lr: [0.006398881553388281], Loss: 2.095880, Acc:0.787380, Semantic loss: 0.784586, BCE loss: 0.544464, SB loss: 0.766830
2023-10-30 09:52:24,278 Epoch: [189/484] Iter:[150/495], Time: 0.38, lr: [0.006398486789489547], Loss: 2.089879, Acc:0.788462, Semantic loss: 0.782461, BCE loss: 0.542888, SB loss: 0.764530
2023-10-30 09:52:28,017 Epoch: [189/484] Iter:[160/495], Time: 0.38, lr: [0.006398092022884626], Loss: 2.093823, Acc:0.789800, Semantic loss: 0.783914, BCE loss: 0.546199, SB loss: 0.763710
2023-10-30 09:52:31,730 Epoch: [189/484] Iter:[170/495], Time: 0.38, lr: [0.006397697253573312], Loss: 2.083271, Acc:0.789459, Semantic loss: 0.779846, BCE loss: 0.543554, SB loss: 0.759870
2023-10-30 09:52:35,421 Epoch: [189/484] Iter:[180/495], Time: 0.38, lr: [0.006397302481555399], Loss: 2.081598, Acc:0.791403, Semantic loss: 0.778408, BCE loss: 0.543963, SB loss: 0.759227
2023-10-30 09:52:39,172 Epoch: [189/484] Iter:[190/495], Time: 0.38, lr: [0.006396907706830688], Loss: 2.082918, Acc:0.792307, Semantic loss: 0.778749, BCE loss: 0.547000, SB loss: 0.757168
2023-10-30 09:52:42,979 Epoch: [189/484] Iter:[200/495], Time: 0.38, lr: [0.00639651292939897], Loss: 2.077356, Acc:0.790226, Semantic loss: 0.775678, BCE loss: 0.544169, SB loss: 0.757510
2023-10-30 09:52:46,789 Epoch: [189/484] Iter:[210/495], Time: 0.38, lr: [0.006396118149260043], Loss: 2.078723, Acc:0.791120, Semantic loss: 0.775882, BCE loss: 0.546010, SB loss: 0.756831
2023-10-30 09:52:50,604 Epoch: [189/484] Iter:[220/495], Time: 0.38, lr: [0.006395723366413704], Loss: 2.077163, Acc:0.792521, Semantic loss: 0.774528, BCE loss: 0.546083, SB loss: 0.756552
2023-10-30 09:52:54,365 Epoch: [189/484] Iter:[230/495], Time: 0.38, lr: [0.006395328580859746], Loss: 2.082253, Acc:0.792515, Semantic loss: 0.778620, BCE loss: 0.546069, SB loss: 0.757564
2023-10-30 09:52:58,124 Epoch: [189/484] Iter:[240/495], Time: 0.38, lr: [0.006394933792597967], Loss: 2.082694, Acc:0.793111, Semantic loss: 0.777948, BCE loss: 0.546844, SB loss: 0.757901
2023-10-30 09:53:01,700 Epoch: [189/484] Iter:[250/495], Time: 0.38, lr: [0.0063945390016281614], Loss: 2.077444, Acc:0.794026, Semantic loss: 0.776423, BCE loss: 0.544926, SB loss: 0.756095
2023-10-30 09:53:05,434 Epoch: [189/484] Iter:[260/495], Time: 0.38, lr: [0.006394144207950124], Loss: 2.075813, Acc:0.793097, Semantic loss: 0.776698, BCE loss: 0.544048, SB loss: 0.755066
2023-10-30 09:53:09,129 Epoch: [189/484] Iter:[270/495], Time: 0.38, lr: [0.006393749411563653], Loss: 2.077203, Acc:0.792995, Semantic loss: 0.778976, BCE loss: 0.543761, SB loss: 0.754466
2023-10-30 09:53:12,826 Epoch: [189/484] Iter:[280/495], Time: 0.38, lr: [0.006393354612468541], Loss: 2.078440, Acc:0.793197, Semantic loss: 0.779506, BCE loss: 0.544052, SB loss: 0.754882
2023-10-30 09:53:16,617 Epoch: [189/484] Iter:[290/495], Time: 0.38, lr: [0.006392959810664586], Loss: 2.074012, Acc:0.793670, Semantic loss: 0.777124, BCE loss: 0.542259, SB loss: 0.754629
2023-10-30 09:53:20,251 Epoch: [189/484] Iter:[300/495], Time: 0.38, lr: [0.006392565006151584], Loss: 2.073447, Acc:0.794006, Semantic loss: 0.777327, BCE loss: 0.541790, SB loss: 0.754330
2023-10-30 09:53:23,894 Epoch: [189/484] Iter:[310/495], Time: 0.38, lr: [0.006392170198929328], Loss: 2.074502, Acc:0.792664, Semantic loss: 0.776983, BCE loss: 0.543434, SB loss: 0.754085
2023-10-30 09:53:27,653 Epoch: [189/484] Iter:[320/495], Time: 0.38, lr: [0.006391775388997615], Loss: 2.071056, Acc:0.792453, Semantic loss: 0.775515, BCE loss: 0.541536, SB loss: 0.754005
2023-10-30 09:53:31,484 Epoch: [189/484] Iter:[330/495], Time: 0.38, lr: [0.006391380576356239], Loss: 2.070346, Acc:0.791964, Semantic loss: 0.776837, BCE loss: 0.540266, SB loss: 0.753244
2023-10-30 09:53:35,255 Epoch: [189/484] Iter:[340/495], Time: 0.38, lr: [0.006390985761004997], Loss: 2.072332, Acc:0.792224, Semantic loss: 0.777173, BCE loss: 0.541513, SB loss: 0.753645
2023-10-30 09:53:38,930 Epoch: [189/484] Iter:[350/495], Time: 0.38, lr: [0.006390590942943684], Loss: 2.071429, Acc:0.791723, Semantic loss: 0.775688, BCE loss: 0.541907, SB loss: 0.753833
2023-10-30 09:53:42,782 Epoch: [189/484] Iter:[360/495], Time: 0.38, lr: [0.006390196122172095], Loss: 2.066990, Acc:0.792106, Semantic loss: 0.773903, BCE loss: 0.540340, SB loss: 0.752747
2023-10-30 09:53:46,553 Epoch: [189/484] Iter:[370/495], Time: 0.38, lr: [0.0063898012986900255], Loss: 2.069736, Acc:0.792760, Semantic loss: 0.774093, BCE loss: 0.542973, SB loss: 0.752671
2023-10-30 09:53:50,288 Epoch: [189/484] Iter:[380/495], Time: 0.38, lr: [0.0063894064724972725], Loss: 2.069451, Acc:0.793544, Semantic loss: 0.775189, BCE loss: 0.541954, SB loss: 0.752308
2023-10-30 09:53:54,111 Epoch: [189/484] Iter:[390/495], Time: 0.38, lr: [0.006389011643593629], Loss: 2.070572, Acc:0.794391, Semantic loss: 0.776170, BCE loss: 0.540941, SB loss: 0.753460
2023-10-30 09:53:57,884 Epoch: [189/484] Iter:[400/495], Time: 0.38, lr: [0.00638861681197889], Loss: 2.071222, Acc:0.795163, Semantic loss: 0.776204, BCE loss: 0.541119, SB loss: 0.753898
2023-10-30 09:54:01,571 Epoch: [189/484] Iter:[410/495], Time: 0.38, lr: [0.006388221977652853], Loss: 2.069745, Acc:0.794931, Semantic loss: 0.775718, BCE loss: 0.540147, SB loss: 0.753880
2023-10-30 09:54:05,239 Epoch: [189/484] Iter:[420/495], Time: 0.38, lr: [0.00638782714061531], Loss: 2.070441, Acc:0.795312, Semantic loss: 0.776221, BCE loss: 0.541020, SB loss: 0.753200
2023-10-30 09:54:08,912 Epoch: [189/484] Iter:[430/495], Time: 0.38, lr: [0.00638743230086606], Loss: 2.067383, Acc:0.795991, Semantic loss: 0.774749, BCE loss: 0.540310, SB loss: 0.752324
2023-10-30 09:54:12,550 Epoch: [189/484] Iter:[440/495], Time: 0.38, lr: [0.006387037458404893], Loss: 2.068177, Acc:0.796406, Semantic loss: 0.775697, BCE loss: 0.540049, SB loss: 0.752432
2023-10-30 09:54:16,267 Epoch: [189/484] Iter:[450/495], Time: 0.38, lr: [0.00638664261323161], Loss: 2.066312, Acc:0.796271, Semantic loss: 0.775406, BCE loss: 0.539428, SB loss: 0.751478
2023-10-30 09:54:19,960 Epoch: [189/484] Iter:[460/495], Time: 0.38, lr: [0.006386247765346003], Loss: 2.068694, Acc:0.795420, Semantic loss: 0.777400, BCE loss: 0.539499, SB loss: 0.751795
2023-10-30 09:54:23,665 Epoch: [189/484] Iter:[470/495], Time: 0.38, lr: [0.006385852914747866], Loss: 2.066998, Acc:0.795766, Semantic loss: 0.776971, BCE loss: 0.538720, SB loss: 0.751306
2023-10-30 09:54:27,449 Epoch: [189/484] Iter:[480/495], Time: 0.38, lr: [0.006385458061436996], Loss: 2.064010, Acc:0.795910, Semantic loss: 0.774739, BCE loss: 0.538891, SB loss: 0.750380
2023-10-30 09:54:30,979 Epoch: [189/484] Iter:[490/495], Time: 0.38, lr: [0.006385063205413189], Loss: 2.064721, Acc:0.795731, Semantic loss: 0.775258, BCE loss: 0.538123, SB loss: 0.751340
2023-10-30 09:54:32,373 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 09:54:32,613 Loss: 2.128, MeanIU:  0.6793, Best_mIoU:  0.6984
2023-10-30 09:54:32,613 [0.97287601 0.78721954 0.89806559 0.38267983 0.39824899 0.57613896
 0.65800338 0.71164067 0.90612866 0.55979264 0.92973363 0.76823989
 0.56170568 0.92608055 0.47772597 0.71078082 0.47112119 0.50779506
 0.70238765]
2023-10-30 09:54:34,431 Epoch: [190/484] Iter:[0/495], Time: 1.78, lr: [0.006384865776383867], Loss: 2.467731, Acc:0.743769, Semantic loss: 0.883779, BCE loss: 0.710834, SB loss: 0.873119
2023-10-30 09:54:38,483 Epoch: [190/484] Iter:[10/495], Time: 0.53, lr: [0.006384470916290266], Loss: 2.138815, Acc:0.747014, Semantic loss: 0.816793, BCE loss: 0.562459, SB loss: 0.759562
2023-10-30 09:54:42,314 Epoch: [190/484] Iter:[20/495], Time: 0.46, lr: [0.0063840760534832125], Loss: 2.245507, Acc:0.775541, Semantic loss: 0.902223, BCE loss: 0.569476, SB loss: 0.773808
2023-10-30 09:54:46,194 Epoch: [190/484] Iter:[30/495], Time: 0.44, lr: [0.006383681187962504], Loss: 2.163399, Acc:0.778687, Semantic loss: 0.835940, BCE loss: 0.568542, SB loss: 0.758917
2023-10-30 09:54:49,943 Epoch: [190/484] Iter:[40/495], Time: 0.42, lr: [0.006383286319727933], Loss: 2.144320, Acc:0.777757, Semantic loss: 0.827441, BCE loss: 0.562456, SB loss: 0.754423
2023-10-30 09:54:53,664 Epoch: [190/484] Iter:[50/495], Time: 0.41, lr: [0.006382891448779296], Loss: 2.175990, Acc:0.779138, Semantic loss: 0.847200, BCE loss: 0.564023, SB loss: 0.764768
2023-10-30 09:54:57,315 Epoch: [190/484] Iter:[60/495], Time: 0.40, lr: [0.006382496575116386], Loss: 2.182417, Acc:0.783658, Semantic loss: 0.844915, BCE loss: 0.569322, SB loss: 0.768180
2023-10-30 09:55:00,997 Epoch: [190/484] Iter:[70/495], Time: 0.40, lr: [0.006382101698738998], Loss: 2.162908, Acc:0.789363, Semantic loss: 0.830082, BCE loss: 0.565572, SB loss: 0.767254
2023-10-30 09:55:04,639 Epoch: [190/484] Iter:[80/495], Time: 0.39, lr: [0.006381706819646928], Loss: 2.156905, Acc:0.789560, Semantic loss: 0.827990, BCE loss: 0.563373, SB loss: 0.765543
2023-10-30 09:55:08,322 Epoch: [190/484] Iter:[90/495], Time: 0.39, lr: [0.0063813119378399695], Loss: 2.149904, Acc:0.791624, Semantic loss: 0.824067, BCE loss: 0.561266, SB loss: 0.764571
2023-10-30 09:55:12,008 Epoch: [190/484] Iter:[100/495], Time: 0.39, lr: [0.0063809170533179185], Loss: 2.129940, Acc:0.791645, Semantic loss: 0.810635, BCE loss: 0.561484, SB loss: 0.757821
2023-10-30 09:55:15,866 Epoch: [190/484] Iter:[110/495], Time: 0.39, lr: [0.006380522166080568], Loss: 2.116165, Acc:0.793451, Semantic loss: 0.803270, BCE loss: 0.561325, SB loss: 0.751569
2023-10-30 09:55:19,524 Epoch: [190/484] Iter:[120/495], Time: 0.39, lr: [0.0063801272761277155], Loss: 2.115557, Acc:0.790528, Semantic loss: 0.803067, BCE loss: 0.561029, SB loss: 0.751461
2023-10-30 09:55:23,249 Epoch: [190/484] Iter:[130/495], Time: 0.39, lr: [0.0063797323834591515], Loss: 2.110715, Acc:0.791417, Semantic loss: 0.798155, BCE loss: 0.560250, SB loss: 0.752311
2023-10-30 09:55:26,894 Epoch: [190/484] Iter:[140/495], Time: 0.38, lr: [0.006379337488074673], Loss: 2.103276, Acc:0.791671, Semantic loss: 0.794999, BCE loss: 0.557698, SB loss: 0.750579
2023-10-30 09:55:30,570 Epoch: [190/484] Iter:[150/495], Time: 0.38, lr: [0.006378942589974076], Loss: 2.100082, Acc:0.793512, Semantic loss: 0.792913, BCE loss: 0.555225, SB loss: 0.751943
2023-10-30 09:55:34,263 Epoch: [190/484] Iter:[160/495], Time: 0.38, lr: [0.006378547689157151], Loss: 2.095286, Acc:0.794120, Semantic loss: 0.790084, BCE loss: 0.555962, SB loss: 0.749240
2023-10-30 09:55:37,917 Epoch: [190/484] Iter:[170/495], Time: 0.38, lr: [0.006378152785623694], Loss: 2.099951, Acc:0.792599, Semantic loss: 0.795100, BCE loss: 0.553649, SB loss: 0.751202
2023-10-30 09:55:41,626 Epoch: [190/484] Iter:[180/495], Time: 0.38, lr: [0.0063777578793735015], Loss: 2.096504, Acc:0.792478, Semantic loss: 0.792377, BCE loss: 0.552494, SB loss: 0.751633
2023-10-30 09:55:45,354 Epoch: [190/484] Iter:[190/495], Time: 0.38, lr: [0.0063773629704063665], Loss: 2.099174, Acc:0.792815, Semantic loss: 0.791496, BCE loss: 0.555345, SB loss: 0.752333
2023-10-30 09:55:49,018 Epoch: [190/484] Iter:[200/495], Time: 0.38, lr: [0.006376968058722082], Loss: 2.094531, Acc:0.794529, Semantic loss: 0.789043, BCE loss: 0.553175, SB loss: 0.752313
2023-10-30 09:55:52,661 Epoch: [190/484] Iter:[210/495], Time: 0.38, lr: [0.0063765731443204444], Loss: 2.094591, Acc:0.794268, Semantic loss: 0.790268, BCE loss: 0.552710, SB loss: 0.751613
2023-10-30 09:55:56,354 Epoch: [190/484] Iter:[220/495], Time: 0.38, lr: [0.006376178227201248], Loss: 2.093056, Acc:0.795073, Semantic loss: 0.788872, BCE loss: 0.552294, SB loss: 0.751890
2023-10-30 09:56:00,073 Epoch: [190/484] Iter:[230/495], Time: 0.38, lr: [0.006375783307364285], Loss: 2.092423, Acc:0.794148, Semantic loss: 0.790888, BCE loss: 0.549706, SB loss: 0.751828
2023-10-30 09:56:03,861 Epoch: [190/484] Iter:[240/495], Time: 0.38, lr: [0.006375388384809351], Loss: 2.086628, Acc:0.792473, Semantic loss: 0.788872, BCE loss: 0.546630, SB loss: 0.751126
2023-10-30 09:56:07,636 Epoch: [190/484] Iter:[250/495], Time: 0.38, lr: [0.006374993459536241], Loss: 2.078171, Acc:0.791947, Semantic loss: 0.784784, BCE loss: 0.544978, SB loss: 0.748409
2023-10-30 09:56:11,414 Epoch: [190/484] Iter:[260/495], Time: 0.38, lr: [0.006374598531544748], Loss: 2.080526, Acc:0.793099, Semantic loss: 0.784496, BCE loss: 0.545953, SB loss: 0.750078
2023-10-30 09:56:15,154 Epoch: [190/484] Iter:[270/495], Time: 0.38, lr: [0.006374203600834666], Loss: 2.078001, Acc:0.792351, Semantic loss: 0.782385, BCE loss: 0.546920, SB loss: 0.748696
2023-10-30 09:56:18,838 Epoch: [190/484] Iter:[280/495], Time: 0.38, lr: [0.00637380866740579], Loss: 2.077170, Acc:0.791462, Semantic loss: 0.782392, BCE loss: 0.545519, SB loss: 0.749259
2023-10-30 09:56:22,568 Epoch: [190/484] Iter:[290/495], Time: 0.38, lr: [0.006373413731257914], Loss: 2.072264, Acc:0.791220, Semantic loss: 0.779727, BCE loss: 0.544101, SB loss: 0.748436
2023-10-30 09:56:26,169 Epoch: [190/484] Iter:[300/495], Time: 0.38, lr: [0.006373018792390831], Loss: 2.070336, Acc:0.791742, Semantic loss: 0.777523, BCE loss: 0.544497, SB loss: 0.748316
2023-10-30 09:56:30,044 Epoch: [190/484] Iter:[310/495], Time: 0.38, lr: [0.006372623850804338], Loss: 2.066891, Acc:0.792453, Semantic loss: 0.776275, BCE loss: 0.542432, SB loss: 0.748184
2023-10-30 09:56:33,882 Epoch: [190/484] Iter:[320/495], Time: 0.38, lr: [0.006372228906498224], Loss: 2.064125, Acc:0.793905, Semantic loss: 0.773656, BCE loss: 0.542859, SB loss: 0.747610
2023-10-30 09:56:37,659 Epoch: [190/484] Iter:[330/495], Time: 0.38, lr: [0.006371833959472288], Loss: 2.064240, Acc:0.795145, Semantic loss: 0.773263, BCE loss: 0.543168, SB loss: 0.747809
2023-10-30 09:56:41,387 Epoch: [190/484] Iter:[340/495], Time: 0.38, lr: [0.006371439009726318], Loss: 2.065937, Acc:0.796574, Semantic loss: 0.773148, BCE loss: 0.545133, SB loss: 0.747655
2023-10-30 09:56:45,067 Epoch: [190/484] Iter:[350/495], Time: 0.38, lr: [0.006371044057260116], Loss: 2.064287, Acc:0.797592, Semantic loss: 0.772026, BCE loss: 0.545927, SB loss: 0.746334
2023-10-30 09:56:48,747 Epoch: [190/484] Iter:[360/495], Time: 0.38, lr: [0.00637064910207347], Loss: 2.065813, Acc:0.797811, Semantic loss: 0.772731, BCE loss: 0.546945, SB loss: 0.746137
2023-10-30 09:56:52,471 Epoch: [190/484] Iter:[370/495], Time: 0.38, lr: [0.006370254144166177], Loss: 2.064750, Acc:0.798665, Semantic loss: 0.772408, BCE loss: 0.546555, SB loss: 0.745787
2023-10-30 09:56:56,220 Epoch: [190/484] Iter:[380/495], Time: 0.38, lr: [0.006369859183538027], Loss: 2.060196, Acc:0.798735, Semantic loss: 0.771438, BCE loss: 0.544317, SB loss: 0.744440
2023-10-30 09:57:00,128 Epoch: [190/484] Iter:[390/495], Time: 0.38, lr: [0.006369464220188818], Loss: 2.061232, Acc:0.798675, Semantic loss: 0.773188, BCE loss: 0.543607, SB loss: 0.744437
2023-10-30 09:57:03,864 Epoch: [190/484] Iter:[400/495], Time: 0.38, lr: [0.006369069254118341], Loss: 2.060804, Acc:0.799727, Semantic loss: 0.772804, BCE loss: 0.543799, SB loss: 0.744201
2023-10-30 09:57:07,565 Epoch: [190/484] Iter:[410/495], Time: 0.38, lr: [0.0063686742853263905], Loss: 2.066590, Acc:0.799700, Semantic loss: 0.776943, BCE loss: 0.543953, SB loss: 0.745694
2023-10-30 09:57:11,286 Epoch: [190/484] Iter:[420/495], Time: 0.38, lr: [0.006368279313812759], Loss: 2.068401, Acc:0.799295, Semantic loss: 0.777566, BCE loss: 0.544525, SB loss: 0.746310
2023-10-30 09:57:15,023 Epoch: [190/484] Iter:[430/495], Time: 0.38, lr: [0.006367884339577244], Loss: 2.069366, Acc:0.798882, Semantic loss: 0.777463, BCE loss: 0.545154, SB loss: 0.746749
2023-10-30 09:57:18,718 Epoch: [190/484] Iter:[440/495], Time: 0.38, lr: [0.006367489362619635], Loss: 2.074521, Acc:0.798880, Semantic loss: 0.780988, BCE loss: 0.545727, SB loss: 0.747806
2023-10-30 09:57:22,584 Epoch: [190/484] Iter:[450/495], Time: 0.38, lr: [0.006367094382939728], Loss: 2.072507, Acc:0.798610, Semantic loss: 0.780394, BCE loss: 0.544340, SB loss: 0.747773
2023-10-30 09:57:26,350 Epoch: [190/484] Iter:[460/495], Time: 0.38, lr: [0.006366699400537316], Loss: 2.072623, Acc:0.798808, Semantic loss: 0.779677, BCE loss: 0.544907, SB loss: 0.748040
2023-10-30 09:57:29,988 Epoch: [190/484] Iter:[470/495], Time: 0.38, lr: [0.006366304415412193], Loss: 2.073647, Acc:0.798671, Semantic loss: 0.779482, BCE loss: 0.546129, SB loss: 0.748036
2023-10-30 09:57:33,739 Epoch: [190/484] Iter:[480/495], Time: 0.38, lr: [0.006365909427564149], Loss: 2.070444, Acc:0.799360, Semantic loss: 0.778217, BCE loss: 0.545323, SB loss: 0.746904
2023-10-30 09:57:37,215 Epoch: [190/484] Iter:[490/495], Time: 0.38, lr: [0.006365514436992984], Loss: 2.071839, Acc:0.799318, Semantic loss: 0.778792, BCE loss: 0.545386, SB loss: 0.747661
2023-10-30 10:00:33,333 0 [9.40115503e-01 6.60725764e-01 8.15015834e-01 1.31854217e-01
 2.50947820e-01 3.90959741e-01 4.50083307e-01 5.75741546e-01
 8.79726337e-01 4.36427583e-01 8.44847182e-01 5.88944511e-01
 1.51957703e-02 8.07936047e-01 8.21081799e-04 5.68257943e-02
 4.11315560e-02 4.84718779e-02 5.77516941e-01] 0.4480678112776468
2023-10-30 10:00:33,334 1 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531] 0.7072390634370924
2023-10-30 10:00:33,338 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:00:33,702 Loss: 2.091, MeanIU:  0.7072, Best_mIoU:  0.7072
2023-10-30 10:00:33,703 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531]
2023-10-30 10:00:35,781 Epoch: [191/484] Iter:[0/495], Time: 2.05, lr: [0.006365316940686164], Loss: 2.190938, Acc:0.862658, Semantic loss: 0.767263, BCE loss: 0.722192, SB loss: 0.701484
2023-10-30 10:00:39,644 Epoch: [191/484] Iter:[10/495], Time: 0.54, lr: [0.006364921946029924], Loss: 2.033306, Acc:0.808785, Semantic loss: 0.748896, BCE loss: 0.562749, SB loss: 0.721661
2023-10-30 10:00:43,186 Epoch: [191/484] Iter:[20/495], Time: 0.45, lr: [0.006364526948650043], Loss: 2.071248, Acc:0.820304, Semantic loss: 0.801978, BCE loss: 0.532019, SB loss: 0.737251
2023-10-30 10:00:46,628 Epoch: [191/484] Iter:[30/495], Time: 0.42, lr: [0.006364131948546315], Loss: 2.036565, Acc:0.796766, Semantic loss: 0.782505, BCE loss: 0.520182, SB loss: 0.733878
2023-10-30 10:00:50,099 Epoch: [191/484] Iter:[40/495], Time: 0.40, lr: [0.006363736945718531], Loss: 2.039772, Acc:0.789833, Semantic loss: 0.776485, BCE loss: 0.520995, SB loss: 0.742292
2023-10-30 10:00:53,714 Epoch: [191/484] Iter:[50/495], Time: 0.39, lr: [0.006363341940166488], Loss: 2.087121, Acc:0.792146, Semantic loss: 0.797950, BCE loss: 0.539381, SB loss: 0.749789
2023-10-30 10:00:57,208 Epoch: [191/484] Iter:[60/495], Time: 0.38, lr: [0.006362946931889977], Loss: 2.062103, Acc:0.792957, Semantic loss: 0.785588, BCE loss: 0.532265, SB loss: 0.744250
2023-10-30 10:01:00,705 Epoch: [191/484] Iter:[70/495], Time: 0.38, lr: [0.006362551920888792], Loss: 2.062138, Acc:0.793275, Semantic loss: 0.779197, BCE loss: 0.538084, SB loss: 0.744857
2023-10-30 10:01:04,286 Epoch: [191/484] Iter:[80/495], Time: 0.38, lr: [0.006362156907162725], Loss: 2.075464, Acc:0.792160, Semantic loss: 0.788287, BCE loss: 0.536337, SB loss: 0.750840
2023-10-30 10:01:07,851 Epoch: [191/484] Iter:[90/495], Time: 0.37, lr: [0.006361761890711572], Loss: 2.074003, Acc:0.791281, Semantic loss: 0.784294, BCE loss: 0.534149, SB loss: 0.755560
2023-10-30 10:01:11,534 Epoch: [191/484] Iter:[100/495], Time: 0.37, lr: [0.006361366871535122], Loss: 2.088489, Acc:0.790613, Semantic loss: 0.794888, BCE loss: 0.533171, SB loss: 0.760431
2023-10-30 10:01:15,166 Epoch: [191/484] Iter:[110/495], Time: 0.37, lr: [0.006360971849633174], Loss: 2.087311, Acc:0.788189, Semantic loss: 0.795445, BCE loss: 0.529035, SB loss: 0.762831
2023-10-30 10:01:18,690 Epoch: [191/484] Iter:[120/495], Time: 0.37, lr: [0.006360576825005516], Loss: 2.082051, Acc:0.787626, Semantic loss: 0.790726, BCE loss: 0.529852, SB loss: 0.761473
2023-10-30 10:01:22,278 Epoch: [191/484] Iter:[130/495], Time: 0.37, lr: [0.006360181797651943], Loss: 2.087734, Acc:0.789247, Semantic loss: 0.793651, BCE loss: 0.531172, SB loss: 0.762910
2023-10-30 10:01:25,946 Epoch: [191/484] Iter:[140/495], Time: 0.37, lr: [0.006359786767572246], Loss: 2.087614, Acc:0.785613, Semantic loss: 0.793106, BCE loss: 0.530420, SB loss: 0.764087
2023-10-30 10:01:29,497 Epoch: [191/484] Iter:[150/495], Time: 0.37, lr: [0.006359391734766223], Loss: 2.085976, Acc:0.786340, Semantic loss: 0.789624, BCE loss: 0.533913, SB loss: 0.762439
2023-10-30 10:01:33,123 Epoch: [191/484] Iter:[160/495], Time: 0.37, lr: [0.006358996699233663], Loss: 2.094147, Acc:0.787632, Semantic loss: 0.796097, BCE loss: 0.535514, SB loss: 0.762535
2023-10-30 10:01:36,764 Epoch: [191/484] Iter:[170/495], Time: 0.37, lr: [0.006358601660974359], Loss: 2.088857, Acc:0.788295, Semantic loss: 0.792254, BCE loss: 0.535682, SB loss: 0.760921
2023-10-30 10:01:40,504 Epoch: [191/484] Iter:[180/495], Time: 0.37, lr: [0.006358206619988106], Loss: 2.088870, Acc:0.789215, Semantic loss: 0.791547, BCE loss: 0.538887, SB loss: 0.758437
2023-10-30 10:01:44,123 Epoch: [191/484] Iter:[190/495], Time: 0.37, lr: [0.006357811576274696], Loss: 2.085552, Acc:0.788225, Semantic loss: 0.787981, BCE loss: 0.540074, SB loss: 0.757497
2023-10-30 10:01:47,817 Epoch: [191/484] Iter:[200/495], Time: 0.37, lr: [0.006357416529833922], Loss: 2.091576, Acc:0.788413, Semantic loss: 0.790566, BCE loss: 0.542224, SB loss: 0.758786
2023-10-30 10:01:51,436 Epoch: [191/484] Iter:[210/495], Time: 0.37, lr: [0.006357021480665576], Loss: 2.086232, Acc:0.787567, Semantic loss: 0.788324, BCE loss: 0.540374, SB loss: 0.757534
2023-10-30 10:01:55,167 Epoch: [191/484] Iter:[220/495], Time: 0.37, lr: [0.006356626428769451], Loss: 2.094550, Acc:0.787037, Semantic loss: 0.796933, BCE loss: 0.539786, SB loss: 0.757831
2023-10-30 10:01:58,820 Epoch: [191/484] Iter:[230/495], Time: 0.37, lr: [0.00635623137414534], Loss: 2.095112, Acc:0.787887, Semantic loss: 0.798842, BCE loss: 0.539110, SB loss: 0.757160
2023-10-30 10:02:02,475 Epoch: [191/484] Iter:[240/495], Time: 0.37, lr: [0.0063558363167930355], Loss: 2.103263, Acc:0.788470, Semantic loss: 0.804114, BCE loss: 0.541327, SB loss: 0.757822
2023-10-30 10:02:06,180 Epoch: [191/484] Iter:[250/495], Time: 0.37, lr: [0.006355441256712332], Loss: 2.105222, Acc:0.788673, Semantic loss: 0.802919, BCE loss: 0.544986, SB loss: 0.757318
2023-10-30 10:02:09,889 Epoch: [191/484] Iter:[260/495], Time: 0.37, lr: [0.006355046193903022], Loss: 2.105903, Acc:0.789560, Semantic loss: 0.802478, BCE loss: 0.546282, SB loss: 0.757142
2023-10-30 10:02:13,556 Epoch: [191/484] Iter:[270/495], Time: 0.37, lr: [0.006354651128364895], Loss: 2.100427, Acc:0.789633, Semantic loss: 0.797348, BCE loss: 0.547156, SB loss: 0.755923
2023-10-30 10:02:17,297 Epoch: [191/484] Iter:[280/495], Time: 0.37, lr: [0.006354256060097747], Loss: 2.095654, Acc:0.789361, Semantic loss: 0.797064, BCE loss: 0.543906, SB loss: 0.754683
2023-10-30 10:02:20,984 Epoch: [191/484] Iter:[290/495], Time: 0.37, lr: [0.00635386098910137], Loss: 2.093482, Acc:0.790104, Semantic loss: 0.794438, BCE loss: 0.545448, SB loss: 0.753596
2023-10-30 10:02:24,751 Epoch: [191/484] Iter:[300/495], Time: 0.37, lr: [0.006353465915375554], Loss: 2.090985, Acc:0.791141, Semantic loss: 0.792394, BCE loss: 0.545047, SB loss: 0.753544
2023-10-30 10:02:28,377 Epoch: [191/484] Iter:[310/495], Time: 0.37, lr: [0.006353070838920095], Loss: 2.095915, Acc:0.791295, Semantic loss: 0.796279, BCE loss: 0.545599, SB loss: 0.754037
2023-10-30 10:02:32,104 Epoch: [191/484] Iter:[320/495], Time: 0.37, lr: [0.006352675759734783], Loss: 2.092241, Acc:0.792058, Semantic loss: 0.796522, BCE loss: 0.543228, SB loss: 0.752491
2023-10-30 10:02:35,816 Epoch: [191/484] Iter:[330/495], Time: 0.37, lr: [0.006352280677819412], Loss: 2.092442, Acc:0.793572, Semantic loss: 0.796101, BCE loss: 0.543603, SB loss: 0.752738
2023-10-30 10:02:39,621 Epoch: [191/484] Iter:[340/495], Time: 0.37, lr: [0.006351885593173774], Loss: 2.092988, Acc:0.793998, Semantic loss: 0.794555, BCE loss: 0.545263, SB loss: 0.753171
2023-10-30 10:02:43,337 Epoch: [191/484] Iter:[350/495], Time: 0.37, lr: [0.006351490505797662], Loss: 2.094685, Acc:0.794053, Semantic loss: 0.795054, BCE loss: 0.545978, SB loss: 0.753652
2023-10-30 10:02:46,979 Epoch: [191/484] Iter:[360/495], Time: 0.37, lr: [0.006351095415690868], Loss: 2.091028, Acc:0.794299, Semantic loss: 0.793524, BCE loss: 0.544563, SB loss: 0.752941
2023-10-30 10:02:50,830 Epoch: [191/484] Iter:[370/495], Time: 0.37, lr: [0.006350700322853184], Loss: 2.089653, Acc:0.794406, Semantic loss: 0.793890, BCE loss: 0.543497, SB loss: 0.752265
2023-10-30 10:02:54,520 Epoch: [191/484] Iter:[380/495], Time: 0.37, lr: [0.006350305227284402], Loss: 2.087976, Acc:0.795303, Semantic loss: 0.792847, BCE loss: 0.542965, SB loss: 0.752164
2023-10-30 10:02:58,143 Epoch: [191/484] Iter:[390/495], Time: 0.37, lr: [0.006349910128984316], Loss: 2.084656, Acc:0.795062, Semantic loss: 0.791478, BCE loss: 0.541585, SB loss: 0.751593
2023-10-30 10:03:01,885 Epoch: [191/484] Iter:[400/495], Time: 0.37, lr: [0.006349515027952715], Loss: 2.081080, Acc:0.794471, Semantic loss: 0.789334, BCE loss: 0.540615, SB loss: 0.751131
2023-10-30 10:03:05,488 Epoch: [191/484] Iter:[410/495], Time: 0.37, lr: [0.006349119924189395], Loss: 2.079711, Acc:0.794766, Semantic loss: 0.788609, BCE loss: 0.540545, SB loss: 0.750557
2023-10-30 10:03:09,170 Epoch: [191/484] Iter:[420/495], Time: 0.37, lr: [0.006348724817694147], Loss: 2.084376, Acc:0.794542, Semantic loss: 0.791684, BCE loss: 0.540883, SB loss: 0.751810
2023-10-30 10:03:12,941 Epoch: [191/484] Iter:[430/495], Time: 0.37, lr: [0.006348329708466763], Loss: 2.083034, Acc:0.795183, Semantic loss: 0.790869, BCE loss: 0.540819, SB loss: 0.751346
2023-10-30 10:03:16,587 Epoch: [191/484] Iter:[440/495], Time: 0.37, lr: [0.006347934596507036], Loss: 2.078281, Acc:0.796131, Semantic loss: 0.788086, BCE loss: 0.539946, SB loss: 0.750249
2023-10-30 10:03:20,219 Epoch: [191/484] Iter:[450/495], Time: 0.37, lr: [0.006347539481814755], Loss: 2.083466, Acc:0.795580, Semantic loss: 0.790241, BCE loss: 0.541608, SB loss: 0.751617
2023-10-30 10:03:23,980 Epoch: [191/484] Iter:[460/495], Time: 0.37, lr: [0.006347144364389715], Loss: 2.082433, Acc:0.796045, Semantic loss: 0.789853, BCE loss: 0.541862, SB loss: 0.750718
2023-10-30 10:03:27,692 Epoch: [191/484] Iter:[470/495], Time: 0.37, lr: [0.0063467492442317065], Loss: 2.079873, Acc:0.796055, Semantic loss: 0.789215, BCE loss: 0.540906, SB loss: 0.749753
2023-10-30 10:03:31,433 Epoch: [191/484] Iter:[480/495], Time: 0.37, lr: [0.006346354121340524], Loss: 2.081966, Acc:0.796191, Semantic loss: 0.790062, BCE loss: 0.541569, SB loss: 0.750335
2023-10-30 10:03:34,919 Epoch: [191/484] Iter:[490/495], Time: 0.37, lr: [0.006345958995715958], Loss: 2.078498, Acc:0.796395, Semantic loss: 0.787929, BCE loss: 0.541128, SB loss: 0.749441
2023-10-30 10:03:36,330 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:03:36,570 Loss: 2.091, MeanIU:  0.7072, Best_mIoU:  0.7072
2023-10-30 10:03:36,570 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531]
2023-10-30 10:03:38,483 Epoch: [192/484] Iter:[0/495], Time: 1.88, lr: [0.00634576143187859], Loss: 1.974058, Acc:0.869459, Semantic loss: 0.728061, BCE loss: 0.420205, SB loss: 0.825792
2023-10-30 10:03:42,571 Epoch: [192/484] Iter:[10/495], Time: 0.54, lr: [0.006345366302153559], Loss: 2.125390, Acc:0.801724, Semantic loss: 0.784261, BCE loss: 0.540369, SB loss: 0.800760
2023-10-30 10:03:46,245 Epoch: [192/484] Iter:[20/495], Time: 0.46, lr: [0.006344971169694624], Loss: 2.061226, Acc:0.795359, Semantic loss: 0.763287, BCE loss: 0.537913, SB loss: 0.760026
2023-10-30 10:03:49,850 Epoch: [192/484] Iter:[30/495], Time: 0.43, lr: [0.006344576034501578], Loss: 2.048667, Acc:0.798103, Semantic loss: 0.765075, BCE loss: 0.525886, SB loss: 0.757706
2023-10-30 10:03:53,496 Epoch: [192/484] Iter:[40/495], Time: 0.41, lr: [0.0063441808965742095], Loss: 2.022384, Acc:0.798573, Semantic loss: 0.753290, BCE loss: 0.520314, SB loss: 0.748780
2023-10-30 10:03:57,167 Epoch: [192/484] Iter:[50/495], Time: 0.40, lr: [0.006343785755912315], Loss: 2.012559, Acc:0.792301, Semantic loss: 0.756278, BCE loss: 0.511791, SB loss: 0.744490
2023-10-30 10:04:00,803 Epoch: [192/484] Iter:[60/495], Time: 0.40, lr: [0.006343390612515682], Loss: 2.006545, Acc:0.798629, Semantic loss: 0.750038, BCE loss: 0.519683, SB loss: 0.736824
2023-10-30 10:04:04,372 Epoch: [192/484] Iter:[70/495], Time: 0.39, lr: [0.006342995466384107], Loss: 2.037711, Acc:0.801533, Semantic loss: 0.759532, BCE loss: 0.531987, SB loss: 0.746192
2023-10-30 10:04:08,227 Epoch: [192/484] Iter:[80/495], Time: 0.39, lr: [0.00634260031751738], Loss: 2.043646, Acc:0.797394, Semantic loss: 0.761255, BCE loss: 0.532603, SB loss: 0.749787
2023-10-30 10:04:11,945 Epoch: [192/484] Iter:[90/495], Time: 0.39, lr: [0.006342205165915291], Loss: 2.061148, Acc:0.795676, Semantic loss: 0.771046, BCE loss: 0.537595, SB loss: 0.752507
2023-10-30 10:04:15,659 Epoch: [192/484] Iter:[100/495], Time: 0.39, lr: [0.006341810011577634], Loss: 2.072542, Acc:0.797462, Semantic loss: 0.772712, BCE loss: 0.542667, SB loss: 0.757163
2023-10-30 10:04:19,399 Epoch: [192/484] Iter:[110/495], Time: 0.39, lr: [0.0063414148545041975], Loss: 2.085124, Acc:0.799063, Semantic loss: 0.783743, BCE loss: 0.542919, SB loss: 0.758463
2023-10-30 10:04:23,040 Epoch: [192/484] Iter:[120/495], Time: 0.38, lr: [0.0063410196946947755], Loss: 2.091586, Acc:0.797351, Semantic loss: 0.790261, BCE loss: 0.539772, SB loss: 0.761553
2023-10-30 10:04:26,743 Epoch: [192/484] Iter:[130/495], Time: 0.38, lr: [0.006340624532149159], Loss: 2.075567, Acc:0.799824, Semantic loss: 0.780092, BCE loss: 0.538966, SB loss: 0.756509
2023-10-30 10:04:30,549 Epoch: [192/484] Iter:[140/495], Time: 0.38, lr: [0.006340229366867139], Loss: 2.070999, Acc:0.801987, Semantic loss: 0.778909, BCE loss: 0.538516, SB loss: 0.753574
2023-10-30 10:04:34,217 Epoch: [192/484] Iter:[150/495], Time: 0.38, lr: [0.00633983419884851], Loss: 2.058397, Acc:0.801779, Semantic loss: 0.773037, BCE loss: 0.534729, SB loss: 0.750631
2023-10-30 10:04:37,870 Epoch: [192/484] Iter:[160/495], Time: 0.38, lr: [0.006339439028093061], Loss: 2.053934, Acc:0.801800, Semantic loss: 0.774062, BCE loss: 0.530145, SB loss: 0.749727
2023-10-30 10:04:41,646 Epoch: [192/484] Iter:[170/495], Time: 0.38, lr: [0.006339043854600584], Loss: 2.054355, Acc:0.800578, Semantic loss: 0.773975, BCE loss: 0.528549, SB loss: 0.751831
2023-10-30 10:04:45,404 Epoch: [192/484] Iter:[180/495], Time: 0.38, lr: [0.00633864867837087], Loss: 2.063937, Acc:0.801179, Semantic loss: 0.779758, BCE loss: 0.529291, SB loss: 0.754889
2023-10-30 10:04:49,108 Epoch: [192/484] Iter:[190/495], Time: 0.38, lr: [0.00633825349940371], Loss: 2.061815, Acc:0.800905, Semantic loss: 0.779509, BCE loss: 0.528561, SB loss: 0.753745
2023-10-30 10:04:52,811 Epoch: [192/484] Iter:[200/495], Time: 0.38, lr: [0.006337858317698896], Loss: 2.070538, Acc:0.800438, Semantic loss: 0.783092, BCE loss: 0.530987, SB loss: 0.756458
2023-10-30 10:04:56,491 Epoch: [192/484] Iter:[210/495], Time: 0.38, lr: [0.00633746313325622], Loss: 2.077294, Acc:0.799832, Semantic loss: 0.784074, BCE loss: 0.535664, SB loss: 0.757556
2023-10-30 10:05:00,191 Epoch: [192/484] Iter:[220/495], Time: 0.38, lr: [0.006337067946075472], Loss: 2.079614, Acc:0.799293, Semantic loss: 0.783789, BCE loss: 0.538309, SB loss: 0.757517
2023-10-30 10:05:03,846 Epoch: [192/484] Iter:[230/495], Time: 0.38, lr: [0.006336672756156445], Loss: 2.077481, Acc:0.799431, Semantic loss: 0.784313, BCE loss: 0.537393, SB loss: 0.755775
2023-10-30 10:05:07,467 Epoch: [192/484] Iter:[240/495], Time: 0.38, lr: [0.00633627756349893], Loss: 2.079676, Acc:0.799171, Semantic loss: 0.786480, BCE loss: 0.537449, SB loss: 0.755747
2023-10-30 10:05:11,222 Epoch: [192/484] Iter:[250/495], Time: 0.38, lr: [0.006335882368102718], Loss: 2.079369, Acc:0.799314, Semantic loss: 0.784594, BCE loss: 0.539227, SB loss: 0.755548
2023-10-30 10:05:14,830 Epoch: [192/484] Iter:[260/495], Time: 0.38, lr: [0.006335487169967599], Loss: 2.082529, Acc:0.798731, Semantic loss: 0.786166, BCE loss: 0.539657, SB loss: 0.756706
2023-10-30 10:05:18,482 Epoch: [192/484] Iter:[270/495], Time: 0.38, lr: [0.006335091969093364], Loss: 2.080148, Acc:0.798526, Semantic loss: 0.785388, BCE loss: 0.539432, SB loss: 0.755327
2023-10-30 10:05:22,146 Epoch: [192/484] Iter:[280/495], Time: 0.38, lr: [0.006334696765479807], Loss: 2.079052, Acc:0.799095, Semantic loss: 0.784448, BCE loss: 0.540501, SB loss: 0.754103
2023-10-30 10:05:25,893 Epoch: [192/484] Iter:[290/495], Time: 0.38, lr: [0.006334301559126715], Loss: 2.078456, Acc:0.799688, Semantic loss: 0.783896, BCE loss: 0.540118, SB loss: 0.754442
2023-10-30 10:05:29,613 Epoch: [192/484] Iter:[300/495], Time: 0.38, lr: [0.006333906350033883], Loss: 2.077331, Acc:0.799642, Semantic loss: 0.783235, BCE loss: 0.538982, SB loss: 0.755114
2023-10-30 10:05:33,317 Epoch: [192/484] Iter:[310/495], Time: 0.38, lr: [0.006333511138201102], Loss: 2.077008, Acc:0.799771, Semantic loss: 0.782584, BCE loss: 0.539126, SB loss: 0.755298
2023-10-30 10:05:37,015 Epoch: [192/484] Iter:[320/495], Time: 0.38, lr: [0.00633311592362816], Loss: 2.074628, Acc:0.800105, Semantic loss: 0.781398, BCE loss: 0.538998, SB loss: 0.754232
2023-10-30 10:05:40,624 Epoch: [192/484] Iter:[330/495], Time: 0.37, lr: [0.0063327207063148495], Loss: 2.075761, Acc:0.800216, Semantic loss: 0.783090, BCE loss: 0.538574, SB loss: 0.754096
2023-10-30 10:05:44,280 Epoch: [192/484] Iter:[340/495], Time: 0.37, lr: [0.006332325486260962], Loss: 2.072724, Acc:0.798606, Semantic loss: 0.782569, BCE loss: 0.536704, SB loss: 0.753450
2023-10-30 10:05:47,986 Epoch: [192/484] Iter:[350/495], Time: 0.37, lr: [0.006331930263466286], Loss: 2.072232, Acc:0.798158, Semantic loss: 0.781655, BCE loss: 0.537185, SB loss: 0.753393
2023-10-30 10:05:51,658 Epoch: [192/484] Iter:[360/495], Time: 0.37, lr: [0.006331535037930616], Loss: 2.076857, Acc:0.799222, Semantic loss: 0.782643, BCE loss: 0.539998, SB loss: 0.754217
2023-10-30 10:05:55,331 Epoch: [192/484] Iter:[370/495], Time: 0.37, lr: [0.006331139809653739], Loss: 2.084203, Acc:0.798862, Semantic loss: 0.786555, BCE loss: 0.541638, SB loss: 0.756009
2023-10-30 10:05:59,023 Epoch: [192/484] Iter:[380/495], Time: 0.37, lr: [0.006330744578635451], Loss: 2.084177, Acc:0.797724, Semantic loss: 0.786901, BCE loss: 0.541174, SB loss: 0.756103
2023-10-30 10:06:02,734 Epoch: [192/484] Iter:[390/495], Time: 0.37, lr: [0.006330349344875539], Loss: 2.085914, Acc:0.798048, Semantic loss: 0.786630, BCE loss: 0.543287, SB loss: 0.755997
2023-10-30 10:06:06,461 Epoch: [192/484] Iter:[400/495], Time: 0.37, lr: [0.006329954108373796], Loss: 2.087004, Acc:0.798244, Semantic loss: 0.787704, BCE loss: 0.542218, SB loss: 0.757083
2023-10-30 10:06:10,132 Epoch: [192/484] Iter:[410/495], Time: 0.37, lr: [0.006329558869130009], Loss: 2.086053, Acc:0.799194, Semantic loss: 0.787250, BCE loss: 0.542323, SB loss: 0.756480
2023-10-30 10:06:13,900 Epoch: [192/484] Iter:[420/495], Time: 0.37, lr: [0.006329163627143973], Loss: 2.082813, Acc:0.798906, Semantic loss: 0.786883, BCE loss: 0.540965, SB loss: 0.754965
2023-10-30 10:06:17,662 Epoch: [192/484] Iter:[430/495], Time: 0.37, lr: [0.006328768382415475], Loss: 2.081889, Acc:0.797946, Semantic loss: 0.787137, BCE loss: 0.539830, SB loss: 0.754921
2023-10-30 10:06:21,379 Epoch: [192/484] Iter:[440/495], Time: 0.37, lr: [0.006328373134944308], Loss: 2.085033, Acc:0.797926, Semantic loss: 0.789348, BCE loss: 0.539748, SB loss: 0.755937
2023-10-30 10:06:25,047 Epoch: [192/484] Iter:[450/495], Time: 0.37, lr: [0.0063279778847302615], Loss: 2.085501, Acc:0.796851, Semantic loss: 0.788846, BCE loss: 0.540480, SB loss: 0.756175
2023-10-30 10:06:28,676 Epoch: [192/484] Iter:[460/495], Time: 0.37, lr: [0.006327582631773129], Loss: 2.086396, Acc:0.797124, Semantic loss: 0.789092, BCE loss: 0.541094, SB loss: 0.756210
2023-10-30 10:06:32,398 Epoch: [192/484] Iter:[470/495], Time: 0.37, lr: [0.006327187376072697], Loss: 2.082570, Acc:0.796652, Semantic loss: 0.787106, BCE loss: 0.540090, SB loss: 0.755374
2023-10-30 10:06:36,099 Epoch: [192/484] Iter:[480/495], Time: 0.37, lr: [0.006326792117628759], Loss: 2.083302, Acc:0.796536, Semantic loss: 0.787646, BCE loss: 0.540521, SB loss: 0.755135
2023-10-30 10:06:39,636 Epoch: [192/484] Iter:[490/495], Time: 0.37, lr: [0.006326396856441104], Loss: 2.085525, Acc:0.796021, Semantic loss: 0.789702, BCE loss: 0.540259, SB loss: 0.755564
2023-10-30 10:06:41,044 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:06:41,284 Loss: 2.091, MeanIU:  0.7072, Best_mIoU:  0.7072
2023-10-30 10:06:41,284 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531]
2023-10-30 10:06:43,437 Epoch: [193/484] Iter:[0/495], Time: 2.12, lr: [0.006326199224818318], Loss: 2.003729, Acc:0.904512, Semantic loss: 0.698207, BCE loss: 0.584355, SB loss: 0.721168
2023-10-30 10:06:47,407 Epoch: [193/484] Iter:[10/495], Time: 0.55, lr: [0.006325803959514696], Loss: 2.255425, Acc:0.801157, Semantic loss: 0.936846, BCE loss: 0.502475, SB loss: 0.816105
2023-10-30 10:06:51,120 Epoch: [193/484] Iter:[20/495], Time: 0.47, lr: [0.006325408691466831], Loss: 2.145673, Acc:0.801055, Semantic loss: 0.862174, BCE loss: 0.514085, SB loss: 0.769414
2023-10-30 10:06:54,831 Epoch: [193/484] Iter:[30/495], Time: 0.44, lr: [0.006325013420674518], Loss: 2.072378, Acc:0.788096, Semantic loss: 0.803711, BCE loss: 0.508898, SB loss: 0.759769
2023-10-30 10:06:58,484 Epoch: [193/484] Iter:[40/495], Time: 0.42, lr: [0.006324618147137544], Loss: 2.049991, Acc:0.792260, Semantic loss: 0.781769, BCE loss: 0.513751, SB loss: 0.754471
2023-10-30 10:07:02,166 Epoch: [193/484] Iter:[50/495], Time: 0.41, lr: [0.006324222870855702], Loss: 2.024419, Acc:0.791902, Semantic loss: 0.776547, BCE loss: 0.501849, SB loss: 0.746022
2023-10-30 10:07:05,759 Epoch: [193/484] Iter:[60/495], Time: 0.40, lr: [0.00632382759182878], Loss: 2.033333, Acc:0.792633, Semantic loss: 0.777072, BCE loss: 0.511092, SB loss: 0.745169
2023-10-30 10:07:09,559 Epoch: [193/484] Iter:[70/495], Time: 0.40, lr: [0.00632343231005657], Loss: 2.018220, Acc:0.795468, Semantic loss: 0.765221, BCE loss: 0.512640, SB loss: 0.740359
2023-10-30 10:07:13,313 Epoch: [193/484] Iter:[80/495], Time: 0.39, lr: [0.006323037025538863], Loss: 2.042848, Acc:0.797346, Semantic loss: 0.775033, BCE loss: 0.521149, SB loss: 0.746666
2023-10-30 10:07:16,957 Epoch: [193/484] Iter:[90/495], Time: 0.39, lr: [0.0063226417382754455], Loss: 2.036326, Acc:0.797157, Semantic loss: 0.770568, BCE loss: 0.522742, SB loss: 0.743015
2023-10-30 10:07:20,660 Epoch: [193/484] Iter:[100/495], Time: 0.39, lr: [0.006322246448266109], Loss: 2.056961, Acc:0.799266, Semantic loss: 0.779184, BCE loss: 0.531598, SB loss: 0.746179
2023-10-30 10:07:24,319 Epoch: [193/484] Iter:[110/495], Time: 0.39, lr: [0.006321851155510646], Loss: 2.052549, Acc:0.801517, Semantic loss: 0.774097, BCE loss: 0.533498, SB loss: 0.744954
2023-10-30 10:07:27,984 Epoch: [193/484] Iter:[120/495], Time: 0.39, lr: [0.0063214558600088455], Loss: 2.059716, Acc:0.802839, Semantic loss: 0.777827, BCE loss: 0.535598, SB loss: 0.746292
2023-10-30 10:07:31,531 Epoch: [193/484] Iter:[130/495], Time: 0.38, lr: [0.0063210605617604965], Loss: 2.048367, Acc:0.801981, Semantic loss: 0.773898, BCE loss: 0.529826, SB loss: 0.744644
2023-10-30 10:07:35,161 Epoch: [193/484] Iter:[140/495], Time: 0.38, lr: [0.0063206652607653915], Loss: 2.028995, Acc:0.799630, Semantic loss: 0.767277, BCE loss: 0.521010, SB loss: 0.740707
2023-10-30 10:07:38,812 Epoch: [193/484] Iter:[150/495], Time: 0.38, lr: [0.006320269957023318], Loss: 2.026646, Acc:0.799805, Semantic loss: 0.767870, BCE loss: 0.519263, SB loss: 0.739513
2023-10-30 10:07:42,476 Epoch: [193/484] Iter:[160/495], Time: 0.38, lr: [0.006319874650534066], Loss: 2.036152, Acc:0.797957, Semantic loss: 0.774536, BCE loss: 0.516894, SB loss: 0.744721
2023-10-30 10:07:46,100 Epoch: [193/484] Iter:[170/495], Time: 0.38, lr: [0.006319479341297427], Loss: 2.033405, Acc:0.797462, Semantic loss: 0.771148, BCE loss: 0.517146, SB loss: 0.745110
2023-10-30 10:07:49,751 Epoch: [193/484] Iter:[180/495], Time: 0.38, lr: [0.006319084029313192], Loss: 2.044301, Acc:0.796190, Semantic loss: 0.777970, BCE loss: 0.519450, SB loss: 0.746881
2023-10-30 10:07:53,376 Epoch: [193/484] Iter:[190/495], Time: 0.38, lr: [0.006318688714581145], Loss: 2.041834, Acc:0.793961, Semantic loss: 0.776328, BCE loss: 0.517640, SB loss: 0.747865
2023-10-30 10:07:57,109 Epoch: [193/484] Iter:[200/495], Time: 0.38, lr: [0.006318293397101085], Loss: 2.051762, Acc:0.792419, Semantic loss: 0.782923, BCE loss: 0.517906, SB loss: 0.750933
2023-10-30 10:08:00,892 Epoch: [193/484] Iter:[210/495], Time: 0.38, lr: [0.006317898076872794], Loss: 2.057607, Acc:0.792295, Semantic loss: 0.784289, BCE loss: 0.520870, SB loss: 0.752448
2023-10-30 10:08:04,581 Epoch: [193/484] Iter:[220/495], Time: 0.38, lr: [0.006317502753896066], Loss: 2.055978, Acc:0.793616, Semantic loss: 0.781241, BCE loss: 0.522220, SB loss: 0.752517
2023-10-30 10:08:08,357 Epoch: [193/484] Iter:[230/495], Time: 0.38, lr: [0.0063171074281706905], Loss: 2.058336, Acc:0.792910, Semantic loss: 0.785132, BCE loss: 0.519884, SB loss: 0.753320
2023-10-30 10:08:11,952 Epoch: [193/484] Iter:[240/495], Time: 0.38, lr: [0.0063167120996964555], Loss: 2.057641, Acc:0.792688, Semantic loss: 0.783847, BCE loss: 0.520902, SB loss: 0.752892
2023-10-30 10:08:15,566 Epoch: [193/484] Iter:[250/495], Time: 0.38, lr: [0.00631631676847315], Loss: 2.056009, Acc:0.792613, Semantic loss: 0.781934, BCE loss: 0.521225, SB loss: 0.752850
2023-10-30 10:08:19,319 Epoch: [193/484] Iter:[260/495], Time: 0.38, lr: [0.006315921434500568], Loss: 2.053331, Acc:0.791495, Semantic loss: 0.780114, BCE loss: 0.520586, SB loss: 0.752632
2023-10-30 10:08:23,089 Epoch: [193/484] Iter:[270/495], Time: 0.38, lr: [0.006315526097778495], Loss: 2.057839, Acc:0.791829, Semantic loss: 0.783258, BCE loss: 0.521071, SB loss: 0.753510
2023-10-30 10:08:26,767 Epoch: [193/484] Iter:[280/495], Time: 0.38, lr: [0.006315130758306722], Loss: 2.057264, Acc:0.792694, Semantic loss: 0.781499, BCE loss: 0.523036, SB loss: 0.752729
2023-10-30 10:08:30,501 Epoch: [193/484] Iter:[290/495], Time: 0.38, lr: [0.00631473541608504], Loss: 2.054200, Acc:0.791485, Semantic loss: 0.779221, BCE loss: 0.521956, SB loss: 0.753022
2023-10-30 10:08:34,221 Epoch: [193/484] Iter:[300/495], Time: 0.38, lr: [0.006314340071113236], Loss: 2.058145, Acc:0.793022, Semantic loss: 0.778837, BCE loss: 0.526099, SB loss: 0.753209
2023-10-30 10:08:37,989 Epoch: [193/484] Iter:[310/495], Time: 0.38, lr: [0.0063139447233911015], Loss: 2.063201, Acc:0.792894, Semantic loss: 0.783537, BCE loss: 0.526167, SB loss: 0.753497
2023-10-30 10:08:41,671 Epoch: [193/484] Iter:[320/495], Time: 0.37, lr: [0.006313549372918426], Loss: 2.060069, Acc:0.792646, Semantic loss: 0.782787, BCE loss: 0.524960, SB loss: 0.752322
2023-10-30 10:08:45,416 Epoch: [193/484] Iter:[330/495], Time: 0.37, lr: [0.006313154019694997], Loss: 2.059871, Acc:0.793145, Semantic loss: 0.783174, BCE loss: 0.524562, SB loss: 0.752134
2023-10-30 10:08:49,077 Epoch: [193/484] Iter:[340/495], Time: 0.37, lr: [0.006312758663720606], Loss: 2.060711, Acc:0.792942, Semantic loss: 0.783184, BCE loss: 0.524864, SB loss: 0.752663
2023-10-30 10:08:52,725 Epoch: [193/484] Iter:[350/495], Time: 0.37, lr: [0.006312363304995041], Loss: 2.062545, Acc:0.793534, Semantic loss: 0.784008, BCE loss: 0.524999, SB loss: 0.753537
2023-10-30 10:08:56,446 Epoch: [193/484] Iter:[360/495], Time: 0.37, lr: [0.0063119679435180934], Loss: 2.061936, Acc:0.792064, Semantic loss: 0.784201, BCE loss: 0.523825, SB loss: 0.753911
2023-10-30 10:09:00,146 Epoch: [193/484] Iter:[370/495], Time: 0.37, lr: [0.006311572579289552], Loss: 2.059916, Acc:0.792420, Semantic loss: 0.782330, BCE loss: 0.524701, SB loss: 0.752884
2023-10-30 10:09:03,826 Epoch: [193/484] Iter:[380/495], Time: 0.37, lr: [0.0063111772123092035], Loss: 2.059872, Acc:0.791181, Semantic loss: 0.781776, BCE loss: 0.525283, SB loss: 0.752814
2023-10-30 10:09:07,586 Epoch: [193/484] Iter:[390/495], Time: 0.37, lr: [0.0063107818425768404], Loss: 2.064314, Acc:0.791726, Semantic loss: 0.784448, BCE loss: 0.525807, SB loss: 0.754059
2023-10-30 10:09:11,282 Epoch: [193/484] Iter:[400/495], Time: 0.37, lr: [0.006310386470092251], Loss: 2.066875, Acc:0.791987, Semantic loss: 0.785113, BCE loss: 0.527064, SB loss: 0.754698
2023-10-30 10:09:14,985 Epoch: [193/484] Iter:[410/495], Time: 0.37, lr: [0.006309991094855223], Loss: 2.069298, Acc:0.792202, Semantic loss: 0.784797, BCE loss: 0.529263, SB loss: 0.755238
2023-10-30 10:09:18,725 Epoch: [193/484] Iter:[420/495], Time: 0.37, lr: [0.006309595716865547], Loss: 2.070079, Acc:0.792267, Semantic loss: 0.784970, BCE loss: 0.529649, SB loss: 0.755459
2023-10-30 10:09:22,395 Epoch: [193/484] Iter:[430/495], Time: 0.37, lr: [0.006309200336123012], Loss: 2.069393, Acc:0.791783, Semantic loss: 0.784675, BCE loss: 0.529006, SB loss: 0.755713
2023-10-30 10:09:26,019 Epoch: [193/484] Iter:[440/495], Time: 0.37, lr: [0.006308804952627409], Loss: 2.070379, Acc:0.791553, Semantic loss: 0.784484, BCE loss: 0.529603, SB loss: 0.756291
2023-10-30 10:09:29,842 Epoch: [193/484] Iter:[450/495], Time: 0.37, lr: [0.006308409566378523], Loss: 2.070220, Acc:0.791178, Semantic loss: 0.785265, BCE loss: 0.528874, SB loss: 0.756081
2023-10-30 10:09:33,574 Epoch: [193/484] Iter:[460/495], Time: 0.37, lr: [0.0063080141773761466], Loss: 2.068555, Acc:0.791285, Semantic loss: 0.785707, BCE loss: 0.526903, SB loss: 0.755944
2023-10-30 10:09:37,267 Epoch: [193/484] Iter:[470/495], Time: 0.37, lr: [0.006307618785620068], Loss: 2.064235, Acc:0.790485, Semantic loss: 0.783151, BCE loss: 0.526062, SB loss: 0.755022
2023-10-30 10:09:41,045 Epoch: [193/484] Iter:[480/495], Time: 0.37, lr: [0.006307223391110076], Loss: 2.063366, Acc:0.790652, Semantic loss: 0.782764, BCE loss: 0.525999, SB loss: 0.754603
2023-10-30 10:09:44,585 Epoch: [193/484] Iter:[490/495], Time: 0.37, lr: [0.006306827993845957], Loss: 2.068487, Acc:0.790565, Semantic loss: 0.785129, BCE loss: 0.526740, SB loss: 0.756617
2023-10-30 10:09:45,998 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:09:46,239 Loss: 2.091, MeanIU:  0.7072, Best_mIoU:  0.7072
2023-10-30 10:09:46,239 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531]
2023-10-30 10:09:48,385 Epoch: [194/484] Iter:[0/495], Time: 2.11, lr: [0.006306630294181036], Loss: 1.776358, Acc:0.778993, Semantic loss: 0.592667, BCE loss: 0.430283, SB loss: 0.753408
2023-10-30 10:09:52,372 Epoch: [194/484] Iter:[10/495], Time: 0.55, lr: [0.006306234892785336], Loss: 2.294234, Acc:0.818010, Semantic loss: 0.886221, BCE loss: 0.592573, SB loss: 0.815439
2023-10-30 10:09:56,115 Epoch: [194/484] Iter:[20/495], Time: 0.47, lr: [0.006305839488634985], Loss: 2.245973, Acc:0.806792, Semantic loss: 0.877796, BCE loss: 0.582550, SB loss: 0.785627
2023-10-30 10:09:59,785 Epoch: [194/484] Iter:[30/495], Time: 0.44, lr: [0.00630544408172977], Loss: 2.231882, Acc:0.798255, Semantic loss: 0.864426, BCE loss: 0.583045, SB loss: 0.784412
2023-10-30 10:10:03,495 Epoch: [194/484] Iter:[40/495], Time: 0.42, lr: [0.00630504867206948], Loss: 2.171498, Acc:0.793224, Semantic loss: 0.833286, BCE loss: 0.564227, SB loss: 0.773985
2023-10-30 10:10:07,137 Epoch: [194/484] Iter:[50/495], Time: 0.41, lr: [0.0063046532596539055], Loss: 2.173832, Acc:0.791663, Semantic loss: 0.848076, BCE loss: 0.547570, SB loss: 0.778187
2023-10-30 10:10:10,913 Epoch: [194/484] Iter:[60/495], Time: 0.40, lr: [0.006304257844482833], Loss: 2.204142, Acc:0.791441, Semantic loss: 0.860197, BCE loss: 0.554641, SB loss: 0.789305
2023-10-30 10:10:14,562 Epoch: [194/484] Iter:[70/495], Time: 0.40, lr: [0.006303862426556053], Loss: 2.182910, Acc:0.792844, Semantic loss: 0.851955, BCE loss: 0.549105, SB loss: 0.781850
2023-10-30 10:10:18,292 Epoch: [194/484] Iter:[80/495], Time: 0.40, lr: [0.006303467005873353], Loss: 2.175482, Acc:0.788496, Semantic loss: 0.846944, BCE loss: 0.545133, SB loss: 0.783404
2023-10-30 10:10:21,999 Epoch: [194/484] Iter:[90/495], Time: 0.39, lr: [0.006303071582434523], Loss: 2.168248, Acc:0.785074, Semantic loss: 0.843221, BCE loss: 0.544129, SB loss: 0.780898
2023-10-30 10:10:25,762 Epoch: [194/484] Iter:[100/495], Time: 0.39, lr: [0.0063026761562393506], Loss: 2.177731, Acc:0.782886, Semantic loss: 0.851711, BCE loss: 0.546986, SB loss: 0.779034
2023-10-30 10:10:29,380 Epoch: [194/484] Iter:[110/495], Time: 0.39, lr: [0.006302280727287626], Loss: 2.169503, Acc:0.783525, Semantic loss: 0.847413, BCE loss: 0.547159, SB loss: 0.774931
2023-10-30 10:10:33,096 Epoch: [194/484] Iter:[120/495], Time: 0.39, lr: [0.006301885295579136], Loss: 2.152206, Acc:0.782748, Semantic loss: 0.835570, BCE loss: 0.544968, SB loss: 0.771667
2023-10-30 10:10:36,799 Epoch: [194/484] Iter:[130/495], Time: 0.39, lr: [0.00630148986111367], Loss: 2.147840, Acc:0.784168, Semantic loss: 0.826801, BCE loss: 0.552313, SB loss: 0.768726
2023-10-30 10:10:40,540 Epoch: [194/484] Iter:[140/495], Time: 0.38, lr: [0.006301094423891017], Loss: 2.153362, Acc:0.784273, Semantic loss: 0.828368, BCE loss: 0.557029, SB loss: 0.767965
2023-10-30 10:10:44,309 Epoch: [194/484] Iter:[150/495], Time: 0.38, lr: [0.006300698983910963], Loss: 2.140658, Acc:0.786622, Semantic loss: 0.819307, BCE loss: 0.556993, SB loss: 0.764358
2023-10-30 10:10:48,058 Epoch: [194/484] Iter:[160/495], Time: 0.38, lr: [0.0063003035411733], Loss: 2.129679, Acc:0.788335, Semantic loss: 0.813212, BCE loss: 0.554778, SB loss: 0.761689
2023-10-30 10:10:51,781 Epoch: [194/484] Iter:[170/495], Time: 0.38, lr: [0.0062999080956778145], Loss: 2.135642, Acc:0.789421, Semantic loss: 0.817698, BCE loss: 0.552937, SB loss: 0.765007
2023-10-30 10:10:55,574 Epoch: [194/484] Iter:[180/495], Time: 0.38, lr: [0.006299512647424295], Loss: 2.131326, Acc:0.789953, Semantic loss: 0.814336, BCE loss: 0.552259, SB loss: 0.764732
2023-10-30 10:10:59,385 Epoch: [194/484] Iter:[190/495], Time: 0.38, lr: [0.00629911719641253], Loss: 2.128449, Acc:0.790420, Semantic loss: 0.811159, BCE loss: 0.555245, SB loss: 0.762044
2023-10-30 10:11:03,216 Epoch: [194/484] Iter:[200/495], Time: 0.38, lr: [0.006298721742642309], Loss: 2.126092, Acc:0.791699, Semantic loss: 0.809501, BCE loss: 0.553673, SB loss: 0.762918
2023-10-30 10:11:06,913 Epoch: [194/484] Iter:[210/495], Time: 0.38, lr: [0.006298326286113419], Loss: 2.123595, Acc:0.792542, Semantic loss: 0.807680, BCE loss: 0.553210, SB loss: 0.762705
2023-10-30 10:11:10,672 Epoch: [194/484] Iter:[220/495], Time: 0.38, lr: [0.006297930826825649], Loss: 2.127482, Acc:0.792768, Semantic loss: 0.813021, BCE loss: 0.551626, SB loss: 0.762835
2023-10-30 10:11:14,422 Epoch: [194/484] Iter:[230/495], Time: 0.38, lr: [0.006297535364778786], Loss: 2.129761, Acc:0.794537, Semantic loss: 0.815145, BCE loss: 0.552212, SB loss: 0.762404
2023-10-30 10:11:18,210 Epoch: [194/484] Iter:[240/495], Time: 0.38, lr: [0.006297139899972619], Loss: 2.142154, Acc:0.794039, Semantic loss: 0.822321, BCE loss: 0.555234, SB loss: 0.764598
2023-10-30 10:11:21,925 Epoch: [194/484] Iter:[250/495], Time: 0.38, lr: [0.006296744432406937], Loss: 2.140097, Acc:0.793362, Semantic loss: 0.820528, BCE loss: 0.554504, SB loss: 0.765065
2023-10-30 10:11:25,666 Epoch: [194/484] Iter:[260/495], Time: 0.38, lr: [0.0062963489620815275], Loss: 2.139285, Acc:0.791882, Semantic loss: 0.822053, BCE loss: 0.551797, SB loss: 0.765436
2023-10-30 10:11:29,415 Epoch: [194/484] Iter:[270/495], Time: 0.38, lr: [0.006295953488996178], Loss: 2.130774, Acc:0.789488, Semantic loss: 0.816722, BCE loss: 0.549578, SB loss: 0.764473
2023-10-30 10:11:33,294 Epoch: [194/484] Iter:[280/495], Time: 0.38, lr: [0.006295558013150678], Loss: 2.123712, Acc:0.788936, Semantic loss: 0.813201, BCE loss: 0.546645, SB loss: 0.763866
2023-10-30 10:11:37,055 Epoch: [194/484] Iter:[290/495], Time: 0.38, lr: [0.006295162534544816], Loss: 2.126257, Acc:0.788990, Semantic loss: 0.814200, BCE loss: 0.548655, SB loss: 0.763402
2023-10-30 10:11:40,949 Epoch: [194/484] Iter:[300/495], Time: 0.38, lr: [0.006294767053178377], Loss: 2.125818, Acc:0.789259, Semantic loss: 0.812722, BCE loss: 0.550291, SB loss: 0.762804
2023-10-30 10:11:44,741 Epoch: [194/484] Iter:[310/495], Time: 0.38, lr: [0.006294371569051152], Loss: 2.122011, Acc:0.789948, Semantic loss: 0.811075, BCE loss: 0.548536, SB loss: 0.762399
2023-10-30 10:11:48,490 Epoch: [194/484] Iter:[320/495], Time: 0.38, lr: [0.006293976082162926], Loss: 2.122953, Acc:0.789734, Semantic loss: 0.813420, BCE loss: 0.547202, SB loss: 0.762331
2023-10-30 10:11:52,217 Epoch: [194/484] Iter:[330/495], Time: 0.38, lr: [0.0062935805925134905], Loss: 2.120361, Acc:0.788675, Semantic loss: 0.812136, BCE loss: 0.545957, SB loss: 0.762268
2023-10-30 10:11:55,922 Epoch: [194/484] Iter:[340/495], Time: 0.38, lr: [0.006293185100102632], Loss: 2.119947, Acc:0.790229, Semantic loss: 0.810810, BCE loss: 0.546455, SB loss: 0.762681
2023-10-30 10:11:59,685 Epoch: [194/484] Iter:[350/495], Time: 0.38, lr: [0.006292789604930138], Loss: 2.114751, Acc:0.788989, Semantic loss: 0.807628, BCE loss: 0.544754, SB loss: 0.762369
2023-10-30 10:12:03,414 Epoch: [194/484] Iter:[360/495], Time: 0.38, lr: [0.0062923941069957965], Loss: 2.115516, Acc:0.789478, Semantic loss: 0.806508, BCE loss: 0.545370, SB loss: 0.763638
2023-10-30 10:12:07,089 Epoch: [194/484] Iter:[370/495], Time: 0.38, lr: [0.006291998606299396], Loss: 2.114521, Acc:0.789224, Semantic loss: 0.806572, BCE loss: 0.545197, SB loss: 0.762752
2023-10-30 10:12:10,834 Epoch: [194/484] Iter:[380/495], Time: 0.38, lr: [0.006291603102840723], Loss: 2.111216, Acc:0.790240, Semantic loss: 0.804311, BCE loss: 0.544799, SB loss: 0.762106
2023-10-30 10:12:14,509 Epoch: [194/484] Iter:[390/495], Time: 0.38, lr: [0.006291207596619566], Loss: 2.108874, Acc:0.789970, Semantic loss: 0.803644, BCE loss: 0.543559, SB loss: 0.761671
2023-10-30 10:12:18,150 Epoch: [194/484] Iter:[400/495], Time: 0.38, lr: [0.006290812087635712], Loss: 2.108720, Acc:0.790794, Semantic loss: 0.803496, BCE loss: 0.543428, SB loss: 0.761796
2023-10-30 10:12:21,891 Epoch: [194/484] Iter:[410/495], Time: 0.38, lr: [0.0062904165758889494], Loss: 2.115509, Acc:0.790421, Semantic loss: 0.808665, BCE loss: 0.542940, SB loss: 0.763904
2023-10-30 10:12:25,596 Epoch: [194/484] Iter:[420/495], Time: 0.38, lr: [0.0062900210613790674], Loss: 2.115549, Acc:0.789472, Semantic loss: 0.809502, BCE loss: 0.542353, SB loss: 0.763694
2023-10-30 10:12:29,302 Epoch: [194/484] Iter:[430/495], Time: 0.38, lr: [0.006289625544105852], Loss: 2.110951, Acc:0.790026, Semantic loss: 0.806858, BCE loss: 0.540786, SB loss: 0.763307
2023-10-30 10:12:33,079 Epoch: [194/484] Iter:[440/495], Time: 0.38, lr: [0.00628923002406909], Loss: 2.109993, Acc:0.789956, Semantic loss: 0.806839, BCE loss: 0.540268, SB loss: 0.762885
2023-10-30 10:12:36,841 Epoch: [194/484] Iter:[450/495], Time: 0.38, lr: [0.00628883450126857], Loss: 2.105225, Acc:0.789863, Semantic loss: 0.803663, BCE loss: 0.539143, SB loss: 0.762419
2023-10-30 10:12:40,500 Epoch: [194/484] Iter:[460/495], Time: 0.38, lr: [0.00628843897570408], Loss: 2.106198, Acc:0.790484, Semantic loss: 0.804088, BCE loss: 0.539434, SB loss: 0.762677
2023-10-30 10:12:44,256 Epoch: [194/484] Iter:[470/495], Time: 0.38, lr: [0.006288043447375406], Loss: 2.105565, Acc:0.791091, Semantic loss: 0.803968, BCE loss: 0.539212, SB loss: 0.762385
2023-10-30 10:12:47,920 Epoch: [194/484] Iter:[480/495], Time: 0.38, lr: [0.006287647916282338], Loss: 2.104718, Acc:0.791504, Semantic loss: 0.803753, BCE loss: 0.539152, SB loss: 0.761814
2023-10-30 10:12:51,428 Epoch: [194/484] Iter:[490/495], Time: 0.38, lr: [0.00628725238242466], Loss: 2.104402, Acc:0.791654, Semantic loss: 0.803473, BCE loss: 0.539464, SB loss: 0.761465
2023-10-30 10:12:52,868 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:12:53,108 Loss: 2.091, MeanIU:  0.7072, Best_mIoU:  0.7072
2023-10-30 10:12:53,108 [0.97448167 0.81687344 0.90253059 0.39154605 0.53697791 0.55478403
 0.65780561 0.73364811 0.90646698 0.55164099 0.92883377 0.76432778
 0.5089012  0.92634528 0.61644849 0.77080059 0.65978862 0.50388579
 0.73145531]
2023-10-30 10:12:55,510 Epoch: [195/484] Iter:[0/495], Time: 2.37, lr: [0.0062870546144590264], Loss: 1.882940, Acc:0.868646, Semantic loss: 0.646671, BCE loss: 0.508127, SB loss: 0.728143
2023-10-30 10:12:59,544 Epoch: [195/484] Iter:[10/495], Time: 0.58, lr: [0.006286659076454038], Loss: 2.061056, Acc:0.815253, Semantic loss: 0.745246, BCE loss: 0.575229, SB loss: 0.740582
2023-10-30 10:13:03,296 Epoch: [195/484] Iter:[20/495], Time: 0.48, lr: [0.006286263535683912], Loss: 2.041308, Acc:0.805494, Semantic loss: 0.738692, BCE loss: 0.548191, SB loss: 0.754424
2023-10-30 10:13:06,975 Epoch: [195/484] Iter:[30/495], Time: 0.45, lr: [0.006285867992148433], Loss: 2.016180, Acc:0.800348, Semantic loss: 0.731357, BCE loss: 0.539417, SB loss: 0.745407
2023-10-30 10:13:10,769 Epoch: [195/484] Iter:[40/495], Time: 0.43, lr: [0.006285472445847389], Loss: 1.998748, Acc:0.801054, Semantic loss: 0.727640, BCE loss: 0.532913, SB loss: 0.738195
2023-10-30 10:13:14,448 Epoch: [195/484] Iter:[50/495], Time: 0.42, lr: [0.006285076896780566], Loss: 2.019077, Acc:0.804505, Semantic loss: 0.734250, BCE loss: 0.544175, SB loss: 0.740651
2023-10-30 10:13:18,244 Epoch: [195/484] Iter:[60/495], Time: 0.41, lr: [0.006284681344947755], Loss: 2.012849, Acc:0.805390, Semantic loss: 0.735305, BCE loss: 0.540930, SB loss: 0.736614
2023-10-30 10:13:21,840 Epoch: [195/484] Iter:[70/495], Time: 0.40, lr: [0.006284285790348738], Loss: 2.002824, Acc:0.801798, Semantic loss: 0.737013, BCE loss: 0.535196, SB loss: 0.730615
2023-10-30 10:13:25,493 Epoch: [195/484] Iter:[80/495], Time: 0.40, lr: [0.006283890232983307], Loss: 1.992969, Acc:0.793740, Semantic loss: 0.735411, BCE loss: 0.525266, SB loss: 0.732291
2023-10-30 10:13:29,110 Epoch: [195/484] Iter:[90/495], Time: 0.40, lr: [0.006283494672851247], Loss: 1.998927, Acc:0.796051, Semantic loss: 0.737750, BCE loss: 0.527963, SB loss: 0.733214
2023-10-30 10:13:32,718 Epoch: [195/484] Iter:[100/495], Time: 0.39, lr: [0.006283099109952346], Loss: 1.994134, Acc:0.793610, Semantic loss: 0.741081, BCE loss: 0.523848, SB loss: 0.729205
2023-10-30 10:13:36,484 Epoch: [195/484] Iter:[110/495], Time: 0.39, lr: [0.00628270354428639], Loss: 1.985922, Acc:0.791017, Semantic loss: 0.737855, BCE loss: 0.518737, SB loss: 0.729330
2023-10-30 10:13:40,285 Epoch: [195/484] Iter:[120/495], Time: 0.39, lr: [0.0062823079758531665], Loss: 1.990028, Acc:0.797978, Semantic loss: 0.736305, BCE loss: 0.525911, SB loss: 0.727811
2023-10-30 10:13:43,946 Epoch: [195/484] Iter:[130/495], Time: 0.39, lr: [0.0062819124046524615], Loss: 2.008082, Acc:0.799535, Semantic loss: 0.747439, BCE loss: 0.529724, SB loss: 0.730920
2023-10-30 10:13:47,634 Epoch: [195/484] Iter:[140/495], Time: 0.39, lr: [0.006281516830684063], Loss: 2.015847, Acc:0.799430, Semantic loss: 0.748167, BCE loss: 0.535724, SB loss: 0.731956
2023-10-30 10:13:51,258 Epoch: [195/484] Iter:[150/495], Time: 0.38, lr: [0.006281121253947759], Loss: 2.017473, Acc:0.801096, Semantic loss: 0.751069, BCE loss: 0.535302, SB loss: 0.731102
2023-10-30 10:13:54,903 Epoch: [195/484] Iter:[160/495], Time: 0.38, lr: [0.006280725674443335], Loss: 2.020810, Acc:0.800754, Semantic loss: 0.755672, BCE loss: 0.531825, SB loss: 0.733313
2023-10-30 10:13:58,721 Epoch: [195/484] Iter:[170/495], Time: 0.38, lr: [0.00628033009217058], Loss: 2.019502, Acc:0.798324, Semantic loss: 0.753636, BCE loss: 0.530674, SB loss: 0.735192
2023-10-30 10:14:02,491 Epoch: [195/484] Iter:[180/495], Time: 0.38, lr: [0.006279934507129278], Loss: 2.021061, Acc:0.798267, Semantic loss: 0.751488, BCE loss: 0.534125, SB loss: 0.735449
2023-10-30 10:14:06,205 Epoch: [195/484] Iter:[190/495], Time: 0.38, lr: [0.0062795389193192165], Loss: 2.019755, Acc:0.800335, Semantic loss: 0.750098, BCE loss: 0.535237, SB loss: 0.734421
2023-10-30 10:14:09,920 Epoch: [195/484] Iter:[200/495], Time: 0.38, lr: [0.006279143328740184], Loss: 2.020912, Acc:0.800471, Semantic loss: 0.754112, BCE loss: 0.532223, SB loss: 0.734576
2023-10-30 10:14:13,565 Epoch: [195/484] Iter:[210/495], Time: 0.38, lr: [0.0062787477353919655], Loss: 2.021820, Acc:0.801894, Semantic loss: 0.753933, BCE loss: 0.533394, SB loss: 0.734493
2023-10-30 10:14:17,297 Epoch: [195/484] Iter:[220/495], Time: 0.38, lr: [0.006278352139274348], Loss: 2.023025, Acc:0.802453, Semantic loss: 0.754868, BCE loss: 0.533785, SB loss: 0.734373
2023-10-30 10:14:21,073 Epoch: [195/484] Iter:[230/495], Time: 0.38, lr: [0.006277956540387118], Loss: 2.024734, Acc:0.802508, Semantic loss: 0.754622, BCE loss: 0.534993, SB loss: 0.735118
2023-10-30 10:14:24,692 Epoch: [195/484] Iter:[240/495], Time: 0.38, lr: [0.006277560938730066], Loss: 2.024594, Acc:0.802325, Semantic loss: 0.754026, BCE loss: 0.536950, SB loss: 0.733617
2023-10-30 10:14:28,299 Epoch: [195/484] Iter:[250/495], Time: 0.38, lr: [0.006277165334302974], Loss: 2.021333, Acc:0.802011, Semantic loss: 0.752603, BCE loss: 0.535290, SB loss: 0.733439
2023-10-30 10:14:32,113 Epoch: [195/484] Iter:[260/495], Time: 0.38, lr: [0.00627676972710563], Loss: 2.027373, Acc:0.801498, Semantic loss: 0.753951, BCE loss: 0.538590, SB loss: 0.734833
2023-10-30 10:14:35,745 Epoch: [195/484] Iter:[270/495], Time: 0.38, lr: [0.006276374117137821], Loss: 2.029813, Acc:0.801786, Semantic loss: 0.754548, BCE loss: 0.539386, SB loss: 0.735879
2023-10-30 10:14:39,544 Epoch: [195/484] Iter:[280/495], Time: 0.38, lr: [0.006275978504399334], Loss: 2.032331, Acc:0.800691, Semantic loss: 0.756409, BCE loss: 0.538545, SB loss: 0.737377
2023-10-30 10:14:43,267 Epoch: [195/484] Iter:[290/495], Time: 0.38, lr: [0.006275582888889952], Loss: 2.031711, Acc:0.800770, Semantic loss: 0.758261, BCE loss: 0.536521, SB loss: 0.736929
2023-10-30 10:14:47,011 Epoch: [195/484] Iter:[300/495], Time: 0.38, lr: [0.006275187270609467], Loss: 2.028626, Acc:0.800738, Semantic loss: 0.756687, BCE loss: 0.535882, SB loss: 0.736056
2023-10-30 10:14:50,693 Epoch: [195/484] Iter:[310/495], Time: 0.38, lr: [0.006274791649557662], Loss: 2.034580, Acc:0.800619, Semantic loss: 0.758896, BCE loss: 0.538441, SB loss: 0.737243
2023-10-30 10:14:54,497 Epoch: [195/484] Iter:[320/495], Time: 0.38, lr: [0.006274396025734325], Loss: 2.040185, Acc:0.799836, Semantic loss: 0.763230, BCE loss: 0.537843, SB loss: 0.739112
2023-10-30 10:14:58,215 Epoch: [195/484] Iter:[330/495], Time: 0.38, lr: [0.00627400039913924], Loss: 2.043810, Acc:0.800449, Semantic loss: 0.765637, BCE loss: 0.538740, SB loss: 0.739433
2023-10-30 10:15:02,093 Epoch: [195/484] Iter:[340/495], Time: 0.38, lr: [0.006273604769772198], Loss: 2.053208, Acc:0.800018, Semantic loss: 0.770245, BCE loss: 0.541108, SB loss: 0.741854
2023-10-30 10:15:05,787 Epoch: [195/484] Iter:[350/495], Time: 0.38, lr: [0.006273209137632981], Loss: 2.056145, Acc:0.800497, Semantic loss: 0.769977, BCE loss: 0.543462, SB loss: 0.742706
2023-10-30 10:15:09,456 Epoch: [195/484] Iter:[360/495], Time: 0.38, lr: [0.006272813502721375], Loss: 2.051508, Acc:0.800909, Semantic loss: 0.768029, BCE loss: 0.541989, SB loss: 0.741490
2023-10-30 10:15:13,337 Epoch: [195/484] Iter:[370/495], Time: 0.38, lr: [0.006272417865037169], Loss: 2.049648, Acc:0.800100, Semantic loss: 0.768971, BCE loss: 0.539629, SB loss: 0.741048
2023-10-30 10:15:17,045 Epoch: [195/484] Iter:[380/495], Time: 0.38, lr: [0.006272022224580149], Loss: 2.048211, Acc:0.800281, Semantic loss: 0.768586, BCE loss: 0.538542, SB loss: 0.741082
2023-10-30 10:15:20,770 Epoch: [195/484] Iter:[390/495], Time: 0.38, lr: [0.0062716265813501], Loss: 2.050382, Acc:0.799174, Semantic loss: 0.769417, BCE loss: 0.540251, SB loss: 0.740714
2023-10-30 10:15:24,502 Epoch: [195/484] Iter:[400/495], Time: 0.38, lr: [0.006271230935346809], Loss: 2.047335, Acc:0.798908, Semantic loss: 0.767485, BCE loss: 0.540141, SB loss: 0.739710
2023-10-30 10:15:28,199 Epoch: [195/484] Iter:[410/495], Time: 0.38, lr: [0.006270835286570062], Loss: 2.048862, Acc:0.799171, Semantic loss: 0.767940, BCE loss: 0.541434, SB loss: 0.739487
2023-10-30 10:15:31,980 Epoch: [195/484] Iter:[420/495], Time: 0.38, lr: [0.006270439635019644], Loss: 2.047730, Acc:0.799272, Semantic loss: 0.766605, BCE loss: 0.542004, SB loss: 0.739121
2023-10-30 10:15:35,702 Epoch: [195/484] Iter:[430/495], Time: 0.38, lr: [0.006270043980695342], Loss: 2.049778, Acc:0.799426, Semantic loss: 0.767854, BCE loss: 0.542321, SB loss: 0.739602
2023-10-30 10:15:39,453 Epoch: [195/484] Iter:[440/495], Time: 0.38, lr: [0.006269648323596943], Loss: 2.045471, Acc:0.799156, Semantic loss: 0.765405, BCE loss: 0.541669, SB loss: 0.738397
2023-10-30 10:15:43,216 Epoch: [195/484] Iter:[450/495], Time: 0.38, lr: [0.006269252663724232], Loss: 2.043738, Acc:0.800229, Semantic loss: 0.765538, BCE loss: 0.540581, SB loss: 0.737619
2023-10-30 10:15:46,925 Epoch: [195/484] Iter:[460/495], Time: 0.38, lr: [0.0062688570010769945], Loss: 2.041056, Acc:0.800549, Semantic loss: 0.765035, BCE loss: 0.538966, SB loss: 0.737055
2023-10-30 10:15:50,558 Epoch: [195/484] Iter:[470/495], Time: 0.38, lr: [0.006268461335655018], Loss: 2.039892, Acc:0.799857, Semantic loss: 0.764349, BCE loss: 0.538054, SB loss: 0.737490
2023-10-30 10:15:54,258 Epoch: [195/484] Iter:[480/495], Time: 0.38, lr: [0.006268065667458087], Loss: 2.041315, Acc:0.799677, Semantic loss: 0.765300, BCE loss: 0.538193, SB loss: 0.737821
2023-10-30 10:15:57,795 Epoch: [195/484] Iter:[490/495], Time: 0.38, lr: [0.006267669996485988], Loss: 2.043972, Acc:0.800054, Semantic loss: 0.767168, BCE loss: 0.538480, SB loss: 0.738323
2023-10-30 10:18:53,834 0 [9.34315916e-01 6.29868095e-01 8.10083724e-01 1.55480139e-01
 2.41766047e-01 3.99569265e-01 4.40071878e-01 5.73663650e-01
 8.76832992e-01 3.78092654e-01 8.54241407e-01 5.97541945e-01
 1.00769685e-02 7.97184608e-01 4.41781044e-05 6.27536790e-02
 3.45249423e-02 5.14739600e-02 5.71425341e-01] 0.44310586257751344
2023-10-30 10:18:53,834 1 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541] 0.6310407858071878
2023-10-30 10:18:53,837 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:18:54,071 Loss: 2.140, MeanIU:  0.6310, Best_mIoU:  0.7072
2023-10-30 10:18:54,072 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541]
2023-10-30 10:18:56,150 Epoch: [196/484] Iter:[0/495], Time: 2.05, lr: [0.006267472159959184], Loss: 2.208303, Acc:0.784830, Semantic loss: 0.898733, BCE loss: 0.483583, SB loss: 0.825987
2023-10-30 10:18:59,954 Epoch: [196/484] Iter:[10/495], Time: 0.53, lr: [0.006267076484823932], Loss: 2.012329, Acc:0.819202, Semantic loss: 0.749549, BCE loss: 0.551227, SB loss: 0.711553
2023-10-30 10:19:03,641 Epoch: [196/484] Iter:[20/495], Time: 0.45, lr: [0.006266680806912977], Loss: 2.057401, Acc:0.795269, Semantic loss: 0.782670, BCE loss: 0.533646, SB loss: 0.741084
2023-10-30 10:19:07,300 Epoch: [196/484] Iter:[30/495], Time: 0.43, lr: [0.006266285126226102], Loss: 2.090216, Acc:0.798095, Semantic loss: 0.792352, BCE loss: 0.555393, SB loss: 0.742471
2023-10-30 10:19:10,868 Epoch: [196/484] Iter:[40/495], Time: 0.41, lr: [0.006265889442763096], Loss: 2.123320, Acc:0.808383, Semantic loss: 0.804175, BCE loss: 0.571179, SB loss: 0.747966
2023-10-30 10:19:14,436 Epoch: [196/484] Iter:[50/495], Time: 0.40, lr: [0.006265493756523744], Loss: 2.126660, Acc:0.810065, Semantic loss: 0.804503, BCE loss: 0.577721, SB loss: 0.744436
2023-10-30 10:19:17,992 Epoch: [196/484] Iter:[60/495], Time: 0.39, lr: [0.006265098067507833], Loss: 2.119933, Acc:0.806258, Semantic loss: 0.802498, BCE loss: 0.567251, SB loss: 0.750184
2023-10-30 10:19:21,543 Epoch: [196/484] Iter:[70/495], Time: 0.39, lr: [0.006264702375715145], Loss: 2.099204, Acc:0.805970, Semantic loss: 0.795499, BCE loss: 0.559183, SB loss: 0.744522
2023-10-30 10:19:25,124 Epoch: [196/484] Iter:[80/495], Time: 0.38, lr: [0.006264306681145471], Loss: 2.093952, Acc:0.801524, Semantic loss: 0.793049, BCE loss: 0.555576, SB loss: 0.745327
2023-10-30 10:19:28,871 Epoch: [196/484] Iter:[90/495], Time: 0.38, lr: [0.0062639109837985905], Loss: 2.091313, Acc:0.802249, Semantic loss: 0.787993, BCE loss: 0.556442, SB loss: 0.746877
2023-10-30 10:19:32,571 Epoch: [196/484] Iter:[100/495], Time: 0.38, lr: [0.006263515283674294], Loss: 2.096932, Acc:0.798405, Semantic loss: 0.793659, BCE loss: 0.553253, SB loss: 0.750021
2023-10-30 10:19:36,358 Epoch: [196/484] Iter:[110/495], Time: 0.38, lr: [0.006263119580772364], Loss: 2.105548, Acc:0.801044, Semantic loss: 0.789405, BCE loss: 0.563061, SB loss: 0.753082
2023-10-30 10:19:40,021 Epoch: [196/484] Iter:[120/495], Time: 0.38, lr: [0.006262723875092587], Loss: 2.105233, Acc:0.802452, Semantic loss: 0.789191, BCE loss: 0.563456, SB loss: 0.752587
2023-10-30 10:19:43,656 Epoch: [196/484] Iter:[130/495], Time: 0.38, lr: [0.006262328166634749], Loss: 2.099015, Acc:0.803140, Semantic loss: 0.784996, BCE loss: 0.563531, SB loss: 0.750488
2023-10-30 10:19:47,256 Epoch: [196/484] Iter:[140/495], Time: 0.38, lr: [0.006261932455398634], Loss: 2.102638, Acc:0.802493, Semantic loss: 0.788614, BCE loss: 0.562295, SB loss: 0.751729
2023-10-30 10:19:50,855 Epoch: [196/484] Iter:[150/495], Time: 0.38, lr: [0.0062615367413840295], Loss: 2.099941, Acc:0.803316, Semantic loss: 0.787498, BCE loss: 0.560153, SB loss: 0.752290
2023-10-30 10:19:54,426 Epoch: [196/484] Iter:[160/495], Time: 0.37, lr: [0.0062611410245907205], Loss: 2.101803, Acc:0.804841, Semantic loss: 0.787157, BCE loss: 0.563188, SB loss: 0.751458
2023-10-30 10:19:58,028 Epoch: [196/484] Iter:[170/495], Time: 0.37, lr: [0.006260745305018491], Loss: 2.092660, Acc:0.805107, Semantic loss: 0.783908, BCE loss: 0.558735, SB loss: 0.750018
2023-10-30 10:20:01,632 Epoch: [196/484] Iter:[180/495], Time: 0.37, lr: [0.006260349582667127], Loss: 2.085236, Acc:0.804052, Semantic loss: 0.781986, BCE loss: 0.554133, SB loss: 0.749117
2023-10-30 10:20:05,201 Epoch: [196/484] Iter:[190/495], Time: 0.37, lr: [0.006259953857536414], Loss: 2.078223, Acc:0.803693, Semantic loss: 0.779764, BCE loss: 0.549936, SB loss: 0.748523
2023-10-30 10:20:08,945 Epoch: [196/484] Iter:[200/495], Time: 0.37, lr: [0.006259558129626136], Loss: 2.082243, Acc:0.803972, Semantic loss: 0.781041, BCE loss: 0.551458, SB loss: 0.749745
2023-10-30 10:20:12,636 Epoch: [196/484] Iter:[210/495], Time: 0.37, lr: [0.006259162398936079], Loss: 2.087069, Acc:0.801646, Semantic loss: 0.785907, BCE loss: 0.550439, SB loss: 0.750723
2023-10-30 10:20:16,379 Epoch: [196/484] Iter:[220/495], Time: 0.37, lr: [0.00625876666546603], Loss: 2.089767, Acc:0.801437, Semantic loss: 0.785698, BCE loss: 0.553093, SB loss: 0.750976
2023-10-30 10:20:19,943 Epoch: [196/484] Iter:[230/495], Time: 0.37, lr: [0.006258370929215772], Loss: 2.086574, Acc:0.801340, Semantic loss: 0.784713, BCE loss: 0.551341, SB loss: 0.750520
2023-10-30 10:20:23,612 Epoch: [196/484] Iter:[240/495], Time: 0.37, lr: [0.0062579751901850915], Loss: 2.088435, Acc:0.802827, Semantic loss: 0.785866, BCE loss: 0.550808, SB loss: 0.751761
2023-10-30 10:20:27,252 Epoch: [196/484] Iter:[250/495], Time: 0.37, lr: [0.006257579448373772], Loss: 2.094515, Acc:0.802810, Semantic loss: 0.789322, BCE loss: 0.552501, SB loss: 0.752691
2023-10-30 10:20:30,999 Epoch: [196/484] Iter:[260/495], Time: 0.37, lr: [0.006257183703781599], Loss: 2.100497, Acc:0.802912, Semantic loss: 0.790887, BCE loss: 0.556662, SB loss: 0.752949
2023-10-30 10:20:34,649 Epoch: [196/484] Iter:[270/495], Time: 0.37, lr: [0.0062567879564083585], Loss: 2.097851, Acc:0.801415, Semantic loss: 0.788775, BCE loss: 0.556736, SB loss: 0.752340
2023-10-30 10:20:38,523 Epoch: [196/484] Iter:[280/495], Time: 0.37, lr: [0.006256392206253834], Loss: 2.094680, Acc:0.800260, Semantic loss: 0.787852, BCE loss: 0.554761, SB loss: 0.752068
2023-10-30 10:20:42,098 Epoch: [196/484] Iter:[290/495], Time: 0.37, lr: [0.006255996453317813], Loss: 2.092766, Acc:0.800022, Semantic loss: 0.785428, BCE loss: 0.555805, SB loss: 0.751533
2023-10-30 10:20:45,848 Epoch: [196/484] Iter:[300/495], Time: 0.37, lr: [0.006255600697600078], Loss: 2.089681, Acc:0.798991, Semantic loss: 0.784328, BCE loss: 0.554474, SB loss: 0.750879
2023-10-30 10:20:49,564 Epoch: [196/484] Iter:[310/495], Time: 0.37, lr: [0.006255204939100415], Loss: 2.087802, Acc:0.798957, Semantic loss: 0.783814, BCE loss: 0.553705, SB loss: 0.750283
2023-10-30 10:20:53,256 Epoch: [196/484] Iter:[320/495], Time: 0.37, lr: [0.00625480917781861], Loss: 2.083320, Acc:0.799462, Semantic loss: 0.781764, BCE loss: 0.552595, SB loss: 0.748961
2023-10-30 10:20:56,906 Epoch: [196/484] Iter:[330/495], Time: 0.37, lr: [0.006254413413754445], Loss: 2.077140, Acc:0.798361, Semantic loss: 0.779446, BCE loss: 0.550225, SB loss: 0.747469
2023-10-30 10:21:00,659 Epoch: [196/484] Iter:[340/495], Time: 0.37, lr: [0.006254017646907706], Loss: 2.075953, Acc:0.798688, Semantic loss: 0.779247, BCE loss: 0.549498, SB loss: 0.747208
2023-10-30 10:21:04,416 Epoch: [196/484] Iter:[350/495], Time: 0.37, lr: [0.006253621877278178], Loss: 2.077829, Acc:0.799190, Semantic loss: 0.779732, BCE loss: 0.550171, SB loss: 0.747926
2023-10-30 10:21:08,027 Epoch: [196/484] Iter:[360/495], Time: 0.37, lr: [0.006253226104865645], Loss: 2.075359, Acc:0.798778, Semantic loss: 0.779201, BCE loss: 0.548986, SB loss: 0.747172
2023-10-30 10:21:11,704 Epoch: [196/484] Iter:[370/495], Time: 0.37, lr: [0.006252830329669896], Loss: 2.072100, Acc:0.798958, Semantic loss: 0.778013, BCE loss: 0.547374, SB loss: 0.746714
2023-10-30 10:21:15,373 Epoch: [196/484] Iter:[380/495], Time: 0.37, lr: [0.00625243455169071], Loss: 2.070084, Acc:0.798016, Semantic loss: 0.777706, BCE loss: 0.546341, SB loss: 0.746037
2023-10-30 10:21:19,093 Epoch: [196/484] Iter:[390/495], Time: 0.37, lr: [0.006252038770927875], Loss: 2.070208, Acc:0.797489, Semantic loss: 0.777905, BCE loss: 0.546530, SB loss: 0.745773
2023-10-30 10:21:22,673 Epoch: [196/484] Iter:[400/495], Time: 0.37, lr: [0.006251642987381173], Loss: 2.066535, Acc:0.797247, Semantic loss: 0.776173, BCE loss: 0.545461, SB loss: 0.744902
2023-10-30 10:21:26,439 Epoch: [196/484] Iter:[410/495], Time: 0.37, lr: [0.0062512472010503905], Loss: 2.070059, Acc:0.796839, Semantic loss: 0.777887, BCE loss: 0.546845, SB loss: 0.745327
2023-10-30 10:21:30,191 Epoch: [196/484] Iter:[420/495], Time: 0.37, lr: [0.006250851411935312], Loss: 2.071746, Acc:0.796898, Semantic loss: 0.778922, BCE loss: 0.546887, SB loss: 0.745937
2023-10-30 10:21:33,879 Epoch: [196/484] Iter:[430/495], Time: 0.37, lr: [0.006250455620035722], Loss: 2.070939, Acc:0.796739, Semantic loss: 0.778430, BCE loss: 0.546925, SB loss: 0.745583
2023-10-30 10:21:37,667 Epoch: [196/484] Iter:[440/495], Time: 0.37, lr: [0.006250059825351403], Loss: 2.074165, Acc:0.796510, Semantic loss: 0.780793, BCE loss: 0.547247, SB loss: 0.746125
2023-10-30 10:21:41,444 Epoch: [196/484] Iter:[450/495], Time: 0.37, lr: [0.006249664027882143], Loss: 2.074030, Acc:0.796064, Semantic loss: 0.780637, BCE loss: 0.547238, SB loss: 0.746155
2023-10-30 10:21:45,070 Epoch: [196/484] Iter:[460/495], Time: 0.37, lr: [0.0062492682276277245], Loss: 2.070994, Acc:0.796232, Semantic loss: 0.779230, BCE loss: 0.546289, SB loss: 0.745474
2023-10-30 10:21:48,776 Epoch: [196/484] Iter:[470/495], Time: 0.37, lr: [0.006248872424587932], Loss: 2.068970, Acc:0.796276, Semantic loss: 0.777930, BCE loss: 0.545866, SB loss: 0.745174
2023-10-30 10:21:52,496 Epoch: [196/484] Iter:[480/495], Time: 0.37, lr: [0.00624847661876255], Loss: 2.068931, Acc:0.796662, Semantic loss: 0.778559, BCE loss: 0.544937, SB loss: 0.745436
2023-10-30 10:21:55,978 Epoch: [196/484] Iter:[490/495], Time: 0.37, lr: [0.006248080810151362], Loss: 2.070517, Acc:0.796186, Semantic loss: 0.779584, BCE loss: 0.545110, SB loss: 0.745823
2023-10-30 10:21:57,385 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:21:57,621 Loss: 2.140, MeanIU:  0.6310, Best_mIoU:  0.7072
2023-10-30 10:21:57,621 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541]
2023-10-30 10:21:59,683 Epoch: [197/484] Iter:[0/495], Time: 2.03, lr: [0.006247882904801023], Loss: 2.543536, Acc:0.817470, Semantic loss: 1.134064, BCE loss: 0.608867, SB loss: 0.800605
2023-10-30 10:22:03,757 Epoch: [197/484] Iter:[10/495], Time: 0.55, lr: [0.0062474870920107214], Loss: 2.294548, Acc:0.790156, Semantic loss: 0.932282, BCE loss: 0.564509, SB loss: 0.797757
2023-10-30 10:22:07,550 Epoch: [197/484] Iter:[20/495], Time: 0.47, lr: [0.0062470912764340785], Loss: 2.250767, Acc:0.785366, Semantic loss: 0.903844, BCE loss: 0.555045, SB loss: 0.791878
2023-10-30 10:22:11,295 Epoch: [197/484] Iter:[30/495], Time: 0.44, lr: [0.006246695458070871], Loss: 2.207512, Acc:0.790418, Semantic loss: 0.861876, BCE loss: 0.559477, SB loss: 0.786158
2023-10-30 10:22:15,067 Epoch: [197/484] Iter:[40/495], Time: 0.42, lr: [0.0062462996369208905], Loss: 2.165081, Acc:0.793429, Semantic loss: 0.837431, BCE loss: 0.549346, SB loss: 0.778304
2023-10-30 10:22:18,725 Epoch: [197/484] Iter:[50/495], Time: 0.41, lr: [0.006245903812983918], Loss: 2.135074, Acc:0.790218, Semantic loss: 0.821598, BCE loss: 0.540890, SB loss: 0.772586
2023-10-30 10:22:22,504 Epoch: [197/484] Iter:[60/495], Time: 0.41, lr: [0.006245507986259735], Loss: 2.146370, Acc:0.790612, Semantic loss: 0.828676, BCE loss: 0.542876, SB loss: 0.774817
2023-10-30 10:22:26,238 Epoch: [197/484] Iter:[70/495], Time: 0.40, lr: [0.006245112156748131], Loss: 2.121062, Acc:0.789433, Semantic loss: 0.813433, BCE loss: 0.540090, SB loss: 0.767539
2023-10-30 10:22:29,984 Epoch: [197/484] Iter:[80/495], Time: 0.40, lr: [0.006244716324448886], Loss: 2.138484, Acc:0.792053, Semantic loss: 0.818246, BCE loss: 0.550657, SB loss: 0.769580
2023-10-30 10:22:33,679 Epoch: [197/484] Iter:[90/495], Time: 0.40, lr: [0.006244320489361785], Loss: 2.126673, Acc:0.792836, Semantic loss: 0.810981, BCE loss: 0.551949, SB loss: 0.763743
2023-10-30 10:22:37,320 Epoch: [197/484] Iter:[100/495], Time: 0.39, lr: [0.006243924651486613], Loss: 2.122343, Acc:0.790325, Semantic loss: 0.809132, BCE loss: 0.547353, SB loss: 0.765858
2023-10-30 10:22:41,043 Epoch: [197/484] Iter:[110/495], Time: 0.39, lr: [0.006243528810823152], Loss: 2.124234, Acc:0.790229, Semantic loss: 0.810325, BCE loss: 0.548136, SB loss: 0.765773
2023-10-30 10:22:44,724 Epoch: [197/484] Iter:[120/495], Time: 0.39, lr: [0.006243132967371188], Loss: 2.107707, Acc:0.788471, Semantic loss: 0.804288, BCE loss: 0.541291, SB loss: 0.762129
2023-10-30 10:22:48,355 Epoch: [197/484] Iter:[130/495], Time: 0.39, lr: [0.006242737121130504], Loss: 2.110216, Acc:0.787171, Semantic loss: 0.802295, BCE loss: 0.546485, SB loss: 0.761435
2023-10-30 10:22:51,956 Epoch: [197/484] Iter:[140/495], Time: 0.39, lr: [0.006242341272100885], Loss: 2.110572, Acc:0.788266, Semantic loss: 0.802209, BCE loss: 0.547007, SB loss: 0.761357
2023-10-30 10:22:55,658 Epoch: [197/484] Iter:[150/495], Time: 0.38, lr: [0.0062419454202821125], Loss: 2.110426, Acc:0.789533, Semantic loss: 0.798535, BCE loss: 0.551692, SB loss: 0.760198
2023-10-30 10:22:59,321 Epoch: [197/484] Iter:[160/495], Time: 0.38, lr: [0.006241549565673971], Loss: 2.110436, Acc:0.788112, Semantic loss: 0.796613, BCE loss: 0.553188, SB loss: 0.760636
2023-10-30 10:23:02,940 Epoch: [197/484] Iter:[170/495], Time: 0.38, lr: [0.006241153708276246], Loss: 2.127996, Acc:0.787566, Semantic loss: 0.808989, BCE loss: 0.554939, SB loss: 0.764068
2023-10-30 10:23:06,655 Epoch: [197/484] Iter:[180/495], Time: 0.38, lr: [0.0062407578480887195], Loss: 2.116518, Acc:0.787079, Semantic loss: 0.802781, BCE loss: 0.551399, SB loss: 0.762338
2023-10-30 10:23:10,362 Epoch: [197/484] Iter:[190/495], Time: 0.38, lr: [0.006240361985111177], Loss: 2.109614, Acc:0.789322, Semantic loss: 0.796378, BCE loss: 0.551743, SB loss: 0.761493
2023-10-30 10:23:14,051 Epoch: [197/484] Iter:[200/495], Time: 0.38, lr: [0.006239966119343401], Loss: 2.117386, Acc:0.789519, Semantic loss: 0.800965, BCE loss: 0.551119, SB loss: 0.765303
2023-10-30 10:23:17,781 Epoch: [197/484] Iter:[210/495], Time: 0.38, lr: [0.006239570250785175], Loss: 2.116154, Acc:0.789993, Semantic loss: 0.799270, BCE loss: 0.552911, SB loss: 0.763973
2023-10-30 10:23:21,522 Epoch: [197/484] Iter:[220/495], Time: 0.38, lr: [0.006239174379436282], Loss: 2.108611, Acc:0.789771, Semantic loss: 0.794100, BCE loss: 0.551719, SB loss: 0.762792
2023-10-30 10:23:25,152 Epoch: [197/484] Iter:[230/495], Time: 0.38, lr: [0.006238778505296507], Loss: 2.110840, Acc:0.789630, Semantic loss: 0.796385, BCE loss: 0.551244, SB loss: 0.763210
2023-10-30 10:23:28,970 Epoch: [197/484] Iter:[240/495], Time: 0.38, lr: [0.006238382628365632], Loss: 2.104083, Acc:0.788493, Semantic loss: 0.792663, BCE loss: 0.550372, SB loss: 0.761048
2023-10-30 10:23:32,582 Epoch: [197/484] Iter:[250/495], Time: 0.38, lr: [0.006237986748643442], Loss: 2.105709, Acc:0.789186, Semantic loss: 0.793706, BCE loss: 0.550934, SB loss: 0.761070
2023-10-30 10:23:36,420 Epoch: [197/484] Iter:[260/495], Time: 0.38, lr: [0.0062375908661297195], Loss: 2.101482, Acc:0.788647, Semantic loss: 0.792140, BCE loss: 0.548934, SB loss: 0.760408
2023-10-30 10:23:40,050 Epoch: [197/484] Iter:[270/495], Time: 0.38, lr: [0.006237194980824249], Loss: 2.100132, Acc:0.788332, Semantic loss: 0.792104, BCE loss: 0.548205, SB loss: 0.759824
2023-10-30 10:23:43,838 Epoch: [197/484] Iter:[280/495], Time: 0.38, lr: [0.0062367990927268135], Loss: 2.098892, Acc:0.789432, Semantic loss: 0.791588, BCE loss: 0.547787, SB loss: 0.759517
2023-10-30 10:23:47,578 Epoch: [197/484] Iter:[290/495], Time: 0.38, lr: [0.006236403201837198], Loss: 2.101234, Acc:0.790742, Semantic loss: 0.792977, BCE loss: 0.548854, SB loss: 0.759402
2023-10-30 10:23:51,291 Epoch: [197/484] Iter:[300/495], Time: 0.38, lr: [0.006236007308155182], Loss: 2.099788, Acc:0.790808, Semantic loss: 0.792611, BCE loss: 0.548472, SB loss: 0.758705
2023-10-30 10:23:54,926 Epoch: [197/484] Iter:[310/495], Time: 0.38, lr: [0.006235611411680551], Loss: 2.101102, Acc:0.788991, Semantic loss: 0.793578, BCE loss: 0.547983, SB loss: 0.759542
2023-10-30 10:23:58,554 Epoch: [197/484] Iter:[320/495], Time: 0.38, lr: [0.006235215512413087], Loss: 2.100113, Acc:0.789305, Semantic loss: 0.791673, BCE loss: 0.548808, SB loss: 0.759632
2023-10-30 10:24:02,254 Epoch: [197/484] Iter:[330/495], Time: 0.38, lr: [0.006234819610352577], Loss: 2.100706, Acc:0.789231, Semantic loss: 0.793319, BCE loss: 0.547910, SB loss: 0.759476
2023-10-30 10:24:05,940 Epoch: [197/484] Iter:[340/495], Time: 0.38, lr: [0.0062344237054987985], Loss: 2.097936, Acc:0.788950, Semantic loss: 0.790624, BCE loss: 0.547760, SB loss: 0.759552
2023-10-30 10:24:09,620 Epoch: [197/484] Iter:[350/495], Time: 0.38, lr: [0.0062340277978515405], Loss: 2.096978, Acc:0.789044, Semantic loss: 0.788994, BCE loss: 0.549422, SB loss: 0.758562
2023-10-30 10:24:13,285 Epoch: [197/484] Iter:[360/495], Time: 0.38, lr: [0.006233631887410583], Loss: 2.096841, Acc:0.789558, Semantic loss: 0.789402, BCE loss: 0.548976, SB loss: 0.758463
2023-10-30 10:24:17,024 Epoch: [197/484] Iter:[370/495], Time: 0.38, lr: [0.006233235974175709], Loss: 2.094138, Acc:0.789970, Semantic loss: 0.787523, BCE loss: 0.549638, SB loss: 0.756977
2023-10-30 10:24:20,668 Epoch: [197/484] Iter:[380/495], Time: 0.38, lr: [0.0062328400581467035], Loss: 2.094120, Acc:0.790427, Semantic loss: 0.788226, BCE loss: 0.549303, SB loss: 0.756591
2023-10-30 10:24:24,348 Epoch: [197/484] Iter:[390/495], Time: 0.38, lr: [0.006232444139323349], Loss: 2.095698, Acc:0.790578, Semantic loss: 0.789119, BCE loss: 0.549459, SB loss: 0.757120
2023-10-30 10:24:28,051 Epoch: [197/484] Iter:[400/495], Time: 0.38, lr: [0.006232048217705426], Loss: 2.090550, Acc:0.790904, Semantic loss: 0.787332, BCE loss: 0.547400, SB loss: 0.755819
2023-10-30 10:24:31,717 Epoch: [197/484] Iter:[410/495], Time: 0.37, lr: [0.00623165229329272], Loss: 2.087256, Acc:0.790301, Semantic loss: 0.785471, BCE loss: 0.545745, SB loss: 0.756040
2023-10-30 10:24:35,385 Epoch: [197/484] Iter:[420/495], Time: 0.37, lr: [0.006231256366085013], Loss: 2.083483, Acc:0.790499, Semantic loss: 0.784768, BCE loss: 0.543614, SB loss: 0.755101
2023-10-30 10:24:39,008 Epoch: [197/484] Iter:[430/495], Time: 0.37, lr: [0.006230860436082088], Loss: 2.084591, Acc:0.790261, Semantic loss: 0.785988, BCE loss: 0.543317, SB loss: 0.755286
2023-10-30 10:24:42,692 Epoch: [197/484] Iter:[440/495], Time: 0.37, lr: [0.0062304645032837305], Loss: 2.083789, Acc:0.790115, Semantic loss: 0.785290, BCE loss: 0.543354, SB loss: 0.755145
2023-10-30 10:24:46,365 Epoch: [197/484] Iter:[450/495], Time: 0.37, lr: [0.00623006856768972], Loss: 2.084029, Acc:0.791500, Semantic loss: 0.784693, BCE loss: 0.544429, SB loss: 0.754906
2023-10-30 10:24:50,093 Epoch: [197/484] Iter:[460/495], Time: 0.37, lr: [0.00622967262929984], Loss: 2.084582, Acc:0.791406, Semantic loss: 0.784720, BCE loss: 0.543931, SB loss: 0.755931
2023-10-30 10:24:53,776 Epoch: [197/484] Iter:[470/495], Time: 0.37, lr: [0.006229276688113874], Loss: 2.083622, Acc:0.791273, Semantic loss: 0.784332, BCE loss: 0.544158, SB loss: 0.755133
2023-10-30 10:24:57,435 Epoch: [197/484] Iter:[480/495], Time: 0.37, lr: [0.006228880744131604], Loss: 2.083348, Acc:0.791741, Semantic loss: 0.784023, BCE loss: 0.544228, SB loss: 0.755097
2023-10-30 10:25:00,993 Epoch: [197/484] Iter:[490/495], Time: 0.37, lr: [0.006228484797352813], Loss: 2.081346, Acc:0.791338, Semantic loss: 0.783516, BCE loss: 0.542780, SB loss: 0.755051
2023-10-30 10:25:02,388 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:25:02,632 Loss: 2.140, MeanIU:  0.6310, Best_mIoU:  0.7072
2023-10-30 10:25:02,633 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541]
2023-10-30 10:25:04,566 Epoch: [198/484] Iter:[0/495], Time: 1.90, lr: [0.006228286822914655], Loss: 1.897736, Acc:0.680265, Semantic loss: 0.692920, BCE loss: 0.444069, SB loss: 0.760746
2023-10-30 10:25:08,627 Epoch: [198/484] Iter:[10/495], Time: 0.54, lr: [0.006227890871940677], Loss: 2.076733, Acc:0.795643, Semantic loss: 0.765329, BCE loss: 0.582666, SB loss: 0.728737
2023-10-30 10:25:12,324 Epoch: [198/484] Iter:[20/495], Time: 0.46, lr: [0.006227494918169634], Loss: 2.100940, Acc:0.783297, Semantic loss: 0.796857, BCE loss: 0.551457, SB loss: 0.752626
2023-10-30 10:25:15,976 Epoch: [198/484] Iter:[30/495], Time: 0.43, lr: [0.006227098961601311], Loss: 2.091860, Acc:0.805237, Semantic loss: 0.788154, BCE loss: 0.550804, SB loss: 0.752902
2023-10-30 10:25:19,559 Epoch: [198/484] Iter:[40/495], Time: 0.41, lr: [0.006226703002235489], Loss: 2.070857, Acc:0.800939, Semantic loss: 0.786547, BCE loss: 0.529321, SB loss: 0.754989
2023-10-30 10:25:23,226 Epoch: [198/484] Iter:[50/495], Time: 0.40, lr: [0.0062263070400719505], Loss: 2.081264, Acc:0.800685, Semantic loss: 0.797720, BCE loss: 0.529475, SB loss: 0.754069
2023-10-30 10:25:27,020 Epoch: [198/484] Iter:[60/495], Time: 0.40, lr: [0.0062259110751104775], Loss: 2.071361, Acc:0.800263, Semantic loss: 0.794969, BCE loss: 0.526572, SB loss: 0.749820
2023-10-30 10:25:30,715 Epoch: [198/484] Iter:[70/495], Time: 0.40, lr: [0.006225515107350854], Loss: 2.072632, Acc:0.805652, Semantic loss: 0.793537, BCE loss: 0.527973, SB loss: 0.751122
2023-10-30 10:25:34,500 Epoch: [198/484] Iter:[80/495], Time: 0.39, lr: [0.006225119136792862], Loss: 2.088988, Acc:0.801608, Semantic loss: 0.799161, BCE loss: 0.533830, SB loss: 0.755996
2023-10-30 10:25:38,255 Epoch: [198/484] Iter:[90/495], Time: 0.39, lr: [0.006224723163436283], Loss: 2.091945, Acc:0.799554, Semantic loss: 0.798699, BCE loss: 0.539039, SB loss: 0.754207
2023-10-30 10:25:41,884 Epoch: [198/484] Iter:[100/495], Time: 0.39, lr: [0.006224327187280902], Loss: 2.066819, Acc:0.801596, Semantic loss: 0.788333, BCE loss: 0.529651, SB loss: 0.748836
2023-10-30 10:25:45,542 Epoch: [198/484] Iter:[110/495], Time: 0.39, lr: [0.006223931208326499], Loss: 2.057129, Acc:0.797719, Semantic loss: 0.785887, BCE loss: 0.524407, SB loss: 0.746835
2023-10-30 10:25:49,368 Epoch: [198/484] Iter:[120/495], Time: 0.39, lr: [0.0062235352265728565], Loss: 2.076683, Acc:0.796030, Semantic loss: 0.794821, BCE loss: 0.528619, SB loss: 0.753242
2023-10-30 10:25:52,971 Epoch: [198/484] Iter:[130/495], Time: 0.38, lr: [0.0062231392420197575], Loss: 2.080337, Acc:0.793372, Semantic loss: 0.793430, BCE loss: 0.534105, SB loss: 0.752802
2023-10-30 10:25:56,635 Epoch: [198/484] Iter:[140/495], Time: 0.38, lr: [0.006222743254666984], Loss: 2.080407, Acc:0.793918, Semantic loss: 0.790666, BCE loss: 0.535267, SB loss: 0.754474
2023-10-30 10:26:00,272 Epoch: [198/484] Iter:[150/495], Time: 0.38, lr: [0.006222347264514317], Loss: 2.078344, Acc:0.793941, Semantic loss: 0.789127, BCE loss: 0.536031, SB loss: 0.753186
2023-10-30 10:26:03,999 Epoch: [198/484] Iter:[160/495], Time: 0.38, lr: [0.006221951271561541], Loss: 2.080627, Acc:0.793889, Semantic loss: 0.792746, BCE loss: 0.536185, SB loss: 0.751695
2023-10-30 10:26:07,756 Epoch: [198/484] Iter:[170/495], Time: 0.38, lr: [0.006221555275808438], Loss: 2.075591, Acc:0.794374, Semantic loss: 0.789713, BCE loss: 0.536603, SB loss: 0.749275
2023-10-30 10:26:11,469 Epoch: [198/484] Iter:[180/495], Time: 0.38, lr: [0.00622115927725479], Loss: 2.073814, Acc:0.794359, Semantic loss: 0.788366, BCE loss: 0.536947, SB loss: 0.748500
2023-10-30 10:26:15,230 Epoch: [198/484] Iter:[190/495], Time: 0.38, lr: [0.006220763275900377], Loss: 2.071286, Acc:0.795010, Semantic loss: 0.786727, BCE loss: 0.536264, SB loss: 0.748295
2023-10-30 10:26:18,869 Epoch: [198/484] Iter:[200/495], Time: 0.38, lr: [0.006220367271744983], Loss: 2.081526, Acc:0.796413, Semantic loss: 0.793761, BCE loss: 0.537982, SB loss: 0.749783
2023-10-30 10:26:22,466 Epoch: [198/484] Iter:[210/495], Time: 0.38, lr: [0.00621997126478839], Loss: 2.079082, Acc:0.795017, Semantic loss: 0.789906, BCE loss: 0.540496, SB loss: 0.748679
2023-10-30 10:26:26,136 Epoch: [198/484] Iter:[220/495], Time: 0.38, lr: [0.0062195752550303785], Loss: 2.080652, Acc:0.792199, Semantic loss: 0.792796, BCE loss: 0.538168, SB loss: 0.749688
2023-10-30 10:26:29,781 Epoch: [198/484] Iter:[230/495], Time: 0.38, lr: [0.006219179242470733], Loss: 2.080414, Acc:0.792571, Semantic loss: 0.793049, BCE loss: 0.536162, SB loss: 0.751203
2023-10-30 10:26:33,388 Epoch: [198/484] Iter:[240/495], Time: 0.38, lr: [0.006218783227109232], Loss: 2.077727, Acc:0.793522, Semantic loss: 0.792286, BCE loss: 0.535177, SB loss: 0.750264
2023-10-30 10:26:37,101 Epoch: [198/484] Iter:[250/495], Time: 0.38, lr: [0.006218387208945662], Loss: 2.077592, Acc:0.793398, Semantic loss: 0.792527, BCE loss: 0.534851, SB loss: 0.750214
2023-10-30 10:26:40,786 Epoch: [198/484] Iter:[260/495], Time: 0.38, lr: [0.006217991187979801], Loss: 2.072561, Acc:0.794000, Semantic loss: 0.787982, BCE loss: 0.535268, SB loss: 0.749310
2023-10-30 10:26:44,439 Epoch: [198/484] Iter:[270/495], Time: 0.38, lr: [0.006217595164211433], Loss: 2.069797, Acc:0.793695, Semantic loss: 0.785837, BCE loss: 0.535759, SB loss: 0.748201
2023-10-30 10:26:48,149 Epoch: [198/484] Iter:[280/495], Time: 0.38, lr: [0.006217199137640338], Loss: 2.074931, Acc:0.792600, Semantic loss: 0.788904, BCE loss: 0.536027, SB loss: 0.749999
2023-10-30 10:26:51,804 Epoch: [198/484] Iter:[290/495], Time: 0.38, lr: [0.0062168031082663], Loss: 2.082588, Acc:0.791877, Semantic loss: 0.793177, BCE loss: 0.537451, SB loss: 0.751960
2023-10-30 10:26:55,499 Epoch: [198/484] Iter:[300/495], Time: 0.37, lr: [0.006216407076089099], Loss: 2.081436, Acc:0.791163, Semantic loss: 0.791873, BCE loss: 0.537078, SB loss: 0.752485
2023-10-30 10:26:59,169 Epoch: [198/484] Iter:[310/495], Time: 0.37, lr: [0.006216011041108518], Loss: 2.083497, Acc:0.791259, Semantic loss: 0.792869, BCE loss: 0.537642, SB loss: 0.752986
2023-10-30 10:27:02,909 Epoch: [198/484] Iter:[320/495], Time: 0.37, lr: [0.006215615003324336], Loss: 2.087135, Acc:0.792388, Semantic loss: 0.795788, BCE loss: 0.536335, SB loss: 0.755012
2023-10-30 10:27:06,587 Epoch: [198/484] Iter:[330/495], Time: 0.37, lr: [0.00621521896273634], Loss: 2.087058, Acc:0.792329, Semantic loss: 0.795199, BCE loss: 0.536389, SB loss: 0.755471
2023-10-30 10:27:10,365 Epoch: [198/484] Iter:[340/495], Time: 0.37, lr: [0.0062148229193443065], Loss: 2.085080, Acc:0.791871, Semantic loss: 0.794419, BCE loss: 0.535315, SB loss: 0.755346
2023-10-30 10:27:14,004 Epoch: [198/484] Iter:[350/495], Time: 0.37, lr: [0.0062144268731480195], Loss: 2.082103, Acc:0.791036, Semantic loss: 0.792279, BCE loss: 0.534693, SB loss: 0.755130
2023-10-30 10:27:17,679 Epoch: [198/484] Iter:[360/495], Time: 0.37, lr: [0.00621403082414726], Loss: 2.082302, Acc:0.790761, Semantic loss: 0.792616, BCE loss: 0.535025, SB loss: 0.754661
2023-10-30 10:27:21,450 Epoch: [198/484] Iter:[370/495], Time: 0.37, lr: [0.006213634772341809], Loss: 2.088994, Acc:0.788881, Semantic loss: 0.796276, BCE loss: 0.533911, SB loss: 0.758806
2023-10-30 10:27:25,067 Epoch: [198/484] Iter:[380/495], Time: 0.37, lr: [0.00621323871773145], Loss: 2.088077, Acc:0.789450, Semantic loss: 0.794940, BCE loss: 0.534078, SB loss: 0.759059
2023-10-30 10:27:28,728 Epoch: [198/484] Iter:[390/495], Time: 0.37, lr: [0.006212842660315961], Loss: 2.093596, Acc:0.788771, Semantic loss: 0.798374, BCE loss: 0.534624, SB loss: 0.760597
2023-10-30 10:27:32,418 Epoch: [198/484] Iter:[400/495], Time: 0.37, lr: [0.006212446600095126], Loss: 2.093757, Acc:0.788323, Semantic loss: 0.798006, BCE loss: 0.534606, SB loss: 0.761145
2023-10-30 10:27:36,097 Epoch: [198/484] Iter:[410/495], Time: 0.37, lr: [0.006212050537068727], Loss: 2.089650, Acc:0.789232, Semantic loss: 0.796022, BCE loss: 0.533415, SB loss: 0.760213
2023-10-30 10:27:39,720 Epoch: [198/484] Iter:[420/495], Time: 0.37, lr: [0.006211654471236544], Loss: 2.094509, Acc:0.789431, Semantic loss: 0.798060, BCE loss: 0.535637, SB loss: 0.760811
2023-10-30 10:27:43,488 Epoch: [198/484] Iter:[430/495], Time: 0.37, lr: [0.006211258402598359], Loss: 2.095570, Acc:0.789842, Semantic loss: 0.797467, BCE loss: 0.537405, SB loss: 0.760698
2023-10-30 10:27:47,236 Epoch: [198/484] Iter:[440/495], Time: 0.37, lr: [0.0062108623311539525], Loss: 2.094261, Acc:0.789984, Semantic loss: 0.796496, BCE loss: 0.537280, SB loss: 0.760485
2023-10-30 10:27:51,031 Epoch: [198/484] Iter:[450/495], Time: 0.37, lr: [0.006210466256903107], Loss: 2.097080, Acc:0.790378, Semantic loss: 0.797214, BCE loss: 0.538617, SB loss: 0.761249
2023-10-30 10:27:54,762 Epoch: [198/484] Iter:[460/495], Time: 0.37, lr: [0.006210070179845601], Loss: 2.098527, Acc:0.790875, Semantic loss: 0.798358, BCE loss: 0.538178, SB loss: 0.761991
2023-10-30 10:27:58,407 Epoch: [198/484] Iter:[470/495], Time: 0.37, lr: [0.006209674099981219], Loss: 2.097295, Acc:0.791423, Semantic loss: 0.796712, BCE loss: 0.538856, SB loss: 0.761727
2023-10-30 10:28:02,097 Epoch: [198/484] Iter:[480/495], Time: 0.37, lr: [0.00620927801730974], Loss: 2.098313, Acc:0.791591, Semantic loss: 0.797479, BCE loss: 0.538848, SB loss: 0.761986
2023-10-30 10:28:05,643 Epoch: [198/484] Iter:[490/495], Time: 0.37, lr: [0.006208881931830946], Loss: 2.097553, Acc:0.791949, Semantic loss: 0.797544, BCE loss: 0.537747, SB loss: 0.762263
2023-10-30 10:28:07,061 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:28:07,302 Loss: 2.140, MeanIU:  0.6310, Best_mIoU:  0.7072
2023-10-30 10:28:07,302 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541]
2023-10-30 10:28:09,666 Epoch: [199/484] Iter:[0/495], Time: 2.33, lr: [0.0062086838880387385], Loss: 2.062764, Acc:0.719364, Semantic loss: 0.814676, BCE loss: 0.416791, SB loss: 0.831297
2023-10-30 10:28:13,724 Epoch: [199/484] Iter:[10/495], Time: 0.58, lr: [0.006208287798348562], Loss: 1.980907, Acc:0.813610, Semantic loss: 0.716943, BCE loss: 0.535816, SB loss: 0.728147
2023-10-30 10:28:17,500 Epoch: [199/484] Iter:[20/495], Time: 0.48, lr: [0.006207891705850524], Loss: 2.038475, Acc:0.796284, Semantic loss: 0.739600, BCE loss: 0.547032, SB loss: 0.751843
2023-10-30 10:28:21,158 Epoch: [199/484] Iter:[30/495], Time: 0.45, lr: [0.006207495610544404], Loss: 2.039510, Acc:0.805030, Semantic loss: 0.743096, BCE loss: 0.546156, SB loss: 0.750258
2023-10-30 10:28:24,976 Epoch: [199/484] Iter:[40/495], Time: 0.43, lr: [0.006207099512429984], Loss: 2.054439, Acc:0.810565, Semantic loss: 0.749095, BCE loss: 0.566140, SB loss: 0.739204
2023-10-30 10:28:28,749 Epoch: [199/484] Iter:[50/495], Time: 0.42, lr: [0.006206703411507043], Loss: 2.088004, Acc:0.811568, Semantic loss: 0.777060, BCE loss: 0.565134, SB loss: 0.745810
2023-10-30 10:28:32,457 Epoch: [199/484] Iter:[60/495], Time: 0.41, lr: [0.006206307307775365], Loss: 2.093536, Acc:0.810257, Semantic loss: 0.787079, BCE loss: 0.559533, SB loss: 0.746924
2023-10-30 10:28:36,224 Epoch: [199/484] Iter:[70/495], Time: 0.41, lr: [0.00620591120123473], Loss: 2.089677, Acc:0.811956, Semantic loss: 0.787032, BCE loss: 0.556099, SB loss: 0.746545
2023-10-30 10:28:39,911 Epoch: [199/484] Iter:[80/495], Time: 0.40, lr: [0.006205515091884918], Loss: 2.091823, Acc:0.809040, Semantic loss: 0.795767, BCE loss: 0.549562, SB loss: 0.746494
2023-10-30 10:28:43,601 Epoch: [199/484] Iter:[90/495], Time: 0.40, lr: [0.00620511897972571], Loss: 2.084605, Acc:0.806982, Semantic loss: 0.789908, BCE loss: 0.546088, SB loss: 0.748609
2023-10-30 10:28:47,297 Epoch: [199/484] Iter:[100/495], Time: 0.40, lr: [0.006204722864756889], Loss: 2.075032, Acc:0.800750, Semantic loss: 0.787449, BCE loss: 0.540300, SB loss: 0.747283
2023-10-30 10:28:50,918 Epoch: [199/484] Iter:[110/495], Time: 0.39, lr: [0.0062043267469782315], Loss: 2.070073, Acc:0.796634, Semantic loss: 0.785710, BCE loss: 0.538406, SB loss: 0.745957
2023-10-30 10:28:54,681 Epoch: [199/484] Iter:[120/495], Time: 0.39, lr: [0.00620393062638952], Loss: 2.068607, Acc:0.798382, Semantic loss: 0.782770, BCE loss: 0.539105, SB loss: 0.746733
2023-10-30 10:28:58,293 Epoch: [199/484] Iter:[130/495], Time: 0.39, lr: [0.006203534502990537], Loss: 2.069524, Acc:0.796253, Semantic loss: 0.781114, BCE loss: 0.539771, SB loss: 0.748640
2023-10-30 10:29:01,957 Epoch: [199/484] Iter:[140/495], Time: 0.39, lr: [0.0062031383767810625], Loss: 2.066111, Acc:0.795698, Semantic loss: 0.781251, BCE loss: 0.536319, SB loss: 0.748541
2023-10-30 10:29:05,654 Epoch: [199/484] Iter:[150/495], Time: 0.39, lr: [0.006202742247760875], Loss: 2.070476, Acc:0.795585, Semantic loss: 0.783104, BCE loss: 0.538848, SB loss: 0.748524
2023-10-30 10:29:09,390 Epoch: [199/484] Iter:[160/495], Time: 0.39, lr: [0.006202346115929759], Loss: 2.055947, Acc:0.795903, Semantic loss: 0.775688, BCE loss: 0.535564, SB loss: 0.744694
2023-10-30 10:29:13,168 Epoch: [199/484] Iter:[170/495], Time: 0.38, lr: [0.006201949981287491], Loss: 2.057088, Acc:0.796009, Semantic loss: 0.776205, BCE loss: 0.536540, SB loss: 0.744344
2023-10-30 10:29:16,844 Epoch: [199/484] Iter:[180/495], Time: 0.38, lr: [0.006201553843833854], Loss: 2.053668, Acc:0.795881, Semantic loss: 0.772396, BCE loss: 0.537198, SB loss: 0.744074
2023-10-30 10:29:20,489 Epoch: [199/484] Iter:[190/495], Time: 0.38, lr: [0.006201157703568628], Loss: 2.051477, Acc:0.795118, Semantic loss: 0.771204, BCE loss: 0.536952, SB loss: 0.743321
2023-10-30 10:29:24,246 Epoch: [199/484] Iter:[200/495], Time: 0.38, lr: [0.006200761560491592], Loss: 2.051140, Acc:0.796875, Semantic loss: 0.770600, BCE loss: 0.536723, SB loss: 0.743818
2023-10-30 10:29:27,952 Epoch: [199/484] Iter:[210/495], Time: 0.38, lr: [0.006200365414602529], Loss: 2.052838, Acc:0.798901, Semantic loss: 0.769093, BCE loss: 0.540912, SB loss: 0.742832
2023-10-30 10:29:31,599 Epoch: [199/484] Iter:[220/495], Time: 0.38, lr: [0.0061999692659012165], Loss: 2.060047, Acc:0.798856, Semantic loss: 0.773440, BCE loss: 0.543657, SB loss: 0.742950
2023-10-30 10:29:35,354 Epoch: [199/484] Iter:[230/495], Time: 0.38, lr: [0.006199573114387438], Loss: 2.054863, Acc:0.797403, Semantic loss: 0.772713, BCE loss: 0.540892, SB loss: 0.741259
2023-10-30 10:29:39,134 Epoch: [199/484] Iter:[240/495], Time: 0.38, lr: [0.006199176960060972], Loss: 2.057982, Acc:0.797149, Semantic loss: 0.775061, BCE loss: 0.540890, SB loss: 0.742031
2023-10-30 10:29:42,788 Epoch: [199/484] Iter:[250/495], Time: 0.38, lr: [0.0061987808029216], Loss: 2.059312, Acc:0.797480, Semantic loss: 0.775254, BCE loss: 0.540431, SB loss: 0.743626
2023-10-30 10:29:46,556 Epoch: [199/484] Iter:[260/495], Time: 0.38, lr: [0.0061983846429691], Loss: 2.055525, Acc:0.796226, Semantic loss: 0.773753, BCE loss: 0.539648, SB loss: 0.742124
2023-10-30 10:29:50,224 Epoch: [199/484] Iter:[270/495], Time: 0.38, lr: [0.0061979884802032545], Loss: 2.054505, Acc:0.796969, Semantic loss: 0.773428, BCE loss: 0.538655, SB loss: 0.742422
2023-10-30 10:29:53,967 Epoch: [199/484] Iter:[280/495], Time: 0.38, lr: [0.006197592314623843], Loss: 2.056420, Acc:0.796322, Semantic loss: 0.773567, BCE loss: 0.540285, SB loss: 0.742569
2023-10-30 10:29:57,732 Epoch: [199/484] Iter:[290/495], Time: 0.38, lr: [0.006197196146230645], Loss: 2.051217, Acc:0.796576, Semantic loss: 0.771250, BCE loss: 0.539459, SB loss: 0.740508
2023-10-30 10:30:01,451 Epoch: [199/484] Iter:[300/495], Time: 0.38, lr: [0.006196799975023441], Loss: 2.051709, Acc:0.796775, Semantic loss: 0.772752, BCE loss: 0.537801, SB loss: 0.741156
2023-10-30 10:30:05,135 Epoch: [199/484] Iter:[310/495], Time: 0.38, lr: [0.006196403801002012], Loss: 2.049238, Acc:0.795865, Semantic loss: 0.772911, BCE loss: 0.535418, SB loss: 0.740909
2023-10-30 10:30:08,719 Epoch: [199/484] Iter:[320/495], Time: 0.38, lr: [0.006196007624166138], Loss: 2.047067, Acc:0.796936, Semantic loss: 0.771612, BCE loss: 0.534000, SB loss: 0.741455
2023-10-30 10:30:12,410 Epoch: [199/484] Iter:[330/495], Time: 0.38, lr: [0.006195611444515597], Loss: 2.042112, Acc:0.796754, Semantic loss: 0.769308, BCE loss: 0.532627, SB loss: 0.740177
2023-10-30 10:30:16,098 Epoch: [199/484] Iter:[340/495], Time: 0.38, lr: [0.006195215262050172], Loss: 2.042610, Acc:0.796802, Semantic loss: 0.769465, BCE loss: 0.532383, SB loss: 0.740763
2023-10-30 10:30:19,819 Epoch: [199/484] Iter:[350/495], Time: 0.38, lr: [0.006194819076769643], Loss: 2.039343, Acc:0.796882, Semantic loss: 0.767488, BCE loss: 0.531621, SB loss: 0.740234
2023-10-30 10:30:23,450 Epoch: [199/484] Iter:[360/495], Time: 0.38, lr: [0.0061944228886737845], Loss: 2.038098, Acc:0.796278, Semantic loss: 0.767892, BCE loss: 0.530076, SB loss: 0.740130
2023-10-30 10:30:27,154 Epoch: [199/484] Iter:[370/495], Time: 0.38, lr: [0.006194026697762382], Loss: 2.037990, Acc:0.795654, Semantic loss: 0.768524, BCE loss: 0.530119, SB loss: 0.739348
2023-10-30 10:30:30,969 Epoch: [199/484] Iter:[380/495], Time: 0.38, lr: [0.006193630504035214], Loss: 2.035176, Acc:0.796422, Semantic loss: 0.767245, BCE loss: 0.529569, SB loss: 0.738362
2023-10-30 10:30:34,720 Epoch: [199/484] Iter:[390/495], Time: 0.38, lr: [0.006193234307492059], Loss: 2.036515, Acc:0.797761, Semantic loss: 0.767353, BCE loss: 0.530700, SB loss: 0.738463
2023-10-30 10:30:38,535 Epoch: [199/484] Iter:[400/495], Time: 0.38, lr: [0.0061928381081327], Loss: 2.038485, Acc:0.797641, Semantic loss: 0.768617, BCE loss: 0.530861, SB loss: 0.739007
2023-10-30 10:30:42,264 Epoch: [199/484] Iter:[410/495], Time: 0.38, lr: [0.006192441905956914], Loss: 2.035785, Acc:0.796652, Semantic loss: 0.767942, BCE loss: 0.529931, SB loss: 0.737912
2023-10-30 10:30:45,881 Epoch: [199/484] Iter:[420/495], Time: 0.38, lr: [0.006192045700964481], Loss: 2.035940, Acc:0.796501, Semantic loss: 0.769206, BCE loss: 0.529044, SB loss: 0.737690
2023-10-30 10:30:49,543 Epoch: [199/484] Iter:[430/495], Time: 0.38, lr: [0.006191649493155181], Loss: 2.032789, Acc:0.796288, Semantic loss: 0.767160, BCE loss: 0.528071, SB loss: 0.737559
2023-10-30 10:30:53,290 Epoch: [199/484] Iter:[440/495], Time: 0.38, lr: [0.006191253282528794], Loss: 2.032511, Acc:0.796461, Semantic loss: 0.767139, BCE loss: 0.528298, SB loss: 0.737073
2023-10-30 10:30:57,001 Epoch: [199/484] Iter:[450/495], Time: 0.38, lr: [0.0061908570690851], Loss: 2.031486, Acc:0.795932, Semantic loss: 0.767299, BCE loss: 0.526825, SB loss: 0.737363
2023-10-30 10:31:00,752 Epoch: [199/484] Iter:[460/495], Time: 0.38, lr: [0.006190460852823877], Loss: 2.032618, Acc:0.796325, Semantic loss: 0.767254, BCE loss: 0.527687, SB loss: 0.737677
2023-10-30 10:31:04,445 Epoch: [199/484] Iter:[470/495], Time: 0.38, lr: [0.006190064633744908], Loss: 2.033739, Acc:0.796527, Semantic loss: 0.768001, BCE loss: 0.528015, SB loss: 0.737723
2023-10-30 10:31:08,200 Epoch: [199/484] Iter:[480/495], Time: 0.38, lr: [0.006189668411847969], Loss: 2.034868, Acc:0.796415, Semantic loss: 0.768611, BCE loss: 0.528097, SB loss: 0.738160
2023-10-30 10:31:11,693 Epoch: [199/484] Iter:[490/495], Time: 0.38, lr: [0.0061892721871328405], Loss: 2.036409, Acc:0.797347, Semantic loss: 0.769572, BCE loss: 0.528694, SB loss: 0.738143
2023-10-30 10:31:13,095 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:31:13,330 Loss: 2.140, MeanIU:  0.6310, Best_mIoU:  0.7072
2023-10-30 10:31:13,330 [0.96892157 0.77654469 0.89942326 0.46644777 0.53915847 0.55479434
 0.64862633 0.72600518 0.90674552 0.52990268 0.92890567 0.76754933
 0.54808415 0.91131851 0.4295291  0.04213136 0.17601482 0.44140677
 0.72826541]
2023-10-30 10:31:15,512 Epoch: [200/484] Iter:[0/495], Time: 2.15, lr: [0.0061890740737183874], Loss: 2.515622, Acc:0.903857, Semantic loss: 0.915705, BCE loss: 0.745206, SB loss: 0.854711
2023-10-30 10:31:19,590 Epoch: [200/484] Iter:[10/495], Time: 0.57, lr: [0.006188677844775561], Loss: 2.243362, Acc:0.811015, Semantic loss: 0.885763, BCE loss: 0.594303, SB loss: 0.763297
2023-10-30 10:31:23,270 Epoch: [200/484] Iter:[20/495], Time: 0.47, lr: [0.006188281613013995], Loss: 2.163618, Acc:0.804260, Semantic loss: 0.840027, BCE loss: 0.571634, SB loss: 0.751956
2023-10-30 10:31:26,979 Epoch: [200/484] Iter:[30/495], Time: 0.44, lr: [0.0061878853784334675], Loss: 2.094059, Acc:0.800558, Semantic loss: 0.806328, BCE loss: 0.547460, SB loss: 0.740271
2023-10-30 10:31:30,712 Epoch: [200/484] Iter:[40/495], Time: 0.42, lr: [0.0061874891410337585], Loss: 2.077480, Acc:0.803362, Semantic loss: 0.794474, BCE loss: 0.545249, SB loss: 0.737757
2023-10-30 10:31:34,357 Epoch: [200/484] Iter:[50/495], Time: 0.41, lr: [0.006187092900814647], Loss: 2.049210, Acc:0.801440, Semantic loss: 0.774594, BCE loss: 0.538995, SB loss: 0.735621
2023-10-30 10:31:38,112 Epoch: [200/484] Iter:[60/495], Time: 0.41, lr: [0.006186696657775913], Loss: 2.043974, Acc:0.800802, Semantic loss: 0.769095, BCE loss: 0.537085, SB loss: 0.737794
2023-10-30 10:31:41,810 Epoch: [200/484] Iter:[70/495], Time: 0.40, lr: [0.006186300411917336], Loss: 2.045430, Acc:0.801128, Semantic loss: 0.769739, BCE loss: 0.539659, SB loss: 0.736032
2023-10-30 10:31:45,530 Epoch: [200/484] Iter:[80/495], Time: 0.40, lr: [0.006185904163238693], Loss: 2.024756, Acc:0.801196, Semantic loss: 0.761754, BCE loss: 0.528522, SB loss: 0.734480
2023-10-30 10:31:49,217 Epoch: [200/484] Iter:[90/495], Time: 0.39, lr: [0.006185507911739766], Loss: 2.027115, Acc:0.800682, Semantic loss: 0.766137, BCE loss: 0.526367, SB loss: 0.734611
2023-10-30 10:31:52,922 Epoch: [200/484] Iter:[100/495], Time: 0.39, lr: [0.006185111657420332], Loss: 2.021316, Acc:0.800317, Semantic loss: 0.764715, BCE loss: 0.522123, SB loss: 0.734477
2023-10-30 10:31:56,674 Epoch: [200/484] Iter:[110/495], Time: 0.39, lr: [0.0061847154002801705], Loss: 2.025920, Acc:0.800182, Semantic loss: 0.762890, BCE loss: 0.525882, SB loss: 0.737149
2023-10-30 10:32:00,354 Epoch: [200/484] Iter:[120/495], Time: 0.39, lr: [0.006184319140319062], Loss: 2.032045, Acc:0.802640, Semantic loss: 0.766067, BCE loss: 0.527327, SB loss: 0.738651
2023-10-30 10:32:04,019 Epoch: [200/484] Iter:[130/495], Time: 0.39, lr: [0.006183922877536784], Loss: 2.038649, Acc:0.800892, Semantic loss: 0.771605, BCE loss: 0.526956, SB loss: 0.740088
2023-10-30 10:32:07,718 Epoch: [200/484] Iter:[140/495], Time: 0.39, lr: [0.006183526611933116], Loss: 2.034812, Acc:0.801565, Semantic loss: 0.768582, BCE loss: 0.526268, SB loss: 0.739961
2023-10-30 10:32:11,513 Epoch: [200/484] Iter:[150/495], Time: 0.39, lr: [0.006183130343507838], Loss: 2.041574, Acc:0.802356, Semantic loss: 0.773882, BCE loss: 0.525600, SB loss: 0.742092
2023-10-30 10:32:15,193 Epoch: [200/484] Iter:[160/495], Time: 0.38, lr: [0.006182734072260728], Loss: 2.061740, Acc:0.800103, Semantic loss: 0.783418, BCE loss: 0.528880, SB loss: 0.749442
2023-10-30 10:32:18,922 Epoch: [200/484] Iter:[170/495], Time: 0.38, lr: [0.006182337798191566], Loss: 2.054026, Acc:0.800685, Semantic loss: 0.777288, BCE loss: 0.529343, SB loss: 0.747395
2023-10-30 10:32:22,652 Epoch: [200/484] Iter:[180/495], Time: 0.38, lr: [0.006181941521300129], Loss: 2.046979, Acc:0.798966, Semantic loss: 0.774060, BCE loss: 0.527349, SB loss: 0.745569
2023-10-30 10:32:26,425 Epoch: [200/484] Iter:[190/495], Time: 0.38, lr: [0.006181545241586197], Loss: 2.056504, Acc:0.799097, Semantic loss: 0.777516, BCE loss: 0.531041, SB loss: 0.747947
2023-10-30 10:32:30,187 Epoch: [200/484] Iter:[200/495], Time: 0.38, lr: [0.006181148959049548], Loss: 2.057164, Acc:0.801197, Semantic loss: 0.776153, BCE loss: 0.534114, SB loss: 0.746896
2023-10-30 10:32:34,052 Epoch: [200/484] Iter:[210/495], Time: 0.38, lr: [0.0061807526736899635], Loss: 2.059070, Acc:0.803119, Semantic loss: 0.775675, BCE loss: 0.536278, SB loss: 0.747117
2023-10-30 10:32:37,791 Epoch: [200/484] Iter:[220/495], Time: 0.38, lr: [0.006180356385507219], Loss: 2.053165, Acc:0.802454, Semantic loss: 0.773464, BCE loss: 0.533776, SB loss: 0.745925
2023-10-30 10:32:41,537 Epoch: [200/484] Iter:[230/495], Time: 0.38, lr: [0.006179960094501096], Loss: 2.050210, Acc:0.802425, Semantic loss: 0.772348, BCE loss: 0.532330, SB loss: 0.745531
2023-10-30 10:32:45,282 Epoch: [200/484] Iter:[240/495], Time: 0.38, lr: [0.00617956380067137], Loss: 2.051317, Acc:0.802588, Semantic loss: 0.772076, BCE loss: 0.533478, SB loss: 0.745763
2023-10-30 10:32:48,890 Epoch: [200/484] Iter:[250/495], Time: 0.38, lr: [0.006179167504017824], Loss: 2.052810, Acc:0.801666, Semantic loss: 0.773599, BCE loss: 0.534922, SB loss: 0.744290
2023-10-30 10:32:52,532 Epoch: [200/484] Iter:[260/495], Time: 0.38, lr: [0.006178771204540232], Loss: 2.053228, Acc:0.800025, Semantic loss: 0.773799, BCE loss: 0.533923, SB loss: 0.745505
2023-10-30 10:32:56,335 Epoch: [200/484] Iter:[270/495], Time: 0.38, lr: [0.006178374902238376], Loss: 2.048764, Acc:0.799967, Semantic loss: 0.772519, BCE loss: 0.531746, SB loss: 0.744499
2023-10-30 10:33:00,060 Epoch: [200/484] Iter:[280/495], Time: 0.38, lr: [0.0061779785971120315], Loss: 2.050387, Acc:0.800341, Semantic loss: 0.774789, BCE loss: 0.530961, SB loss: 0.744637
2023-10-30 10:33:03,802 Epoch: [200/484] Iter:[290/495], Time: 0.38, lr: [0.006177582289160981], Loss: 2.053219, Acc:0.800657, Semantic loss: 0.774709, BCE loss: 0.532555, SB loss: 0.745956
2023-10-30 10:33:07,627 Epoch: [200/484] Iter:[300/495], Time: 0.38, lr: [0.006177185978385001], Loss: 2.052437, Acc:0.800330, Semantic loss: 0.774452, BCE loss: 0.531677, SB loss: 0.746308
2023-10-30 10:33:11,230 Epoch: [200/484] Iter:[310/495], Time: 0.38, lr: [0.00617678966478387], Loss: 2.055073, Acc:0.799579, Semantic loss: 0.775090, BCE loss: 0.533582, SB loss: 0.746400
2023-10-30 10:33:14,983 Epoch: [200/484] Iter:[320/495], Time: 0.38, lr: [0.006176393348357365], Loss: 2.054901, Acc:0.800188, Semantic loss: 0.775230, BCE loss: 0.533527, SB loss: 0.746144
2023-10-30 10:33:18,690 Epoch: [200/484] Iter:[330/495], Time: 0.38, lr: [0.006175997029105267], Loss: 2.061623, Acc:0.799118, Semantic loss: 0.780183, BCE loss: 0.532783, SB loss: 0.748657
2023-10-30 10:33:22,370 Epoch: [200/484] Iter:[340/495], Time: 0.38, lr: [0.006175600707027352], Loss: 2.066460, Acc:0.799190, Semantic loss: 0.781343, BCE loss: 0.536086, SB loss: 0.749031
2023-10-30 10:33:26,109 Epoch: [200/484] Iter:[350/495], Time: 0.38, lr: [0.006175204382123401], Loss: 2.062339, Acc:0.799325, Semantic loss: 0.779701, BCE loss: 0.534083, SB loss: 0.748554
2023-10-30 10:33:29,764 Epoch: [200/484] Iter:[360/495], Time: 0.38, lr: [0.006174808054393189], Loss: 2.058646, Acc:0.799132, Semantic loss: 0.777781, BCE loss: 0.533207, SB loss: 0.747658
2023-10-30 10:33:33,497 Epoch: [200/484] Iter:[370/495], Time: 0.38, lr: [0.006174411723836498], Loss: 2.060267, Acc:0.798934, Semantic loss: 0.779204, BCE loss: 0.532969, SB loss: 0.748094
2023-10-30 10:33:37,124 Epoch: [200/484] Iter:[380/495], Time: 0.38, lr: [0.006174015390453105], Loss: 2.061765, Acc:0.798615, Semantic loss: 0.779472, BCE loss: 0.533383, SB loss: 0.748911
2023-10-30 10:33:40,861 Epoch: [200/484] Iter:[390/495], Time: 0.38, lr: [0.0061736190542427865], Loss: 2.061171, Acc:0.797517, Semantic loss: 0.779944, BCE loss: 0.531594, SB loss: 0.749633
2023-10-30 10:33:44,570 Epoch: [200/484] Iter:[400/495], Time: 0.38, lr: [0.006173222715205322], Loss: 2.061681, Acc:0.798003, Semantic loss: 0.780164, BCE loss: 0.531837, SB loss: 0.749681
2023-10-30 10:33:48,266 Epoch: [200/484] Iter:[410/495], Time: 0.38, lr: [0.006172826373340489], Loss: 2.066756, Acc:0.797771, Semantic loss: 0.784336, BCE loss: 0.530853, SB loss: 0.751566
2023-10-30 10:33:51,964 Epoch: [200/484] Iter:[420/495], Time: 0.38, lr: [0.006172430028648066], Loss: 2.069249, Acc:0.797319, Semantic loss: 0.786218, BCE loss: 0.530472, SB loss: 0.752560
2023-10-30 10:33:55,791 Epoch: [200/484] Iter:[430/495], Time: 0.38, lr: [0.006172033681127831], Loss: 2.066120, Acc:0.797284, Semantic loss: 0.784144, BCE loss: 0.530047, SB loss: 0.751929
2023-10-30 10:33:59,547 Epoch: [200/484] Iter:[440/495], Time: 0.38, lr: [0.006171637330779562], Loss: 2.065275, Acc:0.797723, Semantic loss: 0.783825, BCE loss: 0.530101, SB loss: 0.751349
2023-10-30 10:34:03,226 Epoch: [200/484] Iter:[450/495], Time: 0.38, lr: [0.006171240977603039], Loss: 2.062634, Acc:0.797218, Semantic loss: 0.782086, BCE loss: 0.529799, SB loss: 0.750749
2023-10-30 10:34:07,046 Epoch: [200/484] Iter:[460/495], Time: 0.38, lr: [0.006170844621598038], Loss: 2.064109, Acc:0.797187, Semantic loss: 0.782847, BCE loss: 0.529919, SB loss: 0.751344
2023-10-30 10:34:10,757 Epoch: [200/484] Iter:[470/495], Time: 0.38, lr: [0.006170448262764336], Loss: 2.064642, Acc:0.796733, Semantic loss: 0.782534, BCE loss: 0.530262, SB loss: 0.751846
2023-10-30 10:34:14,347 Epoch: [200/484] Iter:[480/495], Time: 0.38, lr: [0.006170051901101712], Loss: 2.065837, Acc:0.797137, Semantic loss: 0.782205, BCE loss: 0.531072, SB loss: 0.752560
2023-10-30 10:34:17,918 Epoch: [200/484] Iter:[490/495], Time: 0.38, lr: [0.0061696555366099436], Loss: 2.066577, Acc:0.796379, Semantic loss: 0.782866, BCE loss: 0.530823, SB loss: 0.752888
2023-10-30 10:37:14,282 0 [9.23323327e-01 5.62583911e-01 8.12819063e-01 7.19189525e-02
 2.57760336e-01 3.86867982e-01 3.64719670e-01 5.76998565e-01
 8.59973953e-01 4.18094777e-01 8.77271750e-01 4.02999197e-01
 7.49683467e-04 7.85392229e-01 1.62828364e-03 1.31781901e-01
 6.59622725e-02 7.86000175e-03 4.90637501e-01] 0.42101807145462056
2023-10-30 10:37:14,283 1 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ] 0.6537482741535316
2023-10-30 10:37:14,286 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:37:14,524 Loss: 2.141, MeanIU:  0.6537, Best_mIoU:  0.7072
2023-10-30 10:37:14,524 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ]
2023-10-30 10:37:16,651 Epoch: [201/484] Iter:[0/495], Time: 2.10, lr: [0.006169457353303062], Loss: 1.673263, Acc:0.761536, Semantic loss: 0.542930, BCE loss: 0.520399, SB loss: 0.609935
2023-10-30 10:37:20,456 Epoch: [201/484] Iter:[10/495], Time: 0.54, lr: [0.006169060984567162], Loss: 2.075027, Acc:0.819715, Semantic loss: 0.766611, BCE loss: 0.578513, SB loss: 0.729904
2023-10-30 10:37:24,053 Epoch: [201/484] Iter:[20/495], Time: 0.45, lr: [0.006168664613001561], Loss: 2.043615, Acc:0.816062, Semantic loss: 0.729841, BCE loss: 0.595501, SB loss: 0.718273
2023-10-30 10:37:27,663 Epoch: [201/484] Iter:[30/495], Time: 0.42, lr: [0.0061682682386060405], Loss: 2.035155, Acc:0.819459, Semantic loss: 0.740106, BCE loss: 0.564491, SB loss: 0.730558
2023-10-30 10:37:31,212 Epoch: [201/484] Iter:[40/495], Time: 0.41, lr: [0.006167871861380375], Loss: 2.016607, Acc:0.827399, Semantic loss: 0.740642, BCE loss: 0.544401, SB loss: 0.731564
2023-10-30 10:37:34,807 Epoch: [201/484] Iter:[50/495], Time: 0.40, lr: [0.006167475481324344], Loss: 2.000375, Acc:0.820763, Semantic loss: 0.739330, BCE loss: 0.529347, SB loss: 0.731699
2023-10-30 10:37:38,272 Epoch: [201/484] Iter:[60/495], Time: 0.39, lr: [0.006167079098437725], Loss: 2.013253, Acc:0.813210, Semantic loss: 0.752492, BCE loss: 0.524840, SB loss: 0.735920
2023-10-30 10:37:41,832 Epoch: [201/484] Iter:[70/495], Time: 0.38, lr: [0.006166682712720294], Loss: 2.020353, Acc:0.813518, Semantic loss: 0.755606, BCE loss: 0.526922, SB loss: 0.737825
2023-10-30 10:37:45,406 Epoch: [201/484] Iter:[80/495], Time: 0.38, lr: [0.006166286324171828], Loss: 2.019864, Acc:0.813286, Semantic loss: 0.757634, BCE loss: 0.528393, SB loss: 0.733837
2023-10-30 10:37:48,912 Epoch: [201/484] Iter:[90/495], Time: 0.38, lr: [0.006165889932792109], Loss: 2.027680, Acc:0.810097, Semantic loss: 0.765094, BCE loss: 0.525500, SB loss: 0.737086
2023-10-30 10:37:52,486 Epoch: [201/484] Iter:[100/495], Time: 0.38, lr: [0.00616549353858091], Loss: 2.020301, Acc:0.805717, Semantic loss: 0.764903, BCE loss: 0.517845, SB loss: 0.737553
2023-10-30 10:37:56,048 Epoch: [201/484] Iter:[110/495], Time: 0.37, lr: [0.006165097141538011], Loss: 2.005782, Acc:0.809541, Semantic loss: 0.754896, BCE loss: 0.517728, SB loss: 0.733159
2023-10-30 10:37:59,651 Epoch: [201/484] Iter:[120/495], Time: 0.37, lr: [0.006164700741663189], Loss: 2.015519, Acc:0.809704, Semantic loss: 0.764403, BCE loss: 0.519560, SB loss: 0.731556
2023-10-30 10:38:03,250 Epoch: [201/484] Iter:[130/495], Time: 0.37, lr: [0.0061643043389562205], Loss: 2.022021, Acc:0.806110, Semantic loss: 0.766321, BCE loss: 0.520529, SB loss: 0.735171
2023-10-30 10:38:06,808 Epoch: [201/484] Iter:[140/495], Time: 0.37, lr: [0.006163907933416884], Loss: 2.021494, Acc:0.805875, Semantic loss: 0.762005, BCE loss: 0.524102, SB loss: 0.735387
2023-10-30 10:38:10,426 Epoch: [201/484] Iter:[150/495], Time: 0.37, lr: [0.006163511525044955], Loss: 2.024607, Acc:0.805594, Semantic loss: 0.762907, BCE loss: 0.525303, SB loss: 0.736397
2023-10-30 10:38:14,106 Epoch: [201/484] Iter:[160/495], Time: 0.37, lr: [0.006163115113840214], Loss: 2.014032, Acc:0.805424, Semantic loss: 0.756863, BCE loss: 0.522826, SB loss: 0.734343
2023-10-30 10:38:17,888 Epoch: [201/484] Iter:[170/495], Time: 0.37, lr: [0.006162718699802437], Loss: 2.011638, Acc:0.805311, Semantic loss: 0.755434, BCE loss: 0.521020, SB loss: 0.735184
2023-10-30 10:38:21,515 Epoch: [201/484] Iter:[180/495], Time: 0.37, lr: [0.006162322282931399], Loss: 2.026878, Acc:0.803101, Semantic loss: 0.764248, BCE loss: 0.524833, SB loss: 0.737797
2023-10-30 10:38:25,256 Epoch: [201/484] Iter:[190/495], Time: 0.37, lr: [0.00616192586322688], Loss: 2.026083, Acc:0.801670, Semantic loss: 0.765006, BCE loss: 0.522480, SB loss: 0.738597
2023-10-30 10:38:28,972 Epoch: [201/484] Iter:[200/495], Time: 0.37, lr: [0.006161529440688657], Loss: 2.025428, Acc:0.800822, Semantic loss: 0.762922, BCE loss: 0.523344, SB loss: 0.739161
2023-10-30 10:38:32,557 Epoch: [201/484] Iter:[210/495], Time: 0.37, lr: [0.006161133015316506], Loss: 2.026208, Acc:0.801023, Semantic loss: 0.761725, BCE loss: 0.524511, SB loss: 0.739971
2023-10-30 10:38:36,362 Epoch: [201/484] Iter:[220/495], Time: 0.37, lr: [0.006160736587110205], Loss: 2.028553, Acc:0.800329, Semantic loss: 0.764923, BCE loss: 0.524733, SB loss: 0.738896
2023-10-30 10:38:39,984 Epoch: [201/484] Iter:[230/495], Time: 0.37, lr: [0.006160340156069529], Loss: 2.025681, Acc:0.798843, Semantic loss: 0.765122, BCE loss: 0.522693, SB loss: 0.737867
2023-10-30 10:38:43,649 Epoch: [201/484] Iter:[240/495], Time: 0.37, lr: [0.006159943722194258], Loss: 2.033439, Acc:0.800465, Semantic loss: 0.767179, BCE loss: 0.526867, SB loss: 0.739394
2023-10-30 10:38:47,247 Epoch: [201/484] Iter:[250/495], Time: 0.37, lr: [0.006159547285484167], Loss: 2.041514, Acc:0.799207, Semantic loss: 0.771925, BCE loss: 0.527884, SB loss: 0.741705
2023-10-30 10:38:50,959 Epoch: [201/484] Iter:[260/495], Time: 0.37, lr: [0.0061591508459390345], Loss: 2.043427, Acc:0.798587, Semantic loss: 0.771852, BCE loss: 0.530869, SB loss: 0.740706
2023-10-30 10:38:54,684 Epoch: [201/484] Iter:[270/495], Time: 0.37, lr: [0.006158754403558638], Loss: 2.041423, Acc:0.799288, Semantic loss: 0.771189, BCE loss: 0.530670, SB loss: 0.739564
2023-10-30 10:38:58,335 Epoch: [201/484] Iter:[280/495], Time: 0.37, lr: [0.00615835795834275], Loss: 2.045296, Acc:0.800494, Semantic loss: 0.770840, BCE loss: 0.534175, SB loss: 0.740280
2023-10-30 10:39:02,087 Epoch: [201/484] Iter:[290/495], Time: 0.37, lr: [0.006157961510291153], Loss: 2.043701, Acc:0.800565, Semantic loss: 0.768960, BCE loss: 0.534334, SB loss: 0.740406
2023-10-30 10:39:05,780 Epoch: [201/484] Iter:[300/495], Time: 0.37, lr: [0.006157565059403623], Loss: 2.040410, Acc:0.800638, Semantic loss: 0.767399, BCE loss: 0.533673, SB loss: 0.739339
2023-10-30 10:39:09,384 Epoch: [201/484] Iter:[310/495], Time: 0.37, lr: [0.006157168605679932], Loss: 2.039544, Acc:0.800622, Semantic loss: 0.767714, BCE loss: 0.532520, SB loss: 0.739310
2023-10-30 10:39:13,086 Epoch: [201/484] Iter:[320/495], Time: 0.37, lr: [0.006156772149119861], Loss: 2.041493, Acc:0.801490, Semantic loss: 0.765895, BCE loss: 0.536022, SB loss: 0.739575
2023-10-30 10:39:16,872 Epoch: [201/484] Iter:[330/495], Time: 0.37, lr: [0.006156375689723185], Loss: 2.045625, Acc:0.801525, Semantic loss: 0.767894, BCE loss: 0.537837, SB loss: 0.739894
2023-10-30 10:39:20,585 Epoch: [201/484] Iter:[340/495], Time: 0.37, lr: [0.006155979227489683], Loss: 2.045264, Acc:0.802110, Semantic loss: 0.767419, BCE loss: 0.537914, SB loss: 0.739930
2023-10-30 10:39:24,223 Epoch: [201/484] Iter:[350/495], Time: 0.37, lr: [0.006155582762419131], Loss: 2.041179, Acc:0.801621, Semantic loss: 0.765441, BCE loss: 0.536510, SB loss: 0.739228
2023-10-30 10:39:27,810 Epoch: [201/484] Iter:[360/495], Time: 0.37, lr: [0.006155186294511303], Loss: 2.040345, Acc:0.801323, Semantic loss: 0.763958, BCE loss: 0.538194, SB loss: 0.738193
2023-10-30 10:39:31,500 Epoch: [201/484] Iter:[370/495], Time: 0.37, lr: [0.00615478982376598], Loss: 2.038119, Acc:0.802049, Semantic loss: 0.762943, BCE loss: 0.537694, SB loss: 0.737482
2023-10-30 10:39:35,096 Epoch: [201/484] Iter:[380/495], Time: 0.37, lr: [0.006154393350182934], Loss: 2.036636, Acc:0.802033, Semantic loss: 0.762621, BCE loss: 0.537189, SB loss: 0.736826
2023-10-30 10:39:38,853 Epoch: [201/484] Iter:[390/495], Time: 0.37, lr: [0.006153996873761943], Loss: 2.034629, Acc:0.802310, Semantic loss: 0.761623, BCE loss: 0.536598, SB loss: 0.736408
2023-10-30 10:39:42,576 Epoch: [201/484] Iter:[400/495], Time: 0.37, lr: [0.006153600394502787], Loss: 2.034468, Acc:0.801237, Semantic loss: 0.763055, BCE loss: 0.535226, SB loss: 0.736187
2023-10-30 10:39:46,206 Epoch: [201/484] Iter:[410/495], Time: 0.37, lr: [0.006153203912405238], Loss: 2.037780, Acc:0.801869, Semantic loss: 0.763876, BCE loss: 0.536797, SB loss: 0.737108
2023-10-30 10:39:49,913 Epoch: [201/484] Iter:[420/495], Time: 0.37, lr: [0.006152807427469075], Loss: 2.035682, Acc:0.801740, Semantic loss: 0.763931, BCE loss: 0.535161, SB loss: 0.736590
2023-10-30 10:39:53,573 Epoch: [201/484] Iter:[430/495], Time: 0.37, lr: [0.006152410939694073], Loss: 2.036379, Acc:0.801616, Semantic loss: 0.764645, BCE loss: 0.535413, SB loss: 0.736321
2023-10-30 10:39:57,209 Epoch: [201/484] Iter:[440/495], Time: 0.37, lr: [0.00615201444908001], Loss: 2.041520, Acc:0.801306, Semantic loss: 0.768146, BCE loss: 0.535668, SB loss: 0.737705
2023-10-30 10:40:00,923 Epoch: [201/484] Iter:[450/495], Time: 0.37, lr: [0.00615161795562666], Loss: 2.042201, Acc:0.801107, Semantic loss: 0.768075, BCE loss: 0.535814, SB loss: 0.738312
2023-10-30 10:40:04,648 Epoch: [201/484] Iter:[460/495], Time: 0.37, lr: [0.006151221459333802], Loss: 2.045706, Acc:0.800738, Semantic loss: 0.770934, BCE loss: 0.535991, SB loss: 0.738781
2023-10-30 10:40:08,318 Epoch: [201/484] Iter:[470/495], Time: 0.37, lr: [0.00615082496020121], Loss: 2.042389, Acc:0.799396, Semantic loss: 0.769908, BCE loss: 0.534066, SB loss: 0.738416
2023-10-30 10:40:12,003 Epoch: [201/484] Iter:[480/495], Time: 0.37, lr: [0.006150428458228663], Loss: 2.044743, Acc:0.799660, Semantic loss: 0.771388, BCE loss: 0.534224, SB loss: 0.739131
2023-10-30 10:40:15,480 Epoch: [201/484] Iter:[490/495], Time: 0.37, lr: [0.006150031953415933], Loss: 2.044911, Acc:0.799630, Semantic loss: 0.771281, BCE loss: 0.534225, SB loss: 0.739405
2023-10-30 10:40:16,883 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:40:17,120 Loss: 2.141, MeanIU:  0.6537, Best_mIoU:  0.7072
2023-10-30 10:40:17,121 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ]
2023-10-30 10:40:19,218 Epoch: [202/484] Iter:[0/495], Time: 2.06, lr: [0.006149833699944432], Loss: 1.966453, Acc:0.773333, Semantic loss: 0.781420, BCE loss: 0.415989, SB loss: 0.769044
2023-10-30 10:40:23,212 Epoch: [202/484] Iter:[10/495], Time: 0.55, lr: [0.006149437190871013], Loss: 2.038916, Acc:0.789305, Semantic loss: 0.765875, BCE loss: 0.548825, SB loss: 0.724215
2023-10-30 10:40:26,986 Epoch: [202/484] Iter:[20/495], Time: 0.47, lr: [0.006149040678956854], Loss: 2.004364, Acc:0.782233, Semantic loss: 0.746768, BCE loss: 0.545603, SB loss: 0.711992
2023-10-30 10:40:30,646 Epoch: [202/484] Iter:[30/495], Time: 0.44, lr: [0.006148644164201732], Loss: 2.091763, Acc:0.783080, Semantic loss: 0.791209, BCE loss: 0.557475, SB loss: 0.743078
2023-10-30 10:40:34,355 Epoch: [202/484] Iter:[40/495], Time: 0.42, lr: [0.006148247646605422], Loss: 2.083964, Acc:0.775771, Semantic loss: 0.787261, BCE loss: 0.554118, SB loss: 0.742585
2023-10-30 10:40:38,024 Epoch: [202/484] Iter:[50/495], Time: 0.41, lr: [0.006147851126167698], Loss: 2.070948, Acc:0.772408, Semantic loss: 0.780899, BCE loss: 0.551321, SB loss: 0.738728
2023-10-30 10:40:41,716 Epoch: [202/484] Iter:[60/495], Time: 0.40, lr: [0.00614745460288834], Loss: 2.065126, Acc:0.778086, Semantic loss: 0.783498, BCE loss: 0.538769, SB loss: 0.742859
2023-10-30 10:40:45,467 Epoch: [202/484] Iter:[70/495], Time: 0.40, lr: [0.006147058076767122], Loss: 2.065153, Acc:0.779784, Semantic loss: 0.785761, BCE loss: 0.537867, SB loss: 0.741525
2023-10-30 10:40:49,192 Epoch: [202/484] Iter:[80/495], Time: 0.40, lr: [0.00614666154780382], Loss: 2.071514, Acc:0.782341, Semantic loss: 0.788751, BCE loss: 0.538313, SB loss: 0.744451
2023-10-30 10:40:52,833 Epoch: [202/484] Iter:[90/495], Time: 0.39, lr: [0.00614626501599821], Loss: 2.056421, Acc:0.780806, Semantic loss: 0.778654, BCE loss: 0.534892, SB loss: 0.742876
2023-10-30 10:40:56,587 Epoch: [202/484] Iter:[100/495], Time: 0.39, lr: [0.006145868481350069], Loss: 2.035988, Acc:0.784186, Semantic loss: 0.769765, BCE loss: 0.527751, SB loss: 0.738473
2023-10-30 10:41:00,198 Epoch: [202/484] Iter:[110/495], Time: 0.39, lr: [0.006145471943859171], Loss: 2.044351, Acc:0.784270, Semantic loss: 0.772191, BCE loss: 0.531206, SB loss: 0.740954
2023-10-30 10:41:03,889 Epoch: [202/484] Iter:[120/495], Time: 0.39, lr: [0.006145075403525292], Loss: 2.039413, Acc:0.784202, Semantic loss: 0.769359, BCE loss: 0.529970, SB loss: 0.740084
2023-10-30 10:41:07,602 Epoch: [202/484] Iter:[130/495], Time: 0.39, lr: [0.006144678860348208], Loss: 2.040775, Acc:0.786093, Semantic loss: 0.767160, BCE loss: 0.534479, SB loss: 0.739136
2023-10-30 10:41:11,201 Epoch: [202/484] Iter:[140/495], Time: 0.38, lr: [0.006144282314327696], Loss: 2.038863, Acc:0.785927, Semantic loss: 0.768747, BCE loss: 0.531957, SB loss: 0.738159
2023-10-30 10:41:14,925 Epoch: [202/484] Iter:[150/495], Time: 0.38, lr: [0.006143885765463529], Loss: 2.032860, Acc:0.788143, Semantic loss: 0.767970, BCE loss: 0.526230, SB loss: 0.738660
2023-10-30 10:41:18,577 Epoch: [202/484] Iter:[160/495], Time: 0.38, lr: [0.006143489213755487], Loss: 2.046390, Acc:0.790978, Semantic loss: 0.768862, BCE loss: 0.536389, SB loss: 0.741139
2023-10-30 10:41:22,217 Epoch: [202/484] Iter:[170/495], Time: 0.38, lr: [0.006143092659203342], Loss: 2.047295, Acc:0.793025, Semantic loss: 0.768602, BCE loss: 0.537277, SB loss: 0.741416
2023-10-30 10:41:25,907 Epoch: [202/484] Iter:[180/495], Time: 0.38, lr: [0.0061426961018068715], Loss: 2.054394, Acc:0.792533, Semantic loss: 0.773649, BCE loss: 0.537671, SB loss: 0.743074
2023-10-30 10:41:29,563 Epoch: [202/484] Iter:[190/495], Time: 0.38, lr: [0.006142299541565849], Loss: 2.054794, Acc:0.794039, Semantic loss: 0.772478, BCE loss: 0.540844, SB loss: 0.741472
2023-10-30 10:41:33,232 Epoch: [202/484] Iter:[200/495], Time: 0.38, lr: [0.0061419029784800525], Loss: 2.049262, Acc:0.795244, Semantic loss: 0.769448, BCE loss: 0.540380, SB loss: 0.739434
2023-10-30 10:41:36,967 Epoch: [202/484] Iter:[210/495], Time: 0.38, lr: [0.006141506412549255], Loss: 2.061006, Acc:0.793317, Semantic loss: 0.781166, BCE loss: 0.539306, SB loss: 0.740534
2023-10-30 10:41:40,749 Epoch: [202/484] Iter:[220/495], Time: 0.38, lr: [0.006141109843773234], Loss: 2.062062, Acc:0.792557, Semantic loss: 0.781403, BCE loss: 0.538574, SB loss: 0.742085
2023-10-30 10:41:44,359 Epoch: [202/484] Iter:[230/495], Time: 0.38, lr: [0.006140713272151764], Loss: 2.066136, Acc:0.792406, Semantic loss: 0.782100, BCE loss: 0.541348, SB loss: 0.742688
2023-10-30 10:41:48,118 Epoch: [202/484] Iter:[240/495], Time: 0.38, lr: [0.006140316697684619], Loss: 2.074803, Acc:0.790488, Semantic loss: 0.786674, BCE loss: 0.542449, SB loss: 0.745680
2023-10-30 10:41:51,796 Epoch: [202/484] Iter:[250/495], Time: 0.38, lr: [0.006139920120371578], Loss: 2.084094, Acc:0.790248, Semantic loss: 0.789716, BCE loss: 0.545994, SB loss: 0.748384
2023-10-30 10:41:55,494 Epoch: [202/484] Iter:[260/495], Time: 0.38, lr: [0.006139523540212415], Loss: 2.085707, Acc:0.790997, Semantic loss: 0.788985, BCE loss: 0.548115, SB loss: 0.748607
2023-10-30 10:41:59,092 Epoch: [202/484] Iter:[270/495], Time: 0.38, lr: [0.006139126957206903], Loss: 2.085283, Acc:0.788668, Semantic loss: 0.789070, BCE loss: 0.547174, SB loss: 0.749040
2023-10-30 10:42:02,767 Epoch: [202/484] Iter:[280/495], Time: 0.38, lr: [0.00613873037135482], Loss: 2.084352, Acc:0.788183, Semantic loss: 0.788481, BCE loss: 0.545543, SB loss: 0.750328
2023-10-30 10:42:06,485 Epoch: [202/484] Iter:[290/495], Time: 0.38, lr: [0.0061383337826559385], Loss: 2.081999, Acc:0.789017, Semantic loss: 0.785886, BCE loss: 0.546832, SB loss: 0.749281
2023-10-30 10:42:10,295 Epoch: [202/484] Iter:[300/495], Time: 0.38, lr: [0.006137937191110037], Loss: 2.085688, Acc:0.788884, Semantic loss: 0.789898, BCE loss: 0.546024, SB loss: 0.749765
2023-10-30 10:42:13,937 Epoch: [202/484] Iter:[310/495], Time: 0.38, lr: [0.006137540596716887], Loss: 2.093612, Acc:0.789912, Semantic loss: 0.792041, BCE loss: 0.547959, SB loss: 0.753613
2023-10-30 10:42:17,628 Epoch: [202/484] Iter:[320/495], Time: 0.38, lr: [0.006137143999476267], Loss: 2.096147, Acc:0.790536, Semantic loss: 0.793769, BCE loss: 0.549053, SB loss: 0.753324
2023-10-30 10:42:21,380 Epoch: [202/484] Iter:[330/495], Time: 0.38, lr: [0.006136747399387951], Loss: 2.094657, Acc:0.789064, Semantic loss: 0.794807, BCE loss: 0.547268, SB loss: 0.752583
2023-10-30 10:42:25,011 Epoch: [202/484] Iter:[340/495], Time: 0.37, lr: [0.006136350796451714], Loss: 2.096977, Acc:0.788757, Semantic loss: 0.795586, BCE loss: 0.546808, SB loss: 0.754583
2023-10-30 10:42:28,727 Epoch: [202/484] Iter:[350/495], Time: 0.37, lr: [0.00613595419066733], Loss: 2.101028, Acc:0.788468, Semantic loss: 0.797412, BCE loss: 0.547148, SB loss: 0.756467
2023-10-30 10:42:32,474 Epoch: [202/484] Iter:[360/495], Time: 0.37, lr: [0.006135557582034574], Loss: 2.103433, Acc:0.788500, Semantic loss: 0.797701, BCE loss: 0.547654, SB loss: 0.758077
2023-10-30 10:42:36,132 Epoch: [202/484] Iter:[370/495], Time: 0.37, lr: [0.006135160970553223], Loss: 2.103344, Acc:0.789207, Semantic loss: 0.796755, BCE loss: 0.548370, SB loss: 0.758218
2023-10-30 10:42:39,827 Epoch: [202/484] Iter:[380/495], Time: 0.37, lr: [0.00613476435622305], Loss: 2.102601, Acc:0.789667, Semantic loss: 0.797007, BCE loss: 0.547511, SB loss: 0.758082
2023-10-30 10:42:43,496 Epoch: [202/484] Iter:[390/495], Time: 0.37, lr: [0.00613436773904383], Loss: 2.104227, Acc:0.789914, Semantic loss: 0.798107, BCE loss: 0.548277, SB loss: 0.757842
2023-10-30 10:42:47,150 Epoch: [202/484] Iter:[400/495], Time: 0.37, lr: [0.0061339711190153395], Loss: 2.099442, Acc:0.789828, Semantic loss: 0.794796, BCE loss: 0.547228, SB loss: 0.757418
2023-10-30 10:42:50,792 Epoch: [202/484] Iter:[410/495], Time: 0.37, lr: [0.006133574496137352], Loss: 2.095920, Acc:0.789488, Semantic loss: 0.793769, BCE loss: 0.545405, SB loss: 0.756745
2023-10-30 10:42:54,480 Epoch: [202/484] Iter:[420/495], Time: 0.37, lr: [0.006133177870409643], Loss: 2.096782, Acc:0.789483, Semantic loss: 0.793683, BCE loss: 0.545900, SB loss: 0.757199
2023-10-30 10:42:58,214 Epoch: [202/484] Iter:[430/495], Time: 0.37, lr: [0.006132781241831986], Loss: 2.094612, Acc:0.789542, Semantic loss: 0.793767, BCE loss: 0.545113, SB loss: 0.755732
2023-10-30 10:43:02,005 Epoch: [202/484] Iter:[440/495], Time: 0.37, lr: [0.006132384610404158], Loss: 2.101502, Acc:0.789951, Semantic loss: 0.798693, BCE loss: 0.544932, SB loss: 0.757878
2023-10-30 10:43:05,694 Epoch: [202/484] Iter:[450/495], Time: 0.37, lr: [0.00613198797612593], Loss: 2.098632, Acc:0.789468, Semantic loss: 0.797313, BCE loss: 0.544180, SB loss: 0.757139
2023-10-30 10:43:09,407 Epoch: [202/484] Iter:[460/495], Time: 0.37, lr: [0.00613159133899708], Loss: 2.100372, Acc:0.789767, Semantic loss: 0.797745, BCE loss: 0.544779, SB loss: 0.757848
2023-10-30 10:43:13,104 Epoch: [202/484] Iter:[470/495], Time: 0.37, lr: [0.006131194699017381], Loss: 2.097627, Acc:0.790313, Semantic loss: 0.796231, BCE loss: 0.544031, SB loss: 0.757366
2023-10-30 10:43:16,732 Epoch: [202/484] Iter:[480/495], Time: 0.37, lr: [0.006130798056186608], Loss: 2.104978, Acc:0.790643, Semantic loss: 0.801308, BCE loss: 0.544442, SB loss: 0.759228
2023-10-30 10:43:20,215 Epoch: [202/484] Iter:[490/495], Time: 0.37, lr: [0.0061304014105045355], Loss: 2.104055, Acc:0.789776, Semantic loss: 0.800549, BCE loss: 0.544122, SB loss: 0.759383
2023-10-30 10:43:21,626 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:43:21,866 Loss: 2.141, MeanIU:  0.6537, Best_mIoU:  0.7072
2023-10-30 10:43:21,866 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ]
2023-10-30 10:43:23,964 Epoch: [203/484] Iter:[0/495], Time: 2.06, lr: [0.006130203086594193], Loss: 1.597541, Acc:0.876940, Semantic loss: 0.540805, BCE loss: 0.437628, SB loss: 0.619109
2023-10-30 10:43:28,033 Epoch: [203/484] Iter:[10/495], Time: 0.56, lr: [0.00612980643663475], Loss: 2.267764, Acc:0.796619, Semantic loss: 0.844278, BCE loss: 0.617735, SB loss: 0.805751
2023-10-30 10:43:31,895 Epoch: [203/484] Iter:[20/495], Time: 0.48, lr: [0.006129409783823442], Loss: 2.141990, Acc:0.778023, Semantic loss: 0.786332, BCE loss: 0.563457, SB loss: 0.792201
2023-10-30 10:43:35,725 Epoch: [203/484] Iter:[30/495], Time: 0.45, lr: [0.006129013128160046], Loss: 2.156349, Acc:0.790761, Semantic loss: 0.790161, BCE loss: 0.568738, SB loss: 0.797451
2023-10-30 10:43:39,319 Epoch: [203/484] Iter:[40/495], Time: 0.42, lr: [0.0061286164696443355], Loss: 2.193233, Acc:0.798543, Semantic loss: 0.815286, BCE loss: 0.579437, SB loss: 0.798510
2023-10-30 10:43:42,987 Epoch: [203/484] Iter:[50/495], Time: 0.41, lr: [0.006128219808276086], Loss: 2.138843, Acc:0.789085, Semantic loss: 0.802972, BCE loss: 0.552865, SB loss: 0.783005
2023-10-30 10:43:46,645 Epoch: [203/484] Iter:[60/495], Time: 0.41, lr: [0.00612782314405507], Loss: 2.118182, Acc:0.793577, Semantic loss: 0.793064, BCE loss: 0.552730, SB loss: 0.772388
2023-10-30 10:43:50,508 Epoch: [203/484] Iter:[70/495], Time: 0.40, lr: [0.006127426476981064], Loss: 2.116072, Acc:0.793681, Semantic loss: 0.794333, BCE loss: 0.546252, SB loss: 0.775488
2023-10-30 10:43:54,224 Epoch: [203/484] Iter:[80/495], Time: 0.40, lr: [0.0061270298070538395], Loss: 2.103454, Acc:0.795715, Semantic loss: 0.790083, BCE loss: 0.542319, SB loss: 0.771052
2023-10-30 10:43:57,965 Epoch: [203/484] Iter:[90/495], Time: 0.40, lr: [0.006126633134273173], Loss: 2.108398, Acc:0.794110, Semantic loss: 0.798725, BCE loss: 0.539397, SB loss: 0.770276
2023-10-30 10:44:01,583 Epoch: [203/484] Iter:[100/495], Time: 0.39, lr: [0.006126236458638839], Loss: 2.096153, Acc:0.796667, Semantic loss: 0.789640, BCE loss: 0.536984, SB loss: 0.769529
2023-10-30 10:44:05,226 Epoch: [203/484] Iter:[110/495], Time: 0.39, lr: [0.006125839780150607], Loss: 2.113364, Acc:0.794939, Semantic loss: 0.804234, BCE loss: 0.538787, SB loss: 0.770343
2023-10-30 10:44:08,921 Epoch: [203/484] Iter:[120/495], Time: 0.39, lr: [0.006125443098808258], Loss: 2.110598, Acc:0.795062, Semantic loss: 0.799928, BCE loss: 0.540683, SB loss: 0.769987
2023-10-30 10:44:12,595 Epoch: [203/484] Iter:[130/495], Time: 0.39, lr: [0.006125046414611561], Loss: 2.103096, Acc:0.793706, Semantic loss: 0.796659, BCE loss: 0.540886, SB loss: 0.765551
2023-10-30 10:44:16,269 Epoch: [203/484] Iter:[140/495], Time: 0.39, lr: [0.006124649727560292], Loss: 2.094084, Acc:0.795088, Semantic loss: 0.790302, BCE loss: 0.542380, SB loss: 0.761403
2023-10-30 10:44:19,955 Epoch: [203/484] Iter:[150/495], Time: 0.38, lr: [0.006124253037654225], Loss: 2.085495, Acc:0.796026, Semantic loss: 0.784510, BCE loss: 0.540770, SB loss: 0.760214
2023-10-30 10:44:23,751 Epoch: [203/484] Iter:[160/495], Time: 0.38, lr: [0.006123856344893135], Loss: 2.086944, Acc:0.796354, Semantic loss: 0.786301, BCE loss: 0.539370, SB loss: 0.761273
2023-10-30 10:44:27,549 Epoch: [203/484] Iter:[170/495], Time: 0.38, lr: [0.006123459649276793], Loss: 2.081703, Acc:0.797147, Semantic loss: 0.782385, BCE loss: 0.541729, SB loss: 0.757589
2023-10-30 10:44:31,253 Epoch: [203/484] Iter:[180/495], Time: 0.38, lr: [0.006123062950804976], Loss: 2.083943, Acc:0.797933, Semantic loss: 0.783550, BCE loss: 0.543327, SB loss: 0.757065
2023-10-30 10:44:34,950 Epoch: [203/484] Iter:[190/495], Time: 0.38, lr: [0.006122666249477456], Loss: 2.089026, Acc:0.798079, Semantic loss: 0.784576, BCE loss: 0.547720, SB loss: 0.756730
2023-10-30 10:44:38,637 Epoch: [203/484] Iter:[200/495], Time: 0.38, lr: [0.006122269545294007], Loss: 2.084494, Acc:0.799457, Semantic loss: 0.780675, BCE loss: 0.549532, SB loss: 0.754287
2023-10-30 10:44:42,319 Epoch: [203/484] Iter:[210/495], Time: 0.38, lr: [0.006121872838254403], Loss: 2.079342, Acc:0.798794, Semantic loss: 0.778431, BCE loss: 0.547527, SB loss: 0.753384
2023-10-30 10:44:46,045 Epoch: [203/484] Iter:[220/495], Time: 0.38, lr: [0.00612147612835842], Loss: 2.089776, Acc:0.797950, Semantic loss: 0.785907, BCE loss: 0.547000, SB loss: 0.756869
2023-10-30 10:44:49,809 Epoch: [203/484] Iter:[230/495], Time: 0.38, lr: [0.006121079415605828], Loss: 2.082871, Acc:0.797914, Semantic loss: 0.780513, BCE loss: 0.546489, SB loss: 0.755870
2023-10-30 10:44:53,620 Epoch: [203/484] Iter:[240/495], Time: 0.38, lr: [0.006120682699996403], Loss: 2.093794, Acc:0.798625, Semantic loss: 0.790978, BCE loss: 0.546039, SB loss: 0.756777
2023-10-30 10:44:57,253 Epoch: [203/484] Iter:[250/495], Time: 0.38, lr: [0.0061202859815299195], Loss: 2.093998, Acc:0.799691, Semantic loss: 0.791161, BCE loss: 0.545397, SB loss: 0.757440
2023-10-30 10:45:00,980 Epoch: [203/484] Iter:[260/495], Time: 0.38, lr: [0.006119889260206148], Loss: 2.094529, Acc:0.799800, Semantic loss: 0.790508, BCE loss: 0.546007, SB loss: 0.758014
2023-10-30 10:45:04,662 Epoch: [203/484] Iter:[270/495], Time: 0.38, lr: [0.006119492536024864], Loss: 2.093905, Acc:0.800388, Semantic loss: 0.789223, BCE loss: 0.546311, SB loss: 0.758371
2023-10-30 10:45:08,321 Epoch: [203/484] Iter:[280/495], Time: 0.38, lr: [0.0061190958089858425], Loss: 2.089554, Acc:0.799902, Semantic loss: 0.786683, BCE loss: 0.546380, SB loss: 0.756492
2023-10-30 10:45:11,979 Epoch: [203/484] Iter:[290/495], Time: 0.38, lr: [0.006118699079088854], Loss: 2.089672, Acc:0.800486, Semantic loss: 0.787135, BCE loss: 0.545811, SB loss: 0.756726
2023-10-30 10:45:15,701 Epoch: [203/484] Iter:[300/495], Time: 0.38, lr: [0.006118302346333675], Loss: 2.083816, Acc:0.800497, Semantic loss: 0.783188, BCE loss: 0.545620, SB loss: 0.755008
2023-10-30 10:45:19,336 Epoch: [203/484] Iter:[310/495], Time: 0.38, lr: [0.006117905610720077], Loss: 2.087486, Acc:0.800773, Semantic loss: 0.785362, BCE loss: 0.545625, SB loss: 0.756499
2023-10-30 10:45:23,073 Epoch: [203/484] Iter:[320/495], Time: 0.38, lr: [0.0061175088722478345], Loss: 2.089827, Acc:0.801367, Semantic loss: 0.785870, BCE loss: 0.546188, SB loss: 0.757769
2023-10-30 10:45:26,735 Epoch: [203/484] Iter:[330/495], Time: 0.38, lr: [0.00611711213091672], Loss: 2.085041, Acc:0.800652, Semantic loss: 0.784094, BCE loss: 0.544885, SB loss: 0.756062
2023-10-30 10:45:30,554 Epoch: [203/484] Iter:[340/495], Time: 0.38, lr: [0.006116715386726508], Loss: 2.084161, Acc:0.800775, Semantic loss: 0.783724, BCE loss: 0.544688, SB loss: 0.755749
2023-10-30 10:45:34,282 Epoch: [203/484] Iter:[350/495], Time: 0.38, lr: [0.00611631863967697], Loss: 2.088998, Acc:0.801334, Semantic loss: 0.785476, BCE loss: 0.547289, SB loss: 0.756233
2023-10-30 10:45:37,959 Epoch: [203/484] Iter:[360/495], Time: 0.38, lr: [0.006115921889767881], Loss: 2.090212, Acc:0.801163, Semantic loss: 0.785772, BCE loss: 0.547762, SB loss: 0.756678
2023-10-30 10:45:41,770 Epoch: [203/484] Iter:[370/495], Time: 0.38, lr: [0.006115525136999012], Loss: 2.088304, Acc:0.801309, Semantic loss: 0.784738, BCE loss: 0.548053, SB loss: 0.755513
2023-10-30 10:45:45,433 Epoch: [203/484] Iter:[380/495], Time: 0.38, lr: [0.0061151283813701395], Loss: 2.089109, Acc:0.801601, Semantic loss: 0.785066, BCE loss: 0.548943, SB loss: 0.755100
2023-10-30 10:45:49,089 Epoch: [203/484] Iter:[390/495], Time: 0.38, lr: [0.006114731622881036], Loss: 2.085851, Acc:0.801748, Semantic loss: 0.784377, BCE loss: 0.546655, SB loss: 0.754819
2023-10-30 10:45:52,792 Epoch: [203/484] Iter:[400/495], Time: 0.38, lr: [0.006114334861531473], Loss: 2.082022, Acc:0.800324, Semantic loss: 0.782867, BCE loss: 0.544205, SB loss: 0.754949
2023-10-30 10:45:56,512 Epoch: [203/484] Iter:[410/495], Time: 0.38, lr: [0.006113938097321226], Loss: 2.080971, Acc:0.800343, Semantic loss: 0.782347, BCE loss: 0.544426, SB loss: 0.754198
2023-10-30 10:46:00,247 Epoch: [203/484] Iter:[420/495], Time: 0.38, lr: [0.006113541330250064], Loss: 2.080086, Acc:0.800427, Semantic loss: 0.781617, BCE loss: 0.544636, SB loss: 0.753832
2023-10-30 10:46:03,975 Epoch: [203/484] Iter:[430/495], Time: 0.38, lr: [0.006113144560317764], Loss: 2.083814, Acc:0.800930, Semantic loss: 0.782737, BCE loss: 0.546208, SB loss: 0.754868
2023-10-30 10:46:07,808 Epoch: [203/484] Iter:[440/495], Time: 0.38, lr: [0.006112747787524096], Loss: 2.080699, Acc:0.801411, Semantic loss: 0.781164, BCE loss: 0.545920, SB loss: 0.753615
2023-10-30 10:46:11,462 Epoch: [203/484] Iter:[450/495], Time: 0.38, lr: [0.006112351011868836], Loss: 2.077923, Acc:0.801479, Semantic loss: 0.779690, BCE loss: 0.544931, SB loss: 0.753302
2023-10-30 10:46:15,117 Epoch: [203/484] Iter:[460/495], Time: 0.38, lr: [0.0061119542333517565], Loss: 2.078398, Acc:0.801989, Semantic loss: 0.779288, BCE loss: 0.546212, SB loss: 0.752898
2023-10-30 10:46:18,852 Epoch: [203/484] Iter:[470/495], Time: 0.38, lr: [0.006111557451972628], Loss: 2.075859, Acc:0.801405, Semantic loss: 0.777775, BCE loss: 0.545875, SB loss: 0.752208
2023-10-30 10:46:22,488 Epoch: [203/484] Iter:[480/495], Time: 0.38, lr: [0.006111160667731226], Loss: 2.073517, Acc:0.801106, Semantic loss: 0.777234, BCE loss: 0.544705, SB loss: 0.751578
2023-10-30 10:46:25,999 Epoch: [203/484] Iter:[490/495], Time: 0.37, lr: [0.006110763880627323], Loss: 2.072063, Acc:0.800869, Semantic loss: 0.776501, BCE loss: 0.544464, SB loss: 0.751098
2023-10-30 10:46:27,423 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:46:27,666 Loss: 2.141, MeanIU:  0.6537, Best_mIoU:  0.7072
2023-10-30 10:46:27,666 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ]
2023-10-30 10:46:29,878 Epoch: [204/484] Iter:[0/495], Time: 2.20, lr: [0.006110565486001861], Loss: 1.750181, Acc:0.927164, Semantic loss: 0.648866, BCE loss: 0.445753, SB loss: 0.655562
2023-10-30 10:46:33,873 Epoch: [204/484] Iter:[10/495], Time: 0.56, lr: [0.006110168694603778], Loss: 2.048826, Acc:0.799776, Semantic loss: 0.828618, BCE loss: 0.471525, SB loss: 0.748683
2023-10-30 10:46:37,588 Epoch: [204/484] Iter:[20/495], Time: 0.47, lr: [0.006109771900342626], Loss: 2.042141, Acc:0.808717, Semantic loss: 0.791345, BCE loss: 0.503412, SB loss: 0.747384
2023-10-30 10:46:41,345 Epoch: [204/484] Iter:[30/495], Time: 0.44, lr: [0.0061093751032181755], Loss: 2.127545, Acc:0.805444, Semantic loss: 0.828400, BCE loss: 0.532522, SB loss: 0.766623
2023-10-30 10:46:44,985 Epoch: [204/484] Iter:[40/495], Time: 0.42, lr: [0.006108978303230202], Loss: 2.131126, Acc:0.806724, Semantic loss: 0.825078, BCE loss: 0.538079, SB loss: 0.767969
2023-10-30 10:46:48,607 Epoch: [204/484] Iter:[50/495], Time: 0.41, lr: [0.0061085815003784774], Loss: 2.108743, Acc:0.807937, Semantic loss: 0.806718, BCE loss: 0.543158, SB loss: 0.758867
2023-10-30 10:46:52,276 Epoch: [204/484] Iter:[60/495], Time: 0.40, lr: [0.006108184694662774], Loss: 2.181036, Acc:0.806381, Semantic loss: 0.863379, BCE loss: 0.544347, SB loss: 0.773309
2023-10-30 10:46:56,026 Epoch: [204/484] Iter:[70/495], Time: 0.40, lr: [0.006107787886082864], Loss: 2.195849, Acc:0.804481, Semantic loss: 0.865764, BCE loss: 0.553333, SB loss: 0.776752
2023-10-30 10:46:59,672 Epoch: [204/484] Iter:[80/495], Time: 0.39, lr: [0.0061073910746385195], Loss: 2.166399, Acc:0.799661, Semantic loss: 0.846102, BCE loss: 0.548627, SB loss: 0.771670
2023-10-30 10:47:03,251 Epoch: [204/484] Iter:[90/495], Time: 0.39, lr: [0.006106994260329513], Loss: 2.160432, Acc:0.798012, Semantic loss: 0.845600, BCE loss: 0.546818, SB loss: 0.768014
2023-10-30 10:47:06,914 Epoch: [204/484] Iter:[100/495], Time: 0.39, lr: [0.006106597443155619], Loss: 2.135000, Acc:0.797724, Semantic loss: 0.830565, BCE loss: 0.539241, SB loss: 0.765194
2023-10-30 10:47:10,582 Epoch: [204/484] Iter:[110/495], Time: 0.39, lr: [0.006106200623116608], Loss: 2.121613, Acc:0.797765, Semantic loss: 0.818881, BCE loss: 0.538389, SB loss: 0.764343
2023-10-30 10:47:14,249 Epoch: [204/484] Iter:[120/495], Time: 0.38, lr: [0.006105803800212254], Loss: 2.107512, Acc:0.794189, Semantic loss: 0.811492, BCE loss: 0.534023, SB loss: 0.761997
2023-10-30 10:47:17,987 Epoch: [204/484] Iter:[130/495], Time: 0.38, lr: [0.006105406974442329], Loss: 2.103862, Acc:0.793556, Semantic loss: 0.808114, BCE loss: 0.534229, SB loss: 0.761520
2023-10-30 10:47:21,663 Epoch: [204/484] Iter:[140/495], Time: 0.38, lr: [0.006105010145806604], Loss: 2.110622, Acc:0.790067, Semantic loss: 0.812088, BCE loss: 0.536525, SB loss: 0.762009
2023-10-30 10:47:25,327 Epoch: [204/484] Iter:[150/495], Time: 0.38, lr: [0.006104613314304852], Loss: 2.101156, Acc:0.791968, Semantic loss: 0.805315, BCE loss: 0.534060, SB loss: 0.761781
2023-10-30 10:47:28,951 Epoch: [204/484] Iter:[160/495], Time: 0.38, lr: [0.006104216479936846], Loss: 2.087203, Acc:0.791714, Semantic loss: 0.797533, BCE loss: 0.531338, SB loss: 0.758331
2023-10-30 10:47:32,688 Epoch: [204/484] Iter:[170/495], Time: 0.38, lr: [0.006103819642702357], Loss: 2.090408, Acc:0.793147, Semantic loss: 0.801204, BCE loss: 0.532070, SB loss: 0.757135
2023-10-30 10:47:36,473 Epoch: [204/484] Iter:[180/495], Time: 0.38, lr: [0.006103422802601158], Loss: 2.090541, Acc:0.795760, Semantic loss: 0.800198, BCE loss: 0.534004, SB loss: 0.756339
2023-10-30 10:47:40,131 Epoch: [204/484] Iter:[190/495], Time: 0.38, lr: [0.006103025959633022], Loss: 2.092815, Acc:0.794286, Semantic loss: 0.803459, BCE loss: 0.531500, SB loss: 0.757856
2023-10-30 10:47:43,816 Epoch: [204/484] Iter:[200/495], Time: 0.38, lr: [0.0061026291137977196], Loss: 2.086909, Acc:0.794272, Semantic loss: 0.802525, BCE loss: 0.528040, SB loss: 0.756344
2023-10-30 10:47:47,520 Epoch: [204/484] Iter:[210/495], Time: 0.38, lr: [0.006102232265095025], Loss: 2.077095, Acc:0.793149, Semantic loss: 0.796667, BCE loss: 0.525265, SB loss: 0.755162
2023-10-30 10:47:51,227 Epoch: [204/484] Iter:[220/495], Time: 0.38, lr: [0.006101835413524707], Loss: 2.076851, Acc:0.792817, Semantic loss: 0.796707, BCE loss: 0.525846, SB loss: 0.754298
2023-10-30 10:47:54,891 Epoch: [204/484] Iter:[230/495], Time: 0.38, lr: [0.006101438559086542], Loss: 2.079086, Acc:0.793689, Semantic loss: 0.796359, BCE loss: 0.527862, SB loss: 0.754864
2023-10-30 10:47:58,559 Epoch: [204/484] Iter:[240/495], Time: 0.38, lr: [0.006101041701780298], Loss: 2.077654, Acc:0.793609, Semantic loss: 0.794470, BCE loss: 0.528234, SB loss: 0.754950
2023-10-30 10:48:02,291 Epoch: [204/484] Iter:[250/495], Time: 0.38, lr: [0.006100644841605748], Loss: 2.079488, Acc:0.793510, Semantic loss: 0.794016, BCE loss: 0.530134, SB loss: 0.755338
2023-10-30 10:48:05,986 Epoch: [204/484] Iter:[260/495], Time: 0.38, lr: [0.006100247978562665], Loss: 2.075718, Acc:0.794060, Semantic loss: 0.791636, BCE loss: 0.530732, SB loss: 0.753350
2023-10-30 10:48:09,596 Epoch: [204/484] Iter:[270/495], Time: 0.38, lr: [0.006099851112650821], Loss: 2.081733, Acc:0.793463, Semantic loss: 0.795469, BCE loss: 0.532259, SB loss: 0.754005
2023-10-30 10:48:13,322 Epoch: [204/484] Iter:[280/495], Time: 0.38, lr: [0.0060994542438699865], Loss: 2.080582, Acc:0.793744, Semantic loss: 0.794680, BCE loss: 0.532461, SB loss: 0.753442
2023-10-30 10:48:16,952 Epoch: [204/484] Iter:[290/495], Time: 0.38, lr: [0.0060990573722199334], Loss: 2.083558, Acc:0.792894, Semantic loss: 0.795709, BCE loss: 0.533124, SB loss: 0.754725
2023-10-30 10:48:20,644 Epoch: [204/484] Iter:[300/495], Time: 0.38, lr: [0.006098660497700437], Loss: 2.082580, Acc:0.792895, Semantic loss: 0.795601, BCE loss: 0.533667, SB loss: 0.753311
2023-10-30 10:48:24,406 Epoch: [204/484] Iter:[310/495], Time: 0.38, lr: [0.006098263620311264], Loss: 2.080874, Acc:0.792617, Semantic loss: 0.795990, BCE loss: 0.531595, SB loss: 0.753288
2023-10-30 10:48:28,077 Epoch: [204/484] Iter:[320/495], Time: 0.37, lr: [0.006097866740052188], Loss: 2.074879, Acc:0.793318, Semantic loss: 0.791951, BCE loss: 0.530769, SB loss: 0.752159
2023-10-30 10:48:31,718 Epoch: [204/484] Iter:[330/495], Time: 0.37, lr: [0.006097469856922983], Loss: 2.072694, Acc:0.792592, Semantic loss: 0.790628, BCE loss: 0.530855, SB loss: 0.751211
2023-10-30 10:48:35,355 Epoch: [204/484] Iter:[340/495], Time: 0.37, lr: [0.0060970729709234174], Loss: 2.075070, Acc:0.792032, Semantic loss: 0.794382, BCE loss: 0.530550, SB loss: 0.750137
2023-10-30 10:48:39,046 Epoch: [204/484] Iter:[350/495], Time: 0.37, lr: [0.006096676082053265], Loss: 2.073719, Acc:0.791744, Semantic loss: 0.793469, BCE loss: 0.530970, SB loss: 0.749280
2023-10-30 10:48:42,823 Epoch: [204/484] Iter:[360/495], Time: 0.37, lr: [0.006096279190312297], Loss: 2.071913, Acc:0.792614, Semantic loss: 0.791874, BCE loss: 0.531489, SB loss: 0.748550
2023-10-30 10:48:46,569 Epoch: [204/484] Iter:[370/495], Time: 0.37, lr: [0.006095882295700285], Loss: 2.072263, Acc:0.792325, Semantic loss: 0.792519, BCE loss: 0.531814, SB loss: 0.747930
2023-10-30 10:48:50,239 Epoch: [204/484] Iter:[380/495], Time: 0.37, lr: [0.006095485398216999], Loss: 2.072920, Acc:0.792388, Semantic loss: 0.791314, BCE loss: 0.533009, SB loss: 0.748597
2023-10-30 10:48:53,982 Epoch: [204/484] Iter:[390/495], Time: 0.37, lr: [0.006095088497862213], Loss: 2.070236, Acc:0.791797, Semantic loss: 0.789336, BCE loss: 0.532751, SB loss: 0.748150
2023-10-30 10:48:57,644 Epoch: [204/484] Iter:[400/495], Time: 0.37, lr: [0.006094691594635694], Loss: 2.071530, Acc:0.791906, Semantic loss: 0.790126, BCE loss: 0.531980, SB loss: 0.749423
2023-10-30 10:49:01,283 Epoch: [204/484] Iter:[410/495], Time: 0.37, lr: [0.006094294688537219], Loss: 2.073306, Acc:0.792038, Semantic loss: 0.791738, BCE loss: 0.531772, SB loss: 0.749795
2023-10-30 10:49:04,930 Epoch: [204/484] Iter:[420/495], Time: 0.37, lr: [0.0060938977795665554], Loss: 2.068318, Acc:0.791543, Semantic loss: 0.789719, BCE loss: 0.529751, SB loss: 0.748848
2023-10-30 10:49:08,607 Epoch: [204/484] Iter:[430/495], Time: 0.37, lr: [0.006093500867723477], Loss: 2.067429, Acc:0.791272, Semantic loss: 0.789203, BCE loss: 0.529818, SB loss: 0.748408
2023-10-30 10:49:12,316 Epoch: [204/484] Iter:[440/495], Time: 0.37, lr: [0.006093103953007755], Loss: 2.067424, Acc:0.790813, Semantic loss: 0.789451, BCE loss: 0.528129, SB loss: 0.749844
2023-10-30 10:49:16,007 Epoch: [204/484] Iter:[450/495], Time: 0.37, lr: [0.006092707035419159], Loss: 2.067346, Acc:0.790640, Semantic loss: 0.788878, BCE loss: 0.528214, SB loss: 0.750253
2023-10-30 10:49:19,690 Epoch: [204/484] Iter:[460/495], Time: 0.37, lr: [0.006092310114957461], Loss: 2.066275, Acc:0.790595, Semantic loss: 0.788869, BCE loss: 0.527584, SB loss: 0.749822
2023-10-30 10:49:23,446 Epoch: [204/484] Iter:[470/495], Time: 0.37, lr: [0.006091913191622433], Loss: 2.064885, Acc:0.790136, Semantic loss: 0.788690, BCE loss: 0.526091, SB loss: 0.750105
2023-10-30 10:49:27,256 Epoch: [204/484] Iter:[480/495], Time: 0.37, lr: [0.0060915162654138445], Loss: 2.066877, Acc:0.790020, Semantic loss: 0.788492, BCE loss: 0.527849, SB loss: 0.750537
2023-10-30 10:49:30,830 Epoch: [204/484] Iter:[490/495], Time: 0.37, lr: [0.006091119336331469], Loss: 2.069530, Acc:0.790523, Semantic loss: 0.788719, BCE loss: 0.529679, SB loss: 0.751132
2023-10-30 10:49:32,237 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:49:32,475 Loss: 2.141, MeanIU:  0.6537, Best_mIoU:  0.7072
2023-10-30 10:49:32,475 [0.97381237 0.80555128 0.8984761  0.24875393 0.41200154 0.54705723
 0.59362495 0.71905973 0.89876724 0.4858995  0.93744698 0.69138171
 0.47041902 0.90596263 0.47858953 0.60626792 0.64327767 0.39937958
 0.7054883 ]
2023-10-30 10:49:34,636 Epoch: [205/484] Iter:[0/495], Time: 2.13, lr: [0.006090920870712538], Loss: 1.862687, Acc:0.849077, Semantic loss: 0.626637, BCE loss: 0.553951, SB loss: 0.682099
2023-10-30 10:49:38,576 Epoch: [205/484] Iter:[10/495], Time: 0.55, lr: [0.006090523937319049], Loss: 2.084069, Acc:0.795449, Semantic loss: 0.735709, BCE loss: 0.591113, SB loss: 0.757247
2023-10-30 10:49:42,253 Epoch: [205/484] Iter:[20/495], Time: 0.46, lr: [0.0060901270010512015], Loss: 2.007126, Acc:0.818041, Semantic loss: 0.714472, BCE loss: 0.545589, SB loss: 0.747066
2023-10-30 10:49:45,962 Epoch: [205/484] Iter:[30/495], Time: 0.43, lr: [0.0060897300619087635], Loss: 2.070904, Acc:0.807820, Semantic loss: 0.780315, BCE loss: 0.535364, SB loss: 0.755226
2023-10-30 10:49:49,606 Epoch: [205/484] Iter:[40/495], Time: 0.42, lr: [0.006089333119891507], Loss: 2.054585, Acc:0.809636, Semantic loss: 0.761649, BCE loss: 0.540715, SB loss: 0.752221
2023-10-30 10:49:53,334 Epoch: [205/484] Iter:[50/495], Time: 0.41, lr: [0.006088936174999202], Loss: 2.072648, Acc:0.806271, Semantic loss: 0.770530, BCE loss: 0.546857, SB loss: 0.755261
2023-10-30 10:49:57,045 Epoch: [205/484] Iter:[60/495], Time: 0.40, lr: [0.006088539227231621], Loss: 2.072846, Acc:0.799555, Semantic loss: 0.775636, BCE loss: 0.538811, SB loss: 0.758399
2023-10-30 10:50:00,748 Epoch: [205/484] Iter:[70/495], Time: 0.40, lr: [0.006088142276588533], Loss: 2.071857, Acc:0.796500, Semantic loss: 0.775761, BCE loss: 0.539394, SB loss: 0.756702
2023-10-30 10:50:04,442 Epoch: [205/484] Iter:[80/495], Time: 0.39, lr: [0.006087745323069712], Loss: 2.061850, Acc:0.800212, Semantic loss: 0.768328, BCE loss: 0.541421, SB loss: 0.752101
2023-10-30 10:50:08,232 Epoch: [205/484] Iter:[90/495], Time: 0.39, lr: [0.006087348366674924], Loss: 2.063787, Acc:0.800519, Semantic loss: 0.769116, BCE loss: 0.544221, SB loss: 0.750450
2023-10-30 10:50:12,007 Epoch: [205/484] Iter:[100/495], Time: 0.39, lr: [0.006086951407403946], Loss: 2.085168, Acc:0.805914, Semantic loss: 0.781610, BCE loss: 0.549518, SB loss: 0.754039
2023-10-30 10:50:15,668 Epoch: [205/484] Iter:[110/495], Time: 0.39, lr: [0.0060865544452565435], Loss: 2.078379, Acc:0.801785, Semantic loss: 0.779088, BCE loss: 0.546424, SB loss: 0.752868
2023-10-30 10:50:19,375 Epoch: [205/484] Iter:[120/495], Time: 0.39, lr: [0.006086157480232489], Loss: 2.070981, Acc:0.803044, Semantic loss: 0.770575, BCE loss: 0.548993, SB loss: 0.751413
2023-10-30 10:50:23,077 Epoch: [205/484] Iter:[130/495], Time: 0.39, lr: [0.006085760512331554], Loss: 2.062773, Acc:0.802102, Semantic loss: 0.765358, BCE loss: 0.545774, SB loss: 0.751640
2023-10-30 10:50:26,731 Epoch: [205/484] Iter:[140/495], Time: 0.38, lr: [0.006085363541553507], Loss: 2.064939, Acc:0.801781, Semantic loss: 0.769011, BCE loss: 0.543668, SB loss: 0.752260
2023-10-30 10:50:30,533 Epoch: [205/484] Iter:[150/495], Time: 0.38, lr: [0.006084966567898121], Loss: 2.059128, Acc:0.801899, Semantic loss: 0.768647, BCE loss: 0.540634, SB loss: 0.749848
2023-10-30 10:50:34,212 Epoch: [205/484] Iter:[160/495], Time: 0.38, lr: [0.006084569591365164], Loss: 2.053712, Acc:0.800056, Semantic loss: 0.765670, BCE loss: 0.540637, SB loss: 0.747405
2023-10-30 10:50:37,906 Epoch: [205/484] Iter:[170/495], Time: 0.38, lr: [0.0060841726119544096], Loss: 2.044487, Acc:0.801008, Semantic loss: 0.760603, BCE loss: 0.540151, SB loss: 0.743733
2023-10-30 10:50:41,625 Epoch: [205/484] Iter:[180/495], Time: 0.38, lr: [0.0060837756296656265], Loss: 2.046705, Acc:0.801277, Semantic loss: 0.764645, BCE loss: 0.538762, SB loss: 0.743298
2023-10-30 10:50:45,407 Epoch: [205/484] Iter:[190/495], Time: 0.38, lr: [0.006083378644498586], Loss: 2.041651, Acc:0.801245, Semantic loss: 0.762623, BCE loss: 0.536919, SB loss: 0.742109
2023-10-30 10:50:49,144 Epoch: [205/484] Iter:[200/495], Time: 0.38, lr: [0.006082981656453058], Loss: 2.043033, Acc:0.802187, Semantic loss: 0.761742, BCE loss: 0.539488, SB loss: 0.741803
2023-10-30 10:50:52,887 Epoch: [205/484] Iter:[210/495], Time: 0.38, lr: [0.006082584665528813], Loss: 2.044100, Acc:0.802975, Semantic loss: 0.762517, BCE loss: 0.540794, SB loss: 0.740789
2023-10-30 10:50:56,580 Epoch: [205/484] Iter:[220/495], Time: 0.38, lr: [0.00608218767172562], Loss: 2.042902, Acc:0.804610, Semantic loss: 0.762034, BCE loss: 0.540089, SB loss: 0.740780
2023-10-30 10:51:00,262 Epoch: [205/484] Iter:[230/495], Time: 0.38, lr: [0.006081790675043251], Loss: 2.043248, Acc:0.803295, Semantic loss: 0.760740, BCE loss: 0.540880, SB loss: 0.741628
2023-10-30 10:51:03,985 Epoch: [205/484] Iter:[240/495], Time: 0.38, lr: [0.006081393675481475], Loss: 2.038800, Acc:0.804473, Semantic loss: 0.759541, BCE loss: 0.538065, SB loss: 0.741194
2023-10-30 10:51:07,695 Epoch: [205/484] Iter:[250/495], Time: 0.38, lr: [0.006080996673040065], Loss: 2.042321, Acc:0.804124, Semantic loss: 0.762296, BCE loss: 0.537881, SB loss: 0.742143
2023-10-30 10:51:11,402 Epoch: [205/484] Iter:[260/495], Time: 0.38, lr: [0.006080599667718788], Loss: 2.037552, Acc:0.805268, Semantic loss: 0.758893, BCE loss: 0.538187, SB loss: 0.740472
2023-10-30 10:51:15,103 Epoch: [205/484] Iter:[270/495], Time: 0.38, lr: [0.006080202659517416], Loss: 2.031045, Acc:0.805017, Semantic loss: 0.756702, BCE loss: 0.535611, SB loss: 0.738732
2023-10-30 10:51:18,796 Epoch: [205/484] Iter:[280/495], Time: 0.38, lr: [0.006079805648435719], Loss: 2.034690, Acc:0.803830, Semantic loss: 0.759729, BCE loss: 0.535074, SB loss: 0.739888
2023-10-30 10:51:22,538 Epoch: [205/484] Iter:[290/495], Time: 0.38, lr: [0.0060794086344734665], Loss: 2.038980, Acc:0.804077, Semantic loss: 0.761405, BCE loss: 0.538409, SB loss: 0.739167
2023-10-30 10:51:26,203 Epoch: [205/484] Iter:[300/495], Time: 0.38, lr: [0.006079011617630428], Loss: 2.036706, Acc:0.803745, Semantic loss: 0.760331, BCE loss: 0.536981, SB loss: 0.739394
2023-10-30 10:51:29,951 Epoch: [205/484] Iter:[310/495], Time: 0.38, lr: [0.006078614597906376], Loss: 2.040383, Acc:0.803989, Semantic loss: 0.761801, BCE loss: 0.538003, SB loss: 0.740579
2023-10-30 10:51:33,637 Epoch: [205/484] Iter:[320/495], Time: 0.38, lr: [0.006078217575301077], Loss: 2.038504, Acc:0.803570, Semantic loss: 0.760753, BCE loss: 0.537514, SB loss: 0.740237
2023-10-30 10:51:37,390 Epoch: [205/484] Iter:[330/495], Time: 0.38, lr: [0.006077820549814305], Loss: 2.037129, Acc:0.804060, Semantic loss: 0.760310, BCE loss: 0.536904, SB loss: 0.739915
2023-10-30 10:51:41,134 Epoch: [205/484] Iter:[340/495], Time: 0.38, lr: [0.006077423521445826], Loss: 2.035145, Acc:0.805277, Semantic loss: 0.759482, BCE loss: 0.536491, SB loss: 0.739171
2023-10-30 10:51:44,829 Epoch: [205/484] Iter:[350/495], Time: 0.38, lr: [0.006077026490195413], Loss: 2.032244, Acc:0.805685, Semantic loss: 0.758176, BCE loss: 0.535434, SB loss: 0.738634
2023-10-30 10:51:48,559 Epoch: [205/484] Iter:[360/495], Time: 0.38, lr: [0.006076629456062834], Loss: 2.031663, Acc:0.805565, Semantic loss: 0.758101, BCE loss: 0.534797, SB loss: 0.738764
2023-10-30 10:51:52,229 Epoch: [205/484] Iter:[370/495], Time: 0.38, lr: [0.0060762324190478615], Loss: 2.031573, Acc:0.804540, Semantic loss: 0.758745, BCE loss: 0.533851, SB loss: 0.738977
2023-10-30 10:51:55,884 Epoch: [205/484] Iter:[380/495], Time: 0.38, lr: [0.00607583537915026], Loss: 2.033366, Acc:0.804002, Semantic loss: 0.760235, BCE loss: 0.534229, SB loss: 0.738901
2023-10-30 10:51:59,532 Epoch: [205/484] Iter:[390/495], Time: 0.38, lr: [0.006075438336369804], Loss: 2.035300, Acc:0.803841, Semantic loss: 0.762794, BCE loss: 0.532415, SB loss: 0.740091
2023-10-30 10:52:03,140 Epoch: [205/484] Iter:[400/495], Time: 0.38, lr: [0.006075041290706261], Loss: 2.038575, Acc:0.803515, Semantic loss: 0.764138, BCE loss: 0.533567, SB loss: 0.740870
2023-10-30 10:52:06,872 Epoch: [205/484] Iter:[410/495], Time: 0.38, lr: [0.0060746442421594025], Loss: 2.046812, Acc:0.802907, Semantic loss: 0.768900, BCE loss: 0.535058, SB loss: 0.742854
2023-10-30 10:52:10,531 Epoch: [205/484] Iter:[420/495], Time: 0.38, lr: [0.006074247190728997], Loss: 2.049252, Acc:0.802992, Semantic loss: 0.769268, BCE loss: 0.536601, SB loss: 0.743383
2023-10-30 10:52:14,240 Epoch: [205/484] Iter:[430/495], Time: 0.38, lr: [0.006073850136414815], Loss: 2.044704, Acc:0.802494, Semantic loss: 0.766992, BCE loss: 0.534647, SB loss: 0.743065
2023-10-30 10:52:17,948 Epoch: [205/484] Iter:[440/495], Time: 0.38, lr: [0.006073453079216624], Loss: 2.044446, Acc:0.802639, Semantic loss: 0.766982, BCE loss: 0.534271, SB loss: 0.743193
2023-10-30 10:52:21,627 Epoch: [205/484] Iter:[450/495], Time: 0.37, lr: [0.006073056019134195], Loss: 2.048409, Acc:0.802205, Semantic loss: 0.769152, BCE loss: 0.533990, SB loss: 0.745267
2023-10-30 10:52:25,332 Epoch: [205/484] Iter:[460/495], Time: 0.37, lr: [0.006072658956167297], Loss: 2.047772, Acc:0.802191, Semantic loss: 0.768340, BCE loss: 0.534144, SB loss: 0.745288
2023-10-30 10:52:29,010 Epoch: [205/484] Iter:[470/495], Time: 0.37, lr: [0.006072261890315701], Loss: 2.048125, Acc:0.801949, Semantic loss: 0.769081, BCE loss: 0.533800, SB loss: 0.745244
2023-10-30 10:52:32,741 Epoch: [205/484] Iter:[480/495], Time: 0.37, lr: [0.006071864821579174], Loss: 2.045696, Acc:0.801935, Semantic loss: 0.767953, BCE loss: 0.533008, SB loss: 0.744736
2023-10-30 10:52:36,306 Epoch: [205/484] Iter:[490/495], Time: 0.37, lr: [0.006071467749957488], Loss: 2.043465, Acc:0.802460, Semantic loss: 0.766623, BCE loss: 0.533000, SB loss: 0.743843
2023-10-30 10:55:33,182 0 [9.41756596e-01 6.59248372e-01 8.24868179e-01 1.10486405e-01
 2.31394634e-01 4.06318495e-01 4.78836746e-01 6.00506270e-01
 8.86035107e-01 4.70429535e-01 8.56401431e-01 6.07966412e-01
 3.00015701e-02 7.72778913e-01 4.59662615e-04 6.64575101e-02
 5.30866339e-02 7.95879270e-02 5.27664173e-01] 0.45285708268008457
2023-10-30 10:55:33,182 1 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088] 0.6706243273106332
2023-10-30 10:55:33,186 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:55:33,425 Loss: 2.055, MeanIU:  0.6706, Best_mIoU:  0.7072
2023-10-30 10:55:33,425 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088]
2023-10-30 10:55:35,457 Epoch: [206/484] Iter:[0/495], Time: 2.00, lr: [0.006071269213064638], Loss: 2.189069, Acc:0.800272, Semantic loss: 0.882230, BCE loss: 0.483891, SB loss: 0.822948
2023-10-30 10:55:39,317 Epoch: [206/484] Iter:[10/495], Time: 0.53, lr: [0.006070872137114779], Loss: 2.066968, Acc:0.827022, Semantic loss: 0.793290, BCE loss: 0.546751, SB loss: 0.726927
2023-10-30 10:55:43,058 Epoch: [206/484] Iter:[20/495], Time: 0.46, lr: [0.006070475058279183], Loss: 2.025971, Acc:0.820531, Semantic loss: 0.747939, BCE loss: 0.548564, SB loss: 0.729469
2023-10-30 10:55:46,617 Epoch: [206/484] Iter:[30/495], Time: 0.42, lr: [0.00607007797655762], Loss: 2.051587, Acc:0.816824, Semantic loss: 0.745312, BCE loss: 0.572272, SB loss: 0.734003
2023-10-30 10:55:50,220 Epoch: [206/484] Iter:[40/495], Time: 0.41, lr: [0.006069680891949857], Loss: 2.037394, Acc:0.813898, Semantic loss: 0.749688, BCE loss: 0.553278, SB loss: 0.734427
2023-10-30 10:55:53,844 Epoch: [206/484] Iter:[50/495], Time: 0.40, lr: [0.006069283804455666], Loss: 2.047943, Acc:0.810918, Semantic loss: 0.766666, BCE loss: 0.540085, SB loss: 0.741192
2023-10-30 10:55:57,554 Epoch: [206/484] Iter:[60/495], Time: 0.39, lr: [0.006068886714074814], Loss: 2.035413, Acc:0.810661, Semantic loss: 0.764152, BCE loss: 0.535941, SB loss: 0.735319
2023-10-30 10:56:01,172 Epoch: [206/484] Iter:[70/495], Time: 0.39, lr: [0.006068489620807073], Loss: 2.052693, Acc:0.806982, Semantic loss: 0.772306, BCE loss: 0.536284, SB loss: 0.744103
2023-10-30 10:56:04,745 Epoch: [206/484] Iter:[80/495], Time: 0.39, lr: [0.00606809252465221], Loss: 2.068074, Acc:0.809233, Semantic loss: 0.778537, BCE loss: 0.539704, SB loss: 0.749834
2023-10-30 10:56:08,359 Epoch: [206/484] Iter:[90/495], Time: 0.38, lr: [0.006067695425609994], Loss: 2.082959, Acc:0.806067, Semantic loss: 0.785767, BCE loss: 0.541026, SB loss: 0.756166
2023-10-30 10:56:12,116 Epoch: [206/484] Iter:[100/495], Time: 0.38, lr: [0.006067298323680195], Loss: 2.074299, Acc:0.803828, Semantic loss: 0.782519, BCE loss: 0.536822, SB loss: 0.754958
2023-10-30 10:56:15,757 Epoch: [206/484] Iter:[110/495], Time: 0.38, lr: [0.00606690121886258], Loss: 2.060082, Acc:0.807916, Semantic loss: 0.772571, BCE loss: 0.535750, SB loss: 0.751761
2023-10-30 10:56:19,355 Epoch: [206/484] Iter:[120/495], Time: 0.38, lr: [0.006066504111156921], Loss: 2.063300, Acc:0.804967, Semantic loss: 0.773650, BCE loss: 0.534237, SB loss: 0.755413
2023-10-30 10:56:22,949 Epoch: [206/484] Iter:[130/495], Time: 0.38, lr: [0.006066107000562985], Loss: 2.065302, Acc:0.803927, Semantic loss: 0.775305, BCE loss: 0.536390, SB loss: 0.753607
2023-10-30 10:56:26,629 Epoch: [206/484] Iter:[140/495], Time: 0.38, lr: [0.006065709887080541], Loss: 2.063557, Acc:0.804771, Semantic loss: 0.770697, BCE loss: 0.541137, SB loss: 0.751723
2023-10-30 10:56:30,289 Epoch: [206/484] Iter:[150/495], Time: 0.38, lr: [0.006065312770709358], Loss: 2.068937, Acc:0.803202, Semantic loss: 0.772762, BCE loss: 0.544175, SB loss: 0.751999
2023-10-30 10:56:33,875 Epoch: [206/484] Iter:[160/495], Time: 0.38, lr: [0.006064915651449205], Loss: 2.071147, Acc:0.802252, Semantic loss: 0.776559, BCE loss: 0.542223, SB loss: 0.752364
2023-10-30 10:56:37,544 Epoch: [206/484] Iter:[170/495], Time: 0.37, lr: [0.006064518529299852], Loss: 2.066169, Acc:0.800301, Semantic loss: 0.773431, BCE loss: 0.542409, SB loss: 0.750328
2023-10-30 10:56:41,157 Epoch: [206/484] Iter:[180/495], Time: 0.37, lr: [0.006064121404261066], Loss: 2.068415, Acc:0.800403, Semantic loss: 0.772224, BCE loss: 0.546656, SB loss: 0.749535
2023-10-30 10:56:44,834 Epoch: [206/484] Iter:[190/495], Time: 0.37, lr: [0.006063724276332616], Loss: 2.081235, Acc:0.799413, Semantic loss: 0.782430, BCE loss: 0.545012, SB loss: 0.753793
2023-10-30 10:56:48,527 Epoch: [206/484] Iter:[200/495], Time: 0.37, lr: [0.00606332714551427], Loss: 2.087195, Acc:0.800394, Semantic loss: 0.783424, BCE loss: 0.548443, SB loss: 0.755328
2023-10-30 10:56:52,220 Epoch: [206/484] Iter:[210/495], Time: 0.37, lr: [0.006062930011805799], Loss: 2.084040, Acc:0.800209, Semantic loss: 0.780826, BCE loss: 0.548696, SB loss: 0.754518
2023-10-30 10:56:55,801 Epoch: [206/484] Iter:[220/495], Time: 0.37, lr: [0.006062532875206968], Loss: 2.083952, Acc:0.799214, Semantic loss: 0.780148, BCE loss: 0.549088, SB loss: 0.754717
2023-10-30 10:56:59,455 Epoch: [206/484] Iter:[230/495], Time: 0.37, lr: [0.006062135735717551], Loss: 2.087409, Acc:0.797647, Semantic loss: 0.781448, BCE loss: 0.548336, SB loss: 0.757625
2023-10-30 10:57:03,149 Epoch: [206/484] Iter:[240/495], Time: 0.37, lr: [0.006061738593337313], Loss: 2.079881, Acc:0.797147, Semantic loss: 0.777846, BCE loss: 0.546069, SB loss: 0.755966
2023-10-30 10:57:06,847 Epoch: [206/484] Iter:[250/495], Time: 0.37, lr: [0.006061341448066021], Loss: 2.083331, Acc:0.797394, Semantic loss: 0.778037, BCE loss: 0.548964, SB loss: 0.756331
2023-10-30 10:57:10,528 Epoch: [206/484] Iter:[260/495], Time: 0.37, lr: [0.006060944299903447], Loss: 2.085798, Acc:0.796420, Semantic loss: 0.779812, BCE loss: 0.549192, SB loss: 0.756794
2023-10-30 10:57:14,205 Epoch: [206/484] Iter:[270/495], Time: 0.37, lr: [0.006060547148849358], Loss: 2.095976, Acc:0.796256, Semantic loss: 0.786782, BCE loss: 0.550127, SB loss: 0.759068
2023-10-30 10:57:17,854 Epoch: [206/484] Iter:[280/495], Time: 0.37, lr: [0.00606014999490352], Loss: 2.099284, Acc:0.795856, Semantic loss: 0.788027, BCE loss: 0.550826, SB loss: 0.760432
2023-10-30 10:57:21,510 Epoch: [206/484] Iter:[290/495], Time: 0.37, lr: [0.006059752838065705], Loss: 2.100178, Acc:0.795039, Semantic loss: 0.789279, BCE loss: 0.549963, SB loss: 0.760936
2023-10-30 10:57:25,064 Epoch: [206/484] Iter:[300/495], Time: 0.37, lr: [0.00605935567833568], Loss: 2.101863, Acc:0.793601, Semantic loss: 0.791878, BCE loss: 0.549033, SB loss: 0.760951
2023-10-30 10:57:28,663 Epoch: [206/484] Iter:[310/495], Time: 0.37, lr: [0.006058958515713213], Loss: 2.096570, Acc:0.792029, Semantic loss: 0.788469, BCE loss: 0.547885, SB loss: 0.760216
2023-10-30 10:57:32,267 Epoch: [206/484] Iter:[320/495], Time: 0.37, lr: [0.006058561350198073], Loss: 2.092402, Acc:0.792451, Semantic loss: 0.785815, BCE loss: 0.547108, SB loss: 0.759479
2023-10-30 10:57:35,980 Epoch: [206/484] Iter:[330/495], Time: 0.37, lr: [0.006058164181790028], Loss: 2.096552, Acc:0.792641, Semantic loss: 0.787569, BCE loss: 0.548095, SB loss: 0.760887
2023-10-30 10:57:39,756 Epoch: [206/484] Iter:[340/495], Time: 0.37, lr: [0.006057767010488846], Loss: 2.092872, Acc:0.792601, Semantic loss: 0.786258, BCE loss: 0.546573, SB loss: 0.760042
2023-10-30 10:57:43,338 Epoch: [206/484] Iter:[350/495], Time: 0.37, lr: [0.006057369836294294], Loss: 2.087407, Acc:0.793553, Semantic loss: 0.784216, BCE loss: 0.544497, SB loss: 0.758694
2023-10-30 10:57:47,015 Epoch: [206/484] Iter:[360/495], Time: 0.37, lr: [0.006056972659206142], Loss: 2.086413, Acc:0.792304, Semantic loss: 0.784955, BCE loss: 0.542574, SB loss: 0.758883
2023-10-30 10:57:50,699 Epoch: [206/484] Iter:[370/495], Time: 0.37, lr: [0.006056575479224157], Loss: 2.087082, Acc:0.792646, Semantic loss: 0.785517, BCE loss: 0.543285, SB loss: 0.758279
2023-10-30 10:57:54,531 Epoch: [206/484] Iter:[380/495], Time: 0.37, lr: [0.006056178296348106], Loss: 2.087603, Acc:0.793722, Semantic loss: 0.786381, BCE loss: 0.543404, SB loss: 0.757818
2023-10-30 10:57:58,204 Epoch: [206/484] Iter:[390/495], Time: 0.37, lr: [0.00605578111057776], Loss: 2.088019, Acc:0.793828, Semantic loss: 0.787080, BCE loss: 0.543128, SB loss: 0.757811
2023-10-30 10:58:01,856 Epoch: [206/484] Iter:[400/495], Time: 0.37, lr: [0.0060553839219128856], Loss: 2.088968, Acc:0.793473, Semantic loss: 0.787019, BCE loss: 0.543659, SB loss: 0.758289
2023-10-30 10:58:05,525 Epoch: [206/484] Iter:[410/495], Time: 0.37, lr: [0.006054986730353251], Loss: 2.085807, Acc:0.792355, Semantic loss: 0.785826, BCE loss: 0.541895, SB loss: 0.758086
2023-10-30 10:58:09,219 Epoch: [206/484] Iter:[420/495], Time: 0.37, lr: [0.006054589535898622], Loss: 2.087768, Acc:0.792888, Semantic loss: 0.786821, BCE loss: 0.543094, SB loss: 0.757853
2023-10-30 10:58:12,993 Epoch: [206/484] Iter:[430/495], Time: 0.37, lr: [0.00605419233854877], Loss: 2.086296, Acc:0.792615, Semantic loss: 0.786315, BCE loss: 0.542640, SB loss: 0.757341
2023-10-30 10:58:16,828 Epoch: [206/484] Iter:[440/495], Time: 0.37, lr: [0.00605379513830346], Loss: 2.089189, Acc:0.793084, Semantic loss: 0.787388, BCE loss: 0.544447, SB loss: 0.757353
2023-10-30 10:58:20,624 Epoch: [206/484] Iter:[450/495], Time: 0.37, lr: [0.00605339793516246], Loss: 2.090535, Acc:0.793836, Semantic loss: 0.788064, BCE loss: 0.544198, SB loss: 0.758274
2023-10-30 10:58:24,370 Epoch: [206/484] Iter:[460/495], Time: 0.37, lr: [0.006053000729125539], Loss: 2.083955, Acc:0.794156, Semantic loss: 0.784709, BCE loss: 0.542550, SB loss: 0.756696
2023-10-30 10:58:28,009 Epoch: [206/484] Iter:[470/495], Time: 0.37, lr: [0.006052603520192465], Loss: 2.082513, Acc:0.794132, Semantic loss: 0.784655, BCE loss: 0.542230, SB loss: 0.755628
2023-10-30 10:58:31,602 Epoch: [206/484] Iter:[480/495], Time: 0.37, lr: [0.0060522063083630045], Loss: 2.079234, Acc:0.794668, Semantic loss: 0.781933, BCE loss: 0.542663, SB loss: 0.754637
2023-10-30 10:58:35,116 Epoch: [206/484] Iter:[490/495], Time: 0.37, lr: [0.0060518090936369255], Loss: 2.079401, Acc:0.794969, Semantic loss: 0.782847, BCE loss: 0.541651, SB loss: 0.754904
2023-10-30 10:58:36,513 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 10:58:36,760 Loss: 2.055, MeanIU:  0.6706, Best_mIoU:  0.7072
2023-10-30 10:58:36,760 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088]
2023-10-30 10:58:38,970 Epoch: [207/484] Iter:[0/495], Time: 2.17, lr: [0.006051610485187581], Loss: 2.916374, Acc:0.780585, Semantic loss: 1.230009, BCE loss: 0.787867, SB loss: 0.898498
2023-10-30 10:58:42,999 Epoch: [207/484] Iter:[10/495], Time: 0.56, lr: [0.006051213266116139], Loss: 2.183393, Acc:0.765378, Semantic loss: 0.843715, BCE loss: 0.579595, SB loss: 0.760083
2023-10-30 10:58:46,752 Epoch: [207/484] Iter:[20/495], Time: 0.47, lr: [0.006050816044147497], Loss: 2.075187, Acc:0.770591, Semantic loss: 0.816477, BCE loss: 0.509371, SB loss: 0.749339
2023-10-30 10:58:50,350 Epoch: [207/484] Iter:[30/495], Time: 0.44, lr: [0.006050418819281423], Loss: 2.026051, Acc:0.794134, Semantic loss: 0.764102, BCE loss: 0.528828, SB loss: 0.733121
2023-10-30 10:58:53,959 Epoch: [207/484] Iter:[40/495], Time: 0.42, lr: [0.006050021591517685], Loss: 2.000905, Acc:0.795630, Semantic loss: 0.749118, BCE loss: 0.523336, SB loss: 0.728452
2023-10-30 10:58:57,671 Epoch: [207/484] Iter:[50/495], Time: 0.41, lr: [0.00604962436085605], Loss: 2.024281, Acc:0.794999, Semantic loss: 0.762626, BCE loss: 0.532566, SB loss: 0.729090
2023-10-30 10:59:01,264 Epoch: [207/484] Iter:[60/495], Time: 0.40, lr: [0.006049227127296286], Loss: 2.034949, Acc:0.794641, Semantic loss: 0.770561, BCE loss: 0.534076, SB loss: 0.730311
2023-10-30 10:59:04,888 Epoch: [207/484] Iter:[70/495], Time: 0.40, lr: [0.00604882989083816], Loss: 2.027855, Acc:0.796049, Semantic loss: 0.762882, BCE loss: 0.538677, SB loss: 0.726296
2023-10-30 10:59:08,581 Epoch: [207/484] Iter:[80/495], Time: 0.39, lr: [0.00604843265148144], Loss: 2.053668, Acc:0.793159, Semantic loss: 0.782746, BCE loss: 0.536879, SB loss: 0.734043
2023-10-30 10:59:12,239 Epoch: [207/484] Iter:[90/495], Time: 0.39, lr: [0.006048035409225891], Loss: 2.046103, Acc:0.795182, Semantic loss: 0.773921, BCE loss: 0.537647, SB loss: 0.734535
2023-10-30 10:59:15,874 Epoch: [207/484] Iter:[100/495], Time: 0.39, lr: [0.006047638164071283], Loss: 2.043569, Acc:0.796879, Semantic loss: 0.770288, BCE loss: 0.538491, SB loss: 0.734790
2023-10-30 10:59:19,549 Epoch: [207/484] Iter:[110/495], Time: 0.39, lr: [0.0060472409160173815], Loss: 2.034377, Acc:0.796012, Semantic loss: 0.766383, BCE loss: 0.533787, SB loss: 0.734207
2023-10-30 10:59:23,098 Epoch: [207/484] Iter:[120/495], Time: 0.38, lr: [0.006046843665063955], Loss: 2.026286, Acc:0.795012, Semantic loss: 0.763889, BCE loss: 0.528649, SB loss: 0.733748
2023-10-30 10:59:26,854 Epoch: [207/484] Iter:[130/495], Time: 0.38, lr: [0.00604644641121077], Loss: 2.022717, Acc:0.793312, Semantic loss: 0.761314, BCE loss: 0.529263, SB loss: 0.732141
2023-10-30 10:59:30,518 Epoch: [207/484] Iter:[140/495], Time: 0.38, lr: [0.006046049154457594], Loss: 2.025325, Acc:0.796275, Semantic loss: 0.762090, BCE loss: 0.531442, SB loss: 0.731794
2023-10-30 10:59:34,284 Epoch: [207/484] Iter:[150/495], Time: 0.38, lr: [0.0060456518948041925], Loss: 2.036930, Acc:0.797042, Semantic loss: 0.767545, BCE loss: 0.533550, SB loss: 0.735835
2023-10-30 10:59:38,045 Epoch: [207/484] Iter:[160/495], Time: 0.38, lr: [0.006045254632250335], Loss: 2.036033, Acc:0.798846, Semantic loss: 0.765549, BCE loss: 0.534904, SB loss: 0.735580
2023-10-30 10:59:41,718 Epoch: [207/484] Iter:[170/495], Time: 0.38, lr: [0.006044857366795789], Loss: 2.035957, Acc:0.797620, Semantic loss: 0.766238, BCE loss: 0.534475, SB loss: 0.735244
2023-10-30 10:59:45,451 Epoch: [207/484] Iter:[180/495], Time: 0.38, lr: [0.006044460098440317], Loss: 2.030573, Acc:0.798816, Semantic loss: 0.764680, BCE loss: 0.532511, SB loss: 0.733381
2023-10-30 10:59:49,201 Epoch: [207/484] Iter:[190/495], Time: 0.38, lr: [0.006044062827183691], Loss: 2.033251, Acc:0.799980, Semantic loss: 0.764698, BCE loss: 0.535004, SB loss: 0.733549
2023-10-30 10:59:52,895 Epoch: [207/484] Iter:[200/495], Time: 0.38, lr: [0.006043665553025673], Loss: 2.035344, Acc:0.800632, Semantic loss: 0.765444, BCE loss: 0.535874, SB loss: 0.734026
2023-10-30 10:59:56,658 Epoch: [207/484] Iter:[210/495], Time: 0.38, lr: [0.0060432682759660366], Loss: 2.038041, Acc:0.800483, Semantic loss: 0.766069, BCE loss: 0.536795, SB loss: 0.735177
2023-10-30 11:00:00,321 Epoch: [207/484] Iter:[220/495], Time: 0.38, lr: [0.006042870996004542], Loss: 2.037448, Acc:0.799236, Semantic loss: 0.767299, BCE loss: 0.534644, SB loss: 0.735505
2023-10-30 11:00:04,069 Epoch: [207/484] Iter:[230/495], Time: 0.38, lr: [0.006042473713140962], Loss: 2.036058, Acc:0.799922, Semantic loss: 0.766121, BCE loss: 0.534539, SB loss: 0.735397
2023-10-30 11:00:07,844 Epoch: [207/484] Iter:[240/495], Time: 0.38, lr: [0.006042076427375058], Loss: 2.041666, Acc:0.800166, Semantic loss: 0.770458, BCE loss: 0.533791, SB loss: 0.737417
2023-10-30 11:00:11,527 Epoch: [207/484] Iter:[250/495], Time: 0.38, lr: [0.006041679138706599], Loss: 2.044177, Acc:0.799472, Semantic loss: 0.772456, BCE loss: 0.533605, SB loss: 0.738116
2023-10-30 11:00:15,130 Epoch: [207/484] Iter:[260/495], Time: 0.38, lr: [0.0060412818471353505], Loss: 2.045671, Acc:0.796998, Semantic loss: 0.773766, BCE loss: 0.533277, SB loss: 0.738627
2023-10-30 11:00:18,796 Epoch: [207/484] Iter:[270/495], Time: 0.38, lr: [0.0060408845526610825], Loss: 2.045488, Acc:0.797545, Semantic loss: 0.771056, BCE loss: 0.536430, SB loss: 0.738001
2023-10-30 11:00:22,621 Epoch: [207/484] Iter:[280/495], Time: 0.38, lr: [0.006040487255283558], Loss: 2.045699, Acc:0.798678, Semantic loss: 0.772632, BCE loss: 0.535995, SB loss: 0.737072
2023-10-30 11:00:26,459 Epoch: [207/484] Iter:[290/495], Time: 0.38, lr: [0.006040089955002546], Loss: 2.049691, Acc:0.799083, Semantic loss: 0.772746, BCE loss: 0.538663, SB loss: 0.738281
2023-10-30 11:00:30,299 Epoch: [207/484] Iter:[300/495], Time: 0.38, lr: [0.006039692651817812], Loss: 2.049757, Acc:0.798858, Semantic loss: 0.771875, BCE loss: 0.539215, SB loss: 0.738667
2023-10-30 11:00:34,074 Epoch: [207/484] Iter:[310/495], Time: 0.38, lr: [0.006039295345729123], Loss: 2.049300, Acc:0.798266, Semantic loss: 0.771299, BCE loss: 0.539949, SB loss: 0.738051
2023-10-30 11:00:37,735 Epoch: [207/484] Iter:[320/495], Time: 0.38, lr: [0.006038898036736246], Loss: 2.046797, Acc:0.798284, Semantic loss: 0.770251, BCE loss: 0.538517, SB loss: 0.738029
2023-10-30 11:00:41,442 Epoch: [207/484] Iter:[330/495], Time: 0.38, lr: [0.006038500724838945], Loss: 2.047639, Acc:0.798534, Semantic loss: 0.771232, BCE loss: 0.538186, SB loss: 0.738221
2023-10-30 11:00:45,218 Epoch: [207/484] Iter:[340/495], Time: 0.38, lr: [0.006038103410036989], Loss: 2.050725, Acc:0.799020, Semantic loss: 0.772570, BCE loss: 0.539650, SB loss: 0.738504
2023-10-30 11:00:48,876 Epoch: [207/484] Iter:[350/495], Time: 0.38, lr: [0.006037706092330144], Loss: 2.053154, Acc:0.798462, Semantic loss: 0.773689, BCE loss: 0.540195, SB loss: 0.739269
2023-10-30 11:00:52,592 Epoch: [207/484] Iter:[360/495], Time: 0.38, lr: [0.006037308771718175], Loss: 2.058349, Acc:0.797927, Semantic loss: 0.776171, BCE loss: 0.541053, SB loss: 0.741124
2023-10-30 11:00:56,367 Epoch: [207/484] Iter:[370/495], Time: 0.38, lr: [0.00603691144820085], Loss: 2.057095, Acc:0.798118, Semantic loss: 0.775506, BCE loss: 0.540617, SB loss: 0.740972
2023-10-30 11:01:00,061 Epoch: [207/484] Iter:[380/495], Time: 0.38, lr: [0.006036514121777934], Loss: 2.058960, Acc:0.796940, Semantic loss: 0.776589, BCE loss: 0.540615, SB loss: 0.741756
2023-10-30 11:01:03,731 Epoch: [207/484] Iter:[390/495], Time: 0.38, lr: [0.006036116792449194], Loss: 2.061031, Acc:0.797090, Semantic loss: 0.777620, BCE loss: 0.540599, SB loss: 0.742812
2023-10-30 11:01:07,479 Epoch: [207/484] Iter:[400/495], Time: 0.38, lr: [0.006035719460214396], Loss: 2.059098, Acc:0.796052, Semantic loss: 0.775807, BCE loss: 0.541256, SB loss: 0.742036
2023-10-30 11:01:11,381 Epoch: [207/484] Iter:[410/495], Time: 0.38, lr: [0.006035322125073307], Loss: 2.059974, Acc:0.796034, Semantic loss: 0.775531, BCE loss: 0.541781, SB loss: 0.742661
2023-10-30 11:01:15,117 Epoch: [207/484] Iter:[420/495], Time: 0.38, lr: [0.006034924787025691], Loss: 2.060890, Acc:0.795283, Semantic loss: 0.776217, BCE loss: 0.542079, SB loss: 0.742594
2023-10-30 11:01:18,700 Epoch: [207/484] Iter:[430/495], Time: 0.38, lr: [0.006034527446071317], Loss: 2.064049, Acc:0.794163, Semantic loss: 0.778632, BCE loss: 0.541405, SB loss: 0.744012
2023-10-30 11:01:22,460 Epoch: [207/484] Iter:[440/495], Time: 0.38, lr: [0.006034130102209946], Loss: 2.066501, Acc:0.793668, Semantic loss: 0.780662, BCE loss: 0.541015, SB loss: 0.744824
2023-10-30 11:01:26,114 Epoch: [207/484] Iter:[450/495], Time: 0.38, lr: [0.00603373275544135], Loss: 2.068068, Acc:0.793093, Semantic loss: 0.782419, BCE loss: 0.540258, SB loss: 0.745390
2023-10-30 11:01:29,862 Epoch: [207/484] Iter:[460/495], Time: 0.38, lr: [0.006033335405765294], Loss: 2.067661, Acc:0.792639, Semantic loss: 0.782398, BCE loss: 0.539855, SB loss: 0.745409
2023-10-30 11:01:33,626 Epoch: [207/484] Iter:[470/495], Time: 0.38, lr: [0.006032938053181541], Loss: 2.065487, Acc:0.793462, Semantic loss: 0.781274, BCE loss: 0.540003, SB loss: 0.744210
2023-10-30 11:01:37,354 Epoch: [207/484] Iter:[480/495], Time: 0.38, lr: [0.006032540697689858], Loss: 2.063714, Acc:0.794582, Semantic loss: 0.780072, BCE loss: 0.539716, SB loss: 0.743927
2023-10-30 11:01:40,930 Epoch: [207/484] Iter:[490/495], Time: 0.38, lr: [0.00603214333929001], Loss: 2.064428, Acc:0.794458, Semantic loss: 0.779874, BCE loss: 0.539967, SB loss: 0.744587
2023-10-30 11:01:42,337 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:01:42,576 Loss: 2.055, MeanIU:  0.6706, Best_mIoU:  0.7072
2023-10-30 11:01:42,576 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088]
2023-10-30 11:01:44,848 Epoch: [208/484] Iter:[0/495], Time: 2.24, lr: [0.006031944658999453], Loss: 1.960736, Acc:0.845282, Semantic loss: 0.646002, BCE loss: 0.612066, SB loss: 0.702668
2023-10-30 11:01:48,774 Epoch: [208/484] Iter:[10/495], Time: 0.56, lr: [0.006031547296236922], Loss: 2.102860, Acc:0.800444, Semantic loss: 0.839638, BCE loss: 0.526658, SB loss: 0.736564
2023-10-30 11:01:52,535 Epoch: [208/484] Iter:[20/495], Time: 0.47, lr: [0.0060311499305656414], Loss: 2.194052, Acc:0.803842, Semantic loss: 0.858799, BCE loss: 0.567774, SB loss: 0.767478
2023-10-30 11:01:56,288 Epoch: [208/484] Iter:[30/495], Time: 0.44, lr: [0.006030752561985379], Loss: 2.173612, Acc:0.813695, Semantic loss: 0.841042, BCE loss: 0.565751, SB loss: 0.766819
2023-10-30 11:01:59,978 Epoch: [208/484] Iter:[40/495], Time: 0.42, lr: [0.006030355190495898], Loss: 2.146426, Acc:0.812796, Semantic loss: 0.821084, BCE loss: 0.558128, SB loss: 0.767213
2023-10-30 11:02:03,731 Epoch: [208/484] Iter:[50/495], Time: 0.41, lr: [0.006029957816096965], Loss: 2.122086, Acc:0.807478, Semantic loss: 0.804405, BCE loss: 0.550149, SB loss: 0.767533
2023-10-30 11:02:07,381 Epoch: [208/484] Iter:[60/495], Time: 0.41, lr: [0.006029560438788347], Loss: 2.112143, Acc:0.805416, Semantic loss: 0.799397, BCE loss: 0.550319, SB loss: 0.762427
2023-10-30 11:02:11,083 Epoch: [208/484] Iter:[70/495], Time: 0.40, lr: [0.006029163058569807], Loss: 2.120589, Acc:0.800435, Semantic loss: 0.800624, BCE loss: 0.551173, SB loss: 0.768792
2023-10-30 11:02:14,832 Epoch: [208/484] Iter:[80/495], Time: 0.40, lr: [0.00602876567544111], Loss: 2.114497, Acc:0.798480, Semantic loss: 0.806187, BCE loss: 0.537817, SB loss: 0.770493
2023-10-30 11:02:18,558 Epoch: [208/484] Iter:[90/495], Time: 0.39, lr: [0.006028368289402027], Loss: 2.091792, Acc:0.801076, Semantic loss: 0.798101, BCE loss: 0.529783, SB loss: 0.763908
2023-10-30 11:02:22,375 Epoch: [208/484] Iter:[100/495], Time: 0.39, lr: [0.0060279709004523166], Loss: 2.071964, Acc:0.800645, Semantic loss: 0.786686, BCE loss: 0.525944, SB loss: 0.759334
2023-10-30 11:02:26,093 Epoch: [208/484] Iter:[110/495], Time: 0.39, lr: [0.006027573508591751], Loss: 2.074959, Acc:0.803234, Semantic loss: 0.785220, BCE loss: 0.529790, SB loss: 0.759949
2023-10-30 11:02:29,790 Epoch: [208/484] Iter:[120/495], Time: 0.39, lr: [0.00602717611382009], Loss: 2.074342, Acc:0.802295, Semantic loss: 0.782513, BCE loss: 0.533068, SB loss: 0.758761
2023-10-30 11:02:33,419 Epoch: [208/484] Iter:[130/495], Time: 0.39, lr: [0.006026778716137103], Loss: 2.071189, Acc:0.802579, Semantic loss: 0.782958, BCE loss: 0.532843, SB loss: 0.755388
2023-10-30 11:02:37,180 Epoch: [208/484] Iter:[140/495], Time: 0.39, lr: [0.006026381315542553], Loss: 2.078304, Acc:0.802420, Semantic loss: 0.786400, BCE loss: 0.537445, SB loss: 0.754459
2023-10-30 11:02:40,863 Epoch: [208/484] Iter:[150/495], Time: 0.39, lr: [0.006025983912036206], Loss: 2.078288, Acc:0.803321, Semantic loss: 0.783187, BCE loss: 0.542766, SB loss: 0.752335
2023-10-30 11:02:44,562 Epoch: [208/484] Iter:[160/495], Time: 0.38, lr: [0.006025586505617826], Loss: 2.072295, Acc:0.801567, Semantic loss: 0.780154, BCE loss: 0.541524, SB loss: 0.750617
2023-10-30 11:02:48,254 Epoch: [208/484] Iter:[170/495], Time: 0.38, lr: [0.006025189096287182], Loss: 2.064813, Acc:0.801262, Semantic loss: 0.776512, BCE loss: 0.538927, SB loss: 0.749373
2023-10-30 11:02:51,955 Epoch: [208/484] Iter:[180/495], Time: 0.38, lr: [0.006024791684044034], Loss: 2.077525, Acc:0.801099, Semantic loss: 0.785242, BCE loss: 0.539130, SB loss: 0.753153
2023-10-30 11:02:55,631 Epoch: [208/484] Iter:[190/495], Time: 0.38, lr: [0.006024394268888153], Loss: 2.072323, Acc:0.801865, Semantic loss: 0.782806, BCE loss: 0.537081, SB loss: 0.752436
2023-10-30 11:02:59,383 Epoch: [208/484] Iter:[200/495], Time: 0.38, lr: [0.0060239968508193], Loss: 2.080001, Acc:0.802153, Semantic loss: 0.785801, BCE loss: 0.540152, SB loss: 0.754048
2023-10-30 11:03:03,162 Epoch: [208/484] Iter:[210/495], Time: 0.38, lr: [0.006023599429837241], Loss: 2.078141, Acc:0.803148, Semantic loss: 0.784686, BCE loss: 0.539242, SB loss: 0.754212
2023-10-30 11:03:06,905 Epoch: [208/484] Iter:[220/495], Time: 0.38, lr: [0.006023202005941741], Loss: 2.077876, Acc:0.803140, Semantic loss: 0.786041, BCE loss: 0.538981, SB loss: 0.752854
2023-10-30 11:03:10,667 Epoch: [208/484] Iter:[230/495], Time: 0.38, lr: [0.006022804579132567], Loss: 2.078740, Acc:0.803827, Semantic loss: 0.783453, BCE loss: 0.542057, SB loss: 0.753230
2023-10-30 11:03:14,406 Epoch: [208/484] Iter:[240/495], Time: 0.38, lr: [0.00602240714940948], Loss: 2.090804, Acc:0.801809, Semantic loss: 0.790239, BCE loss: 0.543307, SB loss: 0.757259
2023-10-30 11:03:18,151 Epoch: [208/484] Iter:[250/495], Time: 0.38, lr: [0.006022009716772248], Loss: 2.088811, Acc:0.799370, Semantic loss: 0.788258, BCE loss: 0.542649, SB loss: 0.757904
2023-10-30 11:03:21,920 Epoch: [208/484] Iter:[260/495], Time: 0.38, lr: [0.006021612281220636], Loss: 2.088414, Acc:0.798442, Semantic loss: 0.787206, BCE loss: 0.543058, SB loss: 0.758150
2023-10-30 11:03:25,648 Epoch: [208/484] Iter:[270/495], Time: 0.38, lr: [0.006021214842754409], Loss: 2.089589, Acc:0.797923, Semantic loss: 0.787505, BCE loss: 0.543347, SB loss: 0.758737
2023-10-30 11:03:29,377 Epoch: [208/484] Iter:[280/495], Time: 0.38, lr: [0.00602081740137333], Loss: 2.092253, Acc:0.798955, Semantic loss: 0.789269, BCE loss: 0.543809, SB loss: 0.759175
2023-10-30 11:03:33,075 Epoch: [208/484] Iter:[290/495], Time: 0.38, lr: [0.006020419957077166], Loss: 2.086486, Acc:0.799781, Semantic loss: 0.786394, BCE loss: 0.542782, SB loss: 0.757310
2023-10-30 11:03:36,763 Epoch: [208/484] Iter:[300/495], Time: 0.38, lr: [0.006020022509865679], Loss: 2.084069, Acc:0.799462, Semantic loss: 0.785736, BCE loss: 0.542687, SB loss: 0.755646
2023-10-30 11:03:40,468 Epoch: [208/484] Iter:[310/495], Time: 0.38, lr: [0.006019625059738636], Loss: 2.084402, Acc:0.799818, Semantic loss: 0.785341, BCE loss: 0.543461, SB loss: 0.755600
2023-10-30 11:03:44,247 Epoch: [208/484] Iter:[320/495], Time: 0.38, lr: [0.0060192276066958015], Loss: 2.081626, Acc:0.799902, Semantic loss: 0.783335, BCE loss: 0.542694, SB loss: 0.755596
2023-10-30 11:03:48,031 Epoch: [208/484] Iter:[330/495], Time: 0.38, lr: [0.00601883015073694], Loss: 2.079107, Acc:0.799611, Semantic loss: 0.781856, BCE loss: 0.543681, SB loss: 0.753569
2023-10-30 11:03:51,773 Epoch: [208/484] Iter:[340/495], Time: 0.38, lr: [0.006018432691861815], Loss: 2.081898, Acc:0.799142, Semantic loss: 0.782788, BCE loss: 0.544993, SB loss: 0.754117
2023-10-30 11:03:55,539 Epoch: [208/484] Iter:[350/495], Time: 0.38, lr: [0.0060180352300701935], Loss: 2.082054, Acc:0.798595, Semantic loss: 0.782211, BCE loss: 0.544423, SB loss: 0.755420
2023-10-30 11:03:59,232 Epoch: [208/484] Iter:[360/495], Time: 0.38, lr: [0.0060176377653618374], Loss: 2.080676, Acc:0.798474, Semantic loss: 0.781595, BCE loss: 0.544240, SB loss: 0.754840
2023-10-30 11:04:02,960 Epoch: [208/484] Iter:[370/495], Time: 0.38, lr: [0.0060172402977365135], Loss: 2.080679, Acc:0.798183, Semantic loss: 0.780652, BCE loss: 0.545407, SB loss: 0.754620
2023-10-30 11:04:06,681 Epoch: [208/484] Iter:[380/495], Time: 0.38, lr: [0.006016842827193986], Loss: 2.080976, Acc:0.799245, Semantic loss: 0.780253, BCE loss: 0.546623, SB loss: 0.754100
2023-10-30 11:04:10,366 Epoch: [208/484] Iter:[390/495], Time: 0.38, lr: [0.006016445353734016], Loss: 2.082630, Acc:0.799165, Semantic loss: 0.781512, BCE loss: 0.546191, SB loss: 0.754928
2023-10-30 11:04:14,033 Epoch: [208/484] Iter:[400/495], Time: 0.38, lr: [0.006016047877356373], Loss: 2.078903, Acc:0.799429, Semantic loss: 0.779546, BCE loss: 0.545625, SB loss: 0.753732
2023-10-30 11:04:17,802 Epoch: [208/484] Iter:[410/495], Time: 0.38, lr: [0.006015650398060817], Loss: 2.078965, Acc:0.799873, Semantic loss: 0.780309, BCE loss: 0.545532, SB loss: 0.753123
2023-10-30 11:04:21,383 Epoch: [208/484] Iter:[420/495], Time: 0.38, lr: [0.006015252915847116], Loss: 2.077381, Acc:0.799435, Semantic loss: 0.780007, BCE loss: 0.544846, SB loss: 0.752528
2023-10-30 11:04:25,131 Epoch: [208/484] Iter:[430/495], Time: 0.38, lr: [0.006014855430715033], Loss: 2.073986, Acc:0.798525, Semantic loss: 0.778337, BCE loss: 0.543393, SB loss: 0.752256
2023-10-30 11:04:28,836 Epoch: [208/484] Iter:[440/495], Time: 0.38, lr: [0.006014457942664331], Loss: 2.072126, Acc:0.799037, Semantic loss: 0.776930, BCE loss: 0.543779, SB loss: 0.751417
2023-10-30 11:04:32,482 Epoch: [208/484] Iter:[450/495], Time: 0.38, lr: [0.006014060451694775], Loss: 2.072870, Acc:0.799331, Semantic loss: 0.777776, BCE loss: 0.544073, SB loss: 0.751021
2023-10-30 11:04:36,160 Epoch: [208/484] Iter:[460/495], Time: 0.38, lr: [0.006013662957806131], Loss: 2.074677, Acc:0.797912, Semantic loss: 0.778790, BCE loss: 0.544484, SB loss: 0.751403
2023-10-30 11:04:39,867 Epoch: [208/484] Iter:[470/495], Time: 0.38, lr: [0.00601326546099816], Loss: 2.074053, Acc:0.798315, Semantic loss: 0.778217, BCE loss: 0.544537, SB loss: 0.751299
2023-10-30 11:04:43,760 Epoch: [208/484] Iter:[480/495], Time: 0.38, lr: [0.006012867961270627], Loss: 2.077795, Acc:0.798391, Semantic loss: 0.780724, BCE loss: 0.544575, SB loss: 0.752496
2023-10-30 11:04:47,301 Epoch: [208/484] Iter:[490/495], Time: 0.38, lr: [0.006012470458623298], Loss: 2.077717, Acc:0.798640, Semantic loss: 0.780256, BCE loss: 0.544226, SB loss: 0.753236
2023-10-30 11:04:48,710 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:04:48,948 Loss: 2.055, MeanIU:  0.6706, Best_mIoU:  0.7072
2023-10-30 11:04:48,948 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088]
2023-10-30 11:04:50,880 Epoch: [209/484] Iter:[0/495], Time: 1.90, lr: [0.006012271706204635], Loss: 1.973271, Acc:0.646578, Semantic loss: 0.791736, BCE loss: 0.435392, SB loss: 0.746143
2023-10-30 11:04:54,746 Epoch: [209/484] Iter:[10/495], Time: 0.52, lr: [0.006011874199177168], Loss: 2.141321, Acc:0.782820, Semantic loss: 0.832630, BCE loss: 0.537645, SB loss: 0.771046
2023-10-30 11:04:58,509 Epoch: [209/484] Iter:[20/495], Time: 0.45, lr: [0.006011476689229315], Loss: 2.106173, Acc:0.778373, Semantic loss: 0.784116, BCE loss: 0.559531, SB loss: 0.762525
2023-10-30 11:05:02,235 Epoch: [209/484] Iter:[30/495], Time: 0.43, lr: [0.006011079176360837], Loss: 2.084686, Acc:0.788263, Semantic loss: 0.766731, BCE loss: 0.560564, SB loss: 0.757391
2023-10-30 11:05:05,955 Epoch: [209/484] Iter:[40/495], Time: 0.41, lr: [0.006010681660571501], Loss: 2.086679, Acc:0.793298, Semantic loss: 0.770913, BCE loss: 0.554502, SB loss: 0.761265
2023-10-30 11:05:09,698 Epoch: [209/484] Iter:[50/495], Time: 0.41, lr: [0.006010284141861069], Loss: 2.106737, Acc:0.799876, Semantic loss: 0.788038, BCE loss: 0.553217, SB loss: 0.765482
2023-10-30 11:05:13,385 Epoch: [209/484] Iter:[60/495], Time: 0.40, lr: [0.006009886620229305], Loss: 2.114745, Acc:0.798633, Semantic loss: 0.805250, BCE loss: 0.547770, SB loss: 0.761725
2023-10-30 11:05:17,152 Epoch: [209/484] Iter:[70/495], Time: 0.40, lr: [0.006009489095675975], Loss: 2.111833, Acc:0.799674, Semantic loss: 0.803358, BCE loss: 0.547335, SB loss: 0.761140
2023-10-30 11:05:20,921 Epoch: [209/484] Iter:[80/495], Time: 0.39, lr: [0.00600909156820084], Loss: 2.104299, Acc:0.798261, Semantic loss: 0.795994, BCE loss: 0.551452, SB loss: 0.756854
2023-10-30 11:05:24,527 Epoch: [209/484] Iter:[90/495], Time: 0.39, lr: [0.006008694037803665], Loss: 2.094745, Acc:0.798624, Semantic loss: 0.792818, BCE loss: 0.551361, SB loss: 0.750566
2023-10-30 11:05:28,219 Epoch: [209/484] Iter:[100/495], Time: 0.39, lr: [0.006008296504484215], Loss: 2.090967, Acc:0.799066, Semantic loss: 0.792230, BCE loss: 0.548017, SB loss: 0.750720
2023-10-30 11:05:31,891 Epoch: [209/484] Iter:[110/495], Time: 0.39, lr: [0.0060078989682422505], Loss: 2.088571, Acc:0.800989, Semantic loss: 0.791753, BCE loss: 0.545030, SB loss: 0.751787
2023-10-30 11:05:35,566 Epoch: [209/484] Iter:[120/495], Time: 0.38, lr: [0.006007501429077538], Loss: 2.085334, Acc:0.799961, Semantic loss: 0.792249, BCE loss: 0.542240, SB loss: 0.750846
2023-10-30 11:05:39,317 Epoch: [209/484] Iter:[130/495], Time: 0.38, lr: [0.00600710388698984], Loss: 2.076095, Acc:0.799671, Semantic loss: 0.786141, BCE loss: 0.541985, SB loss: 0.747970
2023-10-30 11:05:43,022 Epoch: [209/484] Iter:[140/495], Time: 0.38, lr: [0.0060067063419789206], Loss: 2.067506, Acc:0.797593, Semantic loss: 0.780816, BCE loss: 0.540849, SB loss: 0.745841
2023-10-30 11:05:46,760 Epoch: [209/484] Iter:[150/495], Time: 0.38, lr: [0.00600630879404454], Loss: 2.063376, Acc:0.799363, Semantic loss: 0.779534, BCE loss: 0.540285, SB loss: 0.743557
2023-10-30 11:05:50,434 Epoch: [209/484] Iter:[160/495], Time: 0.38, lr: [0.006005911243186468], Loss: 2.061151, Acc:0.798738, Semantic loss: 0.776122, BCE loss: 0.541655, SB loss: 0.743375
2023-10-30 11:05:54,171 Epoch: [209/484] Iter:[170/495], Time: 0.38, lr: [0.006005513689404465], Loss: 2.061774, Acc:0.798912, Semantic loss: 0.776243, BCE loss: 0.541747, SB loss: 0.743784
2023-10-30 11:05:57,974 Epoch: [209/484] Iter:[180/495], Time: 0.38, lr: [0.006005116132698293], Loss: 2.066961, Acc:0.798434, Semantic loss: 0.779885, BCE loss: 0.542169, SB loss: 0.744907
2023-10-30 11:06:01,664 Epoch: [209/484] Iter:[190/495], Time: 0.38, lr: [0.006004718573067717], Loss: 2.068417, Acc:0.797788, Semantic loss: 0.781113, BCE loss: 0.542260, SB loss: 0.745044
2023-10-30 11:06:05,361 Epoch: [209/484] Iter:[200/495], Time: 0.38, lr: [0.006004321010512499], Loss: 2.069521, Acc:0.799644, Semantic loss: 0.780269, BCE loss: 0.545189, SB loss: 0.744063
2023-10-30 11:06:09,024 Epoch: [209/484] Iter:[210/495], Time: 0.38, lr: [0.006003923445032402], Loss: 2.065245, Acc:0.800282, Semantic loss: 0.778992, BCE loss: 0.542280, SB loss: 0.743973
2023-10-30 11:06:12,849 Epoch: [209/484] Iter:[220/495], Time: 0.38, lr: [0.006003525876627193], Loss: 2.067438, Acc:0.799724, Semantic loss: 0.780981, BCE loss: 0.541829, SB loss: 0.744628
2023-10-30 11:06:16,547 Epoch: [209/484] Iter:[230/495], Time: 0.38, lr: [0.00600312830529663], Loss: 2.065044, Acc:0.800882, Semantic loss: 0.778181, BCE loss: 0.542864, SB loss: 0.743999
2023-10-30 11:06:20,189 Epoch: [209/484] Iter:[240/495], Time: 0.38, lr: [0.006002730731040481], Loss: 2.062338, Acc:0.801374, Semantic loss: 0.775104, BCE loss: 0.544000, SB loss: 0.743234
2023-10-30 11:06:23,966 Epoch: [209/484] Iter:[250/495], Time: 0.38, lr: [0.006002333153858507], Loss: 2.059711, Acc:0.800737, Semantic loss: 0.773557, BCE loss: 0.543508, SB loss: 0.742646
2023-10-30 11:06:27,708 Epoch: [209/484] Iter:[260/495], Time: 0.38, lr: [0.006001935573750471], Loss: 2.062049, Acc:0.800788, Semantic loss: 0.774208, BCE loss: 0.544485, SB loss: 0.743357
2023-10-30 11:06:31,344 Epoch: [209/484] Iter:[270/495], Time: 0.38, lr: [0.006001537990716137], Loss: 2.067846, Acc:0.800219, Semantic loss: 0.778553, BCE loss: 0.545279, SB loss: 0.744014
2023-10-30 11:06:35,028 Epoch: [209/484] Iter:[280/495], Time: 0.38, lr: [0.006001140404755266], Loss: 2.067813, Acc:0.799440, Semantic loss: 0.778378, BCE loss: 0.545848, SB loss: 0.743587
2023-10-30 11:06:38,735 Epoch: [209/484] Iter:[290/495], Time: 0.38, lr: [0.0060007428158676225], Loss: 2.063636, Acc:0.799822, Semantic loss: 0.775039, BCE loss: 0.545500, SB loss: 0.743097
2023-10-30 11:06:42,336 Epoch: [209/484] Iter:[300/495], Time: 0.38, lr: [0.0060003452240529696], Loss: 2.063138, Acc:0.799316, Semantic loss: 0.774384, BCE loss: 0.546037, SB loss: 0.742718
2023-10-30 11:06:46,108 Epoch: [209/484] Iter:[310/495], Time: 0.38, lr: [0.00599994762931107], Loss: 2.066776, Acc:0.799703, Semantic loss: 0.775902, BCE loss: 0.547882, SB loss: 0.742993
2023-10-30 11:06:49,809 Epoch: [209/484] Iter:[320/495], Time: 0.38, lr: [0.005999550031641688], Loss: 2.068521, Acc:0.798634, Semantic loss: 0.776614, BCE loss: 0.547190, SB loss: 0.744717
2023-10-30 11:06:53,504 Epoch: [209/484] Iter:[330/495], Time: 0.38, lr: [0.0059991524310445835], Loss: 2.067871, Acc:0.799704, Semantic loss: 0.774818, BCE loss: 0.548524, SB loss: 0.744528
2023-10-30 11:06:57,233 Epoch: [209/484] Iter:[340/495], Time: 0.38, lr: [0.005998754827519521], Loss: 2.065263, Acc:0.799031, Semantic loss: 0.773813, BCE loss: 0.546753, SB loss: 0.744698
2023-10-30 11:07:00,925 Epoch: [209/484] Iter:[350/495], Time: 0.38, lr: [0.005998357221066265], Loss: 2.064576, Acc:0.799187, Semantic loss: 0.774169, BCE loss: 0.546200, SB loss: 0.744208
2023-10-30 11:07:04,619 Epoch: [209/484] Iter:[360/495], Time: 0.38, lr: [0.005997959611684576], Loss: 2.067544, Acc:0.798750, Semantic loss: 0.776443, BCE loss: 0.546139, SB loss: 0.744963
2023-10-30 11:07:08,270 Epoch: [209/484] Iter:[370/495], Time: 0.38, lr: [0.005997561999374215], Loss: 2.063775, Acc:0.798579, Semantic loss: 0.774863, BCE loss: 0.543723, SB loss: 0.745189
2023-10-30 11:07:11,952 Epoch: [209/484] Iter:[380/495], Time: 0.38, lr: [0.005997164384134949], Loss: 2.061328, Acc:0.797872, Semantic loss: 0.774419, BCE loss: 0.542125, SB loss: 0.744783
2023-10-30 11:07:15,572 Epoch: [209/484] Iter:[390/495], Time: 0.37, lr: [0.005996766765966537], Loss: 2.058405, Acc:0.797578, Semantic loss: 0.774021, BCE loss: 0.539876, SB loss: 0.744508
2023-10-30 11:07:19,327 Epoch: [209/484] Iter:[400/495], Time: 0.37, lr: [0.005996369144868745], Loss: 2.058924, Acc:0.797615, Semantic loss: 0.773510, BCE loss: 0.541065, SB loss: 0.744348
2023-10-30 11:07:23,010 Epoch: [209/484] Iter:[410/495], Time: 0.37, lr: [0.005995971520841334], Loss: 2.057081, Acc:0.797138, Semantic loss: 0.772851, BCE loss: 0.540730, SB loss: 0.743499
2023-10-30 11:07:26,741 Epoch: [209/484] Iter:[420/495], Time: 0.37, lr: [0.005995573893884065], Loss: 2.056336, Acc:0.797572, Semantic loss: 0.773744, BCE loss: 0.538850, SB loss: 0.743741
2023-10-30 11:07:30,627 Epoch: [209/484] Iter:[430/495], Time: 0.38, lr: [0.005995176263996703], Loss: 2.059895, Acc:0.797437, Semantic loss: 0.775108, BCE loss: 0.540239, SB loss: 0.744547
2023-10-30 11:07:34,344 Epoch: [209/484] Iter:[440/495], Time: 0.37, lr: [0.0059947786311790085], Loss: 2.064127, Acc:0.797645, Semantic loss: 0.776113, BCE loss: 0.541703, SB loss: 0.746311
2023-10-30 11:07:38,044 Epoch: [209/484] Iter:[450/495], Time: 0.37, lr: [0.005994380995430745], Loss: 2.064988, Acc:0.798252, Semantic loss: 0.775994, BCE loss: 0.542899, SB loss: 0.746095
2023-10-30 11:07:41,804 Epoch: [209/484] Iter:[460/495], Time: 0.37, lr: [0.005993983356751675], Loss: 2.061860, Acc:0.797935, Semantic loss: 0.774849, BCE loss: 0.541463, SB loss: 0.745548
2023-10-30 11:07:45,500 Epoch: [209/484] Iter:[470/495], Time: 0.37, lr: [0.005993585715141559], Loss: 2.060777, Acc:0.797422, Semantic loss: 0.774230, BCE loss: 0.541294, SB loss: 0.745253
2023-10-30 11:07:49,106 Epoch: [209/484] Iter:[480/495], Time: 0.37, lr: [0.005993188070600163], Loss: 2.062490, Acc:0.797003, Semantic loss: 0.775870, BCE loss: 0.541232, SB loss: 0.745388
2023-10-30 11:07:52,693 Epoch: [209/484] Iter:[490/495], Time: 0.37, lr: [0.0059927904231272455], Loss: 2.059222, Acc:0.797272, Semantic loss: 0.774772, BCE loss: 0.540051, SB loss: 0.744399
2023-10-30 11:07:54,117 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:07:54,350 Loss: 2.055, MeanIU:  0.6706, Best_mIoU:  0.7072
2023-10-30 11:07:54,350 [0.97694278 0.82513935 0.90139325 0.39191296 0.5533309  0.54583257
 0.66086884 0.72853547 0.91124365 0.60650289 0.93096679 0.77837326
 0.58322553 0.92314359 0.47888433 0.66356938 0.15804281 0.41120298
 0.71275088]
2023-10-30 11:07:56,465 Epoch: [210/484] Iter:[0/495], Time: 2.08, lr: [0.005992591598291394], Loss: 2.354304, Acc:0.832797, Semantic loss: 0.800999, BCE loss: 0.818283, SB loss: 0.735021
2023-10-30 11:08:00,489 Epoch: [210/484] Iter:[10/495], Time: 0.55, lr: [0.005992193946420752], Loss: 1.964606, Acc:0.807186, Semantic loss: 0.715824, BCE loss: 0.546013, SB loss: 0.702769
2023-10-30 11:08:04,054 Epoch: [210/484] Iter:[20/495], Time: 0.46, lr: [0.005991796291617996], Loss: 1.984004, Acc:0.800774, Semantic loss: 0.730079, BCE loss: 0.537743, SB loss: 0.716181
2023-10-30 11:08:07,648 Epoch: [210/484] Iter:[30/495], Time: 0.43, lr: [0.0059913986338828865], Loss: 1.969418, Acc:0.796575, Semantic loss: 0.730293, BCE loss: 0.528642, SB loss: 0.710483
2023-10-30 11:08:11,311 Epoch: [210/484] Iter:[40/495], Time: 0.41, lr: [0.005991000973215188], Loss: 1.973796, Acc:0.791126, Semantic loss: 0.735528, BCE loss: 0.526832, SB loss: 0.711436
2023-10-30 11:08:15,015 Epoch: [210/484] Iter:[50/495], Time: 0.40, lr: [0.005990603309614661], Loss: 1.992985, Acc:0.795967, Semantic loss: 0.752930, BCE loss: 0.524639, SB loss: 0.715415
2023-10-30 11:08:18,753 Epoch: [210/484] Iter:[60/495], Time: 0.40, lr: [0.005990205643081068], Loss: 2.014820, Acc:0.796674, Semantic loss: 0.757751, BCE loss: 0.532584, SB loss: 0.724485
2023-10-30 11:08:22,389 Epoch: [210/484] Iter:[70/495], Time: 0.39, lr: [0.005989807973614173], Loss: 2.008358, Acc:0.799837, Semantic loss: 0.754687, BCE loss: 0.528014, SB loss: 0.725657
2023-10-30 11:08:26,049 Epoch: [210/484] Iter:[80/495], Time: 0.39, lr: [0.005989410301213735], Loss: 2.000073, Acc:0.801207, Semantic loss: 0.748019, BCE loss: 0.527514, SB loss: 0.724539
2023-10-30 11:08:29,755 Epoch: [210/484] Iter:[90/495], Time: 0.39, lr: [0.005989012625879518], Loss: 2.027031, Acc:0.802998, Semantic loss: 0.755420, BCE loss: 0.538270, SB loss: 0.733341
2023-10-30 11:08:33,482 Epoch: [210/484] Iter:[100/495], Time: 0.39, lr: [0.005988614947611282], Loss: 2.021715, Acc:0.798946, Semantic loss: 0.754972, BCE loss: 0.531979, SB loss: 0.734764
2023-10-30 11:08:37,174 Epoch: [210/484] Iter:[110/495], Time: 0.39, lr: [0.005988217266408789], Loss: 2.036318, Acc:0.796155, Semantic loss: 0.766297, BCE loss: 0.530231, SB loss: 0.739790
2023-10-30 11:08:40,983 Epoch: [210/484] Iter:[120/495], Time: 0.39, lr: [0.005987819582271803], Loss: 2.033338, Acc:0.797362, Semantic loss: 0.762820, BCE loss: 0.531110, SB loss: 0.739409
2023-10-30 11:08:44,784 Epoch: [210/484] Iter:[130/495], Time: 0.38, lr: [0.005987421895200084], Loss: 2.036344, Acc:0.795909, Semantic loss: 0.763899, BCE loss: 0.532869, SB loss: 0.739576
2023-10-30 11:08:48,546 Epoch: [210/484] Iter:[140/495], Time: 0.38, lr: [0.005987024205193393], Loss: 2.032395, Acc:0.797226, Semantic loss: 0.762815, BCE loss: 0.531330, SB loss: 0.738250
2023-10-30 11:08:52,296 Epoch: [210/484] Iter:[150/495], Time: 0.38, lr: [0.005986626512251495], Loss: 2.033474, Acc:0.798940, Semantic loss: 0.762171, BCE loss: 0.533210, SB loss: 0.738092
2023-10-30 11:08:55,955 Epoch: [210/484] Iter:[160/495], Time: 0.38, lr: [0.005986228816374149], Loss: 2.036067, Acc:0.797838, Semantic loss: 0.762205, BCE loss: 0.534740, SB loss: 0.739122
2023-10-30 11:08:59,691 Epoch: [210/484] Iter:[170/495], Time: 0.38, lr: [0.005985831117561118], Loss: 2.044580, Acc:0.797953, Semantic loss: 0.765918, BCE loss: 0.536011, SB loss: 0.742650
2023-10-30 11:09:03,379 Epoch: [210/484] Iter:[180/495], Time: 0.38, lr: [0.0059854334158121626], Loss: 2.041380, Acc:0.797795, Semantic loss: 0.764707, BCE loss: 0.535873, SB loss: 0.740799
2023-10-30 11:09:07,060 Epoch: [210/484] Iter:[190/495], Time: 0.38, lr: [0.005985035711127042], Loss: 2.045041, Acc:0.797145, Semantic loss: 0.767616, BCE loss: 0.535583, SB loss: 0.741841
2023-10-30 11:09:10,887 Epoch: [210/484] Iter:[200/495], Time: 0.38, lr: [0.005984638003505524], Loss: 2.049039, Acc:0.795641, Semantic loss: 0.767558, BCE loss: 0.540282, SB loss: 0.741198
2023-10-30 11:09:14,614 Epoch: [210/484] Iter:[210/495], Time: 0.38, lr: [0.0059842402929473635], Loss: 2.049093, Acc:0.796992, Semantic loss: 0.768801, BCE loss: 0.538766, SB loss: 0.741526
2023-10-30 11:09:18,372 Epoch: [210/484] Iter:[220/495], Time: 0.38, lr: [0.005983842579452327], Loss: 2.052367, Acc:0.796871, Semantic loss: 0.767394, BCE loss: 0.540502, SB loss: 0.744471
2023-10-30 11:09:22,120 Epoch: [210/484] Iter:[230/495], Time: 0.38, lr: [0.005983444863020174], Loss: 2.050612, Acc:0.796605, Semantic loss: 0.767835, BCE loss: 0.538926, SB loss: 0.743851
2023-10-30 11:09:25,934 Epoch: [210/484] Iter:[240/495], Time: 0.38, lr: [0.005983047143650665], Loss: 2.049164, Acc:0.797862, Semantic loss: 0.766678, BCE loss: 0.537909, SB loss: 0.744577
2023-10-30 11:09:29,656 Epoch: [210/484] Iter:[250/495], Time: 0.38, lr: [0.005982649421343562], Loss: 2.052510, Acc:0.798617, Semantic loss: 0.768121, BCE loss: 0.539820, SB loss: 0.744568
2023-10-30 11:09:33,339 Epoch: [210/484] Iter:[260/495], Time: 0.38, lr: [0.005982251696098628], Loss: 2.055065, Acc:0.797987, Semantic loss: 0.768509, BCE loss: 0.542304, SB loss: 0.744251
2023-10-30 11:09:36,990 Epoch: [210/484] Iter:[270/495], Time: 0.38, lr: [0.005981853967915619], Loss: 2.055841, Acc:0.797882, Semantic loss: 0.768435, BCE loss: 0.542653, SB loss: 0.744753
2023-10-30 11:09:40,707 Epoch: [210/484] Iter:[280/495], Time: 0.38, lr: [0.0059814562367943025], Loss: 2.052466, Acc:0.798675, Semantic loss: 0.766105, BCE loss: 0.542181, SB loss: 0.744179
2023-10-30 11:09:44,465 Epoch: [210/484] Iter:[290/495], Time: 0.38, lr: [0.005981058502734437], Loss: 2.048049, Acc:0.798462, Semantic loss: 0.763727, BCE loss: 0.541102, SB loss: 0.743220
2023-10-30 11:09:48,178 Epoch: [210/484] Iter:[300/495], Time: 0.38, lr: [0.0059806607657357826], Loss: 2.044959, Acc:0.799436, Semantic loss: 0.761433, BCE loss: 0.541389, SB loss: 0.742137
2023-10-30 11:09:51,906 Epoch: [210/484] Iter:[310/495], Time: 0.38, lr: [0.005980263025798103], Loss: 2.041920, Acc:0.800184, Semantic loss: 0.759337, BCE loss: 0.541577, SB loss: 0.741005
2023-10-30 11:09:55,708 Epoch: [210/484] Iter:[320/495], Time: 0.38, lr: [0.005979865282921158], Loss: 2.044191, Acc:0.799854, Semantic loss: 0.761265, BCE loss: 0.541168, SB loss: 0.741759
2023-10-30 11:09:59,526 Epoch: [210/484] Iter:[330/495], Time: 0.38, lr: [0.005979467537104708], Loss: 2.039605, Acc:0.801009, Semantic loss: 0.758869, BCE loss: 0.539488, SB loss: 0.741249
2023-10-30 11:10:03,232 Epoch: [210/484] Iter:[340/495], Time: 0.38, lr: [0.005979069788348515], Loss: 2.043018, Acc:0.801196, Semantic loss: 0.761313, BCE loss: 0.539247, SB loss: 0.742459
2023-10-30 11:10:07,024 Epoch: [210/484] Iter:[350/495], Time: 0.38, lr: [0.005978672036652338], Loss: 2.041776, Acc:0.800437, Semantic loss: 0.761238, BCE loss: 0.537789, SB loss: 0.742749
2023-10-30 11:10:10,777 Epoch: [210/484] Iter:[360/495], Time: 0.38, lr: [0.0059782742820159405], Loss: 2.043568, Acc:0.799688, Semantic loss: 0.763182, BCE loss: 0.536941, SB loss: 0.743445
2023-10-30 11:10:14,477 Epoch: [210/484] Iter:[370/495], Time: 0.38, lr: [0.0059778765244390825], Loss: 2.041669, Acc:0.798964, Semantic loss: 0.762696, BCE loss: 0.535488, SB loss: 0.743485
2023-10-30 11:10:18,089 Epoch: [210/484] Iter:[380/495], Time: 0.38, lr: [0.005977478763921525], Loss: 2.042494, Acc:0.798955, Semantic loss: 0.763167, BCE loss: 0.535403, SB loss: 0.743924
2023-10-30 11:10:21,827 Epoch: [210/484] Iter:[390/495], Time: 0.38, lr: [0.0059770810004630285], Loss: 2.047752, Acc:0.798124, Semantic loss: 0.766658, BCE loss: 0.536103, SB loss: 0.744992
2023-10-30 11:10:25,541 Epoch: [210/484] Iter:[400/495], Time: 0.38, lr: [0.005976683234063354], Loss: 2.045774, Acc:0.797724, Semantic loss: 0.766281, BCE loss: 0.535209, SB loss: 0.744284
2023-10-30 11:10:29,185 Epoch: [210/484] Iter:[410/495], Time: 0.38, lr: [0.005976285464722262], Loss: 2.042881, Acc:0.797556, Semantic loss: 0.765443, BCE loss: 0.533685, SB loss: 0.743752
2023-10-30 11:10:32,822 Epoch: [210/484] Iter:[420/495], Time: 0.38, lr: [0.005975887692439514], Loss: 2.045903, Acc:0.797578, Semantic loss: 0.766300, BCE loss: 0.535550, SB loss: 0.744053
2023-10-30 11:10:36,527 Epoch: [210/484] Iter:[430/495], Time: 0.38, lr: [0.005975489917214868], Loss: 2.045650, Acc:0.797826, Semantic loss: 0.766056, BCE loss: 0.536424, SB loss: 0.743170
2023-10-30 11:10:40,300 Epoch: [210/484] Iter:[440/495], Time: 0.38, lr: [0.005975092139048087], Loss: 2.050539, Acc:0.798306, Semantic loss: 0.767330, BCE loss: 0.539028, SB loss: 0.744181
2023-10-30 11:10:43,997 Epoch: [210/484] Iter:[450/495], Time: 0.38, lr: [0.005974694357938932], Loss: 2.051607, Acc:0.798936, Semantic loss: 0.767927, BCE loss: 0.539060, SB loss: 0.744620
2023-10-30 11:10:47,686 Epoch: [210/484] Iter:[460/495], Time: 0.38, lr: [0.005974296573887164], Loss: 2.050407, Acc:0.799013, Semantic loss: 0.767888, BCE loss: 0.537819, SB loss: 0.744700
2023-10-30 11:10:51,536 Epoch: [210/484] Iter:[470/495], Time: 0.38, lr: [0.005973898786892541], Loss: 2.053052, Acc:0.798208, Semantic loss: 0.770170, BCE loss: 0.537699, SB loss: 0.745183
2023-10-30 11:10:55,175 Epoch: [210/484] Iter:[480/495], Time: 0.38, lr: [0.005973500996954825], Loss: 2.050733, Acc:0.798729, Semantic loss: 0.768490, BCE loss: 0.537298, SB loss: 0.744945
2023-10-30 11:10:58,688 Epoch: [210/484] Iter:[490/495], Time: 0.38, lr: [0.005973103204073777], Loss: 2.051385, Acc:0.798639, Semantic loss: 0.770010, BCE loss: 0.536640, SB loss: 0.744735
2023-10-30 11:13:56,089 0 [9.33053552e-01 6.40213355e-01 8.20655773e-01 1.56623573e-01
 2.84883887e-01 4.29592321e-01 3.56782445e-01 5.79989644e-01
 8.80863858e-01 4.80685600e-01 8.40671399e-01 5.88795426e-01
 6.02502696e-03 8.23203919e-01 8.22858778e-04 5.10567044e-02
 3.18476067e-02 3.99160623e-02 6.02699102e-01] 0.44991484812851484
2023-10-30 11:13:56,089 1 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445] 0.7128819437206007
2023-10-30 11:13:56,093 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:13:56,460 Loss: 1.940, MeanIU:  0.7129, Best_mIoU:  0.7129
2023-10-30 11:13:56,460 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445]
2023-10-30 11:13:58,622 Epoch: [211/484] Iter:[0/495], Time: 2.13, lr: [0.005972904306529429], Loss: 2.314611, Acc:0.799702, Semantic loss: 0.781576, BCE loss: 0.878165, SB loss: 0.654870
2023-10-30 11:14:02,351 Epoch: [211/484] Iter:[10/495], Time: 0.53, lr: [0.005972506509232931], Loss: 2.130388, Acc:0.817449, Semantic loss: 0.753293, BCE loss: 0.647423, SB loss: 0.729672
2023-10-30 11:14:05,945 Epoch: [211/484] Iter:[20/495], Time: 0.45, lr: [0.005972108708992503], Loss: 2.080223, Acc:0.821592, Semantic loss: 0.757926, BCE loss: 0.582296, SB loss: 0.740002
2023-10-30 11:14:09,524 Epoch: [211/484] Iter:[30/495], Time: 0.42, lr: [0.0059717109058079025], Loss: 2.103679, Acc:0.812576, Semantic loss: 0.776448, BCE loss: 0.576360, SB loss: 0.750871
2023-10-30 11:14:12,994 Epoch: [211/484] Iter:[40/495], Time: 0.40, lr: [0.0059713130996788925], Loss: 2.088358, Acc:0.812532, Semantic loss: 0.777765, BCE loss: 0.567895, SB loss: 0.742698
2023-10-30 11:14:16,552 Epoch: [211/484] Iter:[50/495], Time: 0.39, lr: [0.005970915290605231], Loss: 2.076068, Acc:0.815850, Semantic loss: 0.772287, BCE loss: 0.560891, SB loss: 0.742890
2023-10-30 11:14:20,052 Epoch: [211/484] Iter:[60/495], Time: 0.39, lr: [0.005970517478586679], Loss: 2.064385, Acc:0.810907, Semantic loss: 0.768319, BCE loss: 0.555231, SB loss: 0.740835
2023-10-30 11:14:23,632 Epoch: [211/484] Iter:[70/495], Time: 0.38, lr: [0.005970119663622997], Loss: 2.058946, Acc:0.802996, Semantic loss: 0.768367, BCE loss: 0.553034, SB loss: 0.737545
2023-10-30 11:14:27,160 Epoch: [211/484] Iter:[80/495], Time: 0.38, lr: [0.005969721845713943], Loss: 2.068560, Acc:0.801457, Semantic loss: 0.777278, BCE loss: 0.551394, SB loss: 0.739889
2023-10-30 11:14:30,737 Epoch: [211/484] Iter:[90/495], Time: 0.38, lr: [0.00596932402485928], Loss: 2.077323, Acc:0.799248, Semantic loss: 0.784967, BCE loss: 0.549818, SB loss: 0.742538
2023-10-30 11:14:34,294 Epoch: [211/484] Iter:[100/495], Time: 0.37, lr: [0.005968926201058767], Loss: 2.080293, Acc:0.803696, Semantic loss: 0.784516, BCE loss: 0.552921, SB loss: 0.742856
2023-10-30 11:14:37,952 Epoch: [211/484] Iter:[110/495], Time: 0.37, lr: [0.005968528374312164], Loss: 2.069226, Acc:0.803598, Semantic loss: 0.780495, BCE loss: 0.547670, SB loss: 0.741062
2023-10-30 11:14:41,493 Epoch: [211/484] Iter:[120/495], Time: 0.37, lr: [0.00596813054461923], Loss: 2.062161, Acc:0.803988, Semantic loss: 0.779202, BCE loss: 0.544265, SB loss: 0.738694
2023-10-30 11:14:45,267 Epoch: [211/484] Iter:[130/495], Time: 0.37, lr: [0.005967732711979727], Loss: 2.060019, Acc:0.804004, Semantic loss: 0.775195, BCE loss: 0.545357, SB loss: 0.739467
2023-10-30 11:14:48,874 Epoch: [211/484] Iter:[140/495], Time: 0.37, lr: [0.005967334876393413], Loss: 2.072566, Acc:0.804445, Semantic loss: 0.782703, BCE loss: 0.546739, SB loss: 0.743124
2023-10-30 11:14:52,409 Epoch: [211/484] Iter:[150/495], Time: 0.37, lr: [0.00596693703786005], Loss: 2.070506, Acc:0.803539, Semantic loss: 0.780621, BCE loss: 0.548152, SB loss: 0.741733
2023-10-30 11:14:56,053 Epoch: [211/484] Iter:[160/495], Time: 0.37, lr: [0.005966539196379396], Loss: 2.059021, Acc:0.802506, Semantic loss: 0.775469, BCE loss: 0.543464, SB loss: 0.740087
2023-10-30 11:14:59,665 Epoch: [211/484] Iter:[170/495], Time: 0.37, lr: [0.00596614135195121], Loss: 2.054275, Acc:0.803938, Semantic loss: 0.772140, BCE loss: 0.544298, SB loss: 0.737837
2023-10-30 11:15:03,321 Epoch: [211/484] Iter:[180/495], Time: 0.37, lr: [0.005965743504575254], Loss: 2.061513, Acc:0.803739, Semantic loss: 0.778186, BCE loss: 0.543067, SB loss: 0.740260
2023-10-30 11:15:07,066 Epoch: [211/484] Iter:[190/495], Time: 0.37, lr: [0.0059653456542512855], Loss: 2.058796, Acc:0.805444, Semantic loss: 0.774419, BCE loss: 0.544914, SB loss: 0.739462
2023-10-30 11:15:10,753 Epoch: [211/484] Iter:[200/495], Time: 0.37, lr: [0.005964947800979067], Loss: 2.055908, Acc:0.803580, Semantic loss: 0.772035, BCE loss: 0.544584, SB loss: 0.739289
2023-10-30 11:15:14,362 Epoch: [211/484] Iter:[210/495], Time: 0.37, lr: [0.005964549944758357], Loss: 2.058057, Acc:0.803497, Semantic loss: 0.775799, BCE loss: 0.541825, SB loss: 0.740434
2023-10-30 11:15:18,029 Epoch: [211/484] Iter:[220/495], Time: 0.37, lr: [0.005964152085588914], Loss: 2.056943, Acc:0.804238, Semantic loss: 0.775188, BCE loss: 0.542248, SB loss: 0.739507
2023-10-30 11:15:21,688 Epoch: [211/484] Iter:[230/495], Time: 0.37, lr: [0.005963754223470499], Loss: 2.052518, Acc:0.803684, Semantic loss: 0.775195, BCE loss: 0.539639, SB loss: 0.737684
2023-10-30 11:15:25,255 Epoch: [211/484] Iter:[240/495], Time: 0.37, lr: [0.00596335635840287], Loss: 2.052503, Acc:0.804434, Semantic loss: 0.773936, BCE loss: 0.540997, SB loss: 0.737569
2023-10-30 11:15:28,966 Epoch: [211/484] Iter:[250/495], Time: 0.37, lr: [0.005962958490385788], Loss: 2.047872, Acc:0.805739, Semantic loss: 0.771685, BCE loss: 0.539914, SB loss: 0.736272
2023-10-30 11:15:32,563 Epoch: [211/484] Iter:[260/495], Time: 0.37, lr: [0.005962560619419012], Loss: 2.051602, Acc:0.805691, Semantic loss: 0.770488, BCE loss: 0.544571, SB loss: 0.736543
2023-10-30 11:15:36,264 Epoch: [211/484] Iter:[270/495], Time: 0.37, lr: [0.0059621627455023], Loss: 2.049270, Acc:0.807100, Semantic loss: 0.769327, BCE loss: 0.543525, SB loss: 0.736418
2023-10-30 11:15:39,894 Epoch: [211/484] Iter:[280/495], Time: 0.37, lr: [0.005961764868635413], Loss: 2.053229, Acc:0.806546, Semantic loss: 0.770923, BCE loss: 0.545570, SB loss: 0.736737
2023-10-30 11:15:43,543 Epoch: [211/484] Iter:[290/495], Time: 0.37, lr: [0.0059613669888181125], Loss: 2.047637, Acc:0.806304, Semantic loss: 0.768664, BCE loss: 0.543647, SB loss: 0.735326
2023-10-30 11:15:47,210 Epoch: [211/484] Iter:[300/495], Time: 0.37, lr: [0.005960969106050152], Loss: 2.047708, Acc:0.807147, Semantic loss: 0.768718, BCE loss: 0.543164, SB loss: 0.735826
2023-10-30 11:15:50,900 Epoch: [211/484] Iter:[310/495], Time: 0.37, lr: [0.005960571220331297], Loss: 2.047418, Acc:0.806646, Semantic loss: 0.767531, BCE loss: 0.543124, SB loss: 0.736763
2023-10-30 11:15:54,512 Epoch: [211/484] Iter:[320/495], Time: 0.37, lr: [0.005960173331661303], Loss: 2.050330, Acc:0.806149, Semantic loss: 0.769165, BCE loss: 0.543481, SB loss: 0.737683
2023-10-30 11:15:58,233 Epoch: [211/484] Iter:[330/495], Time: 0.37, lr: [0.005959775440039929], Loss: 2.049086, Acc:0.805829, Semantic loss: 0.768206, BCE loss: 0.542796, SB loss: 0.738083
2023-10-30 11:16:01,943 Epoch: [211/484] Iter:[340/495], Time: 0.37, lr: [0.0059593775454669365], Loss: 2.051993, Acc:0.805278, Semantic loss: 0.769080, BCE loss: 0.543804, SB loss: 0.739109
2023-10-30 11:16:05,657 Epoch: [211/484] Iter:[350/495], Time: 0.37, lr: [0.0059589796479420825], Loss: 2.049926, Acc:0.804830, Semantic loss: 0.768696, BCE loss: 0.542517, SB loss: 0.738713
2023-10-30 11:16:09,426 Epoch: [211/484] Iter:[360/495], Time: 0.37, lr: [0.005958581747465127], Loss: 2.049655, Acc:0.804422, Semantic loss: 0.769205, BCE loss: 0.541795, SB loss: 0.738654
2023-10-30 11:16:13,082 Epoch: [211/484] Iter:[370/495], Time: 0.37, lr: [0.00595818384403583], Loss: 2.054937, Acc:0.804148, Semantic loss: 0.772276, BCE loss: 0.542937, SB loss: 0.739724
2023-10-30 11:16:16,785 Epoch: [211/484] Iter:[380/495], Time: 0.37, lr: [0.005957785937653949], Loss: 2.056024, Acc:0.803233, Semantic loss: 0.772390, BCE loss: 0.543906, SB loss: 0.739728
2023-10-30 11:16:20,404 Epoch: [211/484] Iter:[390/495], Time: 0.37, lr: [0.005957388028319244], Loss: 2.053505, Acc:0.803408, Semantic loss: 0.770719, BCE loss: 0.543392, SB loss: 0.739394
2023-10-30 11:16:24,038 Epoch: [211/484] Iter:[400/495], Time: 0.37, lr: [0.005956990116031473], Loss: 2.057334, Acc:0.802377, Semantic loss: 0.774010, BCE loss: 0.542875, SB loss: 0.740448
2023-10-30 11:16:27,643 Epoch: [211/484] Iter:[410/495], Time: 0.37, lr: [0.005956592200790395], Loss: 2.055883, Acc:0.802530, Semantic loss: 0.773237, BCE loss: 0.541889, SB loss: 0.740757
2023-10-30 11:16:31,345 Epoch: [211/484] Iter:[420/495], Time: 0.37, lr: [0.00595619428259577], Loss: 2.059686, Acc:0.802507, Semantic loss: 0.776972, BCE loss: 0.541212, SB loss: 0.741502
2023-10-30 11:16:35,023 Epoch: [211/484] Iter:[430/495], Time: 0.37, lr: [0.005955796361447356], Loss: 2.056943, Acc:0.801610, Semantic loss: 0.775311, BCE loss: 0.540132, SB loss: 0.741500
2023-10-30 11:16:38,687 Epoch: [211/484] Iter:[440/495], Time: 0.37, lr: [0.005955398437344911], Loss: 2.058144, Acc:0.802059, Semantic loss: 0.775712, BCE loss: 0.540601, SB loss: 0.741830
2023-10-30 11:16:42,443 Epoch: [211/484] Iter:[450/495], Time: 0.37, lr: [0.005955000510288196], Loss: 2.058789, Acc:0.801941, Semantic loss: 0.776128, BCE loss: 0.540641, SB loss: 0.742019
2023-10-30 11:16:46,103 Epoch: [211/484] Iter:[460/495], Time: 0.37, lr: [0.005954602580276968], Loss: 2.060595, Acc:0.801224, Semantic loss: 0.777801, BCE loss: 0.539310, SB loss: 0.743484
2023-10-30 11:16:49,885 Epoch: [211/484] Iter:[470/495], Time: 0.37, lr: [0.0059542046473109855], Loss: 2.064156, Acc:0.801531, Semantic loss: 0.778864, BCE loss: 0.540590, SB loss: 0.744702
2023-10-30 11:16:53,521 Epoch: [211/484] Iter:[480/495], Time: 0.37, lr: [0.0059538067113900075], Loss: 2.066582, Acc:0.802065, Semantic loss: 0.778840, BCE loss: 0.541989, SB loss: 0.745753
2023-10-30 11:16:57,000 Epoch: [211/484] Iter:[490/495], Time: 0.37, lr: [0.005953408772513793], Loss: 2.066878, Acc:0.800508, Semantic loss: 0.779447, BCE loss: 0.540243, SB loss: 0.747188
2023-10-30 11:16:58,404 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:16:58,642 Loss: 1.940, MeanIU:  0.7129, Best_mIoU:  0.7129
2023-10-30 11:16:58,642 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445]
2023-10-30 11:17:00,798 Epoch: [212/484] Iter:[0/495], Time: 2.12, lr: [0.005953209801967397], Loss: 2.391505, Acc:0.846340, Semantic loss: 0.875883, BCE loss: 0.651295, SB loss: 0.864326
2023-10-30 11:17:04,885 Epoch: [212/484] Iter:[10/495], Time: 0.56, lr: [0.005952811858657874], Loss: 2.266332, Acc:0.794311, Semantic loss: 0.863608, BCE loss: 0.577562, SB loss: 0.825161
2023-10-30 11:17:08,619 Epoch: [212/484] Iter:[20/495], Time: 0.47, lr: [0.005952413912392512], Loss: 2.166936, Acc:0.780638, Semantic loss: 0.800888, BCE loss: 0.566123, SB loss: 0.799925
2023-10-30 11:17:12,230 Epoch: [212/484] Iter:[30/495], Time: 0.44, lr: [0.005952015963171068], Loss: 2.079756, Acc:0.789693, Semantic loss: 0.764186, BCE loss: 0.545776, SB loss: 0.769794
2023-10-30 11:17:15,904 Epoch: [212/484] Iter:[40/495], Time: 0.42, lr: [0.0059516180109933006], Loss: 2.097456, Acc:0.790492, Semantic loss: 0.772844, BCE loss: 0.548975, SB loss: 0.775638
2023-10-30 11:17:19,602 Epoch: [212/484] Iter:[50/495], Time: 0.41, lr: [0.005951220055858968], Loss: 2.063497, Acc:0.803060, Semantic loss: 0.757682, BCE loss: 0.542827, SB loss: 0.762988
2023-10-30 11:17:23,384 Epoch: [212/484] Iter:[60/495], Time: 0.41, lr: [0.00595082209776783], Loss: 2.069453, Acc:0.805148, Semantic loss: 0.765776, BCE loss: 0.544556, SB loss: 0.759121
2023-10-30 11:17:27,010 Epoch: [212/484] Iter:[70/495], Time: 0.40, lr: [0.005950424136719641], Loss: 2.068340, Acc:0.799698, Semantic loss: 0.773000, BCE loss: 0.535370, SB loss: 0.759970
2023-10-30 11:17:30,723 Epoch: [212/484] Iter:[80/495], Time: 0.40, lr: [0.005950026172714164], Loss: 2.068725, Acc:0.801643, Semantic loss: 0.770083, BCE loss: 0.541342, SB loss: 0.757300
2023-10-30 11:17:34,323 Epoch: [212/484] Iter:[90/495], Time: 0.39, lr: [0.005949628205751153], Loss: 2.076492, Acc:0.800762, Semantic loss: 0.778401, BCE loss: 0.541533, SB loss: 0.756557
2023-10-30 11:17:38,085 Epoch: [212/484] Iter:[100/495], Time: 0.39, lr: [0.00594923023583037], Loss: 2.075619, Acc:0.797426, Semantic loss: 0.780117, BCE loss: 0.543027, SB loss: 0.752475
2023-10-30 11:17:41,844 Epoch: [212/484] Iter:[110/495], Time: 0.39, lr: [0.005948832262951571], Loss: 2.066815, Acc:0.798380, Semantic loss: 0.773636, BCE loss: 0.542716, SB loss: 0.750463
2023-10-30 11:17:45,472 Epoch: [212/484] Iter:[120/495], Time: 0.39, lr: [0.005948434287114515], Loss: 2.060141, Acc:0.797545, Semantic loss: 0.771154, BCE loss: 0.538338, SB loss: 0.750650
2023-10-30 11:17:49,204 Epoch: [212/484] Iter:[130/495], Time: 0.39, lr: [0.005948036308318959], Loss: 2.062841, Acc:0.797404, Semantic loss: 0.774277, BCE loss: 0.538887, SB loss: 0.749677
2023-10-30 11:17:52,926 Epoch: [212/484] Iter:[140/495], Time: 0.38, lr: [0.005947638326564664], Loss: 2.060473, Acc:0.796191, Semantic loss: 0.775149, BCE loss: 0.537069, SB loss: 0.748256
2023-10-30 11:17:56,674 Epoch: [212/484] Iter:[150/495], Time: 0.38, lr: [0.0059472403418513835], Loss: 2.062483, Acc:0.797423, Semantic loss: 0.776564, BCE loss: 0.538467, SB loss: 0.747453
2023-10-30 11:18:00,413 Epoch: [212/484] Iter:[160/495], Time: 0.38, lr: [0.005946842354178879], Loss: 2.065911, Acc:0.797221, Semantic loss: 0.775920, BCE loss: 0.539785, SB loss: 0.750207
2023-10-30 11:18:04,224 Epoch: [212/484] Iter:[170/495], Time: 0.38, lr: [0.005946444363546906], Loss: 2.065590, Acc:0.796752, Semantic loss: 0.777037, BCE loss: 0.536427, SB loss: 0.752126
2023-10-30 11:18:08,006 Epoch: [212/484] Iter:[180/495], Time: 0.38, lr: [0.005946046369955224], Loss: 2.061401, Acc:0.797347, Semantic loss: 0.773643, BCE loss: 0.537429, SB loss: 0.750329
2023-10-30 11:18:11,845 Epoch: [212/484] Iter:[190/495], Time: 0.38, lr: [0.0059456483734035915], Loss: 2.057082, Acc:0.796224, Semantic loss: 0.772762, BCE loss: 0.535263, SB loss: 0.749057
2023-10-30 11:18:15,515 Epoch: [212/484] Iter:[200/495], Time: 0.38, lr: [0.005945250373891765], Loss: 2.061353, Acc:0.796237, Semantic loss: 0.776199, BCE loss: 0.536092, SB loss: 0.749061
2023-10-30 11:18:19,234 Epoch: [212/484] Iter:[210/495], Time: 0.38, lr: [0.005944852371419503], Loss: 2.065426, Acc:0.795301, Semantic loss: 0.779386, BCE loss: 0.536574, SB loss: 0.749466
2023-10-30 11:18:22,881 Epoch: [212/484] Iter:[220/495], Time: 0.38, lr: [0.005944454365986563], Loss: 2.069141, Acc:0.795807, Semantic loss: 0.780489, BCE loss: 0.538924, SB loss: 0.749728
2023-10-30 11:18:26,672 Epoch: [212/484] Iter:[230/495], Time: 0.38, lr: [0.005944056357592702], Loss: 2.062371, Acc:0.796582, Semantic loss: 0.779458, BCE loss: 0.535124, SB loss: 0.747789
2023-10-30 11:18:30,393 Epoch: [212/484] Iter:[240/495], Time: 0.38, lr: [0.005943658346237678], Loss: 2.062396, Acc:0.794222, Semantic loss: 0.781085, BCE loss: 0.534168, SB loss: 0.747144
2023-10-30 11:18:34,087 Epoch: [212/484] Iter:[250/495], Time: 0.38, lr: [0.005943260331921249], Loss: 2.059366, Acc:0.794020, Semantic loss: 0.779086, BCE loss: 0.533835, SB loss: 0.746445
2023-10-30 11:18:37,799 Epoch: [212/484] Iter:[260/495], Time: 0.38, lr: [0.005942862314643174], Loss: 2.053539, Acc:0.795438, Semantic loss: 0.776945, BCE loss: 0.531305, SB loss: 0.745289
2023-10-30 11:18:41,472 Epoch: [212/484] Iter:[270/495], Time: 0.38, lr: [0.005942464294403208], Loss: 2.051409, Acc:0.796899, Semantic loss: 0.774682, BCE loss: 0.531691, SB loss: 0.745036
2023-10-30 11:18:45,236 Epoch: [212/484] Iter:[280/495], Time: 0.38, lr: [0.0059420662712011095], Loss: 2.044355, Acc:0.797280, Semantic loss: 0.772111, BCE loss: 0.528739, SB loss: 0.743506
2023-10-30 11:18:48,900 Epoch: [212/484] Iter:[290/495], Time: 0.38, lr: [0.0059416682450366375], Loss: 2.046151, Acc:0.797641, Semantic loss: 0.773074, BCE loss: 0.529869, SB loss: 0.743209
2023-10-30 11:18:52,552 Epoch: [212/484] Iter:[300/495], Time: 0.38, lr: [0.0059412702159095465], Loss: 2.039678, Acc:0.797462, Semantic loss: 0.770791, BCE loss: 0.527099, SB loss: 0.741788
2023-10-30 11:18:56,305 Epoch: [212/484] Iter:[310/495], Time: 0.38, lr: [0.0059408721838195965], Loss: 2.040804, Acc:0.796804, Semantic loss: 0.773288, BCE loss: 0.525379, SB loss: 0.742137
2023-10-30 11:18:59,955 Epoch: [212/484] Iter:[320/495], Time: 0.38, lr: [0.005940474148766543], Loss: 2.037329, Acc:0.795867, Semantic loss: 0.772319, BCE loss: 0.523378, SB loss: 0.741632
2023-10-30 11:19:03,685 Epoch: [212/484] Iter:[330/495], Time: 0.38, lr: [0.005940076110750144], Loss: 2.036873, Acc:0.794587, Semantic loss: 0.770649, BCE loss: 0.524401, SB loss: 0.741823
2023-10-30 11:19:07,397 Epoch: [212/484] Iter:[340/495], Time: 0.38, lr: [0.005939678069770159], Loss: 2.037019, Acc:0.795252, Semantic loss: 0.769238, BCE loss: 0.525254, SB loss: 0.742527
2023-10-30 11:19:11,151 Epoch: [212/484] Iter:[350/495], Time: 0.38, lr: [0.005939280025826343], Loss: 2.040539, Acc:0.795698, Semantic loss: 0.769559, BCE loss: 0.528431, SB loss: 0.742550
2023-10-30 11:19:14,844 Epoch: [212/484] Iter:[360/495], Time: 0.38, lr: [0.005938881978918452], Loss: 2.040257, Acc:0.794431, Semantic loss: 0.769518, BCE loss: 0.528214, SB loss: 0.742524
2023-10-30 11:19:18,487 Epoch: [212/484] Iter:[370/495], Time: 0.38, lr: [0.005938483929046247], Loss: 2.039389, Acc:0.794815, Semantic loss: 0.768711, BCE loss: 0.528163, SB loss: 0.742514
2023-10-30 11:19:22,194 Epoch: [212/484] Iter:[380/495], Time: 0.38, lr: [0.005938085876209479], Loss: 2.037723, Acc:0.794452, Semantic loss: 0.768344, BCE loss: 0.526607, SB loss: 0.742772
2023-10-30 11:19:25,894 Epoch: [212/484] Iter:[390/495], Time: 0.38, lr: [0.005937687820407912], Loss: 2.039316, Acc:0.794693, Semantic loss: 0.768357, BCE loss: 0.528009, SB loss: 0.742950
2023-10-30 11:19:29,558 Epoch: [212/484] Iter:[400/495], Time: 0.38, lr: [0.005937289761641299], Loss: 2.041182, Acc:0.794587, Semantic loss: 0.768331, BCE loss: 0.530279, SB loss: 0.742571
2023-10-30 11:19:33,314 Epoch: [212/484] Iter:[410/495], Time: 0.38, lr: [0.005936891699909398], Loss: 2.043723, Acc:0.795035, Semantic loss: 0.770592, BCE loss: 0.530716, SB loss: 0.742415
2023-10-30 11:19:36,908 Epoch: [212/484] Iter:[420/495], Time: 0.38, lr: [0.005936493635211967], Loss: 2.043974, Acc:0.794365, Semantic loss: 0.771857, BCE loss: 0.529796, SB loss: 0.742321
2023-10-30 11:19:40,670 Epoch: [212/484] Iter:[430/495], Time: 0.38, lr: [0.005936095567548761], Loss: 2.045484, Acc:0.794351, Semantic loss: 0.773254, BCE loss: 0.529671, SB loss: 0.742559
2023-10-30 11:19:44,257 Epoch: [212/484] Iter:[440/495], Time: 0.38, lr: [0.0059356974969195396], Loss: 2.041761, Acc:0.793776, Semantic loss: 0.771944, BCE loss: 0.527850, SB loss: 0.741966
2023-10-30 11:19:48,025 Epoch: [212/484] Iter:[450/495], Time: 0.38, lr: [0.005935299423324058], Loss: 2.043705, Acc:0.793050, Semantic loss: 0.772863, BCE loss: 0.527808, SB loss: 0.743034
2023-10-30 11:19:51,703 Epoch: [212/484] Iter:[460/495], Time: 0.38, lr: [0.005934901346762071], Loss: 2.046058, Acc:0.793064, Semantic loss: 0.773608, BCE loss: 0.528625, SB loss: 0.743824
2023-10-30 11:19:55,385 Epoch: [212/484] Iter:[470/495], Time: 0.38, lr: [0.005934503267233339], Loss: 2.050928, Acc:0.793255, Semantic loss: 0.776808, BCE loss: 0.529193, SB loss: 0.744927
2023-10-30 11:19:59,063 Epoch: [212/484] Iter:[480/495], Time: 0.38, lr: [0.005934105184737616], Loss: 2.052473, Acc:0.793647, Semantic loss: 0.776848, BCE loss: 0.530767, SB loss: 0.744858
2023-10-30 11:20:02,620 Epoch: [212/484] Iter:[490/495], Time: 0.37, lr: [0.005933707099274661], Loss: 2.051512, Acc:0.793393, Semantic loss: 0.776385, BCE loss: 0.530798, SB loss: 0.744328
2023-10-30 11:20:04,031 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:20:04,275 Loss: 1.940, MeanIU:  0.7129, Best_mIoU:  0.7129
2023-10-30 11:20:04,275 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445]
2023-10-30 11:20:06,288 Epoch: [213/484] Iter:[0/495], Time: 1.99, lr: [0.005933508055430394], Loss: 2.521641, Acc:0.853357, Semantic loss: 1.172067, BCE loss: 0.443396, SB loss: 0.906178
2023-10-30 11:20:10,244 Epoch: [213/484] Iter:[10/495], Time: 0.54, lr: [0.005933109965516135], Loss: 2.010145, Acc:0.758235, Semantic loss: 0.755991, BCE loss: 0.482923, SB loss: 0.771231
2023-10-30 11:20:13,889 Epoch: [213/484] Iter:[20/495], Time: 0.46, lr: [0.005932711872634032], Loss: 1.990896, Acc:0.757227, Semantic loss: 0.741875, BCE loss: 0.492262, SB loss: 0.756758
2023-10-30 11:20:17,557 Epoch: [213/484] Iter:[30/495], Time: 0.43, lr: [0.005932313776783845], Loss: 1.992742, Acc:0.770092, Semantic loss: 0.753723, BCE loss: 0.492162, SB loss: 0.746856
2023-10-30 11:20:21,218 Epoch: [213/484] Iter:[40/495], Time: 0.41, lr: [0.005931915677965331], Loss: 2.026970, Acc:0.777993, Semantic loss: 0.771152, BCE loss: 0.501917, SB loss: 0.753901
2023-10-30 11:20:24,931 Epoch: [213/484] Iter:[50/495], Time: 0.40, lr: [0.005931517576178242], Loss: 2.026305, Acc:0.776756, Semantic loss: 0.765217, BCE loss: 0.511954, SB loss: 0.749135
2023-10-30 11:20:28,619 Epoch: [213/484] Iter:[60/495], Time: 0.40, lr: [0.005931119471422342], Loss: 2.019851, Acc:0.781292, Semantic loss: 0.765063, BCE loss: 0.511826, SB loss: 0.742962
2023-10-30 11:20:32,285 Epoch: [213/484] Iter:[70/495], Time: 0.39, lr: [0.00593072136369738], Loss: 2.034012, Acc:0.785389, Semantic loss: 0.764783, BCE loss: 0.527206, SB loss: 0.742023
2023-10-30 11:20:36,009 Epoch: [213/484] Iter:[80/495], Time: 0.39, lr: [0.005930323253003117], Loss: 2.037589, Acc:0.783996, Semantic loss: 0.765241, BCE loss: 0.528447, SB loss: 0.743901
2023-10-30 11:20:39,655 Epoch: [213/484] Iter:[90/495], Time: 0.39, lr: [0.005929925139339308], Loss: 2.034318, Acc:0.787794, Semantic loss: 0.761469, BCE loss: 0.531840, SB loss: 0.741009
2023-10-30 11:20:43,270 Epoch: [213/484] Iter:[100/495], Time: 0.39, lr: [0.005929527022705709], Loss: 2.025025, Acc:0.788001, Semantic loss: 0.758188, BCE loss: 0.526558, SB loss: 0.740279
2023-10-30 11:20:47,105 Epoch: [213/484] Iter:[110/495], Time: 0.39, lr: [0.005929128903102078], Loss: 2.033550, Acc:0.792677, Semantic loss: 0.759895, BCE loss: 0.532451, SB loss: 0.741204
2023-10-30 11:20:50,779 Epoch: [213/484] Iter:[120/495], Time: 0.38, lr: [0.005928730780528169], Loss: 2.050033, Acc:0.794634, Semantic loss: 0.765049, BCE loss: 0.541193, SB loss: 0.743791
2023-10-30 11:20:54,480 Epoch: [213/484] Iter:[130/495], Time: 0.38, lr: [0.005928332654983738], Loss: 2.053616, Acc:0.792769, Semantic loss: 0.769630, BCE loss: 0.538020, SB loss: 0.745966
2023-10-30 11:20:58,176 Epoch: [213/484] Iter:[140/495], Time: 0.38, lr: [0.0059279345264685425], Loss: 2.054760, Acc:0.795511, Semantic loss: 0.771505, BCE loss: 0.537083, SB loss: 0.746172
2023-10-30 11:21:01,899 Epoch: [213/484] Iter:[150/495], Time: 0.38, lr: [0.00592753639498234], Loss: 2.041470, Acc:0.795591, Semantic loss: 0.765662, BCE loss: 0.532747, SB loss: 0.743060
2023-10-30 11:21:05,696 Epoch: [213/484] Iter:[160/495], Time: 0.38, lr: [0.005927138260524885], Loss: 2.043539, Acc:0.794958, Semantic loss: 0.767690, BCE loss: 0.531708, SB loss: 0.744141
2023-10-30 11:21:09,349 Epoch: [213/484] Iter:[170/495], Time: 0.38, lr: [0.0059267401230959325], Loss: 2.050489, Acc:0.793532, Semantic loss: 0.772016, BCE loss: 0.534234, SB loss: 0.744238
2023-10-30 11:21:13,060 Epoch: [213/484] Iter:[180/495], Time: 0.38, lr: [0.00592634198269524], Loss: 2.047718, Acc:0.795238, Semantic loss: 0.770158, BCE loss: 0.535436, SB loss: 0.742124
2023-10-30 11:21:16,771 Epoch: [213/484] Iter:[190/495], Time: 0.38, lr: [0.005925943839322564], Loss: 2.054287, Acc:0.795036, Semantic loss: 0.775204, BCE loss: 0.536318, SB loss: 0.742765
2023-10-30 11:21:20,428 Epoch: [213/484] Iter:[200/495], Time: 0.38, lr: [0.005925545692977658], Loss: 2.056684, Acc:0.794445, Semantic loss: 0.777307, BCE loss: 0.534063, SB loss: 0.745314
2023-10-30 11:21:24,067 Epoch: [213/484] Iter:[210/495], Time: 0.38, lr: [0.0059251475436602795], Loss: 2.058673, Acc:0.794908, Semantic loss: 0.777068, BCE loss: 0.533551, SB loss: 0.748055
2023-10-30 11:21:27,661 Epoch: [213/484] Iter:[220/495], Time: 0.38, lr: [0.005924749391370185], Loss: 2.060810, Acc:0.795178, Semantic loss: 0.780194, BCE loss: 0.532209, SB loss: 0.748407
2023-10-30 11:21:31,344 Epoch: [213/484] Iter:[230/495], Time: 0.38, lr: [0.005924351236107131], Loss: 2.055701, Acc:0.795761, Semantic loss: 0.779025, BCE loss: 0.529556, SB loss: 0.747120
2023-10-30 11:21:35,124 Epoch: [213/484] Iter:[240/495], Time: 0.38, lr: [0.00592395307787087], Loss: 2.055565, Acc:0.796072, Semantic loss: 0.780003, BCE loss: 0.528842, SB loss: 0.746721
2023-10-30 11:21:38,827 Epoch: [213/484] Iter:[250/495], Time: 0.38, lr: [0.005923554916661161], Loss: 2.053730, Acc:0.796675, Semantic loss: 0.779161, BCE loss: 0.526920, SB loss: 0.747649
2023-10-30 11:21:42,498 Epoch: [213/484] Iter:[260/495], Time: 0.38, lr: [0.005923156752477759], Loss: 2.053335, Acc:0.797521, Semantic loss: 0.778839, BCE loss: 0.526868, SB loss: 0.747628
2023-10-30 11:21:46,214 Epoch: [213/484] Iter:[270/495], Time: 0.38, lr: [0.005922758585320418], Loss: 2.052955, Acc:0.798445, Semantic loss: 0.777717, BCE loss: 0.527486, SB loss: 0.747751
2023-10-30 11:21:49,849 Epoch: [213/484] Iter:[280/495], Time: 0.38, lr: [0.0059223604151888935], Loss: 2.047733, Acc:0.797892, Semantic loss: 0.775022, BCE loss: 0.527430, SB loss: 0.745281
2023-10-30 11:21:53,466 Epoch: [213/484] Iter:[290/495], Time: 0.38, lr: [0.005921962242082944], Loss: 2.045410, Acc:0.797335, Semantic loss: 0.773391, BCE loss: 0.527450, SB loss: 0.744570
2023-10-30 11:21:57,183 Epoch: [213/484] Iter:[300/495], Time: 0.37, lr: [0.005921564066002323], Loss: 2.045260, Acc:0.796879, Semantic loss: 0.773994, BCE loss: 0.526939, SB loss: 0.744326
2023-10-30 11:22:00,914 Epoch: [213/484] Iter:[310/495], Time: 0.37, lr: [0.005921165886946787], Loss: 2.046362, Acc:0.796850, Semantic loss: 0.774758, BCE loss: 0.526239, SB loss: 0.745365
2023-10-30 11:22:04,549 Epoch: [213/484] Iter:[320/495], Time: 0.37, lr: [0.00592076770491609], Loss: 2.038582, Acc:0.795247, Semantic loss: 0.771106, BCE loss: 0.523885, SB loss: 0.743591
2023-10-30 11:22:08,181 Epoch: [213/484] Iter:[330/495], Time: 0.37, lr: [0.005920369519909989], Loss: 2.041411, Acc:0.794196, Semantic loss: 0.773180, BCE loss: 0.524299, SB loss: 0.743932
2023-10-30 11:22:11,909 Epoch: [213/484] Iter:[340/495], Time: 0.37, lr: [0.00591997133192824], Loss: 2.035111, Acc:0.794959, Semantic loss: 0.769096, BCE loss: 0.523954, SB loss: 0.742061
2023-10-30 11:22:15,607 Epoch: [213/484] Iter:[350/495], Time: 0.37, lr: [0.005919573140970596], Loss: 2.035037, Acc:0.794793, Semantic loss: 0.769611, BCE loss: 0.523332, SB loss: 0.742094
2023-10-30 11:22:19,356 Epoch: [213/484] Iter:[360/495], Time: 0.37, lr: [0.005919174947036813], Loss: 2.036087, Acc:0.793835, Semantic loss: 0.770715, BCE loss: 0.522559, SB loss: 0.742813
2023-10-30 11:22:22,967 Epoch: [213/484] Iter:[370/495], Time: 0.37, lr: [0.005918776750126648], Loss: 2.035662, Acc:0.794267, Semantic loss: 0.770139, BCE loss: 0.522868, SB loss: 0.742656
2023-10-30 11:22:26,731 Epoch: [213/484] Iter:[380/495], Time: 0.37, lr: [0.005918378550239854], Loss: 2.036164, Acc:0.794152, Semantic loss: 0.769978, BCE loss: 0.523359, SB loss: 0.742827
2023-10-30 11:22:30,436 Epoch: [213/484] Iter:[390/495], Time: 0.37, lr: [0.0059179803473761875], Loss: 2.036878, Acc:0.794322, Semantic loss: 0.770927, BCE loss: 0.523320, SB loss: 0.742632
2023-10-30 11:22:34,136 Epoch: [213/484] Iter:[400/495], Time: 0.37, lr: [0.005917582141535403], Loss: 2.041521, Acc:0.794428, Semantic loss: 0.773559, BCE loss: 0.524022, SB loss: 0.743939
2023-10-30 11:22:37,846 Epoch: [213/484] Iter:[410/495], Time: 0.37, lr: [0.005917183932717258], Loss: 2.038708, Acc:0.793736, Semantic loss: 0.772130, BCE loss: 0.522977, SB loss: 0.743601
2023-10-30 11:22:41,507 Epoch: [213/484] Iter:[420/495], Time: 0.37, lr: [0.005916785720921505], Loss: 2.036955, Acc:0.794398, Semantic loss: 0.770640, BCE loss: 0.522938, SB loss: 0.743378
2023-10-30 11:22:45,259 Epoch: [213/484] Iter:[430/495], Time: 0.37, lr: [0.0059163875061479], Loss: 2.046398, Acc:0.793373, Semantic loss: 0.778651, BCE loss: 0.521703, SB loss: 0.746044
2023-10-30 11:22:48,957 Epoch: [213/484] Iter:[440/495], Time: 0.37, lr: [0.005915989288396197], Loss: 2.047421, Acc:0.793247, Semantic loss: 0.778571, BCE loss: 0.521903, SB loss: 0.746947
2023-10-30 11:22:52,607 Epoch: [213/484] Iter:[450/495], Time: 0.37, lr: [0.005915591067666152], Loss: 2.048166, Acc:0.792920, Semantic loss: 0.778239, BCE loss: 0.521957, SB loss: 0.747970
2023-10-30 11:22:56,359 Epoch: [213/484] Iter:[460/495], Time: 0.37, lr: [0.005915192843957519], Loss: 2.053054, Acc:0.792284, Semantic loss: 0.781741, BCE loss: 0.521493, SB loss: 0.749820
2023-10-30 11:23:00,053 Epoch: [213/484] Iter:[470/495], Time: 0.37, lr: [0.0059147946172700555], Loss: 2.052280, Acc:0.792332, Semantic loss: 0.781529, BCE loss: 0.520849, SB loss: 0.749902
2023-10-30 11:23:03,870 Epoch: [213/484] Iter:[480/495], Time: 0.37, lr: [0.005914396387603513], Loss: 2.054984, Acc:0.792729, Semantic loss: 0.782617, BCE loss: 0.522470, SB loss: 0.749898
2023-10-30 11:23:07,416 Epoch: [213/484] Iter:[490/495], Time: 0.37, lr: [0.005913998154957649], Loss: 2.053755, Acc:0.792526, Semantic loss: 0.781257, BCE loss: 0.522352, SB loss: 0.750146
2023-10-30 11:23:08,833 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:23:09,073 Loss: 1.940, MeanIU:  0.7129, Best_mIoU:  0.7129
2023-10-30 11:23:09,073 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445]
2023-10-30 11:23:11,052 Epoch: [214/484] Iter:[0/495], Time: 1.94, lr: [0.0059137990375173945], Loss: 2.306405, Acc:0.621822, Semantic loss: 1.018250, BCE loss: 0.333314, SB loss: 0.954841
2023-10-30 11:23:15,033 Epoch: [214/484] Iter:[10/495], Time: 0.54, lr: [0.005913400800402087], Loss: 2.155100, Acc:0.761294, Semantic loss: 0.854925, BCE loss: 0.493527, SB loss: 0.806648
2023-10-30 11:23:18,836 Epoch: [214/484] Iter:[20/495], Time: 0.46, lr: [0.005913002560306841], Loss: 2.096029, Acc:0.786164, Semantic loss: 0.817658, BCE loss: 0.513241, SB loss: 0.765131
2023-10-30 11:23:22,487 Epoch: [214/484] Iter:[30/495], Time: 0.43, lr: [0.005912604317231418], Loss: 2.061971, Acc:0.794208, Semantic loss: 0.790083, BCE loss: 0.518497, SB loss: 0.753391
2023-10-30 11:23:26,181 Epoch: [214/484] Iter:[40/495], Time: 0.42, lr: [0.005912206071175565], Loss: 2.036202, Acc:0.799011, Semantic loss: 0.770194, BCE loss: 0.521251, SB loss: 0.744756
2023-10-30 11:23:29,890 Epoch: [214/484] Iter:[50/495], Time: 0.41, lr: [0.0059118078221390424], Loss: 2.053432, Acc:0.799694, Semantic loss: 0.786260, BCE loss: 0.518628, SB loss: 0.748545
2023-10-30 11:23:33,596 Epoch: [214/484] Iter:[60/495], Time: 0.40, lr: [0.005911409570121603], Loss: 2.055003, Acc:0.803252, Semantic loss: 0.782986, BCE loss: 0.526813, SB loss: 0.745204
2023-10-30 11:23:37,326 Epoch: [214/484] Iter:[70/495], Time: 0.40, lr: [0.005911011315123001], Loss: 2.059197, Acc:0.800561, Semantic loss: 0.784168, BCE loss: 0.527991, SB loss: 0.747038
2023-10-30 11:23:40,991 Epoch: [214/484] Iter:[80/495], Time: 0.39, lr: [0.00591061305714299], Loss: 2.068930, Acc:0.803660, Semantic loss: 0.791768, BCE loss: 0.526600, SB loss: 0.750561
2023-10-30 11:23:44,693 Epoch: [214/484] Iter:[90/495], Time: 0.39, lr: [0.005910214796181327], Loss: 2.072781, Acc:0.802543, Semantic loss: 0.795425, BCE loss: 0.526725, SB loss: 0.750631
2023-10-30 11:23:48,440 Epoch: [214/484] Iter:[100/495], Time: 0.39, lr: [0.005909816532237763], Loss: 2.075730, Acc:0.804208, Semantic loss: 0.796171, BCE loss: 0.527745, SB loss: 0.751814
2023-10-30 11:23:52,155 Epoch: [214/484] Iter:[110/495], Time: 0.39, lr: [0.005909418265312054], Loss: 2.086426, Acc:0.803201, Semantic loss: 0.799389, BCE loss: 0.533508, SB loss: 0.753529
2023-10-30 11:23:55,872 Epoch: [214/484] Iter:[120/495], Time: 0.39, lr: [0.005909019995403956], Loss: 2.093015, Acc:0.801132, Semantic loss: 0.805644, BCE loss: 0.535048, SB loss: 0.752322
2023-10-30 11:23:59,500 Epoch: [214/484] Iter:[130/495], Time: 0.38, lr: [0.005908621722513221], Loss: 2.081045, Acc:0.801259, Semantic loss: 0.799445, BCE loss: 0.531882, SB loss: 0.749719
2023-10-30 11:24:03,174 Epoch: [214/484] Iter:[140/495], Time: 0.38, lr: [0.005908223446639604], Loss: 2.085432, Acc:0.801358, Semantic loss: 0.797944, BCE loss: 0.535492, SB loss: 0.751996
2023-10-30 11:24:06,881 Epoch: [214/484] Iter:[150/495], Time: 0.38, lr: [0.005907825167782861], Loss: 2.094707, Acc:0.798960, Semantic loss: 0.803764, BCE loss: 0.538389, SB loss: 0.752554
2023-10-30 11:24:10,548 Epoch: [214/484] Iter:[160/495], Time: 0.38, lr: [0.005907426885942744], Loss: 2.083889, Acc:0.800293, Semantic loss: 0.795057, BCE loss: 0.538267, SB loss: 0.750565
2023-10-30 11:24:14,215 Epoch: [214/484] Iter:[170/495], Time: 0.38, lr: [0.005907028601119007], Loss: 2.085178, Acc:0.800107, Semantic loss: 0.796385, BCE loss: 0.536184, SB loss: 0.752610
2023-10-30 11:24:18,024 Epoch: [214/484] Iter:[180/495], Time: 0.38, lr: [0.005906630313311404], Loss: 2.086679, Acc:0.799364, Semantic loss: 0.795579, BCE loss: 0.535864, SB loss: 0.755236
2023-10-30 11:24:21,736 Epoch: [214/484] Iter:[190/495], Time: 0.38, lr: [0.005906232022519692], Loss: 2.075594, Acc:0.798661, Semantic loss: 0.788623, BCE loss: 0.534916, SB loss: 0.752055
2023-10-30 11:24:25,391 Epoch: [214/484] Iter:[200/495], Time: 0.38, lr: [0.005905833728743621], Loss: 2.069805, Acc:0.799989, Semantic loss: 0.784625, BCE loss: 0.534821, SB loss: 0.750359
2023-10-30 11:24:29,072 Epoch: [214/484] Iter:[210/495], Time: 0.38, lr: [0.005905435431982948], Loss: 2.068802, Acc:0.800665, Semantic loss: 0.783016, BCE loss: 0.536155, SB loss: 0.749631
2023-10-30 11:24:32,779 Epoch: [214/484] Iter:[220/495], Time: 0.38, lr: [0.005905037132237426], Loss: 2.069238, Acc:0.799626, Semantic loss: 0.783586, BCE loss: 0.536973, SB loss: 0.748678
2023-10-30 11:24:36,436 Epoch: [214/484] Iter:[230/495], Time: 0.38, lr: [0.00590463882950681], Loss: 2.069477, Acc:0.799100, Semantic loss: 0.783611, BCE loss: 0.536680, SB loss: 0.749186
2023-10-30 11:24:40,196 Epoch: [214/484] Iter:[240/495], Time: 0.38, lr: [0.0059042405237908525], Loss: 2.070540, Acc:0.799469, Semantic loss: 0.783394, BCE loss: 0.537602, SB loss: 0.749545
2023-10-30 11:24:43,862 Epoch: [214/484] Iter:[250/495], Time: 0.38, lr: [0.005903842215089307], Loss: 2.067163, Acc:0.799385, Semantic loss: 0.781285, BCE loss: 0.536359, SB loss: 0.749519
2023-10-30 11:24:47,586 Epoch: [214/484] Iter:[260/495], Time: 0.38, lr: [0.0059034439034019275], Loss: 2.065895, Acc:0.798985, Semantic loss: 0.781540, BCE loss: 0.535553, SB loss: 0.748803
2023-10-30 11:24:51,364 Epoch: [214/484] Iter:[270/495], Time: 0.38, lr: [0.005903045588728469], Loss: 2.064152, Acc:0.800052, Semantic loss: 0.779795, BCE loss: 0.536315, SB loss: 0.748042
2023-10-30 11:24:55,086 Epoch: [214/484] Iter:[280/495], Time: 0.38, lr: [0.005902647271068683], Loss: 2.064857, Acc:0.801166, Semantic loss: 0.779438, BCE loss: 0.535873, SB loss: 0.749546
2023-10-30 11:24:58,744 Epoch: [214/484] Iter:[290/495], Time: 0.38, lr: [0.005902248950422326], Loss: 2.066088, Acc:0.800791, Semantic loss: 0.780617, BCE loss: 0.535378, SB loss: 0.750094
2023-10-30 11:25:02,516 Epoch: [214/484] Iter:[300/495], Time: 0.38, lr: [0.00590185062678915], Loss: 2.069053, Acc:0.799804, Semantic loss: 0.783013, BCE loss: 0.535953, SB loss: 0.750087
2023-10-30 11:25:06,202 Epoch: [214/484] Iter:[310/495], Time: 0.38, lr: [0.005901452300168909], Loss: 2.066760, Acc:0.800207, Semantic loss: 0.781758, BCE loss: 0.535639, SB loss: 0.749363
2023-10-30 11:25:09,856 Epoch: [214/484] Iter:[320/495], Time: 0.38, lr: [0.005901053970561357], Loss: 2.068241, Acc:0.801126, Semantic loss: 0.783311, BCE loss: 0.535266, SB loss: 0.749665
2023-10-30 11:25:13,485 Epoch: [214/484] Iter:[330/495], Time: 0.38, lr: [0.005900655637966247], Loss: 2.068486, Acc:0.800965, Semantic loss: 0.783220, BCE loss: 0.535571, SB loss: 0.749694
2023-10-30 11:25:17,139 Epoch: [214/484] Iter:[340/495], Time: 0.38, lr: [0.005900257302383331], Loss: 2.066359, Acc:0.800573, Semantic loss: 0.781995, BCE loss: 0.535029, SB loss: 0.749334
2023-10-30 11:25:20,865 Epoch: [214/484] Iter:[350/495], Time: 0.38, lr: [0.005899858963812366], Loss: 2.064211, Acc:0.800525, Semantic loss: 0.781019, BCE loss: 0.534095, SB loss: 0.749097
2023-10-30 11:25:24,589 Epoch: [214/484] Iter:[360/495], Time: 0.38, lr: [0.005899460622253101], Loss: 2.064299, Acc:0.800034, Semantic loss: 0.781182, BCE loss: 0.534082, SB loss: 0.749035
2023-10-30 11:25:28,365 Epoch: [214/484] Iter:[370/495], Time: 0.38, lr: [0.005899062277705294], Loss: 2.063224, Acc:0.799319, Semantic loss: 0.780069, BCE loss: 0.534382, SB loss: 0.748773
2023-10-30 11:25:31,957 Epoch: [214/484] Iter:[380/495], Time: 0.37, lr: [0.005898663930168695], Loss: 2.062223, Acc:0.798954, Semantic loss: 0.778491, BCE loss: 0.534965, SB loss: 0.748766
2023-10-30 11:25:35,751 Epoch: [214/484] Iter:[390/495], Time: 0.38, lr: [0.00589826557964306], Loss: 2.063176, Acc:0.798341, Semantic loss: 0.779072, BCE loss: 0.535562, SB loss: 0.748543
2023-10-30 11:25:39,320 Epoch: [214/484] Iter:[400/495], Time: 0.37, lr: [0.00589786722612814], Loss: 2.063974, Acc:0.797812, Semantic loss: 0.779630, BCE loss: 0.536021, SB loss: 0.748323
2023-10-30 11:25:43,005 Epoch: [214/484] Iter:[410/495], Time: 0.37, lr: [0.0058974688696236885], Loss: 2.064607, Acc:0.797801, Semantic loss: 0.779605, BCE loss: 0.536960, SB loss: 0.748042
2023-10-30 11:25:46,626 Epoch: [214/484] Iter:[420/495], Time: 0.37, lr: [0.0058970705101294586], Loss: 2.062068, Acc:0.797657, Semantic loss: 0.777576, BCE loss: 0.536984, SB loss: 0.747508
2023-10-30 11:25:50,376 Epoch: [214/484] Iter:[430/495], Time: 0.37, lr: [0.005896672147645205], Loss: 2.059487, Acc:0.796978, Semantic loss: 0.776083, BCE loss: 0.536563, SB loss: 0.746841
2023-10-30 11:25:54,030 Epoch: [214/484] Iter:[440/495], Time: 0.37, lr: [0.005896273782170679], Loss: 2.059897, Acc:0.796324, Semantic loss: 0.774876, BCE loss: 0.538031, SB loss: 0.746990
2023-10-30 11:25:57,693 Epoch: [214/484] Iter:[450/495], Time: 0.37, lr: [0.005895875413705635], Loss: 2.060006, Acc:0.796316, Semantic loss: 0.774579, BCE loss: 0.537871, SB loss: 0.747557
2023-10-30 11:26:01,383 Epoch: [214/484] Iter:[460/495], Time: 0.37, lr: [0.005895477042249826], Loss: 2.060594, Acc:0.795579, Semantic loss: 0.774792, BCE loss: 0.538380, SB loss: 0.747421
2023-10-30 11:26:05,111 Epoch: [214/484] Iter:[470/495], Time: 0.37, lr: [0.0058950786678030045], Loss: 2.063898, Acc:0.796431, Semantic loss: 0.776353, BCE loss: 0.539147, SB loss: 0.748399
2023-10-30 11:26:08,850 Epoch: [214/484] Iter:[480/495], Time: 0.37, lr: [0.005894680290364923], Loss: 2.059739, Acc:0.796557, Semantic loss: 0.774352, BCE loss: 0.537927, SB loss: 0.747460
2023-10-30 11:26:12,436 Epoch: [214/484] Iter:[490/495], Time: 0.37, lr: [0.005894281909935335], Loss: 2.060075, Acc:0.796864, Semantic loss: 0.774129, BCE loss: 0.538717, SB loss: 0.747229
2023-10-30 11:26:13,851 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:26:14,091 Loss: 1.940, MeanIU:  0.7129, Best_mIoU:  0.7129
2023-10-30 11:26:14,091 [0.97244382 0.78605173 0.90056686 0.39658778 0.51977494 0.58504462
 0.63100891 0.72909992 0.91055443 0.59394531 0.9196332  0.78076419
 0.58414403 0.93683615 0.706699   0.79561419 0.69136797 0.37372545
 0.73089445]
2023-10-30 11:26:16,573 Epoch: [215/484] Iter:[0/495], Time: 2.45, lr: [0.005894082718598648], Loss: 2.609657, Acc:0.776715, Semantic loss: 0.939416, BCE loss: 0.713679, SB loss: 0.956562
2023-10-30 11:26:20,510 Epoch: [215/484] Iter:[10/495], Time: 0.58, lr: [0.0058936843336813375], Loss: 2.288573, Acc:0.803630, Semantic loss: 0.910136, BCE loss: 0.598997, SB loss: 0.779439
2023-10-30 11:26:24,231 Epoch: [215/484] Iter:[20/495], Time: 0.48, lr: [0.0058932859457719], Loss: 2.163724, Acc:0.790313, Semantic loss: 0.840309, BCE loss: 0.568874, SB loss: 0.754542
2023-10-30 11:26:27,869 Epoch: [215/484] Iter:[30/495], Time: 0.44, lr: [0.005892887554870094], Loss: 2.081742, Acc:0.798571, Semantic loss: 0.792168, BCE loss: 0.546147, SB loss: 0.743427
2023-10-30 11:26:31,620 Epoch: [215/484] Iter:[40/495], Time: 0.43, lr: [0.005892489160975667], Loss: 2.083630, Acc:0.802074, Semantic loss: 0.783545, BCE loss: 0.549586, SB loss: 0.750498
2023-10-30 11:26:35,342 Epoch: [215/484] Iter:[50/495], Time: 0.42, lr: [0.005892090764088375], Loss: 2.069003, Acc:0.809040, Semantic loss: 0.774080, BCE loss: 0.552997, SB loss: 0.741925
2023-10-30 11:26:39,063 Epoch: [215/484] Iter:[60/495], Time: 0.41, lr: [0.005891692364207969], Loss: 2.033512, Acc:0.807312, Semantic loss: 0.759783, BCE loss: 0.542141, SB loss: 0.731588
2023-10-30 11:26:42,784 Epoch: [215/484] Iter:[70/495], Time: 0.40, lr: [0.005891293961334202], Loss: 2.089278, Acc:0.802208, Semantic loss: 0.798280, BCE loss: 0.548585, SB loss: 0.742413
2023-10-30 11:26:46,491 Epoch: [215/484] Iter:[80/495], Time: 0.40, lr: [0.0058908955554668255], Loss: 2.084680, Acc:0.801033, Semantic loss: 0.792172, BCE loss: 0.550640, SB loss: 0.741868
2023-10-30 11:26:50,182 Epoch: [215/484] Iter:[90/495], Time: 0.40, lr: [0.005890497146605595], Loss: 2.087524, Acc:0.799237, Semantic loss: 0.793084, BCE loss: 0.550095, SB loss: 0.744345
2023-10-30 11:26:53,890 Epoch: [215/484] Iter:[100/495], Time: 0.39, lr: [0.005890098734750259], Loss: 2.074942, Acc:0.798407, Semantic loss: 0.783716, BCE loss: 0.548669, SB loss: 0.742557
2023-10-30 11:26:57,546 Epoch: [215/484] Iter:[110/495], Time: 0.39, lr: [0.005889700319900574], Loss: 2.074054, Acc:0.800462, Semantic loss: 0.784209, BCE loss: 0.546590, SB loss: 0.743255
2023-10-30 11:27:01,202 Epoch: [215/484] Iter:[120/495], Time: 0.39, lr: [0.00588930190205629], Loss: 2.076588, Acc:0.800163, Semantic loss: 0.783367, BCE loss: 0.548948, SB loss: 0.744273
2023-10-30 11:27:04,912 Epoch: [215/484] Iter:[130/495], Time: 0.39, lr: [0.005888903481217161], Loss: 2.079939, Acc:0.800918, Semantic loss: 0.785467, BCE loss: 0.548727, SB loss: 0.745745
2023-10-30 11:27:08,683 Epoch: [215/484] Iter:[140/495], Time: 0.39, lr: [0.0058885050573829366], Loss: 2.075257, Acc:0.799278, Semantic loss: 0.784389, BCE loss: 0.546705, SB loss: 0.744164
2023-10-30 11:27:12,441 Epoch: [215/484] Iter:[150/495], Time: 0.39, lr: [0.005888106630553371], Loss: 2.074226, Acc:0.800137, Semantic loss: 0.786571, BCE loss: 0.542538, SB loss: 0.745118
2023-10-30 11:27:16,184 Epoch: [215/484] Iter:[160/495], Time: 0.39, lr: [0.005887708200728217], Loss: 2.069507, Acc:0.800507, Semantic loss: 0.782645, BCE loss: 0.540544, SB loss: 0.746317
2023-10-30 11:27:19,840 Epoch: [215/484] Iter:[170/495], Time: 0.38, lr: [0.005887309767907226], Loss: 2.076596, Acc:0.797622, Semantic loss: 0.788597, BCE loss: 0.541008, SB loss: 0.746991
2023-10-30 11:27:23,566 Epoch: [215/484] Iter:[180/495], Time: 0.38, lr: [0.005886911332090149], Loss: 2.074148, Acc:0.796107, Semantic loss: 0.787547, BCE loss: 0.538386, SB loss: 0.748215
2023-10-30 11:27:27,235 Epoch: [215/484] Iter:[190/495], Time: 0.38, lr: [0.005886512893276741], Loss: 2.074280, Acc:0.797379, Semantic loss: 0.787691, BCE loss: 0.537551, SB loss: 0.749038
2023-10-30 11:27:31,048 Epoch: [215/484] Iter:[200/495], Time: 0.38, lr: [0.005886114451466753], Loss: 2.069206, Acc:0.798866, Semantic loss: 0.784412, BCE loss: 0.537583, SB loss: 0.747210
2023-10-30 11:27:34,777 Epoch: [215/484] Iter:[210/495], Time: 0.38, lr: [0.005885716006659936], Loss: 2.069569, Acc:0.799066, Semantic loss: 0.782693, BCE loss: 0.539546, SB loss: 0.747330
2023-10-30 11:27:38,461 Epoch: [215/484] Iter:[220/495], Time: 0.38, lr: [0.005885317558856044], Loss: 2.077755, Acc:0.797580, Semantic loss: 0.790670, BCE loss: 0.538576, SB loss: 0.748509
2023-10-30 11:27:42,235 Epoch: [215/484] Iter:[230/495], Time: 0.38, lr: [0.005884919108054826], Loss: 2.072202, Acc:0.796397, Semantic loss: 0.789237, BCE loss: 0.536524, SB loss: 0.746441
2023-10-30 11:27:45,998 Epoch: [215/484] Iter:[240/495], Time: 0.38, lr: [0.0058845206542560355], Loss: 2.083855, Acc:0.796855, Semantic loss: 0.795439, BCE loss: 0.539368, SB loss: 0.749048
2023-10-30 11:27:49,696 Epoch: [215/484] Iter:[250/495], Time: 0.38, lr: [0.005884122197459425], Loss: 2.086803, Acc:0.797429, Semantic loss: 0.795926, BCE loss: 0.539515, SB loss: 0.751362
2023-10-30 11:27:53,349 Epoch: [215/484] Iter:[260/495], Time: 0.38, lr: [0.005883723737664746], Loss: 2.096767, Acc:0.796711, Semantic loss: 0.799368, BCE loss: 0.543171, SB loss: 0.754228
2023-10-30 11:27:57,121 Epoch: [215/484] Iter:[270/495], Time: 0.38, lr: [0.00588332527487175], Loss: 2.094647, Acc:0.797489, Semantic loss: 0.796306, BCE loss: 0.543954, SB loss: 0.754387
2023-10-30 11:28:00,957 Epoch: [215/484] Iter:[280/495], Time: 0.38, lr: [0.00588292680908019], Loss: 2.096830, Acc:0.798575, Semantic loss: 0.797336, BCE loss: 0.544133, SB loss: 0.755361
2023-10-30 11:28:04,644 Epoch: [215/484] Iter:[290/495], Time: 0.38, lr: [0.005882528340289818], Loss: 2.097247, Acc:0.797833, Semantic loss: 0.796729, BCE loss: 0.545247, SB loss: 0.755270
2023-10-30 11:28:08,384 Epoch: [215/484] Iter:[300/495], Time: 0.38, lr: [0.005882129868500383], Loss: 2.096547, Acc:0.797047, Semantic loss: 0.796462, BCE loss: 0.543810, SB loss: 0.756274
2023-10-30 11:28:12,034 Epoch: [215/484] Iter:[310/495], Time: 0.38, lr: [0.005881731393711639], Loss: 2.095374, Acc:0.797332, Semantic loss: 0.795264, BCE loss: 0.544389, SB loss: 0.755721
2023-10-30 11:28:15,823 Epoch: [215/484] Iter:[320/495], Time: 0.38, lr: [0.005881332915923335], Loss: 2.096898, Acc:0.797164, Semantic loss: 0.795893, BCE loss: 0.545998, SB loss: 0.755007
2023-10-30 11:28:19,603 Epoch: [215/484] Iter:[330/495], Time: 0.38, lr: [0.0058809344351352264], Loss: 2.099951, Acc:0.798041, Semantic loss: 0.797353, BCE loss: 0.548042, SB loss: 0.754556
2023-10-30 11:28:23,344 Epoch: [215/484] Iter:[340/495], Time: 0.38, lr: [0.005880535951347063], Loss: 2.098504, Acc:0.798694, Semantic loss: 0.795597, BCE loss: 0.548407, SB loss: 0.754500
2023-10-30 11:28:27,110 Epoch: [215/484] Iter:[350/495], Time: 0.38, lr: [0.005880137464558594], Loss: 2.095745, Acc:0.799379, Semantic loss: 0.793335, BCE loss: 0.548839, SB loss: 0.753571
2023-10-30 11:28:31,044 Epoch: [215/484] Iter:[360/495], Time: 0.38, lr: [0.0058797389747695765], Loss: 2.098471, Acc:0.799378, Semantic loss: 0.795542, BCE loss: 0.548510, SB loss: 0.754419
2023-10-30 11:28:34,717 Epoch: [215/484] Iter:[370/495], Time: 0.38, lr: [0.005879340481979757], Loss: 2.094238, Acc:0.799704, Semantic loss: 0.792716, BCE loss: 0.548011, SB loss: 0.753511
2023-10-30 11:28:38,409 Epoch: [215/484] Iter:[380/495], Time: 0.38, lr: [0.00587894198618889], Loss: 2.095274, Acc:0.798730, Semantic loss: 0.794576, BCE loss: 0.546103, SB loss: 0.754595
2023-10-30 11:28:42,192 Epoch: [215/484] Iter:[390/495], Time: 0.38, lr: [0.005878543487396724], Loss: 2.094058, Acc:0.798459, Semantic loss: 0.793931, BCE loss: 0.545509, SB loss: 0.754617
2023-10-30 11:28:45,834 Epoch: [215/484] Iter:[400/495], Time: 0.38, lr: [0.00587814498560301], Loss: 2.093866, Acc:0.799104, Semantic loss: 0.793400, BCE loss: 0.545970, SB loss: 0.754495
2023-10-30 11:28:49,521 Epoch: [215/484] Iter:[410/495], Time: 0.38, lr: [0.005877746480807503], Loss: 2.090894, Acc:0.799092, Semantic loss: 0.792519, BCE loss: 0.544262, SB loss: 0.754113
2023-10-30 11:28:53,228 Epoch: [215/484] Iter:[420/495], Time: 0.38, lr: [0.005877347973009951], Loss: 2.091866, Acc:0.798401, Semantic loss: 0.794224, BCE loss: 0.542312, SB loss: 0.755330
2023-10-30 11:28:56,956 Epoch: [215/484] Iter:[430/495], Time: 0.38, lr: [0.005876949462210108], Loss: 2.092314, Acc:0.797435, Semantic loss: 0.793851, BCE loss: 0.542791, SB loss: 0.755672
2023-10-30 11:29:00,801 Epoch: [215/484] Iter:[440/495], Time: 0.38, lr: [0.0058765509484077225], Loss: 2.090469, Acc:0.798309, Semantic loss: 0.792624, BCE loss: 0.543082, SB loss: 0.754763
2023-10-30 11:29:04,506 Epoch: [215/484] Iter:[450/495], Time: 0.38, lr: [0.005876152431602548], Loss: 2.093500, Acc:0.798808, Semantic loss: 0.794301, BCE loss: 0.543632, SB loss: 0.755566
2023-10-30 11:29:08,248 Epoch: [215/484] Iter:[460/495], Time: 0.38, lr: [0.005875753911794334], Loss: 2.093198, Acc:0.799029, Semantic loss: 0.793527, BCE loss: 0.544256, SB loss: 0.755414
2023-10-30 11:29:11,942 Epoch: [215/484] Iter:[470/495], Time: 0.38, lr: [0.005875355388982832], Loss: 2.093638, Acc:0.798847, Semantic loss: 0.792610, BCE loss: 0.544947, SB loss: 0.756080
2023-10-30 11:29:15,631 Epoch: [215/484] Iter:[480/495], Time: 0.38, lr: [0.005874956863167792], Loss: 2.093245, Acc:0.798869, Semantic loss: 0.791555, BCE loss: 0.546208, SB loss: 0.755482
2023-10-30 11:29:19,149 Epoch: [215/484] Iter:[490/495], Time: 0.38, lr: [0.005874558334348965], Loss: 2.093175, Acc:0.798397, Semantic loss: 0.791373, BCE loss: 0.546470, SB loss: 0.755332
2023-10-30 11:32:16,000 0 [9.34080976e-01 6.18021571e-01 8.31291251e-01 1.53828919e-01
 2.54969945e-01 4.33774199e-01 4.81877441e-01 5.74616957e-01
 8.80191625e-01 4.50122166e-01 8.75539528e-01 6.22109956e-01
 4.14444016e-02 8.18222965e-01 3.16590920e-04 7.43867762e-02
 1.77607632e-02 6.01837930e-02 5.97531309e-01] 0.45896163853954736
2023-10-30 11:32:16,000 1 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991] 0.7151281346108942
2023-10-30 11:32:16,004 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:32:16,367 Loss: 2.010, MeanIU:  0.7151, Best_mIoU:  0.7151
2023-10-30 11:32:16,367 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991]
2023-10-30 11:32:18,494 Epoch: [216/484] Iter:[0/495], Time: 2.09, lr: [0.005874359068813055], Loss: 1.950291, Acc:0.729474, Semantic loss: 0.740621, BCE loss: 0.555661, SB loss: 0.654009
2023-10-30 11:32:22,321 Epoch: [216/484] Iter:[10/495], Time: 0.54, lr: [0.0058739605354880845], Loss: 2.071535, Acc:0.797178, Semantic loss: 0.802768, BCE loss: 0.549790, SB loss: 0.718978
2023-10-30 11:32:26,016 Epoch: [216/484] Iter:[20/495], Time: 0.46, lr: [0.005873561999158704], Loss: 2.072653, Acc:0.797069, Semantic loss: 0.799380, BCE loss: 0.539256, SB loss: 0.734017
2023-10-30 11:32:29,582 Epoch: [216/484] Iter:[30/495], Time: 0.43, lr: [0.005873163459824665], Loss: 2.031794, Acc:0.808894, Semantic loss: 0.766467, BCE loss: 0.530208, SB loss: 0.735120
2023-10-30 11:32:33,151 Epoch: [216/484] Iter:[40/495], Time: 0.41, lr: [0.00587276491748572], Loss: 2.043563, Acc:0.815378, Semantic loss: 0.765976, BCE loss: 0.537310, SB loss: 0.740277
2023-10-30 11:32:36,689 Epoch: [216/484] Iter:[50/495], Time: 0.40, lr: [0.005872366372141619], Loss: 2.047197, Acc:0.812470, Semantic loss: 0.766376, BCE loss: 0.541625, SB loss: 0.739196
2023-10-30 11:32:40,335 Epoch: [216/484] Iter:[60/495], Time: 0.39, lr: [0.0058719678237921106], Loss: 2.025953, Acc:0.810066, Semantic loss: 0.759185, BCE loss: 0.532655, SB loss: 0.734113
2023-10-30 11:32:43,868 Epoch: [216/484] Iter:[70/495], Time: 0.39, lr: [0.005871569272436947], Loss: 2.041081, Acc:0.809902, Semantic loss: 0.774360, BCE loss: 0.528709, SB loss: 0.738013
2023-10-30 11:32:47,493 Epoch: [216/484] Iter:[80/495], Time: 0.38, lr: [0.00587117071807588], Loss: 2.042991, Acc:0.808418, Semantic loss: 0.770007, BCE loss: 0.536550, SB loss: 0.736434
2023-10-30 11:32:51,046 Epoch: [216/484] Iter:[90/495], Time: 0.38, lr: [0.00587077216070866], Loss: 2.054338, Acc:0.807008, Semantic loss: 0.770714, BCE loss: 0.544315, SB loss: 0.739310
2023-10-30 11:32:54,687 Epoch: [216/484] Iter:[100/495], Time: 0.38, lr: [0.005870373600335036], Loss: 2.040186, Acc:0.807929, Semantic loss: 0.765045, BCE loss: 0.537878, SB loss: 0.737262
2023-10-30 11:32:58,339 Epoch: [216/484] Iter:[110/495], Time: 0.38, lr: [0.00586997503695476], Loss: 2.049174, Acc:0.804827, Semantic loss: 0.771300, BCE loss: 0.537687, SB loss: 0.740188
2023-10-30 11:33:02,041 Epoch: [216/484] Iter:[120/495], Time: 0.38, lr: [0.005869576470567581], Loss: 2.040632, Acc:0.803605, Semantic loss: 0.766999, BCE loss: 0.535506, SB loss: 0.738127
2023-10-30 11:33:05,632 Epoch: [216/484] Iter:[130/495], Time: 0.38, lr: [0.00586917790117325], Loss: 2.044719, Acc:0.804322, Semantic loss: 0.769064, BCE loss: 0.535901, SB loss: 0.739754
2023-10-30 11:33:09,297 Epoch: [216/484] Iter:[140/495], Time: 0.38, lr: [0.005868779328771519], Loss: 2.047124, Acc:0.800818, Semantic loss: 0.775487, BCE loss: 0.531738, SB loss: 0.739899
2023-10-30 11:33:12,912 Epoch: [216/484] Iter:[150/495], Time: 0.37, lr: [0.005868380753362136], Loss: 2.050476, Acc:0.802484, Semantic loss: 0.776656, BCE loss: 0.533551, SB loss: 0.740268
2023-10-30 11:33:16,624 Epoch: [216/484] Iter:[160/495], Time: 0.37, lr: [0.005867982174944851], Loss: 2.045759, Acc:0.800388, Semantic loss: 0.774517, BCE loss: 0.531899, SB loss: 0.739343
2023-10-30 11:33:20,254 Epoch: [216/484] Iter:[170/495], Time: 0.37, lr: [0.005867583593519418], Loss: 2.038749, Acc:0.800227, Semantic loss: 0.769355, BCE loss: 0.531523, SB loss: 0.737871
2023-10-30 11:33:24,052 Epoch: [216/484] Iter:[180/495], Time: 0.37, lr: [0.0058671850090855834], Loss: 2.030551, Acc:0.798732, Semantic loss: 0.765362, BCE loss: 0.528895, SB loss: 0.736294
2023-10-30 11:33:27,889 Epoch: [216/484] Iter:[190/495], Time: 0.37, lr: [0.005866786421643101], Loss: 2.037221, Acc:0.799724, Semantic loss: 0.770177, BCE loss: 0.528561, SB loss: 0.738483
2023-10-30 11:33:31,607 Epoch: [216/484] Iter:[200/495], Time: 0.37, lr: [0.005866387831191718], Loss: 2.036839, Acc:0.801260, Semantic loss: 0.768515, BCE loss: 0.530876, SB loss: 0.737448
2023-10-30 11:33:35,215 Epoch: [216/484] Iter:[210/495], Time: 0.37, lr: [0.005865989237731184], Loss: 2.030366, Acc:0.800974, Semantic loss: 0.764826, BCE loss: 0.529784, SB loss: 0.735756
2023-10-30 11:33:39,001 Epoch: [216/484] Iter:[220/495], Time: 0.37, lr: [0.005865590641261251], Loss: 2.028472, Acc:0.799796, Semantic loss: 0.763867, BCE loss: 0.529394, SB loss: 0.735211
2023-10-30 11:33:42,633 Epoch: [216/484] Iter:[230/495], Time: 0.37, lr: [0.005865192041781669], Loss: 2.025834, Acc:0.801363, Semantic loss: 0.762339, BCE loss: 0.529800, SB loss: 0.733694
2023-10-30 11:33:46,295 Epoch: [216/484] Iter:[240/495], Time: 0.37, lr: [0.005864793439292186], Loss: 2.025368, Acc:0.799341, Semantic loss: 0.762411, BCE loss: 0.529239, SB loss: 0.733718
2023-10-30 11:33:49,985 Epoch: [216/484] Iter:[250/495], Time: 0.37, lr: [0.005864394833792556], Loss: 2.022844, Acc:0.799293, Semantic loss: 0.761542, BCE loss: 0.528338, SB loss: 0.732964
2023-10-30 11:33:53,626 Epoch: [216/484] Iter:[260/495], Time: 0.37, lr: [0.005863996225282525], Loss: 2.031741, Acc:0.800597, Semantic loss: 0.765145, BCE loss: 0.532859, SB loss: 0.733737
2023-10-30 11:33:57,209 Epoch: [216/484] Iter:[270/495], Time: 0.37, lr: [0.005863597613761845], Loss: 2.025800, Acc:0.800836, Semantic loss: 0.762151, BCE loss: 0.531239, SB loss: 0.732411
2023-10-30 11:34:00,891 Epoch: [216/484] Iter:[280/495], Time: 0.37, lr: [0.005863198999230266], Loss: 2.025487, Acc:0.800854, Semantic loss: 0.761336, BCE loss: 0.530788, SB loss: 0.733363
2023-10-30 11:34:04,587 Epoch: [216/484] Iter:[290/495], Time: 0.37, lr: [0.005862800381687536], Loss: 2.025672, Acc:0.801828, Semantic loss: 0.762147, BCE loss: 0.529481, SB loss: 0.734044
2023-10-30 11:34:08,241 Epoch: [216/484] Iter:[300/495], Time: 0.37, lr: [0.005862401761133404], Loss: 2.025453, Acc:0.802189, Semantic loss: 0.761716, BCE loss: 0.530187, SB loss: 0.733551
2023-10-30 11:34:11,954 Epoch: [216/484] Iter:[310/495], Time: 0.37, lr: [0.005862003137567623], Loss: 2.026513, Acc:0.801356, Semantic loss: 0.763669, BCE loss: 0.528916, SB loss: 0.733928
2023-10-30 11:34:15,586 Epoch: [216/484] Iter:[320/495], Time: 0.37, lr: [0.005861604510989942], Loss: 2.028424, Acc:0.799539, Semantic loss: 0.765204, BCE loss: 0.528701, SB loss: 0.734519
2023-10-30 11:34:19,284 Epoch: [216/484] Iter:[330/495], Time: 0.37, lr: [0.005861205881400109], Loss: 2.025022, Acc:0.800172, Semantic loss: 0.762616, BCE loss: 0.528389, SB loss: 0.734017
2023-10-30 11:34:23,036 Epoch: [216/484] Iter:[340/495], Time: 0.37, lr: [0.005860807248797875], Loss: 2.029304, Acc:0.801567, Semantic loss: 0.764118, BCE loss: 0.530855, SB loss: 0.734332
2023-10-30 11:34:26,596 Epoch: [216/484] Iter:[350/495], Time: 0.37, lr: [0.005860408613182989], Loss: 2.027382, Acc:0.799624, Semantic loss: 0.763369, BCE loss: 0.529790, SB loss: 0.734223
2023-10-30 11:34:30,402 Epoch: [216/484] Iter:[360/495], Time: 0.37, lr: [0.005860009974555201], Loss: 2.027974, Acc:0.799479, Semantic loss: 0.763977, BCE loss: 0.529553, SB loss: 0.734445
2023-10-30 11:34:34,072 Epoch: [216/484] Iter:[370/495], Time: 0.37, lr: [0.0058596113329142585], Loss: 2.028394, Acc:0.800141, Semantic loss: 0.763581, BCE loss: 0.530529, SB loss: 0.734283
2023-10-30 11:34:37,771 Epoch: [216/484] Iter:[380/495], Time: 0.37, lr: [0.0058592126882599125], Loss: 2.026089, Acc:0.799629, Semantic loss: 0.762360, BCE loss: 0.530181, SB loss: 0.733548
2023-10-30 11:34:41,549 Epoch: [216/484] Iter:[390/495], Time: 0.37, lr: [0.005858814040591913], Loss: 2.028477, Acc:0.799989, Semantic loss: 0.763275, BCE loss: 0.530843, SB loss: 0.734359
2023-10-30 11:34:45,281 Epoch: [216/484] Iter:[400/495], Time: 0.37, lr: [0.005858415389910009], Loss: 2.031629, Acc:0.799278, Semantic loss: 0.765453, BCE loss: 0.531360, SB loss: 0.734815
2023-10-30 11:34:48,974 Epoch: [216/484] Iter:[410/495], Time: 0.37, lr: [0.005858016736213951], Loss: 2.033126, Acc:0.799016, Semantic loss: 0.766285, BCE loss: 0.531959, SB loss: 0.734882
2023-10-30 11:34:52,779 Epoch: [216/484] Iter:[420/495], Time: 0.37, lr: [0.005857618079503485], Loss: 2.034596, Acc:0.798538, Semantic loss: 0.766578, BCE loss: 0.532696, SB loss: 0.735322
2023-10-30 11:34:56,507 Epoch: [216/484] Iter:[430/495], Time: 0.37, lr: [0.005857219419778363], Loss: 2.036125, Acc:0.798461, Semantic loss: 0.766163, BCE loss: 0.534444, SB loss: 0.735518
2023-10-30 11:35:00,176 Epoch: [216/484] Iter:[440/495], Time: 0.37, lr: [0.0058568207570383335], Loss: 2.034241, Acc:0.798217, Semantic loss: 0.765230, BCE loss: 0.533582, SB loss: 0.735430
2023-10-30 11:35:03,762 Epoch: [216/484] Iter:[450/495], Time: 0.37, lr: [0.005856422091283144], Loss: 2.032256, Acc:0.798823, Semantic loss: 0.764006, BCE loss: 0.533389, SB loss: 0.734861
2023-10-30 11:35:07,571 Epoch: [216/484] Iter:[460/495], Time: 0.37, lr: [0.005856023422512548], Loss: 2.031667, Acc:0.799135, Semantic loss: 0.763930, BCE loss: 0.533085, SB loss: 0.734652
2023-10-30 11:35:11,246 Epoch: [216/484] Iter:[470/495], Time: 0.37, lr: [0.005855624750726289], Loss: 2.035888, Acc:0.799161, Semantic loss: 0.766473, BCE loss: 0.533873, SB loss: 0.735542
2023-10-30 11:35:15,074 Epoch: [216/484] Iter:[480/495], Time: 0.37, lr: [0.00585522607592412], Loss: 2.040494, Acc:0.798847, Semantic loss: 0.769724, BCE loss: 0.533386, SB loss: 0.737384
2023-10-30 11:35:18,588 Epoch: [216/484] Iter:[490/495], Time: 0.37, lr: [0.005854827398105789], Loss: 2.041976, Acc:0.799004, Semantic loss: 0.770209, BCE loss: 0.533888, SB loss: 0.737880
2023-10-30 11:35:20,021 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:35:20,260 Loss: 2.010, MeanIU:  0.7151, Best_mIoU:  0.7151
2023-10-30 11:35:20,260 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991]
2023-10-30 11:35:22,300 Epoch: [217/484] Iter:[0/495], Time: 2.01, lr: [0.0058546280580654845], Loss: 1.885030, Acc:0.799108, Semantic loss: 0.778892, BCE loss: 0.302023, SB loss: 0.804114
2023-10-30 11:35:26,338 Epoch: [217/484] Iter:[10/495], Time: 0.55, lr: [0.00585422937572244], Loss: 2.042532, Acc:0.760956, Semantic loss: 0.809748, BCE loss: 0.485388, SB loss: 0.747396
2023-10-30 11:35:30,062 Epoch: [217/484] Iter:[20/495], Time: 0.47, lr: [0.005853830690362605], Loss: 2.019714, Acc:0.792625, Semantic loss: 0.778374, BCE loss: 0.507484, SB loss: 0.733856
2023-10-30 11:35:33,681 Epoch: [217/484] Iter:[30/495], Time: 0.43, lr: [0.00585343200198573], Loss: 2.069598, Acc:0.789829, Semantic loss: 0.793917, BCE loss: 0.521442, SB loss: 0.754238
2023-10-30 11:35:37,396 Epoch: [217/484] Iter:[40/495], Time: 0.42, lr: [0.005853033310591561], Loss: 2.047044, Acc:0.794517, Semantic loss: 0.782812, BCE loss: 0.514000, SB loss: 0.750232
2023-10-30 11:35:41,159 Epoch: [217/484] Iter:[50/495], Time: 0.41, lr: [0.005852634616179851], Loss: 2.037576, Acc:0.795704, Semantic loss: 0.779478, BCE loss: 0.509479, SB loss: 0.748619
2023-10-30 11:35:44,930 Epoch: [217/484] Iter:[60/495], Time: 0.40, lr: [0.005852235918750345], Loss: 2.036190, Acc:0.798933, Semantic loss: 0.770837, BCE loss: 0.521123, SB loss: 0.744230
2023-10-30 11:35:48,562 Epoch: [217/484] Iter:[70/495], Time: 0.40, lr: [0.005851837218302794], Loss: 2.056314, Acc:0.805132, Semantic loss: 0.780958, BCE loss: 0.530007, SB loss: 0.745349
2023-10-30 11:35:52,394 Epoch: [217/484] Iter:[80/495], Time: 0.40, lr: [0.005851438514836945], Loss: 2.049847, Acc:0.806116, Semantic loss: 0.773908, BCE loss: 0.531343, SB loss: 0.744595
2023-10-30 11:35:56,081 Epoch: [217/484] Iter:[90/495], Time: 0.39, lr: [0.0058510398083525495], Loss: 2.050895, Acc:0.803045, Semantic loss: 0.774741, BCE loss: 0.532128, SB loss: 0.744026
2023-10-30 11:35:59,782 Epoch: [217/484] Iter:[100/495], Time: 0.39, lr: [0.005850641098849353], Loss: 2.056106, Acc:0.802419, Semantic loss: 0.778986, BCE loss: 0.531885, SB loss: 0.745235
2023-10-30 11:36:03,472 Epoch: [217/484] Iter:[110/495], Time: 0.39, lr: [0.005850242386327105], Loss: 2.068651, Acc:0.801836, Semantic loss: 0.785739, BCE loss: 0.537353, SB loss: 0.745559
2023-10-30 11:36:07,088 Epoch: [217/484] Iter:[120/495], Time: 0.39, lr: [0.0058498436707855525], Loss: 2.052839, Acc:0.799446, Semantic loss: 0.778187, BCE loss: 0.531434, SB loss: 0.743219
2023-10-30 11:36:10,833 Epoch: [217/484] Iter:[130/495], Time: 0.39, lr: [0.005849444952224448], Loss: 2.050259, Acc:0.799268, Semantic loss: 0.779266, BCE loss: 0.528803, SB loss: 0.742191
2023-10-30 11:36:14,462 Epoch: [217/484] Iter:[140/495], Time: 0.38, lr: [0.0058490462306435365], Loss: 2.054521, Acc:0.798806, Semantic loss: 0.780811, BCE loss: 0.530349, SB loss: 0.743361
2023-10-30 11:36:18,253 Epoch: [217/484] Iter:[150/495], Time: 0.38, lr: [0.005848647506042568], Loss: 2.065156, Acc:0.798826, Semantic loss: 0.784699, BCE loss: 0.534773, SB loss: 0.745684
2023-10-30 11:36:21,947 Epoch: [217/484] Iter:[160/495], Time: 0.38, lr: [0.005848248778421291], Loss: 2.058414, Acc:0.799980, Semantic loss: 0.779468, BCE loss: 0.534769, SB loss: 0.744177
2023-10-30 11:36:25,627 Epoch: [217/484] Iter:[170/495], Time: 0.38, lr: [0.005847850047779453], Loss: 2.054964, Acc:0.799965, Semantic loss: 0.775063, BCE loss: 0.536624, SB loss: 0.743278
2023-10-30 11:36:29,380 Epoch: [217/484] Iter:[180/495], Time: 0.38, lr: [0.005847451314116802], Loss: 2.057752, Acc:0.800540, Semantic loss: 0.776090, BCE loss: 0.538429, SB loss: 0.743233
2023-10-30 11:36:33,142 Epoch: [217/484] Iter:[190/495], Time: 0.38, lr: [0.005847052577433085], Loss: 2.063488, Acc:0.801243, Semantic loss: 0.777890, BCE loss: 0.540473, SB loss: 0.745126
2023-10-30 11:36:36,954 Epoch: [217/484] Iter:[200/495], Time: 0.38, lr: [0.005846653837728054], Loss: 2.062399, Acc:0.801155, Semantic loss: 0.777943, BCE loss: 0.539437, SB loss: 0.745019
2023-10-30 11:36:40,658 Epoch: [217/484] Iter:[210/495], Time: 0.38, lr: [0.005846255095001454], Loss: 2.067802, Acc:0.800519, Semantic loss: 0.778647, BCE loss: 0.544120, SB loss: 0.745034
2023-10-30 11:36:44,293 Epoch: [217/484] Iter:[220/495], Time: 0.38, lr: [0.0058458563492530344], Loss: 2.061879, Acc:0.799368, Semantic loss: 0.777425, BCE loss: 0.541326, SB loss: 0.743128
2023-10-30 11:36:48,124 Epoch: [217/484] Iter:[230/495], Time: 0.38, lr: [0.005845457600482544], Loss: 2.058776, Acc:0.800370, Semantic loss: 0.776447, BCE loss: 0.539540, SB loss: 0.742789
2023-10-30 11:36:51,809 Epoch: [217/484] Iter:[240/495], Time: 0.38, lr: [0.00584505884868973], Loss: 2.059314, Acc:0.801344, Semantic loss: 0.776237, BCE loss: 0.540190, SB loss: 0.742887
2023-10-30 11:36:55,414 Epoch: [217/484] Iter:[250/495], Time: 0.38, lr: [0.005844660093874339], Loss: 2.056659, Acc:0.800200, Semantic loss: 0.776016, BCE loss: 0.538841, SB loss: 0.741802
2023-10-30 11:36:59,174 Epoch: [217/484] Iter:[260/495], Time: 0.38, lr: [0.005844261336036121], Loss: 2.053417, Acc:0.800018, Semantic loss: 0.774146, BCE loss: 0.537887, SB loss: 0.741384
2023-10-30 11:37:02,945 Epoch: [217/484] Iter:[270/495], Time: 0.38, lr: [0.005843862575174822], Loss: 2.053032, Acc:0.799991, Semantic loss: 0.773742, BCE loss: 0.538314, SB loss: 0.740976
2023-10-30 11:37:06,606 Epoch: [217/484] Iter:[280/495], Time: 0.38, lr: [0.005843463811290191], Loss: 2.054883, Acc:0.801119, Semantic loss: 0.773272, BCE loss: 0.540651, SB loss: 0.740960
2023-10-30 11:37:10,183 Epoch: [217/484] Iter:[290/495], Time: 0.38, lr: [0.005843065044381977], Loss: 2.060065, Acc:0.800837, Semantic loss: 0.775773, BCE loss: 0.543054, SB loss: 0.741239
2023-10-30 11:37:13,947 Epoch: [217/484] Iter:[300/495], Time: 0.38, lr: [0.005842666274449927], Loss: 2.059294, Acc:0.800013, Semantic loss: 0.774475, BCE loss: 0.543029, SB loss: 0.741790
2023-10-30 11:37:17,612 Epoch: [217/484] Iter:[310/495], Time: 0.38, lr: [0.005842267501493787], Loss: 2.055443, Acc:0.801178, Semantic loss: 0.771025, BCE loss: 0.543740, SB loss: 0.740678
2023-10-30 11:37:21,361 Epoch: [217/484] Iter:[320/495], Time: 0.38, lr: [0.0058418687255133075], Loss: 2.054023, Acc:0.800748, Semantic loss: 0.769509, BCE loss: 0.544186, SB loss: 0.740328
2023-10-30 11:37:25,012 Epoch: [217/484] Iter:[330/495], Time: 0.38, lr: [0.005841469946508235], Loss: 2.057605, Acc:0.801639, Semantic loss: 0.770305, BCE loss: 0.546464, SB loss: 0.740836
2023-10-30 11:37:28,694 Epoch: [217/484] Iter:[340/495], Time: 0.38, lr: [0.005841071164478315], Loss: 2.053040, Acc:0.801194, Semantic loss: 0.769192, BCE loss: 0.544569, SB loss: 0.739279
2023-10-30 11:37:32,367 Epoch: [217/484] Iter:[350/495], Time: 0.38, lr: [0.005840672379423297], Loss: 2.056430, Acc:0.800448, Semantic loss: 0.770780, BCE loss: 0.545151, SB loss: 0.740500
2023-10-30 11:37:36,009 Epoch: [217/484] Iter:[360/495], Time: 0.38, lr: [0.00584027359134293], Loss: 2.060451, Acc:0.799735, Semantic loss: 0.773575, BCE loss: 0.545048, SB loss: 0.741828
2023-10-30 11:37:39,650 Epoch: [217/484] Iter:[370/495], Time: 0.38, lr: [0.005839874800236959], Loss: 2.055069, Acc:0.797948, Semantic loss: 0.770913, BCE loss: 0.543619, SB loss: 0.740537
2023-10-30 11:37:43,471 Epoch: [217/484] Iter:[380/495], Time: 0.38, lr: [0.0058394760061051335], Loss: 2.058326, Acc:0.798225, Semantic loss: 0.772876, BCE loss: 0.543546, SB loss: 0.741904
2023-10-30 11:37:47,149 Epoch: [217/484] Iter:[390/495], Time: 0.38, lr: [0.0058390772089472], Loss: 2.060818, Acc:0.799462, Semantic loss: 0.772359, BCE loss: 0.546480, SB loss: 0.741979
2023-10-30 11:37:50,807 Epoch: [217/484] Iter:[400/495], Time: 0.38, lr: [0.005838678408762905], Loss: 2.061931, Acc:0.799444, Semantic loss: 0.772896, BCE loss: 0.546667, SB loss: 0.742368
2023-10-30 11:37:54,495 Epoch: [217/484] Iter:[410/495], Time: 0.38, lr: [0.005838279605551998], Loss: 2.060880, Acc:0.799051, Semantic loss: 0.772000, BCE loss: 0.546597, SB loss: 0.742283
2023-10-30 11:37:58,228 Epoch: [217/484] Iter:[420/495], Time: 0.38, lr: [0.005837880799314224], Loss: 2.059259, Acc:0.798475, Semantic loss: 0.771843, BCE loss: 0.544983, SB loss: 0.742432
2023-10-30 11:38:01,913 Epoch: [217/484] Iter:[430/495], Time: 0.37, lr: [0.005837481990049332], Loss: 2.057165, Acc:0.799427, Semantic loss: 0.769678, BCE loss: 0.545618, SB loss: 0.741869
2023-10-30 11:38:05,652 Epoch: [217/484] Iter:[440/495], Time: 0.37, lr: [0.005837083177757068], Loss: 2.060395, Acc:0.798674, Semantic loss: 0.772744, BCE loss: 0.545821, SB loss: 0.741830
2023-10-30 11:38:09,482 Epoch: [217/484] Iter:[450/495], Time: 0.38, lr: [0.005836684362437179], Loss: 2.063607, Acc:0.798758, Semantic loss: 0.775582, BCE loss: 0.545575, SB loss: 0.742450
2023-10-30 11:38:13,163 Epoch: [217/484] Iter:[460/495], Time: 0.37, lr: [0.005836285544089413], Loss: 2.064565, Acc:0.798165, Semantic loss: 0.777385, BCE loss: 0.543804, SB loss: 0.743376
2023-10-30 11:38:16,876 Epoch: [217/484] Iter:[470/495], Time: 0.37, lr: [0.0058358867227135194], Loss: 2.065288, Acc:0.798751, Semantic loss: 0.777558, BCE loss: 0.544216, SB loss: 0.743514
2023-10-30 11:38:20,539 Epoch: [217/484] Iter:[480/495], Time: 0.37, lr: [0.005835487898309241], Loss: 2.066364, Acc:0.798442, Semantic loss: 0.777750, BCE loss: 0.544869, SB loss: 0.743745
2023-10-30 11:38:24,096 Epoch: [217/484] Iter:[490/495], Time: 0.37, lr: [0.005835089070876327], Loss: 2.068614, Acc:0.798095, Semantic loss: 0.778825, BCE loss: 0.544753, SB loss: 0.745036
2023-10-30 11:38:25,508 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:38:25,750 Loss: 2.010, MeanIU:  0.7151, Best_mIoU:  0.7151
2023-10-30 11:38:25,750 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991]
2023-10-30 11:38:28,187 Epoch: [218/484] Iter:[0/495], Time: 2.40, lr: [0.005834889656024053], Loss: 2.309869, Acc:0.921892, Semantic loss: 0.766837, BCE loss: 0.701800, SB loss: 0.841232
2023-10-30 11:38:32,190 Epoch: [218/484] Iter:[10/495], Time: 0.58, lr: [0.005834490824047709], Loss: 2.031426, Acc:0.822748, Semantic loss: 0.718604, BCE loss: 0.585865, SB loss: 0.726957
2023-10-30 11:38:35,774 Epoch: [218/484] Iter:[20/495], Time: 0.48, lr: [0.005834091989042099], Loss: 2.068865, Acc:0.803961, Semantic loss: 0.765914, BCE loss: 0.567246, SB loss: 0.735704
2023-10-30 11:38:39,424 Epoch: [218/484] Iter:[30/495], Time: 0.44, lr: [0.005833693151006966], Loss: 2.016042, Acc:0.801588, Semantic loss: 0.730811, BCE loss: 0.549945, SB loss: 0.735285
2023-10-30 11:38:43,084 Epoch: [218/484] Iter:[40/495], Time: 0.42, lr: [0.005833294309942059], Loss: 2.018914, Acc:0.807620, Semantic loss: 0.737761, BCE loss: 0.550405, SB loss: 0.730749
2023-10-30 11:38:46,726 Epoch: [218/484] Iter:[50/495], Time: 0.41, lr: [0.005832895465847123], Loss: 1.993709, Acc:0.803322, Semantic loss: 0.729314, BCE loss: 0.538546, SB loss: 0.725848
2023-10-30 11:38:50,331 Epoch: [218/484] Iter:[60/495], Time: 0.40, lr: [0.005832496618721907], Loss: 1.999725, Acc:0.795420, Semantic loss: 0.733967, BCE loss: 0.534436, SB loss: 0.731322
2023-10-30 11:38:54,001 Epoch: [218/484] Iter:[70/495], Time: 0.40, lr: [0.0058320977685661565], Loss: 1.982678, Acc:0.790565, Semantic loss: 0.726444, BCE loss: 0.531986, SB loss: 0.724249
2023-10-30 11:38:57,699 Epoch: [218/484] Iter:[80/495], Time: 0.39, lr: [0.005831698915379618], Loss: 1.997421, Acc:0.795321, Semantic loss: 0.733543, BCE loss: 0.537218, SB loss: 0.726660
2023-10-30 11:39:01,384 Epoch: [218/484] Iter:[90/495], Time: 0.39, lr: [0.005831300059162038], Loss: 2.015690, Acc:0.794239, Semantic loss: 0.741166, BCE loss: 0.542987, SB loss: 0.731537
2023-10-30 11:39:05,190 Epoch: [218/484] Iter:[100/495], Time: 0.39, lr: [0.0058309011999131645], Loss: 2.022328, Acc:0.798687, Semantic loss: 0.746361, BCE loss: 0.540314, SB loss: 0.735653
2023-10-30 11:39:08,824 Epoch: [218/484] Iter:[110/495], Time: 0.39, lr: [0.005830502337632741], Loss: 2.019881, Acc:0.800552, Semantic loss: 0.753989, BCE loss: 0.533064, SB loss: 0.732828
2023-10-30 11:39:12,399 Epoch: [218/484] Iter:[120/495], Time: 0.39, lr: [0.0058301034723205174], Loss: 2.029424, Acc:0.793635, Semantic loss: 0.763268, BCE loss: 0.531872, SB loss: 0.734284
2023-10-30 11:39:16,121 Epoch: [218/484] Iter:[130/495], Time: 0.38, lr: [0.0058297046039762395], Loss: 2.026905, Acc:0.789629, Semantic loss: 0.759617, BCE loss: 0.531856, SB loss: 0.735432
2023-10-30 11:39:19,775 Epoch: [218/484] Iter:[140/495], Time: 0.38, lr: [0.005829305732599653], Loss: 2.032320, Acc:0.789691, Semantic loss: 0.762603, BCE loss: 0.530671, SB loss: 0.739047
2023-10-30 11:39:23,462 Epoch: [218/484] Iter:[150/495], Time: 0.38, lr: [0.005828906858190504], Loss: 2.039851, Acc:0.790282, Semantic loss: 0.766222, BCE loss: 0.532240, SB loss: 0.741389
2023-10-30 11:39:27,116 Epoch: [218/484] Iter:[160/495], Time: 0.38, lr: [0.005828507980748539], Loss: 2.039350, Acc:0.792134, Semantic loss: 0.763636, BCE loss: 0.534179, SB loss: 0.741535
2023-10-30 11:39:30,800 Epoch: [218/484] Iter:[170/495], Time: 0.38, lr: [0.005828109100273503], Loss: 2.039793, Acc:0.794239, Semantic loss: 0.760312, BCE loss: 0.537051, SB loss: 0.742430
2023-10-30 11:39:34,512 Epoch: [218/484] Iter:[180/495], Time: 0.38, lr: [0.0058277102167651465], Loss: 2.037634, Acc:0.795847, Semantic loss: 0.761524, BCE loss: 0.533897, SB loss: 0.742213
2023-10-30 11:39:38,260 Epoch: [218/484] Iter:[190/495], Time: 0.38, lr: [0.005827311330223211], Loss: 2.038557, Acc:0.796599, Semantic loss: 0.762772, BCE loss: 0.535032, SB loss: 0.740753
2023-10-30 11:39:42,073 Epoch: [218/484] Iter:[200/495], Time: 0.38, lr: [0.005826912440647446], Loss: 2.039761, Acc:0.796305, Semantic loss: 0.763566, BCE loss: 0.535219, SB loss: 0.740977
2023-10-30 11:39:45,741 Epoch: [218/484] Iter:[210/495], Time: 0.38, lr: [0.005826513548037596], Loss: 2.035178, Acc:0.797405, Semantic loss: 0.761390, BCE loss: 0.533573, SB loss: 0.740216
2023-10-30 11:39:49,518 Epoch: [218/484] Iter:[220/495], Time: 0.38, lr: [0.005826114652393409], Loss: 2.052817, Acc:0.795651, Semantic loss: 0.775047, BCE loss: 0.535189, SB loss: 0.742582
2023-10-30 11:39:53,381 Epoch: [218/484] Iter:[230/495], Time: 0.38, lr: [0.0058257157537146284], Loss: 2.057183, Acc:0.796294, Semantic loss: 0.773721, BCE loss: 0.541605, SB loss: 0.741856
2023-10-30 11:39:57,062 Epoch: [218/484] Iter:[240/495], Time: 0.38, lr: [0.005825316852001002], Loss: 2.056305, Acc:0.797213, Semantic loss: 0.774266, BCE loss: 0.540969, SB loss: 0.741070
2023-10-30 11:40:00,809 Epoch: [218/484] Iter:[250/495], Time: 0.38, lr: [0.005824917947252274], Loss: 2.061005, Acc:0.798211, Semantic loss: 0.774890, BCE loss: 0.543183, SB loss: 0.742932
2023-10-30 11:40:04,394 Epoch: [218/484] Iter:[260/495], Time: 0.38, lr: [0.005824519039468194], Loss: 2.058796, Acc:0.797968, Semantic loss: 0.773637, BCE loss: 0.543515, SB loss: 0.741644
2023-10-30 11:40:07,999 Epoch: [218/484] Iter:[270/495], Time: 0.38, lr: [0.005824120128648503], Loss: 2.058842, Acc:0.797481, Semantic loss: 0.772907, BCE loss: 0.543973, SB loss: 0.741963
2023-10-30 11:40:11,685 Epoch: [218/484] Iter:[280/495], Time: 0.38, lr: [0.00582372121479295], Loss: 2.056255, Acc:0.798511, Semantic loss: 0.774826, BCE loss: 0.540519, SB loss: 0.740909
2023-10-30 11:40:15,259 Epoch: [218/484] Iter:[290/495], Time: 0.38, lr: [0.005823322297901282], Loss: 2.055848, Acc:0.798209, Semantic loss: 0.773573, BCE loss: 0.541140, SB loss: 0.741135
2023-10-30 11:40:18,968 Epoch: [218/484] Iter:[300/495], Time: 0.38, lr: [0.005822923377973243], Loss: 2.047806, Acc:0.796595, Semantic loss: 0.769407, BCE loss: 0.538622, SB loss: 0.739777
2023-10-30 11:40:22,688 Epoch: [218/484] Iter:[310/495], Time: 0.38, lr: [0.005822524455008578], Loss: 2.045956, Acc:0.797367, Semantic loss: 0.768670, BCE loss: 0.536655, SB loss: 0.740632
2023-10-30 11:40:26,331 Epoch: [218/484] Iter:[320/495], Time: 0.38, lr: [0.005822125529007033], Loss: 2.052083, Acc:0.797059, Semantic loss: 0.775640, BCE loss: 0.535173, SB loss: 0.741271
2023-10-30 11:40:29,992 Epoch: [218/484] Iter:[330/495], Time: 0.38, lr: [0.005821726599968355], Loss: 2.053555, Acc:0.795876, Semantic loss: 0.775631, BCE loss: 0.536199, SB loss: 0.741726
2023-10-30 11:40:33,641 Epoch: [218/484] Iter:[340/495], Time: 0.37, lr: [0.005821327667892288], Loss: 2.056345, Acc:0.796122, Semantic loss: 0.777092, BCE loss: 0.537110, SB loss: 0.742143
2023-10-30 11:40:37,383 Epoch: [218/484] Iter:[350/495], Time: 0.37, lr: [0.005820928732778579], Loss: 2.057749, Acc:0.795351, Semantic loss: 0.778691, BCE loss: 0.537066, SB loss: 0.741992
2023-10-30 11:40:41,041 Epoch: [218/484] Iter:[360/495], Time: 0.37, lr: [0.005820529794626973], Loss: 2.058481, Acc:0.795462, Semantic loss: 0.780572, BCE loss: 0.535815, SB loss: 0.742094
2023-10-30 11:40:44,735 Epoch: [218/484] Iter:[370/495], Time: 0.37, lr: [0.005820130853437216], Loss: 2.055379, Acc:0.795373, Semantic loss: 0.778309, BCE loss: 0.535256, SB loss: 0.741814
2023-10-30 11:40:48,451 Epoch: [218/484] Iter:[380/495], Time: 0.37, lr: [0.005819731909209052], Loss: 2.054136, Acc:0.793913, Semantic loss: 0.778599, BCE loss: 0.533379, SB loss: 0.742159
2023-10-30 11:40:52,147 Epoch: [218/484] Iter:[390/495], Time: 0.37, lr: [0.005819332961942229], Loss: 2.055285, Acc:0.794031, Semantic loss: 0.778665, BCE loss: 0.533408, SB loss: 0.743213
2023-10-30 11:40:55,908 Epoch: [218/484] Iter:[400/495], Time: 0.37, lr: [0.00581893401163649], Loss: 2.057239, Acc:0.793572, Semantic loss: 0.780417, BCE loss: 0.533122, SB loss: 0.743701
2023-10-30 11:40:59,642 Epoch: [218/484] Iter:[410/495], Time: 0.37, lr: [0.00581853505829158], Loss: 2.057932, Acc:0.794303, Semantic loss: 0.779863, BCE loss: 0.534747, SB loss: 0.743323
2023-10-30 11:41:03,357 Epoch: [218/484] Iter:[420/495], Time: 0.37, lr: [0.005818136101907246], Loss: 2.062567, Acc:0.793297, Semantic loss: 0.783571, BCE loss: 0.534275, SB loss: 0.744721
2023-10-30 11:41:07,045 Epoch: [218/484] Iter:[430/495], Time: 0.37, lr: [0.005817737142483233], Loss: 2.061894, Acc:0.793570, Semantic loss: 0.783355, BCE loss: 0.533731, SB loss: 0.744809
2023-10-30 11:41:10,728 Epoch: [218/484] Iter:[440/495], Time: 0.37, lr: [0.005817338180019286], Loss: 2.065784, Acc:0.792811, Semantic loss: 0.786443, BCE loss: 0.533781, SB loss: 0.745560
2023-10-30 11:41:14,370 Epoch: [218/484] Iter:[450/495], Time: 0.37, lr: [0.00581693921451515], Loss: 2.067296, Acc:0.793134, Semantic loss: 0.785784, BCE loss: 0.535358, SB loss: 0.746154
2023-10-30 11:41:18,183 Epoch: [218/484] Iter:[460/495], Time: 0.37, lr: [0.0058165402459705706], Loss: 2.068128, Acc:0.793487, Semantic loss: 0.785682, BCE loss: 0.536090, SB loss: 0.746356
2023-10-30 11:41:21,960 Epoch: [218/484] Iter:[470/495], Time: 0.37, lr: [0.0058161412743852935], Loss: 2.067331, Acc:0.793621, Semantic loss: 0.784787, BCE loss: 0.535810, SB loss: 0.746734
2023-10-30 11:41:25,677 Epoch: [218/484] Iter:[480/495], Time: 0.37, lr: [0.005815742299759062], Loss: 2.063912, Acc:0.792739, Semantic loss: 0.783354, BCE loss: 0.534376, SB loss: 0.746182
2023-10-30 11:41:29,170 Epoch: [218/484] Iter:[490/495], Time: 0.37, lr: [0.0058153433220916205], Loss: 2.065600, Acc:0.792475, Semantic loss: 0.783993, BCE loss: 0.534788, SB loss: 0.746819
2023-10-30 11:41:30,583 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:41:30,824 Loss: 2.010, MeanIU:  0.7151, Best_mIoU:  0.7151
2023-10-30 11:41:30,824 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991]
2023-10-30 11:41:33,032 Epoch: [219/484] Iter:[0/495], Time: 2.17, lr: [0.005815143832117368], Loss: 2.140481, Acc:0.816323, Semantic loss: 0.858693, BCE loss: 0.509640, SB loss: 0.772148
2023-10-30 11:41:37,208 Epoch: [219/484] Iter:[10/495], Time: 0.58, lr: [0.005814744849887636], Loss: 1.960422, Acc:0.812831, Semantic loss: 0.763211, BCE loss: 0.483143, SB loss: 0.714067
2023-10-30 11:41:41,025 Epoch: [219/484] Iter:[20/495], Time: 0.48, lr: [0.005814345864616059], Loss: 2.021690, Acc:0.813135, Semantic loss: 0.782013, BCE loss: 0.517109, SB loss: 0.722569
2023-10-30 11:41:44,639 Epoch: [219/484] Iter:[30/495], Time: 0.44, lr: [0.005813946876302381], Loss: 2.027225, Acc:0.811967, Semantic loss: 0.765594, BCE loss: 0.536083, SB loss: 0.725548
2023-10-30 11:41:48,437 Epoch: [219/484] Iter:[40/495], Time: 0.43, lr: [0.005813547884946347], Loss: 2.030324, Acc:0.822259, Semantic loss: 0.765037, BCE loss: 0.534725, SB loss: 0.730561
2023-10-30 11:41:52,104 Epoch: [219/484] Iter:[50/495], Time: 0.42, lr: [0.0058131488905477], Loss: 2.033224, Acc:0.807606, Semantic loss: 0.774316, BCE loss: 0.525341, SB loss: 0.733566
2023-10-30 11:41:55,831 Epoch: [219/484] Iter:[60/495], Time: 0.41, lr: [0.005812749893106186], Loss: 2.039205, Acc:0.803926, Semantic loss: 0.766579, BCE loss: 0.538943, SB loss: 0.733684
2023-10-30 11:41:59,512 Epoch: [219/484] Iter:[70/495], Time: 0.40, lr: [0.00581235089262155], Loss: 2.067475, Acc:0.795280, Semantic loss: 0.783036, BCE loss: 0.544074, SB loss: 0.740366
2023-10-30 11:42:03,150 Epoch: [219/484] Iter:[80/495], Time: 0.40, lr: [0.005811951889093537], Loss: 2.086291, Acc:0.793868, Semantic loss: 0.796501, BCE loss: 0.541123, SB loss: 0.748666
2023-10-30 11:42:06,858 Epoch: [219/484] Iter:[90/495], Time: 0.40, lr: [0.00581155288252189], Loss: 2.067722, Acc:0.792171, Semantic loss: 0.782362, BCE loss: 0.541350, SB loss: 0.744010
2023-10-30 11:42:10,704 Epoch: [219/484] Iter:[100/495], Time: 0.39, lr: [0.005811153872906356], Loss: 2.081902, Acc:0.792191, Semantic loss: 0.788949, BCE loss: 0.543354, SB loss: 0.749599
2023-10-30 11:42:14,492 Epoch: [219/484] Iter:[110/495], Time: 0.39, lr: [0.005810754860246677], Loss: 2.073549, Acc:0.792925, Semantic loss: 0.781504, BCE loss: 0.545274, SB loss: 0.746770
2023-10-30 11:42:18,139 Epoch: [219/484] Iter:[120/495], Time: 0.39, lr: [0.0058103558445426005], Loss: 2.084371, Acc:0.796117, Semantic loss: 0.787934, BCE loss: 0.549494, SB loss: 0.746944
2023-10-30 11:42:21,877 Epoch: [219/484] Iter:[130/495], Time: 0.39, lr: [0.00580995682579387], Loss: 2.091296, Acc:0.798407, Semantic loss: 0.790655, BCE loss: 0.551528, SB loss: 0.749113
2023-10-30 11:42:25,613 Epoch: [219/484] Iter:[140/495], Time: 0.39, lr: [0.005809557804000227], Loss: 2.102013, Acc:0.796543, Semantic loss: 0.794159, BCE loss: 0.555570, SB loss: 0.752284
2023-10-30 11:42:29,287 Epoch: [219/484] Iter:[150/495], Time: 0.39, lr: [0.005809158779161418], Loss: 2.096402, Acc:0.797277, Semantic loss: 0.789776, BCE loss: 0.556141, SB loss: 0.750485
2023-10-30 11:42:33,134 Epoch: [219/484] Iter:[160/495], Time: 0.39, lr: [0.005808759751277188], Loss: 2.090177, Acc:0.798019, Semantic loss: 0.786853, BCE loss: 0.554594, SB loss: 0.748731
2023-10-30 11:42:36,841 Epoch: [219/484] Iter:[170/495], Time: 0.39, lr: [0.0058083607203472795], Loss: 2.080923, Acc:0.799643, Semantic loss: 0.782073, BCE loss: 0.552834, SB loss: 0.746017
2023-10-30 11:42:40,597 Epoch: [219/484] Iter:[180/495], Time: 0.39, lr: [0.00580796168637144], Loss: 2.075969, Acc:0.800004, Semantic loss: 0.779287, BCE loss: 0.552015, SB loss: 0.744667
2023-10-30 11:42:44,306 Epoch: [219/484] Iter:[190/495], Time: 0.38, lr: [0.0058075626493494115], Loss: 2.080846, Acc:0.800246, Semantic loss: 0.785252, BCE loss: 0.549789, SB loss: 0.745805
2023-10-30 11:42:48,030 Epoch: [219/484] Iter:[200/495], Time: 0.38, lr: [0.005807163609280939], Loss: 2.078688, Acc:0.799923, Semantic loss: 0.783915, BCE loss: 0.547961, SB loss: 0.746811
2023-10-30 11:42:51,768 Epoch: [219/484] Iter:[210/495], Time: 0.38, lr: [0.005806764566165765], Loss: 2.086713, Acc:0.799812, Semantic loss: 0.789296, BCE loss: 0.548638, SB loss: 0.748779
2023-10-30 11:42:55,480 Epoch: [219/484] Iter:[220/495], Time: 0.38, lr: [0.005806365520003635], Loss: 2.090404, Acc:0.801148, Semantic loss: 0.789463, BCE loss: 0.551626, SB loss: 0.749316
2023-10-30 11:42:59,218 Epoch: [219/484] Iter:[230/495], Time: 0.38, lr: [0.005805966470794292], Loss: 2.083594, Acc:0.800749, Semantic loss: 0.785936, BCE loss: 0.548546, SB loss: 0.749112
2023-10-30 11:43:02,901 Epoch: [219/484] Iter:[240/495], Time: 0.38, lr: [0.005805567418537481], Loss: 2.083175, Acc:0.801646, Semantic loss: 0.785416, BCE loss: 0.549299, SB loss: 0.748460
2023-10-30 11:43:06,709 Epoch: [219/484] Iter:[250/495], Time: 0.38, lr: [0.005805168363232944], Loss: 2.088335, Acc:0.802128, Semantic loss: 0.786163, BCE loss: 0.551793, SB loss: 0.750380
2023-10-30 11:43:10,420 Epoch: [219/484] Iter:[260/495], Time: 0.38, lr: [0.0058047693048804295], Loss: 2.081696, Acc:0.801631, Semantic loss: 0.782738, BCE loss: 0.550354, SB loss: 0.748604
2023-10-30 11:43:14,295 Epoch: [219/484] Iter:[270/495], Time: 0.38, lr: [0.005804370243479677], Loss: 2.076274, Acc:0.802668, Semantic loss: 0.780734, BCE loss: 0.548784, SB loss: 0.746755
2023-10-30 11:43:18,080 Epoch: [219/484] Iter:[280/495], Time: 0.38, lr: [0.0058039711790304335], Loss: 2.069354, Acc:0.803089, Semantic loss: 0.778767, BCE loss: 0.545806, SB loss: 0.744781
2023-10-30 11:43:21,826 Epoch: [219/484] Iter:[290/495], Time: 0.38, lr: [0.00580357211153244], Loss: 2.070155, Acc:0.802438, Semantic loss: 0.780399, BCE loss: 0.545276, SB loss: 0.744480
2023-10-30 11:43:25,488 Epoch: [219/484] Iter:[300/495], Time: 0.38, lr: [0.0058031730409854425], Loss: 2.070701, Acc:0.802694, Semantic loss: 0.781241, BCE loss: 0.544896, SB loss: 0.744564
2023-10-30 11:43:29,125 Epoch: [219/484] Iter:[310/495], Time: 0.38, lr: [0.005802773967389181], Loss: 2.070493, Acc:0.802729, Semantic loss: 0.781510, BCE loss: 0.544419, SB loss: 0.744564
2023-10-30 11:43:32,965 Epoch: [219/484] Iter:[320/495], Time: 0.38, lr: [0.005802374890743405], Loss: 2.070958, Acc:0.803110, Semantic loss: 0.781584, BCE loss: 0.545733, SB loss: 0.743641
2023-10-30 11:43:36,640 Epoch: [219/484] Iter:[330/495], Time: 0.38, lr: [0.005801975811047853], Loss: 2.072019, Acc:0.803993, Semantic loss: 0.781686, BCE loss: 0.545992, SB loss: 0.744342
2023-10-30 11:43:40,391 Epoch: [219/484] Iter:[340/495], Time: 0.38, lr: [0.005801576728302271], Loss: 2.065035, Acc:0.804020, Semantic loss: 0.778061, BCE loss: 0.544099, SB loss: 0.742875
2023-10-30 11:43:44,013 Epoch: [219/484] Iter:[350/495], Time: 0.38, lr: [0.0058011776425064025], Loss: 2.065502, Acc:0.803109, Semantic loss: 0.780109, BCE loss: 0.541990, SB loss: 0.743404
2023-10-30 11:43:47,839 Epoch: [219/484] Iter:[360/495], Time: 0.38, lr: [0.0058007785536599915], Loss: 2.066240, Acc:0.802615, Semantic loss: 0.779436, BCE loss: 0.543724, SB loss: 0.743079
2023-10-30 11:43:51,630 Epoch: [219/484] Iter:[370/495], Time: 0.38, lr: [0.00580037946176278], Loss: 2.071523, Acc:0.802747, Semantic loss: 0.782513, BCE loss: 0.544264, SB loss: 0.744746
2023-10-30 11:43:55,424 Epoch: [219/484] Iter:[380/495], Time: 0.38, lr: [0.0057999803668145125], Loss: 2.071706, Acc:0.803074, Semantic loss: 0.782127, BCE loss: 0.545122, SB loss: 0.744456
2023-10-30 11:43:59,086 Epoch: [219/484] Iter:[390/495], Time: 0.38, lr: [0.005799581268814931], Loss: 2.066953, Acc:0.802988, Semantic loss: 0.779498, BCE loss: 0.543761, SB loss: 0.743693
2023-10-30 11:44:02,746 Epoch: [219/484] Iter:[400/495], Time: 0.38, lr: [0.005799182167763781], Loss: 2.067627, Acc:0.802971, Semantic loss: 0.779589, BCE loss: 0.543181, SB loss: 0.744856
2023-10-30 11:44:06,449 Epoch: [219/484] Iter:[410/495], Time: 0.38, lr: [0.005798783063660804], Loss: 2.070934, Acc:0.802946, Semantic loss: 0.783036, BCE loss: 0.542814, SB loss: 0.745084
2023-10-30 11:44:10,201 Epoch: [219/484] Iter:[420/495], Time: 0.38, lr: [0.005798383956505745], Loss: 2.067118, Acc:0.803371, Semantic loss: 0.779275, BCE loss: 0.543109, SB loss: 0.744735
2023-10-30 11:44:13,970 Epoch: [219/484] Iter:[430/495], Time: 0.38, lr: [0.005797984846298346], Loss: 2.064487, Acc:0.803110, Semantic loss: 0.777822, BCE loss: 0.542387, SB loss: 0.744278
2023-10-30 11:44:17,719 Epoch: [219/484] Iter:[440/495], Time: 0.38, lr: [0.00579758573303835], Loss: 2.069323, Acc:0.802980, Semantic loss: 0.780786, BCE loss: 0.542893, SB loss: 0.745644
2023-10-30 11:44:21,423 Epoch: [219/484] Iter:[450/495], Time: 0.38, lr: [0.005797186616725502], Loss: 2.067817, Acc:0.802251, Semantic loss: 0.780568, BCE loss: 0.541835, SB loss: 0.745413
2023-10-30 11:44:25,128 Epoch: [219/484] Iter:[460/495], Time: 0.38, lr: [0.005796787497359541], Loss: 2.066069, Acc:0.802096, Semantic loss: 0.779917, BCE loss: 0.540660, SB loss: 0.745493
2023-10-30 11:44:28,911 Epoch: [219/484] Iter:[470/495], Time: 0.38, lr: [0.005796388374940215], Loss: 2.066024, Acc:0.801947, Semantic loss: 0.779610, BCE loss: 0.540785, SB loss: 0.745629
2023-10-30 11:44:32,641 Epoch: [219/484] Iter:[480/495], Time: 0.38, lr: [0.0057959892494672625], Loss: 2.066862, Acc:0.801335, Semantic loss: 0.780323, BCE loss: 0.541096, SB loss: 0.745443
2023-10-30 11:44:36,150 Epoch: [219/484] Iter:[490/495], Time: 0.38, lr: [0.005795590120940432], Loss: 2.066055, Acc:0.801114, Semantic loss: 0.779237, BCE loss: 0.541008, SB loss: 0.745810
2023-10-30 11:44:37,562 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:44:37,799 Loss: 2.010, MeanIU:  0.7151, Best_mIoU:  0.7151
2023-10-30 11:44:37,800 [0.97491956 0.80777964 0.90725412 0.44179844 0.57902992 0.58518101
 0.65928385 0.71509825 0.90744069 0.57643605 0.93195166 0.76241461
 0.54063855 0.93041265 0.6765454  0.75396619 0.59248552 0.51331855
 0.73147991]
2023-10-30 11:44:39,907 Epoch: [220/484] Iter:[0/495], Time: 2.07, lr: [0.00579539055553173], Loss: 1.965057, Acc:0.837974, Semantic loss: 0.800445, BCE loss: 0.395457, SB loss: 0.769156
2023-10-30 11:44:43,966 Epoch: [220/484] Iter:[10/495], Time: 0.56, lr: [0.005794991422423595], Loss: 2.031232, Acc:0.819730, Semantic loss: 0.747480, BCE loss: 0.557792, SB loss: 0.725960
2023-10-30 11:44:47,703 Epoch: [220/484] Iter:[20/495], Time: 0.47, lr: [0.0057945922862609345], Loss: 2.023503, Acc:0.807348, Semantic loss: 0.757901, BCE loss: 0.532632, SB loss: 0.732971
2023-10-30 11:44:51,457 Epoch: [220/484] Iter:[30/495], Time: 0.44, lr: [0.005794193147043495], Loss: 2.058186, Acc:0.795475, Semantic loss: 0.789595, BCE loss: 0.526408, SB loss: 0.742183
2023-10-30 11:44:55,133 Epoch: [220/484] Iter:[40/495], Time: 0.42, lr: [0.005793794004771016], Loss: 2.077065, Acc:0.801948, Semantic loss: 0.789965, BCE loss: 0.536961, SB loss: 0.750139
2023-10-30 11:44:58,843 Epoch: [220/484] Iter:[50/495], Time: 0.41, lr: [0.005793394859443241], Loss: 2.106841, Acc:0.794927, Semantic loss: 0.821930, BCE loss: 0.530142, SB loss: 0.754769
2023-10-30 11:45:02,536 Epoch: [220/484] Iter:[60/495], Time: 0.40, lr: [0.005792995711059914], Loss: 2.113004, Acc:0.792356, Semantic loss: 0.824441, BCE loss: 0.535138, SB loss: 0.753426
2023-10-30 11:45:06,252 Epoch: [220/484] Iter:[70/495], Time: 0.40, lr: [0.0057925965596207765], Loss: 2.118950, Acc:0.789607, Semantic loss: 0.822659, BCE loss: 0.542760, SB loss: 0.753531
2023-10-30 11:45:09,997 Epoch: [220/484] Iter:[80/495], Time: 0.40, lr: [0.005792197405125571], Loss: 2.118451, Acc:0.786909, Semantic loss: 0.813638, BCE loss: 0.547546, SB loss: 0.757267
2023-10-30 11:45:13,890 Epoch: [220/484] Iter:[90/495], Time: 0.40, lr: [0.005791798247574043], Loss: 2.115019, Acc:0.785629, Semantic loss: 0.811114, BCE loss: 0.546885, SB loss: 0.757020
2023-10-30 11:45:17,691 Epoch: [220/484] Iter:[100/495], Time: 0.39, lr: [0.00579139908696593], Loss: 2.116903, Acc:0.790229, Semantic loss: 0.804210, BCE loss: 0.555049, SB loss: 0.757644
2023-10-30 11:45:21,370 Epoch: [220/484] Iter:[110/495], Time: 0.39, lr: [0.005790999923300981], Loss: 2.099879, Acc:0.789001, Semantic loss: 0.798737, BCE loss: 0.547018, SB loss: 0.754124
2023-10-30 11:45:25,092 Epoch: [220/484] Iter:[120/495], Time: 0.39, lr: [0.0057906007565789305], Loss: 2.097273, Acc:0.790000, Semantic loss: 0.799297, BCE loss: 0.545711, SB loss: 0.752265
2023-10-30 11:45:28,788 Epoch: [220/484] Iter:[130/495], Time: 0.39, lr: [0.005790201586799527], Loss: 2.082639, Acc:0.789256, Semantic loss: 0.792352, BCE loss: 0.540848, SB loss: 0.749439
2023-10-30 11:45:32,405 Epoch: [220/484] Iter:[140/495], Time: 0.39, lr: [0.00578980241396251], Loss: 2.066520, Acc:0.790637, Semantic loss: 0.784284, BCE loss: 0.535699, SB loss: 0.746537
2023-10-30 11:45:36,137 Epoch: [220/484] Iter:[150/495], Time: 0.39, lr: [0.005789403238067624], Loss: 2.068571, Acc:0.792641, Semantic loss: 0.783687, BCE loss: 0.538422, SB loss: 0.746461
2023-10-30 11:45:39,935 Epoch: [220/484] Iter:[160/495], Time: 0.39, lr: [0.005789004059114609], Loss: 2.074125, Acc:0.793675, Semantic loss: 0.787577, BCE loss: 0.538068, SB loss: 0.748480
2023-10-30 11:45:43,664 Epoch: [220/484] Iter:[170/495], Time: 0.38, lr: [0.0057886048771032105], Loss: 2.068835, Acc:0.793965, Semantic loss: 0.782994, BCE loss: 0.536936, SB loss: 0.748904
2023-10-30 11:45:47,349 Epoch: [220/484] Iter:[180/495], Time: 0.38, lr: [0.005788205692033168], Loss: 2.073391, Acc:0.794665, Semantic loss: 0.784815, BCE loss: 0.538365, SB loss: 0.750211
2023-10-30 11:45:51,087 Epoch: [220/484] Iter:[190/495], Time: 0.38, lr: [0.005787806503904223], Loss: 2.071088, Acc:0.794657, Semantic loss: 0.782623, BCE loss: 0.538517, SB loss: 0.749948
2023-10-30 11:45:54,779 Epoch: [220/484] Iter:[200/495], Time: 0.38, lr: [0.005787407312716121], Loss: 2.075344, Acc:0.793751, Semantic loss: 0.783778, BCE loss: 0.539922, SB loss: 0.751644
2023-10-30 11:45:58,440 Epoch: [220/484] Iter:[210/495], Time: 0.38, lr: [0.005787008118468601], Loss: 2.075559, Acc:0.792905, Semantic loss: 0.783337, BCE loss: 0.539355, SB loss: 0.752867
2023-10-30 11:46:02,221 Epoch: [220/484] Iter:[220/495], Time: 0.38, lr: [0.005786608921161406], Loss: 2.068482, Acc:0.794068, Semantic loss: 0.780710, BCE loss: 0.536158, SB loss: 0.751614
2023-10-30 11:46:05,998 Epoch: [220/484] Iter:[230/495], Time: 0.38, lr: [0.005786209720794278], Loss: 2.069134, Acc:0.794824, Semantic loss: 0.781309, BCE loss: 0.535658, SB loss: 0.752166
2023-10-30 11:46:09,949 Epoch: [220/484] Iter:[240/495], Time: 0.38, lr: [0.00578581051736696], Loss: 2.063740, Acc:0.794727, Semantic loss: 0.779524, BCE loss: 0.533697, SB loss: 0.750520
2023-10-30 11:46:13,676 Epoch: [220/484] Iter:[250/495], Time: 0.38, lr: [0.005785411310879192], Loss: 2.067731, Acc:0.796295, Semantic loss: 0.780025, BCE loss: 0.536899, SB loss: 0.750807
2023-10-30 11:46:17,370 Epoch: [220/484] Iter:[260/495], Time: 0.38, lr: [0.005785012101330718], Loss: 2.073466, Acc:0.796383, Semantic loss: 0.786510, BCE loss: 0.536421, SB loss: 0.750536
2023-10-30 11:46:21,137 Epoch: [220/484] Iter:[270/495], Time: 0.38, lr: [0.005784612888721278], Loss: 2.072786, Acc:0.796697, Semantic loss: 0.784675, BCE loss: 0.537905, SB loss: 0.750206
2023-10-30 11:46:24,780 Epoch: [220/484] Iter:[280/495], Time: 0.38, lr: [0.005784213673050616], Loss: 2.069445, Acc:0.795925, Semantic loss: 0.781622, BCE loss: 0.539218, SB loss: 0.748605
2023-10-30 11:46:28,512 Epoch: [220/484] Iter:[290/495], Time: 0.38, lr: [0.00578381445431847], Loss: 2.067961, Acc:0.795656, Semantic loss: 0.781384, BCE loss: 0.538521, SB loss: 0.748056
2023-10-30 11:46:32,275 Epoch: [220/484] Iter:[300/495], Time: 0.38, lr: [0.005783415232524586], Loss: 2.065509, Acc:0.796280, Semantic loss: 0.779429, BCE loss: 0.539502, SB loss: 0.746578
2023-10-30 11:46:35,898 Epoch: [220/484] Iter:[310/495], Time: 0.38, lr: [0.005783016007668702], Loss: 2.062854, Acc:0.795436, Semantic loss: 0.778864, BCE loss: 0.538003, SB loss: 0.745987
2023-10-30 11:46:39,723 Epoch: [220/484] Iter:[320/495], Time: 0.38, lr: [0.005782616779750563], Loss: 2.058179, Acc:0.794308, Semantic loss: 0.776683, BCE loss: 0.536246, SB loss: 0.745250
2023-10-30 11:46:43,554 Epoch: [220/484] Iter:[330/495], Time: 0.38, lr: [0.005782217548769909], Loss: 2.058539, Acc:0.793893, Semantic loss: 0.775898, BCE loss: 0.537401, SB loss: 0.745240
2023-10-30 11:46:47,343 Epoch: [220/484] Iter:[340/495], Time: 0.38, lr: [0.005781818314726481], Loss: 2.058533, Acc:0.793722, Semantic loss: 0.775801, BCE loss: 0.537321, SB loss: 0.745411
2023-10-30 11:46:51,082 Epoch: [220/484] Iter:[350/495], Time: 0.38, lr: [0.005781419077620022], Loss: 2.058275, Acc:0.793059, Semantic loss: 0.775148, BCE loss: 0.537361, SB loss: 0.745765
2023-10-30 11:46:54,799 Epoch: [220/484] Iter:[360/495], Time: 0.38, lr: [0.005781019837450271], Loss: 2.055550, Acc:0.793810, Semantic loss: 0.774322, BCE loss: 0.536871, SB loss: 0.744357
2023-10-30 11:46:58,554 Epoch: [220/484] Iter:[370/495], Time: 0.38, lr: [0.005780620594216972], Loss: 2.052819, Acc:0.793901, Semantic loss: 0.773412, BCE loss: 0.535726, SB loss: 0.743681
2023-10-30 11:47:02,370 Epoch: [220/484] Iter:[380/495], Time: 0.38, lr: [0.005780221347919865], Loss: 2.056511, Acc:0.793700, Semantic loss: 0.774640, BCE loss: 0.536838, SB loss: 0.745033
2023-10-30 11:47:06,016 Epoch: [220/484] Iter:[390/495], Time: 0.38, lr: [0.005779822098558692], Loss: 2.055591, Acc:0.793705, Semantic loss: 0.773703, BCE loss: 0.536488, SB loss: 0.745400
2023-10-30 11:47:09,757 Epoch: [220/484] Iter:[400/495], Time: 0.38, lr: [0.005779422846133196], Loss: 2.055510, Acc:0.793841, Semantic loss: 0.774629, BCE loss: 0.535165, SB loss: 0.745717
2023-10-30 11:47:13,567 Epoch: [220/484] Iter:[410/495], Time: 0.38, lr: [0.005779023590643115], Loss: 2.055004, Acc:0.794749, Semantic loss: 0.773271, BCE loss: 0.537131, SB loss: 0.744602
2023-10-30 11:47:17,295 Epoch: [220/484] Iter:[420/495], Time: 0.38, lr: [0.005778624332088191], Loss: 2.054734, Acc:0.794932, Semantic loss: 0.773583, BCE loss: 0.536435, SB loss: 0.744716
2023-10-30 11:47:21,034 Epoch: [220/484] Iter:[430/495], Time: 0.38, lr: [0.005778225070468166], Loss: 2.055354, Acc:0.795043, Semantic loss: 0.773709, BCE loss: 0.536961, SB loss: 0.744684
2023-10-30 11:47:24,785 Epoch: [220/484] Iter:[440/495], Time: 0.38, lr: [0.00577782580578278], Loss: 2.056883, Acc:0.794523, Semantic loss: 0.774807, BCE loss: 0.536812, SB loss: 0.745264
2023-10-30 11:47:28,592 Epoch: [220/484] Iter:[450/495], Time: 0.38, lr: [0.005777426538031776], Loss: 2.058330, Acc:0.794437, Semantic loss: 0.775182, BCE loss: 0.537377, SB loss: 0.745771
2023-10-30 11:47:32,291 Epoch: [220/484] Iter:[460/495], Time: 0.38, lr: [0.005777027267214894], Loss: 2.060818, Acc:0.795002, Semantic loss: 0.776055, BCE loss: 0.538983, SB loss: 0.745780
2023-10-30 11:47:35,998 Epoch: [220/484] Iter:[470/495], Time: 0.38, lr: [0.0057766279933318745], Loss: 2.060933, Acc:0.795286, Semantic loss: 0.775962, BCE loss: 0.539738, SB loss: 0.745233
2023-10-30 11:47:39,724 Epoch: [220/484] Iter:[480/495], Time: 0.38, lr: [0.00577622871638246], Loss: 2.061787, Acc:0.795627, Semantic loss: 0.776331, BCE loss: 0.540005, SB loss: 0.745452
2023-10-30 11:47:43,264 Epoch: [220/484] Iter:[490/495], Time: 0.38, lr: [0.005775829436366391], Loss: 2.061595, Acc:0.795605, Semantic loss: 0.776405, BCE loss: 0.539899, SB loss: 0.745291
2023-10-30 11:50:40,226 0 [9.39144337e-01 6.45385783e-01 8.22205624e-01 1.02024317e-01
 2.32424087e-01 4.05314442e-01 3.72490085e-01 5.85369284e-01
 8.80630488e-01 4.47870505e-01 8.70488968e-01 5.51577466e-01
 1.62442917e-02 8.13023014e-01 4.65168393e-04 9.94535993e-02
 5.98516385e-02 2.86270553e-02 5.96799599e-01] 0.4457573553580286
2023-10-30 11:50:40,227 1 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613] 0.6930812114437745
2023-10-30 11:50:40,230 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:50:40,465 Loss: 2.037, MeanIU:  0.6931, Best_mIoU:  0.7151
2023-10-30 11:50:40,465 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613]
2023-10-30 11:50:42,661 Epoch: [221/484] Iter:[0/495], Time: 2.16, lr: [0.0057756297952082794], Loss: 1.924444, Acc:0.815156, Semantic loss: 0.688699, BCE loss: 0.539785, SB loss: 0.695960
2023-10-30 11:50:46,396 Epoch: [221/484] Iter:[10/495], Time: 0.54, lr: [0.005775230510591741], Loss: 2.138094, Acc:0.798044, Semantic loss: 0.817924, BCE loss: 0.530446, SB loss: 0.789725
2023-10-30 11:50:49,881 Epoch: [221/484] Iter:[20/495], Time: 0.45, lr: [0.005774831222907901], Loss: 2.016161, Acc:0.768002, Semantic loss: 0.766110, BCE loss: 0.492837, SB loss: 0.757213
2023-10-30 11:50:53,349 Epoch: [221/484] Iter:[30/495], Time: 0.41, lr: [0.005774431932156496], Loss: 2.050256, Acc:0.769872, Semantic loss: 0.790815, BCE loss: 0.502369, SB loss: 0.757072
2023-10-30 11:50:56,960 Epoch: [221/484] Iter:[40/495], Time: 0.40, lr: [0.005774032638337272], Loss: 2.054660, Acc:0.785033, Semantic loss: 0.784987, BCE loss: 0.516666, SB loss: 0.753008
2023-10-30 11:51:00,602 Epoch: [221/484] Iter:[50/495], Time: 0.39, lr: [0.005773633341449965], Loss: 2.085984, Acc:0.789247, Semantic loss: 0.794104, BCE loss: 0.538063, SB loss: 0.753817
2023-10-30 11:51:04,207 Epoch: [221/484] Iter:[60/495], Time: 0.39, lr: [0.0057732340414943205], Loss: 2.090343, Acc:0.794246, Semantic loss: 0.792521, BCE loss: 0.543885, SB loss: 0.753937
2023-10-30 11:51:07,908 Epoch: [221/484] Iter:[70/495], Time: 0.39, lr: [0.005772834738470076], Loss: 2.073066, Acc:0.794250, Semantic loss: 0.786463, BCE loss: 0.537068, SB loss: 0.749535
2023-10-30 11:51:11,489 Epoch: [221/484] Iter:[80/495], Time: 0.38, lr: [0.005772435432376973], Loss: 2.089486, Acc:0.792483, Semantic loss: 0.796284, BCE loss: 0.537858, SB loss: 0.755345
2023-10-30 11:51:15,077 Epoch: [221/484] Iter:[90/495], Time: 0.38, lr: [0.005772036123214752], Loss: 2.094800, Acc:0.794727, Semantic loss: 0.789574, BCE loss: 0.546762, SB loss: 0.758464
2023-10-30 11:51:18,545 Epoch: [221/484] Iter:[100/495], Time: 0.38, lr: [0.005771636810983153], Loss: 2.098769, Acc:0.794504, Semantic loss: 0.789642, BCE loss: 0.548076, SB loss: 0.761051
2023-10-30 11:51:22,146 Epoch: [221/484] Iter:[110/495], Time: 0.38, lr: [0.005771237495681916], Loss: 2.093019, Acc:0.791498, Semantic loss: 0.789802, BCE loss: 0.543683, SB loss: 0.759533
2023-10-30 11:51:25,705 Epoch: [221/484] Iter:[120/495], Time: 0.37, lr: [0.005770838177310784], Loss: 2.086103, Acc:0.791663, Semantic loss: 0.789564, BCE loss: 0.540255, SB loss: 0.756284
2023-10-30 11:51:29,343 Epoch: [221/484] Iter:[130/495], Time: 0.37, lr: [0.005770438855869492], Loss: 2.079597, Acc:0.791830, Semantic loss: 0.787034, BCE loss: 0.536657, SB loss: 0.755906
2023-10-30 11:51:32,936 Epoch: [221/484] Iter:[140/495], Time: 0.37, lr: [0.005770039531357786], Loss: 2.084813, Acc:0.790518, Semantic loss: 0.793546, BCE loss: 0.534889, SB loss: 0.756378
2023-10-30 11:51:36,556 Epoch: [221/484] Iter:[150/495], Time: 0.37, lr: [0.005769640203775405], Loss: 2.082687, Acc:0.787795, Semantic loss: 0.791494, BCE loss: 0.534933, SB loss: 0.756260
2023-10-30 11:51:40,177 Epoch: [221/484] Iter:[160/495], Time: 0.37, lr: [0.005769240873122087], Loss: 2.072237, Acc:0.788606, Semantic loss: 0.784847, BCE loss: 0.533435, SB loss: 0.753955
2023-10-30 11:51:43,851 Epoch: [221/484] Iter:[170/495], Time: 0.37, lr: [0.005768841539397574], Loss: 2.058974, Acc:0.787933, Semantic loss: 0.778777, BCE loss: 0.530070, SB loss: 0.750127
2023-10-30 11:51:47,566 Epoch: [221/484] Iter:[180/495], Time: 0.37, lr: [0.005768442202601605], Loss: 2.050808, Acc:0.787826, Semantic loss: 0.774311, BCE loss: 0.530025, SB loss: 0.746473
2023-10-30 11:51:51,260 Epoch: [221/484] Iter:[190/495], Time: 0.37, lr: [0.005768042862733921], Loss: 2.048623, Acc:0.788648, Semantic loss: 0.771789, BCE loss: 0.531212, SB loss: 0.745622
2023-10-30 11:51:54,881 Epoch: [221/484] Iter:[200/495], Time: 0.37, lr: [0.005767643519794263], Loss: 2.048670, Acc:0.789933, Semantic loss: 0.769668, BCE loss: 0.534272, SB loss: 0.744730
2023-10-30 11:51:58,465 Epoch: [221/484] Iter:[210/495], Time: 0.37, lr: [0.005767244173782367], Loss: 2.044032, Acc:0.792006, Semantic loss: 0.767404, BCE loss: 0.533933, SB loss: 0.742695
2023-10-30 11:52:02,071 Epoch: [221/484] Iter:[220/495], Time: 0.37, lr: [0.00576684482469798], Loss: 2.040036, Acc:0.793255, Semantic loss: 0.765372, BCE loss: 0.532129, SB loss: 0.742535
2023-10-30 11:52:05,741 Epoch: [221/484] Iter:[230/495], Time: 0.37, lr: [0.005766445472540836], Loss: 2.037686, Acc:0.794879, Semantic loss: 0.765092, BCE loss: 0.530425, SB loss: 0.742169
2023-10-30 11:52:09,423 Epoch: [221/484] Iter:[240/495], Time: 0.37, lr: [0.005766046117310677], Loss: 2.037562, Acc:0.794414, Semantic loss: 0.765776, BCE loss: 0.529566, SB loss: 0.742220
2023-10-30 11:52:13,005 Epoch: [221/484] Iter:[250/495], Time: 0.37, lr: [0.005765646759007243], Loss: 2.033442, Acc:0.794339, Semantic loss: 0.763518, BCE loss: 0.528496, SB loss: 0.741429
2023-10-30 11:52:16,596 Epoch: [221/484] Iter:[260/495], Time: 0.37, lr: [0.005765247397630271], Loss: 2.031656, Acc:0.794856, Semantic loss: 0.762523, BCE loss: 0.528239, SB loss: 0.740894
2023-10-30 11:52:20,287 Epoch: [221/484] Iter:[270/495], Time: 0.37, lr: [0.005764848033179506], Loss: 2.033498, Acc:0.795079, Semantic loss: 0.763515, BCE loss: 0.529207, SB loss: 0.740777
2023-10-30 11:52:24,015 Epoch: [221/484] Iter:[280/495], Time: 0.37, lr: [0.005764448665654683], Loss: 2.033037, Acc:0.794274, Semantic loss: 0.764062, BCE loss: 0.528805, SB loss: 0.740170
2023-10-30 11:52:27,748 Epoch: [221/484] Iter:[290/495], Time: 0.37, lr: [0.0057640492950555445], Loss: 2.031701, Acc:0.794745, Semantic loss: 0.763677, BCE loss: 0.527328, SB loss: 0.740696
2023-10-30 11:52:31,418 Epoch: [221/484] Iter:[300/495], Time: 0.37, lr: [0.00576364992138183], Loss: 2.032178, Acc:0.794403, Semantic loss: 0.764137, BCE loss: 0.526082, SB loss: 0.741959
2023-10-30 11:52:35,162 Epoch: [221/484] Iter:[310/495], Time: 0.37, lr: [0.005763250544633279], Loss: 2.032610, Acc:0.793903, Semantic loss: 0.764461, BCE loss: 0.526246, SB loss: 0.741903
2023-10-30 11:52:38,802 Epoch: [221/484] Iter:[320/495], Time: 0.37, lr: [0.00576285116480963], Loss: 2.037224, Acc:0.794636, Semantic loss: 0.765383, BCE loss: 0.529585, SB loss: 0.742256
2023-10-30 11:52:42,410 Epoch: [221/484] Iter:[330/495], Time: 0.37, lr: [0.005762451781910622], Loss: 2.034648, Acc:0.794173, Semantic loss: 0.765364, BCE loss: 0.527571, SB loss: 0.741712
2023-10-30 11:52:46,038 Epoch: [221/484] Iter:[340/495], Time: 0.37, lr: [0.005762052395935995], Loss: 2.031527, Acc:0.793586, Semantic loss: 0.763951, BCE loss: 0.526112, SB loss: 0.741464
2023-10-30 11:52:49,693 Epoch: [221/484] Iter:[350/495], Time: 0.37, lr: [0.005761653006885491], Loss: 2.031695, Acc:0.793670, Semantic loss: 0.764225, BCE loss: 0.525672, SB loss: 0.741797
2023-10-30 11:52:53,391 Epoch: [221/484] Iter:[360/495], Time: 0.37, lr: [0.005761253614758845], Loss: 2.034586, Acc:0.793532, Semantic loss: 0.765538, BCE loss: 0.526193, SB loss: 0.742856
2023-10-30 11:52:57,156 Epoch: [221/484] Iter:[370/495], Time: 0.37, lr: [0.005760854219555801], Loss: 2.032489, Acc:0.794392, Semantic loss: 0.764765, BCE loss: 0.525290, SB loss: 0.742435
2023-10-30 11:53:00,880 Epoch: [221/484] Iter:[380/495], Time: 0.37, lr: [0.005760454821276096], Loss: 2.029955, Acc:0.794886, Semantic loss: 0.764068, BCE loss: 0.524285, SB loss: 0.741602
2023-10-30 11:53:04,472 Epoch: [221/484] Iter:[390/495], Time: 0.37, lr: [0.005760055419919467], Loss: 2.029191, Acc:0.795419, Semantic loss: 0.763720, BCE loss: 0.524188, SB loss: 0.741282
2023-10-30 11:53:08,084 Epoch: [221/484] Iter:[400/495], Time: 0.37, lr: [0.005759656015485658], Loss: 2.029380, Acc:0.794916, Semantic loss: 0.764734, BCE loss: 0.523925, SB loss: 0.740721
2023-10-30 11:53:11,819 Epoch: [221/484] Iter:[410/495], Time: 0.37, lr: [0.005759256607974404], Loss: 2.033285, Acc:0.794984, Semantic loss: 0.767074, BCE loss: 0.524873, SB loss: 0.741337
2023-10-30 11:53:15,566 Epoch: [221/484] Iter:[420/495], Time: 0.37, lr: [0.0057588571973854474], Loss: 2.032285, Acc:0.794309, Semantic loss: 0.767098, BCE loss: 0.524088, SB loss: 0.741098
2023-10-30 11:53:19,233 Epoch: [221/484] Iter:[430/495], Time: 0.37, lr: [0.005758457783718525], Loss: 2.033171, Acc:0.794480, Semantic loss: 0.768071, BCE loss: 0.523395, SB loss: 0.741704
2023-10-30 11:53:23,070 Epoch: [221/484] Iter:[440/495], Time: 0.37, lr: [0.005758058366973375], Loss: 2.035982, Acc:0.794258, Semantic loss: 0.771375, BCE loss: 0.522958, SB loss: 0.741648
2023-10-30 11:53:26,737 Epoch: [221/484] Iter:[450/495], Time: 0.37, lr: [0.005757658947149741], Loss: 2.033810, Acc:0.795010, Semantic loss: 0.769191, BCE loss: 0.523411, SB loss: 0.741208
2023-10-30 11:53:30,298 Epoch: [221/484] Iter:[460/495], Time: 0.37, lr: [0.005757259524247358], Loss: 2.034637, Acc:0.794552, Semantic loss: 0.769932, BCE loss: 0.523821, SB loss: 0.740884
2023-10-30 11:53:33,938 Epoch: [221/484] Iter:[470/495], Time: 0.37, lr: [0.005756860098265966], Loss: 2.032815, Acc:0.794974, Semantic loss: 0.768505, BCE loss: 0.523175, SB loss: 0.741135
2023-10-30 11:53:37,566 Epoch: [221/484] Iter:[480/495], Time: 0.37, lr: [0.005756460669205305], Loss: 2.032572, Acc:0.794008, Semantic loss: 0.767280, BCE loss: 0.523727, SB loss: 0.741565
2023-10-30 11:53:41,036 Epoch: [221/484] Iter:[490/495], Time: 0.37, lr: [0.005756061237065111], Loss: 2.030112, Acc:0.792991, Semantic loss: 0.766099, BCE loss: 0.522931, SB loss: 0.741082
2023-10-30 11:53:42,447 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:53:42,709 Loss: 2.037, MeanIU:  0.6931, Best_mIoU:  0.7151
2023-10-30 11:53:42,710 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613]
2023-10-30 11:53:44,643 Epoch: [222/484] Iter:[0/495], Time: 1.90, lr: [0.005755861519840108], Loss: 1.676990, Acc:0.739703, Semantic loss: 0.641732, BCE loss: 0.388166, SB loss: 0.647092
2023-10-30 11:53:48,635 Epoch: [222/484] Iter:[10/495], Time: 0.54, lr: [0.005755462083080127], Loss: 1.985134, Acc:0.787663, Semantic loss: 0.742030, BCE loss: 0.511899, SB loss: 0.731204
2023-10-30 11:53:52,296 Epoch: [222/484] Iter:[20/495], Time: 0.45, lr: [0.005755062643239962], Loss: 2.043201, Acc:0.778280, Semantic loss: 0.785527, BCE loss: 0.517977, SB loss: 0.739698
2023-10-30 11:53:56,018 Epoch: [222/484] Iter:[30/495], Time: 0.43, lr: [0.005754663200319353], Loss: 2.041631, Acc:0.792788, Semantic loss: 0.774106, BCE loss: 0.529634, SB loss: 0.737891
2023-10-30 11:53:59,728 Epoch: [222/484] Iter:[40/495], Time: 0.41, lr: [0.005754263754318037], Loss: 2.047565, Acc:0.788257, Semantic loss: 0.780493, BCE loss: 0.526907, SB loss: 0.740165
2023-10-30 11:54:03,402 Epoch: [222/484] Iter:[50/495], Time: 0.41, lr: [0.005753864305235751], Loss: 2.042743, Acc:0.792562, Semantic loss: 0.774964, BCE loss: 0.530478, SB loss: 0.737301
2023-10-30 11:54:07,054 Epoch: [222/484] Iter:[60/495], Time: 0.40, lr: [0.005753464853072237], Loss: 2.061850, Acc:0.797350, Semantic loss: 0.785302, BCE loss: 0.540498, SB loss: 0.736050
2023-10-30 11:54:10,771 Epoch: [222/484] Iter:[70/495], Time: 0.39, lr: [0.00575306539782723], Loss: 2.044129, Acc:0.792507, Semantic loss: 0.773185, BCE loss: 0.536640, SB loss: 0.734303
2023-10-30 11:54:14,492 Epoch: [222/484] Iter:[80/495], Time: 0.39, lr: [0.005752665939500471], Loss: 2.050282, Acc:0.796711, Semantic loss: 0.782278, BCE loss: 0.532626, SB loss: 0.735379
2023-10-30 11:54:18,207 Epoch: [222/484] Iter:[90/495], Time: 0.39, lr: [0.005752266478091698], Loss: 2.061342, Acc:0.797833, Semantic loss: 0.785819, BCE loss: 0.536896, SB loss: 0.738626
2023-10-30 11:54:21,866 Epoch: [222/484] Iter:[100/495], Time: 0.39, lr: [0.005751867013600648], Loss: 2.064274, Acc:0.796095, Semantic loss: 0.782404, BCE loss: 0.541206, SB loss: 0.740664
2023-10-30 11:54:25,601 Epoch: [222/484] Iter:[110/495], Time: 0.39, lr: [0.005751467546027062], Loss: 2.074576, Acc:0.793314, Semantic loss: 0.794619, BCE loss: 0.535499, SB loss: 0.744458
2023-10-30 11:54:29,207 Epoch: [222/484] Iter:[120/495], Time: 0.38, lr: [0.0057510680753706765], Loss: 2.068156, Acc:0.791986, Semantic loss: 0.795292, BCE loss: 0.527499, SB loss: 0.745365
2023-10-30 11:54:32,963 Epoch: [222/484] Iter:[130/495], Time: 0.38, lr: [0.0057506686016312305], Loss: 2.081502, Acc:0.793089, Semantic loss: 0.804030, BCE loss: 0.527953, SB loss: 0.749519
2023-10-30 11:54:36,608 Epoch: [222/484] Iter:[140/495], Time: 0.38, lr: [0.005750269124808462], Loss: 2.079533, Acc:0.793171, Semantic loss: 0.803139, BCE loss: 0.528226, SB loss: 0.748168
2023-10-30 11:54:40,323 Epoch: [222/484] Iter:[150/495], Time: 0.38, lr: [0.005749869644902108], Loss: 2.065303, Acc:0.793424, Semantic loss: 0.795960, BCE loss: 0.524385, SB loss: 0.744958
2023-10-30 11:54:44,042 Epoch: [222/484] Iter:[160/495], Time: 0.38, lr: [0.005749470161911907], Loss: 2.076448, Acc:0.794551, Semantic loss: 0.800329, BCE loss: 0.527591, SB loss: 0.748528
2023-10-30 11:54:47,692 Epoch: [222/484] Iter:[170/495], Time: 0.38, lr: [0.0057490706758376], Loss: 2.066268, Acc:0.795661, Semantic loss: 0.790886, BCE loss: 0.529547, SB loss: 0.745835
2023-10-30 11:54:51,391 Epoch: [222/484] Iter:[180/495], Time: 0.38, lr: [0.005748671186678921], Loss: 2.063029, Acc:0.796000, Semantic loss: 0.788769, BCE loss: 0.528726, SB loss: 0.745535
2023-10-30 11:54:55,033 Epoch: [222/484] Iter:[190/495], Time: 0.38, lr: [0.005748271694435611], Loss: 2.060084, Acc:0.796137, Semantic loss: 0.786157, BCE loss: 0.528908, SB loss: 0.745019
2023-10-30 11:54:58,692 Epoch: [222/484] Iter:[200/495], Time: 0.38, lr: [0.005747872199107407], Loss: 2.056808, Acc:0.796281, Semantic loss: 0.782318, BCE loss: 0.529833, SB loss: 0.744657
2023-10-30 11:55:02,343 Epoch: [222/484] Iter:[210/495], Time: 0.38, lr: [0.005747472700694046], Loss: 2.050196, Acc:0.797961, Semantic loss: 0.778939, BCE loss: 0.527567, SB loss: 0.743690
2023-10-30 11:55:06,046 Epoch: [222/484] Iter:[220/495], Time: 0.38, lr: [0.005747073199195267], Loss: 2.045420, Acc:0.797607, Semantic loss: 0.776558, BCE loss: 0.525888, SB loss: 0.742975
2023-10-30 11:55:09,807 Epoch: [222/484] Iter:[230/495], Time: 0.38, lr: [0.005746673694610809], Loss: 2.045408, Acc:0.796897, Semantic loss: 0.776412, BCE loss: 0.526209, SB loss: 0.742787
2023-10-30 11:55:13,453 Epoch: [222/484] Iter:[240/495], Time: 0.38, lr: [0.005746274186940406], Loss: 2.047015, Acc:0.795203, Semantic loss: 0.778664, BCE loss: 0.524809, SB loss: 0.743542
2023-10-30 11:55:17,188 Epoch: [222/484] Iter:[250/495], Time: 0.38, lr: [0.0057458746761838], Loss: 2.051047, Acc:0.796785, Semantic loss: 0.778004, BCE loss: 0.529841, SB loss: 0.743201
2023-10-30 11:55:20,998 Epoch: [222/484] Iter:[260/495], Time: 0.38, lr: [0.005745475162340725], Loss: 2.051211, Acc:0.797964, Semantic loss: 0.777561, BCE loss: 0.531202, SB loss: 0.742449
2023-10-30 11:55:24,726 Epoch: [222/484] Iter:[270/495], Time: 0.38, lr: [0.005745075645410922], Loss: 2.054373, Acc:0.798611, Semantic loss: 0.778945, BCE loss: 0.532279, SB loss: 0.743149
2023-10-30 11:55:28,447 Epoch: [222/484] Iter:[280/495], Time: 0.38, lr: [0.005744676125394128], Loss: 2.053528, Acc:0.799523, Semantic loss: 0.777443, BCE loss: 0.532955, SB loss: 0.743130
2023-10-30 11:55:32,142 Epoch: [222/484] Iter:[290/495], Time: 0.38, lr: [0.005744276602290079], Loss: 2.050796, Acc:0.798850, Semantic loss: 0.776419, BCE loss: 0.532155, SB loss: 0.742222
2023-10-30 11:55:35,790 Epoch: [222/484] Iter:[300/495], Time: 0.38, lr: [0.0057438770760985134], Loss: 2.054851, Acc:0.799523, Semantic loss: 0.777636, BCE loss: 0.534327, SB loss: 0.742887
2023-10-30 11:55:39,469 Epoch: [222/484] Iter:[310/495], Time: 0.38, lr: [0.005743477546819169], Loss: 2.052392, Acc:0.798607, Semantic loss: 0.777027, BCE loss: 0.532850, SB loss: 0.742515
2023-10-30 11:55:43,214 Epoch: [222/484] Iter:[320/495], Time: 0.38, lr: [0.005743078014451782], Loss: 2.049414, Acc:0.799143, Semantic loss: 0.774723, BCE loss: 0.532889, SB loss: 0.741802
2023-10-30 11:55:46,817 Epoch: [222/484] Iter:[330/495], Time: 0.37, lr: [0.005742678478996092], Loss: 2.052980, Acc:0.798084, Semantic loss: 0.777993, BCE loss: 0.531266, SB loss: 0.743721
2023-10-30 11:55:50,553 Epoch: [222/484] Iter:[340/495], Time: 0.37, lr: [0.0057422789404518336], Loss: 2.055232, Acc:0.798201, Semantic loss: 0.779347, BCE loss: 0.531417, SB loss: 0.744469
2023-10-30 11:55:54,417 Epoch: [222/484] Iter:[350/495], Time: 0.38, lr: [0.005741879398818746], Loss: 2.057097, Acc:0.797949, Semantic loss: 0.780083, BCE loss: 0.531937, SB loss: 0.745077
2023-10-30 11:55:58,037 Epoch: [222/484] Iter:[360/495], Time: 0.37, lr: [0.0057414798540965685], Loss: 2.060210, Acc:0.798676, Semantic loss: 0.780518, BCE loss: 0.533641, SB loss: 0.746052
2023-10-30 11:56:01,667 Epoch: [222/484] Iter:[370/495], Time: 0.37, lr: [0.005741080306285035], Loss: 2.060140, Acc:0.798033, Semantic loss: 0.780244, BCE loss: 0.533782, SB loss: 0.746114
2023-10-30 11:56:05,318 Epoch: [222/484] Iter:[380/495], Time: 0.37, lr: [0.005740680755383884], Loss: 2.066176, Acc:0.797445, Semantic loss: 0.784056, BCE loss: 0.534377, SB loss: 0.747744
2023-10-30 11:56:09,023 Epoch: [222/484] Iter:[390/495], Time: 0.37, lr: [0.005740281201392852], Loss: 2.072136, Acc:0.798772, Semantic loss: 0.785362, BCE loss: 0.538386, SB loss: 0.748388
2023-10-30 11:56:12,714 Epoch: [222/484] Iter:[400/495], Time: 0.37, lr: [0.0057398816443116766], Loss: 2.071939, Acc:0.798485, Semantic loss: 0.783714, BCE loss: 0.539637, SB loss: 0.748589
2023-10-30 11:56:16,372 Epoch: [222/484] Iter:[410/495], Time: 0.37, lr: [0.005739482084140094], Loss: 2.071547, Acc:0.797991, Semantic loss: 0.783619, BCE loss: 0.539545, SB loss: 0.748383
2023-10-30 11:56:19,989 Epoch: [222/484] Iter:[420/495], Time: 0.37, lr: [0.005739082520877843], Loss: 2.068830, Acc:0.797576, Semantic loss: 0.782103, BCE loss: 0.538494, SB loss: 0.748232
2023-10-30 11:56:23,687 Epoch: [222/484] Iter:[430/495], Time: 0.37, lr: [0.00573868295452466], Loss: 2.068664, Acc:0.798044, Semantic loss: 0.782822, BCE loss: 0.537745, SB loss: 0.748097
2023-10-30 11:56:27,341 Epoch: [222/484] Iter:[440/495], Time: 0.37, lr: [0.005738283385080282], Loss: 2.070879, Acc:0.797913, Semantic loss: 0.784362, BCE loss: 0.538510, SB loss: 0.748007
2023-10-30 11:56:31,057 Epoch: [222/484] Iter:[450/495], Time: 0.37, lr: [0.005737883812544446], Loss: 2.070095, Acc:0.797757, Semantic loss: 0.784524, BCE loss: 0.537444, SB loss: 0.748127
2023-10-30 11:56:34,712 Epoch: [222/484] Iter:[460/495], Time: 0.37, lr: [0.005737484236916888], Loss: 2.069025, Acc:0.797900, Semantic loss: 0.783994, BCE loss: 0.536869, SB loss: 0.748163
2023-10-30 11:56:38,335 Epoch: [222/484] Iter:[470/495], Time: 0.37, lr: [0.0057370846581973455], Loss: 2.067069, Acc:0.798227, Semantic loss: 0.782608, BCE loss: 0.536621, SB loss: 0.747840
2023-10-30 11:56:41,959 Epoch: [222/484] Iter:[480/495], Time: 0.37, lr: [0.005736685076385554], Loss: 2.068068, Acc:0.798077, Semantic loss: 0.783726, BCE loss: 0.535850, SB loss: 0.748491
2023-10-30 11:56:45,437 Epoch: [222/484] Iter:[490/495], Time: 0.37, lr: [0.005736285491481252], Loss: 2.067513, Acc:0.798551, Semantic loss: 0.782685, BCE loss: 0.536858, SB loss: 0.747971
2023-10-30 11:56:46,832 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:56:47,070 Loss: 2.037, MeanIU:  0.6931, Best_mIoU:  0.7151
2023-10-30 11:56:47,070 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613]
2023-10-30 11:56:48,857 Epoch: [223/484] Iter:[0/495], Time: 1.75, lr: [0.005736085697869327], Loss: 1.964919, Acc:0.682498, Semantic loss: 0.810878, BCE loss: 0.396882, SB loss: 0.757160
2023-10-30 11:56:52,927 Epoch: [223/484] Iter:[10/495], Time: 0.53, lr: [0.005735686108325765], Loss: 2.119419, Acc:0.759056, Semantic loss: 0.825871, BCE loss: 0.534583, SB loss: 0.758965
2023-10-30 11:56:56,675 Epoch: [223/484] Iter:[20/495], Time: 0.46, lr: [0.005735286515689034], Loss: 2.076359, Acc:0.803935, Semantic loss: 0.773077, BCE loss: 0.572637, SB loss: 0.730645
2023-10-30 11:57:00,302 Epoch: [223/484] Iter:[30/495], Time: 0.43, lr: [0.00573488691995887], Loss: 2.047822, Acc:0.786920, Semantic loss: 0.771986, BCE loss: 0.536418, SB loss: 0.739419
2023-10-30 11:57:03,972 Epoch: [223/484] Iter:[40/495], Time: 0.41, lr: [0.00573448732113501], Loss: 2.049189, Acc:0.796469, Semantic loss: 0.767643, BCE loss: 0.540873, SB loss: 0.740673
2023-10-30 11:57:07,652 Epoch: [223/484] Iter:[50/495], Time: 0.40, lr: [0.005734087719217191], Loss: 2.019148, Acc:0.794985, Semantic loss: 0.754549, BCE loss: 0.523446, SB loss: 0.741152
2023-10-30 11:57:11,402 Epoch: [223/484] Iter:[60/495], Time: 0.40, lr: [0.005733688114205145], Loss: 2.013723, Acc:0.790362, Semantic loss: 0.750005, BCE loss: 0.523620, SB loss: 0.740097
2023-10-30 11:57:15,120 Epoch: [223/484] Iter:[70/495], Time: 0.39, lr: [0.005733288506098615], Loss: 2.019200, Acc:0.794145, Semantic loss: 0.753805, BCE loss: 0.526742, SB loss: 0.738653
2023-10-30 11:57:18,764 Epoch: [223/484] Iter:[80/495], Time: 0.39, lr: [0.0057328888948973335], Loss: 2.018606, Acc:0.791917, Semantic loss: 0.749691, BCE loss: 0.531882, SB loss: 0.737034
2023-10-30 11:57:22,394 Epoch: [223/484] Iter:[90/495], Time: 0.39, lr: [0.00573248928060104], Loss: 2.031260, Acc:0.794061, Semantic loss: 0.757009, BCE loss: 0.537544, SB loss: 0.736707
2023-10-30 11:57:25,985 Epoch: [223/484] Iter:[100/495], Time: 0.38, lr: [0.005732089663209467], Loss: 2.033391, Acc:0.792188, Semantic loss: 0.761571, BCE loss: 0.532784, SB loss: 0.739036
2023-10-30 11:57:29,620 Epoch: [223/484] Iter:[110/495], Time: 0.38, lr: [0.005731690042722353], Loss: 2.048408, Acc:0.791746, Semantic loss: 0.767529, BCE loss: 0.539109, SB loss: 0.741771
2023-10-30 11:57:33,265 Epoch: [223/484] Iter:[120/495], Time: 0.38, lr: [0.005731290419139433], Loss: 2.041109, Acc:0.794694, Semantic loss: 0.763743, BCE loss: 0.537959, SB loss: 0.739407
2023-10-30 11:57:36,877 Epoch: [223/484] Iter:[130/495], Time: 0.38, lr: [0.005730890792460445], Loss: 2.037481, Acc:0.793111, Semantic loss: 0.764443, BCE loss: 0.536193, SB loss: 0.736844
2023-10-30 11:57:40,525 Epoch: [223/484] Iter:[140/495], Time: 0.38, lr: [0.005730491162685122], Loss: 2.039440, Acc:0.797101, Semantic loss: 0.765354, BCE loss: 0.535921, SB loss: 0.738166
2023-10-30 11:57:44,163 Epoch: [223/484] Iter:[150/495], Time: 0.38, lr: [0.0057300915298132025], Loss: 2.038144, Acc:0.794779, Semantic loss: 0.768326, BCE loss: 0.532340, SB loss: 0.737477
2023-10-30 11:57:47,873 Epoch: [223/484] Iter:[160/495], Time: 0.38, lr: [0.005729691893844422], Loss: 2.037096, Acc:0.794442, Semantic loss: 0.764736, BCE loss: 0.534643, SB loss: 0.737717
2023-10-30 11:57:51,561 Epoch: [223/484] Iter:[170/495], Time: 0.38, lr: [0.005729292254778517], Loss: 2.036976, Acc:0.795953, Semantic loss: 0.763076, BCE loss: 0.537017, SB loss: 0.736883
2023-10-30 11:57:55,213 Epoch: [223/484] Iter:[180/495], Time: 0.38, lr: [0.005728892612615224], Loss: 2.035096, Acc:0.797663, Semantic loss: 0.762327, BCE loss: 0.537006, SB loss: 0.735763
2023-10-30 11:57:58,877 Epoch: [223/484] Iter:[190/495], Time: 0.38, lr: [0.005728492967354277], Loss: 2.032468, Acc:0.798118, Semantic loss: 0.763448, BCE loss: 0.533437, SB loss: 0.735583
2023-10-30 11:58:02,561 Epoch: [223/484] Iter:[200/495], Time: 0.38, lr: [0.0057280933189954135], Loss: 2.031619, Acc:0.798583, Semantic loss: 0.762812, BCE loss: 0.534176, SB loss: 0.734630
2023-10-30 11:58:06,260 Epoch: [223/484] Iter:[210/495], Time: 0.38, lr: [0.005727693667538368], Loss: 2.032805, Acc:0.799078, Semantic loss: 0.764088, BCE loss: 0.533436, SB loss: 0.735281
2023-10-30 11:58:09,867 Epoch: [223/484] Iter:[220/495], Time: 0.37, lr: [0.005727294012982877], Loss: 2.035850, Acc:0.800244, Semantic loss: 0.766325, BCE loss: 0.533705, SB loss: 0.735820
2023-10-30 11:58:13,548 Epoch: [223/484] Iter:[230/495], Time: 0.37, lr: [0.005726894355328676], Loss: 2.034209, Acc:0.799516, Semantic loss: 0.765333, BCE loss: 0.533097, SB loss: 0.735779
2023-10-30 11:58:17,246 Epoch: [223/484] Iter:[240/495], Time: 0.37, lr: [0.005726494694575499], Loss: 2.034125, Acc:0.799644, Semantic loss: 0.764029, BCE loss: 0.534611, SB loss: 0.735484
2023-10-30 11:58:21,017 Epoch: [223/484] Iter:[250/495], Time: 0.37, lr: [0.005726095030723086], Loss: 2.034293, Acc:0.799783, Semantic loss: 0.764189, BCE loss: 0.534779, SB loss: 0.735325
2023-10-30 11:58:24,785 Epoch: [223/484] Iter:[260/495], Time: 0.37, lr: [0.00572569536377117], Loss: 2.040717, Acc:0.801458, Semantic loss: 0.766043, BCE loss: 0.537637, SB loss: 0.737038
2023-10-30 11:58:28,498 Epoch: [223/484] Iter:[270/495], Time: 0.37, lr: [0.0057252956937194855], Loss: 2.038054, Acc:0.800725, Semantic loss: 0.765917, BCE loss: 0.536841, SB loss: 0.735296
2023-10-30 11:58:32,237 Epoch: [223/484] Iter:[280/495], Time: 0.37, lr: [0.00572489602056777], Loss: 2.040045, Acc:0.800357, Semantic loss: 0.766222, BCE loss: 0.537739, SB loss: 0.736084
2023-10-30 11:58:35,875 Epoch: [223/484] Iter:[290/495], Time: 0.37, lr: [0.005724496344315758], Loss: 2.045875, Acc:0.799618, Semantic loss: 0.770468, BCE loss: 0.537470, SB loss: 0.737937
2023-10-30 11:58:39,426 Epoch: [223/484] Iter:[300/495], Time: 0.37, lr: [0.005724096664963184], Loss: 2.048874, Acc:0.799134, Semantic loss: 0.771699, BCE loss: 0.537441, SB loss: 0.739733
2023-10-30 11:58:43,132 Epoch: [223/484] Iter:[310/495], Time: 0.37, lr: [0.0057236969825097865], Loss: 2.047208, Acc:0.799688, Semantic loss: 0.771258, BCE loss: 0.536439, SB loss: 0.739511
2023-10-30 11:58:46,740 Epoch: [223/484] Iter:[320/495], Time: 0.37, lr: [0.005723297296955297], Loss: 2.045753, Acc:0.798931, Semantic loss: 0.771265, BCE loss: 0.535891, SB loss: 0.738598
2023-10-30 11:58:50,519 Epoch: [223/484] Iter:[330/495], Time: 0.37, lr: [0.005722897608299454], Loss: 2.048728, Acc:0.799481, Semantic loss: 0.773765, BCE loss: 0.535060, SB loss: 0.739903
2023-10-30 11:58:54,265 Epoch: [223/484] Iter:[340/495], Time: 0.37, lr: [0.005722497916541991], Loss: 2.048714, Acc:0.799896, Semantic loss: 0.773321, BCE loss: 0.535009, SB loss: 0.740384
2023-10-30 11:58:57,932 Epoch: [223/484] Iter:[350/495], Time: 0.37, lr: [0.005722098221682644], Loss: 2.047686, Acc:0.799909, Semantic loss: 0.773002, BCE loss: 0.534332, SB loss: 0.740352
2023-10-30 11:59:01,688 Epoch: [223/484] Iter:[360/495], Time: 0.37, lr: [0.005721698523721147], Loss: 2.050278, Acc:0.799876, Semantic loss: 0.774569, BCE loss: 0.534616, SB loss: 0.741094
2023-10-30 11:59:05,316 Epoch: [223/484] Iter:[370/495], Time: 0.37, lr: [0.005721298822657237], Loss: 2.052847, Acc:0.800971, Semantic loss: 0.774019, BCE loss: 0.537868, SB loss: 0.740961
2023-10-30 11:59:09,031 Epoch: [223/484] Iter:[380/495], Time: 0.37, lr: [0.005720899118490647], Loss: 2.045550, Acc:0.801326, Semantic loss: 0.770172, BCE loss: 0.536150, SB loss: 0.739228
2023-10-30 11:59:12,698 Epoch: [223/484] Iter:[390/495], Time: 0.37, lr: [0.005720499411221113], Loss: 2.049417, Acc:0.801695, Semantic loss: 0.772578, BCE loss: 0.536246, SB loss: 0.740594
2023-10-30 11:59:16,333 Epoch: [223/484] Iter:[400/495], Time: 0.37, lr: [0.00572009970084837], Loss: 2.046311, Acc:0.801362, Semantic loss: 0.771663, BCE loss: 0.534745, SB loss: 0.739902
2023-10-30 11:59:19,973 Epoch: [223/484] Iter:[410/495], Time: 0.37, lr: [0.005719699987372154], Loss: 2.045318, Acc:0.800999, Semantic loss: 0.770649, BCE loss: 0.534252, SB loss: 0.740417
2023-10-30 11:59:23,694 Epoch: [223/484] Iter:[420/495], Time: 0.37, lr: [0.005719300270792198], Loss: 2.047924, Acc:0.800320, Semantic loss: 0.771892, BCE loss: 0.535151, SB loss: 0.740882
2023-10-30 11:59:27,458 Epoch: [223/484] Iter:[430/495], Time: 0.37, lr: [0.00571890055110824], Loss: 2.049063, Acc:0.800258, Semantic loss: 0.772459, BCE loss: 0.535384, SB loss: 0.741219
2023-10-30 11:59:31,096 Epoch: [223/484] Iter:[440/495], Time: 0.37, lr: [0.005718500828320011], Loss: 2.051889, Acc:0.800375, Semantic loss: 0.773516, BCE loss: 0.536597, SB loss: 0.741776
2023-10-30 11:59:34,785 Epoch: [223/484] Iter:[450/495], Time: 0.37, lr: [0.005718101102427248], Loss: 2.051946, Acc:0.801049, Semantic loss: 0.773227, BCE loss: 0.536899, SB loss: 0.741820
2023-10-30 11:59:38,421 Epoch: [223/484] Iter:[460/495], Time: 0.37, lr: [0.005717701373429683], Loss: 2.053218, Acc:0.800994, Semantic loss: 0.774488, BCE loss: 0.537013, SB loss: 0.741717
2023-10-30 11:59:42,106 Epoch: [223/484] Iter:[470/495], Time: 0.37, lr: [0.005717301641327056], Loss: 2.050442, Acc:0.801117, Semantic loss: 0.773567, BCE loss: 0.535821, SB loss: 0.741055
2023-10-30 11:59:45,721 Epoch: [223/484] Iter:[480/495], Time: 0.37, lr: [0.005716901906119096], Loss: 2.051615, Acc:0.800844, Semantic loss: 0.773804, BCE loss: 0.536049, SB loss: 0.741761
2023-10-30 11:59:49,187 Epoch: [223/484] Iter:[490/495], Time: 0.37, lr: [0.005716502167805543], Loss: 2.054895, Acc:0.801532, Semantic loss: 0.776117, BCE loss: 0.536867, SB loss: 0.741911
2023-10-30 11:59:50,587 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 11:59:50,820 Loss: 2.037, MeanIU:  0.6931, Best_mIoU:  0.7151
2023-10-30 11:59:50,820 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613]
2023-10-30 11:59:52,978 Epoch: [224/484] Iter:[0/495], Time: 2.12, lr: [0.005716302297484084], Loss: 2.567418, Acc:0.834812, Semantic loss: 1.039146, BCE loss: 0.681244, SB loss: 0.847029
2023-10-30 11:59:56,901 Epoch: [224/484] Iter:[10/495], Time: 0.55, lr: [0.005715902554511638], Loss: 2.120117, Acc:0.814846, Semantic loss: 0.803621, BCE loss: 0.588944, SB loss: 0.727552
2023-10-30 12:00:00,560 Epoch: [224/484] Iter:[20/495], Time: 0.46, lr: [0.005715502808432934], Loss: 2.084925, Acc:0.815711, Semantic loss: 0.772920, BCE loss: 0.587261, SB loss: 0.724744
2023-10-30 12:00:04,307 Epoch: [224/484] Iter:[30/495], Time: 0.43, lr: [0.005715103059247704], Loss: 2.104086, Acc:0.806059, Semantic loss: 0.793649, BCE loss: 0.576917, SB loss: 0.733519
2023-10-30 12:00:07,871 Epoch: [224/484] Iter:[40/495], Time: 0.42, lr: [0.005714703306955683], Loss: 2.103722, Acc:0.807931, Semantic loss: 0.790266, BCE loss: 0.564607, SB loss: 0.748850
2023-10-30 12:00:11,485 Epoch: [224/484] Iter:[50/495], Time: 0.40, lr: [0.0057143035515566055], Loss: 2.081116, Acc:0.796143, Semantic loss: 0.787898, BCE loss: 0.544952, SB loss: 0.748266
2023-10-30 12:00:15,193 Epoch: [224/484] Iter:[60/495], Time: 0.40, lr: [0.005713903793050207], Loss: 2.052330, Acc:0.799374, Semantic loss: 0.775029, BCE loss: 0.533973, SB loss: 0.743328
2023-10-30 12:00:18,855 Epoch: [224/484] Iter:[70/495], Time: 0.39, lr: [0.005713504031436221], Loss: 2.040563, Acc:0.800828, Semantic loss: 0.773264, BCE loss: 0.529304, SB loss: 0.737994
2023-10-30 12:00:22,529 Epoch: [224/484] Iter:[80/495], Time: 0.39, lr: [0.005713104266714382], Loss: 2.040263, Acc:0.798355, Semantic loss: 0.771606, BCE loss: 0.531317, SB loss: 0.737340
2023-10-30 12:00:26,323 Epoch: [224/484] Iter:[90/495], Time: 0.39, lr: [0.005712704498884423], Loss: 2.032555, Acc:0.796681, Semantic loss: 0.763064, BCE loss: 0.529756, SB loss: 0.739736
2023-10-30 12:00:29,941 Epoch: [224/484] Iter:[100/495], Time: 0.39, lr: [0.005712304727946081], Loss: 2.029579, Acc:0.797214, Semantic loss: 0.759171, BCE loss: 0.530405, SB loss: 0.740003
2023-10-30 12:00:33,538 Epoch: [224/484] Iter:[110/495], Time: 0.38, lr: [0.005711904953899087], Loss: 2.016257, Acc:0.796333, Semantic loss: 0.754282, BCE loss: 0.527036, SB loss: 0.734939
2023-10-30 12:00:37,200 Epoch: [224/484] Iter:[120/495], Time: 0.38, lr: [0.005711505176743174], Loss: 2.024026, Acc:0.798378, Semantic loss: 0.758583, BCE loss: 0.529851, SB loss: 0.735593
2023-10-30 12:00:40,794 Epoch: [224/484] Iter:[130/495], Time: 0.38, lr: [0.0057111053964780814], Loss: 2.034006, Acc:0.794281, Semantic loss: 0.767285, BCE loss: 0.530811, SB loss: 0.735911
2023-10-30 12:00:44,431 Epoch: [224/484] Iter:[140/495], Time: 0.38, lr: [0.0057107056131035375], Loss: 2.028574, Acc:0.794787, Semantic loss: 0.766456, BCE loss: 0.526902, SB loss: 0.735216
2023-10-30 12:00:48,148 Epoch: [224/484] Iter:[150/495], Time: 0.38, lr: [0.0057103058266192806], Loss: 2.033589, Acc:0.792409, Semantic loss: 0.769052, BCE loss: 0.527344, SB loss: 0.737193
2023-10-30 12:00:51,855 Epoch: [224/484] Iter:[160/495], Time: 0.38, lr: [0.0057099060370250435], Loss: 2.034395, Acc:0.791995, Semantic loss: 0.767892, BCE loss: 0.529514, SB loss: 0.736989
2023-10-30 12:00:55,527 Epoch: [224/484] Iter:[170/495], Time: 0.38, lr: [0.005709506244320558], Loss: 2.035255, Acc:0.792554, Semantic loss: 0.767701, BCE loss: 0.531516, SB loss: 0.736037
2023-10-30 12:00:59,235 Epoch: [224/484] Iter:[180/495], Time: 0.38, lr: [0.005709106448505561], Loss: 2.036823, Acc:0.792957, Semantic loss: 0.769151, BCE loss: 0.531241, SB loss: 0.736431
2023-10-30 12:01:02,969 Epoch: [224/484] Iter:[190/495], Time: 0.38, lr: [0.005708706649579783], Loss: 2.038092, Acc:0.793953, Semantic loss: 0.768236, BCE loss: 0.533038, SB loss: 0.736818
2023-10-30 12:01:06,621 Epoch: [224/484] Iter:[200/495], Time: 0.38, lr: [0.005708306847542959], Loss: 2.050477, Acc:0.793977, Semantic loss: 0.776630, BCE loss: 0.536284, SB loss: 0.737562
2023-10-30 12:01:10,305 Epoch: [224/484] Iter:[210/495], Time: 0.38, lr: [0.0057079070423948245], Loss: 2.054032, Acc:0.794971, Semantic loss: 0.778421, BCE loss: 0.537220, SB loss: 0.738391
2023-10-30 12:01:14,001 Epoch: [224/484] Iter:[220/495], Time: 0.38, lr: [0.005707507234135109], Loss: 2.065173, Acc:0.795069, Semantic loss: 0.782270, BCE loss: 0.539420, SB loss: 0.743483
2023-10-30 12:01:17,669 Epoch: [224/484] Iter:[230/495], Time: 0.38, lr: [0.005707107422763551], Loss: 2.070367, Acc:0.794564, Semantic loss: 0.786962, BCE loss: 0.539687, SB loss: 0.743718
2023-10-30 12:01:21,382 Epoch: [224/484] Iter:[240/495], Time: 0.38, lr: [0.005706707608279882], Loss: 2.072396, Acc:0.794757, Semantic loss: 0.786494, BCE loss: 0.541540, SB loss: 0.744362
2023-10-30 12:01:25,049 Epoch: [224/484] Iter:[250/495], Time: 0.38, lr: [0.005706307790683834], Loss: 2.064872, Acc:0.793344, Semantic loss: 0.783470, BCE loss: 0.538258, SB loss: 0.743144
2023-10-30 12:01:28,802 Epoch: [224/484] Iter:[260/495], Time: 0.38, lr: [0.005705907969975144], Loss: 2.066708, Acc:0.792894, Semantic loss: 0.784608, BCE loss: 0.537146, SB loss: 0.744953
2023-10-30 12:01:32,420 Epoch: [224/484] Iter:[270/495], Time: 0.37, lr: [0.005705508146153542], Loss: 2.064188, Acc:0.791578, Semantic loss: 0.782382, BCE loss: 0.536941, SB loss: 0.744864
2023-10-30 12:01:36,065 Epoch: [224/484] Iter:[280/495], Time: 0.37, lr: [0.00570510831921876], Loss: 2.071898, Acc:0.792297, Semantic loss: 0.788440, BCE loss: 0.536478, SB loss: 0.746980
2023-10-30 12:01:39,787 Epoch: [224/484] Iter:[290/495], Time: 0.37, lr: [0.005704708489170537], Loss: 2.071516, Acc:0.793754, Semantic loss: 0.787073, BCE loss: 0.537065, SB loss: 0.747378
2023-10-30 12:01:43,461 Epoch: [224/484] Iter:[300/495], Time: 0.37, lr: [0.005704308656008601], Loss: 2.070725, Acc:0.791874, Semantic loss: 0.788576, BCE loss: 0.534399, SB loss: 0.747751
2023-10-30 12:01:47,150 Epoch: [224/484] Iter:[310/495], Time: 0.37, lr: [0.0057039088197326894], Loss: 2.069042, Acc:0.792518, Semantic loss: 0.786586, BCE loss: 0.534527, SB loss: 0.747929
2023-10-30 12:01:50,826 Epoch: [224/484] Iter:[320/495], Time: 0.37, lr: [0.005703508980342533], Loss: 2.066935, Acc:0.793055, Semantic loss: 0.785347, BCE loss: 0.534528, SB loss: 0.747060
2023-10-30 12:01:54,519 Epoch: [224/484] Iter:[330/495], Time: 0.37, lr: [0.005703109137837865], Loss: 2.065179, Acc:0.793817, Semantic loss: 0.784060, BCE loss: 0.534817, SB loss: 0.746302
2023-10-30 12:01:58,271 Epoch: [224/484] Iter:[340/495], Time: 0.37, lr: [0.00570270929221842], Loss: 2.065256, Acc:0.793803, Semantic loss: 0.783404, BCE loss: 0.536444, SB loss: 0.745408
2023-10-30 12:02:01,850 Epoch: [224/484] Iter:[350/495], Time: 0.37, lr: [0.0057023094434839276], Loss: 2.064846, Acc:0.794363, Semantic loss: 0.782637, BCE loss: 0.536175, SB loss: 0.746034
2023-10-30 12:02:05,592 Epoch: [224/484] Iter:[360/495], Time: 0.37, lr: [0.005701909591634124], Loss: 2.066219, Acc:0.794796, Semantic loss: 0.783342, BCE loss: 0.536063, SB loss: 0.746813
2023-10-30 12:02:09,431 Epoch: [224/484] Iter:[370/495], Time: 0.37, lr: [0.005701509736668742], Loss: 2.068436, Acc:0.795647, Semantic loss: 0.783770, BCE loss: 0.537808, SB loss: 0.746858
2023-10-30 12:02:13,136 Epoch: [224/484] Iter:[380/495], Time: 0.37, lr: [0.005701109878587515], Loss: 2.066962, Acc:0.796626, Semantic loss: 0.782603, BCE loss: 0.537757, SB loss: 0.746603
2023-10-30 12:02:17,032 Epoch: [224/484] Iter:[390/495], Time: 0.37, lr: [0.005700710017390174], Loss: 2.070569, Acc:0.797480, Semantic loss: 0.784468, BCE loss: 0.539064, SB loss: 0.747037
2023-10-30 12:02:20,589 Epoch: [224/484] Iter:[400/495], Time: 0.37, lr: [0.005700310153076453], Loss: 2.076231, Acc:0.797086, Semantic loss: 0.787570, BCE loss: 0.540004, SB loss: 0.748658
2023-10-30 12:02:24,254 Epoch: [224/484] Iter:[410/495], Time: 0.37, lr: [0.005699910285646084], Loss: 2.074517, Acc:0.794824, Semantic loss: 0.786849, BCE loss: 0.538336, SB loss: 0.749332
2023-10-30 12:02:27,837 Epoch: [224/484] Iter:[420/495], Time: 0.37, lr: [0.0056995104150988005], Loss: 2.071117, Acc:0.795207, Semantic loss: 0.784451, BCE loss: 0.538503, SB loss: 0.748163
2023-10-30 12:02:31,484 Epoch: [224/484] Iter:[430/495], Time: 0.37, lr: [0.005699110541434333], Loss: 2.069167, Acc:0.795160, Semantic loss: 0.783378, BCE loss: 0.538113, SB loss: 0.747676
2023-10-30 12:02:35,174 Epoch: [224/484] Iter:[440/495], Time: 0.37, lr: [0.005698710664652419], Loss: 2.068783, Acc:0.795147, Semantic loss: 0.782907, BCE loss: 0.538695, SB loss: 0.747180
2023-10-30 12:02:38,867 Epoch: [224/484] Iter:[450/495], Time: 0.37, lr: [0.005698310784752787], Loss: 2.067153, Acc:0.795425, Semantic loss: 0.781491, BCE loss: 0.539004, SB loss: 0.746657
2023-10-30 12:02:42,570 Epoch: [224/484] Iter:[460/495], Time: 0.37, lr: [0.005697910901735171], Loss: 2.065492, Acc:0.795248, Semantic loss: 0.781300, BCE loss: 0.537173, SB loss: 0.747019
2023-10-30 12:02:46,237 Epoch: [224/484] Iter:[470/495], Time: 0.37, lr: [0.005697511015599304], Loss: 2.066041, Acc:0.796162, Semantic loss: 0.780905, BCE loss: 0.538050, SB loss: 0.747087
2023-10-30 12:02:49,901 Epoch: [224/484] Iter:[480/495], Time: 0.37, lr: [0.005697111126344918], Loss: 2.067955, Acc:0.796624, Semantic loss: 0.781387, BCE loss: 0.538925, SB loss: 0.747643
2023-10-30 12:02:53,379 Epoch: [224/484] Iter:[490/495], Time: 0.37, lr: [0.005696711233971745], Loss: 2.068249, Acc:0.796891, Semantic loss: 0.781131, BCE loss: 0.539264, SB loss: 0.747854
2023-10-30 12:02:54,783 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:02:55,014 Loss: 2.037, MeanIU:  0.6931, Best_mIoU:  0.7151
2023-10-30 12:02:55,014 [0.9750405  0.81107418 0.90970517 0.3461139  0.52490081 0.58254575
 0.63546289 0.70911243 0.90669668 0.56791493 0.93667652 0.75781155
 0.52520235 0.9310728  0.73973441 0.73286545 0.45360461 0.41047195
 0.71253613]
2023-10-30 12:02:56,971 Epoch: [225/484] Iter:[0/495], Time: 1.92, lr: [0.005696511286615531], Loss: 2.536929, Acc:0.747647, Semantic loss: 1.139608, BCE loss: 0.499634, SB loss: 0.897687
2023-10-30 12:03:00,915 Epoch: [225/484] Iter:[10/495], Time: 0.53, lr: [0.005696111389563676], Loss: 2.142608, Acc:0.782809, Semantic loss: 0.829389, BCE loss: 0.514004, SB loss: 0.799215
2023-10-30 12:03:04,642 Epoch: [225/484] Iter:[20/495], Time: 0.46, lr: [0.005695711489392365], Loss: 2.088528, Acc:0.776818, Semantic loss: 0.800230, BCE loss: 0.520373, SB loss: 0.767926
2023-10-30 12:03:08,275 Epoch: [225/484] Iter:[30/495], Time: 0.43, lr: [0.005695311586101333], Loss: 2.101359, Acc:0.790790, Semantic loss: 0.796416, BCE loss: 0.540688, SB loss: 0.764255
2023-10-30 12:03:11,935 Epoch: [225/484] Iter:[40/495], Time: 0.41, lr: [0.005694911679690307], Loss: 2.041024, Acc:0.795470, Semantic loss: 0.764182, BCE loss: 0.529330, SB loss: 0.747512
2023-10-30 12:03:15,619 Epoch: [225/484] Iter:[50/495], Time: 0.40, lr: [0.005694511770159024], Loss: 2.014912, Acc:0.788254, Semantic loss: 0.757079, BCE loss: 0.516560, SB loss: 0.741273
2023-10-30 12:03:19,188 Epoch: [225/484] Iter:[60/495], Time: 0.40, lr: [0.0056941118575072145], Loss: 2.038018, Acc:0.787161, Semantic loss: 0.769646, BCE loss: 0.524237, SB loss: 0.744135
2023-10-30 12:03:22,798 Epoch: [225/484] Iter:[70/495], Time: 0.39, lr: [0.00569371194173461], Loss: 2.033407, Acc:0.787681, Semantic loss: 0.766089, BCE loss: 0.522228, SB loss: 0.745090
2023-10-30 12:03:26,422 Epoch: [225/484] Iter:[80/495], Time: 0.39, lr: [0.005693312022840944], Loss: 2.033988, Acc:0.790265, Semantic loss: 0.767482, BCE loss: 0.525699, SB loss: 0.740807
2023-10-30 12:03:30,104 Epoch: [225/484] Iter:[90/495], Time: 0.39, lr: [0.005692912100825946], Loss: 2.016735, Acc:0.787994, Semantic loss: 0.762042, BCE loss: 0.518722, SB loss: 0.735971
2023-10-30 12:03:33,802 Epoch: [225/484] Iter:[100/495], Time: 0.38, lr: [0.0056925121756893505], Loss: 2.017522, Acc:0.787724, Semantic loss: 0.764463, BCE loss: 0.514603, SB loss: 0.738455
2023-10-30 12:03:37,647 Epoch: [225/484] Iter:[110/495], Time: 0.38, lr: [0.005692112247430888], Loss: 2.016986, Acc:0.789542, Semantic loss: 0.765352, BCE loss: 0.513009, SB loss: 0.738624
2023-10-30 12:03:41,307 Epoch: [225/484] Iter:[120/495], Time: 0.38, lr: [0.005691712316050292], Loss: 2.037592, Acc:0.792976, Semantic loss: 0.772135, BCE loss: 0.521622, SB loss: 0.743835
2023-10-30 12:03:45,030 Epoch: [225/484] Iter:[130/495], Time: 0.38, lr: [0.0056913123815472925], Loss: 2.028000, Acc:0.791213, Semantic loss: 0.765861, BCE loss: 0.519861, SB loss: 0.742278
2023-10-30 12:03:48,712 Epoch: [225/484] Iter:[140/495], Time: 0.38, lr: [0.005690912443921623], Loss: 2.033184, Acc:0.791002, Semantic loss: 0.770055, BCE loss: 0.521756, SB loss: 0.741374
2023-10-30 12:03:52,354 Epoch: [225/484] Iter:[150/495], Time: 0.38, lr: [0.0056905125031730145], Loss: 2.021155, Acc:0.790467, Semantic loss: 0.763368, BCE loss: 0.520008, SB loss: 0.737779
2023-10-30 12:03:56,174 Epoch: [225/484] Iter:[160/495], Time: 0.38, lr: [0.005690112559301198], Loss: 2.027768, Acc:0.791563, Semantic loss: 0.766612, BCE loss: 0.520371, SB loss: 0.740785
2023-10-30 12:03:59,992 Epoch: [225/484] Iter:[170/495], Time: 0.38, lr: [0.005689712612305905], Loss: 2.023547, Acc:0.793013, Semantic loss: 0.763981, BCE loss: 0.520235, SB loss: 0.739331
2023-10-30 12:04:03,726 Epoch: [225/484] Iter:[180/495], Time: 0.38, lr: [0.00568931266218687], Loss: 2.024888, Acc:0.794185, Semantic loss: 0.765785, BCE loss: 0.520561, SB loss: 0.738542
2023-10-30 12:04:07,489 Epoch: [225/484] Iter:[190/495], Time: 0.38, lr: [0.005688912708943821], Loss: 2.035526, Acc:0.793053, Semantic loss: 0.772058, BCE loss: 0.523448, SB loss: 0.740020
2023-10-30 12:04:11,171 Epoch: [225/484] Iter:[200/495], Time: 0.38, lr: [0.005688512752576492], Loss: 2.040205, Acc:0.793785, Semantic loss: 0.774480, BCE loss: 0.524359, SB loss: 0.741366
2023-10-30 12:04:14,792 Epoch: [225/484] Iter:[210/495], Time: 0.38, lr: [0.005688112793084614], Loss: 2.038331, Acc:0.794972, Semantic loss: 0.773463, BCE loss: 0.524068, SB loss: 0.740800
2023-10-30 12:04:18,501 Epoch: [225/484] Iter:[220/495], Time: 0.38, lr: [0.0056877128304679185], Loss: 2.038722, Acc:0.795151, Semantic loss: 0.774418, BCE loss: 0.522899, SB loss: 0.741405
2023-10-30 12:04:22,115 Epoch: [225/484] Iter:[230/495], Time: 0.38, lr: [0.005687312864726136], Loss: 2.041464, Acc:0.795536, Semantic loss: 0.773546, BCE loss: 0.526263, SB loss: 0.741655
2023-10-30 12:04:25,837 Epoch: [225/484] Iter:[240/495], Time: 0.38, lr: [0.005686912895858999], Loss: 2.044330, Acc:0.796376, Semantic loss: 0.774687, BCE loss: 0.529235, SB loss: 0.740407
2023-10-30 12:04:29,699 Epoch: [225/484] Iter:[250/495], Time: 0.38, lr: [0.005686512923866237], Loss: 2.047576, Acc:0.796535, Semantic loss: 0.775991, BCE loss: 0.530749, SB loss: 0.740837
2023-10-30 12:04:33,427 Epoch: [225/484] Iter:[260/495], Time: 0.38, lr: [0.005686112948747584], Loss: 2.051838, Acc:0.796910, Semantic loss: 0.777950, BCE loss: 0.532196, SB loss: 0.741692
2023-10-30 12:04:37,127 Epoch: [225/484] Iter:[270/495], Time: 0.38, lr: [0.0056857129705027674], Loss: 2.053213, Acc:0.796753, Semantic loss: 0.778366, BCE loss: 0.532624, SB loss: 0.742223
2023-10-30 12:04:40,864 Epoch: [225/484] Iter:[280/495], Time: 0.38, lr: [0.005685312989131524], Loss: 2.046921, Acc:0.796489, Semantic loss: 0.774872, BCE loss: 0.531625, SB loss: 0.740424
2023-10-30 12:04:44,577 Epoch: [225/484] Iter:[290/495], Time: 0.38, lr: [0.005684913004633581], Loss: 2.049491, Acc:0.796327, Semantic loss: 0.775435, BCE loss: 0.533702, SB loss: 0.740354
2023-10-30 12:04:48,191 Epoch: [225/484] Iter:[300/495], Time: 0.38, lr: [0.00568451301700867], Loss: 2.048217, Acc:0.797503, Semantic loss: 0.775933, BCE loss: 0.532145, SB loss: 0.740140
2023-10-30 12:04:51,856 Epoch: [225/484] Iter:[310/495], Time: 0.38, lr: [0.005684113026256523], Loss: 2.045283, Acc:0.798211, Semantic loss: 0.775501, BCE loss: 0.529588, SB loss: 0.740194
2023-10-30 12:04:55,696 Epoch: [225/484] Iter:[320/495], Time: 0.38, lr: [0.00568371303237687], Loss: 2.049094, Acc:0.798475, Semantic loss: 0.779037, BCE loss: 0.528910, SB loss: 0.741146
2023-10-30 12:04:59,325 Epoch: [225/484] Iter:[330/495], Time: 0.38, lr: [0.005683313035369443], Loss: 2.050641, Acc:0.798877, Semantic loss: 0.778989, BCE loss: 0.530281, SB loss: 0.741371
2023-10-30 12:05:03,013 Epoch: [225/484] Iter:[340/495], Time: 0.38, lr: [0.005682913035233972], Loss: 2.049516, Acc:0.798928, Semantic loss: 0.777405, BCE loss: 0.530853, SB loss: 0.741258
2023-10-30 12:05:06,794 Epoch: [225/484] Iter:[350/495], Time: 0.38, lr: [0.005682513031970188], Loss: 2.050471, Acc:0.798952, Semantic loss: 0.777311, BCE loss: 0.530865, SB loss: 0.742295
2023-10-30 12:05:10,519 Epoch: [225/484] Iter:[360/495], Time: 0.38, lr: [0.005682113025577822], Loss: 2.049745, Acc:0.799248, Semantic loss: 0.776490, BCE loss: 0.531626, SB loss: 0.741629
2023-10-30 12:05:14,164 Epoch: [225/484] Iter:[370/495], Time: 0.37, lr: [0.005681713016056606], Loss: 2.050664, Acc:0.798817, Semantic loss: 0.777365, BCE loss: 0.531896, SB loss: 0.741402
2023-10-30 12:05:17,889 Epoch: [225/484] Iter:[380/495], Time: 0.37, lr: [0.0056813130034062695], Loss: 2.054289, Acc:0.797807, Semantic loss: 0.779772, BCE loss: 0.532779, SB loss: 0.741737
2023-10-30 12:05:21,619 Epoch: [225/484] Iter:[390/495], Time: 0.37, lr: [0.0056809129876265445], Loss: 2.050518, Acc:0.796614, Semantic loss: 0.777811, BCE loss: 0.531590, SB loss: 0.741116
2023-10-30 12:05:25,268 Epoch: [225/484] Iter:[400/495], Time: 0.37, lr: [0.005680512968717159], Loss: 2.045829, Acc:0.795692, Semantic loss: 0.774744, BCE loss: 0.530710, SB loss: 0.740375
2023-10-30 12:05:28,959 Epoch: [225/484] Iter:[410/495], Time: 0.37, lr: [0.005680112946677846], Loss: 2.043838, Acc:0.795589, Semantic loss: 0.774606, BCE loss: 0.529056, SB loss: 0.740177
2023-10-30 12:05:32,693 Epoch: [225/484] Iter:[420/495], Time: 0.37, lr: [0.005679712921508334], Loss: 2.049877, Acc:0.795877, Semantic loss: 0.779051, BCE loss: 0.529490, SB loss: 0.741336
2023-10-30 12:05:36,487 Epoch: [225/484] Iter:[430/495], Time: 0.37, lr: [0.005679312893208356], Loss: 2.053027, Acc:0.795312, Semantic loss: 0.781272, BCE loss: 0.529201, SB loss: 0.742554
2023-10-30 12:05:40,112 Epoch: [225/484] Iter:[440/495], Time: 0.37, lr: [0.005678912861777642], Loss: 2.054446, Acc:0.795879, Semantic loss: 0.780952, BCE loss: 0.530352, SB loss: 0.743142
2023-10-30 12:05:43,746 Epoch: [225/484] Iter:[450/495], Time: 0.37, lr: [0.005678512827215922], Loss: 2.055590, Acc:0.794867, Semantic loss: 0.780641, BCE loss: 0.531124, SB loss: 0.743826
2023-10-30 12:05:47,511 Epoch: [225/484] Iter:[460/495], Time: 0.37, lr: [0.005678112789522924], Loss: 2.055708, Acc:0.794854, Semantic loss: 0.780093, BCE loss: 0.531714, SB loss: 0.743901
2023-10-30 12:05:51,184 Epoch: [225/484] Iter:[470/495], Time: 0.37, lr: [0.005677712748698383], Loss: 2.057553, Acc:0.795794, Semantic loss: 0.781119, BCE loss: 0.532080, SB loss: 0.744353
2023-10-30 12:05:54,959 Epoch: [225/484] Iter:[480/495], Time: 0.37, lr: [0.005677312704742027], Loss: 2.057745, Acc:0.796373, Semantic loss: 0.780939, BCE loss: 0.532574, SB loss: 0.744232
2023-10-30 12:05:58,443 Epoch: [225/484] Iter:[490/495], Time: 0.37, lr: [0.0056769126576535845], Loss: 2.059703, Acc:0.795631, Semantic loss: 0.781630, BCE loss: 0.533152, SB loss: 0.744920
2023-10-30 12:08:48,875 0 [9.22111615e-01 5.80975575e-01 8.17515233e-01 1.31995199e-01
 2.34213611e-01 3.92338162e-01 4.54507462e-01 5.78685317e-01
 8.73928844e-01 4.34116142e-01 8.62844939e-01 5.16156568e-01
 1.19379157e-02 7.59574625e-01 9.56146556e-05 9.06079315e-02
 6.78147264e-02 5.77725979e-02 5.65137218e-01] 0.4395962787201791
2023-10-30 12:08:48,876 1 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489] 0.6826992823876852
2023-10-30 12:08:48,879 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:08:49,112 Loss: 2.050, MeanIU:  0.6827, Best_mIoU:  0.7151
2023-10-30 12:08:49,112 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489]
2023-10-30 12:08:51,140 Epoch: [226/484] Iter:[0/495], Time: 1.99, lr: [0.0056767126329347484], Loss: 2.256969, Acc:0.812283, Semantic loss: 0.837988, BCE loss: 0.679394, SB loss: 0.739588
2023-10-30 12:08:54,884 Epoch: [226/484] Iter:[10/495], Time: 0.52, lr: [0.005676312581147674], Loss: 2.119663, Acc:0.792609, Semantic loss: 0.769391, BCE loss: 0.620055, SB loss: 0.730217
2023-10-30 12:08:58,471 Epoch: [226/484] Iter:[20/495], Time: 0.44, lr: [0.00567591252622784], Loss: 2.132443, Acc:0.800315, Semantic loss: 0.812219, BCE loss: 0.584250, SB loss: 0.735974
2023-10-30 12:09:01,831 Epoch: [226/484] Iter:[30/495], Time: 0.41, lr: [0.005675512468174977], Loss: 2.107506, Acc:0.801527, Semantic loss: 0.803335, BCE loss: 0.568234, SB loss: 0.735937
2023-10-30 12:09:05,254 Epoch: [226/484] Iter:[40/495], Time: 0.39, lr: [0.005675112406988816], Loss: 2.094166, Acc:0.796167, Semantic loss: 0.803859, BCE loss: 0.549665, SB loss: 0.740642
2023-10-30 12:09:08,708 Epoch: [226/484] Iter:[50/495], Time: 0.38, lr: [0.005674712342669086], Loss: 2.079102, Acc:0.792113, Semantic loss: 0.791070, BCE loss: 0.547472, SB loss: 0.740560
2023-10-30 12:09:12,137 Epoch: [226/484] Iter:[60/495], Time: 0.38, lr: [0.005674312275215516], Loss: 2.058377, Acc:0.794279, Semantic loss: 0.784592, BCE loss: 0.539005, SB loss: 0.734779
2023-10-30 12:09:15,690 Epoch: [226/484] Iter:[70/495], Time: 0.37, lr: [0.005673912204627837], Loss: 2.050879, Acc:0.791925, Semantic loss: 0.781787, BCE loss: 0.530880, SB loss: 0.738213
2023-10-30 12:09:19,321 Epoch: [226/484] Iter:[80/495], Time: 0.37, lr: [0.005673512130905779], Loss: 2.060770, Acc:0.793487, Semantic loss: 0.782713, BCE loss: 0.536129, SB loss: 0.741928
2023-10-30 12:09:22,915 Epoch: [226/484] Iter:[90/495], Time: 0.37, lr: [0.005673112054049071], Loss: 2.061477, Acc:0.795215, Semantic loss: 0.778156, BCE loss: 0.543049, SB loss: 0.740272
2023-10-30 12:09:26,499 Epoch: [226/484] Iter:[100/495], Time: 0.37, lr: [0.005672711974057444], Loss: 2.064912, Acc:0.793528, Semantic loss: 0.780879, BCE loss: 0.540520, SB loss: 0.743513
2023-10-30 12:09:30,041 Epoch: [226/484] Iter:[110/495], Time: 0.37, lr: [0.005672311890930628], Loss: 2.055480, Acc:0.795530, Semantic loss: 0.773510, BCE loss: 0.541226, SB loss: 0.740743
2023-10-30 12:09:33,523 Epoch: [226/484] Iter:[120/495], Time: 0.37, lr: [0.005671911804668352], Loss: 2.052519, Acc:0.796391, Semantic loss: 0.773553, BCE loss: 0.539715, SB loss: 0.739251
2023-10-30 12:09:37,020 Epoch: [226/484] Iter:[130/495], Time: 0.37, lr: [0.005671511715270345], Loss: 2.051079, Acc:0.796306, Semantic loss: 0.770876, BCE loss: 0.541245, SB loss: 0.738958
2023-10-30 12:09:40,555 Epoch: [226/484] Iter:[140/495], Time: 0.36, lr: [0.005671111622736338], Loss: 2.057156, Acc:0.797040, Semantic loss: 0.774461, BCE loss: 0.541857, SB loss: 0.740838
2023-10-30 12:09:44,136 Epoch: [226/484] Iter:[150/495], Time: 0.36, lr: [0.005670711527066059], Loss: 2.055453, Acc:0.797516, Semantic loss: 0.773743, BCE loss: 0.542312, SB loss: 0.739398
2023-10-30 12:09:47,760 Epoch: [226/484] Iter:[160/495], Time: 0.36, lr: [0.00567031142825924], Loss: 2.053689, Acc:0.797587, Semantic loss: 0.773526, BCE loss: 0.540526, SB loss: 0.739637
2023-10-30 12:09:51,383 Epoch: [226/484] Iter:[170/495], Time: 0.36, lr: [0.005669911326315606], Loss: 2.052825, Acc:0.797659, Semantic loss: 0.772110, BCE loss: 0.541441, SB loss: 0.739274
2023-10-30 12:09:54,975 Epoch: [226/484] Iter:[180/495], Time: 0.36, lr: [0.005669511221234892], Loss: 2.054241, Acc:0.797141, Semantic loss: 0.773213, BCE loss: 0.540474, SB loss: 0.740555
2023-10-30 12:09:58,649 Epoch: [226/484] Iter:[190/495], Time: 0.36, lr: [0.005669111113016825], Loss: 2.058807, Acc:0.796404, Semantic loss: 0.777926, BCE loss: 0.538127, SB loss: 0.742754
2023-10-30 12:10:02,332 Epoch: [226/484] Iter:[200/495], Time: 0.36, lr: [0.005668711001661133], Loss: 2.058608, Acc:0.798028, Semantic loss: 0.778173, BCE loss: 0.537092, SB loss: 0.743342
2023-10-30 12:10:06,000 Epoch: [226/484] Iter:[210/495], Time: 0.36, lr: [0.005668310887167547], Loss: 2.059748, Acc:0.799111, Semantic loss: 0.782793, BCE loss: 0.534069, SB loss: 0.742886
2023-10-30 12:10:09,577 Epoch: [226/484] Iter:[220/495], Time: 0.36, lr: [0.005667910769535797], Loss: 2.055359, Acc:0.799018, Semantic loss: 0.778763, BCE loss: 0.535099, SB loss: 0.741498
2023-10-30 12:10:13,214 Epoch: [226/484] Iter:[230/495], Time: 0.36, lr: [0.005667510648765608], Loss: 2.051756, Acc:0.798215, Semantic loss: 0.776135, BCE loss: 0.535018, SB loss: 0.740602
2023-10-30 12:10:16,843 Epoch: [226/484] Iter:[240/495], Time: 0.36, lr: [0.005667110524856715], Loss: 2.054606, Acc:0.797922, Semantic loss: 0.775469, BCE loss: 0.537615, SB loss: 0.741523
2023-10-30 12:10:20,612 Epoch: [226/484] Iter:[250/495], Time: 0.36, lr: [0.005666710397808842], Loss: 2.058518, Acc:0.797692, Semantic loss: 0.777907, BCE loss: 0.537687, SB loss: 0.742924
2023-10-30 12:10:24,226 Epoch: [226/484] Iter:[260/495], Time: 0.36, lr: [0.005666310267621722], Loss: 2.058658, Acc:0.799202, Semantic loss: 0.778380, BCE loss: 0.537749, SB loss: 0.742529
2023-10-30 12:10:27,954 Epoch: [226/484] Iter:[270/495], Time: 0.36, lr: [0.0056659101342950826], Loss: 2.061150, Acc:0.799073, Semantic loss: 0.776960, BCE loss: 0.540520, SB loss: 0.743670
2023-10-30 12:10:31,545 Epoch: [226/484] Iter:[280/495], Time: 0.36, lr: [0.005665509997828653], Loss: 2.063092, Acc:0.799984, Semantic loss: 0.775967, BCE loss: 0.543531, SB loss: 0.743594
2023-10-30 12:10:35,226 Epoch: [226/484] Iter:[290/495], Time: 0.36, lr: [0.0056651098582221615], Loss: 2.057424, Acc:0.799640, Semantic loss: 0.774166, BCE loss: 0.540598, SB loss: 0.742661
2023-10-30 12:10:38,926 Epoch: [226/484] Iter:[300/495], Time: 0.36, lr: [0.0056647097154753365], Loss: 2.057102, Acc:0.800174, Semantic loss: 0.773349, BCE loss: 0.541617, SB loss: 0.742136
2023-10-30 12:10:42,522 Epoch: [226/484] Iter:[310/495], Time: 0.36, lr: [0.005664309569587909], Loss: 2.057921, Acc:0.800734, Semantic loss: 0.774536, BCE loss: 0.540838, SB loss: 0.742547
2023-10-30 12:10:46,203 Epoch: [226/484] Iter:[320/495], Time: 0.36, lr: [0.005663909420559606], Loss: 2.058242, Acc:0.800146, Semantic loss: 0.774903, BCE loss: 0.540708, SB loss: 0.742631
2023-10-30 12:10:49,824 Epoch: [226/484] Iter:[330/495], Time: 0.36, lr: [0.005663509268390157], Loss: 2.059999, Acc:0.799174, Semantic loss: 0.776405, BCE loss: 0.540250, SB loss: 0.743344
2023-10-30 12:10:53,422 Epoch: [226/484] Iter:[340/495], Time: 0.36, lr: [0.00566310911307929], Loss: 2.060352, Acc:0.799034, Semantic loss: 0.776118, BCE loss: 0.540420, SB loss: 0.743814
2023-10-30 12:10:57,028 Epoch: [226/484] Iter:[350/495], Time: 0.36, lr: [0.005662708954626736], Loss: 2.058775, Acc:0.799619, Semantic loss: 0.774130, BCE loss: 0.540046, SB loss: 0.744598
2023-10-30 12:11:00,711 Epoch: [226/484] Iter:[360/495], Time: 0.36, lr: [0.005662308793032221], Loss: 2.061582, Acc:0.800032, Semantic loss: 0.776887, BCE loss: 0.538785, SB loss: 0.745910
2023-10-30 12:11:04,439 Epoch: [226/484] Iter:[370/495], Time: 0.36, lr: [0.005661908628295476], Loss: 2.061121, Acc:0.799634, Semantic loss: 0.777899, BCE loss: 0.537361, SB loss: 0.745861
2023-10-30 12:11:08,188 Epoch: [226/484] Iter:[380/495], Time: 0.36, lr: [0.005661508460416226], Loss: 2.060760, Acc:0.798751, Semantic loss: 0.777219, BCE loss: 0.537655, SB loss: 0.745886
2023-10-30 12:11:11,808 Epoch: [226/484] Iter:[390/495], Time: 0.36, lr: [0.005661108289394202], Loss: 2.064996, Acc:0.798280, Semantic loss: 0.779786, BCE loss: 0.538323, SB loss: 0.746887
2023-10-30 12:11:15,496 Epoch: [226/484] Iter:[400/495], Time: 0.36, lr: [0.005660708115229133], Loss: 2.066119, Acc:0.798442, Semantic loss: 0.779122, BCE loss: 0.540040, SB loss: 0.746957
2023-10-30 12:11:19,126 Epoch: [226/484] Iter:[410/495], Time: 0.36, lr: [0.005660307937920745], Loss: 2.063571, Acc:0.799464, Semantic loss: 0.777904, BCE loss: 0.539957, SB loss: 0.745710
2023-10-30 12:11:22,861 Epoch: [226/484] Iter:[420/495], Time: 0.37, lr: [0.0056599077574687705], Loss: 2.065308, Acc:0.799637, Semantic loss: 0.778188, BCE loss: 0.540620, SB loss: 0.746501
2023-10-30 12:11:26,530 Epoch: [226/484] Iter:[430/495], Time: 0.37, lr: [0.0056595075738729355], Loss: 2.063311, Acc:0.799696, Semantic loss: 0.776935, BCE loss: 0.539889, SB loss: 0.746486
2023-10-30 12:11:30,134 Epoch: [226/484] Iter:[440/495], Time: 0.37, lr: [0.005659107387132967], Loss: 2.060471, Acc:0.799705, Semantic loss: 0.775516, BCE loss: 0.539300, SB loss: 0.745655
2023-10-30 12:11:33,802 Epoch: [226/484] Iter:[450/495], Time: 0.37, lr: [0.005658707197248594], Loss: 2.062826, Acc:0.799575, Semantic loss: 0.778510, BCE loss: 0.538127, SB loss: 0.746189
2023-10-30 12:11:37,449 Epoch: [226/484] Iter:[460/495], Time: 0.37, lr: [0.005658307004219545], Loss: 2.060937, Acc:0.799760, Semantic loss: 0.776941, BCE loss: 0.538445, SB loss: 0.745550
2023-10-30 12:11:41,020 Epoch: [226/484] Iter:[470/495], Time: 0.36, lr: [0.005657906808045549], Loss: 2.059031, Acc:0.799604, Semantic loss: 0.776469, BCE loss: 0.537300, SB loss: 0.745262
2023-10-30 12:11:44,649 Epoch: [226/484] Iter:[480/495], Time: 0.36, lr: [0.005657506608726333], Loss: 2.059761, Acc:0.799205, Semantic loss: 0.778124, BCE loss: 0.535812, SB loss: 0.745824
2023-10-30 12:11:48,129 Epoch: [226/484] Iter:[490/495], Time: 0.36, lr: [0.005657106406261624], Loss: 2.056328, Acc:0.798176, Semantic loss: 0.776365, BCE loss: 0.534527, SB loss: 0.745437
2023-10-30 12:11:49,543 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:11:49,774 Loss: 2.050, MeanIU:  0.6827, Best_mIoU:  0.7151
2023-10-30 12:11:49,774 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489]
2023-10-30 12:11:51,907 Epoch: [227/484] Iter:[0/495], Time: 2.10, lr: [0.005656906303849626], Loss: 2.107821, Acc:0.813011, Semantic loss: 0.649406, BCE loss: 0.769963, SB loss: 0.688452
2023-10-30 12:11:55,868 Epoch: [227/484] Iter:[10/495], Time: 0.55, lr: [0.005656506096666172], Loss: 2.092720, Acc:0.830752, Semantic loss: 0.722548, BCE loss: 0.634267, SB loss: 0.735906
2023-10-30 12:11:59,574 Epoch: [227/484] Iter:[20/495], Time: 0.47, lr: [0.005656105886336546], Loss: 2.087303, Acc:0.817759, Semantic loss: 0.744974, BCE loss: 0.603057, SB loss: 0.739272
2023-10-30 12:12:03,308 Epoch: [227/484] Iter:[30/495], Time: 0.44, lr: [0.005655705672860475], Loss: 2.156096, Acc:0.808747, Semantic loss: 0.816800, BCE loss: 0.573036, SB loss: 0.766260
2023-10-30 12:12:06,895 Epoch: [227/484] Iter:[40/495], Time: 0.42, lr: [0.005655305456237689], Loss: 2.109381, Acc:0.814233, Semantic loss: 0.794341, BCE loss: 0.562016, SB loss: 0.753023
2023-10-30 12:12:10,535 Epoch: [227/484] Iter:[50/495], Time: 0.41, lr: [0.005654905236467915], Loss: 2.071285, Acc:0.812320, Semantic loss: 0.776241, BCE loss: 0.553829, SB loss: 0.741215
2023-10-30 12:12:14,198 Epoch: [227/484] Iter:[60/495], Time: 0.40, lr: [0.0056545050135508815], Loss: 2.092949, Acc:0.806492, Semantic loss: 0.789163, BCE loss: 0.560447, SB loss: 0.743339
2023-10-30 12:12:17,856 Epoch: [227/484] Iter:[70/495], Time: 0.40, lr: [0.005654104787486314], Loss: 2.078948, Acc:0.809178, Semantic loss: 0.772528, BCE loss: 0.567865, SB loss: 0.738555
2023-10-30 12:12:21,543 Epoch: [227/484] Iter:[80/495], Time: 0.39, lr: [0.0056537045582739425], Loss: 2.093494, Acc:0.802038, Semantic loss: 0.784584, BCE loss: 0.566337, SB loss: 0.742573
2023-10-30 12:12:25,188 Epoch: [227/484] Iter:[90/495], Time: 0.39, lr: [0.005653304325913495], Loss: 2.108516, Acc:0.799732, Semantic loss: 0.792833, BCE loss: 0.565739, SB loss: 0.749944
2023-10-30 12:12:28,782 Epoch: [227/484] Iter:[100/495], Time: 0.39, lr: [0.005652904090404696], Loss: 2.102165, Acc:0.798749, Semantic loss: 0.785844, BCE loss: 0.567392, SB loss: 0.748929
2023-10-30 12:12:32,462 Epoch: [227/484] Iter:[110/495], Time: 0.38, lr: [0.005652503851747276], Loss: 2.091791, Acc:0.800565, Semantic loss: 0.783806, BCE loss: 0.561360, SB loss: 0.746625
2023-10-30 12:12:36,111 Epoch: [227/484] Iter:[120/495], Time: 0.38, lr: [0.005652103609940962], Loss: 2.089892, Acc:0.799590, Semantic loss: 0.785344, BCE loss: 0.555827, SB loss: 0.748721
2023-10-30 12:12:39,720 Epoch: [227/484] Iter:[130/495], Time: 0.38, lr: [0.0056517033649854794], Loss: 2.085520, Acc:0.796463, Semantic loss: 0.781884, BCE loss: 0.553735, SB loss: 0.749901
2023-10-30 12:12:43,334 Epoch: [227/484] Iter:[140/495], Time: 0.38, lr: [0.005651303116880558], Loss: 2.077527, Acc:0.795993, Semantic loss: 0.778705, BCE loss: 0.551666, SB loss: 0.747157
2023-10-30 12:12:47,015 Epoch: [227/484] Iter:[150/495], Time: 0.38, lr: [0.005650902865625924], Loss: 2.073735, Acc:0.795172, Semantic loss: 0.780512, BCE loss: 0.545631, SB loss: 0.747592
2023-10-30 12:12:50,648 Epoch: [227/484] Iter:[160/495], Time: 0.38, lr: [0.005650502611221306], Loss: 2.078205, Acc:0.797466, Semantic loss: 0.783265, BCE loss: 0.545906, SB loss: 0.749034
2023-10-30 12:12:54,310 Epoch: [227/484] Iter:[170/495], Time: 0.38, lr: [0.005650102353666431], Loss: 2.081388, Acc:0.796774, Semantic loss: 0.788695, BCE loss: 0.542193, SB loss: 0.750500
2023-10-30 12:12:57,986 Epoch: [227/484] Iter:[180/495], Time: 0.38, lr: [0.005649702092961025], Loss: 2.085096, Acc:0.796343, Semantic loss: 0.788736, BCE loss: 0.542946, SB loss: 0.753414
2023-10-30 12:13:01,670 Epoch: [227/484] Iter:[190/495], Time: 0.38, lr: [0.005649301829104816], Loss: 2.083118, Acc:0.798026, Semantic loss: 0.787199, BCE loss: 0.543279, SB loss: 0.752640
2023-10-30 12:13:05,233 Epoch: [227/484] Iter:[200/495], Time: 0.38, lr: [0.00564890156209753], Loss: 2.084846, Acc:0.797379, Semantic loss: 0.791571, BCE loss: 0.541791, SB loss: 0.751484
2023-10-30 12:13:08,884 Epoch: [227/484] Iter:[210/495], Time: 0.37, lr: [0.005648501291938896], Loss: 2.088020, Acc:0.799665, Semantic loss: 0.791415, BCE loss: 0.543088, SB loss: 0.753517
2023-10-30 12:13:12,617 Epoch: [227/484] Iter:[220/495], Time: 0.37, lr: [0.005648101018628639], Loss: 2.092692, Acc:0.799766, Semantic loss: 0.792694, BCE loss: 0.545549, SB loss: 0.754449
2023-10-30 12:13:16,360 Epoch: [227/484] Iter:[230/495], Time: 0.37, lr: [0.005647700742166487], Loss: 2.090509, Acc:0.799166, Semantic loss: 0.790563, BCE loss: 0.546625, SB loss: 0.753321
2023-10-30 12:13:19,924 Epoch: [227/484] Iter:[240/495], Time: 0.37, lr: [0.0056473004625521685], Loss: 2.090682, Acc:0.798958, Semantic loss: 0.790584, BCE loss: 0.547582, SB loss: 0.752515
2023-10-30 12:13:23,531 Epoch: [227/484] Iter:[250/495], Time: 0.37, lr: [0.0056469001797854095], Loss: 2.084239, Acc:0.797881, Semantic loss: 0.786880, BCE loss: 0.545812, SB loss: 0.751547
2023-10-30 12:13:27,101 Epoch: [227/484] Iter:[260/495], Time: 0.37, lr: [0.005646499893865935], Loss: 2.077419, Acc:0.798356, Semantic loss: 0.785049, BCE loss: 0.541948, SB loss: 0.750423
2023-10-30 12:13:30,687 Epoch: [227/484] Iter:[270/495], Time: 0.37, lr: [0.005646099604793474], Loss: 2.073335, Acc:0.796875, Semantic loss: 0.783333, BCE loss: 0.540532, SB loss: 0.749470
2023-10-30 12:13:34,334 Epoch: [227/484] Iter:[280/495], Time: 0.37, lr: [0.005645699312567753], Loss: 2.068685, Acc:0.795361, Semantic loss: 0.780250, BCE loss: 0.539644, SB loss: 0.748791
2023-10-30 12:13:38,058 Epoch: [227/484] Iter:[290/495], Time: 0.37, lr: [0.005645299017188497], Loss: 2.067968, Acc:0.795329, Semantic loss: 0.779932, BCE loss: 0.538167, SB loss: 0.749870
2023-10-30 12:13:41,778 Epoch: [227/484] Iter:[300/495], Time: 0.37, lr: [0.005644898718655434], Loss: 2.068005, Acc:0.795640, Semantic loss: 0.780911, BCE loss: 0.537156, SB loss: 0.749939
2023-10-30 12:13:45,425 Epoch: [227/484] Iter:[310/495], Time: 0.37, lr: [0.005644498416968291], Loss: 2.067722, Acc:0.794891, Semantic loss: 0.780849, BCE loss: 0.536175, SB loss: 0.750698
2023-10-30 12:13:49,073 Epoch: [227/484] Iter:[320/495], Time: 0.37, lr: [0.005644098112126794], Loss: 2.065309, Acc:0.793544, Semantic loss: 0.780020, BCE loss: 0.535264, SB loss: 0.750025
2023-10-30 12:13:52,672 Epoch: [227/484] Iter:[330/495], Time: 0.37, lr: [0.0056436978041306705], Loss: 2.066903, Acc:0.793843, Semantic loss: 0.780583, BCE loss: 0.536338, SB loss: 0.749981
2023-10-30 12:13:56,336 Epoch: [227/484] Iter:[340/495], Time: 0.37, lr: [0.005643297492979647], Loss: 2.066680, Acc:0.792737, Semantic loss: 0.780174, BCE loss: 0.536092, SB loss: 0.750415
2023-10-30 12:13:59,999 Epoch: [227/484] Iter:[350/495], Time: 0.37, lr: [0.0056428971786734484], Loss: 2.066432, Acc:0.792699, Semantic loss: 0.779469, BCE loss: 0.536805, SB loss: 0.750158
2023-10-30 12:14:03,630 Epoch: [227/484] Iter:[360/495], Time: 0.37, lr: [0.005642496861211802], Loss: 2.066808, Acc:0.792391, Semantic loss: 0.780445, BCE loss: 0.536715, SB loss: 0.749648
2023-10-30 12:14:07,361 Epoch: [227/484] Iter:[370/495], Time: 0.37, lr: [0.005642096540594432], Loss: 2.069492, Acc:0.792046, Semantic loss: 0.781535, BCE loss: 0.537769, SB loss: 0.750189
2023-10-30 12:14:11,075 Epoch: [227/484] Iter:[380/495], Time: 0.37, lr: [0.0056416962168210705], Loss: 2.068119, Acc:0.792344, Semantic loss: 0.780839, BCE loss: 0.537640, SB loss: 0.749641
2023-10-30 12:14:14,730 Epoch: [227/484] Iter:[390/495], Time: 0.37, lr: [0.005641295889891438], Loss: 2.067654, Acc:0.792314, Semantic loss: 0.779455, BCE loss: 0.539099, SB loss: 0.749101
2023-10-30 12:14:18,276 Epoch: [227/484] Iter:[400/495], Time: 0.37, lr: [0.005640895559805264], Loss: 2.065433, Acc:0.791867, Semantic loss: 0.778235, BCE loss: 0.538196, SB loss: 0.749003
2023-10-30 12:14:22,018 Epoch: [227/484] Iter:[410/495], Time: 0.37, lr: [0.005640495226562273], Loss: 2.066203, Acc:0.790997, Semantic loss: 0.780783, BCE loss: 0.536659, SB loss: 0.748761
2023-10-30 12:14:25,635 Epoch: [227/484] Iter:[420/495], Time: 0.37, lr: [0.005640094890162193], Loss: 2.068896, Acc:0.790904, Semantic loss: 0.782290, BCE loss: 0.537057, SB loss: 0.749549
2023-10-30 12:14:29,468 Epoch: [227/484] Iter:[430/495], Time: 0.37, lr: [0.005639694550604748], Loss: 2.065783, Acc:0.791545, Semantic loss: 0.780306, BCE loss: 0.536471, SB loss: 0.749007
2023-10-30 12:14:33,042 Epoch: [227/484] Iter:[440/495], Time: 0.37, lr: [0.005639294207889665], Loss: 2.072177, Acc:0.791220, Semantic loss: 0.784949, BCE loss: 0.536406, SB loss: 0.750823
2023-10-30 12:14:36,666 Epoch: [227/484] Iter:[450/495], Time: 0.37, lr: [0.005638893862016669], Loss: 2.071644, Acc:0.790843, Semantic loss: 0.784730, BCE loss: 0.535252, SB loss: 0.751662
2023-10-30 12:14:40,339 Epoch: [227/484] Iter:[460/495], Time: 0.37, lr: [0.005638493512985489], Loss: 2.072216, Acc:0.790761, Semantic loss: 0.785450, BCE loss: 0.535320, SB loss: 0.751446
2023-10-30 12:14:44,002 Epoch: [227/484] Iter:[470/495], Time: 0.37, lr: [0.0056380931607958465], Loss: 2.069917, Acc:0.790806, Semantic loss: 0.784272, BCE loss: 0.534524, SB loss: 0.751120
2023-10-30 12:14:47,572 Epoch: [227/484] Iter:[480/495], Time: 0.37, lr: [0.005637692805447471], Loss: 2.069216, Acc:0.791539, Semantic loss: 0.783691, BCE loss: 0.534748, SB loss: 0.750777
2023-10-30 12:14:51,057 Epoch: [227/484] Iter:[490/495], Time: 0.37, lr: [0.005637292446940088], Loss: 2.067607, Acc:0.791532, Semantic loss: 0.783112, BCE loss: 0.533944, SB loss: 0.750551
2023-10-30 12:14:52,462 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:14:52,698 Loss: 2.050, MeanIU:  0.6827, Best_mIoU:  0.7151
2023-10-30 12:14:52,698 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489]
2023-10-30 12:14:54,743 Epoch: [228/484] Iter:[0/495], Time: 2.01, lr: [0.0056370922665016825], Loss: 2.987719, Acc:0.573655, Semantic loss: 1.332979, BCE loss: 0.604854, SB loss: 1.049886
2023-10-30 12:14:58,677 Epoch: [228/484] Iter:[10/495], Time: 0.54, lr: [0.005636691903255272], Loss: 2.042205, Acc:0.772304, Semantic loss: 0.746869, BCE loss: 0.570926, SB loss: 0.724410
2023-10-30 12:15:02,434 Epoch: [228/484] Iter:[20/495], Time: 0.46, lr: [0.005636291536849167], Loss: 2.128330, Acc:0.780328, Semantic loss: 0.810492, BCE loss: 0.587185, SB loss: 0.730653
2023-10-30 12:15:06,139 Epoch: [228/484] Iter:[30/495], Time: 0.43, lr: [0.005635891167283093], Loss: 2.084463, Acc:0.784063, Semantic loss: 0.790535, BCE loss: 0.567822, SB loss: 0.726105
2023-10-30 12:15:09,845 Epoch: [228/484] Iter:[40/495], Time: 0.42, lr: [0.005635490794556779], Loss: 2.056792, Acc:0.788495, Semantic loss: 0.767406, BCE loss: 0.561343, SB loss: 0.728043
2023-10-30 12:15:13,486 Epoch: [228/484] Iter:[50/495], Time: 0.41, lr: [0.005635090418669945], Loss: 2.054003, Acc:0.794783, Semantic loss: 0.765527, BCE loss: 0.557618, SB loss: 0.730858
2023-10-30 12:15:17,150 Epoch: [228/484] Iter:[60/495], Time: 0.40, lr: [0.005634690039622321], Loss: 2.051032, Acc:0.802207, Semantic loss: 0.760899, BCE loss: 0.557475, SB loss: 0.732658
2023-10-30 12:15:20,785 Epoch: [228/484] Iter:[70/495], Time: 0.40, lr: [0.005634289657413631], Loss: 2.070172, Acc:0.803771, Semantic loss: 0.775806, BCE loss: 0.560309, SB loss: 0.734057
2023-10-30 12:15:24,426 Epoch: [228/484] Iter:[80/495], Time: 0.39, lr: [0.005633889272043601], Loss: 2.055164, Acc:0.803358, Semantic loss: 0.767552, BCE loss: 0.556020, SB loss: 0.731592
2023-10-30 12:15:28,092 Epoch: [228/484] Iter:[90/495], Time: 0.39, lr: [0.005633488883511954], Loss: 2.071338, Acc:0.802143, Semantic loss: 0.779961, BCE loss: 0.553452, SB loss: 0.737924
2023-10-30 12:15:31,758 Epoch: [228/484] Iter:[100/495], Time: 0.39, lr: [0.005633088491818419], Loss: 2.080965, Acc:0.799155, Semantic loss: 0.786293, BCE loss: 0.551306, SB loss: 0.743366
2023-10-30 12:15:35,464 Epoch: [228/484] Iter:[110/495], Time: 0.38, lr: [0.0056326880969627185], Loss: 2.080172, Acc:0.797799, Semantic loss: 0.788639, BCE loss: 0.547036, SB loss: 0.744497
2023-10-30 12:15:39,146 Epoch: [228/484] Iter:[120/495], Time: 0.38, lr: [0.005632287698944578], Loss: 2.075851, Acc:0.798748, Semantic loss: 0.781987, BCE loss: 0.551107, SB loss: 0.742757
2023-10-30 12:15:42,884 Epoch: [228/484] Iter:[130/495], Time: 0.38, lr: [0.005631887297763724], Loss: 2.065740, Acc:0.798108, Semantic loss: 0.778372, BCE loss: 0.545171, SB loss: 0.742197
2023-10-30 12:15:46,588 Epoch: [228/484] Iter:[140/495], Time: 0.38, lr: [0.005631486893419881], Loss: 2.058867, Acc:0.798896, Semantic loss: 0.772225, BCE loss: 0.545934, SB loss: 0.740708
2023-10-30 12:15:50,263 Epoch: [228/484] Iter:[150/495], Time: 0.38, lr: [0.005631086485912775], Loss: 2.058552, Acc:0.798589, Semantic loss: 0.775104, BCE loss: 0.542272, SB loss: 0.741176
2023-10-30 12:15:53,897 Epoch: [228/484] Iter:[160/495], Time: 0.38, lr: [0.0056306860752421296], Loss: 2.054021, Acc:0.801617, Semantic loss: 0.770939, BCE loss: 0.543814, SB loss: 0.739268
2023-10-30 12:15:57,629 Epoch: [228/484] Iter:[170/495], Time: 0.38, lr: [0.005630285661407671], Loss: 2.057350, Acc:0.802035, Semantic loss: 0.771737, BCE loss: 0.544685, SB loss: 0.740928
2023-10-30 12:16:01,347 Epoch: [228/484] Iter:[180/495], Time: 0.38, lr: [0.005629885244409124], Loss: 2.060934, Acc:0.801915, Semantic loss: 0.776023, BCE loss: 0.542236, SB loss: 0.742675
2023-10-30 12:16:05,144 Epoch: [228/484] Iter:[190/495], Time: 0.38, lr: [0.005629484824246213], Loss: 2.054404, Acc:0.799878, Semantic loss: 0.773113, BCE loss: 0.539319, SB loss: 0.741972
2023-10-30 12:16:08,810 Epoch: [228/484] Iter:[200/495], Time: 0.38, lr: [0.005629084400918662], Loss: 2.049383, Acc:0.801836, Semantic loss: 0.769649, BCE loss: 0.538363, SB loss: 0.741370
2023-10-30 12:16:12,515 Epoch: [228/484] Iter:[210/495], Time: 0.38, lr: [0.005628683974426198], Loss: 2.049542, Acc:0.801167, Semantic loss: 0.770085, BCE loss: 0.536498, SB loss: 0.742959
2023-10-30 12:16:16,185 Epoch: [228/484] Iter:[220/495], Time: 0.38, lr: [0.005628283544768546], Loss: 2.043243, Acc:0.801188, Semantic loss: 0.767423, BCE loss: 0.534724, SB loss: 0.741096
2023-10-30 12:16:19,816 Epoch: [228/484] Iter:[230/495], Time: 0.38, lr: [0.005627883111945429], Loss: 2.039286, Acc:0.802072, Semantic loss: 0.764776, BCE loss: 0.533913, SB loss: 0.740598
2023-10-30 12:16:23,630 Epoch: [228/484] Iter:[240/495], Time: 0.38, lr: [0.0056274826759565725], Loss: 2.045177, Acc:0.801156, Semantic loss: 0.766994, BCE loss: 0.535833, SB loss: 0.742350
2023-10-30 12:16:27,279 Epoch: [228/484] Iter:[250/495], Time: 0.38, lr: [0.005627082236801701], Loss: 2.045293, Acc:0.801109, Semantic loss: 0.766803, BCE loss: 0.535961, SB loss: 0.742528
2023-10-30 12:16:30,912 Epoch: [228/484] Iter:[260/495], Time: 0.38, lr: [0.005626681794480538], Loss: 2.044924, Acc:0.801964, Semantic loss: 0.767660, BCE loss: 0.535118, SB loss: 0.742146
2023-10-30 12:16:34,636 Epoch: [228/484] Iter:[270/495], Time: 0.38, lr: [0.005626281348992809], Loss: 2.046958, Acc:0.802220, Semantic loss: 0.769153, BCE loss: 0.535877, SB loss: 0.741928
2023-10-30 12:16:38,332 Epoch: [228/484] Iter:[280/495], Time: 0.38, lr: [0.00562588090033824], Loss: 2.046079, Acc:0.801477, Semantic loss: 0.767898, BCE loss: 0.536165, SB loss: 0.742017
2023-10-30 12:16:41,943 Epoch: [228/484] Iter:[290/495], Time: 0.38, lr: [0.005625480448516553], Loss: 2.050244, Acc:0.801916, Semantic loss: 0.768895, BCE loss: 0.538389, SB loss: 0.742961
2023-10-30 12:16:45,592 Epoch: [228/484] Iter:[300/495], Time: 0.37, lr: [0.005625079993527475], Loss: 2.048898, Acc:0.801538, Semantic loss: 0.767522, BCE loss: 0.538175, SB loss: 0.743202
2023-10-30 12:16:49,309 Epoch: [228/484] Iter:[310/495], Time: 0.37, lr: [0.00562467953537073], Loss: 2.053333, Acc:0.800999, Semantic loss: 0.769792, BCE loss: 0.539368, SB loss: 0.744174
2023-10-30 12:16:52,962 Epoch: [228/484] Iter:[320/495], Time: 0.37, lr: [0.00562427907404604], Loss: 2.052847, Acc:0.800436, Semantic loss: 0.769337, BCE loss: 0.539351, SB loss: 0.744160
2023-10-30 12:16:56,551 Epoch: [228/484] Iter:[330/495], Time: 0.37, lr: [0.0056238786095531325], Loss: 2.049294, Acc:0.800415, Semantic loss: 0.767736, BCE loss: 0.538124, SB loss: 0.743433
2023-10-30 12:17:00,144 Epoch: [228/484] Iter:[340/495], Time: 0.37, lr: [0.005623478141891727], Loss: 2.046750, Acc:0.800334, Semantic loss: 0.766771, BCE loss: 0.537661, SB loss: 0.742319
2023-10-30 12:17:03,820 Epoch: [228/484] Iter:[350/495], Time: 0.37, lr: [0.0056230776710615524], Loss: 2.047695, Acc:0.800777, Semantic loss: 0.766860, BCE loss: 0.538091, SB loss: 0.742745
2023-10-30 12:17:07,498 Epoch: [228/484] Iter:[360/495], Time: 0.37, lr: [0.005622677197062331], Loss: 2.048320, Acc:0.800734, Semantic loss: 0.767803, BCE loss: 0.536842, SB loss: 0.743675
2023-10-30 12:17:11,111 Epoch: [228/484] Iter:[370/495], Time: 0.37, lr: [0.005622276719893788], Loss: 2.045895, Acc:0.801698, Semantic loss: 0.767384, BCE loss: 0.535830, SB loss: 0.742682
2023-10-30 12:17:14,773 Epoch: [228/484] Iter:[380/495], Time: 0.37, lr: [0.005621876239555647], Loss: 2.045681, Acc:0.801467, Semantic loss: 0.767468, BCE loss: 0.536580, SB loss: 0.741633
2023-10-30 12:17:18,416 Epoch: [228/484] Iter:[390/495], Time: 0.37, lr: [0.005621475756047631], Loss: 2.049317, Acc:0.801095, Semantic loss: 0.770211, BCE loss: 0.536843, SB loss: 0.742263
2023-10-30 12:17:22,098 Epoch: [228/484] Iter:[400/495], Time: 0.37, lr: [0.005621075269369465], Loss: 2.052304, Acc:0.801755, Semantic loss: 0.772075, BCE loss: 0.537690, SB loss: 0.742539
2023-10-30 12:17:25,833 Epoch: [228/484] Iter:[410/495], Time: 0.37, lr: [0.0056206747795208714], Loss: 2.050304, Acc:0.801930, Semantic loss: 0.770792, BCE loss: 0.537501, SB loss: 0.742012
2023-10-30 12:17:29,538 Epoch: [228/484] Iter:[420/495], Time: 0.37, lr: [0.005620274286501574], Loss: 2.049069, Acc:0.802590, Semantic loss: 0.771229, BCE loss: 0.536261, SB loss: 0.741579
2023-10-30 12:17:33,237 Epoch: [228/484] Iter:[430/495], Time: 0.37, lr: [0.005619873790311301], Loss: 2.046204, Acc:0.802993, Semantic loss: 0.769451, BCE loss: 0.535548, SB loss: 0.741204
2023-10-30 12:17:36,938 Epoch: [228/484] Iter:[440/495], Time: 0.37, lr: [0.005619473290949771], Loss: 2.045022, Acc:0.803759, Semantic loss: 0.767943, BCE loss: 0.536514, SB loss: 0.740565
2023-10-30 12:17:40,605 Epoch: [228/484] Iter:[450/495], Time: 0.37, lr: [0.005619072788416711], Loss: 2.044508, Acc:0.803467, Semantic loss: 0.768062, BCE loss: 0.536160, SB loss: 0.740285
2023-10-30 12:17:44,286 Epoch: [228/484] Iter:[460/495], Time: 0.37, lr: [0.005618672282711844], Loss: 2.044229, Acc:0.803438, Semantic loss: 0.767769, BCE loss: 0.536085, SB loss: 0.740375
2023-10-30 12:17:47,983 Epoch: [228/484] Iter:[470/495], Time: 0.37, lr: [0.005618271773834893], Loss: 2.047430, Acc:0.803110, Semantic loss: 0.769969, BCE loss: 0.537116, SB loss: 0.740345
2023-10-30 12:17:51,710 Epoch: [228/484] Iter:[480/495], Time: 0.37, lr: [0.005617871261785582], Loss: 2.047376, Acc:0.802810, Semantic loss: 0.770402, BCE loss: 0.536496, SB loss: 0.740478
2023-10-30 12:17:55,283 Epoch: [228/484] Iter:[490/495], Time: 0.37, lr: [0.005617470746563634], Loss: 2.044330, Acc:0.802809, Semantic loss: 0.769507, BCE loss: 0.534800, SB loss: 0.740023
2023-10-30 12:17:56,700 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:17:56,932 Loss: 2.050, MeanIU:  0.6827, Best_mIoU:  0.7151
2023-10-30 12:17:56,932 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489]
2023-10-30 12:17:58,985 Epoch: [229/484] Iter:[0/495], Time: 2.01, lr: [0.005617270487762836], Loss: 1.606424, Acc:0.838922, Semantic loss: 0.520894, BCE loss: 0.476173, SB loss: 0.609358
2023-10-30 12:18:02,923 Epoch: [229/484] Iter:[10/495], Time: 0.54, lr: [0.005616869967781413], Loss: 1.929805, Acc:0.773600, Semantic loss: 0.710151, BCE loss: 0.504895, SB loss: 0.714759
2023-10-30 12:18:06,593 Epoch: [229/484] Iter:[20/495], Time: 0.46, lr: [0.005616469444626665], Loss: 2.070337, Acc:0.786787, Semantic loss: 0.767448, BCE loss: 0.529928, SB loss: 0.772960
2023-10-30 12:18:10,325 Epoch: [229/484] Iter:[30/495], Time: 0.43, lr: [0.005616068918298311], Loss: 2.074413, Acc:0.794976, Semantic loss: 0.768976, BCE loss: 0.545402, SB loss: 0.760035
2023-10-30 12:18:14,127 Epoch: [229/484] Iter:[40/495], Time: 0.42, lr: [0.005615668388796077], Loss: 2.049616, Acc:0.798961, Semantic loss: 0.758277, BCE loss: 0.542084, SB loss: 0.749255
2023-10-30 12:18:17,743 Epoch: [229/484] Iter:[50/495], Time: 0.41, lr: [0.005615267856119685], Loss: 2.044076, Acc:0.810253, Semantic loss: 0.750728, BCE loss: 0.550950, SB loss: 0.742397
2023-10-30 12:18:21,407 Epoch: [229/484] Iter:[60/495], Time: 0.40, lr: [0.005614867320268858], Loss: 2.043898, Acc:0.804141, Semantic loss: 0.755601, BCE loss: 0.547123, SB loss: 0.741175
2023-10-30 12:18:25,155 Epoch: [229/484] Iter:[70/495], Time: 0.40, lr: [0.005614466781243321], Loss: 2.063657, Acc:0.804349, Semantic loss: 0.776777, BCE loss: 0.544678, SB loss: 0.742202
2023-10-30 12:18:28,820 Epoch: [229/484] Iter:[80/495], Time: 0.39, lr: [0.005614066239042795], Loss: 2.068434, Acc:0.803751, Semantic loss: 0.777331, BCE loss: 0.543243, SB loss: 0.747861
2023-10-30 12:18:32,561 Epoch: [229/484] Iter:[90/495], Time: 0.39, lr: [0.0056136656936670035], Loss: 2.066452, Acc:0.798398, Semantic loss: 0.779234, BCE loss: 0.537780, SB loss: 0.749439
2023-10-30 12:18:36,246 Epoch: [229/484] Iter:[100/495], Time: 0.39, lr: [0.005613265145115672], Loss: 2.081226, Acc:0.799366, Semantic loss: 0.788610, BCE loss: 0.539590, SB loss: 0.753025
2023-10-30 12:18:39,867 Epoch: [229/484] Iter:[110/495], Time: 0.39, lr: [0.00561286459338852], Loss: 2.086305, Acc:0.800923, Semantic loss: 0.791590, BCE loss: 0.540608, SB loss: 0.754107
2023-10-30 12:18:43,499 Epoch: [229/484] Iter:[120/495], Time: 0.38, lr: [0.005612464038485274], Loss: 2.072139, Acc:0.798844, Semantic loss: 0.783603, BCE loss: 0.539291, SB loss: 0.749244
2023-10-30 12:18:47,159 Epoch: [229/484] Iter:[130/495], Time: 0.38, lr: [0.005612063480405655], Loss: 2.077423, Acc:0.794328, Semantic loss: 0.789283, BCE loss: 0.535513, SB loss: 0.752628
2023-10-30 12:18:50,812 Epoch: [229/484] Iter:[140/495], Time: 0.38, lr: [0.005611662919149385], Loss: 2.070202, Acc:0.795263, Semantic loss: 0.783482, BCE loss: 0.535791, SB loss: 0.750929
2023-10-30 12:18:54,555 Epoch: [229/484] Iter:[150/495], Time: 0.38, lr: [0.005611262354716189], Loss: 2.055631, Acc:0.797467, Semantic loss: 0.778464, BCE loss: 0.530969, SB loss: 0.746198
2023-10-30 12:18:58,182 Epoch: [229/484] Iter:[160/495], Time: 0.38, lr: [0.005610861787105788], Loss: 2.066250, Acc:0.797654, Semantic loss: 0.785763, BCE loss: 0.532420, SB loss: 0.748067
2023-10-30 12:19:01,850 Epoch: [229/484] Iter:[170/495], Time: 0.38, lr: [0.005610461216317904], Loss: 2.057403, Acc:0.798319, Semantic loss: 0.779958, BCE loss: 0.530899, SB loss: 0.746547
2023-10-30 12:19:05,442 Epoch: [229/484] Iter:[180/495], Time: 0.38, lr: [0.0056100606423522634], Loss: 2.046654, Acc:0.796641, Semantic loss: 0.774708, BCE loss: 0.527473, SB loss: 0.744473
2023-10-30 12:19:09,143 Epoch: [229/484] Iter:[190/495], Time: 0.38, lr: [0.0056096600652085875], Loss: 2.042499, Acc:0.797040, Semantic loss: 0.772161, BCE loss: 0.525868, SB loss: 0.744471
2023-10-30 12:19:12,837 Epoch: [229/484] Iter:[200/495], Time: 0.38, lr: [0.005609259484886596], Loss: 2.043549, Acc:0.796869, Semantic loss: 0.773656, BCE loss: 0.525599, SB loss: 0.744294
2023-10-30 12:19:16,553 Epoch: [229/484] Iter:[210/495], Time: 0.38, lr: [0.005608858901386016], Loss: 2.048573, Acc:0.797327, Semantic loss: 0.775131, BCE loss: 0.528659, SB loss: 0.744783
2023-10-30 12:19:20,134 Epoch: [229/484] Iter:[220/495], Time: 0.38, lr: [0.005608458314706566], Loss: 2.047070, Acc:0.798134, Semantic loss: 0.773505, BCE loss: 0.529275, SB loss: 0.744290
2023-10-30 12:19:23,813 Epoch: [229/484] Iter:[230/495], Time: 0.38, lr: [0.00560805772484797], Loss: 2.048202, Acc:0.799148, Semantic loss: 0.775305, BCE loss: 0.527703, SB loss: 0.745194
2023-10-30 12:19:27,423 Epoch: [229/484] Iter:[240/495], Time: 0.38, lr: [0.005607657131809951], Loss: 2.047117, Acc:0.798265, Semantic loss: 0.774193, BCE loss: 0.528115, SB loss: 0.744809
2023-10-30 12:19:31,126 Epoch: [229/484] Iter:[250/495], Time: 0.38, lr: [0.005607256535592231], Loss: 2.037050, Acc:0.798721, Semantic loss: 0.769117, BCE loss: 0.526314, SB loss: 0.741620
2023-10-30 12:19:34,744 Epoch: [229/484] Iter:[260/495], Time: 0.37, lr: [0.0056068559361945325], Loss: 2.035139, Acc:0.797899, Semantic loss: 0.768182, BCE loss: 0.527193, SB loss: 0.739763
2023-10-30 12:19:38,392 Epoch: [229/484] Iter:[270/495], Time: 0.37, lr: [0.005606455333616578], Loss: 2.035885, Acc:0.797389, Semantic loss: 0.768999, BCE loss: 0.526423, SB loss: 0.740462
2023-10-30 12:19:42,078 Epoch: [229/484] Iter:[280/495], Time: 0.37, lr: [0.00560605472785809], Loss: 2.034752, Acc:0.797758, Semantic loss: 0.768689, BCE loss: 0.526662, SB loss: 0.739400
2023-10-30 12:19:45,780 Epoch: [229/484] Iter:[290/495], Time: 0.37, lr: [0.00560565411891879], Loss: 2.036387, Acc:0.798100, Semantic loss: 0.768679, BCE loss: 0.528650, SB loss: 0.739059
2023-10-30 12:19:49,414 Epoch: [229/484] Iter:[300/495], Time: 0.37, lr: [0.0056052535067983985], Loss: 2.032854, Acc:0.797699, Semantic loss: 0.767162, BCE loss: 0.527552, SB loss: 0.738140
2023-10-30 12:19:53,088 Epoch: [229/484] Iter:[310/495], Time: 0.37, lr: [0.005604852891496641], Loss: 2.033324, Acc:0.797482, Semantic loss: 0.768172, BCE loss: 0.526863, SB loss: 0.738289
2023-10-30 12:19:56,685 Epoch: [229/484] Iter:[320/495], Time: 0.37, lr: [0.005604452273013236], Loss: 2.033196, Acc:0.797395, Semantic loss: 0.767337, BCE loss: 0.526311, SB loss: 0.739548
2023-10-30 12:20:00,507 Epoch: [229/484] Iter:[330/495], Time: 0.37, lr: [0.00560405165134791], Loss: 2.031268, Acc:0.798434, Semantic loss: 0.765946, BCE loss: 0.526979, SB loss: 0.738343
2023-10-30 12:20:04,114 Epoch: [229/484] Iter:[340/495], Time: 0.37, lr: [0.00560365102650038], Loss: 2.035452, Acc:0.799366, Semantic loss: 0.766722, BCE loss: 0.529576, SB loss: 0.739154
2023-10-30 12:20:07,704 Epoch: [229/484] Iter:[350/495], Time: 0.37, lr: [0.005603250398470373], Loss: 2.032598, Acc:0.799372, Semantic loss: 0.766098, BCE loss: 0.527891, SB loss: 0.738608
2023-10-30 12:20:11,312 Epoch: [229/484] Iter:[360/495], Time: 0.37, lr: [0.005602849767257607], Loss: 2.033423, Acc:0.798818, Semantic loss: 0.767179, BCE loss: 0.527088, SB loss: 0.739157
2023-10-30 12:20:14,915 Epoch: [229/484] Iter:[370/495], Time: 0.37, lr: [0.005602449132861806], Loss: 2.031845, Acc:0.799222, Semantic loss: 0.766838, BCE loss: 0.525643, SB loss: 0.739364
2023-10-30 12:20:18,718 Epoch: [229/484] Iter:[380/495], Time: 0.37, lr: [0.005602048495282691], Loss: 2.029492, Acc:0.799582, Semantic loss: 0.765325, BCE loss: 0.525609, SB loss: 0.738558
2023-10-30 12:20:22,450 Epoch: [229/484] Iter:[390/495], Time: 0.37, lr: [0.005601647854519983], Loss: 2.028771, Acc:0.799658, Semantic loss: 0.764427, BCE loss: 0.526320, SB loss: 0.738024
2023-10-30 12:20:26,049 Epoch: [229/484] Iter:[400/495], Time: 0.37, lr: [0.005601247210573404], Loss: 2.030865, Acc:0.799474, Semantic loss: 0.764608, BCE loss: 0.528447, SB loss: 0.737810
2023-10-30 12:20:29,748 Epoch: [229/484] Iter:[410/495], Time: 0.37, lr: [0.0056008465634426775], Loss: 2.034071, Acc:0.799829, Semantic loss: 0.766983, BCE loss: 0.528072, SB loss: 0.739017
2023-10-30 12:20:33,420 Epoch: [229/484] Iter:[420/495], Time: 0.37, lr: [0.005600445913127522], Loss: 2.036504, Acc:0.799455, Semantic loss: 0.768310, BCE loss: 0.528754, SB loss: 0.739440
2023-10-30 12:20:37,036 Epoch: [229/484] Iter:[430/495], Time: 0.37, lr: [0.005600045259627662], Loss: 2.034990, Acc:0.799007, Semantic loss: 0.767208, BCE loss: 0.528956, SB loss: 0.738826
2023-10-30 12:20:40,680 Epoch: [229/484] Iter:[440/495], Time: 0.37, lr: [0.005599644602942817], Loss: 2.036312, Acc:0.798933, Semantic loss: 0.767594, BCE loss: 0.529687, SB loss: 0.739031
2023-10-30 12:20:44,350 Epoch: [229/484] Iter:[450/495], Time: 0.37, lr: [0.0055992439430727105], Loss: 2.035346, Acc:0.799318, Semantic loss: 0.767006, BCE loss: 0.529167, SB loss: 0.739173
2023-10-30 12:20:48,018 Epoch: [229/484] Iter:[460/495], Time: 0.37, lr: [0.005598843280017062], Loss: 2.036934, Acc:0.798648, Semantic loss: 0.767835, BCE loss: 0.528828, SB loss: 0.740271
2023-10-30 12:20:51,767 Epoch: [229/484] Iter:[470/495], Time: 0.37, lr: [0.005598442613775593], Loss: 2.038401, Acc:0.798317, Semantic loss: 0.767924, BCE loss: 0.530254, SB loss: 0.740223
2023-10-30 12:20:55,414 Epoch: [229/484] Iter:[480/495], Time: 0.37, lr: [0.005598041944348025], Loss: 2.044830, Acc:0.798145, Semantic loss: 0.772410, BCE loss: 0.530730, SB loss: 0.741690
2023-10-30 12:20:58,876 Epoch: [229/484] Iter:[490/495], Time: 0.37, lr: [0.005597641271734081], Loss: 2.045363, Acc:0.797618, Semantic loss: 0.772207, BCE loss: 0.531396, SB loss: 0.741760
2023-10-30 12:21:00,274 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:21:00,510 Loss: 2.050, MeanIU:  0.6827, Best_mIoU:  0.7151
2023-10-30 12:21:00,511 [0.97099605 0.78754552 0.90122084 0.45614793 0.55066488 0.56533591
 0.6307681  0.70890062 0.91036021 0.57486451 0.92918359 0.7229373
 0.51372398 0.90942662 0.55586203 0.69275918 0.46628161 0.4185126
 0.70579489]
2023-10-30 12:21:02,560 Epoch: [230/484] Iter:[0/495], Time: 2.01, lr: [0.005597440934232129], Loss: 2.012588, Acc:0.810169, Semantic loss: 0.859667, BCE loss: 0.429772, SB loss: 0.723149
2023-10-30 12:21:06,631 Epoch: [230/484] Iter:[10/495], Time: 0.55, lr: [0.005597040256838095], Loss: 2.333848, Acc:0.780612, Semantic loss: 0.950298, BCE loss: 0.592925, SB loss: 0.790625
2023-10-30 12:21:10,255 Epoch: [230/484] Iter:[20/495], Time: 0.46, lr: [0.005596639576256988], Loss: 2.257585, Acc:0.803399, Semantic loss: 0.886920, BCE loss: 0.596849, SB loss: 0.773815
2023-10-30 12:21:13,876 Epoch: [230/484] Iter:[30/495], Time: 0.43, lr: [0.0055962388924885266], Loss: 2.198803, Acc:0.799422, Semantic loss: 0.846437, BCE loss: 0.589897, SB loss: 0.762469
2023-10-30 12:21:17,565 Epoch: [230/484] Iter:[40/495], Time: 0.42, lr: [0.0055958382055324345], Loss: 2.190215, Acc:0.808816, Semantic loss: 0.827098, BCE loss: 0.597959, SB loss: 0.765158
2023-10-30 12:21:21,201 Epoch: [230/484] Iter:[50/495], Time: 0.40, lr: [0.00559543751538843], Loss: 2.164711, Acc:0.810966, Semantic loss: 0.831025, BCE loss: 0.577309, SB loss: 0.756377
2023-10-30 12:21:24,927 Epoch: [230/484] Iter:[60/495], Time: 0.40, lr: [0.005595036822056234], Loss: 2.154029, Acc:0.810549, Semantic loss: 0.817169, BCE loss: 0.583377, SB loss: 0.753483
2023-10-30 12:21:28,653 Epoch: [230/484] Iter:[70/495], Time: 0.40, lr: [0.005594636125535571], Loss: 2.133186, Acc:0.813072, Semantic loss: 0.804282, BCE loss: 0.576749, SB loss: 0.752155
2023-10-30 12:21:32,307 Epoch: [230/484] Iter:[80/495], Time: 0.39, lr: [0.0055942354258261585], Loss: 2.111826, Acc:0.810037, Semantic loss: 0.793368, BCE loss: 0.570962, SB loss: 0.747496
2023-10-30 12:21:35,998 Epoch: [230/484] Iter:[90/495], Time: 0.39, lr: [0.005593834722927718], Loss: 2.096697, Acc:0.809337, Semantic loss: 0.781677, BCE loss: 0.570007, SB loss: 0.745012
2023-10-30 12:21:39,612 Epoch: [230/484] Iter:[100/495], Time: 0.39, lr: [0.0055934340168399726], Loss: 2.103940, Acc:0.807538, Semantic loss: 0.785735, BCE loss: 0.569177, SB loss: 0.749028
2023-10-30 12:21:43,331 Epoch: [230/484] Iter:[110/495], Time: 0.39, lr: [0.00559303330756264], Loss: 2.099696, Acc:0.804610, Semantic loss: 0.785222, BCE loss: 0.565811, SB loss: 0.748663
2023-10-30 12:21:47,018 Epoch: [230/484] Iter:[120/495], Time: 0.38, lr: [0.005592632595095444], Loss: 2.097695, Acc:0.803354, Semantic loss: 0.783926, BCE loss: 0.565443, SB loss: 0.748326
2023-10-30 12:21:50,755 Epoch: [230/484] Iter:[130/495], Time: 0.38, lr: [0.005592231879438102], Loss: 2.107789, Acc:0.806188, Semantic loss: 0.785900, BCE loss: 0.570742, SB loss: 0.751147
2023-10-30 12:21:54,441 Epoch: [230/484] Iter:[140/495], Time: 0.38, lr: [0.005591831160590335], Loss: 2.113812, Acc:0.805112, Semantic loss: 0.793934, BCE loss: 0.567327, SB loss: 0.752551
2023-10-30 12:21:58,143 Epoch: [230/484] Iter:[150/495], Time: 0.38, lr: [0.0055914304385518655], Loss: 2.110048, Acc:0.805391, Semantic loss: 0.791563, BCE loss: 0.567948, SB loss: 0.750536
2023-10-30 12:22:01,878 Epoch: [230/484] Iter:[160/495], Time: 0.38, lr: [0.0055910297133224115], Loss: 2.101758, Acc:0.806778, Semantic loss: 0.786424, BCE loss: 0.564747, SB loss: 0.750587
2023-10-30 12:22:05,484 Epoch: [230/484] Iter:[170/495], Time: 0.38, lr: [0.005590628984901698], Loss: 2.095160, Acc:0.805691, Semantic loss: 0.784355, BCE loss: 0.560798, SB loss: 0.750006
2023-10-30 12:22:09,159 Epoch: [230/484] Iter:[180/495], Time: 0.38, lr: [0.005590228253289441], Loss: 2.086349, Acc:0.805156, Semantic loss: 0.781446, BCE loss: 0.556045, SB loss: 0.748858
2023-10-30 12:22:12,835 Epoch: [230/484] Iter:[190/495], Time: 0.38, lr: [0.0055898275184853635], Loss: 2.079569, Acc:0.804747, Semantic loss: 0.777786, BCE loss: 0.553653, SB loss: 0.748131
2023-10-30 12:22:16,568 Epoch: [230/484] Iter:[200/495], Time: 0.38, lr: [0.005589426780489183], Loss: 2.079024, Acc:0.805449, Semantic loss: 0.776332, BCE loss: 0.556605, SB loss: 0.746087
2023-10-30 12:22:20,290 Epoch: [230/484] Iter:[210/495], Time: 0.38, lr: [0.005589026039300623], Loss: 2.076170, Acc:0.806392, Semantic loss: 0.775466, BCE loss: 0.555485, SB loss: 0.745219
2023-10-30 12:22:23,871 Epoch: [230/484] Iter:[220/495], Time: 0.38, lr: [0.0055886252949194], Loss: 2.072358, Acc:0.807588, Semantic loss: 0.773506, BCE loss: 0.555805, SB loss: 0.743047
2023-10-30 12:22:27,501 Epoch: [230/484] Iter:[230/495], Time: 0.38, lr: [0.005588224547345238], Loss: 2.071068, Acc:0.805088, Semantic loss: 0.773587, BCE loss: 0.552878, SB loss: 0.744603
2023-10-30 12:22:31,160 Epoch: [230/484] Iter:[240/495], Time: 0.38, lr: [0.0055878237965778545], Loss: 2.069852, Acc:0.804196, Semantic loss: 0.774730, BCE loss: 0.550305, SB loss: 0.744817
2023-10-30 12:22:34,912 Epoch: [230/484] Iter:[250/495], Time: 0.38, lr: [0.005587423042616972], Loss: 2.070334, Acc:0.804192, Semantic loss: 0.775152, BCE loss: 0.549607, SB loss: 0.745574
2023-10-30 12:22:38,586 Epoch: [230/484] Iter:[260/495], Time: 0.38, lr: [0.005587022285462308], Loss: 2.064821, Acc:0.805320, Semantic loss: 0.773992, BCE loss: 0.546448, SB loss: 0.744381
2023-10-30 12:22:42,300 Epoch: [230/484] Iter:[270/495], Time: 0.38, lr: [0.0055866215251135845], Loss: 2.071699, Acc:0.806166, Semantic loss: 0.776792, BCE loss: 0.548285, SB loss: 0.746622
2023-10-30 12:22:45,954 Epoch: [230/484] Iter:[280/495], Time: 0.38, lr: [0.0055862207615705204], Loss: 2.077543, Acc:0.806413, Semantic loss: 0.780532, BCE loss: 0.549207, SB loss: 0.747804
2023-10-30 12:22:49,630 Epoch: [230/484] Iter:[290/495], Time: 0.37, lr: [0.005585819994832836], Loss: 2.075239, Acc:0.806179, Semantic loss: 0.779643, BCE loss: 0.548552, SB loss: 0.747043
2023-10-30 12:22:53,324 Epoch: [230/484] Iter:[300/495], Time: 0.37, lr: [0.00558541922490025], Loss: 2.072478, Acc:0.805642, Semantic loss: 0.778499, BCE loss: 0.547544, SB loss: 0.746435
2023-10-30 12:22:56,962 Epoch: [230/484] Iter:[310/495], Time: 0.37, lr: [0.005585018451772484], Loss: 2.070810, Acc:0.805187, Semantic loss: 0.778030, BCE loss: 0.546864, SB loss: 0.745916
2023-10-30 12:23:00,607 Epoch: [230/484] Iter:[320/495], Time: 0.37, lr: [0.005584617675449255], Loss: 2.068961, Acc:0.804212, Semantic loss: 0.777447, BCE loss: 0.545552, SB loss: 0.745962
2023-10-30 12:23:04,265 Epoch: [230/484] Iter:[330/495], Time: 0.37, lr: [0.005584216895930288], Loss: 2.069778, Acc:0.804247, Semantic loss: 0.777438, BCE loss: 0.545396, SB loss: 0.746943
2023-10-30 12:23:07,900 Epoch: [230/484] Iter:[340/495], Time: 0.37, lr: [0.005583816113215297], Loss: 2.069684, Acc:0.805081, Semantic loss: 0.778175, BCE loss: 0.544848, SB loss: 0.746661
2023-10-30 12:23:11,472 Epoch: [230/484] Iter:[350/495], Time: 0.37, lr: [0.005583415327304005], Loss: 2.068342, Acc:0.804897, Semantic loss: 0.777554, BCE loss: 0.544393, SB loss: 0.746394
2023-10-30 12:23:15,097 Epoch: [230/484] Iter:[360/495], Time: 0.37, lr: [0.005583014538196131], Loss: 2.066578, Acc:0.803904, Semantic loss: 0.777825, BCE loss: 0.542804, SB loss: 0.745949
2023-10-30 12:23:18,759 Epoch: [230/484] Iter:[370/495], Time: 0.37, lr: [0.005582613745891393], Loss: 2.065998, Acc:0.803776, Semantic loss: 0.777271, BCE loss: 0.543424, SB loss: 0.745303
2023-10-30 12:23:22,420 Epoch: [230/484] Iter:[380/495], Time: 0.37, lr: [0.005582212950389511], Loss: 2.061628, Acc:0.803550, Semantic loss: 0.774725, BCE loss: 0.542791, SB loss: 0.744112
2023-10-30 12:23:26,067 Epoch: [230/484] Iter:[390/495], Time: 0.37, lr: [0.005581812151690206], Loss: 2.065901, Acc:0.804165, Semantic loss: 0.776970, BCE loss: 0.544041, SB loss: 0.744891
2023-10-30 12:23:29,750 Epoch: [230/484] Iter:[400/495], Time: 0.37, lr: [0.005581411349793195], Loss: 2.070439, Acc:0.802952, Semantic loss: 0.781568, BCE loss: 0.542687, SB loss: 0.746185
2023-10-30 12:23:33,385 Epoch: [230/484] Iter:[410/495], Time: 0.37, lr: [0.0055810105446982], Loss: 2.072021, Acc:0.802603, Semantic loss: 0.781702, BCE loss: 0.543966, SB loss: 0.746353
2023-10-30 12:23:37,210 Epoch: [230/484] Iter:[420/495], Time: 0.37, lr: [0.005580609736404939], Loss: 2.067565, Acc:0.802752, Semantic loss: 0.779014, BCE loss: 0.542670, SB loss: 0.745880
2023-10-30 12:23:40,893 Epoch: [230/484] Iter:[430/495], Time: 0.37, lr: [0.005580208924913132], Loss: 2.069472, Acc:0.803083, Semantic loss: 0.779790, BCE loss: 0.543420, SB loss: 0.746262
2023-10-30 12:23:44,517 Epoch: [230/484] Iter:[440/495], Time: 0.37, lr: [0.005579808110222496], Loss: 2.068870, Acc:0.803064, Semantic loss: 0.779396, BCE loss: 0.542503, SB loss: 0.746971
2023-10-30 12:23:48,231 Epoch: [230/484] Iter:[450/495], Time: 0.37, lr: [0.005579407292332752], Loss: 2.067011, Acc:0.803747, Semantic loss: 0.778557, BCE loss: 0.541834, SB loss: 0.746620
2023-10-30 12:23:51,925 Epoch: [230/484] Iter:[460/495], Time: 0.37, lr: [0.005579006471243618], Loss: 2.071545, Acc:0.803155, Semantic loss: 0.781280, BCE loss: 0.543071, SB loss: 0.747194
2023-10-30 12:23:55,655 Epoch: [230/484] Iter:[470/495], Time: 0.37, lr: [0.005578605646954816], Loss: 2.068375, Acc:0.803365, Semantic loss: 0.779546, BCE loss: 0.542417, SB loss: 0.746413
2023-10-30 12:23:59,363 Epoch: [230/484] Iter:[480/495], Time: 0.37, lr: [0.00557820481946606], Loss: 2.067756, Acc:0.803640, Semantic loss: 0.779309, BCE loss: 0.541977, SB loss: 0.746469
2023-10-30 12:24:02,916 Epoch: [230/484] Iter:[490/495], Time: 0.37, lr: [0.005577803988777073], Loss: 2.072637, Acc:0.803686, Semantic loss: 0.781626, BCE loss: 0.543043, SB loss: 0.747968
2023-10-30 12:26:52,740 0 [9.35193907e-01 6.28980863e-01 8.26302657e-01 1.34847421e-01
 2.23252036e-01 4.06620693e-01 4.02143568e-01 5.80047523e-01
 8.80427488e-01 4.21005956e-01 8.51308782e-01 6.14343589e-01
 4.13151112e-02 8.08558974e-01 8.92630908e-04 7.64726295e-02
 7.72527336e-02 4.28240027e-02 5.78018227e-01] 0.4489373047767754
2023-10-30 12:26:52,740 1 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374] 0.6970403233368915
2023-10-30 12:26:52,744 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:26:52,980 Loss: 2.082, MeanIU:  0.6970, Best_mIoU:  0.7151
2023-10-30 12:26:52,980 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374]
2023-10-30 12:26:54,908 Epoch: [231/484] Iter:[0/495], Time: 1.89, lr: [0.005577603572232405], Loss: 2.185208, Acc:0.851619, Semantic loss: 0.811421, BCE loss: 0.598730, SB loss: 0.775058
2023-10-30 12:26:58,729 Epoch: [231/484] Iter:[10/495], Time: 0.52, lr: [0.005577202736742543], Loss: 1.892056, Acc:0.773137, Semantic loss: 0.703096, BCE loss: 0.487735, SB loss: 0.701225
2023-10-30 12:27:02,135 Epoch: [231/484] Iter:[20/495], Time: 0.43, lr: [0.005576801898051745], Loss: 1.951976, Acc:0.761578, Semantic loss: 0.754079, BCE loss: 0.478342, SB loss: 0.719555
2023-10-30 12:27:05,607 Epoch: [231/484] Iter:[30/495], Time: 0.41, lr: [0.005576401056159732], Loss: 2.013385, Acc:0.765848, Semantic loss: 0.770511, BCE loss: 0.505487, SB loss: 0.737387
2023-10-30 12:27:09,069 Epoch: [231/484] Iter:[40/495], Time: 0.39, lr: [0.005576000211066221], Loss: 2.007651, Acc:0.782874, Semantic loss: 0.757611, BCE loss: 0.509387, SB loss: 0.740654
2023-10-30 12:27:12,540 Epoch: [231/484] Iter:[50/495], Time: 0.38, lr: [0.005575599362770931], Loss: 2.019387, Acc:0.785539, Semantic loss: 0.764741, BCE loss: 0.513610, SB loss: 0.741036
2023-10-30 12:27:16,054 Epoch: [231/484] Iter:[60/495], Time: 0.38, lr: [0.005575198511273581], Loss: 1.991624, Acc:0.788703, Semantic loss: 0.747123, BCE loss: 0.514310, SB loss: 0.730191
2023-10-30 12:27:19,535 Epoch: [231/484] Iter:[70/495], Time: 0.37, lr: [0.005574797656573889], Loss: 2.024898, Acc:0.790015, Semantic loss: 0.766232, BCE loss: 0.515300, SB loss: 0.743367
2023-10-30 12:27:23,037 Epoch: [231/484] Iter:[80/495], Time: 0.37, lr: [0.005574396798671575], Loss: 2.001550, Acc:0.788080, Semantic loss: 0.755281, BCE loss: 0.507841, SB loss: 0.738427
2023-10-30 12:27:26,525 Epoch: [231/484] Iter:[90/495], Time: 0.37, lr: [0.005573995937566356], Loss: 2.002059, Acc:0.790040, Semantic loss: 0.754537, BCE loss: 0.509130, SB loss: 0.738392
2023-10-30 12:27:30,048 Epoch: [231/484] Iter:[100/495], Time: 0.37, lr: [0.005573595073257952], Loss: 2.008947, Acc:0.796066, Semantic loss: 0.756862, BCE loss: 0.516507, SB loss: 0.735577
2023-10-30 12:27:33,621 Epoch: [231/484] Iter:[110/495], Time: 0.37, lr: [0.005573194205746079], Loss: 2.013737, Acc:0.794886, Semantic loss: 0.758284, BCE loss: 0.519152, SB loss: 0.736302
2023-10-30 12:27:37,215 Epoch: [231/484] Iter:[120/495], Time: 0.37, lr: [0.005572793335030457], Loss: 2.011131, Acc:0.794011, Semantic loss: 0.758196, BCE loss: 0.516764, SB loss: 0.736171
2023-10-30 12:27:40,896 Epoch: [231/484] Iter:[130/495], Time: 0.37, lr: [0.005572392461110806], Loss: 2.006047, Acc:0.793130, Semantic loss: 0.752191, BCE loss: 0.520307, SB loss: 0.733548
2023-10-30 12:27:44,409 Epoch: [231/484] Iter:[140/495], Time: 0.36, lr: [0.00557199158398684], Loss: 2.015700, Acc:0.794978, Semantic loss: 0.754570, BCE loss: 0.525149, SB loss: 0.735980
2023-10-30 12:27:47,960 Epoch: [231/484] Iter:[150/495], Time: 0.36, lr: [0.0055715907036582805], Loss: 2.018673, Acc:0.794694, Semantic loss: 0.758525, BCE loss: 0.525294, SB loss: 0.734854
2023-10-30 12:27:51,565 Epoch: [231/484] Iter:[160/495], Time: 0.36, lr: [0.0055711898201248455], Loss: 2.016631, Acc:0.795159, Semantic loss: 0.757321, BCE loss: 0.524492, SB loss: 0.734818
2023-10-30 12:27:55,080 Epoch: [231/484] Iter:[170/495], Time: 0.36, lr: [0.005570788933386253], Loss: 2.018761, Acc:0.795693, Semantic loss: 0.762577, BCE loss: 0.521395, SB loss: 0.734789
2023-10-30 12:27:58,705 Epoch: [231/484] Iter:[180/495], Time: 0.36, lr: [0.005570388043442219], Loss: 2.023117, Acc:0.795418, Semantic loss: 0.764202, BCE loss: 0.523010, SB loss: 0.735905
2023-10-30 12:28:02,273 Epoch: [231/484] Iter:[190/495], Time: 0.36, lr: [0.0055699871502924644], Loss: 2.026784, Acc:0.794056, Semantic loss: 0.765172, BCE loss: 0.524971, SB loss: 0.736641
2023-10-30 12:28:05,912 Epoch: [231/484] Iter:[200/495], Time: 0.36, lr: [0.005569586253936705], Loss: 2.025422, Acc:0.792922, Semantic loss: 0.762780, BCE loss: 0.525242, SB loss: 0.737400
2023-10-30 12:28:09,564 Epoch: [231/484] Iter:[210/495], Time: 0.36, lr: [0.00556918535437466], Loss: 2.027356, Acc:0.792928, Semantic loss: 0.766569, BCE loss: 0.523046, SB loss: 0.737741
2023-10-30 12:28:13,166 Epoch: [231/484] Iter:[220/495], Time: 0.36, lr: [0.005568784451606046], Loss: 2.023993, Acc:0.793063, Semantic loss: 0.762841, BCE loss: 0.524820, SB loss: 0.736332
2023-10-30 12:28:16,704 Epoch: [231/484] Iter:[230/495], Time: 0.36, lr: [0.005568383545630583], Loss: 2.019859, Acc:0.792998, Semantic loss: 0.759931, BCE loss: 0.524905, SB loss: 0.735023
2023-10-30 12:28:20,324 Epoch: [231/484] Iter:[240/495], Time: 0.36, lr: [0.005567982636447988], Loss: 2.025119, Acc:0.794007, Semantic loss: 0.762318, BCE loss: 0.527027, SB loss: 0.735775
2023-10-30 12:28:23,887 Epoch: [231/484] Iter:[250/495], Time: 0.36, lr: [0.005567581724057979], Loss: 2.024034, Acc:0.794687, Semantic loss: 0.761277, BCE loss: 0.527201, SB loss: 0.735557
2023-10-30 12:28:27,513 Epoch: [231/484] Iter:[260/495], Time: 0.36, lr: [0.0055671808084602715], Loss: 2.024823, Acc:0.794759, Semantic loss: 0.761923, BCE loss: 0.528159, SB loss: 0.734741
2023-10-30 12:28:31,214 Epoch: [231/484] Iter:[270/495], Time: 0.36, lr: [0.005566779889654586], Loss: 2.020998, Acc:0.795506, Semantic loss: 0.758723, BCE loss: 0.528403, SB loss: 0.733872
2023-10-30 12:28:34,808 Epoch: [231/484] Iter:[280/495], Time: 0.36, lr: [0.005566378967640637], Loss: 2.021394, Acc:0.795602, Semantic loss: 0.759567, BCE loss: 0.526764, SB loss: 0.735062
2023-10-30 12:28:38,395 Epoch: [231/484] Iter:[290/495], Time: 0.36, lr: [0.005565978042418146], Loss: 2.022052, Acc:0.793428, Semantic loss: 0.761347, BCE loss: 0.525214, SB loss: 0.735492
2023-10-30 12:28:42,039 Epoch: [231/484] Iter:[300/495], Time: 0.36, lr: [0.005565577113986827], Loss: 2.030870, Acc:0.792572, Semantic loss: 0.766652, BCE loss: 0.526890, SB loss: 0.737328
2023-10-30 12:28:45,578 Epoch: [231/484] Iter:[310/495], Time: 0.36, lr: [0.0055651761823464], Loss: 2.031396, Acc:0.792410, Semantic loss: 0.767612, BCE loss: 0.525998, SB loss: 0.737786
2023-10-30 12:28:49,316 Epoch: [231/484] Iter:[320/495], Time: 0.36, lr: [0.005564775247496581], Loss: 2.029410, Acc:0.791796, Semantic loss: 0.766072, BCE loss: 0.526669, SB loss: 0.736668
2023-10-30 12:28:52,895 Epoch: [231/484] Iter:[330/495], Time: 0.36, lr: [0.005564374309437088], Loss: 2.031622, Acc:0.793842, Semantic loss: 0.766926, BCE loss: 0.527970, SB loss: 0.736726
2023-10-30 12:28:56,540 Epoch: [231/484] Iter:[340/495], Time: 0.36, lr: [0.005563973368167639], Loss: 2.034374, Acc:0.794110, Semantic loss: 0.768643, BCE loss: 0.528526, SB loss: 0.737205
2023-10-30 12:29:00,243 Epoch: [231/484] Iter:[350/495], Time: 0.36, lr: [0.0055635724236879494], Loss: 2.031902, Acc:0.794324, Semantic loss: 0.766599, BCE loss: 0.528355, SB loss: 0.736947
2023-10-30 12:29:03,980 Epoch: [231/484] Iter:[360/495], Time: 0.36, lr: [0.005563171475997737], Loss: 2.033530, Acc:0.794190, Semantic loss: 0.767618, BCE loss: 0.528539, SB loss: 0.737373
2023-10-30 12:29:07,612 Epoch: [231/484] Iter:[370/495], Time: 0.36, lr: [0.0055627705250967194], Loss: 2.035862, Acc:0.794382, Semantic loss: 0.768151, BCE loss: 0.529557, SB loss: 0.738154
2023-10-30 12:29:11,272 Epoch: [231/484] Iter:[380/495], Time: 0.36, lr: [0.005562369570984613], Loss: 2.038165, Acc:0.795112, Semantic loss: 0.770417, BCE loss: 0.528870, SB loss: 0.738878
2023-10-30 12:29:14,951 Epoch: [231/484] Iter:[390/495], Time: 0.36, lr: [0.005561968613661138], Loss: 2.037215, Acc:0.795207, Semantic loss: 0.769892, BCE loss: 0.528598, SB loss: 0.738725
2023-10-30 12:29:18,564 Epoch: [231/484] Iter:[400/495], Time: 0.36, lr: [0.005561567653126008], Loss: 2.038426, Acc:0.795472, Semantic loss: 0.770667, BCE loss: 0.528604, SB loss: 0.739156
2023-10-30 12:29:22,198 Epoch: [231/484] Iter:[410/495], Time: 0.36, lr: [0.005561166689378941], Loss: 2.036478, Acc:0.796306, Semantic loss: 0.769601, BCE loss: 0.527871, SB loss: 0.739006
2023-10-30 12:29:25,844 Epoch: [231/484] Iter:[420/495], Time: 0.36, lr: [0.005560765722419655], Loss: 2.036844, Acc:0.795051, Semantic loss: 0.768316, BCE loss: 0.529165, SB loss: 0.739363
2023-10-30 12:29:29,492 Epoch: [231/484] Iter:[430/495], Time: 0.36, lr: [0.0055603647522478655], Loss: 2.035838, Acc:0.795836, Semantic loss: 0.766785, BCE loss: 0.530179, SB loss: 0.738873
2023-10-30 12:29:33,184 Epoch: [231/484] Iter:[440/495], Time: 0.36, lr: [0.005559963778863288], Loss: 2.037123, Acc:0.795577, Semantic loss: 0.767598, BCE loss: 0.530106, SB loss: 0.739420
2023-10-30 12:29:36,887 Epoch: [231/484] Iter:[450/495], Time: 0.36, lr: [0.005559562802265643], Loss: 2.038322, Acc:0.794986, Semantic loss: 0.768896, BCE loss: 0.529733, SB loss: 0.739693
2023-10-30 12:29:40,584 Epoch: [231/484] Iter:[460/495], Time: 0.36, lr: [0.005559161822454645], Loss: 2.039631, Acc:0.795583, Semantic loss: 0.768673, BCE loss: 0.531195, SB loss: 0.739763
2023-10-30 12:29:44,199 Epoch: [231/484] Iter:[470/495], Time: 0.36, lr: [0.005558760839430012], Loss: 2.037813, Acc:0.795502, Semantic loss: 0.767641, BCE loss: 0.530988, SB loss: 0.739184
2023-10-30 12:29:47,835 Epoch: [231/484] Iter:[480/495], Time: 0.36, lr: [0.005558359853191458], Loss: 2.036705, Acc:0.795737, Semantic loss: 0.767533, BCE loss: 0.530350, SB loss: 0.738822
2023-10-30 12:29:51,360 Epoch: [231/484] Iter:[490/495], Time: 0.36, lr: [0.005557958863738702], Loss: 2.034001, Acc:0.795701, Semantic loss: 0.766095, BCE loss: 0.530089, SB loss: 0.737818
2023-10-30 12:29:52,767 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:29:53,004 Loss: 2.082, MeanIU:  0.6970, Best_mIoU:  0.7151
2023-10-30 12:29:53,004 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374]
2023-10-30 12:29:54,993 Epoch: [232/484] Iter:[0/495], Time: 1.95, lr: [0.005557758367806911], Loss: 2.568745, Acc:0.819425, Semantic loss: 1.258451, BCE loss: 0.384578, SB loss: 0.925717
2023-10-30 12:29:59,025 Epoch: [232/484] Iter:[10/495], Time: 0.54, lr: [0.00555735737353232], Loss: 2.033813, Acc:0.806538, Semantic loss: 0.776118, BCE loss: 0.525106, SB loss: 0.732588
2023-10-30 12:30:02,785 Epoch: [232/484] Iter:[20/495], Time: 0.46, lr: [0.005556956376042817], Loss: 2.081795, Acc:0.808058, Semantic loss: 0.799109, BCE loss: 0.541805, SB loss: 0.740881
2023-10-30 12:30:06,503 Epoch: [232/484] Iter:[30/495], Time: 0.43, lr: [0.0055565553753381194], Loss: 2.051013, Acc:0.820106, Semantic loss: 0.783460, BCE loss: 0.535567, SB loss: 0.731985
2023-10-30 12:30:10,150 Epoch: [232/484] Iter:[40/495], Time: 0.42, lr: [0.005556154371417943], Loss: 2.072518, Acc:0.813217, Semantic loss: 0.794841, BCE loss: 0.534054, SB loss: 0.743623
2023-10-30 12:30:13,830 Epoch: [232/484] Iter:[50/495], Time: 0.41, lr: [0.005555753364282006], Loss: 2.063983, Acc:0.809626, Semantic loss: 0.790743, BCE loss: 0.534515, SB loss: 0.738726
2023-10-30 12:30:17,412 Epoch: [232/484] Iter:[60/495], Time: 0.40, lr: [0.005555352353930023], Loss: 2.073674, Acc:0.807402, Semantic loss: 0.794893, BCE loss: 0.539020, SB loss: 0.739761
2023-10-30 12:30:21,041 Epoch: [232/484] Iter:[70/495], Time: 0.39, lr: [0.00555495134036171], Loss: 2.062973, Acc:0.805389, Semantic loss: 0.785659, BCE loss: 0.536263, SB loss: 0.741051
2023-10-30 12:30:24,684 Epoch: [232/484] Iter:[80/495], Time: 0.39, lr: [0.005554550323576784], Loss: 2.049726, Acc:0.806604, Semantic loss: 0.774352, BCE loss: 0.533604, SB loss: 0.741770
2023-10-30 12:30:28,229 Epoch: [232/484] Iter:[90/495], Time: 0.39, lr: [0.005554149303574962], Loss: 2.039828, Acc:0.804613, Semantic loss: 0.768175, BCE loss: 0.534079, SB loss: 0.737574
2023-10-30 12:30:31,868 Epoch: [232/484] Iter:[100/495], Time: 0.38, lr: [0.005553748280355957], Loss: 2.043487, Acc:0.804561, Semantic loss: 0.769479, BCE loss: 0.534768, SB loss: 0.739239
2023-10-30 12:30:35,522 Epoch: [232/484] Iter:[110/495], Time: 0.38, lr: [0.005553347253919487], Loss: 2.044057, Acc:0.802097, Semantic loss: 0.768573, BCE loss: 0.538803, SB loss: 0.736681
2023-10-30 12:30:39,160 Epoch: [232/484] Iter:[120/495], Time: 0.38, lr: [0.005552946224265268], Loss: 2.039259, Acc:0.801908, Semantic loss: 0.768272, BCE loss: 0.535086, SB loss: 0.735900
2023-10-30 12:30:42,838 Epoch: [232/484] Iter:[130/495], Time: 0.38, lr: [0.005552545191393018], Loss: 2.036168, Acc:0.802149, Semantic loss: 0.767723, BCE loss: 0.532806, SB loss: 0.735639
2023-10-30 12:30:46,497 Epoch: [232/484] Iter:[140/495], Time: 0.38, lr: [0.00555214415530245], Loss: 2.033073, Acc:0.802723, Semantic loss: 0.766842, BCE loss: 0.531758, SB loss: 0.734473
2023-10-30 12:30:50,155 Epoch: [232/484] Iter:[150/495], Time: 0.38, lr: [0.005551743115993281], Loss: 2.028072, Acc:0.801376, Semantic loss: 0.762698, BCE loss: 0.532359, SB loss: 0.733015
2023-10-30 12:30:53,947 Epoch: [232/484] Iter:[160/495], Time: 0.38, lr: [0.005551342073465228], Loss: 2.023077, Acc:0.802012, Semantic loss: 0.760921, BCE loss: 0.529452, SB loss: 0.732705
2023-10-30 12:30:57,692 Epoch: [232/484] Iter:[170/495], Time: 0.38, lr: [0.005550941027718004], Loss: 2.023521, Acc:0.800875, Semantic loss: 0.761890, BCE loss: 0.529747, SB loss: 0.731884
2023-10-30 12:31:01,344 Epoch: [232/484] Iter:[180/495], Time: 0.38, lr: [0.005550539978751326], Loss: 2.018903, Acc:0.802004, Semantic loss: 0.758220, BCE loss: 0.529103, SB loss: 0.731580
2023-10-30 12:31:05,022 Epoch: [232/484] Iter:[190/495], Time: 0.38, lr: [0.0055501389265649095], Loss: 2.019469, Acc:0.802566, Semantic loss: 0.756721, BCE loss: 0.531395, SB loss: 0.731353
2023-10-30 12:31:08,724 Epoch: [232/484] Iter:[200/495], Time: 0.38, lr: [0.00554973787115847], Loss: 2.030153, Acc:0.802991, Semantic loss: 0.759450, BCE loss: 0.535672, SB loss: 0.735030
2023-10-30 12:31:12,443 Epoch: [232/484] Iter:[210/495], Time: 0.38, lr: [0.005549336812531725], Loss: 2.029932, Acc:0.803008, Semantic loss: 0.760066, BCE loss: 0.534264, SB loss: 0.735602
2023-10-30 12:31:16,101 Epoch: [232/484] Iter:[220/495], Time: 0.38, lr: [0.005548935750684389], Loss: 2.027671, Acc:0.803155, Semantic loss: 0.759360, BCE loss: 0.533931, SB loss: 0.734380
2023-10-30 12:31:19,813 Epoch: [232/484] Iter:[230/495], Time: 0.38, lr: [0.0055485346856161775], Loss: 2.031743, Acc:0.803111, Semantic loss: 0.762593, BCE loss: 0.533347, SB loss: 0.735802
2023-10-30 12:31:23,424 Epoch: [232/484] Iter:[240/495], Time: 0.38, lr: [0.0055481336173268045], Loss: 2.030421, Acc:0.802940, Semantic loss: 0.762399, BCE loss: 0.531617, SB loss: 0.736405
2023-10-30 12:31:27,119 Epoch: [232/484] Iter:[250/495], Time: 0.37, lr: [0.0055477325458159876], Loss: 2.030867, Acc:0.801257, Semantic loss: 0.763875, BCE loss: 0.531235, SB loss: 0.735757
2023-10-30 12:31:30,806 Epoch: [232/484] Iter:[260/495], Time: 0.37, lr: [0.00554733147108344], Loss: 2.035040, Acc:0.801234, Semantic loss: 0.765773, BCE loss: 0.532693, SB loss: 0.736573
2023-10-30 12:31:34,477 Epoch: [232/484] Iter:[270/495], Time: 0.37, lr: [0.005546930393128879], Loss: 2.028909, Acc:0.799901, Semantic loss: 0.763258, BCE loss: 0.529755, SB loss: 0.735896
2023-10-30 12:31:38,142 Epoch: [232/484] Iter:[280/495], Time: 0.37, lr: [0.005546529311952017], Loss: 2.026001, Acc:0.799584, Semantic loss: 0.761891, BCE loss: 0.529061, SB loss: 0.735049
2023-10-30 12:31:41,804 Epoch: [232/484] Iter:[290/495], Time: 0.37, lr: [0.005546128227552572], Loss: 2.025139, Acc:0.799761, Semantic loss: 0.761132, BCE loss: 0.528087, SB loss: 0.735921
2023-10-30 12:31:45,481 Epoch: [232/484] Iter:[300/495], Time: 0.37, lr: [0.00554572713993026], Loss: 2.027959, Acc:0.800229, Semantic loss: 0.761777, BCE loss: 0.529643, SB loss: 0.736539
2023-10-30 12:31:49,167 Epoch: [232/484] Iter:[310/495], Time: 0.37, lr: [0.005545326049084793], Loss: 2.030237, Acc:0.799822, Semantic loss: 0.763035, BCE loss: 0.530703, SB loss: 0.736499
2023-10-30 12:31:52,880 Epoch: [232/484] Iter:[320/495], Time: 0.37, lr: [0.005544924955015887], Loss: 2.024478, Acc:0.799646, Semantic loss: 0.759656, BCE loss: 0.529891, SB loss: 0.734931
2023-10-30 12:31:56,488 Epoch: [232/484] Iter:[330/495], Time: 0.37, lr: [0.005544523857723258], Loss: 2.028245, Acc:0.798412, Semantic loss: 0.761691, BCE loss: 0.530530, SB loss: 0.736024
2023-10-30 12:32:00,237 Epoch: [232/484] Iter:[340/495], Time: 0.37, lr: [0.0055441227572066215], Loss: 2.025672, Acc:0.799300, Semantic loss: 0.760228, BCE loss: 0.530893, SB loss: 0.734551
2023-10-30 12:32:03,840 Epoch: [232/484] Iter:[350/495], Time: 0.37, lr: [0.005543721653465688], Loss: 2.025400, Acc:0.799216, Semantic loss: 0.760415, BCE loss: 0.531018, SB loss: 0.733967
2023-10-30 12:32:07,500 Epoch: [232/484] Iter:[360/495], Time: 0.37, lr: [0.005543320546500179], Loss: 2.023094, Acc:0.799141, Semantic loss: 0.759494, BCE loss: 0.530056, SB loss: 0.733544
2023-10-30 12:32:11,125 Epoch: [232/484] Iter:[370/495], Time: 0.37, lr: [0.0055429194363098054], Loss: 2.022880, Acc:0.800440, Semantic loss: 0.759006, BCE loss: 0.530689, SB loss: 0.733185
2023-10-30 12:32:14,824 Epoch: [232/484] Iter:[380/495], Time: 0.37, lr: [0.005542518322894283], Loss: 2.019440, Acc:0.799535, Semantic loss: 0.757304, BCE loss: 0.529219, SB loss: 0.732918
2023-10-30 12:32:18,477 Epoch: [232/484] Iter:[390/495], Time: 0.37, lr: [0.005542117206253325], Loss: 2.022833, Acc:0.799500, Semantic loss: 0.759235, BCE loss: 0.530065, SB loss: 0.733533
2023-10-30 12:32:22,115 Epoch: [232/484] Iter:[400/495], Time: 0.37, lr: [0.005541716086386649], Loss: 2.022889, Acc:0.799086, Semantic loss: 0.758771, BCE loss: 0.530137, SB loss: 0.733982
2023-10-30 12:32:25,782 Epoch: [232/484] Iter:[410/495], Time: 0.37, lr: [0.005541314963293965], Loss: 2.026963, Acc:0.798688, Semantic loss: 0.760159, BCE loss: 0.531812, SB loss: 0.734992
2023-10-30 12:32:29,457 Epoch: [232/484] Iter:[420/495], Time: 0.37, lr: [0.0055409138369749925], Loss: 2.025904, Acc:0.797931, Semantic loss: 0.759693, BCE loss: 0.530782, SB loss: 0.735429
2023-10-30 12:32:33,187 Epoch: [232/484] Iter:[430/495], Time: 0.37, lr: [0.005540512707429442], Loss: 2.027622, Acc:0.797991, Semantic loss: 0.760467, BCE loss: 0.531379, SB loss: 0.735776
2023-10-30 12:32:36,827 Epoch: [232/484] Iter:[440/495], Time: 0.37, lr: [0.0055401115746570315], Loss: 2.029313, Acc:0.798101, Semantic loss: 0.761418, BCE loss: 0.531853, SB loss: 0.736043
2023-10-30 12:32:40,412 Epoch: [232/484] Iter:[450/495], Time: 0.37, lr: [0.005539710438657475], Loss: 2.025568, Acc:0.797779, Semantic loss: 0.760007, BCE loss: 0.530253, SB loss: 0.735308
2023-10-30 12:32:44,175 Epoch: [232/484] Iter:[460/495], Time: 0.37, lr: [0.005539309299430485], Loss: 2.026349, Acc:0.798071, Semantic loss: 0.760751, BCE loss: 0.530074, SB loss: 0.735525
2023-10-30 12:32:47,881 Epoch: [232/484] Iter:[470/495], Time: 0.37, lr: [0.005538908156975776], Loss: 2.027343, Acc:0.797984, Semantic loss: 0.761191, BCE loss: 0.530911, SB loss: 0.735241
2023-10-30 12:32:51,636 Epoch: [232/484] Iter:[480/495], Time: 0.37, lr: [0.0055385070112930635], Loss: 2.031567, Acc:0.798245, Semantic loss: 0.763837, BCE loss: 0.531878, SB loss: 0.735852
2023-10-30 12:32:55,151 Epoch: [232/484] Iter:[490/495], Time: 0.37, lr: [0.0055381058623820605], Loss: 2.036329, Acc:0.798452, Semantic loss: 0.766501, BCE loss: 0.532930, SB loss: 0.736898
2023-10-30 12:32:56,559 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:32:56,797 Loss: 2.082, MeanIU:  0.6970, Best_mIoU:  0.7151
2023-10-30 12:32:56,797 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374]
2023-10-30 12:32:58,791 Epoch: [233/484] Iter:[0/495], Time: 1.96, lr: [0.005537905286715861], Loss: 2.315681, Acc:0.859070, Semantic loss: 0.778206, BCE loss: 0.684910, SB loss: 0.852565
2023-10-30 12:33:02,757 Epoch: [233/484] Iter:[10/495], Time: 0.54, lr: [0.005537504132961888], Loss: 2.121415, Acc:0.803802, Semantic loss: 0.792236, BCE loss: 0.562363, SB loss: 0.766816
2023-10-30 12:33:06,460 Epoch: [233/484] Iter:[20/495], Time: 0.46, lr: [0.005537102975978909], Loss: 2.220217, Acc:0.797795, Semantic loss: 0.860346, BCE loss: 0.551512, SB loss: 0.808359
2023-10-30 12:33:10,234 Epoch: [233/484] Iter:[30/495], Time: 0.43, lr: [0.005536701815766641], Loss: 2.181154, Acc:0.801309, Semantic loss: 0.836452, BCE loss: 0.556711, SB loss: 0.787991
2023-10-30 12:33:13,930 Epoch: [233/484] Iter:[40/495], Time: 0.42, lr: [0.005536300652324796], Loss: 2.155263, Acc:0.802504, Semantic loss: 0.811736, BCE loss: 0.561188, SB loss: 0.782339
2023-10-30 12:33:17,654 Epoch: [233/484] Iter:[50/495], Time: 0.41, lr: [0.00553589948565309], Loss: 2.133786, Acc:0.805193, Semantic loss: 0.799700, BCE loss: 0.556976, SB loss: 0.777110
2023-10-30 12:33:21,310 Epoch: [233/484] Iter:[60/495], Time: 0.40, lr: [0.005535498315751234], Loss: 2.124365, Acc:0.804518, Semantic loss: 0.799252, BCE loss: 0.553528, SB loss: 0.771584
2023-10-30 12:33:24,983 Epoch: [233/484] Iter:[70/495], Time: 0.40, lr: [0.0055350971426189445], Loss: 2.108407, Acc:0.809532, Semantic loss: 0.788765, BCE loss: 0.553413, SB loss: 0.766228
2023-10-30 12:33:28,551 Epoch: [233/484] Iter:[80/495], Time: 0.39, lr: [0.005534695966255933], Loss: 2.091496, Acc:0.807958, Semantic loss: 0.782863, BCE loss: 0.544410, SB loss: 0.764223
2023-10-30 12:33:32,149 Epoch: [233/484] Iter:[90/495], Time: 0.39, lr: [0.005534294786661916], Loss: 2.088212, Acc:0.805014, Semantic loss: 0.782716, BCE loss: 0.543544, SB loss: 0.761952
2023-10-30 12:33:35,900 Epoch: [233/484] Iter:[100/495], Time: 0.39, lr: [0.005533893603836604], Loss: 2.075153, Acc:0.805197, Semantic loss: 0.774896, BCE loss: 0.543761, SB loss: 0.756496
2023-10-30 12:33:39,560 Epoch: [233/484] Iter:[110/495], Time: 0.38, lr: [0.005533492417779713], Loss: 2.078926, Acc:0.802940, Semantic loss: 0.782994, BCE loss: 0.538662, SB loss: 0.757269
2023-10-30 12:33:43,271 Epoch: [233/484] Iter:[120/495], Time: 0.38, lr: [0.0055330912284909575], Loss: 2.081278, Acc:0.798989, Semantic loss: 0.786365, BCE loss: 0.537544, SB loss: 0.757368
2023-10-30 12:33:46,873 Epoch: [233/484] Iter:[130/495], Time: 0.38, lr: [0.00553269003597005], Loss: 2.080755, Acc:0.798211, Semantic loss: 0.789030, BCE loss: 0.535933, SB loss: 0.755792
2023-10-30 12:33:50,480 Epoch: [233/484] Iter:[140/495], Time: 0.38, lr: [0.0055322888402167016], Loss: 2.079847, Acc:0.795866, Semantic loss: 0.785431, BCE loss: 0.538568, SB loss: 0.755847
2023-10-30 12:33:54,182 Epoch: [233/484] Iter:[150/495], Time: 0.38, lr: [0.0055318876412306294], Loss: 2.068505, Acc:0.795680, Semantic loss: 0.779815, BCE loss: 0.535782, SB loss: 0.752908
2023-10-30 12:33:57,921 Epoch: [233/484] Iter:[160/495], Time: 0.38, lr: [0.005531486439011544], Loss: 2.066225, Acc:0.799570, Semantic loss: 0.777894, BCE loss: 0.534451, SB loss: 0.753880
2023-10-30 12:34:01,576 Epoch: [233/484] Iter:[170/495], Time: 0.38, lr: [0.00553108523355916], Loss: 2.070970, Acc:0.798702, Semantic loss: 0.777585, BCE loss: 0.540159, SB loss: 0.753226
2023-10-30 12:34:05,129 Epoch: [233/484] Iter:[180/495], Time: 0.38, lr: [0.005530684024873191], Loss: 2.068771, Acc:0.800192, Semantic loss: 0.775204, BCE loss: 0.542117, SB loss: 0.751450
2023-10-30 12:34:08,858 Epoch: [233/484] Iter:[190/495], Time: 0.38, lr: [0.005530282812953352], Loss: 2.067229, Acc:0.799417, Semantic loss: 0.775807, BCE loss: 0.540553, SB loss: 0.750868
2023-10-30 12:34:12,622 Epoch: [233/484] Iter:[200/495], Time: 0.38, lr: [0.005529881597799355], Loss: 2.068586, Acc:0.799676, Semantic loss: 0.778221, BCE loss: 0.539079, SB loss: 0.751287
2023-10-30 12:34:16,262 Epoch: [233/484] Iter:[210/495], Time: 0.38, lr: [0.0055294803794109105], Loss: 2.061259, Acc:0.798036, Semantic loss: 0.774955, BCE loss: 0.536721, SB loss: 0.749583
2023-10-30 12:34:19,968 Epoch: [233/484] Iter:[220/495], Time: 0.38, lr: [0.005529079157787735], Loss: 2.056399, Acc:0.797022, Semantic loss: 0.772503, BCE loss: 0.535057, SB loss: 0.748839
2023-10-30 12:34:23,623 Epoch: [233/484] Iter:[230/495], Time: 0.38, lr: [0.005528677932929539], Loss: 2.066494, Acc:0.796525, Semantic loss: 0.778139, BCE loss: 0.535924, SB loss: 0.752431
2023-10-30 12:34:27,315 Epoch: [233/484] Iter:[240/495], Time: 0.38, lr: [0.005528276704836038], Loss: 2.059532, Acc:0.796445, Semantic loss: 0.774280, BCE loss: 0.534431, SB loss: 0.750822
2023-10-30 12:34:30,936 Epoch: [233/484] Iter:[250/495], Time: 0.37, lr: [0.0055278754735069435], Loss: 2.057481, Acc:0.796214, Semantic loss: 0.772650, BCE loss: 0.534818, SB loss: 0.750013
2023-10-30 12:34:34,678 Epoch: [233/484] Iter:[260/495], Time: 0.37, lr: [0.00552747423894197], Loss: 2.055957, Acc:0.795605, Semantic loss: 0.771953, BCE loss: 0.535423, SB loss: 0.748581
2023-10-30 12:34:38,540 Epoch: [233/484] Iter:[270/495], Time: 0.38, lr: [0.005527073001140829], Loss: 2.052492, Acc:0.796307, Semantic loss: 0.770066, BCE loss: 0.534909, SB loss: 0.747517
2023-10-30 12:34:42,238 Epoch: [233/484] Iter:[280/495], Time: 0.38, lr: [0.005526671760103233], Loss: 2.047234, Acc:0.796289, Semantic loss: 0.767344, BCE loss: 0.533879, SB loss: 0.746011
2023-10-30 12:34:45,924 Epoch: [233/484] Iter:[290/495], Time: 0.37, lr: [0.005526270515828896], Loss: 2.046848, Acc:0.796972, Semantic loss: 0.768304, BCE loss: 0.533595, SB loss: 0.744948
2023-10-30 12:34:49,585 Epoch: [233/484] Iter:[300/495], Time: 0.37, lr: [0.005525869268317531], Loss: 2.042181, Acc:0.797266, Semantic loss: 0.766268, BCE loss: 0.531715, SB loss: 0.744198
2023-10-30 12:34:53,230 Epoch: [233/484] Iter:[310/495], Time: 0.37, lr: [0.005525468017568849], Loss: 2.040653, Acc:0.798432, Semantic loss: 0.763921, BCE loss: 0.533167, SB loss: 0.743564
2023-10-30 12:34:56,867 Epoch: [233/484] Iter:[320/495], Time: 0.37, lr: [0.005525066763582564], Loss: 2.037881, Acc:0.797394, Semantic loss: 0.762827, BCE loss: 0.532243, SB loss: 0.742811
2023-10-30 12:35:00,506 Epoch: [233/484] Iter:[330/495], Time: 0.37, lr: [0.005524665506358387], Loss: 2.039877, Acc:0.796527, Semantic loss: 0.766288, BCE loss: 0.529667, SB loss: 0.743922
2023-10-30 12:35:04,184 Epoch: [233/484] Iter:[340/495], Time: 0.37, lr: [0.005524264245896034], Loss: 2.035196, Acc:0.796825, Semantic loss: 0.764825, BCE loss: 0.527886, SB loss: 0.742485
2023-10-30 12:35:07,862 Epoch: [233/484] Iter:[350/495], Time: 0.37, lr: [0.005523862982195215], Loss: 2.035430, Acc:0.796504, Semantic loss: 0.765294, BCE loss: 0.528293, SB loss: 0.741842
2023-10-30 12:35:11,498 Epoch: [233/484] Iter:[360/495], Time: 0.37, lr: [0.005523461715255642], Loss: 2.033998, Acc:0.795207, Semantic loss: 0.764772, BCE loss: 0.527932, SB loss: 0.741295
2023-10-30 12:35:15,037 Epoch: [233/484] Iter:[370/495], Time: 0.37, lr: [0.005523060445077028], Loss: 2.036829, Acc:0.793768, Semantic loss: 0.764782, BCE loss: 0.530394, SB loss: 0.741653
2023-10-30 12:35:18,651 Epoch: [233/484] Iter:[380/495], Time: 0.37, lr: [0.005522659171659087], Loss: 2.037727, Acc:0.793670, Semantic loss: 0.766102, BCE loss: 0.530037, SB loss: 0.741589
2023-10-30 12:35:22,315 Epoch: [233/484] Iter:[390/495], Time: 0.37, lr: [0.005522257895001529], Loss: 2.035781, Acc:0.793938, Semantic loss: 0.766438, BCE loss: 0.528689, SB loss: 0.740655
2023-10-30 12:35:25,959 Epoch: [233/484] Iter:[400/495], Time: 0.37, lr: [0.005521856615104067], Loss: 2.035340, Acc:0.793921, Semantic loss: 0.766152, BCE loss: 0.528383, SB loss: 0.740804
2023-10-30 12:35:29,688 Epoch: [233/484] Iter:[410/495], Time: 0.37, lr: [0.005521455331966414], Loss: 2.033917, Acc:0.794030, Semantic loss: 0.764853, BCE loss: 0.528209, SB loss: 0.740856
2023-10-30 12:35:33,381 Epoch: [233/484] Iter:[420/495], Time: 0.37, lr: [0.0055210540455882815], Loss: 2.035274, Acc:0.795057, Semantic loss: 0.765845, BCE loss: 0.528830, SB loss: 0.740598
2023-10-30 12:35:37,019 Epoch: [233/484] Iter:[430/495], Time: 0.37, lr: [0.005520652755969382], Loss: 2.034170, Acc:0.795282, Semantic loss: 0.765539, BCE loss: 0.528625, SB loss: 0.740005
2023-10-30 12:35:40,740 Epoch: [233/484] Iter:[440/495], Time: 0.37, lr: [0.005520251463109428], Loss: 2.033116, Acc:0.795301, Semantic loss: 0.766276, BCE loss: 0.527185, SB loss: 0.739656
2023-10-30 12:35:44,486 Epoch: [233/484] Iter:[450/495], Time: 0.37, lr: [0.00551985016700813], Loss: 2.031528, Acc:0.796033, Semantic loss: 0.765010, BCE loss: 0.527049, SB loss: 0.739469
2023-10-30 12:35:48,214 Epoch: [233/484] Iter:[460/495], Time: 0.37, lr: [0.005519448867665202], Loss: 2.032682, Acc:0.796491, Semantic loss: 0.765066, BCE loss: 0.528283, SB loss: 0.739333
2023-10-30 12:35:51,855 Epoch: [233/484] Iter:[470/495], Time: 0.37, lr: [0.005519047565080353], Loss: 2.037364, Acc:0.796626, Semantic loss: 0.768314, BCE loss: 0.528696, SB loss: 0.740353
2023-10-30 12:35:55,511 Epoch: [233/484] Iter:[480/495], Time: 0.37, lr: [0.005518646259253298], Loss: 2.035300, Acc:0.796487, Semantic loss: 0.767366, BCE loss: 0.528002, SB loss: 0.739933
2023-10-30 12:35:59,064 Epoch: [233/484] Iter:[490/495], Time: 0.37, lr: [0.005518244950183746], Loss: 2.033016, Acc:0.796691, Semantic loss: 0.766086, BCE loss: 0.527957, SB loss: 0.738973
2023-10-30 12:36:00,461 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:36:00,689 Loss: 2.082, MeanIU:  0.6970, Best_mIoU:  0.7151
2023-10-30 12:36:00,689 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374]
2023-10-30 12:36:02,784 Epoch: [234/484] Iter:[0/495], Time: 2.06, lr: [0.005518044294432946], Loss: 1.880783, Acc:0.713578, Semantic loss: 0.731978, BCE loss: 0.411483, SB loss: 0.737322
2023-10-30 12:36:06,788 Epoch: [234/484] Iter:[10/495], Time: 0.55, lr: [0.005517642980499111], Loss: 2.098579, Acc:0.791076, Semantic loss: 0.875760, BCE loss: 0.496265, SB loss: 0.726554
2023-10-30 12:36:10,604 Epoch: [234/484] Iter:[20/495], Time: 0.47, lr: [0.005517241663322061], Loss: 2.118868, Acc:0.787679, Semantic loss: 0.844675, BCE loss: 0.539972, SB loss: 0.734220
2023-10-30 12:36:14,218 Epoch: [234/484] Iter:[30/495], Time: 0.44, lr: [0.005516840342901507], Loss: 2.081862, Acc:0.804466, Semantic loss: 0.816599, BCE loss: 0.533471, SB loss: 0.731792
2023-10-30 12:36:17,866 Epoch: [234/484] Iter:[40/495], Time: 0.42, lr: [0.005516439019237159], Loss: 2.021633, Acc:0.795284, Semantic loss: 0.777465, BCE loss: 0.518152, SB loss: 0.726016
2023-10-30 12:36:21,562 Epoch: [234/484] Iter:[50/495], Time: 0.41, lr: [0.0055160376923287305], Loss: 1.992725, Acc:0.798766, Semantic loss: 0.753558, BCE loss: 0.519618, SB loss: 0.719549
2023-10-30 12:36:25,255 Epoch: [234/484] Iter:[60/495], Time: 0.40, lr: [0.005515636362175932], Loss: 2.021200, Acc:0.803102, Semantic loss: 0.758976, BCE loss: 0.536077, SB loss: 0.726147
2023-10-30 12:36:28,866 Epoch: [234/484] Iter:[70/495], Time: 0.40, lr: [0.005515235028778474], Loss: 2.011698, Acc:0.800033, Semantic loss: 0.757797, BCE loss: 0.529075, SB loss: 0.724825
2023-10-30 12:36:32,536 Epoch: [234/484] Iter:[80/495], Time: 0.39, lr: [0.005514833692136071], Loss: 2.024006, Acc:0.799943, Semantic loss: 0.763250, BCE loss: 0.530420, SB loss: 0.730336
2023-10-30 12:36:36,202 Epoch: [234/484] Iter:[90/495], Time: 0.39, lr: [0.0055144323522484315], Loss: 2.027979, Acc:0.800260, Semantic loss: 0.763323, BCE loss: 0.533423, SB loss: 0.731233
2023-10-30 12:36:39,887 Epoch: [234/484] Iter:[100/495], Time: 0.39, lr: [0.005514031009115269], Loss: 2.016300, Acc:0.803985, Semantic loss: 0.756981, BCE loss: 0.529440, SB loss: 0.729878
2023-10-30 12:36:43,522 Epoch: [234/484] Iter:[110/495], Time: 0.39, lr: [0.005513629662736294], Loss: 2.010350, Acc:0.800350, Semantic loss: 0.755137, BCE loss: 0.525821, SB loss: 0.729391
2023-10-30 12:36:47,199 Epoch: [234/484] Iter:[120/495], Time: 0.38, lr: [0.005513228313111217], Loss: 2.004454, Acc:0.798726, Semantic loss: 0.754067, BCE loss: 0.520492, SB loss: 0.729895
2023-10-30 12:36:50,789 Epoch: [234/484] Iter:[130/495], Time: 0.38, lr: [0.005512826960239748], Loss: 1.994724, Acc:0.797686, Semantic loss: 0.750927, BCE loss: 0.514943, SB loss: 0.728854
2023-10-30 12:36:54,631 Epoch: [234/484] Iter:[140/495], Time: 0.38, lr: [0.005512425604121601], Loss: 1.997125, Acc:0.798107, Semantic loss: 0.751726, BCE loss: 0.515049, SB loss: 0.730350
2023-10-30 12:36:58,286 Epoch: [234/484] Iter:[150/495], Time: 0.38, lr: [0.005512024244756485], Loss: 2.003797, Acc:0.797795, Semantic loss: 0.752509, BCE loss: 0.518808, SB loss: 0.732480
2023-10-30 12:37:01,951 Epoch: [234/484] Iter:[160/495], Time: 0.38, lr: [0.005511622882144113], Loss: 2.017113, Acc:0.799140, Semantic loss: 0.757190, BCE loss: 0.526325, SB loss: 0.733598
2023-10-30 12:37:05,633 Epoch: [234/484] Iter:[170/495], Time: 0.38, lr: [0.0055112215162841935], Loss: 2.021218, Acc:0.798409, Semantic loss: 0.757942, BCE loss: 0.528705, SB loss: 0.734571
2023-10-30 12:37:09,300 Epoch: [234/484] Iter:[180/495], Time: 0.38, lr: [0.00551082014717644], Loss: 2.010116, Acc:0.798388, Semantic loss: 0.754586, BCE loss: 0.523510, SB loss: 0.732020
2023-10-30 12:37:13,071 Epoch: [234/484] Iter:[190/495], Time: 0.38, lr: [0.0055104187748205614], Loss: 2.012106, Acc:0.796849, Semantic loss: 0.754536, BCE loss: 0.524886, SB loss: 0.732684
2023-10-30 12:37:16,791 Epoch: [234/484] Iter:[200/495], Time: 0.38, lr: [0.005510017399216269], Loss: 2.011327, Acc:0.795973, Semantic loss: 0.755914, BCE loss: 0.523104, SB loss: 0.732310
2023-10-30 12:37:20,370 Epoch: [234/484] Iter:[210/495], Time: 0.38, lr: [0.005509616020363274], Loss: 2.006410, Acc:0.796622, Semantic loss: 0.753389, BCE loss: 0.521297, SB loss: 0.731724
2023-10-30 12:37:24,048 Epoch: [234/484] Iter:[220/495], Time: 0.38, lr: [0.005509214638261288], Loss: 2.007305, Acc:0.796922, Semantic loss: 0.755116, BCE loss: 0.520552, SB loss: 0.731637
2023-10-30 12:37:27,891 Epoch: [234/484] Iter:[230/495], Time: 0.38, lr: [0.005508813252910019], Loss: 2.006694, Acc:0.795772, Semantic loss: 0.754158, BCE loss: 0.519709, SB loss: 0.732827
2023-10-30 12:37:31,529 Epoch: [234/484] Iter:[240/495], Time: 0.38, lr: [0.005508411864309179], Loss: 2.013001, Acc:0.795581, Semantic loss: 0.756905, BCE loss: 0.520274, SB loss: 0.735823
2023-10-30 12:37:35,213 Epoch: [234/484] Iter:[250/495], Time: 0.38, lr: [0.005508010472458481], Loss: 2.014056, Acc:0.795375, Semantic loss: 0.757877, BCE loss: 0.520974, SB loss: 0.735205
2023-10-30 12:37:38,814 Epoch: [234/484] Iter:[260/495], Time: 0.38, lr: [0.005507609077357633], Loss: 2.012303, Acc:0.796473, Semantic loss: 0.756856, BCE loss: 0.520556, SB loss: 0.734891
2023-10-30 12:37:42,435 Epoch: [234/484] Iter:[270/495], Time: 0.38, lr: [0.005507207679006345], Loss: 2.008204, Acc:0.795561, Semantic loss: 0.754876, BCE loss: 0.518943, SB loss: 0.734385
2023-10-30 12:37:46,096 Epoch: [234/484] Iter:[280/495], Time: 0.37, lr: [0.005506806277404328], Loss: 2.009639, Acc:0.794656, Semantic loss: 0.756982, BCE loss: 0.519119, SB loss: 0.733539
2023-10-30 12:37:49,733 Epoch: [234/484] Iter:[290/495], Time: 0.37, lr: [0.005506404872551293], Loss: 2.007975, Acc:0.795006, Semantic loss: 0.755913, BCE loss: 0.518876, SB loss: 0.733187
2023-10-30 12:37:53,357 Epoch: [234/484] Iter:[300/495], Time: 0.37, lr: [0.00550600346444695], Loss: 2.007146, Acc:0.795377, Semantic loss: 0.756523, BCE loss: 0.517865, SB loss: 0.732758
2023-10-30 12:37:57,094 Epoch: [234/484] Iter:[310/495], Time: 0.37, lr: [0.005505602053091009], Loss: 2.011350, Acc:0.795543, Semantic loss: 0.759533, BCE loss: 0.518139, SB loss: 0.733678
2023-10-30 12:38:00,721 Epoch: [234/484] Iter:[320/495], Time: 0.37, lr: [0.005505200638483181], Loss: 2.011075, Acc:0.795901, Semantic loss: 0.757633, BCE loss: 0.519553, SB loss: 0.733889
2023-10-30 12:38:04,320 Epoch: [234/484] Iter:[330/495], Time: 0.37, lr: [0.005504799220623176], Loss: 2.013604, Acc:0.795467, Semantic loss: 0.759393, BCE loss: 0.519800, SB loss: 0.734411
2023-10-30 12:38:08,009 Epoch: [234/484] Iter:[340/495], Time: 0.37, lr: [0.005504397799510705], Loss: 2.012821, Acc:0.795464, Semantic loss: 0.758989, BCE loss: 0.519614, SB loss: 0.734218
2023-10-30 12:38:11,623 Epoch: [234/484] Iter:[350/495], Time: 0.37, lr: [0.005503996375145476], Loss: 2.011740, Acc:0.794936, Semantic loss: 0.758451, BCE loss: 0.519791, SB loss: 0.733497
2023-10-30 12:38:15,241 Epoch: [234/484] Iter:[360/495], Time: 0.37, lr: [0.0055035949475272], Loss: 2.011867, Acc:0.795286, Semantic loss: 0.759394, BCE loss: 0.518871, SB loss: 0.733603
2023-10-30 12:38:18,860 Epoch: [234/484] Iter:[370/495], Time: 0.37, lr: [0.0055031935166555855], Loss: 2.011373, Acc:0.795219, Semantic loss: 0.758111, BCE loss: 0.520109, SB loss: 0.733152
2023-10-30 12:38:22,499 Epoch: [234/484] Iter:[380/495], Time: 0.37, lr: [0.0055027920825303465], Loss: 2.012630, Acc:0.796254, Semantic loss: 0.758904, BCE loss: 0.520327, SB loss: 0.733399
2023-10-30 12:38:26,201 Epoch: [234/484] Iter:[390/495], Time: 0.37, lr: [0.005502390645151189], Loss: 2.015053, Acc:0.796767, Semantic loss: 0.761216, BCE loss: 0.520451, SB loss: 0.733387
2023-10-30 12:38:29,799 Epoch: [234/484] Iter:[400/495], Time: 0.37, lr: [0.005501989204517824], Loss: 2.012991, Acc:0.795563, Semantic loss: 0.760788, BCE loss: 0.518455, SB loss: 0.733748
2023-10-30 12:38:33,423 Epoch: [234/484] Iter:[410/495], Time: 0.37, lr: [0.005501587760629962], Loss: 2.016069, Acc:0.795634, Semantic loss: 0.761252, BCE loss: 0.520027, SB loss: 0.734790
2023-10-30 12:38:37,130 Epoch: [234/484] Iter:[420/495], Time: 0.37, lr: [0.005501186313487314], Loss: 2.017868, Acc:0.796046, Semantic loss: 0.761843, BCE loss: 0.521250, SB loss: 0.734775
2023-10-30 12:38:40,819 Epoch: [234/484] Iter:[430/495], Time: 0.37, lr: [0.005500784863089587], Loss: 2.019724, Acc:0.795822, Semantic loss: 0.762452, BCE loss: 0.522086, SB loss: 0.735186
2023-10-30 12:38:44,512 Epoch: [234/484] Iter:[440/495], Time: 0.37, lr: [0.00550038340943649], Loss: 2.020134, Acc:0.796275, Semantic loss: 0.762009, BCE loss: 0.523612, SB loss: 0.734513
2023-10-30 12:38:48,091 Epoch: [234/484] Iter:[450/495], Time: 0.37, lr: [0.005499981952527735], Loss: 2.020588, Acc:0.796160, Semantic loss: 0.763280, BCE loss: 0.522991, SB loss: 0.734317
2023-10-30 12:38:51,774 Epoch: [234/484] Iter:[460/495], Time: 0.37, lr: [0.005499580492363032], Loss: 2.019569, Acc:0.797013, Semantic loss: 0.762749, BCE loss: 0.523130, SB loss: 0.733691
2023-10-30 12:38:55,476 Epoch: [234/484] Iter:[470/495], Time: 0.37, lr: [0.005499179028942087], Loss: 2.021018, Acc:0.796382, Semantic loss: 0.763398, BCE loss: 0.523452, SB loss: 0.734168
2023-10-30 12:38:59,181 Epoch: [234/484] Iter:[480/495], Time: 0.37, lr: [0.005498777562264614], Loss: 2.022232, Acc:0.796939, Semantic loss: 0.763930, BCE loss: 0.524035, SB loss: 0.734267
2023-10-30 12:39:02,771 Epoch: [234/484] Iter:[490/495], Time: 0.37, lr: [0.00549837609233032], Loss: 2.021839, Acc:0.796728, Semantic loss: 0.763595, BCE loss: 0.524317, SB loss: 0.733927
2023-10-30 12:39:04,173 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:39:04,406 Loss: 2.082, MeanIU:  0.6970, Best_mIoU:  0.7151
2023-10-30 12:39:04,406 [0.97052598 0.7891351  0.90466081 0.42835681 0.53994168 0.55149774
 0.63366353 0.71294896 0.91067414 0.56617789 0.93241259 0.76937022
 0.56829006 0.92702292 0.50532201 0.70800557 0.61729016 0.48432621
 0.72414374]
2023-10-30 12:39:06,267 Epoch: [235/484] Iter:[0/495], Time: 1.83, lr: [0.005498175356141773], Loss: 1.697417, Acc:0.594191, Semantic loss: 0.687398, BCE loss: 0.323610, SB loss: 0.686410
2023-10-30 12:39:10,205 Epoch: [235/484] Iter:[10/495], Time: 0.52, lr: [0.005497773881321702], Loss: 1.961124, Acc:0.764395, Semantic loss: 0.770119, BCE loss: 0.454040, SB loss: 0.736965
2023-10-30 12:39:13,836 Epoch: [235/484] Iter:[20/495], Time: 0.45, lr: [0.005497372403244084], Loss: 1.970720, Acc:0.775774, Semantic loss: 0.759135, BCE loss: 0.479500, SB loss: 0.732084
2023-10-30 12:39:17,439 Epoch: [235/484] Iter:[30/495], Time: 0.42, lr: [0.005496970921908627], Loss: 1.942671, Acc:0.788605, Semantic loss: 0.732648, BCE loss: 0.490052, SB loss: 0.719970
2023-10-30 12:39:21,029 Epoch: [235/484] Iter:[40/495], Time: 0.40, lr: [0.005496569437315041], Loss: 1.951819, Acc:0.790863, Semantic loss: 0.739118, BCE loss: 0.488105, SB loss: 0.724595
2023-10-30 12:39:24,786 Epoch: [235/484] Iter:[50/495], Time: 0.40, lr: [0.005496167949463035], Loss: 1.948994, Acc:0.791754, Semantic loss: 0.740206, BCE loss: 0.485691, SB loss: 0.723097
2023-10-30 12:39:28,457 Epoch: [235/484] Iter:[60/495], Time: 0.39, lr: [0.005495766458352318], Loss: 1.992653, Acc:0.791679, Semantic loss: 0.763678, BCE loss: 0.496466, SB loss: 0.732508
2023-10-30 12:39:32,157 Epoch: [235/484] Iter:[70/495], Time: 0.39, lr: [0.005495364963982599], Loss: 2.015185, Acc:0.800524, Semantic loss: 0.768663, BCE loss: 0.513583, SB loss: 0.732940
2023-10-30 12:39:35,867 Epoch: [235/484] Iter:[80/495], Time: 0.39, lr: [0.005494963466353587], Loss: 2.030224, Acc:0.802611, Semantic loss: 0.773611, BCE loss: 0.514267, SB loss: 0.742346
2023-10-30 12:39:39,519 Epoch: [235/484] Iter:[90/495], Time: 0.39, lr: [0.005494561965464993], Loss: 2.023742, Acc:0.805994, Semantic loss: 0.768837, BCE loss: 0.513846, SB loss: 0.741059
2023-10-30 12:39:43,247 Epoch: [235/484] Iter:[100/495], Time: 0.38, lr: [0.005494160461316522], Loss: 2.027791, Acc:0.803353, Semantic loss: 0.765866, BCE loss: 0.521646, SB loss: 0.740279
2023-10-30 12:39:46,901 Epoch: [235/484] Iter:[110/495], Time: 0.38, lr: [0.005493758953907884], Loss: 2.037767, Acc:0.801364, Semantic loss: 0.768284, BCE loss: 0.526730, SB loss: 0.742753
2023-10-30 12:39:50,622 Epoch: [235/484] Iter:[120/495], Time: 0.38, lr: [0.005493357443238789], Loss: 2.033533, Acc:0.802563, Semantic loss: 0.763588, BCE loss: 0.526148, SB loss: 0.743797
2023-10-30 12:39:54,241 Epoch: [235/484] Iter:[130/495], Time: 0.38, lr: [0.005492955929308945], Loss: 2.033888, Acc:0.803271, Semantic loss: 0.764890, BCE loss: 0.526013, SB loss: 0.742985
2023-10-30 12:39:57,787 Epoch: [235/484] Iter:[140/495], Time: 0.38, lr: [0.005492554412118061], Loss: 2.023526, Acc:0.802377, Semantic loss: 0.760847, BCE loss: 0.523539, SB loss: 0.739140
2023-10-30 12:40:01,534 Epoch: [235/484] Iter:[150/495], Time: 0.38, lr: [0.005492152891665847], Loss: 2.016799, Acc:0.802536, Semantic loss: 0.756534, BCE loss: 0.522587, SB loss: 0.737678
2023-10-30 12:40:05,123 Epoch: [235/484] Iter:[160/495], Time: 0.38, lr: [0.00549175136795201], Loss: 2.020999, Acc:0.801294, Semantic loss: 0.758506, BCE loss: 0.523707, SB loss: 0.738786
2023-10-30 12:40:08,827 Epoch: [235/484] Iter:[170/495], Time: 0.38, lr: [0.005491349840976258], Loss: 2.017650, Acc:0.800026, Semantic loss: 0.758104, BCE loss: 0.522823, SB loss: 0.736723
2023-10-30 12:40:12,516 Epoch: [235/484] Iter:[180/495], Time: 0.38, lr: [0.0054909483107382995], Loss: 2.013112, Acc:0.798537, Semantic loss: 0.758133, BCE loss: 0.519145, SB loss: 0.735834
2023-10-30 12:40:16,168 Epoch: [235/484] Iter:[190/495], Time: 0.38, lr: [0.0054905467772378425], Loss: 2.009296, Acc:0.798820, Semantic loss: 0.757220, BCE loss: 0.517631, SB loss: 0.734446
2023-10-30 12:40:19,778 Epoch: [235/484] Iter:[200/495], Time: 0.37, lr: [0.005490145240474599], Loss: 2.010806, Acc:0.797754, Semantic loss: 0.757296, BCE loss: 0.519066, SB loss: 0.734444
2023-10-30 12:40:23,421 Epoch: [235/484] Iter:[210/495], Time: 0.37, lr: [0.005489743700448273], Loss: 2.008025, Acc:0.797424, Semantic loss: 0.755455, BCE loss: 0.518720, SB loss: 0.733851
2023-10-30 12:40:27,054 Epoch: [235/484] Iter:[220/495], Time: 0.37, lr: [0.005489342157158576], Loss: 2.005109, Acc:0.796641, Semantic loss: 0.753623, BCE loss: 0.516144, SB loss: 0.735343
2023-10-30 12:40:30,725 Epoch: [235/484] Iter:[230/495], Time: 0.37, lr: [0.005488940610605214], Loss: 2.003672, Acc:0.797473, Semantic loss: 0.754274, BCE loss: 0.514234, SB loss: 0.735163
2023-10-30 12:40:34,381 Epoch: [235/484] Iter:[240/495], Time: 0.37, lr: [0.005488539060787896], Loss: 2.001253, Acc:0.797726, Semantic loss: 0.752230, BCE loss: 0.514745, SB loss: 0.734278
2023-10-30 12:40:38,092 Epoch: [235/484] Iter:[250/495], Time: 0.37, lr: [0.0054881375077063315], Loss: 1.995749, Acc:0.796917, Semantic loss: 0.750547, BCE loss: 0.512063, SB loss: 0.733139
2023-10-30 12:40:41,726 Epoch: [235/484] Iter:[260/495], Time: 0.37, lr: [0.0054877359513602255], Loss: 1.996816, Acc:0.796118, Semantic loss: 0.752370, BCE loss: 0.511654, SB loss: 0.732792
2023-10-30 12:40:45,378 Epoch: [235/484] Iter:[270/495], Time: 0.37, lr: [0.005487334391749288], Loss: 1.999567, Acc:0.794922, Semantic loss: 0.754410, BCE loss: 0.510648, SB loss: 0.734508
2023-10-30 12:40:49,068 Epoch: [235/484] Iter:[280/495], Time: 0.37, lr: [0.005486932828873227], Loss: 2.002039, Acc:0.795116, Semantic loss: 0.754416, BCE loss: 0.512406, SB loss: 0.735217
2023-10-30 12:40:52,696 Epoch: [235/484] Iter:[290/495], Time: 0.37, lr: [0.00548653126273175], Loss: 2.004582, Acc:0.793973, Semantic loss: 0.757305, BCE loss: 0.511176, SB loss: 0.736101
2023-10-30 12:40:56,379 Epoch: [235/484] Iter:[300/495], Time: 0.37, lr: [0.0054861296933245655], Loss: 2.005827, Acc:0.794330, Semantic loss: 0.757739, BCE loss: 0.512035, SB loss: 0.736053
2023-10-30 12:41:00,091 Epoch: [235/484] Iter:[310/495], Time: 0.37, lr: [0.005485728120651381], Loss: 2.009909, Acc:0.794084, Semantic loss: 0.759517, BCE loss: 0.513522, SB loss: 0.736870
2023-10-30 12:41:03,741 Epoch: [235/484] Iter:[320/495], Time: 0.37, lr: [0.005485326544711904], Loss: 2.009246, Acc:0.793927, Semantic loss: 0.758750, BCE loss: 0.514521, SB loss: 0.735975
2023-10-30 12:41:07,368 Epoch: [235/484] Iter:[330/495], Time: 0.37, lr: [0.005484924965505842], Loss: 2.010826, Acc:0.794030, Semantic loss: 0.759498, BCE loss: 0.515231, SB loss: 0.736097
2023-10-30 12:41:11,041 Epoch: [235/484] Iter:[340/495], Time: 0.37, lr: [0.005484523383032905], Loss: 2.010089, Acc:0.795131, Semantic loss: 0.758073, BCE loss: 0.516334, SB loss: 0.735682
2023-10-30 12:41:14,642 Epoch: [235/484] Iter:[350/495], Time: 0.37, lr: [0.005484121797292796], Loss: 2.010136, Acc:0.796065, Semantic loss: 0.758003, BCE loss: 0.517069, SB loss: 0.735064
2023-10-30 12:41:18,274 Epoch: [235/484] Iter:[360/495], Time: 0.37, lr: [0.005483720208285227], Loss: 2.010583, Acc:0.795888, Semantic loss: 0.758220, BCE loss: 0.517087, SB loss: 0.735276
2023-10-30 12:41:21,911 Epoch: [235/484] Iter:[370/495], Time: 0.37, lr: [0.005483318616009903], Loss: 2.016472, Acc:0.795139, Semantic loss: 0.763638, BCE loss: 0.516553, SB loss: 0.736282
2023-10-30 12:41:25,495 Epoch: [235/484] Iter:[380/495], Time: 0.37, lr: [0.0054829170204665325], Loss: 2.020110, Acc:0.794813, Semantic loss: 0.766600, BCE loss: 0.515898, SB loss: 0.737612
2023-10-30 12:41:29,117 Epoch: [235/484] Iter:[390/495], Time: 0.37, lr: [0.005482515421654823], Loss: 2.021861, Acc:0.794078, Semantic loss: 0.768469, BCE loss: 0.514812, SB loss: 0.738580
2023-10-30 12:41:32,753 Epoch: [235/484] Iter:[400/495], Time: 0.37, lr: [0.005482113819574482], Loss: 2.023550, Acc:0.793153, Semantic loss: 0.768212, BCE loss: 0.516310, SB loss: 0.739027
2023-10-30 12:41:36,312 Epoch: [235/484] Iter:[410/495], Time: 0.37, lr: [0.005481712214225217], Loss: 2.025301, Acc:0.792916, Semantic loss: 0.769170, BCE loss: 0.516664, SB loss: 0.739467
2023-10-30 12:41:39,866 Epoch: [235/484] Iter:[420/495], Time: 0.37, lr: [0.005481310605606735], Loss: 2.025382, Acc:0.793230, Semantic loss: 0.768859, BCE loss: 0.516989, SB loss: 0.739533
2023-10-30 12:41:43,496 Epoch: [235/484] Iter:[430/495], Time: 0.37, lr: [0.0054809089937187415], Loss: 2.023716, Acc:0.794097, Semantic loss: 0.767823, BCE loss: 0.516635, SB loss: 0.739258
2023-10-30 12:41:47,074 Epoch: [235/484] Iter:[440/495], Time: 0.37, lr: [0.005480507378560946], Loss: 2.022477, Acc:0.793942, Semantic loss: 0.767528, BCE loss: 0.515989, SB loss: 0.738960
2023-10-30 12:41:50,693 Epoch: [235/484] Iter:[450/495], Time: 0.37, lr: [0.005480105760133054], Loss: 2.023799, Acc:0.793712, Semantic loss: 0.768284, BCE loss: 0.516503, SB loss: 0.739012
2023-10-30 12:41:54,190 Epoch: [235/484] Iter:[460/495], Time: 0.37, lr: [0.005479704138434776], Loss: 2.025408, Acc:0.793773, Semantic loss: 0.768562, BCE loss: 0.517724, SB loss: 0.739123
2023-10-30 12:41:57,977 Epoch: [235/484] Iter:[470/495], Time: 0.37, lr: [0.005479302513465815], Loss: 2.024238, Acc:0.793801, Semantic loss: 0.767615, BCE loss: 0.517699, SB loss: 0.738924
2023-10-30 12:42:01,615 Epoch: [235/484] Iter:[480/495], Time: 0.37, lr: [0.00547890088522588], Loss: 2.024016, Acc:0.793798, Semantic loss: 0.767246, BCE loss: 0.518409, SB loss: 0.738360
2023-10-30 12:42:05,096 Epoch: [235/484] Iter:[490/495], Time: 0.37, lr: [0.005478499253714676], Loss: 2.025967, Acc:0.793751, Semantic loss: 0.767504, BCE loss: 0.519779, SB loss: 0.738685
2023-10-30 12:44:56,306 0 [8.25259203e-01 4.81473412e-01 7.79778947e-01 1.22432519e-01
 1.04310350e-01 3.49297594e-01 3.99558791e-01 5.33067337e-01
 8.28612328e-01 4.25728789e-01 8.39426761e-01 3.35002232e-01
 5.95973447e-02 4.92301627e-01 1.41146530e-04 8.46081587e-02
 5.55033140e-02 5.96242144e-02 4.78404078e-01] 0.38179621811562
2023-10-30 12:44:56,307 1 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632] 0.5718497295641957
2023-10-30 12:44:56,310 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:44:56,541 Loss: 2.457, MeanIU:  0.5718, Best_mIoU:  0.7151
2023-10-30 12:44:56,541 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632]
2023-10-30 12:44:58,422 Epoch: [236/484] Iter:[0/495], Time: 1.85, lr: [0.0054782984367322575], Loss: 2.521986, Acc:0.768689, Semantic loss: 1.037415, BCE loss: 0.600379, SB loss: 0.884192
2023-10-30 12:45:02,058 Epoch: [236/484] Iter:[10/495], Time: 0.50, lr: [0.005477896800313603], Loss: 2.088306, Acc:0.775498, Semantic loss: 0.789161, BCE loss: 0.542449, SB loss: 0.756696
2023-10-30 12:45:05,731 Epoch: [236/484] Iter:[20/495], Time: 0.44, lr: [0.005477495160622949], Loss: 2.192477, Acc:0.776034, Semantic loss: 0.839215, BCE loss: 0.576819, SB loss: 0.776443
2023-10-30 12:45:09,117 Epoch: [236/484] Iter:[30/495], Time: 0.40, lr: [0.005477093517659999], Loss: 2.159301, Acc:0.792384, Semantic loss: 0.822233, BCE loss: 0.569972, SB loss: 0.767095
2023-10-30 12:45:12,539 Epoch: [236/484] Iter:[40/495], Time: 0.39, lr: [0.005476691871424464], Loss: 2.076993, Acc:0.796209, Semantic loss: 0.776733, BCE loss: 0.556271, SB loss: 0.743989
2023-10-30 12:45:15,937 Epoch: [236/484] Iter:[50/495], Time: 0.38, lr: [0.005476290221916049], Loss: 2.062178, Acc:0.798028, Semantic loss: 0.764882, BCE loss: 0.551973, SB loss: 0.745323
2023-10-30 12:45:19,501 Epoch: [236/484] Iter:[60/495], Time: 0.38, lr: [0.005475888569134461], Loss: 2.068031, Acc:0.795209, Semantic loss: 0.777962, BCE loss: 0.541909, SB loss: 0.748160
2023-10-30 12:45:23,071 Epoch: [236/484] Iter:[70/495], Time: 0.37, lr: [0.005475486913079404], Loss: 2.057807, Acc:0.799553, Semantic loss: 0.774631, BCE loss: 0.541164, SB loss: 0.742012
2023-10-30 12:45:26,519 Epoch: [236/484] Iter:[80/495], Time: 0.37, lr: [0.005475085253750587], Loss: 2.062704, Acc:0.798314, Semantic loss: 0.774383, BCE loss: 0.541335, SB loss: 0.746986
2023-10-30 12:45:30,047 Epoch: [236/484] Iter:[90/495], Time: 0.37, lr: [0.005474683591147715], Loss: 2.092516, Acc:0.795417, Semantic loss: 0.795525, BCE loss: 0.541841, SB loss: 0.755150
2023-10-30 12:45:33,616 Epoch: [236/484] Iter:[100/495], Time: 0.37, lr: [0.005474281925270497], Loss: 2.090660, Acc:0.797136, Semantic loss: 0.793149, BCE loss: 0.546386, SB loss: 0.751125
2023-10-30 12:45:37,131 Epoch: [236/484] Iter:[110/495], Time: 0.37, lr: [0.005473880256118635], Loss: 2.090883, Acc:0.795188, Semantic loss: 0.790589, BCE loss: 0.550269, SB loss: 0.750024
2023-10-30 12:45:40,686 Epoch: [236/484] Iter:[120/495], Time: 0.36, lr: [0.00547347858369184], Loss: 2.073638, Acc:0.793084, Semantic loss: 0.783095, BCE loss: 0.542956, SB loss: 0.747587
2023-10-30 12:45:44,192 Epoch: [236/484] Iter:[130/495], Time: 0.36, lr: [0.005473076907989816], Loss: 2.080509, Acc:0.794691, Semantic loss: 0.789298, BCE loss: 0.543954, SB loss: 0.747257
2023-10-30 12:45:47,681 Epoch: [236/484] Iter:[140/495], Time: 0.36, lr: [0.00547267522901227], Loss: 2.079401, Acc:0.795550, Semantic loss: 0.785933, BCE loss: 0.546166, SB loss: 0.747302
2023-10-30 12:45:51,202 Epoch: [236/484] Iter:[150/495], Time: 0.36, lr: [0.005472273546758906], Loss: 2.072329, Acc:0.795629, Semantic loss: 0.781600, BCE loss: 0.545073, SB loss: 0.745656
2023-10-30 12:45:54,689 Epoch: [236/484] Iter:[160/495], Time: 0.36, lr: [0.005471871861229433], Loss: 2.069718, Acc:0.792498, Semantic loss: 0.780962, BCE loss: 0.542365, SB loss: 0.746392
2023-10-30 12:45:58,256 Epoch: [236/484] Iter:[170/495], Time: 0.36, lr: [0.005471470172423554], Loss: 2.060321, Acc:0.791697, Semantic loss: 0.776928, BCE loss: 0.538745, SB loss: 0.744648
2023-10-30 12:46:01,917 Epoch: [236/484] Iter:[180/495], Time: 0.36, lr: [0.005471068480340978], Loss: 2.067656, Acc:0.790756, Semantic loss: 0.780841, BCE loss: 0.540787, SB loss: 0.746028
2023-10-30 12:46:05,482 Epoch: [236/484] Iter:[190/495], Time: 0.36, lr: [0.005470666784981409], Loss: 2.066778, Acc:0.792749, Semantic loss: 0.778370, BCE loss: 0.542141, SB loss: 0.746268
2023-10-30 12:46:09,257 Epoch: [236/484] Iter:[200/495], Time: 0.36, lr: [0.005470265086344553], Loss: 2.064977, Acc:0.790754, Semantic loss: 0.777075, BCE loss: 0.541605, SB loss: 0.746297
2023-10-30 12:46:12,796 Epoch: [236/484] Iter:[210/495], Time: 0.36, lr: [0.005469863384430118], Loss: 2.065874, Acc:0.791284, Semantic loss: 0.776241, BCE loss: 0.543254, SB loss: 0.746379
2023-10-30 12:46:16,498 Epoch: [236/484] Iter:[220/495], Time: 0.36, lr: [0.005469461679237807], Loss: 2.059287, Acc:0.791873, Semantic loss: 0.773405, BCE loss: 0.540255, SB loss: 0.745626
2023-10-30 12:46:20,160 Epoch: [236/484] Iter:[230/495], Time: 0.36, lr: [0.005469059970767329], Loss: 2.057306, Acc:0.792070, Semantic loss: 0.772287, BCE loss: 0.540002, SB loss: 0.745017
2023-10-30 12:46:23,701 Epoch: [236/484] Iter:[240/495], Time: 0.36, lr: [0.005468658259018385], Loss: 2.054661, Acc:0.791631, Semantic loss: 0.772883, BCE loss: 0.536959, SB loss: 0.744819
2023-10-30 12:46:27,222 Epoch: [236/484] Iter:[250/495], Time: 0.36, lr: [0.0054682565439906836], Loss: 2.061058, Acc:0.791396, Semantic loss: 0.775809, BCE loss: 0.539257, SB loss: 0.745992
2023-10-30 12:46:30,814 Epoch: [236/484] Iter:[260/495], Time: 0.36, lr: [0.005467854825683932], Loss: 2.058811, Acc:0.791684, Semantic loss: 0.774469, BCE loss: 0.538113, SB loss: 0.746229
2023-10-30 12:46:34,487 Epoch: [236/484] Iter:[270/495], Time: 0.36, lr: [0.005467453104097832], Loss: 2.060068, Acc:0.792614, Semantic loss: 0.772954, BCE loss: 0.541148, SB loss: 0.745966
2023-10-30 12:46:38,024 Epoch: [236/484] Iter:[280/495], Time: 0.36, lr: [0.005467051379232092], Loss: 2.058670, Acc:0.794655, Semantic loss: 0.772305, BCE loss: 0.541084, SB loss: 0.745281
2023-10-30 12:46:41,583 Epoch: [236/484] Iter:[290/495], Time: 0.36, lr: [0.005466649651086417], Loss: 2.062037, Acc:0.794732, Semantic loss: 0.775828, BCE loss: 0.540723, SB loss: 0.745486
2023-10-30 12:46:45,136 Epoch: [236/484] Iter:[300/495], Time: 0.36, lr: [0.0054662479196605105], Loss: 2.061078, Acc:0.795270, Semantic loss: 0.774737, BCE loss: 0.541531, SB loss: 0.744810
2023-10-30 12:46:48,699 Epoch: [236/484] Iter:[310/495], Time: 0.36, lr: [0.005465846184954081], Loss: 2.072333, Acc:0.795448, Semantic loss: 0.780841, BCE loss: 0.544430, SB loss: 0.747062
2023-10-30 12:46:52,230 Epoch: [236/484] Iter:[320/495], Time: 0.36, lr: [0.005465444446966831], Loss: 2.069802, Acc:0.795445, Semantic loss: 0.778820, BCE loss: 0.544571, SB loss: 0.746410
2023-10-30 12:46:55,812 Epoch: [236/484] Iter:[330/495], Time: 0.36, lr: [0.0054650427056984665], Loss: 2.064783, Acc:0.794477, Semantic loss: 0.776173, BCE loss: 0.543234, SB loss: 0.745376
2023-10-30 12:46:59,312 Epoch: [236/484] Iter:[340/495], Time: 0.36, lr: [0.005464640961148692], Loss: 2.068154, Acc:0.793624, Semantic loss: 0.776814, BCE loss: 0.544832, SB loss: 0.746507
2023-10-30 12:47:02,980 Epoch: [236/484] Iter:[350/495], Time: 0.36, lr: [0.005464239213317215], Loss: 2.064404, Acc:0.794352, Semantic loss: 0.774584, BCE loss: 0.543560, SB loss: 0.746261
2023-10-30 12:47:06,555 Epoch: [236/484] Iter:[360/495], Time: 0.36, lr: [0.005463837462203739], Loss: 2.065394, Acc:0.795510, Semantic loss: 0.775150, BCE loss: 0.544235, SB loss: 0.746010
2023-10-30 12:47:10,190 Epoch: [236/484] Iter:[370/495], Time: 0.36, lr: [0.0054634357078079685], Loss: 2.065699, Acc:0.795565, Semantic loss: 0.776425, BCE loss: 0.542895, SB loss: 0.746379
2023-10-30 12:47:13,703 Epoch: [236/484] Iter:[380/495], Time: 0.36, lr: [0.005463033950129611], Loss: 2.066776, Acc:0.796634, Semantic loss: 0.777193, BCE loss: 0.542772, SB loss: 0.746811
2023-10-30 12:47:17,350 Epoch: [236/484] Iter:[390/495], Time: 0.36, lr: [0.005462632189168369], Loss: 2.066247, Acc:0.795648, Semantic loss: 0.777432, BCE loss: 0.541750, SB loss: 0.747065
2023-10-30 12:47:20,968 Epoch: [236/484] Iter:[400/495], Time: 0.36, lr: [0.005462230424923946], Loss: 2.061534, Acc:0.795623, Semantic loss: 0.774475, BCE loss: 0.541371, SB loss: 0.745688
2023-10-30 12:47:24,662 Epoch: [236/484] Iter:[410/495], Time: 0.36, lr: [0.005461828657396052], Loss: 2.058773, Acc:0.795416, Semantic loss: 0.773183, BCE loss: 0.540131, SB loss: 0.745459
2023-10-30 12:47:28,325 Epoch: [236/484] Iter:[420/495], Time: 0.36, lr: [0.005461426886584387], Loss: 2.055974, Acc:0.796186, Semantic loss: 0.772006, BCE loss: 0.539587, SB loss: 0.744381
2023-10-30 12:47:31,910 Epoch: [236/484] Iter:[430/495], Time: 0.36, lr: [0.005461025112488657], Loss: 2.060515, Acc:0.796793, Semantic loss: 0.774469, BCE loss: 0.541203, SB loss: 0.744843
2023-10-30 12:47:35,991 Epoch: [236/484] Iter:[440/495], Time: 0.36, lr: [0.005460623335108569], Loss: 2.057344, Acc:0.796759, Semantic loss: 0.773034, BCE loss: 0.539969, SB loss: 0.744342
2023-10-30 12:47:39,570 Epoch: [236/484] Iter:[450/495], Time: 0.36, lr: [0.0054602215544438245], Loss: 2.053494, Acc:0.796930, Semantic loss: 0.770330, BCE loss: 0.540322, SB loss: 0.742841
2023-10-30 12:47:43,245 Epoch: [236/484] Iter:[460/495], Time: 0.36, lr: [0.00545981977049413], Loss: 2.052789, Acc:0.797575, Semantic loss: 0.770749, BCE loss: 0.540018, SB loss: 0.742023
2023-10-30 12:47:46,766 Epoch: [236/484] Iter:[470/495], Time: 0.36, lr: [0.00545941798325919], Loss: 2.051653, Acc:0.798011, Semantic loss: 0.770364, BCE loss: 0.539466, SB loss: 0.741822
2023-10-30 12:47:50,394 Epoch: [236/484] Iter:[480/495], Time: 0.36, lr: [0.005459016192738706], Loss: 2.051396, Acc:0.798343, Semantic loss: 0.770668, BCE loss: 0.539049, SB loss: 0.741679
2023-10-30 12:47:53,858 Epoch: [236/484] Iter:[490/495], Time: 0.36, lr: [0.005458614398932387], Loss: 2.048663, Acc:0.798373, Semantic loss: 0.769112, BCE loss: 0.538827, SB loss: 0.740724
2023-10-30 12:47:55,474 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:47:55,713 Loss: 2.457, MeanIU:  0.5718, Best_mIoU:  0.7151
2023-10-30 12:47:55,714 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632]
2023-10-30 12:47:57,513 Epoch: [237/484] Iter:[0/495], Time: 1.77, lr: [0.005458413500796946], Loss: 2.118395, Acc:0.766951, Semantic loss: 0.762069, BCE loss: 0.587869, SB loss: 0.768457
2023-10-30 12:48:01,782 Epoch: [237/484] Iter:[10/495], Time: 0.55, lr: [0.005458011702061317], Loss: 1.986013, Acc:0.813933, Semantic loss: 0.714940, BCE loss: 0.559717, SB loss: 0.711356
2023-10-30 12:48:05,372 Epoch: [237/484] Iter:[20/495], Time: 0.46, lr: [0.00545760990003911], Loss: 1.949141, Acc:0.822713, Semantic loss: 0.679186, BCE loss: 0.566412, SB loss: 0.703542
2023-10-30 12:48:09,029 Epoch: [237/484] Iter:[30/495], Time: 0.43, lr: [0.005457208094730033], Loss: 2.021226, Acc:0.813265, Semantic loss: 0.735146, BCE loss: 0.557075, SB loss: 0.729006
2023-10-30 12:48:12,680 Epoch: [237/484] Iter:[40/495], Time: 0.41, lr: [0.0054568062861337875], Loss: 2.012323, Acc:0.803846, Semantic loss: 0.744606, BCE loss: 0.542014, SB loss: 0.725703
2023-10-30 12:48:16,611 Epoch: [237/484] Iter:[50/495], Time: 0.41, lr: [0.005456404474250078], Loss: 2.010217, Acc:0.803951, Semantic loss: 0.748167, BCE loss: 0.536357, SB loss: 0.725693
2023-10-30 12:48:20,247 Epoch: [237/484] Iter:[60/495], Time: 0.40, lr: [0.005456002659078611], Loss: 2.008470, Acc:0.803898, Semantic loss: 0.748423, BCE loss: 0.528922, SB loss: 0.731125
2023-10-30 12:48:23,871 Epoch: [237/484] Iter:[70/495], Time: 0.40, lr: [0.005455600840619085], Loss: 2.004148, Acc:0.803028, Semantic loss: 0.746940, BCE loss: 0.524949, SB loss: 0.732259
2023-10-30 12:48:27,491 Epoch: [237/484] Iter:[80/495], Time: 0.39, lr: [0.00545519901887121], Loss: 2.013733, Acc:0.805756, Semantic loss: 0.755061, BCE loss: 0.525841, SB loss: 0.732832
2023-10-30 12:48:31,092 Epoch: [237/484] Iter:[90/495], Time: 0.39, lr: [0.005454797193834686], Loss: 2.031180, Acc:0.806483, Semantic loss: 0.768563, BCE loss: 0.523548, SB loss: 0.739069
2023-10-30 12:48:34,750 Epoch: [237/484] Iter:[100/495], Time: 0.39, lr: [0.005454395365509219], Loss: 2.011728, Acc:0.806105, Semantic loss: 0.758416, BCE loss: 0.518905, SB loss: 0.734406
2023-10-30 12:48:38,374 Epoch: [237/484] Iter:[110/495], Time: 0.38, lr: [0.0054539935338945135], Loss: 2.006346, Acc:0.802560, Semantic loss: 0.756901, BCE loss: 0.517914, SB loss: 0.731532
2023-10-30 12:48:41,947 Epoch: [237/484] Iter:[120/495], Time: 0.38, lr: [0.005453591698990273], Loss: 2.025187, Acc:0.802929, Semantic loss: 0.767355, BCE loss: 0.522948, SB loss: 0.734884
2023-10-30 12:48:45,633 Epoch: [237/484] Iter:[130/495], Time: 0.38, lr: [0.005453189860796197], Loss: 2.033789, Acc:0.800697, Semantic loss: 0.768675, BCE loss: 0.529416, SB loss: 0.735698
2023-10-30 12:48:49,258 Epoch: [237/484] Iter:[140/495], Time: 0.38, lr: [0.005452788019311995], Loss: 2.032231, Acc:0.800249, Semantic loss: 0.765567, BCE loss: 0.530908, SB loss: 0.735756
2023-10-30 12:48:52,781 Epoch: [237/484] Iter:[150/495], Time: 0.38, lr: [0.005452386174537367], Loss: 2.022711, Acc:0.799148, Semantic loss: 0.759456, BCE loss: 0.532478, SB loss: 0.730777
2023-10-30 12:48:56,283 Epoch: [237/484] Iter:[160/495], Time: 0.38, lr: [0.005451984326472017], Loss: 2.020775, Acc:0.798730, Semantic loss: 0.757780, BCE loss: 0.533172, SB loss: 0.729823
2023-10-30 12:48:59,859 Epoch: [237/484] Iter:[170/495], Time: 0.37, lr: [0.005451582475115651], Loss: 2.023829, Acc:0.798798, Semantic loss: 0.758276, BCE loss: 0.535139, SB loss: 0.730414
2023-10-30 12:49:03,543 Epoch: [237/484] Iter:[180/495], Time: 0.37, lr: [0.00545118062046797], Loss: 2.025764, Acc:0.797914, Semantic loss: 0.759652, BCE loss: 0.535871, SB loss: 0.730241
2023-10-30 12:49:07,131 Epoch: [237/484] Iter:[190/495], Time: 0.37, lr: [0.005450778762528679], Loss: 2.019208, Acc:0.797995, Semantic loss: 0.755604, BCE loss: 0.533910, SB loss: 0.729694
2023-10-30 12:49:10,760 Epoch: [237/484] Iter:[200/495], Time: 0.37, lr: [0.00545037690129748], Loss: 2.013812, Acc:0.798873, Semantic loss: 0.751977, BCE loss: 0.533868, SB loss: 0.727967
2023-10-30 12:49:14,303 Epoch: [237/484] Iter:[210/495], Time: 0.37, lr: [0.005449975036774079], Loss: 2.008834, Acc:0.798137, Semantic loss: 0.749420, BCE loss: 0.531854, SB loss: 0.727560
2023-10-30 12:49:17,903 Epoch: [237/484] Iter:[220/495], Time: 0.37, lr: [0.005449573168958174], Loss: 2.012593, Acc:0.798689, Semantic loss: 0.750615, BCE loss: 0.532790, SB loss: 0.729189
2023-10-30 12:49:21,475 Epoch: [237/484] Iter:[230/495], Time: 0.37, lr: [0.005449171297849473], Loss: 2.012876, Acc:0.799004, Semantic loss: 0.751901, BCE loss: 0.531834, SB loss: 0.729140
2023-10-30 12:49:25,088 Epoch: [237/484] Iter:[240/495], Time: 0.37, lr: [0.005448769423447678], Loss: 2.013662, Acc:0.798647, Semantic loss: 0.751962, BCE loss: 0.531254, SB loss: 0.730447
2023-10-30 12:49:28,730 Epoch: [237/484] Iter:[250/495], Time: 0.37, lr: [0.005448367545752492], Loss: 2.012864, Acc:0.800133, Semantic loss: 0.750989, BCE loss: 0.532537, SB loss: 0.729338
2023-10-30 12:49:32,385 Epoch: [237/484] Iter:[260/495], Time: 0.37, lr: [0.005447965664763617], Loss: 2.009720, Acc:0.799737, Semantic loss: 0.749477, BCE loss: 0.531578, SB loss: 0.728666
2023-10-30 12:49:35,974 Epoch: [237/484] Iter:[270/495], Time: 0.37, lr: [0.005447563780480759], Loss: 2.014713, Acc:0.800785, Semantic loss: 0.751967, BCE loss: 0.532179, SB loss: 0.730567
2023-10-30 12:49:39,508 Epoch: [237/484] Iter:[280/495], Time: 0.37, lr: [0.005447161892903618], Loss: 2.014213, Acc:0.800739, Semantic loss: 0.753108, BCE loss: 0.529933, SB loss: 0.731172
2023-10-30 12:49:43,129 Epoch: [237/484] Iter:[290/495], Time: 0.37, lr: [0.005446760002031898], Loss: 2.012503, Acc:0.799767, Semantic loss: 0.753264, BCE loss: 0.527642, SB loss: 0.731597
2023-10-30 12:49:46,785 Epoch: [237/484] Iter:[300/495], Time: 0.37, lr: [0.005446358107865301], Loss: 2.014354, Acc:0.800965, Semantic loss: 0.753823, BCE loss: 0.528764, SB loss: 0.731767
2023-10-30 12:49:50,412 Epoch: [237/484] Iter:[310/495], Time: 0.37, lr: [0.005445956210403532], Loss: 2.011600, Acc:0.801162, Semantic loss: 0.751844, BCE loss: 0.527691, SB loss: 0.732065
2023-10-30 12:49:54,109 Epoch: [237/484] Iter:[320/495], Time: 0.37, lr: [0.005445554309646291], Loss: 2.011657, Acc:0.801174, Semantic loss: 0.751913, BCE loss: 0.527790, SB loss: 0.731954
2023-10-30 12:49:57,690 Epoch: [237/484] Iter:[330/495], Time: 0.37, lr: [0.005445152405593283], Loss: 2.013607, Acc:0.800631, Semantic loss: 0.752094, BCE loss: 0.529859, SB loss: 0.731654
2023-10-30 12:50:01,304 Epoch: [237/484] Iter:[340/495], Time: 0.37, lr: [0.00544475049824421], Loss: 2.018230, Acc:0.800446, Semantic loss: 0.753612, BCE loss: 0.532464, SB loss: 0.732154
2023-10-30 12:50:04,822 Epoch: [237/484] Iter:[350/495], Time: 0.37, lr: [0.005444348587598774], Loss: 2.018254, Acc:0.799161, Semantic loss: 0.754278, BCE loss: 0.532273, SB loss: 0.731703
2023-10-30 12:50:08,476 Epoch: [237/484] Iter:[360/495], Time: 0.37, lr: [0.005443946673656679], Loss: 2.018309, Acc:0.798820, Semantic loss: 0.754696, BCE loss: 0.531797, SB loss: 0.731816
2023-10-30 12:50:12,136 Epoch: [237/484] Iter:[370/495], Time: 0.37, lr: [0.005443544756417626], Loss: 2.021041, Acc:0.798353, Semantic loss: 0.757066, BCE loss: 0.532395, SB loss: 0.731579
2023-10-30 12:50:15,865 Epoch: [237/484] Iter:[380/495], Time: 0.37, lr: [0.005443142835881319], Loss: 2.018501, Acc:0.797947, Semantic loss: 0.756153, BCE loss: 0.530999, SB loss: 0.731349
2023-10-30 12:50:19,446 Epoch: [237/484] Iter:[390/495], Time: 0.37, lr: [0.005442740912047458], Loss: 2.025657, Acc:0.798136, Semantic loss: 0.759486, BCE loss: 0.533083, SB loss: 0.733089
2023-10-30 12:50:23,099 Epoch: [237/484] Iter:[400/495], Time: 0.37, lr: [0.005442338984915747], Loss: 2.026158, Acc:0.798290, Semantic loss: 0.759910, BCE loss: 0.532770, SB loss: 0.733478
2023-10-30 12:50:26,700 Epoch: [237/484] Iter:[410/495], Time: 0.37, lr: [0.005441937054485888], Loss: 2.030669, Acc:0.798168, Semantic loss: 0.762550, BCE loss: 0.533483, SB loss: 0.734636
2023-10-30 12:50:30,282 Epoch: [237/484] Iter:[420/495], Time: 0.37, lr: [0.0054415351207575844], Loss: 2.030783, Acc:0.798803, Semantic loss: 0.762830, BCE loss: 0.533188, SB loss: 0.734765
2023-10-30 12:50:33,977 Epoch: [237/484] Iter:[430/495], Time: 0.37, lr: [0.005441133183730538], Loss: 2.033010, Acc:0.798523, Semantic loss: 0.763868, BCE loss: 0.534138, SB loss: 0.735003
2023-10-30 12:50:37,661 Epoch: [237/484] Iter:[440/495], Time: 0.37, lr: [0.00544073124340445], Loss: 2.033311, Acc:0.798254, Semantic loss: 0.763958, BCE loss: 0.534460, SB loss: 0.734894
2023-10-30 12:50:41,282 Epoch: [237/484] Iter:[450/495], Time: 0.37, lr: [0.0054403292997790235], Loss: 2.033817, Acc:0.797957, Semantic loss: 0.763571, BCE loss: 0.535045, SB loss: 0.735201
2023-10-30 12:50:44,949 Epoch: [237/484] Iter:[460/495], Time: 0.37, lr: [0.0054399273528539585], Loss: 2.030869, Acc:0.797441, Semantic loss: 0.761696, BCE loss: 0.534729, SB loss: 0.734444
2023-10-30 12:50:48,597 Epoch: [237/484] Iter:[470/495], Time: 0.37, lr: [0.005439525402628959], Loss: 2.034633, Acc:0.797813, Semantic loss: 0.763135, BCE loss: 0.535482, SB loss: 0.736017
2023-10-30 12:50:52,138 Epoch: [237/484] Iter:[480/495], Time: 0.37, lr: [0.005439123449103727], Loss: 2.037386, Acc:0.797848, Semantic loss: 0.763894, BCE loss: 0.536475, SB loss: 0.737017
2023-10-30 12:50:55,592 Epoch: [237/484] Iter:[490/495], Time: 0.37, lr: [0.005438721492277964], Loss: 2.038838, Acc:0.797808, Semantic loss: 0.765021, BCE loss: 0.536605, SB loss: 0.737213
2023-10-30 12:50:56,963 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:50:57,201 Loss: 2.457, MeanIU:  0.5718, Best_mIoU:  0.7151
2023-10-30 12:50:57,201 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632]
2023-10-30 12:50:58,941 Epoch: [238/484] Iter:[0/495], Time: 1.71, lr: [0.005438520512627289], Loss: 1.726174, Acc:0.665159, Semantic loss: 0.688487, BCE loss: 0.337685, SB loss: 0.700002
2023-10-30 12:51:02,860 Epoch: [238/484] Iter:[10/495], Time: 0.51, lr: [0.005438118550850171], Loss: 1.972982, Acc:0.793661, Semantic loss: 0.728568, BCE loss: 0.516764, SB loss: 0.727651
2023-10-30 12:51:06,538 Epoch: [238/484] Iter:[20/495], Time: 0.44, lr: [0.005437716585771776], Loss: 1.991697, Acc:0.807856, Semantic loss: 0.750639, BCE loss: 0.515056, SB loss: 0.726002
2023-10-30 12:51:10,156 Epoch: [238/484] Iter:[30/495], Time: 0.42, lr: [0.0054373146173918065], Loss: 2.010979, Acc:0.802361, Semantic loss: 0.751963, BCE loss: 0.525166, SB loss: 0.733849
2023-10-30 12:51:13,848 Epoch: [238/484] Iter:[40/495], Time: 0.41, lr: [0.005436912645709962], Loss: 2.012296, Acc:0.802310, Semantic loss: 0.748007, BCE loss: 0.531094, SB loss: 0.733195
2023-10-30 12:51:17,464 Epoch: [238/484] Iter:[50/495], Time: 0.40, lr: [0.005436510670725948], Loss: 2.039352, Acc:0.804105, Semantic loss: 0.759626, BCE loss: 0.542359, SB loss: 0.737367
2023-10-30 12:51:21,066 Epoch: [238/484] Iter:[60/495], Time: 0.39, lr: [0.005436108692439462], Loss: 2.029555, Acc:0.803366, Semantic loss: 0.758432, BCE loss: 0.537161, SB loss: 0.733962
2023-10-30 12:51:24,614 Epoch: [238/484] Iter:[70/495], Time: 0.39, lr: [0.00543570671085021], Loss: 2.020197, Acc:0.802839, Semantic loss: 0.750758, BCE loss: 0.536629, SB loss: 0.732810
2023-10-30 12:51:28,212 Epoch: [238/484] Iter:[80/495], Time: 0.38, lr: [0.00543530472595789], Loss: 2.031302, Acc:0.806243, Semantic loss: 0.756601, BCE loss: 0.538606, SB loss: 0.736095
2023-10-30 12:51:31,796 Epoch: [238/484] Iter:[90/495], Time: 0.38, lr: [0.005434902737762205], Loss: 2.012834, Acc:0.806082, Semantic loss: 0.750438, BCE loss: 0.532854, SB loss: 0.729541
2023-10-30 12:51:35,408 Epoch: [238/484] Iter:[100/495], Time: 0.38, lr: [0.005434500746262856], Loss: 2.021450, Acc:0.805920, Semantic loss: 0.755849, BCE loss: 0.532807, SB loss: 0.732794
2023-10-30 12:51:38,997 Epoch: [238/484] Iter:[110/495], Time: 0.38, lr: [0.005434098751459544], Loss: 2.022762, Acc:0.806827, Semantic loss: 0.759967, BCE loss: 0.529442, SB loss: 0.733353
2023-10-30 12:51:42,499 Epoch: [238/484] Iter:[120/495], Time: 0.37, lr: [0.0054336967533519685], Loss: 2.016208, Acc:0.803905, Semantic loss: 0.757895, BCE loss: 0.526965, SB loss: 0.731347
2023-10-30 12:51:45,991 Epoch: [238/484] Iter:[130/495], Time: 0.37, lr: [0.005433294751939836], Loss: 2.010851, Acc:0.800490, Semantic loss: 0.756254, BCE loss: 0.524012, SB loss: 0.730584
2023-10-30 12:51:49,623 Epoch: [238/484] Iter:[140/495], Time: 0.37, lr: [0.005432892747222842], Loss: 2.002085, Acc:0.800235, Semantic loss: 0.753578, BCE loss: 0.520195, SB loss: 0.728312
2023-10-30 12:51:53,299 Epoch: [238/484] Iter:[150/495], Time: 0.37, lr: [0.005432490739200691], Loss: 2.009561, Acc:0.799339, Semantic loss: 0.761498, BCE loss: 0.519133, SB loss: 0.728929
2023-10-30 12:51:56,854 Epoch: [238/484] Iter:[160/495], Time: 0.37, lr: [0.005432088727873082], Loss: 2.010459, Acc:0.798798, Semantic loss: 0.762539, BCE loss: 0.517216, SB loss: 0.730704
2023-10-30 12:52:00,469 Epoch: [238/484] Iter:[170/495], Time: 0.37, lr: [0.005431686713239719], Loss: 2.012753, Acc:0.798661, Semantic loss: 0.762923, BCE loss: 0.516987, SB loss: 0.732843
2023-10-30 12:52:04,127 Epoch: [238/484] Iter:[180/495], Time: 0.37, lr: [0.005431284695300301], Loss: 2.009492, Acc:0.799293, Semantic loss: 0.761040, BCE loss: 0.517164, SB loss: 0.731288
2023-10-30 12:52:07,707 Epoch: [238/484] Iter:[190/495], Time: 0.37, lr: [0.005430882674054527], Loss: 2.014711, Acc:0.801400, Semantic loss: 0.764530, BCE loss: 0.518039, SB loss: 0.732143
2023-10-30 12:52:11,323 Epoch: [238/484] Iter:[200/495], Time: 0.37, lr: [0.005430480649502099], Loss: 2.012268, Acc:0.801393, Semantic loss: 0.760965, BCE loss: 0.520274, SB loss: 0.731030
2023-10-30 12:52:14,993 Epoch: [238/484] Iter:[210/495], Time: 0.37, lr: [0.005430078621642721], Loss: 2.012384, Acc:0.801759, Semantic loss: 0.761943, BCE loss: 0.520717, SB loss: 0.729724
2023-10-30 12:52:18,656 Epoch: [238/484] Iter:[220/495], Time: 0.37, lr: [0.00542967659047609], Loss: 2.014950, Acc:0.802548, Semantic loss: 0.762692, BCE loss: 0.522810, SB loss: 0.729449
2023-10-30 12:52:22,253 Epoch: [238/484] Iter:[230/495], Time: 0.37, lr: [0.005429274556001908], Loss: 2.024416, Acc:0.802185, Semantic loss: 0.767925, BCE loss: 0.524504, SB loss: 0.731987
2023-10-30 12:52:25,915 Epoch: [238/484] Iter:[240/495], Time: 0.37, lr: [0.005428872518219877], Loss: 2.023075, Acc:0.802853, Semantic loss: 0.766902, BCE loss: 0.524440, SB loss: 0.731733
2023-10-30 12:52:29,449 Epoch: [238/484] Iter:[250/495], Time: 0.37, lr: [0.005428470477129696], Loss: 2.025198, Acc:0.803065, Semantic loss: 0.768724, BCE loss: 0.523912, SB loss: 0.732562
2023-10-30 12:52:33,042 Epoch: [238/484] Iter:[260/495], Time: 0.37, lr: [0.005428068432731066], Loss: 2.016838, Acc:0.803387, Semantic loss: 0.764134, BCE loss: 0.522663, SB loss: 0.730041
2023-10-30 12:52:36,640 Epoch: [238/484] Iter:[270/495], Time: 0.37, lr: [0.005427666385023686], Loss: 2.018053, Acc:0.802788, Semantic loss: 0.764370, BCE loss: 0.523581, SB loss: 0.730102
2023-10-30 12:52:40,215 Epoch: [238/484] Iter:[280/495], Time: 0.37, lr: [0.005427264334007258], Loss: 2.018041, Acc:0.801260, Semantic loss: 0.764779, BCE loss: 0.522101, SB loss: 0.731161
2023-10-30 12:52:43,870 Epoch: [238/484] Iter:[290/495], Time: 0.37, lr: [0.005426862279681483], Loss: 2.019200, Acc:0.801942, Semantic loss: 0.763883, BCE loss: 0.523727, SB loss: 0.731590
2023-10-30 12:52:47,391 Epoch: [238/484] Iter:[300/495], Time: 0.37, lr: [0.005426460222046059], Loss: 2.025260, Acc:0.801875, Semantic loss: 0.766437, BCE loss: 0.526330, SB loss: 0.732493
2023-10-30 12:52:51,097 Epoch: [238/484] Iter:[310/495], Time: 0.37, lr: [0.0054260581611006884], Loss: 2.023871, Acc:0.801796, Semantic loss: 0.765488, BCE loss: 0.526758, SB loss: 0.731625
2023-10-30 12:52:54,856 Epoch: [238/484] Iter:[320/495], Time: 0.37, lr: [0.005425656096845072], Loss: 2.025823, Acc:0.801173, Semantic loss: 0.766572, BCE loss: 0.527426, SB loss: 0.731824
2023-10-30 12:52:58,526 Epoch: [238/484] Iter:[330/495], Time: 0.37, lr: [0.0054252540292789074], Loss: 2.027797, Acc:0.801716, Semantic loss: 0.767676, BCE loss: 0.527207, SB loss: 0.732914
2023-10-30 12:53:02,108 Epoch: [238/484] Iter:[340/495], Time: 0.37, lr: [0.005424851958401897], Loss: 2.025476, Acc:0.801754, Semantic loss: 0.766131, BCE loss: 0.526060, SB loss: 0.733286
2023-10-30 12:53:05,783 Epoch: [238/484] Iter:[350/495], Time: 0.37, lr: [0.00542444988421374], Loss: 2.026642, Acc:0.802141, Semantic loss: 0.767074, BCE loss: 0.526497, SB loss: 0.733071
2023-10-30 12:53:09,336 Epoch: [238/484] Iter:[360/495], Time: 0.37, lr: [0.005424047806714135], Loss: 2.028276, Acc:0.801844, Semantic loss: 0.767039, BCE loss: 0.527658, SB loss: 0.733580
2023-10-30 12:53:12,903 Epoch: [238/484] Iter:[370/495], Time: 0.37, lr: [0.005423645725902785], Loss: 2.029307, Acc:0.800975, Semantic loss: 0.767985, BCE loss: 0.527185, SB loss: 0.734137
2023-10-30 12:53:16,616 Epoch: [238/484] Iter:[380/495], Time: 0.37, lr: [0.005423243641779387], Loss: 2.031194, Acc:0.800172, Semantic loss: 0.769128, BCE loss: 0.526705, SB loss: 0.735361
2023-10-30 12:53:20,283 Epoch: [238/484] Iter:[390/495], Time: 0.37, lr: [0.005422841554343644], Loss: 2.032555, Acc:0.799632, Semantic loss: 0.768750, BCE loss: 0.527314, SB loss: 0.736491
2023-10-30 12:53:23,955 Epoch: [238/484] Iter:[400/495], Time: 0.37, lr: [0.005422439463595253], Loss: 2.036961, Acc:0.798512, Semantic loss: 0.771402, BCE loss: 0.528056, SB loss: 0.737503
2023-10-30 12:53:27,576 Epoch: [238/484] Iter:[410/495], Time: 0.37, lr: [0.005422037369533914], Loss: 2.034224, Acc:0.797847, Semantic loss: 0.769973, BCE loss: 0.527575, SB loss: 0.736676
2023-10-30 12:53:31,195 Epoch: [238/484] Iter:[420/495], Time: 0.37, lr: [0.005421635272159329], Loss: 2.035459, Acc:0.796879, Semantic loss: 0.771292, BCE loss: 0.526901, SB loss: 0.737267
2023-10-30 12:53:34,773 Epoch: [238/484] Iter:[430/495], Time: 0.37, lr: [0.005421233171471196], Loss: 2.038524, Acc:0.797194, Semantic loss: 0.772601, BCE loss: 0.528312, SB loss: 0.737612
2023-10-30 12:53:38,421 Epoch: [238/484] Iter:[440/495], Time: 0.37, lr: [0.005420831067469213], Loss: 2.036770, Acc:0.796975, Semantic loss: 0.770915, BCE loss: 0.528309, SB loss: 0.737546
2023-10-30 12:53:42,102 Epoch: [238/484] Iter:[450/495], Time: 0.37, lr: [0.005420428960153082], Loss: 2.040358, Acc:0.797272, Semantic loss: 0.772642, BCE loss: 0.528950, SB loss: 0.738766
2023-10-30 12:53:45,842 Epoch: [238/484] Iter:[460/495], Time: 0.37, lr: [0.0054200268495225015], Loss: 2.042380, Acc:0.797365, Semantic loss: 0.772576, BCE loss: 0.530468, SB loss: 0.739336
2023-10-30 12:53:49,393 Epoch: [238/484] Iter:[470/495], Time: 0.37, lr: [0.005419624735577173], Loss: 2.043836, Acc:0.797172, Semantic loss: 0.772837, BCE loss: 0.531790, SB loss: 0.739210
2023-10-30 12:53:53,057 Epoch: [238/484] Iter:[480/495], Time: 0.37, lr: [0.005419222618316792], Loss: 2.046601, Acc:0.797067, Semantic loss: 0.775739, BCE loss: 0.531195, SB loss: 0.739667
2023-10-30 12:53:56,494 Epoch: [238/484] Iter:[490/495], Time: 0.37, lr: [0.005418820497741062], Loss: 2.046961, Acc:0.797207, Semantic loss: 0.776929, BCE loss: 0.531171, SB loss: 0.738861
2023-10-30 12:53:57,854 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:53:58,084 Loss: 2.457, MeanIU:  0.5718, Best_mIoU:  0.7151
2023-10-30 12:53:58,084 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632]
2023-10-30 12:54:00,239 Epoch: [239/484] Iter:[0/495], Time: 2.12, lr: [0.005418619436209846], Loss: 1.881736, Acc:0.786024, Semantic loss: 0.712217, BCE loss: 0.498842, SB loss: 0.670677
2023-10-30 12:54:04,197 Epoch: [239/484] Iter:[10/495], Time: 0.55, lr: [0.005418217310660526], Loss: 2.032140, Acc:0.795715, Semantic loss: 0.769577, BCE loss: 0.534424, SB loss: 0.728139
2023-10-30 12:54:07,683 Epoch: [239/484] Iter:[20/495], Time: 0.46, lr: [0.005417815181795102], Loss: 2.028585, Acc:0.773456, Semantic loss: 0.763396, BCE loss: 0.519162, SB loss: 0.746028
2023-10-30 12:54:11,273 Epoch: [239/484] Iter:[30/495], Time: 0.42, lr: [0.005417413049613274], Loss: 2.042441, Acc:0.775498, Semantic loss: 0.759171, BCE loss: 0.535254, SB loss: 0.748016
2023-10-30 12:54:14,804 Epoch: [239/484] Iter:[40/495], Time: 0.41, lr: [0.00541701091411474], Loss: 2.056448, Acc:0.783922, Semantic loss: 0.772454, BCE loss: 0.532155, SB loss: 0.751839
2023-10-30 12:54:18,368 Epoch: [239/484] Iter:[50/495], Time: 0.40, lr: [0.005416608775299203], Loss: 2.049653, Acc:0.782185, Semantic loss: 0.773230, BCE loss: 0.525665, SB loss: 0.750759
2023-10-30 12:54:21,973 Epoch: [239/484] Iter:[60/495], Time: 0.39, lr: [0.005416206633166359], Loss: 2.026184, Acc:0.788931, Semantic loss: 0.765496, BCE loss: 0.520680, SB loss: 0.740008
2023-10-30 12:54:25,611 Epoch: [239/484] Iter:[70/495], Time: 0.39, lr: [0.005415804487715908], Loss: 2.040958, Acc:0.792176, Semantic loss: 0.771913, BCE loss: 0.524024, SB loss: 0.745021
2023-10-30 12:54:29,186 Epoch: [239/484] Iter:[80/495], Time: 0.38, lr: [0.005415402338947549], Loss: 2.062881, Acc:0.798785, Semantic loss: 0.777970, BCE loss: 0.532533, SB loss: 0.752378
2023-10-30 12:54:32,838 Epoch: [239/484] Iter:[90/495], Time: 0.38, lr: [0.00541500018686098], Loss: 2.052778, Acc:0.800264, Semantic loss: 0.772276, BCE loss: 0.530521, SB loss: 0.749981
2023-10-30 12:54:36,387 Epoch: [239/484] Iter:[100/495], Time: 0.38, lr: [0.005414598031455898], Loss: 2.065924, Acc:0.799591, Semantic loss: 0.777955, BCE loss: 0.534855, SB loss: 0.753114
2023-10-30 12:54:39,920 Epoch: [239/484] Iter:[110/495], Time: 0.38, lr: [0.005414195872732005], Loss: 2.050185, Acc:0.794145, Semantic loss: 0.769943, BCE loss: 0.530201, SB loss: 0.750040
2023-10-30 12:54:43,452 Epoch: [239/484] Iter:[120/495], Time: 0.37, lr: [0.005413793710688998], Loss: 2.056639, Acc:0.792398, Semantic loss: 0.777181, BCE loss: 0.527988, SB loss: 0.751470
2023-10-30 12:54:47,085 Epoch: [239/484] Iter:[130/495], Time: 0.37, lr: [0.005413391545326577], Loss: 2.049171, Acc:0.791477, Semantic loss: 0.772139, BCE loss: 0.526065, SB loss: 0.750967
2023-10-30 12:54:50,661 Epoch: [239/484] Iter:[140/495], Time: 0.37, lr: [0.0054129893766444405], Loss: 2.047313, Acc:0.794126, Semantic loss: 0.771689, BCE loss: 0.526000, SB loss: 0.749624
2023-10-30 12:54:54,415 Epoch: [239/484] Iter:[150/495], Time: 0.37, lr: [0.005412587204642285], Loss: 2.043710, Acc:0.796417, Semantic loss: 0.769363, BCE loss: 0.525752, SB loss: 0.748595
2023-10-30 12:54:58,068 Epoch: [239/484] Iter:[160/495], Time: 0.37, lr: [0.005412185029319811], Loss: 2.041157, Acc:0.799554, Semantic loss: 0.766155, BCE loss: 0.528791, SB loss: 0.746211
2023-10-30 12:55:01,717 Epoch: [239/484] Iter:[170/495], Time: 0.37, lr: [0.005411782850676716], Loss: 2.042609, Acc:0.801549, Semantic loss: 0.765253, BCE loss: 0.531438, SB loss: 0.745918
2023-10-30 12:55:05,356 Epoch: [239/484] Iter:[180/495], Time: 0.37, lr: [0.005411380668712698], Loss: 2.059672, Acc:0.802379, Semantic loss: 0.776745, BCE loss: 0.533294, SB loss: 0.749632
2023-10-30 12:55:09,047 Epoch: [239/484] Iter:[190/495], Time: 0.37, lr: [0.005410978483427456], Loss: 2.068861, Acc:0.803279, Semantic loss: 0.778176, BCE loss: 0.538536, SB loss: 0.752149
2023-10-30 12:55:12,644 Epoch: [239/484] Iter:[200/495], Time: 0.37, lr: [0.005410576294820689], Loss: 2.066862, Acc:0.803407, Semantic loss: 0.777519, BCE loss: 0.538973, SB loss: 0.750370
2023-10-30 12:55:16,272 Epoch: [239/484] Iter:[210/495], Time: 0.37, lr: [0.005410174102892094], Loss: 2.064071, Acc:0.802668, Semantic loss: 0.773737, BCE loss: 0.541710, SB loss: 0.748625
2023-10-30 12:55:19,974 Epoch: [239/484] Iter:[220/495], Time: 0.37, lr: [0.005409771907641371], Loss: 2.066926, Acc:0.803196, Semantic loss: 0.774431, BCE loss: 0.542902, SB loss: 0.749593
2023-10-30 12:55:23,576 Epoch: [239/484] Iter:[230/495], Time: 0.37, lr: [0.005409369709068216], Loss: 2.065074, Acc:0.802286, Semantic loss: 0.773293, BCE loss: 0.543081, SB loss: 0.748700
2023-10-30 12:55:27,213 Epoch: [239/484] Iter:[240/495], Time: 0.37, lr: [0.005408967507172327], Loss: 2.062267, Acc:0.800851, Semantic loss: 0.771709, BCE loss: 0.542147, SB loss: 0.748411
2023-10-30 12:55:30,878 Epoch: [239/484] Iter:[250/495], Time: 0.37, lr: [0.005408565301953404], Loss: 2.068519, Acc:0.800418, Semantic loss: 0.778081, BCE loss: 0.540331, SB loss: 0.750107
2023-10-30 12:55:34,540 Epoch: [239/484] Iter:[260/495], Time: 0.37, lr: [0.005408163093411142], Loss: 2.067482, Acc:0.799722, Semantic loss: 0.779130, BCE loss: 0.538602, SB loss: 0.749750
2023-10-30 12:55:38,035 Epoch: [239/484] Iter:[270/495], Time: 0.37, lr: [0.005407760881545243], Loss: 2.065241, Acc:0.800172, Semantic loss: 0.777273, BCE loss: 0.538378, SB loss: 0.749591
2023-10-30 12:55:41,656 Epoch: [239/484] Iter:[280/495], Time: 0.37, lr: [0.005407358666355401], Loss: 2.066386, Acc:0.799483, Semantic loss: 0.777148, BCE loss: 0.540029, SB loss: 0.749209
2023-10-30 12:55:45,259 Epoch: [239/484] Iter:[290/495], Time: 0.37, lr: [0.005406956447841316], Loss: 2.065602, Acc:0.798887, Semantic loss: 0.777899, BCE loss: 0.539017, SB loss: 0.748687
2023-10-30 12:55:48,800 Epoch: [239/484] Iter:[300/495], Time: 0.37, lr: [0.005406554226002685], Loss: 2.063242, Acc:0.797048, Semantic loss: 0.776693, BCE loss: 0.538425, SB loss: 0.748125
2023-10-30 12:55:52,436 Epoch: [239/484] Iter:[310/495], Time: 0.37, lr: [0.005406152000839206], Loss: 2.066751, Acc:0.796240, Semantic loss: 0.779125, BCE loss: 0.537805, SB loss: 0.749821
2023-10-30 12:55:56,029 Epoch: [239/484] Iter:[320/495], Time: 0.37, lr: [0.005405749772350578], Loss: 2.061534, Acc:0.795200, Semantic loss: 0.777855, BCE loss: 0.535579, SB loss: 0.748100
2023-10-30 12:55:59,680 Epoch: [239/484] Iter:[330/495], Time: 0.37, lr: [0.0054053475405364945], Loss: 2.059326, Acc:0.795247, Semantic loss: 0.776471, BCE loss: 0.535637, SB loss: 0.747218
2023-10-30 12:56:03,357 Epoch: [239/484] Iter:[340/495], Time: 0.37, lr: [0.005404945305396657], Loss: 2.063061, Acc:0.795727, Semantic loss: 0.777592, BCE loss: 0.537290, SB loss: 0.748180
2023-10-30 12:56:06,921 Epoch: [239/484] Iter:[350/495], Time: 0.37, lr: [0.005404543066930762], Loss: 2.066801, Acc:0.795713, Semantic loss: 0.779318, BCE loss: 0.538201, SB loss: 0.749283
2023-10-30 12:56:10,582 Epoch: [239/484] Iter:[360/495], Time: 0.37, lr: [0.005404140825138505], Loss: 2.064514, Acc:0.795780, Semantic loss: 0.777302, BCE loss: 0.539004, SB loss: 0.748208
2023-10-30 12:56:14,268 Epoch: [239/484] Iter:[370/495], Time: 0.37, lr: [0.005403738580019586], Loss: 2.065144, Acc:0.795797, Semantic loss: 0.777326, BCE loss: 0.539629, SB loss: 0.748189
2023-10-30 12:56:17,971 Epoch: [239/484] Iter:[380/495], Time: 0.37, lr: [0.0054033363315737016], Loss: 2.064248, Acc:0.796673, Semantic loss: 0.777422, BCE loss: 0.538488, SB loss: 0.748339
2023-10-30 12:56:21,650 Epoch: [239/484] Iter:[390/495], Time: 0.37, lr: [0.00540293407980055], Loss: 2.064460, Acc:0.797008, Semantic loss: 0.776926, BCE loss: 0.539974, SB loss: 0.747560
2023-10-30 12:56:25,208 Epoch: [239/484] Iter:[400/495], Time: 0.37, lr: [0.005402531824699825], Loss: 2.068545, Acc:0.796950, Semantic loss: 0.778926, BCE loss: 0.540489, SB loss: 0.749129
2023-10-30 12:56:28,821 Epoch: [239/484] Iter:[410/495], Time: 0.37, lr: [0.005402129566271228], Loss: 2.063765, Acc:0.797520, Semantic loss: 0.775670, BCE loss: 0.540404, SB loss: 0.747691
2023-10-30 12:56:32,452 Epoch: [239/484] Iter:[420/495], Time: 0.37, lr: [0.005401727304514452], Loss: 2.060963, Acc:0.797835, Semantic loss: 0.774479, BCE loss: 0.539688, SB loss: 0.746796
2023-10-30 12:56:36,061 Epoch: [239/484] Iter:[430/495], Time: 0.37, lr: [0.005401325039429198], Loss: 2.059492, Acc:0.797827, Semantic loss: 0.774800, BCE loss: 0.538630, SB loss: 0.746062
2023-10-30 12:56:39,675 Epoch: [239/484] Iter:[440/495], Time: 0.37, lr: [0.0054009227710151595], Loss: 2.058060, Acc:0.798233, Semantic loss: 0.774075, BCE loss: 0.537835, SB loss: 0.746150
2023-10-30 12:56:43,327 Epoch: [239/484] Iter:[450/495], Time: 0.37, lr: [0.005400520499272037], Loss: 2.060861, Acc:0.798661, Semantic loss: 0.774055, BCE loss: 0.540559, SB loss: 0.746247
2023-10-30 12:56:47,045 Epoch: [239/484] Iter:[460/495], Time: 0.37, lr: [0.005400118224199525], Loss: 2.059269, Acc:0.798430, Semantic loss: 0.773830, BCE loss: 0.540066, SB loss: 0.745373
2023-10-30 12:56:50,583 Epoch: [239/484] Iter:[470/495], Time: 0.37, lr: [0.005399715945797322], Loss: 2.062762, Acc:0.798769, Semantic loss: 0.775461, BCE loss: 0.541207, SB loss: 0.746094
2023-10-30 12:56:54,262 Epoch: [239/484] Iter:[480/495], Time: 0.37, lr: [0.005399313664065123], Loss: 2.062637, Acc:0.798379, Semantic loss: 0.776169, BCE loss: 0.540216, SB loss: 0.746252
2023-10-30 12:56:57,726 Epoch: [239/484] Iter:[490/495], Time: 0.37, lr: [0.0053989113790026255], Loss: 2.064153, Acc:0.798630, Semantic loss: 0.777263, BCE loss: 0.540614, SB loss: 0.746277
2023-10-30 12:56:59,084 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 12:56:59,318 Loss: 2.457, MeanIU:  0.5718, Best_mIoU:  0.7151
2023-10-30 12:56:59,319 [0.92764726 0.59981017 0.85025153 0.2310123  0.20942836 0.51190078
 0.59216566 0.69791376 0.88329689 0.54346257 0.9297706  0.587529
 0.41915951 0.82812901 0.20017457 0.49420652 0.48322559 0.21697447
 0.65908632]
2023-10-30 12:57:01,280 Epoch: [240/484] Iter:[0/495], Time: 1.93, lr: [0.005398710235222419], Loss: 2.485919, Acc:0.893033, Semantic loss: 0.944895, BCE loss: 0.619830, SB loss: 0.921195
2023-10-30 12:57:05,052 Epoch: [240/484] Iter:[10/495], Time: 0.52, lr: [0.005398307945163906], Loss: 2.078817, Acc:0.788568, Semantic loss: 0.788437, BCE loss: 0.527399, SB loss: 0.762981
2023-10-30 12:57:08,593 Epoch: [240/484] Iter:[20/495], Time: 0.44, lr: [0.005397905651774334], Loss: 2.111852, Acc:0.785678, Semantic loss: 0.805818, BCE loss: 0.538916, SB loss: 0.767118
2023-10-30 12:57:12,091 Epoch: [240/484] Iter:[30/495], Time: 0.41, lr: [0.005397503355053404], Loss: 2.065961, Acc:0.784941, Semantic loss: 0.782550, BCE loss: 0.529972, SB loss: 0.753439
2023-10-30 12:57:15,721 Epoch: [240/484] Iter:[40/495], Time: 0.40, lr: [0.005397101055000809], Loss: 2.070820, Acc:0.789812, Semantic loss: 0.781986, BCE loss: 0.537745, SB loss: 0.751089
2023-10-30 12:57:19,282 Epoch: [240/484] Iter:[50/495], Time: 0.39, lr: [0.005396698751616248], Loss: 2.092394, Acc:0.795434, Semantic loss: 0.788772, BCE loss: 0.553561, SB loss: 0.750061
2023-10-30 12:57:22,910 Epoch: [240/484] Iter:[60/495], Time: 0.39, lr: [0.005396296444899416], Loss: 2.063953, Acc:0.796040, Semantic loss: 0.769373, BCE loss: 0.554973, SB loss: 0.739607
2023-10-30 12:57:26,544 Epoch: [240/484] Iter:[70/495], Time: 0.38, lr: [0.005395894134850009], Loss: 2.055614, Acc:0.789326, Semantic loss: 0.767041, BCE loss: 0.546095, SB loss: 0.742478
2023-10-30 12:57:30,209 Epoch: [240/484] Iter:[80/495], Time: 0.38, lr: [0.005395491821467724], Loss: 2.044780, Acc:0.791388, Semantic loss: 0.765703, BCE loss: 0.538781, SB loss: 0.740296
2023-10-30 12:57:33,977 Epoch: [240/484] Iter:[90/495], Time: 0.38, lr: [0.005395089504752258], Loss: 2.044102, Acc:0.794073, Semantic loss: 0.765807, BCE loss: 0.540832, SB loss: 0.737464
2023-10-30 12:57:37,616 Epoch: [240/484] Iter:[100/495], Time: 0.38, lr: [0.005394687184703304], Loss: 2.042555, Acc:0.794438, Semantic loss: 0.767025, BCE loss: 0.538850, SB loss: 0.736679
2023-10-30 12:57:41,190 Epoch: [240/484] Iter:[110/495], Time: 0.38, lr: [0.005394284861320562], Loss: 2.042988, Acc:0.793933, Semantic loss: 0.764309, BCE loss: 0.540774, SB loss: 0.737905
2023-10-30 12:57:44,835 Epoch: [240/484] Iter:[120/495], Time: 0.38, lr: [0.005393882534603727], Loss: 2.034382, Acc:0.794310, Semantic loss: 0.757366, BCE loss: 0.539839, SB loss: 0.737178
2023-10-30 12:57:48,452 Epoch: [240/484] Iter:[130/495], Time: 0.37, lr: [0.005393480204552495], Loss: 2.032633, Acc:0.794236, Semantic loss: 0.760581, BCE loss: 0.533182, SB loss: 0.738870
2023-10-30 12:57:52,077 Epoch: [240/484] Iter:[140/495], Time: 0.37, lr: [0.00539307787116656], Loss: 2.038177, Acc:0.792142, Semantic loss: 0.764494, BCE loss: 0.532408, SB loss: 0.741275
2023-10-30 12:57:55,726 Epoch: [240/484] Iter:[150/495], Time: 0.37, lr: [0.005392675534445621], Loss: 2.034815, Acc:0.793424, Semantic loss: 0.764227, BCE loss: 0.530857, SB loss: 0.739732
2023-10-30 12:57:59,412 Epoch: [240/484] Iter:[160/495], Time: 0.37, lr: [0.005392273194389372], Loss: 2.043685, Acc:0.793386, Semantic loss: 0.770598, BCE loss: 0.530970, SB loss: 0.742117
2023-10-30 12:58:03,070 Epoch: [240/484] Iter:[170/495], Time: 0.37, lr: [0.005391870850997509], Loss: 2.045011, Acc:0.794802, Semantic loss: 0.773064, BCE loss: 0.530178, SB loss: 0.741769
2023-10-30 12:58:06,652 Epoch: [240/484] Iter:[180/495], Time: 0.37, lr: [0.0053914685042697275], Loss: 2.045202, Acc:0.797875, Semantic loss: 0.772178, BCE loss: 0.533438, SB loss: 0.739586
2023-10-30 12:58:10,219 Epoch: [240/484] Iter:[190/495], Time: 0.37, lr: [0.0053910661542057245], Loss: 2.038824, Acc:0.796735, Semantic loss: 0.768656, BCE loss: 0.530518, SB loss: 0.739650
2023-10-30 12:58:13,870 Epoch: [240/484] Iter:[200/495], Time: 0.37, lr: [0.005390663800805196], Loss: 2.031559, Acc:0.795000, Semantic loss: 0.765601, BCE loss: 0.527671, SB loss: 0.738287
2023-10-30 12:58:17,441 Epoch: [240/484] Iter:[210/495], Time: 0.37, lr: [0.005390261444067837], Loss: 2.029201, Acc:0.795873, Semantic loss: 0.764375, BCE loss: 0.527461, SB loss: 0.737365
2023-10-30 12:58:21,189 Epoch: [240/484] Iter:[220/495], Time: 0.37, lr: [0.00538985908399334], Loss: 2.024573, Acc:0.796177, Semantic loss: 0.763224, BCE loss: 0.523990, SB loss: 0.737359
2023-10-30 12:58:24,873 Epoch: [240/484] Iter:[230/495], Time: 0.37, lr: [0.005389456720581406], Loss: 2.021978, Acc:0.794466, Semantic loss: 0.762894, BCE loss: 0.522434, SB loss: 0.736650
2023-10-30 12:58:28,525 Epoch: [240/484] Iter:[240/495], Time: 0.37, lr: [0.005389054353831725], Loss: 2.023567, Acc:0.795370, Semantic loss: 0.763038, BCE loss: 0.524438, SB loss: 0.736090
2023-10-30 12:58:32,190 Epoch: [240/484] Iter:[250/495], Time: 0.37, lr: [0.005388651983743996], Loss: 2.027451, Acc:0.796894, Semantic loss: 0.765394, BCE loss: 0.525548, SB loss: 0.736510
2023-10-30 12:58:35,795 Epoch: [240/484] Iter:[260/495], Time: 0.37, lr: [0.005388249610317914], Loss: 2.023297, Acc:0.798038, Semantic loss: 0.763681, BCE loss: 0.524211, SB loss: 0.735406
2023-10-30 12:58:39,428 Epoch: [240/484] Iter:[270/495], Time: 0.37, lr: [0.005387847233553174], Loss: 2.021763, Acc:0.797501, Semantic loss: 0.764087, BCE loss: 0.522630, SB loss: 0.735046
2023-10-30 12:58:43,028 Epoch: [240/484] Iter:[280/495], Time: 0.37, lr: [0.00538744485344947], Loss: 2.021592, Acc:0.797796, Semantic loss: 0.762985, BCE loss: 0.524602, SB loss: 0.734005
2023-10-30 12:58:46,611 Epoch: [240/484] Iter:[290/495], Time: 0.37, lr: [0.005387042470006499], Loss: 2.017030, Acc:0.797894, Semantic loss: 0.760198, BCE loss: 0.524827, SB loss: 0.732006
2023-10-30 12:58:50,177 Epoch: [240/484] Iter:[300/495], Time: 0.37, lr: [0.0053866400832239545], Loss: 2.014713, Acc:0.797507, Semantic loss: 0.759924, BCE loss: 0.522918, SB loss: 0.731872
2023-10-30 12:58:53,773 Epoch: [240/484] Iter:[310/495], Time: 0.37, lr: [0.005386237693101533], Loss: 2.013237, Acc:0.797164, Semantic loss: 0.759427, BCE loss: 0.522563, SB loss: 0.731246
2023-10-30 12:58:57,361 Epoch: [240/484] Iter:[320/495], Time: 0.37, lr: [0.005385835299638929], Loss: 2.012377, Acc:0.799017, Semantic loss: 0.759270, BCE loss: 0.521571, SB loss: 0.731536
2023-10-30 12:59:01,028 Epoch: [240/484] Iter:[330/495], Time: 0.37, lr: [0.005385432902835836], Loss: 2.016103, Acc:0.797747, Semantic loss: 0.760696, BCE loss: 0.522614, SB loss: 0.732793
2023-10-30 12:59:04,703 Epoch: [240/484] Iter:[340/495], Time: 0.37, lr: [0.005385030502691952], Loss: 2.022226, Acc:0.797201, Semantic loss: 0.762653, BCE loss: 0.526342, SB loss: 0.733231
2023-10-30 12:59:08,414 Epoch: [240/484] Iter:[350/495], Time: 0.37, lr: [0.00538462809920697], Loss: 2.022869, Acc:0.797740, Semantic loss: 0.762402, BCE loss: 0.526503, SB loss: 0.733964
2023-10-30 12:59:12,176 Epoch: [240/484] Iter:[360/495], Time: 0.37, lr: [0.0053842256923805855], Loss: 2.027852, Acc:0.798280, Semantic loss: 0.766484, BCE loss: 0.525414, SB loss: 0.735955
2023-10-30 12:59:15,787 Epoch: [240/484] Iter:[370/495], Time: 0.37, lr: [0.005383823282212492], Loss: 2.030599, Acc:0.797079, Semantic loss: 0.767819, BCE loss: 0.525599, SB loss: 0.737181
2023-10-30 12:59:19,444 Epoch: [240/484] Iter:[380/495], Time: 0.37, lr: [0.005383420868702386], Loss: 2.032969, Acc:0.796490, Semantic loss: 0.769534, BCE loss: 0.525568, SB loss: 0.737868
2023-10-30 12:59:23,060 Epoch: [240/484] Iter:[390/495], Time: 0.37, lr: [0.005383018451849959], Loss: 2.040967, Acc:0.797140, Semantic loss: 0.773494, BCE loss: 0.527879, SB loss: 0.739594
2023-10-30 12:59:26,646 Epoch: [240/484] Iter:[400/495], Time: 0.37, lr: [0.00538261603165491], Loss: 2.046990, Acc:0.796514, Semantic loss: 0.778382, BCE loss: 0.527448, SB loss: 0.741160
2023-10-30 12:59:30,265 Epoch: [240/484] Iter:[410/495], Time: 0.37, lr: [0.0053822136081169295], Loss: 2.045794, Acc:0.796450, Semantic loss: 0.778092, BCE loss: 0.526353, SB loss: 0.741349
2023-10-30 12:59:33,874 Epoch: [240/484] Iter:[420/495], Time: 0.37, lr: [0.005381811181235715], Loss: 2.045749, Acc:0.796263, Semantic loss: 0.776488, BCE loss: 0.527445, SB loss: 0.741817
2023-10-30 12:59:37,507 Epoch: [240/484] Iter:[430/495], Time: 0.37, lr: [0.00538140875101096], Loss: 2.046832, Acc:0.796498, Semantic loss: 0.776921, BCE loss: 0.527882, SB loss: 0.742029
2023-10-30 12:59:41,115 Epoch: [240/484] Iter:[440/495], Time: 0.37, lr: [0.0053810063174423595], Loss: 2.045912, Acc:0.796405, Semantic loss: 0.777276, BCE loss: 0.526019, SB loss: 0.742617
2023-10-30 12:59:44,831 Epoch: [240/484] Iter:[450/495], Time: 0.37, lr: [0.005380603880529606], Loss: 2.048135, Acc:0.796403, Semantic loss: 0.777534, BCE loss: 0.527107, SB loss: 0.743494
2023-10-30 12:59:48,503 Epoch: [240/484] Iter:[460/495], Time: 0.37, lr: [0.005380201440272395], Loss: 2.048523, Acc:0.796677, Semantic loss: 0.777260, BCE loss: 0.527594, SB loss: 0.743669
2023-10-30 12:59:52,044 Epoch: [240/484] Iter:[470/495], Time: 0.37, lr: [0.0053797989966704205], Loss: 2.048564, Acc:0.796951, Semantic loss: 0.776312, BCE loss: 0.528907, SB loss: 0.743345
2023-10-30 12:59:55,717 Epoch: [240/484] Iter:[480/495], Time: 0.37, lr: [0.005379396549723378], Loss: 2.046528, Acc:0.796778, Semantic loss: 0.774903, BCE loss: 0.528235, SB loss: 0.743390
2023-10-30 12:59:59,191 Epoch: [240/484] Iter:[490/495], Time: 0.37, lr: [0.005378994099430958], Loss: 2.047938, Acc:0.796768, Semantic loss: 0.775023, BCE loss: 0.529431, SB loss: 0.743485
2023-10-30 13:02:49,313 0 [9.41178660e-01 6.48283669e-01 8.08777895e-01 1.72973170e-01
 1.96307449e-01 4.25750463e-01 3.91467959e-01 5.69770028e-01
 8.74785348e-01 4.54412879e-01 8.69988741e-01 5.74672575e-01
 5.93992276e-03 7.80702337e-01 3.49566335e-04 4.35849924e-02
 2.27553930e-02 3.05000546e-02 5.39142134e-01] 0.43954438085290215
2023-10-30 13:02:49,313 1 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502] 0.6607326474006893
2023-10-30 13:02:49,317 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:02:49,554 Loss: 2.047, MeanIU:  0.6607, Best_mIoU:  0.7151
2023-10-30 13:02:49,554 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502]
2023-10-30 13:02:51,657 Epoch: [241/484] Iter:[0/495], Time: 2.07, lr: [0.005378792873030137], Loss: 1.973605, Acc:0.848415, Semantic loss: 0.672868, BCE loss: 0.627872, SB loss: 0.672865
2023-10-30 13:02:55,401 Epoch: [241/484] Iter:[10/495], Time: 0.53, lr: [0.0053783904177190835], Loss: 2.044554, Acc:0.797202, Semantic loss: 0.775197, BCE loss: 0.541987, SB loss: 0.727369
2023-10-30 13:02:58,990 Epoch: [241/484] Iter:[20/495], Time: 0.45, lr: [0.005377987959061889], Loss: 2.003261, Acc:0.809172, Semantic loss: 0.737384, BCE loss: 0.549556, SB loss: 0.716322
2023-10-30 13:03:02,386 Epoch: [241/484] Iter:[30/495], Time: 0.41, lr: [0.0053775854970582486], Loss: 2.057151, Acc:0.813316, Semantic loss: 0.759558, BCE loss: 0.562698, SB loss: 0.734894
2023-10-30 13:03:05,775 Epoch: [241/484] Iter:[40/495], Time: 0.39, lr: [0.005377183031707855], Loss: 2.083396, Acc:0.806637, Semantic loss: 0.780578, BCE loss: 0.553727, SB loss: 0.749091
2023-10-30 13:03:09,216 Epoch: [241/484] Iter:[50/495], Time: 0.38, lr: [0.005376780563010404], Loss: 2.060123, Acc:0.805625, Semantic loss: 0.768961, BCE loss: 0.546328, SB loss: 0.744834
2023-10-30 13:03:12,757 Epoch: [241/484] Iter:[60/495], Time: 0.38, lr: [0.005376378090965588], Loss: 2.063650, Acc:0.812410, Semantic loss: 0.768898, BCE loss: 0.548999, SB loss: 0.745753
2023-10-30 13:03:16,187 Epoch: [241/484] Iter:[70/495], Time: 0.37, lr: [0.005375975615573102], Loss: 2.062276, Acc:0.809208, Semantic loss: 0.772138, BCE loss: 0.547193, SB loss: 0.742945
2023-10-30 13:03:19,677 Epoch: [241/484] Iter:[80/495], Time: 0.37, lr: [0.005375573136832638], Loss: 2.052416, Acc:0.804593, Semantic loss: 0.773611, BCE loss: 0.537662, SB loss: 0.741143
2023-10-30 13:03:23,226 Epoch: [241/484] Iter:[90/495], Time: 0.37, lr: [0.0053751706547438905], Loss: 2.056849, Acc:0.804911, Semantic loss: 0.774670, BCE loss: 0.542702, SB loss: 0.739477
2023-10-30 13:03:26,839 Epoch: [241/484] Iter:[100/495], Time: 0.37, lr: [0.005374768169306554], Loss: 2.043875, Acc:0.806815, Semantic loss: 0.769919, BCE loss: 0.538708, SB loss: 0.735247
2023-10-30 13:03:30,327 Epoch: [241/484] Iter:[110/495], Time: 0.37, lr: [0.005374365680520321], Loss: 2.041076, Acc:0.804854, Semantic loss: 0.768657, BCE loss: 0.538223, SB loss: 0.734196
2023-10-30 13:03:33,820 Epoch: [241/484] Iter:[120/495], Time: 0.37, lr: [0.005373963188384885], Loss: 2.045029, Acc:0.803533, Semantic loss: 0.767418, BCE loss: 0.542243, SB loss: 0.735369
2023-10-30 13:03:37,315 Epoch: [241/484] Iter:[130/495], Time: 0.36, lr: [0.005373560692899939], Loss: 2.036948, Acc:0.803935, Semantic loss: 0.764134, BCE loss: 0.541294, SB loss: 0.731520
2023-10-30 13:03:40,774 Epoch: [241/484] Iter:[140/495], Time: 0.36, lr: [0.0053731581940651765], Loss: 2.034149, Acc:0.804205, Semantic loss: 0.761070, BCE loss: 0.542358, SB loss: 0.730721
2023-10-30 13:03:44,261 Epoch: [241/484] Iter:[150/495], Time: 0.36, lr: [0.0053727556918802925], Loss: 2.031431, Acc:0.803419, Semantic loss: 0.760676, BCE loss: 0.540663, SB loss: 0.730092
2023-10-30 13:03:47,816 Epoch: [241/484] Iter:[160/495], Time: 0.36, lr: [0.005372353186344977], Loss: 2.020055, Acc:0.800373, Semantic loss: 0.756022, BCE loss: 0.536385, SB loss: 0.727648
2023-10-30 13:03:51,353 Epoch: [241/484] Iter:[170/495], Time: 0.36, lr: [0.005371950677458927], Loss: 2.024852, Acc:0.801343, Semantic loss: 0.755762, BCE loss: 0.541585, SB loss: 0.727504
2023-10-30 13:03:54,965 Epoch: [241/484] Iter:[180/495], Time: 0.36, lr: [0.005371548165221832], Loss: 2.019511, Acc:0.797822, Semantic loss: 0.754349, BCE loss: 0.538861, SB loss: 0.726301
2023-10-30 13:03:58,530 Epoch: [241/484] Iter:[190/495], Time: 0.36, lr: [0.005371145649633389], Loss: 2.024467, Acc:0.797637, Semantic loss: 0.755976, BCE loss: 0.539452, SB loss: 0.729039
2023-10-30 13:04:02,080 Epoch: [241/484] Iter:[200/495], Time: 0.36, lr: [0.005370743130693288], Loss: 2.033185, Acc:0.797196, Semantic loss: 0.760862, BCE loss: 0.541269, SB loss: 0.731054
2023-10-30 13:04:05,641 Epoch: [241/484] Iter:[210/495], Time: 0.36, lr: [0.00537034060840122], Loss: 2.031282, Acc:0.797299, Semantic loss: 0.761423, BCE loss: 0.538207, SB loss: 0.731652
2023-10-30 13:04:09,208 Epoch: [241/484] Iter:[220/495], Time: 0.36, lr: [0.005369938082756884], Loss: 2.031883, Acc:0.798953, Semantic loss: 0.760264, BCE loss: 0.538416, SB loss: 0.733204
2023-10-30 13:04:12,783 Epoch: [241/484] Iter:[230/495], Time: 0.36, lr: [0.005369535553759969], Loss: 2.037761, Acc:0.797399, Semantic loss: 0.764037, BCE loss: 0.538864, SB loss: 0.734860
2023-10-30 13:04:16,335 Epoch: [241/484] Iter:[240/495], Time: 0.36, lr: [0.005369133021410169], Loss: 2.041302, Acc:0.797161, Semantic loss: 0.766096, BCE loss: 0.538261, SB loss: 0.736945
2023-10-30 13:04:19,903 Epoch: [241/484] Iter:[250/495], Time: 0.36, lr: [0.005368730485707175], Loss: 2.035638, Acc:0.798634, Semantic loss: 0.760935, BCE loss: 0.539499, SB loss: 0.735204
2023-10-30 13:04:23,465 Epoch: [241/484] Iter:[260/495], Time: 0.36, lr: [0.0053683279466506814], Loss: 2.033489, Acc:0.798602, Semantic loss: 0.759987, BCE loss: 0.538978, SB loss: 0.734525
2023-10-30 13:04:27,081 Epoch: [241/484] Iter:[270/495], Time: 0.36, lr: [0.005367925404240382], Loss: 2.033888, Acc:0.798138, Semantic loss: 0.761509, BCE loss: 0.538520, SB loss: 0.733859
2023-10-30 13:04:30,663 Epoch: [241/484] Iter:[280/495], Time: 0.36, lr: [0.005367522858475965], Loss: 2.030969, Acc:0.799418, Semantic loss: 0.759678, BCE loss: 0.537945, SB loss: 0.733346
2023-10-30 13:04:34,321 Epoch: [241/484] Iter:[290/495], Time: 0.36, lr: [0.005367120309357126], Loss: 2.025043, Acc:0.799293, Semantic loss: 0.757410, BCE loss: 0.535906, SB loss: 0.731727
2023-10-30 13:04:37,831 Epoch: [241/484] Iter:[300/495], Time: 0.36, lr: [0.005366717756883559], Loss: 2.024583, Acc:0.800111, Semantic loss: 0.755470, BCE loss: 0.537650, SB loss: 0.731463
2023-10-30 13:04:41,336 Epoch: [241/484] Iter:[310/495], Time: 0.36, lr: [0.005366315201054953], Loss: 2.024505, Acc:0.797955, Semantic loss: 0.755874, BCE loss: 0.537106, SB loss: 0.731525
2023-10-30 13:04:44,984 Epoch: [241/484] Iter:[320/495], Time: 0.36, lr: [0.005365912641871004], Loss: 2.019910, Acc:0.797107, Semantic loss: 0.753759, BCE loss: 0.534697, SB loss: 0.731454
2023-10-30 13:04:48,565 Epoch: [241/484] Iter:[330/495], Time: 0.36, lr: [0.005365510079331401], Loss: 2.023328, Acc:0.797648, Semantic loss: 0.755435, BCE loss: 0.535325, SB loss: 0.732568
2023-10-30 13:04:52,125 Epoch: [241/484] Iter:[340/495], Time: 0.36, lr: [0.005365107513435838], Loss: 2.019846, Acc:0.796541, Semantic loss: 0.754677, BCE loss: 0.533046, SB loss: 0.732122
2023-10-30 13:04:55,699 Epoch: [241/484] Iter:[350/495], Time: 0.36, lr: [0.0053647049441840075], Loss: 2.018509, Acc:0.796283, Semantic loss: 0.754356, BCE loss: 0.531968, SB loss: 0.732184
2023-10-30 13:04:59,279 Epoch: [241/484] Iter:[360/495], Time: 0.36, lr: [0.0053643023715756015], Loss: 2.017223, Acc:0.796476, Semantic loss: 0.753280, BCE loss: 0.532345, SB loss: 0.731598
2023-10-30 13:05:03,042 Epoch: [241/484] Iter:[370/495], Time: 0.36, lr: [0.0053638997956103095], Loss: 2.015282, Acc:0.796864, Semantic loss: 0.753341, BCE loss: 0.530768, SB loss: 0.731173
2023-10-30 13:05:06,677 Epoch: [241/484] Iter:[380/495], Time: 0.36, lr: [0.005363497216287828], Loss: 2.015038, Acc:0.795754, Semantic loss: 0.753735, BCE loss: 0.530821, SB loss: 0.730483
2023-10-30 13:05:10,278 Epoch: [241/484] Iter:[390/495], Time: 0.36, lr: [0.005363094633607845], Loss: 2.017264, Acc:0.796192, Semantic loss: 0.755465, BCE loss: 0.531202, SB loss: 0.730597
2023-10-30 13:05:13,837 Epoch: [241/484] Iter:[400/495], Time: 0.36, lr: [0.005362692047570056], Loss: 2.016736, Acc:0.796037, Semantic loss: 0.755633, BCE loss: 0.530531, SB loss: 0.730572
2023-10-30 13:05:17,539 Epoch: [241/484] Iter:[410/495], Time: 0.36, lr: [0.00536228945817415], Loss: 2.022538, Acc:0.795690, Semantic loss: 0.761235, BCE loss: 0.530188, SB loss: 0.731115
2023-10-30 13:05:21,149 Epoch: [241/484] Iter:[420/495], Time: 0.36, lr: [0.005361886865419821], Loss: 2.020936, Acc:0.795475, Semantic loss: 0.759980, BCE loss: 0.530002, SB loss: 0.730955
2023-10-30 13:05:24,851 Epoch: [241/484] Iter:[430/495], Time: 0.36, lr: [0.005361484269306759], Loss: 2.020001, Acc:0.795742, Semantic loss: 0.759600, BCE loss: 0.529702, SB loss: 0.730699
2023-10-30 13:05:28,536 Epoch: [241/484] Iter:[440/495], Time: 0.36, lr: [0.0053610816698346575], Loss: 2.024132, Acc:0.795932, Semantic loss: 0.761867, BCE loss: 0.530609, SB loss: 0.731656
2023-10-30 13:05:32,137 Epoch: [241/484] Iter:[450/495], Time: 0.36, lr: [0.005360679067003206], Loss: 2.026199, Acc:0.795982, Semantic loss: 0.762041, BCE loss: 0.531404, SB loss: 0.732754
2023-10-30 13:05:35,699 Epoch: [241/484] Iter:[460/495], Time: 0.36, lr: [0.005360276460812098], Loss: 2.021227, Acc:0.795945, Semantic loss: 0.759111, BCE loss: 0.529571, SB loss: 0.732545
2023-10-30 13:05:39,264 Epoch: [241/484] Iter:[470/495], Time: 0.36, lr: [0.005359873851261024], Loss: 2.020630, Acc:0.795960, Semantic loss: 0.757687, BCE loss: 0.530120, SB loss: 0.732823
2023-10-30 13:05:42,839 Epoch: [241/484] Iter:[480/495], Time: 0.36, lr: [0.005359471238349676], Loss: 2.018130, Acc:0.794572, Semantic loss: 0.757533, BCE loss: 0.527955, SB loss: 0.732643
2023-10-30 13:05:46,255 Epoch: [241/484] Iter:[490/495], Time: 0.36, lr: [0.005359068622077746], Loss: 2.018991, Acc:0.794687, Semantic loss: 0.757645, BCE loss: 0.528293, SB loss: 0.733053
2023-10-30 13:05:47,632 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:05:47,868 Loss: 2.047, MeanIU:  0.6607, Best_mIoU:  0.7151
2023-10-30 13:05:47,868 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502]
2023-10-30 13:05:49,784 Epoch: [242/484] Iter:[0/495], Time: 1.88, lr: [0.005358867312681466], Loss: 1.985570, Acc:0.642912, Semantic loss: 0.843082, BCE loss: 0.387363, SB loss: 0.755124
2023-10-30 13:05:53,733 Epoch: [242/484] Iter:[10/495], Time: 0.53, lr: [0.005358464691368084], Loss: 1.974970, Acc:0.802611, Semantic loss: 0.738890, BCE loss: 0.535026, SB loss: 0.701053
2023-10-30 13:05:57,456 Epoch: [242/484] Iter:[20/495], Time: 0.45, lr: [0.0053580620666933455], Loss: 2.005010, Acc:0.807258, Semantic loss: 0.758251, BCE loss: 0.527410, SB loss: 0.719349
2023-10-30 13:06:01,084 Epoch: [242/484] Iter:[30/495], Time: 0.43, lr: [0.0053576594386569466], Loss: 2.000698, Acc:0.815240, Semantic loss: 0.754686, BCE loss: 0.530273, SB loss: 0.715739
2023-10-30 13:06:04,647 Epoch: [242/484] Iter:[40/495], Time: 0.41, lr: [0.005357256807258576], Loss: 2.011089, Acc:0.814325, Semantic loss: 0.756765, BCE loss: 0.536692, SB loss: 0.717632
2023-10-30 13:06:08,257 Epoch: [242/484] Iter:[50/495], Time: 0.40, lr: [0.005356854172497925], Loss: 1.987957, Acc:0.809683, Semantic loss: 0.755025, BCE loss: 0.519001, SB loss: 0.713930
2023-10-30 13:06:11,920 Epoch: [242/484] Iter:[60/495], Time: 0.39, lr: [0.0053564515343746824], Loss: 2.008958, Acc:0.807441, Semantic loss: 0.763029, BCE loss: 0.524347, SB loss: 0.721582
2023-10-30 13:06:15,568 Epoch: [242/484] Iter:[70/495], Time: 0.39, lr: [0.005356048892888543], Loss: 2.037221, Acc:0.804820, Semantic loss: 0.777311, BCE loss: 0.527182, SB loss: 0.732728
2023-10-30 13:06:19,151 Epoch: [242/484] Iter:[80/495], Time: 0.39, lr: [0.005355646248039198], Loss: 2.029760, Acc:0.802173, Semantic loss: 0.770381, BCE loss: 0.527608, SB loss: 0.731771
2023-10-30 13:06:22,809 Epoch: [242/484] Iter:[90/495], Time: 0.38, lr: [0.005355243599826335], Loss: 2.045153, Acc:0.802409, Semantic loss: 0.780083, BCE loss: 0.526911, SB loss: 0.738158
2023-10-30 13:06:26,364 Epoch: [242/484] Iter:[100/495], Time: 0.38, lr: [0.005354840948249646], Loss: 2.056596, Acc:0.802767, Semantic loss: 0.783978, BCE loss: 0.530823, SB loss: 0.741795
2023-10-30 13:06:30,039 Epoch: [242/484] Iter:[110/495], Time: 0.38, lr: [0.005354438293308824], Loss: 2.039793, Acc:0.799899, Semantic loss: 0.775055, BCE loss: 0.525445, SB loss: 0.739293
2023-10-30 13:06:33,692 Epoch: [242/484] Iter:[120/495], Time: 0.38, lr: [0.005354035635003558], Loss: 2.050712, Acc:0.800726, Semantic loss: 0.775406, BCE loss: 0.533916, SB loss: 0.741389
2023-10-30 13:06:37,277 Epoch: [242/484] Iter:[130/495], Time: 0.38, lr: [0.00535363297333354], Loss: 2.037927, Acc:0.801188, Semantic loss: 0.772021, BCE loss: 0.529438, SB loss: 0.736467
2023-10-30 13:06:40,867 Epoch: [242/484] Iter:[140/495], Time: 0.38, lr: [0.005353230308298457], Loss: 2.040773, Acc:0.801456, Semantic loss: 0.773213, BCE loss: 0.529547, SB loss: 0.738013
2023-10-30 13:06:44,571 Epoch: [242/484] Iter:[150/495], Time: 0.38, lr: [0.0053528276398980045], Loss: 2.035273, Acc:0.800821, Semantic loss: 0.771280, BCE loss: 0.526717, SB loss: 0.737276
2023-10-30 13:06:48,367 Epoch: [242/484] Iter:[160/495], Time: 0.38, lr: [0.00535242496813187], Loss: 2.036959, Acc:0.800229, Semantic loss: 0.771936, BCE loss: 0.526601, SB loss: 0.738421
2023-10-30 13:06:52,252 Epoch: [242/484] Iter:[170/495], Time: 0.38, lr: [0.0053520222929997465], Loss: 2.028433, Acc:0.802100, Semantic loss: 0.767430, BCE loss: 0.523999, SB loss: 0.737003
2023-10-30 13:06:55,977 Epoch: [242/484] Iter:[180/495], Time: 0.38, lr: [0.005351619614501321], Loss: 2.030833, Acc:0.800473, Semantic loss: 0.768428, BCE loss: 0.525392, SB loss: 0.737014
2023-10-30 13:06:59,641 Epoch: [242/484] Iter:[190/495], Time: 0.38, lr: [0.005351216932636286], Loss: 2.023601, Acc:0.801711, Semantic loss: 0.764357, BCE loss: 0.524817, SB loss: 0.734427
2023-10-30 13:07:03,267 Epoch: [242/484] Iter:[200/495], Time: 0.37, lr: [0.005350814247404332], Loss: 2.024057, Acc:0.803029, Semantic loss: 0.765558, BCE loss: 0.524322, SB loss: 0.734177
2023-10-30 13:07:06,934 Epoch: [242/484] Iter:[210/495], Time: 0.37, lr: [0.005350411558805151], Loss: 2.029083, Acc:0.802051, Semantic loss: 0.768767, BCE loss: 0.525999, SB loss: 0.734317
2023-10-30 13:07:10,629 Epoch: [242/484] Iter:[220/495], Time: 0.37, lr: [0.005350008866838427], Loss: 2.030119, Acc:0.802002, Semantic loss: 0.767979, BCE loss: 0.525958, SB loss: 0.736182
2023-10-30 13:07:14,235 Epoch: [242/484] Iter:[230/495], Time: 0.37, lr: [0.005349606171503858], Loss: 2.024304, Acc:0.800598, Semantic loss: 0.765204, BCE loss: 0.522921, SB loss: 0.736179
2023-10-30 13:07:17,860 Epoch: [242/484] Iter:[240/495], Time: 0.37, lr: [0.005349203472801129], Loss: 2.027422, Acc:0.799377, Semantic loss: 0.766671, BCE loss: 0.523724, SB loss: 0.737028
2023-10-30 13:07:21,557 Epoch: [242/484] Iter:[250/495], Time: 0.37, lr: [0.005348800770729934], Loss: 2.027764, Acc:0.800757, Semantic loss: 0.764971, BCE loss: 0.526764, SB loss: 0.736029
2023-10-30 13:07:25,172 Epoch: [242/484] Iter:[260/495], Time: 0.37, lr: [0.0053483980652899565], Loss: 2.032524, Acc:0.800620, Semantic loss: 0.767058, BCE loss: 0.526570, SB loss: 0.738896
2023-10-30 13:07:28,837 Epoch: [242/484] Iter:[270/495], Time: 0.37, lr: [0.005347995356480894], Loss: 2.030008, Acc:0.801248, Semantic loss: 0.765028, BCE loss: 0.527384, SB loss: 0.737596
2023-10-30 13:07:32,559 Epoch: [242/484] Iter:[280/495], Time: 0.37, lr: [0.0053475926443024326], Loss: 2.031433, Acc:0.801279, Semantic loss: 0.763883, BCE loss: 0.530324, SB loss: 0.737225
2023-10-30 13:07:36,110 Epoch: [242/484] Iter:[290/495], Time: 0.37, lr: [0.005347189928754262], Loss: 2.029030, Acc:0.800754, Semantic loss: 0.762693, BCE loss: 0.529375, SB loss: 0.736962
2023-10-30 13:07:39,698 Epoch: [242/484] Iter:[300/495], Time: 0.37, lr: [0.0053467872098360725], Loss: 2.022338, Acc:0.800314, Semantic loss: 0.759251, BCE loss: 0.528239, SB loss: 0.734848
2023-10-30 13:07:43,366 Epoch: [242/484] Iter:[310/495], Time: 0.37, lr: [0.005346384487547555], Loss: 2.025967, Acc:0.801286, Semantic loss: 0.760695, BCE loss: 0.530567, SB loss: 0.734705
2023-10-30 13:07:47,084 Epoch: [242/484] Iter:[320/495], Time: 0.37, lr: [0.0053459817618883975], Loss: 2.029033, Acc:0.801215, Semantic loss: 0.762858, BCE loss: 0.530827, SB loss: 0.735348
2023-10-30 13:07:50,703 Epoch: [242/484] Iter:[330/495], Time: 0.37, lr: [0.005345579032858292], Loss: 2.025873, Acc:0.801317, Semantic loss: 0.761601, BCE loss: 0.529818, SB loss: 0.734453
2023-10-30 13:07:54,287 Epoch: [242/484] Iter:[340/495], Time: 0.37, lr: [0.005345176300456924], Loss: 2.029425, Acc:0.800880, Semantic loss: 0.763668, BCE loss: 0.531101, SB loss: 0.734656
2023-10-30 13:07:57,981 Epoch: [242/484] Iter:[350/495], Time: 0.37, lr: [0.005344773564683988], Loss: 2.028787, Acc:0.800838, Semantic loss: 0.763201, BCE loss: 0.531128, SB loss: 0.734458
2023-10-30 13:08:01,678 Epoch: [242/484] Iter:[360/495], Time: 0.37, lr: [0.00534437082553917], Loss: 2.033573, Acc:0.800255, Semantic loss: 0.765180, BCE loss: 0.532810, SB loss: 0.735582
2023-10-30 13:08:05,317 Epoch: [242/484] Iter:[370/495], Time: 0.37, lr: [0.0053439680830221605], Loss: 2.030418, Acc:0.800328, Semantic loss: 0.763954, BCE loss: 0.531550, SB loss: 0.734914
2023-10-30 13:08:09,051 Epoch: [242/484] Iter:[380/495], Time: 0.37, lr: [0.005343565337132648], Loss: 2.031811, Acc:0.801231, Semantic loss: 0.765919, BCE loss: 0.530632, SB loss: 0.735260
2023-10-30 13:08:12,638 Epoch: [242/484] Iter:[390/495], Time: 0.37, lr: [0.005343162587870324], Loss: 2.030071, Acc:0.800270, Semantic loss: 0.764893, BCE loss: 0.530349, SB loss: 0.734829
2023-10-30 13:08:16,236 Epoch: [242/484] Iter:[400/495], Time: 0.37, lr: [0.005342759835234876], Loss: 2.029766, Acc:0.800803, Semantic loss: 0.764166, BCE loss: 0.530423, SB loss: 0.735177
2023-10-30 13:08:19,937 Epoch: [242/484] Iter:[410/495], Time: 0.37, lr: [0.005342357079225994], Loss: 2.029162, Acc:0.800165, Semantic loss: 0.764556, BCE loss: 0.529432, SB loss: 0.735173
2023-10-30 13:08:23,588 Epoch: [242/484] Iter:[420/495], Time: 0.37, lr: [0.0053419543198433665], Loss: 2.029197, Acc:0.800846, Semantic loss: 0.764548, BCE loss: 0.529561, SB loss: 0.735089
2023-10-30 13:08:27,219 Epoch: [242/484] Iter:[430/495], Time: 0.37, lr: [0.005341551557086682], Loss: 2.031160, Acc:0.800657, Semantic loss: 0.764656, BCE loss: 0.530774, SB loss: 0.735731
2023-10-30 13:08:30,864 Epoch: [242/484] Iter:[440/495], Time: 0.37, lr: [0.005341148790955632], Loss: 2.030973, Acc:0.800070, Semantic loss: 0.764674, BCE loss: 0.530420, SB loss: 0.735879
2023-10-30 13:08:34,501 Epoch: [242/484] Iter:[450/495], Time: 0.37, lr: [0.005340746021449904], Loss: 2.028770, Acc:0.800072, Semantic loss: 0.762941, BCE loss: 0.530471, SB loss: 0.735359
2023-10-30 13:08:38,085 Epoch: [242/484] Iter:[460/495], Time: 0.37, lr: [0.005340343248569186], Loss: 2.029783, Acc:0.800876, Semantic loss: 0.763165, BCE loss: 0.531151, SB loss: 0.735467
2023-10-30 13:08:41,694 Epoch: [242/484] Iter:[470/495], Time: 0.37, lr: [0.005339940472313168], Loss: 2.026948, Acc:0.800820, Semantic loss: 0.762167, BCE loss: 0.529938, SB loss: 0.734844
2023-10-30 13:08:45,396 Epoch: [242/484] Iter:[480/495], Time: 0.37, lr: [0.00533953769268154], Loss: 2.031433, Acc:0.801112, Semantic loss: 0.764324, BCE loss: 0.531417, SB loss: 0.735693
2023-10-30 13:08:48,921 Epoch: [242/484] Iter:[490/495], Time: 0.37, lr: [0.005339134909673989], Loss: 2.027308, Acc:0.800822, Semantic loss: 0.762488, BCE loss: 0.529869, SB loss: 0.734952
2023-10-30 13:08:50,319 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:08:50,559 Loss: 2.047, MeanIU:  0.6607, Best_mIoU:  0.7151
2023-10-30 13:08:50,559 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502]
2023-10-30 13:08:52,345 Epoch: [243/484] Iter:[0/495], Time: 1.75, lr: [0.005338933516904143], Loss: 1.751245, Acc:0.817890, Semantic loss: 0.652882, BCE loss: 0.371952, SB loss: 0.726412
2023-10-30 13:08:56,359 Epoch: [243/484] Iter:[10/495], Time: 0.52, lr: [0.005338530728832124], Loss: 1.966774, Acc:0.763283, Semantic loss: 0.758635, BCE loss: 0.434641, SB loss: 0.773497
2023-10-30 13:08:59,973 Epoch: [243/484] Iter:[20/495], Time: 0.45, lr: [0.005338127937383404], Loss: 1.994875, Acc:0.782963, Semantic loss: 0.752341, BCE loss: 0.483603, SB loss: 0.758930
2023-10-30 13:09:03,583 Epoch: [243/484] Iter:[30/495], Time: 0.42, lr: [0.005337725142557672], Loss: 2.052687, Acc:0.794463, Semantic loss: 0.786883, BCE loss: 0.513071, SB loss: 0.752733
2023-10-30 13:09:07,189 Epoch: [243/484] Iter:[40/495], Time: 0.40, lr: [0.005337322344354616], Loss: 1.990110, Acc:0.799017, Semantic loss: 0.745541, BCE loss: 0.512997, SB loss: 0.731572
2023-10-30 13:09:10,696 Epoch: [243/484] Iter:[50/495], Time: 0.39, lr: [0.005336919542773925], Loss: 2.009937, Acc:0.795268, Semantic loss: 0.767123, BCE loss: 0.508334, SB loss: 0.734480
2023-10-30 13:09:14,273 Epoch: [243/484] Iter:[60/495], Time: 0.39, lr: [0.005336516737815287], Loss: 2.005085, Acc:0.792907, Semantic loss: 0.763788, BCE loss: 0.502015, SB loss: 0.739282
2023-10-30 13:09:17,850 Epoch: [243/484] Iter:[70/495], Time: 0.38, lr: [0.005336113929478391], Loss: 1.991996, Acc:0.792604, Semantic loss: 0.755716, BCE loss: 0.500544, SB loss: 0.735736
2023-10-30 13:09:21,487 Epoch: [243/484] Iter:[80/495], Time: 0.38, lr: [0.0053357111177629235], Loss: 2.019082, Acc:0.793181, Semantic loss: 0.770316, BCE loss: 0.508782, SB loss: 0.739984
2023-10-30 13:09:25,107 Epoch: [243/484] Iter:[90/495], Time: 0.38, lr: [0.0053353083026685755], Loss: 2.046501, Acc:0.795755, Semantic loss: 0.784364, BCE loss: 0.517096, SB loss: 0.745041
2023-10-30 13:09:28,690 Epoch: [243/484] Iter:[100/495], Time: 0.38, lr: [0.005334905484195033], Loss: 2.062360, Acc:0.796935, Semantic loss: 0.791059, BCE loss: 0.522903, SB loss: 0.748399
2023-10-30 13:09:32,277 Epoch: [243/484] Iter:[110/495], Time: 0.38, lr: [0.005334502662341986], Loss: 2.053566, Acc:0.798361, Semantic loss: 0.785898, BCE loss: 0.522309, SB loss: 0.745359
2023-10-30 13:09:35,906 Epoch: [243/484] Iter:[120/495], Time: 0.37, lr: [0.00533409983710912], Loss: 2.050428, Acc:0.800171, Semantic loss: 0.780110, BCE loss: 0.524890, SB loss: 0.745428
2023-10-30 13:09:39,513 Epoch: [243/484] Iter:[130/495], Time: 0.37, lr: [0.005333697008496126], Loss: 2.060625, Acc:0.803925, Semantic loss: 0.780737, BCE loss: 0.531222, SB loss: 0.748665
2023-10-30 13:09:43,158 Epoch: [243/484] Iter:[140/495], Time: 0.37, lr: [0.005333294176502689], Loss: 2.065490, Acc:0.799828, Semantic loss: 0.786526, BCE loss: 0.527964, SB loss: 0.751000
2023-10-30 13:09:46,729 Epoch: [243/484] Iter:[150/495], Time: 0.37, lr: [0.0053328913411285], Loss: 2.075042, Acc:0.799165, Semantic loss: 0.789155, BCE loss: 0.531962, SB loss: 0.753925
2023-10-30 13:09:50,330 Epoch: [243/484] Iter:[160/495], Time: 0.37, lr: [0.0053324885023732435], Loss: 2.065625, Acc:0.796286, Semantic loss: 0.785464, BCE loss: 0.528850, SB loss: 0.751310
2023-10-30 13:09:53,992 Epoch: [243/484] Iter:[170/495], Time: 0.37, lr: [0.0053320856602366105], Loss: 2.067176, Acc:0.797150, Semantic loss: 0.785670, BCE loss: 0.530723, SB loss: 0.750783
2023-10-30 13:09:57,635 Epoch: [243/484] Iter:[180/495], Time: 0.37, lr: [0.005331682814718288], Loss: 2.057330, Acc:0.795236, Semantic loss: 0.779155, BCE loss: 0.530660, SB loss: 0.747515
2023-10-30 13:10:01,361 Epoch: [243/484] Iter:[190/495], Time: 0.37, lr: [0.005331279965817963], Loss: 2.057200, Acc:0.795159, Semantic loss: 0.777333, BCE loss: 0.530939, SB loss: 0.748928
2023-10-30 13:10:04,931 Epoch: [243/484] Iter:[200/495], Time: 0.37, lr: [0.005330877113535322], Loss: 2.058963, Acc:0.797257, Semantic loss: 0.779946, BCE loss: 0.532442, SB loss: 0.746575
2023-10-30 13:10:08,677 Epoch: [243/484] Iter:[210/495], Time: 0.37, lr: [0.005330474257870055], Loss: 2.061496, Acc:0.794241, Semantic loss: 0.783443, BCE loss: 0.530612, SB loss: 0.747441
2023-10-30 13:10:12,264 Epoch: [243/484] Iter:[220/495], Time: 0.37, lr: [0.005330071398821848], Loss: 2.062999, Acc:0.794528, Semantic loss: 0.782610, BCE loss: 0.533598, SB loss: 0.746791
2023-10-30 13:10:15,956 Epoch: [243/484] Iter:[230/495], Time: 0.37, lr: [0.00532966853639039], Loss: 2.070894, Acc:0.796002, Semantic loss: 0.784042, BCE loss: 0.539255, SB loss: 0.747597
2023-10-30 13:10:19,537 Epoch: [243/484] Iter:[240/495], Time: 0.37, lr: [0.005329265670575365], Loss: 2.074329, Acc:0.796517, Semantic loss: 0.786383, BCE loss: 0.539934, SB loss: 0.748012
2023-10-30 13:10:23,221 Epoch: [243/484] Iter:[250/495], Time: 0.37, lr: [0.005328862801376465], Loss: 2.071948, Acc:0.797572, Semantic loss: 0.784550, BCE loss: 0.541006, SB loss: 0.746392
2023-10-30 13:10:26,813 Epoch: [243/484] Iter:[260/495], Time: 0.37, lr: [0.0053284599287933745], Loss: 2.083420, Acc:0.796598, Semantic loss: 0.793021, BCE loss: 0.540698, SB loss: 0.749700
2023-10-30 13:10:30,621 Epoch: [243/484] Iter:[270/495], Time: 0.37, lr: [0.005328057052825781], Loss: 2.095709, Acc:0.796582, Semantic loss: 0.799377, BCE loss: 0.543092, SB loss: 0.753240
2023-10-30 13:10:34,240 Epoch: [243/484] Iter:[280/495], Time: 0.37, lr: [0.005327654173473372], Loss: 2.097659, Acc:0.796064, Semantic loss: 0.799729, BCE loss: 0.543784, SB loss: 0.754147
2023-10-30 13:10:37,873 Epoch: [243/484] Iter:[290/495], Time: 0.37, lr: [0.0053272512907358354], Loss: 2.091122, Acc:0.794936, Semantic loss: 0.795486, BCE loss: 0.542212, SB loss: 0.753424
2023-10-30 13:10:41,552 Epoch: [243/484] Iter:[300/495], Time: 0.37, lr: [0.005326848404612857], Loss: 2.090083, Acc:0.795129, Semantic loss: 0.794329, BCE loss: 0.542327, SB loss: 0.753426
2023-10-30 13:10:45,219 Epoch: [243/484] Iter:[310/495], Time: 0.37, lr: [0.005326445515104124], Loss: 2.088416, Acc:0.795271, Semantic loss: 0.794100, BCE loss: 0.541315, SB loss: 0.753001
2023-10-30 13:10:48,826 Epoch: [243/484] Iter:[320/495], Time: 0.37, lr: [0.005326042622209324], Loss: 2.089723, Acc:0.794903, Semantic loss: 0.794198, BCE loss: 0.542364, SB loss: 0.753161
2023-10-30 13:10:52,625 Epoch: [243/484] Iter:[330/495], Time: 0.37, lr: [0.005325639725928144], Loss: 2.093743, Acc:0.794438, Semantic loss: 0.797010, BCE loss: 0.542721, SB loss: 0.754012
2023-10-30 13:10:56,182 Epoch: [243/484] Iter:[340/495], Time: 0.37, lr: [0.005325236826260272], Loss: 2.087130, Acc:0.794575, Semantic loss: 0.793387, BCE loss: 0.541490, SB loss: 0.752253
2023-10-30 13:10:59,762 Epoch: [243/484] Iter:[350/495], Time: 0.37, lr: [0.005324833923205391], Loss: 2.088812, Acc:0.793768, Semantic loss: 0.794578, BCE loss: 0.541456, SB loss: 0.752778
2023-10-30 13:11:03,529 Epoch: [243/484] Iter:[360/495], Time: 0.37, lr: [0.005324431016763192], Loss: 2.087478, Acc:0.793743, Semantic loss: 0.794322, BCE loss: 0.540325, SB loss: 0.752830
2023-10-30 13:11:07,097 Epoch: [243/484] Iter:[370/495], Time: 0.37, lr: [0.005324028106933359], Loss: 2.081168, Acc:0.794458, Semantic loss: 0.791720, BCE loss: 0.537930, SB loss: 0.751518
2023-10-30 13:11:10,856 Epoch: [243/484] Iter:[380/495], Time: 0.37, lr: [0.00532362519371558], Loss: 2.084349, Acc:0.793725, Semantic loss: 0.792658, BCE loss: 0.540334, SB loss: 0.751357
2023-10-30 13:11:14,484 Epoch: [243/484] Iter:[390/495], Time: 0.37, lr: [0.005323222277109542], Loss: 2.085292, Acc:0.794640, Semantic loss: 0.792761, BCE loss: 0.540880, SB loss: 0.751651
2023-10-30 13:11:18,128 Epoch: [243/484] Iter:[400/495], Time: 0.37, lr: [0.005322819357114928], Loss: 2.082708, Acc:0.794640, Semantic loss: 0.791657, BCE loss: 0.540003, SB loss: 0.751048
2023-10-30 13:11:21,730 Epoch: [243/484] Iter:[410/495], Time: 0.37, lr: [0.005322416433731429], Loss: 2.077309, Acc:0.794964, Semantic loss: 0.789182, BCE loss: 0.538552, SB loss: 0.749575
2023-10-30 13:11:25,458 Epoch: [243/484] Iter:[420/495], Time: 0.37, lr: [0.005322013506958731], Loss: 2.079766, Acc:0.794738, Semantic loss: 0.792913, BCE loss: 0.537183, SB loss: 0.749670
2023-10-30 13:11:29,076 Epoch: [243/484] Iter:[430/495], Time: 0.37, lr: [0.005321610576796519], Loss: 2.074440, Acc:0.794862, Semantic loss: 0.789921, BCE loss: 0.536311, SB loss: 0.748208
2023-10-30 13:11:32,763 Epoch: [243/484] Iter:[440/495], Time: 0.37, lr: [0.0053212076432444765], Loss: 2.077134, Acc:0.794702, Semantic loss: 0.790257, BCE loss: 0.537549, SB loss: 0.749328
2023-10-30 13:11:36,494 Epoch: [243/484] Iter:[450/495], Time: 0.37, lr: [0.005320804706302295], Loss: 2.080214, Acc:0.794218, Semantic loss: 0.792594, BCE loss: 0.537107, SB loss: 0.750514
2023-10-30 13:11:40,159 Epoch: [243/484] Iter:[460/495], Time: 0.37, lr: [0.005320401765969658], Loss: 2.081445, Acc:0.794569, Semantic loss: 0.793335, BCE loss: 0.537129, SB loss: 0.750981
2023-10-30 13:11:43,888 Epoch: [243/484] Iter:[470/495], Time: 0.37, lr: [0.005319998822246252], Loss: 2.080831, Acc:0.794383, Semantic loss: 0.792842, BCE loss: 0.537347, SB loss: 0.750641
2023-10-30 13:11:47,442 Epoch: [243/484] Iter:[480/495], Time: 0.37, lr: [0.005319595875131763], Loss: 2.082238, Acc:0.794174, Semantic loss: 0.792490, BCE loss: 0.539306, SB loss: 0.750442
2023-10-30 13:11:50,865 Epoch: [243/484] Iter:[490/495], Time: 0.37, lr: [0.005319192924625877], Loss: 2.077463, Acc:0.793415, Semantic loss: 0.789852, BCE loss: 0.537991, SB loss: 0.749620
2023-10-30 13:11:52,268 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:11:52,499 Loss: 2.047, MeanIU:  0.6607, Best_mIoU:  0.7151
2023-10-30 13:11:52,499 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502]
2023-10-30 13:11:54,483 Epoch: [244/484] Iter:[0/495], Time: 1.95, lr: [0.005318991448101063], Loss: 2.338132, Acc:0.886042, Semantic loss: 0.815186, BCE loss: 0.750775, SB loss: 0.772171
2023-10-30 13:11:58,353 Epoch: [244/484] Iter:[10/495], Time: 0.53, lr: [0.005318588492507493], Loss: 2.158823, Acc:0.830380, Semantic loss: 0.823034, BCE loss: 0.566394, SB loss: 0.769395
2023-10-30 13:12:01,971 Epoch: [244/484] Iter:[20/495], Time: 0.45, lr: [0.005318185533521741], Loss: 2.140141, Acc:0.819618, Semantic loss: 0.820062, BCE loss: 0.553563, SB loss: 0.766516
2023-10-30 13:12:05,687 Epoch: [244/484] Iter:[30/495], Time: 0.42, lr: [0.005317782571143494], Loss: 2.065368, Acc:0.804695, Semantic loss: 0.792725, BCE loss: 0.526148, SB loss: 0.746495
2023-10-30 13:12:09,366 Epoch: [244/484] Iter:[40/495], Time: 0.41, lr: [0.005317379605372436], Loss: 2.055532, Acc:0.806938, Semantic loss: 0.776318, BCE loss: 0.528387, SB loss: 0.750826
2023-10-30 13:12:12,971 Epoch: [244/484] Iter:[50/495], Time: 0.40, lr: [0.005316976636208254], Loss: 2.056879, Acc:0.806845, Semantic loss: 0.782018, BCE loss: 0.525068, SB loss: 0.749793
2023-10-30 13:12:16,661 Epoch: [244/484] Iter:[60/495], Time: 0.40, lr: [0.005316573663650632], Loss: 2.067256, Acc:0.806724, Semantic loss: 0.797833, BCE loss: 0.523094, SB loss: 0.746328
2023-10-30 13:12:20,357 Epoch: [244/484] Iter:[70/495], Time: 0.39, lr: [0.005316170687699258], Loss: 2.052676, Acc:0.810382, Semantic loss: 0.784404, BCE loss: 0.527907, SB loss: 0.740364
2023-10-30 13:12:23,928 Epoch: [244/484] Iter:[80/495], Time: 0.39, lr: [0.005315767708353816], Loss: 2.043507, Acc:0.808218, Semantic loss: 0.777857, BCE loss: 0.526233, SB loss: 0.739417
2023-10-30 13:12:27,516 Epoch: [244/484] Iter:[90/495], Time: 0.38, lr: [0.005315364725613991], Loss: 2.044066, Acc:0.804512, Semantic loss: 0.779491, BCE loss: 0.520942, SB loss: 0.743633
2023-10-30 13:12:31,048 Epoch: [244/484] Iter:[100/495], Time: 0.38, lr: [0.00531496173947947], Loss: 2.034688, Acc:0.800472, Semantic loss: 0.778133, BCE loss: 0.514212, SB loss: 0.742343
2023-10-30 13:12:34,739 Epoch: [244/484] Iter:[110/495], Time: 0.38, lr: [0.0053145587499499386], Loss: 2.040978, Acc:0.802211, Semantic loss: 0.782853, BCE loss: 0.516305, SB loss: 0.741820
2023-10-30 13:12:38,352 Epoch: [244/484] Iter:[120/495], Time: 0.38, lr: [0.005314155757025081], Loss: 2.045105, Acc:0.802557, Semantic loss: 0.782229, BCE loss: 0.520953, SB loss: 0.741923
2023-10-30 13:12:41,934 Epoch: [244/484] Iter:[130/495], Time: 0.38, lr: [0.005313752760704582], Loss: 2.028750, Acc:0.798569, Semantic loss: 0.772736, BCE loss: 0.516528, SB loss: 0.739486
2023-10-30 13:12:45,463 Epoch: [244/484] Iter:[140/495], Time: 0.38, lr: [0.005313349760988128], Loss: 2.038281, Acc:0.795147, Semantic loss: 0.778293, BCE loss: 0.518617, SB loss: 0.741371
2023-10-30 13:12:49,108 Epoch: [244/484] Iter:[150/495], Time: 0.37, lr: [0.005312946757875405], Loss: 2.040560, Acc:0.794268, Semantic loss: 0.777220, BCE loss: 0.521597, SB loss: 0.741743
2023-10-30 13:12:52,705 Epoch: [244/484] Iter:[160/495], Time: 0.37, lr: [0.0053125437513660955], Loss: 2.043461, Acc:0.793610, Semantic loss: 0.775531, BCE loss: 0.525376, SB loss: 0.742554
2023-10-30 13:12:56,341 Epoch: [244/484] Iter:[170/495], Time: 0.37, lr: [0.0053121407414598865], Loss: 2.049446, Acc:0.793578, Semantic loss: 0.777277, BCE loss: 0.527320, SB loss: 0.744849
2023-10-30 13:12:59,987 Epoch: [244/484] Iter:[180/495], Time: 0.37, lr: [0.005311737728156462], Loss: 2.053843, Acc:0.793982, Semantic loss: 0.780233, BCE loss: 0.527545, SB loss: 0.746065
2023-10-30 13:13:03,599 Epoch: [244/484] Iter:[190/495], Time: 0.37, lr: [0.005311334711455509], Loss: 2.046672, Acc:0.792818, Semantic loss: 0.774236, BCE loss: 0.527082, SB loss: 0.745354
2023-10-30 13:13:07,242 Epoch: [244/484] Iter:[200/495], Time: 0.37, lr: [0.005310931691356709], Loss: 2.039950, Acc:0.792865, Semantic loss: 0.771641, BCE loss: 0.524193, SB loss: 0.744116
2023-10-30 13:13:10,923 Epoch: [244/484] Iter:[210/495], Time: 0.37, lr: [0.005310528667859751], Loss: 2.042520, Acc:0.794698, Semantic loss: 0.772301, BCE loss: 0.524047, SB loss: 0.746172
2023-10-30 13:13:14,577 Epoch: [244/484] Iter:[220/495], Time: 0.37, lr: [0.005310125640964316], Loss: 2.036680, Acc:0.794648, Semantic loss: 0.768960, BCE loss: 0.523517, SB loss: 0.744203
2023-10-30 13:13:18,221 Epoch: [244/484] Iter:[230/495], Time: 0.37, lr: [0.005309722610670091], Loss: 2.039239, Acc:0.795133, Semantic loss: 0.769620, BCE loss: 0.524379, SB loss: 0.745240
2023-10-30 13:13:21,801 Epoch: [244/484] Iter:[240/495], Time: 0.37, lr: [0.00530931957697676], Loss: 2.038699, Acc:0.795307, Semantic loss: 0.768349, BCE loss: 0.525472, SB loss: 0.744878
2023-10-30 13:13:25,445 Epoch: [244/484] Iter:[250/495], Time: 0.37, lr: [0.0053089165398840085], Loss: 2.043006, Acc:0.795789, Semantic loss: 0.770718, BCE loss: 0.527264, SB loss: 0.745024
2023-10-30 13:13:28,966 Epoch: [244/484] Iter:[260/495], Time: 0.37, lr: [0.0053085134993915185], Loss: 2.040545, Acc:0.793716, Semantic loss: 0.772056, BCE loss: 0.525464, SB loss: 0.743024
2023-10-30 13:13:32,614 Epoch: [244/484] Iter:[270/495], Time: 0.37, lr: [0.0053081104554989775], Loss: 2.038508, Acc:0.794142, Semantic loss: 0.771393, BCE loss: 0.525324, SB loss: 0.741791
2023-10-30 13:13:36,227 Epoch: [244/484] Iter:[280/495], Time: 0.37, lr: [0.005307707408206068], Loss: 2.040483, Acc:0.793676, Semantic loss: 0.771226, BCE loss: 0.528823, SB loss: 0.740434
2023-10-30 13:13:39,877 Epoch: [244/484] Iter:[290/495], Time: 0.37, lr: [0.005307304357512476], Loss: 2.041489, Acc:0.794438, Semantic loss: 0.773142, BCE loss: 0.528214, SB loss: 0.740133
2023-10-30 13:13:43,554 Epoch: [244/484] Iter:[300/495], Time: 0.37, lr: [0.005306901303417884], Loss: 2.044239, Acc:0.794724, Semantic loss: 0.775407, BCE loss: 0.528030, SB loss: 0.740801
2023-10-30 13:13:47,328 Epoch: [244/484] Iter:[310/495], Time: 0.37, lr: [0.005306498245921978], Loss: 2.045303, Acc:0.795730, Semantic loss: 0.773610, BCE loss: 0.531593, SB loss: 0.740100
2023-10-30 13:13:51,000 Epoch: [244/484] Iter:[320/495], Time: 0.37, lr: [0.005306095185024441], Loss: 2.046205, Acc:0.795564, Semantic loss: 0.774645, BCE loss: 0.530218, SB loss: 0.741342
2023-10-30 13:13:54,646 Epoch: [244/484] Iter:[330/495], Time: 0.37, lr: [0.0053056921207249585], Loss: 2.042097, Acc:0.796032, Semantic loss: 0.772338, BCE loss: 0.529328, SB loss: 0.740431
2023-10-30 13:13:58,328 Epoch: [244/484] Iter:[340/495], Time: 0.37, lr: [0.005305289053023212], Loss: 2.040650, Acc:0.796942, Semantic loss: 0.772349, BCE loss: 0.528519, SB loss: 0.739783
2023-10-30 13:14:02,000 Epoch: [244/484] Iter:[350/495], Time: 0.37, lr: [0.005304885981918889], Loss: 2.035726, Acc:0.796737, Semantic loss: 0.769688, BCE loss: 0.527139, SB loss: 0.738899
2023-10-30 13:14:05,557 Epoch: [244/484] Iter:[360/495], Time: 0.37, lr: [0.005304482907411672], Loss: 2.032907, Acc:0.797132, Semantic loss: 0.769137, BCE loss: 0.525170, SB loss: 0.738600
2023-10-30 13:14:09,270 Epoch: [244/484] Iter:[370/495], Time: 0.37, lr: [0.0053040798295012435], Loss: 2.032964, Acc:0.797199, Semantic loss: 0.769670, BCE loss: 0.524629, SB loss: 0.738665
2023-10-30 13:14:12,944 Epoch: [244/484] Iter:[380/495], Time: 0.37, lr: [0.00530367674818729], Loss: 2.034860, Acc:0.796455, Semantic loss: 0.770701, BCE loss: 0.524954, SB loss: 0.739205
2023-10-30 13:14:16,609 Epoch: [244/484] Iter:[390/495], Time: 0.37, lr: [0.0053032736634694945], Loss: 2.035391, Acc:0.796400, Semantic loss: 0.770318, BCE loss: 0.525724, SB loss: 0.739349
2023-10-30 13:14:20,206 Epoch: [244/484] Iter:[400/495], Time: 0.37, lr: [0.005302870575347539], Loss: 2.035726, Acc:0.796795, Semantic loss: 0.771062, BCE loss: 0.525568, SB loss: 0.739096
2023-10-30 13:14:23,823 Epoch: [244/484] Iter:[410/495], Time: 0.37, lr: [0.005302467483821108], Loss: 2.032200, Acc:0.795989, Semantic loss: 0.769086, BCE loss: 0.525600, SB loss: 0.737514
2023-10-30 13:14:27,420 Epoch: [244/484] Iter:[420/495], Time: 0.37, lr: [0.005302064388889888], Loss: 2.031417, Acc:0.795959, Semantic loss: 0.769044, BCE loss: 0.524865, SB loss: 0.737508
2023-10-30 13:14:31,075 Epoch: [244/484] Iter:[430/495], Time: 0.37, lr: [0.0053016612905535596], Loss: 2.032706, Acc:0.796110, Semantic loss: 0.769618, BCE loss: 0.525929, SB loss: 0.737159
2023-10-30 13:14:34,778 Epoch: [244/484] Iter:[440/495], Time: 0.37, lr: [0.005301258188811809], Loss: 2.032412, Acc:0.796375, Semantic loss: 0.770675, BCE loss: 0.525535, SB loss: 0.736203
2023-10-30 13:14:38,455 Epoch: [244/484] Iter:[450/495], Time: 0.37, lr: [0.005300855083664314], Loss: 2.034141, Acc:0.796889, Semantic loss: 0.770333, BCE loss: 0.526871, SB loss: 0.736937
2023-10-30 13:14:42,000 Epoch: [244/484] Iter:[460/495], Time: 0.37, lr: [0.005300451975110764], Loss: 2.035087, Acc:0.797088, Semantic loss: 0.769354, BCE loss: 0.528516, SB loss: 0.737218
2023-10-30 13:14:45,668 Epoch: [244/484] Iter:[470/495], Time: 0.37, lr: [0.005300048863150841], Loss: 2.033565, Acc:0.796786, Semantic loss: 0.768078, BCE loss: 0.528656, SB loss: 0.736830
2023-10-30 13:14:49,244 Epoch: [244/484] Iter:[480/495], Time: 0.37, lr: [0.005299645747784227], Loss: 2.032290, Acc:0.796896, Semantic loss: 0.767062, BCE loss: 0.528233, SB loss: 0.736995
2023-10-30 13:14:52,751 Epoch: [244/484] Iter:[490/495], Time: 0.37, lr: [0.005299242629010606], Loss: 2.032102, Acc:0.796956, Semantic loss: 0.767276, BCE loss: 0.528040, SB loss: 0.736786
2023-10-30 13:14:54,162 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:14:54,398 Loss: 2.047, MeanIU:  0.6607, Best_mIoU:  0.7151
2023-10-30 13:14:54,398 [0.97228308 0.80327876 0.9008585  0.38384372 0.50224521 0.58543331
 0.62637581 0.69871103 0.91105545 0.59800312 0.93146323 0.7285973
 0.56108717 0.90514944 0.41605055 0.47488813 0.35837466 0.48544683
 0.71077502]
2023-10-30 13:14:56,430 Epoch: [245/484] Iter:[0/495], Time: 2.00, lr: [0.005299041068346068], Loss: 1.931522, Acc:0.777868, Semantic loss: 0.687794, BCE loss: 0.556650, SB loss: 0.687078
2023-10-30 13:15:00,481 Epoch: [245/484] Iter:[10/495], Time: 0.55, lr: [0.0052986379444613435], Loss: 2.164627, Acc:0.793568, Semantic loss: 0.874333, BCE loss: 0.545795, SB loss: 0.744498
2023-10-30 13:15:04,109 Epoch: [245/484] Iter:[20/495], Time: 0.46, lr: [0.0052982348171688185], Loss: 2.151856, Acc:0.793682, Semantic loss: 0.850752, BCE loss: 0.542855, SB loss: 0.758249
2023-10-30 13:15:07,771 Epoch: [245/484] Iter:[30/495], Time: 0.43, lr: [0.0052978316864681785], Loss: 2.145542, Acc:0.780128, Semantic loss: 0.840459, BCE loss: 0.532995, SB loss: 0.772088
2023-10-30 13:15:11,419 Epoch: [245/484] Iter:[40/495], Time: 0.41, lr: [0.005297428552359104], Loss: 2.114646, Acc:0.779181, Semantic loss: 0.820465, BCE loss: 0.533620, SB loss: 0.760562
2023-10-30 13:15:15,018 Epoch: [245/484] Iter:[50/495], Time: 0.40, lr: [0.0052970254148412815], Loss: 2.112515, Acc:0.785374, Semantic loss: 0.815936, BCE loss: 0.543352, SB loss: 0.753226
2023-10-30 13:15:18,627 Epoch: [245/484] Iter:[60/495], Time: 0.40, lr: [0.005296622273914391], Loss: 2.098167, Acc:0.785437, Semantic loss: 0.803681, BCE loss: 0.538502, SB loss: 0.755984
2023-10-30 13:15:22,297 Epoch: [245/484] Iter:[70/495], Time: 0.39, lr: [0.005296219129578116], Loss: 2.106642, Acc:0.783424, Semantic loss: 0.807344, BCE loss: 0.539279, SB loss: 0.760019
2023-10-30 13:15:26,011 Epoch: [245/484] Iter:[80/495], Time: 0.39, lr: [0.00529581598183214], Loss: 2.094080, Acc:0.786711, Semantic loss: 0.799684, BCE loss: 0.535237, SB loss: 0.759158
2023-10-30 13:15:29,730 Epoch: [245/484] Iter:[90/495], Time: 0.39, lr: [0.005295412830676145], Loss: 2.093048, Acc:0.788675, Semantic loss: 0.799110, BCE loss: 0.534605, SB loss: 0.759333
2023-10-30 13:15:33,358 Epoch: [245/484] Iter:[100/495], Time: 0.39, lr: [0.0052950096761098155], Loss: 2.079957, Acc:0.788091, Semantic loss: 0.795940, BCE loss: 0.529102, SB loss: 0.754914
2023-10-30 13:15:36,983 Epoch: [245/484] Iter:[110/495], Time: 0.38, lr: [0.005294606518132832], Loss: 2.063665, Acc:0.787416, Semantic loss: 0.788305, BCE loss: 0.524672, SB loss: 0.750688
2023-10-30 13:15:40,604 Epoch: [245/484] Iter:[120/495], Time: 0.38, lr: [0.005294203356744876], Loss: 2.050997, Acc:0.788031, Semantic loss: 0.781540, BCE loss: 0.522290, SB loss: 0.747167
2023-10-30 13:15:44,277 Epoch: [245/484] Iter:[130/495], Time: 0.38, lr: [0.005293800191945633], Loss: 2.046947, Acc:0.792552, Semantic loss: 0.778873, BCE loss: 0.522577, SB loss: 0.745497
2023-10-30 13:15:47,988 Epoch: [245/484] Iter:[140/495], Time: 0.38, lr: [0.005293397023734785], Loss: 2.050803, Acc:0.790443, Semantic loss: 0.779893, BCE loss: 0.524636, SB loss: 0.746274
2023-10-30 13:15:51,781 Epoch: [245/484] Iter:[150/495], Time: 0.38, lr: [0.005292993852112014], Loss: 2.053029, Acc:0.792243, Semantic loss: 0.781590, BCE loss: 0.523975, SB loss: 0.747464
2023-10-30 13:15:55,381 Epoch: [245/484] Iter:[160/495], Time: 0.38, lr: [0.005292590677077], Loss: 2.055771, Acc:0.794260, Semantic loss: 0.781402, BCE loss: 0.526684, SB loss: 0.747685
2023-10-30 13:15:59,037 Epoch: [245/484] Iter:[170/495], Time: 0.38, lr: [0.00529218749862943], Loss: 2.047839, Acc:0.793092, Semantic loss: 0.778274, BCE loss: 0.523436, SB loss: 0.746129
2023-10-30 13:16:02,788 Epoch: [245/484] Iter:[180/495], Time: 0.38, lr: [0.005291784316768982], Loss: 2.049438, Acc:0.792242, Semantic loss: 0.779098, BCE loss: 0.522750, SB loss: 0.747589
2023-10-30 13:16:06,447 Epoch: [245/484] Iter:[190/495], Time: 0.38, lr: [0.0052913811314953384], Loss: 2.046502, Acc:0.794964, Semantic loss: 0.776732, BCE loss: 0.523430, SB loss: 0.746340
2023-10-30 13:16:10,072 Epoch: [245/484] Iter:[200/495], Time: 0.38, lr: [0.005290977942808185], Loss: 2.049030, Acc:0.795247, Semantic loss: 0.777957, BCE loss: 0.523511, SB loss: 0.747562
2023-10-30 13:16:13,765 Epoch: [245/484] Iter:[210/495], Time: 0.38, lr: [0.005290574750707201], Loss: 2.051857, Acc:0.793217, Semantic loss: 0.780131, BCE loss: 0.522749, SB loss: 0.748977
2023-10-30 13:16:17,448 Epoch: [245/484] Iter:[220/495], Time: 0.38, lr: [0.005290171555192069], Loss: 2.045841, Acc:0.793198, Semantic loss: 0.776518, BCE loss: 0.522451, SB loss: 0.746871
2023-10-30 13:16:21,118 Epoch: [245/484] Iter:[230/495], Time: 0.38, lr: [0.00528976835626247], Loss: 2.039608, Acc:0.792987, Semantic loss: 0.773670, BCE loss: 0.520746, SB loss: 0.745193
2023-10-30 13:16:24,801 Epoch: [245/484] Iter:[240/495], Time: 0.37, lr: [0.005289365153918089], Loss: 2.044629, Acc:0.792792, Semantic loss: 0.777207, BCE loss: 0.522578, SB loss: 0.744843
2023-10-30 13:16:28,457 Epoch: [245/484] Iter:[250/495], Time: 0.37, lr: [0.005288961948158604], Loss: 2.043819, Acc:0.792750, Semantic loss: 0.776871, BCE loss: 0.522196, SB loss: 0.744752
2023-10-30 13:16:32,220 Epoch: [245/484] Iter:[260/495], Time: 0.37, lr: [0.0052885587389836985], Loss: 2.041213, Acc:0.793053, Semantic loss: 0.773638, BCE loss: 0.523541, SB loss: 0.744033
2023-10-30 13:16:35,892 Epoch: [245/484] Iter:[270/495], Time: 0.37, lr: [0.005288155526393055], Loss: 2.038330, Acc:0.793401, Semantic loss: 0.772824, BCE loss: 0.522678, SB loss: 0.742829
2023-10-30 13:16:39,645 Epoch: [245/484] Iter:[280/495], Time: 0.37, lr: [0.0052877523103863535], Loss: 2.039647, Acc:0.794123, Semantic loss: 0.773260, BCE loss: 0.524287, SB loss: 0.742100
2023-10-30 13:16:43,369 Epoch: [245/484] Iter:[290/495], Time: 0.37, lr: [0.005287349090963277], Loss: 2.044986, Acc:0.794646, Semantic loss: 0.775406, BCE loss: 0.525969, SB loss: 0.743611
2023-10-30 13:16:47,074 Epoch: [245/484] Iter:[300/495], Time: 0.37, lr: [0.0052869458681235075], Loss: 2.043077, Acc:0.794249, Semantic loss: 0.775103, BCE loss: 0.524735, SB loss: 0.743240
2023-10-30 13:16:50,694 Epoch: [245/484] Iter:[310/495], Time: 0.37, lr: [0.005286542641866724], Loss: 2.039760, Acc:0.794326, Semantic loss: 0.772905, BCE loss: 0.524363, SB loss: 0.742492
2023-10-30 13:16:54,335 Epoch: [245/484] Iter:[320/495], Time: 0.37, lr: [0.005286139412192611], Loss: 2.033614, Acc:0.794936, Semantic loss: 0.769656, BCE loss: 0.522572, SB loss: 0.741386
2023-10-30 13:16:57,995 Epoch: [245/484] Iter:[330/495], Time: 0.37, lr: [0.005285736179100847], Loss: 2.037610, Acc:0.794506, Semantic loss: 0.772973, BCE loss: 0.522493, SB loss: 0.742144
2023-10-30 13:17:01,669 Epoch: [245/484] Iter:[340/495], Time: 0.37, lr: [0.0052853329425911165], Loss: 2.037169, Acc:0.793419, Semantic loss: 0.773315, BCE loss: 0.521207, SB loss: 0.742646
2023-10-30 13:17:05,382 Epoch: [245/484] Iter:[350/495], Time: 0.37, lr: [0.005284929702663097], Loss: 2.035553, Acc:0.793960, Semantic loss: 0.772710, BCE loss: 0.520929, SB loss: 0.741913
2023-10-30 13:17:09,051 Epoch: [245/484] Iter:[360/495], Time: 0.37, lr: [0.005284526459316473], Loss: 2.040410, Acc:0.793168, Semantic loss: 0.775141, BCE loss: 0.522180, SB loss: 0.743090
2023-10-30 13:17:12,774 Epoch: [245/484] Iter:[370/495], Time: 0.37, lr: [0.005284123212550924], Loss: 2.038445, Acc:0.793793, Semantic loss: 0.775053, BCE loss: 0.520837, SB loss: 0.742554
2023-10-30 13:17:16,460 Epoch: [245/484] Iter:[380/495], Time: 0.37, lr: [0.005283719962366132], Loss: 2.039371, Acc:0.794142, Semantic loss: 0.776171, BCE loss: 0.521677, SB loss: 0.741523
2023-10-30 13:17:20,178 Epoch: [245/484] Iter:[390/495], Time: 0.37, lr: [0.005283316708761777], Loss: 2.038516, Acc:0.794481, Semantic loss: 0.775589, BCE loss: 0.521055, SB loss: 0.741872
2023-10-30 13:17:23,978 Epoch: [245/484] Iter:[400/495], Time: 0.37, lr: [0.0052829134517375425], Loss: 2.041381, Acc:0.794808, Semantic loss: 0.776520, BCE loss: 0.522587, SB loss: 0.742274
2023-10-30 13:17:27,595 Epoch: [245/484] Iter:[410/495], Time: 0.37, lr: [0.005282510191293105], Loss: 2.041558, Acc:0.794526, Semantic loss: 0.777310, BCE loss: 0.521696, SB loss: 0.742552
2023-10-30 13:17:31,313 Epoch: [245/484] Iter:[420/495], Time: 0.37, lr: [0.00528210692742815], Loss: 2.037954, Acc:0.794441, Semantic loss: 0.775567, BCE loss: 0.521334, SB loss: 0.741052
2023-10-30 13:17:34,992 Epoch: [245/484] Iter:[430/495], Time: 0.37, lr: [0.005281703660142354], Loss: 2.037446, Acc:0.795602, Semantic loss: 0.775555, BCE loss: 0.521281, SB loss: 0.740609
2023-10-30 13:17:38,617 Epoch: [245/484] Iter:[440/495], Time: 0.37, lr: [0.0052813003894354015], Loss: 2.040007, Acc:0.795135, Semantic loss: 0.776177, BCE loss: 0.522811, SB loss: 0.741020
2023-10-30 13:17:42,260 Epoch: [245/484] Iter:[450/495], Time: 0.37, lr: [0.005280897115306972], Loss: 2.039794, Acc:0.795378, Semantic loss: 0.775497, BCE loss: 0.523170, SB loss: 0.741127
2023-10-30 13:17:45,874 Epoch: [245/484] Iter:[460/495], Time: 0.37, lr: [0.005280493837756746], Loss: 2.039277, Acc:0.794989, Semantic loss: 0.775932, BCE loss: 0.521198, SB loss: 0.742147
2023-10-30 13:17:49,536 Epoch: [245/484] Iter:[470/495], Time: 0.37, lr: [0.005280090556784403], Loss: 2.041672, Acc:0.794652, Semantic loss: 0.776724, BCE loss: 0.522078, SB loss: 0.742870
2023-10-30 13:17:53,169 Epoch: [245/484] Iter:[480/495], Time: 0.37, lr: [0.005279687272389625], Loss: 2.040864, Acc:0.794848, Semantic loss: 0.775905, BCE loss: 0.522432, SB loss: 0.742527
2023-10-30 13:17:56,664 Epoch: [245/484] Iter:[490/495], Time: 0.37, lr: [0.005279283984572092], Loss: 2.039724, Acc:0.794439, Semantic loss: 0.774538, BCE loss: 0.523233, SB loss: 0.741954
2023-10-30 13:20:46,110 0 [9.28363629e-01 6.02600541e-01 8.30652529e-01 1.56434094e-01
 2.72101284e-01 4.30278233e-01 4.68792209e-01 5.94211618e-01
 8.81538218e-01 4.15348304e-01 8.58779647e-01 5.83549414e-01
 6.52784344e-03 8.15275760e-01 7.14768617e-04 4.65061441e-02
 8.11460881e-02 2.92203658e-02 6.05029572e-01] 0.4530036980826528
2023-10-30 13:20:46,111 1 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747] 0.7103428274542385
2023-10-30 13:20:46,114 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:20:46,373 Loss: 2.011, MeanIU:  0.7103, Best_mIoU:  0.7151
2023-10-30 13:20:46,373 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747]
2023-10-30 13:20:48,249 Epoch: [246/484] Iter:[0/495], Time: 1.84, lr: [0.005279082339379693], Loss: 1.864216, Acc:0.919965, Semantic loss: 0.623551, BCE loss: 0.570219, SB loss: 0.670446
2023-10-30 13:20:51,848 Epoch: [246/484] Iter:[10/495], Time: 0.49, lr: [0.005278679046427427], Loss: 1.877342, Acc:0.809163, Semantic loss: 0.682402, BCE loss: 0.490847, SB loss: 0.704093
2023-10-30 13:20:55,264 Epoch: [246/484] Iter:[20/495], Time: 0.42, lr: [0.005278275750051609], Loss: 1.943464, Acc:0.785752, Semantic loss: 0.726185, BCE loss: 0.493873, SB loss: 0.723406
2023-10-30 13:20:58,767 Epoch: [246/484] Iter:[30/495], Time: 0.40, lr: [0.005277872450251916], Loss: 1.943894, Acc:0.782762, Semantic loss: 0.732609, BCE loss: 0.492981, SB loss: 0.718304
2023-10-30 13:21:02,261 Epoch: [246/484] Iter:[40/495], Time: 0.39, lr: [0.00527746914702803], Loss: 1.950448, Acc:0.785399, Semantic loss: 0.733546, BCE loss: 0.501009, SB loss: 0.715893
2023-10-30 13:21:05,664 Epoch: [246/484] Iter:[50/495], Time: 0.38, lr: [0.0052770658403796305], Loss: 1.967273, Acc:0.789643, Semantic loss: 0.748862, BCE loss: 0.499972, SB loss: 0.718439
2023-10-30 13:21:09,196 Epoch: [246/484] Iter:[60/495], Time: 0.37, lr: [0.005276662530306397], Loss: 1.976157, Acc:0.792111, Semantic loss: 0.747507, BCE loss: 0.508239, SB loss: 0.720412
2023-10-30 13:21:12,636 Epoch: [246/484] Iter:[70/495], Time: 0.37, lr: [0.005276259216808012], Loss: 2.008075, Acc:0.796332, Semantic loss: 0.768525, BCE loss: 0.511489, SB loss: 0.728061
2023-10-30 13:21:16,293 Epoch: [246/484] Iter:[80/495], Time: 0.37, lr: [0.005275855899884154], Loss: 2.027016, Acc:0.798580, Semantic loss: 0.777856, BCE loss: 0.515748, SB loss: 0.733412
2023-10-30 13:21:19,913 Epoch: [246/484] Iter:[90/495], Time: 0.37, lr: [0.0052754525795345], Loss: 2.032501, Acc:0.795017, Semantic loss: 0.779369, BCE loss: 0.517888, SB loss: 0.735244
2023-10-30 13:21:23,370 Epoch: [246/484] Iter:[100/495], Time: 0.37, lr: [0.005275049255758735], Loss: 2.044926, Acc:0.794767, Semantic loss: 0.790285, BCE loss: 0.520160, SB loss: 0.734481
2023-10-30 13:21:26,950 Epoch: [246/484] Iter:[110/495], Time: 0.37, lr: [0.005274645928556536], Loss: 2.033697, Acc:0.796647, Semantic loss: 0.779196, BCE loss: 0.522524, SB loss: 0.731977
2023-10-30 13:21:30,541 Epoch: [246/484] Iter:[120/495], Time: 0.36, lr: [0.0052742425979275835], Loss: 2.029135, Acc:0.797874, Semantic loss: 0.774923, BCE loss: 0.522312, SB loss: 0.731900
2023-10-30 13:21:34,081 Epoch: [246/484] Iter:[130/495], Time: 0.36, lr: [0.005273839263871556], Loss: 2.040871, Acc:0.797671, Semantic loss: 0.780764, BCE loss: 0.527218, SB loss: 0.732889
2023-10-30 13:21:37,605 Epoch: [246/484] Iter:[140/495], Time: 0.36, lr: [0.0052734359263881345], Loss: 2.042976, Acc:0.800432, Semantic loss: 0.779747, BCE loss: 0.530235, SB loss: 0.732993
2023-10-30 13:21:41,192 Epoch: [246/484] Iter:[150/495], Time: 0.36, lr: [0.005273032585476999], Loss: 2.032229, Acc:0.800970, Semantic loss: 0.773895, BCE loss: 0.526891, SB loss: 0.731444
2023-10-30 13:21:44,859 Epoch: [246/484] Iter:[160/495], Time: 0.36, lr: [0.0052726292411378285], Loss: 2.022654, Acc:0.803405, Semantic loss: 0.767420, BCE loss: 0.527606, SB loss: 0.727629
2023-10-30 13:21:48,477 Epoch: [246/484] Iter:[170/495], Time: 0.36, lr: [0.005272225893370301], Loss: 2.024395, Acc:0.804678, Semantic loss: 0.768314, BCE loss: 0.528907, SB loss: 0.727175
2023-10-30 13:21:52,036 Epoch: [246/484] Iter:[180/495], Time: 0.36, lr: [0.005271822542174097], Loss: 2.026515, Acc:0.804453, Semantic loss: 0.770345, BCE loss: 0.528064, SB loss: 0.728106
2023-10-30 13:21:55,629 Epoch: [246/484] Iter:[190/495], Time: 0.36, lr: [0.005271419187548897], Loss: 2.031174, Acc:0.804240, Semantic loss: 0.772042, BCE loss: 0.529013, SB loss: 0.730118
2023-10-30 13:21:59,249 Epoch: [246/484] Iter:[200/495], Time: 0.36, lr: [0.00527101582949438], Loss: 2.031221, Acc:0.804530, Semantic loss: 0.769503, BCE loss: 0.531877, SB loss: 0.729841
2023-10-30 13:22:02,907 Epoch: [246/484] Iter:[210/495], Time: 0.36, lr: [0.005270612468010223], Loss: 2.030495, Acc:0.806225, Semantic loss: 0.766445, BCE loss: 0.535218, SB loss: 0.728832
2023-10-30 13:22:06,634 Epoch: [246/484] Iter:[220/495], Time: 0.36, lr: [0.005270209103096108], Loss: 2.029787, Acc:0.805846, Semantic loss: 0.763883, BCE loss: 0.538400, SB loss: 0.727504
2023-10-30 13:22:10,225 Epoch: [246/484] Iter:[230/495], Time: 0.36, lr: [0.005269805734751712], Loss: 2.025122, Acc:0.804636, Semantic loss: 0.762742, BCE loss: 0.535047, SB loss: 0.727333
2023-10-30 13:22:13,848 Epoch: [246/484] Iter:[240/495], Time: 0.36, lr: [0.005269402362976717], Loss: 2.021811, Acc:0.805965, Semantic loss: 0.760806, BCE loss: 0.534462, SB loss: 0.726542
2023-10-30 13:22:17,448 Epoch: [246/484] Iter:[250/495], Time: 0.36, lr: [0.005268998987770797], Loss: 2.021048, Acc:0.807643, Semantic loss: 0.760362, BCE loss: 0.534702, SB loss: 0.725985
2023-10-30 13:22:21,098 Epoch: [246/484] Iter:[260/495], Time: 0.36, lr: [0.005268595609133635], Loss: 2.020959, Acc:0.805924, Semantic loss: 0.761181, BCE loss: 0.532779, SB loss: 0.726998
2023-10-30 13:22:24,681 Epoch: [246/484] Iter:[270/495], Time: 0.36, lr: [0.005268192227064911], Loss: 2.022158, Acc:0.805444, Semantic loss: 0.762171, BCE loss: 0.533214, SB loss: 0.726773
2023-10-30 13:22:28,293 Epoch: [246/484] Iter:[280/495], Time: 0.36, lr: [0.005267788841564301], Loss: 2.025120, Acc:0.805630, Semantic loss: 0.764356, BCE loss: 0.533978, SB loss: 0.726786
2023-10-30 13:22:31,903 Epoch: [246/484] Iter:[290/495], Time: 0.36, lr: [0.005267385452631482], Loss: 2.023974, Acc:0.804676, Semantic loss: 0.762801, BCE loss: 0.534969, SB loss: 0.726203
2023-10-30 13:22:35,517 Epoch: [246/484] Iter:[300/495], Time: 0.36, lr: [0.0052669820602661375], Loss: 2.017178, Acc:0.804879, Semantic loss: 0.758727, BCE loss: 0.533847, SB loss: 0.724603
2023-10-30 13:22:39,170 Epoch: [246/484] Iter:[310/495], Time: 0.36, lr: [0.005266578664467945], Loss: 2.014011, Acc:0.805879, Semantic loss: 0.756893, BCE loss: 0.533108, SB loss: 0.724010
2023-10-30 13:22:42,785 Epoch: [246/484] Iter:[320/495], Time: 0.36, lr: [0.0052661752652365815], Loss: 2.015582, Acc:0.806131, Semantic loss: 0.756968, BCE loss: 0.534083, SB loss: 0.724531
2023-10-30 13:22:46,468 Epoch: [246/484] Iter:[330/495], Time: 0.36, lr: [0.005265771862571724], Loss: 2.020904, Acc:0.805616, Semantic loss: 0.760299, BCE loss: 0.534460, SB loss: 0.726146
2023-10-30 13:22:50,056 Epoch: [246/484] Iter:[340/495], Time: 0.36, lr: [0.005265368456473055], Loss: 2.020654, Acc:0.806314, Semantic loss: 0.759850, BCE loss: 0.534559, SB loss: 0.726246
2023-10-30 13:22:53,750 Epoch: [246/484] Iter:[350/495], Time: 0.36, lr: [0.005264965046940252], Loss: 2.020003, Acc:0.806913, Semantic loss: 0.760076, BCE loss: 0.534288, SB loss: 0.725639
2023-10-30 13:22:57,349 Epoch: [246/484] Iter:[360/495], Time: 0.36, lr: [0.005264561633972992], Loss: 2.024007, Acc:0.806608, Semantic loss: 0.763587, BCE loss: 0.532950, SB loss: 0.727470
2023-10-30 13:23:01,081 Epoch: [246/484] Iter:[370/495], Time: 0.36, lr: [0.005264158217570953], Loss: 2.024134, Acc:0.807186, Semantic loss: 0.761915, BCE loss: 0.535508, SB loss: 0.726712
2023-10-30 13:23:04,635 Epoch: [246/484] Iter:[380/495], Time: 0.36, lr: [0.0052637547977338155], Loss: 2.028070, Acc:0.806942, Semantic loss: 0.763609, BCE loss: 0.535779, SB loss: 0.728683
2023-10-30 13:23:08,239 Epoch: [246/484] Iter:[390/495], Time: 0.36, lr: [0.005263351374461256], Loss: 2.025441, Acc:0.805616, Semantic loss: 0.761621, BCE loss: 0.535160, SB loss: 0.728660
2023-10-30 13:23:11,877 Epoch: [246/484] Iter:[400/495], Time: 0.36, lr: [0.005262947947752953], Loss: 2.024523, Acc:0.805279, Semantic loss: 0.760879, BCE loss: 0.535077, SB loss: 0.728568
2023-10-30 13:23:15,460 Epoch: [246/484] Iter:[410/495], Time: 0.36, lr: [0.005262544517608584], Loss: 2.029739, Acc:0.806139, Semantic loss: 0.763533, BCE loss: 0.536632, SB loss: 0.729574
2023-10-30 13:23:19,173 Epoch: [246/484] Iter:[420/495], Time: 0.36, lr: [0.005262141084027829], Loss: 2.029532, Acc:0.806583, Semantic loss: 0.763590, BCE loss: 0.536378, SB loss: 0.729563
2023-10-30 13:23:22,858 Epoch: [246/484] Iter:[430/495], Time: 0.36, lr: [0.0052617376470103635], Loss: 2.024784, Acc:0.806694, Semantic loss: 0.760130, BCE loss: 0.535788, SB loss: 0.728867
2023-10-30 13:23:26,583 Epoch: [246/484] Iter:[440/495], Time: 0.36, lr: [0.005261334206555868], Loss: 2.023580, Acc:0.807052, Semantic loss: 0.759218, BCE loss: 0.535852, SB loss: 0.728510
2023-10-30 13:23:30,228 Epoch: [246/484] Iter:[450/495], Time: 0.36, lr: [0.005260930762664018], Loss: 2.020909, Acc:0.806993, Semantic loss: 0.758667, BCE loss: 0.533883, SB loss: 0.728358
2023-10-30 13:23:33,875 Epoch: [246/484] Iter:[460/495], Time: 0.36, lr: [0.005260527315334492], Loss: 2.023366, Acc:0.807115, Semantic loss: 0.759391, BCE loss: 0.535101, SB loss: 0.728875
2023-10-30 13:23:37,393 Epoch: [246/484] Iter:[470/495], Time: 0.36, lr: [0.00526012386456697], Loss: 2.024322, Acc:0.807254, Semantic loss: 0.759274, BCE loss: 0.535266, SB loss: 0.729783
2023-10-30 13:23:41,045 Epoch: [246/484] Iter:[480/495], Time: 0.36, lr: [0.005259720410361128], Loss: 2.022794, Acc:0.806582, Semantic loss: 0.759293, BCE loss: 0.534561, SB loss: 0.728940
2023-10-30 13:23:44,504 Epoch: [246/484] Iter:[490/495], Time: 0.36, lr: [0.005259316952716641], Loss: 2.022660, Acc:0.806593, Semantic loss: 0.759005, BCE loss: 0.534782, SB loss: 0.728873
2023-10-30 13:23:45,898 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:23:46,129 Loss: 2.011, MeanIU:  0.7103, Best_mIoU:  0.7151
2023-10-30 13:23:46,130 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747]
2023-10-30 13:23:48,018 Epoch: [247/484] Iter:[0/495], Time: 1.85, lr: [0.005259115222604805], Loss: 1.879951, Acc:0.871693, Semantic loss: 0.620813, BCE loss: 0.606848, SB loss: 0.652290
2023-10-30 13:23:51,871 Epoch: [247/484] Iter:[10/495], Time: 0.52, lr: [0.005258711759801752], Loss: 1.871950, Acc:0.799770, Semantic loss: 0.686027, BCE loss: 0.492829, SB loss: 0.693095
2023-10-30 13:23:55,507 Epoch: [247/484] Iter:[20/495], Time: 0.44, lr: [0.0052583082935592496], Loss: 1.937592, Acc:0.817671, Semantic loss: 0.728978, BCE loss: 0.500697, SB loss: 0.707917
2023-10-30 13:23:59,103 Epoch: [247/484] Iter:[30/495], Time: 0.42, lr: [0.005257904823876974], Loss: 1.950755, Acc:0.817318, Semantic loss: 0.740689, BCE loss: 0.494595, SB loss: 0.715470
2023-10-30 13:24:02,725 Epoch: [247/484] Iter:[40/495], Time: 0.40, lr: [0.005257501350754608], Loss: 1.974912, Acc:0.812726, Semantic loss: 0.746147, BCE loss: 0.511703, SB loss: 0.717062
2023-10-30 13:24:06,366 Epoch: [247/484] Iter:[50/495], Time: 0.40, lr: [0.0052570978741918245], Loss: 1.998512, Acc:0.817655, Semantic loss: 0.748868, BCE loss: 0.523154, SB loss: 0.726490
2023-10-30 13:24:10,084 Epoch: [247/484] Iter:[60/495], Time: 0.39, lr: [0.0052566943941883], Loss: 2.007783, Acc:0.814264, Semantic loss: 0.746282, BCE loss: 0.537551, SB loss: 0.723950
2023-10-30 13:24:13,678 Epoch: [247/484] Iter:[70/495], Time: 0.39, lr: [0.005256290910743714], Loss: 1.996456, Acc:0.819366, Semantic loss: 0.739577, BCE loss: 0.536830, SB loss: 0.720050
2023-10-30 13:24:17,291 Epoch: [247/484] Iter:[80/495], Time: 0.38, lr: [0.005255887423857744], Loss: 2.011675, Acc:0.816275, Semantic loss: 0.748814, BCE loss: 0.540311, SB loss: 0.722550
2023-10-30 13:24:20,939 Epoch: [247/484] Iter:[90/495], Time: 0.38, lr: [0.005255483933530067], Loss: 2.022978, Acc:0.819039, Semantic loss: 0.750295, BCE loss: 0.545062, SB loss: 0.727621
2023-10-30 13:24:24,507 Epoch: [247/484] Iter:[100/495], Time: 0.38, lr: [0.005255080439760358], Loss: 2.020804, Acc:0.816842, Semantic loss: 0.754066, BCE loss: 0.538644, SB loss: 0.728095
2023-10-30 13:24:28,114 Epoch: [247/484] Iter:[110/495], Time: 0.38, lr: [0.005254676942548294], Loss: 2.001397, Acc:0.814555, Semantic loss: 0.744935, BCE loss: 0.531252, SB loss: 0.725210
2023-10-30 13:24:31,773 Epoch: [247/484] Iter:[120/495], Time: 0.38, lr: [0.005254273441893556], Loss: 1.997212, Acc:0.812559, Semantic loss: 0.745560, BCE loss: 0.527524, SB loss: 0.724128
2023-10-30 13:24:35,381 Epoch: [247/484] Iter:[130/495], Time: 0.38, lr: [0.005253869937795816], Loss: 2.005672, Acc:0.808365, Semantic loss: 0.754839, BCE loss: 0.524240, SB loss: 0.726593
2023-10-30 13:24:38,933 Epoch: [247/484] Iter:[140/495], Time: 0.37, lr: [0.0052534664302547555], Loss: 2.011066, Acc:0.804377, Semantic loss: 0.758154, BCE loss: 0.523851, SB loss: 0.729061
2023-10-30 13:24:42,638 Epoch: [247/484] Iter:[150/495], Time: 0.37, lr: [0.005253062919270045], Loss: 2.024939, Acc:0.805829, Semantic loss: 0.764091, BCE loss: 0.529743, SB loss: 0.731105
2023-10-30 13:24:46,291 Epoch: [247/484] Iter:[160/495], Time: 0.37, lr: [0.005252659404841367], Loss: 2.011642, Acc:0.803234, Semantic loss: 0.758663, BCE loss: 0.524964, SB loss: 0.728014
2023-10-30 13:24:49,979 Epoch: [247/484] Iter:[170/495], Time: 0.37, lr: [0.005252255886968395], Loss: 2.025085, Acc:0.803208, Semantic loss: 0.764824, BCE loss: 0.529129, SB loss: 0.731132
2023-10-30 13:24:53,530 Epoch: [247/484] Iter:[180/495], Time: 0.37, lr: [0.005251852365650809], Loss: 2.024003, Acc:0.801062, Semantic loss: 0.765230, BCE loss: 0.527556, SB loss: 0.731216
2023-10-30 13:24:57,066 Epoch: [247/484] Iter:[190/495], Time: 0.37, lr: [0.00525144884088828], Loss: 2.020889, Acc:0.800742, Semantic loss: 0.763737, BCE loss: 0.525673, SB loss: 0.731478
2023-10-30 13:25:00,716 Epoch: [247/484] Iter:[200/495], Time: 0.37, lr: [0.005251045312680489], Loss: 2.012891, Acc:0.799016, Semantic loss: 0.760192, BCE loss: 0.521663, SB loss: 0.731036
2023-10-30 13:25:04,392 Epoch: [247/484] Iter:[210/495], Time: 0.37, lr: [0.005250641781027111], Loss: 2.010486, Acc:0.799289, Semantic loss: 0.759696, BCE loss: 0.519916, SB loss: 0.730875
2023-10-30 13:25:07,946 Epoch: [247/484] Iter:[220/495], Time: 0.37, lr: [0.005250238245927822], Loss: 2.014064, Acc:0.800147, Semantic loss: 0.760375, BCE loss: 0.522823, SB loss: 0.730866
2023-10-30 13:25:11,550 Epoch: [247/484] Iter:[230/495], Time: 0.37, lr: [0.005249834707382297], Loss: 2.021280, Acc:0.798635, Semantic loss: 0.765129, BCE loss: 0.524221, SB loss: 0.731930
2023-10-30 13:25:15,188 Epoch: [247/484] Iter:[240/495], Time: 0.37, lr: [0.005249431165390216], Loss: 2.016125, Acc:0.799107, Semantic loss: 0.761641, BCE loss: 0.523047, SB loss: 0.731437
2023-10-30 13:25:18,879 Epoch: [247/484] Iter:[250/495], Time: 0.37, lr: [0.0052490276199512525], Loss: 2.018478, Acc:0.798711, Semantic loss: 0.763367, BCE loss: 0.522483, SB loss: 0.732629
2023-10-30 13:25:22,621 Epoch: [247/484] Iter:[260/495], Time: 0.37, lr: [0.005248624071065084], Loss: 2.018593, Acc:0.798389, Semantic loss: 0.761348, BCE loss: 0.525522, SB loss: 0.731723
2023-10-30 13:25:26,196 Epoch: [247/484] Iter:[270/495], Time: 0.37, lr: [0.005248220518731382], Loss: 2.018276, Acc:0.797657, Semantic loss: 0.760668, BCE loss: 0.526156, SB loss: 0.731452
2023-10-30 13:25:29,857 Epoch: [247/484] Iter:[280/495], Time: 0.37, lr: [0.00524781696294983], Loss: 2.019160, Acc:0.798973, Semantic loss: 0.761072, BCE loss: 0.527060, SB loss: 0.731028
2023-10-30 13:25:33,581 Epoch: [247/484] Iter:[290/495], Time: 0.37, lr: [0.005247413403720098], Loss: 2.025170, Acc:0.798605, Semantic loss: 0.766305, BCE loss: 0.527270, SB loss: 0.731595
2023-10-30 13:25:37,204 Epoch: [247/484] Iter:[300/495], Time: 0.37, lr: [0.005247009841041865], Loss: 2.027018, Acc:0.797093, Semantic loss: 0.767552, BCE loss: 0.526697, SB loss: 0.732768
2023-10-30 13:25:40,991 Epoch: [247/484] Iter:[310/495], Time: 0.37, lr: [0.0052466062749148045], Loss: 2.027460, Acc:0.798123, Semantic loss: 0.765844, BCE loss: 0.528612, SB loss: 0.733004
2023-10-30 13:25:44,675 Epoch: [247/484] Iter:[320/495], Time: 0.37, lr: [0.005246202705338594], Loss: 2.027140, Acc:0.799422, Semantic loss: 0.764475, BCE loss: 0.529866, SB loss: 0.732799
2023-10-30 13:25:48,212 Epoch: [247/484] Iter:[330/495], Time: 0.37, lr: [0.0052457991323129095], Loss: 2.030517, Acc:0.799827, Semantic loss: 0.767150, BCE loss: 0.530818, SB loss: 0.732549
2023-10-30 13:25:51,844 Epoch: [247/484] Iter:[340/495], Time: 0.37, lr: [0.0052453955558374255], Loss: 2.025288, Acc:0.798857, Semantic loss: 0.765739, BCE loss: 0.527699, SB loss: 0.731849
2023-10-30 13:25:55,446 Epoch: [247/484] Iter:[350/495], Time: 0.37, lr: [0.005244991975911817], Loss: 2.023709, Acc:0.798960, Semantic loss: 0.765916, BCE loss: 0.526555, SB loss: 0.731238
2023-10-30 13:25:59,057 Epoch: [247/484] Iter:[360/495], Time: 0.37, lr: [0.005244588392535761], Loss: 2.027769, Acc:0.798792, Semantic loss: 0.768714, BCE loss: 0.526790, SB loss: 0.732265
2023-10-30 13:26:02,656 Epoch: [247/484] Iter:[370/495], Time: 0.37, lr: [0.005244184805708933], Loss: 2.026138, Acc:0.798329, Semantic loss: 0.767411, BCE loss: 0.526890, SB loss: 0.731837
2023-10-30 13:26:06,358 Epoch: [247/484] Iter:[380/495], Time: 0.37, lr: [0.005243781215431008], Loss: 2.035439, Acc:0.797980, Semantic loss: 0.773849, BCE loss: 0.527980, SB loss: 0.733609
2023-10-30 13:26:10,052 Epoch: [247/484] Iter:[390/495], Time: 0.37, lr: [0.00524337762170166], Loss: 2.033650, Acc:0.798253, Semantic loss: 0.773529, BCE loss: 0.526654, SB loss: 0.733467
2023-10-30 13:26:13,615 Epoch: [247/484] Iter:[400/495], Time: 0.37, lr: [0.005242974024520567], Loss: 2.030897, Acc:0.797565, Semantic loss: 0.771814, BCE loss: 0.525145, SB loss: 0.733938
2023-10-30 13:26:17,292 Epoch: [247/484] Iter:[410/495], Time: 0.37, lr: [0.005242570423887403], Loss: 2.028657, Acc:0.797712, Semantic loss: 0.769043, BCE loss: 0.526252, SB loss: 0.733362
2023-10-30 13:26:20,853 Epoch: [247/484] Iter:[420/495], Time: 0.37, lr: [0.005242166819801842], Loss: 2.026314, Acc:0.797280, Semantic loss: 0.767141, BCE loss: 0.525681, SB loss: 0.733492
2023-10-30 13:26:24,484 Epoch: [247/484] Iter:[430/495], Time: 0.37, lr: [0.005241763212263559], Loss: 2.026205, Acc:0.796986, Semantic loss: 0.766958, BCE loss: 0.525614, SB loss: 0.733634
2023-10-30 13:26:28,186 Epoch: [247/484] Iter:[440/495], Time: 0.37, lr: [0.005241359601272232], Loss: 2.026512, Acc:0.797727, Semantic loss: 0.766413, BCE loss: 0.526752, SB loss: 0.733348
2023-10-30 13:26:31,789 Epoch: [247/484] Iter:[450/495], Time: 0.37, lr: [0.005240955986827534], Loss: 2.027632, Acc:0.798048, Semantic loss: 0.766700, BCE loss: 0.527837, SB loss: 0.733095
2023-10-30 13:26:35,399 Epoch: [247/484] Iter:[460/495], Time: 0.37, lr: [0.00524055236892914], Loss: 2.026091, Acc:0.798057, Semantic loss: 0.765444, BCE loss: 0.528004, SB loss: 0.732644
2023-10-30 13:26:39,054 Epoch: [247/484] Iter:[470/495], Time: 0.37, lr: [0.005240148747576724], Loss: 2.024042, Acc:0.797863, Semantic loss: 0.764813, BCE loss: 0.526904, SB loss: 0.732326
2023-10-30 13:26:42,702 Epoch: [247/484] Iter:[480/495], Time: 0.37, lr: [0.005239745122769962], Loss: 2.028443, Acc:0.797842, Semantic loss: 0.766536, BCE loss: 0.529516, SB loss: 0.732391
2023-10-30 13:26:46,159 Epoch: [247/484] Iter:[490/495], Time: 0.37, lr: [0.005239341494508529], Loss: 2.027152, Acc:0.798243, Semantic loss: 0.765167, BCE loss: 0.529612, SB loss: 0.732373
2023-10-30 13:26:47,558 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:26:47,795 Loss: 2.011, MeanIU:  0.7103, Best_mIoU:  0.7151
2023-10-30 13:26:47,795 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747]
2023-10-30 13:26:49,757 Epoch: [248/484] Iter:[0/495], Time: 1.93, lr: [0.00523913967908221], Loss: 2.085823, Acc:0.846283, Semantic loss: 0.774405, BCE loss: 0.584867, SB loss: 0.726550
2023-10-30 13:26:53,734 Epoch: [248/484] Iter:[10/495], Time: 0.54, lr: [0.005238736045638158], Loss: 2.066823, Acc:0.798043, Semantic loss: 0.728166, BCE loss: 0.596385, SB loss: 0.742273
2023-10-30 13:26:57,470 Epoch: [248/484] Iter:[20/495], Time: 0.46, lr: [0.005238332408738624], Loss: 2.058985, Acc:0.791309, Semantic loss: 0.739348, BCE loss: 0.575038, SB loss: 0.744598
2023-10-30 13:27:01,167 Epoch: [248/484] Iter:[30/495], Time: 0.43, lr: [0.005237928768383279], Loss: 2.017669, Acc:0.797263, Semantic loss: 0.724507, BCE loss: 0.562955, SB loss: 0.730207
2023-10-30 13:27:04,844 Epoch: [248/484] Iter:[40/495], Time: 0.41, lr: [0.005237525124571799], Loss: 2.050768, Acc:0.802201, Semantic loss: 0.748286, BCE loss: 0.562520, SB loss: 0.739963
2023-10-30 13:27:08,477 Epoch: [248/484] Iter:[50/495], Time: 0.40, lr: [0.005237121477303857], Loss: 2.054038, Acc:0.802210, Semantic loss: 0.752920, BCE loss: 0.561306, SB loss: 0.739812
2023-10-30 13:27:12,062 Epoch: [248/484] Iter:[60/495], Time: 0.40, lr: [0.005236717826579128], Loss: 2.053828, Acc:0.799976, Semantic loss: 0.757954, BCE loss: 0.555322, SB loss: 0.740553
2023-10-30 13:27:15,639 Epoch: [248/484] Iter:[70/495], Time: 0.39, lr: [0.005236314172397287], Loss: 2.057015, Acc:0.799413, Semantic loss: 0.762376, BCE loss: 0.553038, SB loss: 0.741601
2023-10-30 13:27:19,286 Epoch: [248/484] Iter:[80/495], Time: 0.39, lr: [0.005235910514758008], Loss: 2.053017, Acc:0.798877, Semantic loss: 0.762319, BCE loss: 0.551835, SB loss: 0.738863
2023-10-30 13:27:22,905 Epoch: [248/484] Iter:[90/495], Time: 0.39, lr: [0.005235506853660964], Loss: 2.028374, Acc:0.796695, Semantic loss: 0.755268, BCE loss: 0.540067, SB loss: 0.733039
2023-10-30 13:27:26,553 Epoch: [248/484] Iter:[100/495], Time: 0.38, lr: [0.005235103189105831], Loss: 2.034271, Acc:0.800929, Semantic loss: 0.756168, BCE loss: 0.542451, SB loss: 0.735652
2023-10-30 13:27:30,254 Epoch: [248/484] Iter:[110/495], Time: 0.38, lr: [0.005234699521092282], Loss: 2.024369, Acc:0.801549, Semantic loss: 0.752008, BCE loss: 0.540479, SB loss: 0.731881
2023-10-30 13:27:33,816 Epoch: [248/484] Iter:[120/495], Time: 0.38, lr: [0.0052342958496199915], Loss: 2.026170, Acc:0.800465, Semantic loss: 0.755759, BCE loss: 0.538297, SB loss: 0.732113
2023-10-30 13:27:37,473 Epoch: [248/484] Iter:[130/495], Time: 0.38, lr: [0.005233892174688633], Loss: 2.034530, Acc:0.800366, Semantic loss: 0.759265, BCE loss: 0.541579, SB loss: 0.733686
2023-10-30 13:27:41,058 Epoch: [248/484] Iter:[140/495], Time: 0.38, lr: [0.00523348849629788], Loss: 2.030249, Acc:0.798268, Semantic loss: 0.758990, BCE loss: 0.537220, SB loss: 0.734039
2023-10-30 13:27:44,686 Epoch: [248/484] Iter:[150/495], Time: 0.38, lr: [0.005233084814447409], Loss: 2.025323, Acc:0.798403, Semantic loss: 0.757598, BCE loss: 0.534675, SB loss: 0.733050
2023-10-30 13:27:48,360 Epoch: [248/484] Iter:[160/495], Time: 0.38, lr: [0.005232681129136891], Loss: 2.021705, Acc:0.798666, Semantic loss: 0.756812, BCE loss: 0.531334, SB loss: 0.733559
2023-10-30 13:27:52,059 Epoch: [248/484] Iter:[170/495], Time: 0.38, lr: [0.005232277440365999], Loss: 2.021502, Acc:0.801088, Semantic loss: 0.754243, BCE loss: 0.534779, SB loss: 0.732479
2023-10-30 13:27:55,666 Epoch: [248/484] Iter:[180/495], Time: 0.37, lr: [0.00523187374813441], Loss: 2.024424, Acc:0.801349, Semantic loss: 0.757101, BCE loss: 0.535583, SB loss: 0.731740
2023-10-30 13:27:59,362 Epoch: [248/484] Iter:[190/495], Time: 0.37, lr: [0.005231470052441796], Loss: 2.032733, Acc:0.800066, Semantic loss: 0.761358, BCE loss: 0.537413, SB loss: 0.733961
2023-10-30 13:28:03,022 Epoch: [248/484] Iter:[200/495], Time: 0.37, lr: [0.005231066353287831], Loss: 2.027558, Acc:0.802225, Semantic loss: 0.759163, BCE loss: 0.534524, SB loss: 0.733871
2023-10-30 13:28:06,646 Epoch: [248/484] Iter:[210/495], Time: 0.37, lr: [0.005230662650672186], Loss: 2.030895, Acc:0.800250, Semantic loss: 0.763713, BCE loss: 0.531281, SB loss: 0.735900
2023-10-30 13:28:10,403 Epoch: [248/484] Iter:[220/495], Time: 0.37, lr: [0.005230258944594538], Loss: 2.040670, Acc:0.800031, Semantic loss: 0.767498, BCE loss: 0.532175, SB loss: 0.740996
2023-10-30 13:28:14,000 Epoch: [248/484] Iter:[230/495], Time: 0.37, lr: [0.005229855235054559], Loss: 2.043630, Acc:0.800705, Semantic loss: 0.765495, BCE loss: 0.537230, SB loss: 0.740904
2023-10-30 13:28:17,683 Epoch: [248/484] Iter:[240/495], Time: 0.37, lr: [0.005229451522051922], Loss: 2.039166, Acc:0.799422, Semantic loss: 0.762682, BCE loss: 0.536116, SB loss: 0.740367
2023-10-30 13:28:21,293 Epoch: [248/484] Iter:[250/495], Time: 0.37, lr: [0.005229047805586299], Loss: 2.046987, Acc:0.797848, Semantic loss: 0.768210, BCE loss: 0.538078, SB loss: 0.740699
2023-10-30 13:28:25,046 Epoch: [248/484] Iter:[260/495], Time: 0.37, lr: [0.005228644085657367], Loss: 2.053230, Acc:0.797053, Semantic loss: 0.773098, BCE loss: 0.539216, SB loss: 0.740915
2023-10-30 13:28:28,746 Epoch: [248/484] Iter:[270/495], Time: 0.37, lr: [0.005228240362264796], Loss: 2.062145, Acc:0.797153, Semantic loss: 0.776749, BCE loss: 0.541837, SB loss: 0.743559
2023-10-30 13:28:32,386 Epoch: [248/484] Iter:[280/495], Time: 0.37, lr: [0.0052278366354082595], Loss: 2.061312, Acc:0.796032, Semantic loss: 0.775155, BCE loss: 0.542998, SB loss: 0.743159
2023-10-30 13:28:36,073 Epoch: [248/484] Iter:[290/495], Time: 0.37, lr: [0.00522743290508743], Loss: 2.057166, Acc:0.796109, Semantic loss: 0.771691, BCE loss: 0.542646, SB loss: 0.742830
2023-10-30 13:28:39,776 Epoch: [248/484] Iter:[300/495], Time: 0.37, lr: [0.005227029171301983], Loss: 2.053532, Acc:0.796717, Semantic loss: 0.769057, BCE loss: 0.542855, SB loss: 0.741620
2023-10-30 13:28:43,397 Epoch: [248/484] Iter:[310/495], Time: 0.37, lr: [0.005226625434051591], Loss: 2.052808, Acc:0.796420, Semantic loss: 0.767939, BCE loss: 0.543109, SB loss: 0.741759
2023-10-30 13:28:47,030 Epoch: [248/484] Iter:[320/495], Time: 0.37, lr: [0.005226221693335924], Loss: 2.049775, Acc:0.796274, Semantic loss: 0.766502, BCE loss: 0.542543, SB loss: 0.740730
2023-10-30 13:28:50,565 Epoch: [248/484] Iter:[330/495], Time: 0.37, lr: [0.005225817949154657], Loss: 2.050305, Acc:0.797237, Semantic loss: 0.767363, BCE loss: 0.542033, SB loss: 0.740909
2023-10-30 13:28:54,122 Epoch: [248/484] Iter:[340/495], Time: 0.37, lr: [0.005225414201507462], Loss: 2.046246, Acc:0.797835, Semantic loss: 0.765497, BCE loss: 0.541194, SB loss: 0.739555
2023-10-30 13:28:57,715 Epoch: [248/484] Iter:[350/495], Time: 0.37, lr: [0.005225010450394013], Loss: 2.049106, Acc:0.797217, Semantic loss: 0.768394, BCE loss: 0.540302, SB loss: 0.740410
2023-10-30 13:29:01,325 Epoch: [248/484] Iter:[360/495], Time: 0.37, lr: [0.005224606695813981], Loss: 2.046425, Acc:0.797239, Semantic loss: 0.766990, BCE loss: 0.539832, SB loss: 0.739603
2023-10-30 13:29:05,103 Epoch: [248/484] Iter:[370/495], Time: 0.37, lr: [0.005224202937767038], Loss: 2.046056, Acc:0.797742, Semantic loss: 0.766100, BCE loss: 0.540504, SB loss: 0.739453
2023-10-30 13:29:08,684 Epoch: [248/484] Iter:[380/495], Time: 0.37, lr: [0.00522379917625286], Loss: 2.046768, Acc:0.797905, Semantic loss: 0.767029, BCE loss: 0.539562, SB loss: 0.740177
2023-10-30 13:29:12,257 Epoch: [248/484] Iter:[390/495], Time: 0.37, lr: [0.005223395411271116], Loss: 2.043196, Acc:0.797248, Semantic loss: 0.765698, BCE loss: 0.537647, SB loss: 0.739851
2023-10-30 13:29:15,900 Epoch: [248/484] Iter:[400/495], Time: 0.37, lr: [0.00522299164282148], Loss: 2.042642, Acc:0.797241, Semantic loss: 0.765298, BCE loss: 0.538111, SB loss: 0.739233
2023-10-30 13:29:19,522 Epoch: [248/484] Iter:[410/495], Time: 0.37, lr: [0.005222587870903623], Loss: 2.041395, Acc:0.797165, Semantic loss: 0.765329, BCE loss: 0.536982, SB loss: 0.739084
2023-10-30 13:29:23,200 Epoch: [248/484] Iter:[420/495], Time: 0.37, lr: [0.0052221840955172195], Loss: 2.038437, Acc:0.796421, Semantic loss: 0.764311, BCE loss: 0.535061, SB loss: 0.739065
2023-10-30 13:29:26,803 Epoch: [248/484] Iter:[430/495], Time: 0.37, lr: [0.005221780316661939], Loss: 2.037143, Acc:0.796388, Semantic loss: 0.763863, BCE loss: 0.534212, SB loss: 0.739068
2023-10-30 13:29:30,474 Epoch: [248/484] Iter:[440/495], Time: 0.37, lr: [0.005221376534337455], Loss: 2.040848, Acc:0.796672, Semantic loss: 0.764758, BCE loss: 0.536705, SB loss: 0.739386
2023-10-30 13:29:34,120 Epoch: [248/484] Iter:[450/495], Time: 0.37, lr: [0.005220972748543441], Loss: 2.039760, Acc:0.796896, Semantic loss: 0.764875, BCE loss: 0.535929, SB loss: 0.738955
2023-10-30 13:29:37,838 Epoch: [248/484] Iter:[460/495], Time: 0.37, lr: [0.0052205689592795665], Loss: 2.040354, Acc:0.797098, Semantic loss: 0.765498, BCE loss: 0.536193, SB loss: 0.738663
2023-10-30 13:29:41,525 Epoch: [248/484] Iter:[470/495], Time: 0.37, lr: [0.005220165166545506], Loss: 2.039333, Acc:0.797256, Semantic loss: 0.764239, BCE loss: 0.537228, SB loss: 0.737867
2023-10-30 13:29:45,154 Epoch: [248/484] Iter:[480/495], Time: 0.37, lr: [0.005219761370340929], Loss: 2.041814, Acc:0.797333, Semantic loss: 0.764411, BCE loss: 0.538655, SB loss: 0.738748
2023-10-30 13:29:48,637 Epoch: [248/484] Iter:[490/495], Time: 0.37, lr: [0.005219357570665508], Loss: 2.039352, Acc:0.796624, Semantic loss: 0.763355, BCE loss: 0.537296, SB loss: 0.738702
2023-10-30 13:29:50,034 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:29:50,269 Loss: 2.011, MeanIU:  0.7103, Best_mIoU:  0.7151
2023-10-30 13:29:50,269 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747]
2023-10-30 13:29:52,409 Epoch: [249/484] Iter:[0/495], Time: 2.11, lr: [0.00521915566952613], Loss: 2.132999, Acc:0.872393, Semantic loss: 0.811159, BCE loss: 0.417059, SB loss: 0.904782
2023-10-30 13:29:56,332 Epoch: [249/484] Iter:[10/495], Time: 0.55, lr: [0.005218751864643829], Loss: 2.076804, Acc:0.795770, Semantic loss: 0.793274, BCE loss: 0.522204, SB loss: 0.761326
2023-10-30 13:29:59,993 Epoch: [249/484] Iter:[20/495], Time: 0.46, lr: [0.005218348056289864], Loss: 2.103741, Acc:0.793204, Semantic loss: 0.804376, BCE loss: 0.546193, SB loss: 0.753171
2023-10-30 13:30:03,756 Epoch: [249/484] Iter:[30/495], Time: 0.43, lr: [0.005217944244463904], Loss: 2.092521, Acc:0.801515, Semantic loss: 0.801355, BCE loss: 0.543924, SB loss: 0.747242
2023-10-30 13:30:07,389 Epoch: [249/484] Iter:[40/495], Time: 0.42, lr: [0.005217540429165627], Loss: 2.065971, Acc:0.800236, Semantic loss: 0.784593, BCE loss: 0.537313, SB loss: 0.744065
2023-10-30 13:30:11,049 Epoch: [249/484] Iter:[50/495], Time: 0.41, lr: [0.005217136610394699], Loss: 2.092637, Acc:0.803698, Semantic loss: 0.791475, BCE loss: 0.554753, SB loss: 0.746409
2023-10-30 13:30:14,799 Epoch: [249/484] Iter:[60/495], Time: 0.40, lr: [0.005216732788150793], Loss: 2.092425, Acc:0.795992, Semantic loss: 0.792410, BCE loss: 0.550793, SB loss: 0.749222
2023-10-30 13:30:18,482 Epoch: [249/484] Iter:[70/495], Time: 0.40, lr: [0.00521632896243358], Loss: 2.085077, Acc:0.797528, Semantic loss: 0.790166, BCE loss: 0.543922, SB loss: 0.750990
2023-10-30 13:30:22,206 Epoch: [249/484] Iter:[80/495], Time: 0.39, lr: [0.0052159251332427325], Loss: 2.077213, Acc:0.801168, Semantic loss: 0.786534, BCE loss: 0.542395, SB loss: 0.748284
2023-10-30 13:30:25,789 Epoch: [249/484] Iter:[90/495], Time: 0.39, lr: [0.005215521300577921], Loss: 2.087937, Acc:0.801093, Semantic loss: 0.794563, BCE loss: 0.543391, SB loss: 0.749983
2023-10-30 13:30:29,472 Epoch: [249/484] Iter:[100/495], Time: 0.39, lr: [0.005215117464438818], Loss: 2.059711, Acc:0.800648, Semantic loss: 0.783498, BCE loss: 0.532049, SB loss: 0.744163
2023-10-30 13:30:33,158 Epoch: [249/484] Iter:[110/495], Time: 0.39, lr: [0.00521471362482509], Loss: 2.065936, Acc:0.800884, Semantic loss: 0.787787, BCE loss: 0.532953, SB loss: 0.745197
2023-10-30 13:30:36,820 Epoch: [249/484] Iter:[120/495], Time: 0.38, lr: [0.005214309781736415], Loss: 2.071535, Acc:0.799245, Semantic loss: 0.788243, BCE loss: 0.535194, SB loss: 0.748098
2023-10-30 13:30:40,461 Epoch: [249/484] Iter:[130/495], Time: 0.38, lr: [0.005213905935172461], Loss: 2.057532, Acc:0.801213, Semantic loss: 0.779037, BCE loss: 0.535664, SB loss: 0.742831
2023-10-30 13:30:44,130 Epoch: [249/484] Iter:[140/495], Time: 0.38, lr: [0.005213502085132897], Loss: 2.054620, Acc:0.802732, Semantic loss: 0.776060, BCE loss: 0.536847, SB loss: 0.741713
2023-10-30 13:30:47,830 Epoch: [249/484] Iter:[150/495], Time: 0.38, lr: [0.005213098231617396], Loss: 2.054226, Acc:0.801649, Semantic loss: 0.776084, BCE loss: 0.535321, SB loss: 0.742821
2023-10-30 13:30:51,516 Epoch: [249/484] Iter:[160/495], Time: 0.38, lr: [0.005212694374625629], Loss: 2.048856, Acc:0.803939, Semantic loss: 0.772562, BCE loss: 0.535346, SB loss: 0.740948
2023-10-30 13:30:55,172 Epoch: [249/484] Iter:[170/495], Time: 0.38, lr: [0.005212290514157266], Loss: 2.051271, Acc:0.804371, Semantic loss: 0.773448, BCE loss: 0.538030, SB loss: 0.739793
2023-10-30 13:30:58,845 Epoch: [249/484] Iter:[180/495], Time: 0.38, lr: [0.005211886650211978], Loss: 2.056387, Acc:0.803892, Semantic loss: 0.777640, BCE loss: 0.538334, SB loss: 0.740413
2023-10-30 13:31:02,552 Epoch: [249/484] Iter:[190/495], Time: 0.38, lr: [0.0052114827827894365], Loss: 2.044429, Acc:0.803997, Semantic loss: 0.772310, BCE loss: 0.534348, SB loss: 0.737771
2023-10-30 13:31:06,268 Epoch: [249/484] Iter:[200/495], Time: 0.38, lr: [0.005211078911889311], Loss: 2.042597, Acc:0.805836, Semantic loss: 0.770132, BCE loss: 0.533307, SB loss: 0.739158
2023-10-30 13:31:09,939 Epoch: [249/484] Iter:[210/495], Time: 0.38, lr: [0.005210675037511273], Loss: 2.044348, Acc:0.806277, Semantic loss: 0.770793, BCE loss: 0.534612, SB loss: 0.738942
2023-10-30 13:31:13,548 Epoch: [249/484] Iter:[220/495], Time: 0.38, lr: [0.005210271159654991], Loss: 2.039996, Acc:0.804961, Semantic loss: 0.768092, BCE loss: 0.534114, SB loss: 0.737790
2023-10-30 13:31:17,186 Epoch: [249/484] Iter:[230/495], Time: 0.38, lr: [0.005209867278320139], Loss: 2.043832, Acc:0.805955, Semantic loss: 0.768752, BCE loss: 0.537543, SB loss: 0.737538
2023-10-30 13:31:20,839 Epoch: [249/484] Iter:[240/495], Time: 0.38, lr: [0.005209463393506385], Loss: 2.038699, Acc:0.805650, Semantic loss: 0.765353, BCE loss: 0.537452, SB loss: 0.735894
2023-10-30 13:31:24,448 Epoch: [249/484] Iter:[250/495], Time: 0.38, lr: [0.005209059505213399], Loss: 2.046051, Acc:0.803904, Semantic loss: 0.770566, BCE loss: 0.538415, SB loss: 0.737070
2023-10-30 13:31:28,109 Epoch: [249/484] Iter:[260/495], Time: 0.37, lr: [0.005208655613440852], Loss: 2.044949, Acc:0.802291, Semantic loss: 0.771190, BCE loss: 0.536553, SB loss: 0.737206
2023-10-30 13:31:31,757 Epoch: [249/484] Iter:[270/495], Time: 0.37, lr: [0.0052082517181884155], Loss: 2.041191, Acc:0.803296, Semantic loss: 0.767726, BCE loss: 0.538025, SB loss: 0.735441
2023-10-30 13:31:35,399 Epoch: [249/484] Iter:[280/495], Time: 0.37, lr: [0.005207847819455759], Loss: 2.037887, Acc:0.803162, Semantic loss: 0.765002, BCE loss: 0.537474, SB loss: 0.735411
2023-10-30 13:31:39,107 Epoch: [249/484] Iter:[290/495], Time: 0.37, lr: [0.00520744391724255], Loss: 2.040412, Acc:0.803696, Semantic loss: 0.765398, BCE loss: 0.539360, SB loss: 0.735654
2023-10-30 13:31:42,695 Epoch: [249/484] Iter:[300/495], Time: 0.37, lr: [0.005207040011548461], Loss: 2.037580, Acc:0.804217, Semantic loss: 0.764148, BCE loss: 0.538944, SB loss: 0.734488
2023-10-30 13:31:46,402 Epoch: [249/484] Iter:[310/495], Time: 0.37, lr: [0.0052066361023731635], Loss: 2.038134, Acc:0.804218, Semantic loss: 0.765554, BCE loss: 0.537858, SB loss: 0.734722
2023-10-30 13:31:50,050 Epoch: [249/484] Iter:[320/495], Time: 0.37, lr: [0.005206232189716324], Loss: 2.037788, Acc:0.804383, Semantic loss: 0.765607, BCE loss: 0.537020, SB loss: 0.735161
2023-10-30 13:31:53,626 Epoch: [249/484] Iter:[330/495], Time: 0.37, lr: [0.0052058282735776154], Loss: 2.028070, Acc:0.803216, Semantic loss: 0.761486, BCE loss: 0.533466, SB loss: 0.733117
2023-10-30 13:31:57,391 Epoch: [249/484] Iter:[340/495], Time: 0.37, lr: [0.0052054243539567035], Loss: 2.030240, Acc:0.802913, Semantic loss: 0.760877, BCE loss: 0.535313, SB loss: 0.734050
2023-10-30 13:32:01,018 Epoch: [249/484] Iter:[350/495], Time: 0.37, lr: [0.005205020430853262], Loss: 2.029156, Acc:0.803293, Semantic loss: 0.761218, BCE loss: 0.534542, SB loss: 0.733396
2023-10-30 13:32:04,586 Epoch: [249/484] Iter:[360/495], Time: 0.37, lr: [0.005204616504266959], Loss: 2.029884, Acc:0.803870, Semantic loss: 0.762006, BCE loss: 0.534998, SB loss: 0.732880
2023-10-30 13:32:08,337 Epoch: [249/484] Iter:[370/495], Time: 0.37, lr: [0.0052042125741974645], Loss: 2.031948, Acc:0.804090, Semantic loss: 0.763968, BCE loss: 0.534943, SB loss: 0.733037
2023-10-30 13:32:11,981 Epoch: [249/484] Iter:[380/495], Time: 0.37, lr: [0.005203808640644447], Loss: 2.040703, Acc:0.803517, Semantic loss: 0.768294, BCE loss: 0.536986, SB loss: 0.735424
2023-10-30 13:32:15,690 Epoch: [249/484] Iter:[390/495], Time: 0.37, lr: [0.0052034047036075785], Loss: 2.041182, Acc:0.803218, Semantic loss: 0.769655, BCE loss: 0.536339, SB loss: 0.735187
2023-10-30 13:32:19,360 Epoch: [249/484] Iter:[400/495], Time: 0.37, lr: [0.005203000763086525], Loss: 2.045531, Acc:0.803249, Semantic loss: 0.771413, BCE loss: 0.538604, SB loss: 0.735514
2023-10-30 13:32:23,016 Epoch: [249/484] Iter:[410/495], Time: 0.37, lr: [0.005202596819080959], Loss: 2.044149, Acc:0.803379, Semantic loss: 0.770629, BCE loss: 0.538686, SB loss: 0.734834
2023-10-30 13:32:26,624 Epoch: [249/484] Iter:[420/495], Time: 0.37, lr: [0.005202192871590548], Loss: 2.048056, Acc:0.803690, Semantic loss: 0.771895, BCE loss: 0.539900, SB loss: 0.736260
2023-10-30 13:32:30,374 Epoch: [249/484] Iter:[430/495], Time: 0.37, lr: [0.005201788920614962], Loss: 2.051201, Acc:0.802895, Semantic loss: 0.773258, BCE loss: 0.540720, SB loss: 0.737223
2023-10-30 13:32:34,073 Epoch: [249/484] Iter:[440/495], Time: 0.37, lr: [0.0052013849661538695], Loss: 2.052707, Acc:0.803266, Semantic loss: 0.773889, BCE loss: 0.541240, SB loss: 0.737578
2023-10-30 13:32:37,708 Epoch: [249/484] Iter:[450/495], Time: 0.37, lr: [0.005200981008206941], Loss: 2.052717, Acc:0.803506, Semantic loss: 0.774030, BCE loss: 0.540996, SB loss: 0.737692
2023-10-30 13:32:41,350 Epoch: [249/484] Iter:[460/495], Time: 0.37, lr: [0.005200577046773843], Loss: 2.050555, Acc:0.803961, Semantic loss: 0.772326, BCE loss: 0.540175, SB loss: 0.738054
2023-10-30 13:32:45,118 Epoch: [249/484] Iter:[470/495], Time: 0.37, lr: [0.005200173081854248], Loss: 2.052865, Acc:0.803142, Semantic loss: 0.774035, BCE loss: 0.540686, SB loss: 0.738144
2023-10-30 13:32:48,719 Epoch: [249/484] Iter:[480/495], Time: 0.37, lr: [0.005199769113447823], Loss: 2.057285, Acc:0.802776, Semantic loss: 0.776653, BCE loss: 0.541323, SB loss: 0.739309
2023-10-30 13:32:52,221 Epoch: [249/484] Iter:[490/495], Time: 0.37, lr: [0.005199365141554236], Loss: 2.056581, Acc:0.802436, Semantic loss: 0.775683, BCE loss: 0.541845, SB loss: 0.739053
2023-10-30 13:32:53,629 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:32:53,865 Loss: 2.011, MeanIU:  0.7103, Best_mIoU:  0.7151
2023-10-30 13:32:53,865 [0.96567195 0.76218943 0.90174719 0.39033006 0.536675   0.60043802
 0.65779575 0.72250403 0.9111339  0.57174164 0.935404   0.78500862
 0.58153825 0.92894834 0.62410917 0.79125841 0.60365745 0.49162504
 0.73473747]
2023-10-30 13:32:55,823 Epoch: [250/484] Iter:[0/495], Time: 1.92, lr: [0.005199163154299655], Loss: 1.681308, Acc:0.636348, Semantic loss: 0.643913, BCE loss: 0.352903, SB loss: 0.684491
2023-10-30 13:32:59,743 Epoch: [250/484] Iter:[10/495], Time: 0.53, lr: [0.005198759177174705], Loss: 2.075897, Acc:0.752970, Semantic loss: 0.837886, BCE loss: 0.486127, SB loss: 0.751883
2023-10-30 13:33:03,481 Epoch: [250/484] Iter:[20/495], Time: 0.46, lr: [0.005198355196561768], Loss: 2.033534, Acc:0.777918, Semantic loss: 0.810289, BCE loss: 0.484593, SB loss: 0.738652
2023-10-30 13:33:07,087 Epoch: [250/484] Iter:[30/495], Time: 0.43, lr: [0.005197951212460511], Loss: 2.057897, Acc:0.786331, Semantic loss: 0.808038, BCE loss: 0.507755, SB loss: 0.742104
2023-10-30 13:33:10,738 Epoch: [250/484] Iter:[40/495], Time: 0.41, lr: [0.005197547224870602], Loss: 2.091922, Acc:0.784369, Semantic loss: 0.817391, BCE loss: 0.518453, SB loss: 0.756078
2023-10-30 13:33:14,326 Epoch: [250/484] Iter:[50/495], Time: 0.40, lr: [0.00519714323379171], Loss: 2.112542, Acc:0.786246, Semantic loss: 0.832581, BCE loss: 0.516805, SB loss: 0.763156
2023-10-30 13:33:17,927 Epoch: [250/484] Iter:[60/495], Time: 0.39, lr: [0.0051967392392235036], Loss: 2.118701, Acc:0.789446, Semantic loss: 0.833739, BCE loss: 0.525943, SB loss: 0.759019
2023-10-30 13:33:21,476 Epoch: [250/484] Iter:[70/495], Time: 0.39, lr: [0.0051963352411656515], Loss: 2.134889, Acc:0.781490, Semantic loss: 0.847407, BCE loss: 0.528188, SB loss: 0.759295
2023-10-30 13:33:25,048 Epoch: [250/484] Iter:[80/495], Time: 0.38, lr: [0.00519593123961782], Loss: 2.129671, Acc:0.782596, Semantic loss: 0.840205, BCE loss: 0.530029, SB loss: 0.759437
2023-10-30 13:33:28,668 Epoch: [250/484] Iter:[90/495], Time: 0.38, lr: [0.005195527234579682], Loss: 2.128475, Acc:0.784254, Semantic loss: 0.835458, BCE loss: 0.535946, SB loss: 0.757071
2023-10-30 13:33:32,325 Epoch: [250/484] Iter:[100/495], Time: 0.38, lr: [0.005195123226050902], Loss: 2.124815, Acc:0.783278, Semantic loss: 0.836510, BCE loss: 0.533771, SB loss: 0.754534
2023-10-30 13:33:36,035 Epoch: [250/484] Iter:[110/495], Time: 0.38, lr: [0.005194719214031149], Loss: 2.113512, Acc:0.784886, Semantic loss: 0.830583, BCE loss: 0.529949, SB loss: 0.752981
2023-10-30 13:33:39,668 Epoch: [250/484] Iter:[120/495], Time: 0.38, lr: [0.005194315198520092], Loss: 2.119187, Acc:0.787951, Semantic loss: 0.829184, BCE loss: 0.536041, SB loss: 0.753962
2023-10-30 13:33:43,186 Epoch: [250/484] Iter:[130/495], Time: 0.38, lr: [0.005193911179517397], Loss: 2.099009, Acc:0.787118, Semantic loss: 0.818538, BCE loss: 0.531077, SB loss: 0.749394
2023-10-30 13:33:46,910 Epoch: [250/484] Iter:[140/495], Time: 0.38, lr: [0.005193507157022735], Loss: 2.088412, Acc:0.787609, Semantic loss: 0.811159, BCE loss: 0.529203, SB loss: 0.748050
2023-10-30 13:33:50,512 Epoch: [250/484] Iter:[150/495], Time: 0.37, lr: [0.0051931031310357735], Loss: 2.097458, Acc:0.788047, Semantic loss: 0.816930, BCE loss: 0.531161, SB loss: 0.749367
2023-10-30 13:33:54,117 Epoch: [250/484] Iter:[160/495], Time: 0.37, lr: [0.005192699101556178], Loss: 2.083711, Acc:0.787377, Semantic loss: 0.808107, BCE loss: 0.529629, SB loss: 0.745974
2023-10-30 13:33:57,797 Epoch: [250/484] Iter:[170/495], Time: 0.37, lr: [0.005192295068583617], Loss: 2.074710, Acc:0.786234, Semantic loss: 0.802606, BCE loss: 0.528319, SB loss: 0.743785
2023-10-30 13:34:01,405 Epoch: [250/484] Iter:[180/495], Time: 0.37, lr: [0.00519189103211776], Loss: 2.082672, Acc:0.787457, Semantic loss: 0.803144, BCE loss: 0.532905, SB loss: 0.746623
2023-10-30 13:34:04,993 Epoch: [250/484] Iter:[190/495], Time: 0.37, lr: [0.005191486992158275], Loss: 2.072102, Acc:0.789228, Semantic loss: 0.797114, BCE loss: 0.531807, SB loss: 0.743181
2023-10-30 13:34:08,720 Epoch: [250/484] Iter:[200/495], Time: 0.37, lr: [0.005191082948704826], Loss: 2.066710, Acc:0.791105, Semantic loss: 0.793116, BCE loss: 0.531360, SB loss: 0.742234
2023-10-30 13:34:12,462 Epoch: [250/484] Iter:[210/495], Time: 0.37, lr: [0.0051906789017570855], Loss: 2.067906, Acc:0.789559, Semantic loss: 0.795579, BCE loss: 0.528023, SB loss: 0.744303
2023-10-30 13:34:16,209 Epoch: [250/484] Iter:[220/495], Time: 0.37, lr: [0.005190274851314718], Loss: 2.065928, Acc:0.790446, Semantic loss: 0.795079, BCE loss: 0.526714, SB loss: 0.744135
2023-10-30 13:34:19,842 Epoch: [250/484] Iter:[230/495], Time: 0.37, lr: [0.005189870797377391], Loss: 2.075660, Acc:0.790462, Semantic loss: 0.799843, BCE loss: 0.530349, SB loss: 0.745468
2023-10-30 13:34:23,506 Epoch: [250/484] Iter:[240/495], Time: 0.37, lr: [0.005189466739944772], Loss: 2.075454, Acc:0.790755, Semantic loss: 0.798693, BCE loss: 0.532880, SB loss: 0.743881
2023-10-30 13:34:27,139 Epoch: [250/484] Iter:[250/495], Time: 0.37, lr: [0.005189062679016531], Loss: 2.066333, Acc:0.791964, Semantic loss: 0.793136, BCE loss: 0.531263, SB loss: 0.741934
2023-10-30 13:34:30,783 Epoch: [250/484] Iter:[260/495], Time: 0.37, lr: [0.005188658614592332], Loss: 2.065630, Acc:0.792796, Semantic loss: 0.789818, BCE loss: 0.534443, SB loss: 0.741369
2023-10-30 13:34:34,540 Epoch: [250/484] Iter:[270/495], Time: 0.37, lr: [0.005188254546671845], Loss: 2.066466, Acc:0.792404, Semantic loss: 0.790820, BCE loss: 0.534266, SB loss: 0.741379
2023-10-30 13:34:38,177 Epoch: [250/484] Iter:[280/495], Time: 0.37, lr: [0.005187850475254733], Loss: 2.071827, Acc:0.793611, Semantic loss: 0.792141, BCE loss: 0.538136, SB loss: 0.741550
2023-10-30 13:34:41,837 Epoch: [250/484] Iter:[290/495], Time: 0.37, lr: [0.005187446400340668], Loss: 2.069252, Acc:0.793652, Semantic loss: 0.790469, BCE loss: 0.537589, SB loss: 0.741195
2023-10-30 13:34:45,480 Epoch: [250/484] Iter:[300/495], Time: 0.37, lr: [0.005187042321929314], Loss: 2.069805, Acc:0.793201, Semantic loss: 0.790538, BCE loss: 0.537694, SB loss: 0.741573
2023-10-30 13:34:49,209 Epoch: [250/484] Iter:[310/495], Time: 0.37, lr: [0.005186638240020339], Loss: 2.067336, Acc:0.794066, Semantic loss: 0.789721, BCE loss: 0.537201, SB loss: 0.740413
2023-10-30 13:34:52,883 Epoch: [250/484] Iter:[320/495], Time: 0.37, lr: [0.005186234154613409], Loss: 2.067686, Acc:0.795455, Semantic loss: 0.789307, BCE loss: 0.537833, SB loss: 0.740547
2023-10-30 13:34:56,675 Epoch: [250/484] Iter:[330/495], Time: 0.37, lr: [0.005185830065708194], Loss: 2.070276, Acc:0.794731, Semantic loss: 0.792727, BCE loss: 0.536172, SB loss: 0.741376
2023-10-30 13:35:00,317 Epoch: [250/484] Iter:[340/495], Time: 0.37, lr: [0.005185425973304358], Loss: 2.070281, Acc:0.795930, Semantic loss: 0.792011, BCE loss: 0.537240, SB loss: 0.741030
2023-10-30 13:35:03,978 Epoch: [250/484] Iter:[350/495], Time: 0.37, lr: [0.005185021877401568], Loss: 2.071863, Acc:0.796569, Semantic loss: 0.791272, BCE loss: 0.538465, SB loss: 0.742126
2023-10-30 13:35:07,761 Epoch: [250/484] Iter:[360/495], Time: 0.37, lr: [0.005184617777999489], Loss: 2.071534, Acc:0.795976, Semantic loss: 0.790667, BCE loss: 0.538817, SB loss: 0.742050
2023-10-30 13:35:11,495 Epoch: [250/484] Iter:[370/495], Time: 0.37, lr: [0.005184213675097793], Loss: 2.072031, Acc:0.795867, Semantic loss: 0.790903, BCE loss: 0.538838, SB loss: 0.742291
2023-10-30 13:35:15,106 Epoch: [250/484] Iter:[380/495], Time: 0.37, lr: [0.0051838095686961416], Loss: 2.071079, Acc:0.796168, Semantic loss: 0.790259, BCE loss: 0.538351, SB loss: 0.742469
2023-10-30 13:35:18,687 Epoch: [250/484] Iter:[390/495], Time: 0.37, lr: [0.005183405458794205], Loss: 2.066393, Acc:0.795668, Semantic loss: 0.787504, BCE loss: 0.537658, SB loss: 0.741231
2023-10-30 13:35:22,369 Epoch: [250/484] Iter:[400/495], Time: 0.37, lr: [0.0051830013453916446], Loss: 2.063687, Acc:0.795193, Semantic loss: 0.785657, BCE loss: 0.536918, SB loss: 0.741112
2023-10-30 13:35:26,054 Epoch: [250/484] Iter:[410/495], Time: 0.37, lr: [0.005182597228488132], Loss: 2.064772, Acc:0.796400, Semantic loss: 0.785246, BCE loss: 0.538843, SB loss: 0.740683
2023-10-30 13:35:29,748 Epoch: [250/484] Iter:[420/495], Time: 0.37, lr: [0.00518219310808333], Loss: 2.068798, Acc:0.795618, Semantic loss: 0.788313, BCE loss: 0.538880, SB loss: 0.741605
2023-10-30 13:35:33,343 Epoch: [250/484] Iter:[430/495], Time: 0.37, lr: [0.005181788984176908], Loss: 2.070871, Acc:0.795637, Semantic loss: 0.788083, BCE loss: 0.540240, SB loss: 0.742548
2023-10-30 13:35:37,012 Epoch: [250/484] Iter:[440/495], Time: 0.37, lr: [0.005181384856768529], Loss: 2.068667, Acc:0.795429, Semantic loss: 0.787401, BCE loss: 0.539577, SB loss: 0.741689
2023-10-30 13:35:40,691 Epoch: [250/484] Iter:[450/495], Time: 0.37, lr: [0.0051809807258578625], Loss: 2.071859, Acc:0.795378, Semantic loss: 0.789146, BCE loss: 0.540652, SB loss: 0.742061
2023-10-30 13:35:44,382 Epoch: [250/484] Iter:[460/495], Time: 0.37, lr: [0.005180576591444572], Loss: 2.072610, Acc:0.795360, Semantic loss: 0.789832, BCE loss: 0.540350, SB loss: 0.742427
2023-10-30 13:35:48,014 Epoch: [250/484] Iter:[470/495], Time: 0.37, lr: [0.0051801724535283245], Loss: 2.071718, Acc:0.795139, Semantic loss: 0.789076, BCE loss: 0.539591, SB loss: 0.743051
2023-10-30 13:35:51,670 Epoch: [250/484] Iter:[480/495], Time: 0.37, lr: [0.0051797683121087845], Loss: 2.067900, Acc:0.795565, Semantic loss: 0.787112, BCE loss: 0.538747, SB loss: 0.742041
2023-10-30 13:35:55,169 Epoch: [250/484] Iter:[490/495], Time: 0.37, lr: [0.005179364167185621], Loss: 2.067152, Acc:0.795941, Semantic loss: 0.786607, BCE loss: 0.539152, SB loss: 0.741393
2023-10-30 13:38:45,289 0 [9.14431609e-01 5.40061698e-01 8.07869835e-01 1.25119646e-01
 2.47858743e-01 3.99559737e-01 4.04277657e-01 5.63555603e-01
 8.56392070e-01 3.93047471e-01 8.56167667e-01 6.14389465e-01
 1.66394354e-02 7.71223774e-01 2.73689332e-04 5.57425861e-02
 2.94795641e-02 1.05960587e-02 5.75811606e-01] 0.430657784984252
2023-10-30 13:38:45,289 1 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ] 0.6674562908303202
2023-10-30 13:38:45,293 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:38:45,519 Loss: 2.135, MeanIU:  0.6675, Best_mIoU:  0.7151
2023-10-30 13:38:45,519 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ]
2023-10-30 13:38:47,615 Epoch: [251/484] Iter:[0/495], Time: 2.06, lr: [0.005179162093410075], Loss: 3.275020, Acc:0.799187, Semantic loss: 1.861865, BCE loss: 0.640856, SB loss: 0.772299
2023-10-30 13:38:51,420 Epoch: [251/484] Iter:[10/495], Time: 0.53, lr: [0.005178757943230846], Loss: 2.162645, Acc:0.780952, Semantic loss: 0.842429, BCE loss: 0.569947, SB loss: 0.750269
2023-10-30 13:38:54,947 Epoch: [251/484] Iter:[20/495], Time: 0.45, lr: [0.005178353789547157], Loss: 2.071472, Acc:0.796132, Semantic loss: 0.789114, BCE loss: 0.544642, SB loss: 0.737717
2023-10-30 13:38:58,442 Epoch: [251/484] Iter:[30/495], Time: 0.42, lr: [0.005177949632358673], Loss: 2.025209, Acc:0.794405, Semantic loss: 0.745860, BCE loss: 0.546992, SB loss: 0.732357
2023-10-30 13:39:01,806 Epoch: [251/484] Iter:[40/495], Time: 0.40, lr: [0.005177545471665059], Loss: 2.008982, Acc:0.796650, Semantic loss: 0.745123, BCE loss: 0.541119, SB loss: 0.722740
2023-10-30 13:39:05,240 Epoch: [251/484] Iter:[50/495], Time: 0.39, lr: [0.005177141307465982], Loss: 2.023879, Acc:0.798002, Semantic loss: 0.748995, BCE loss: 0.549116, SB loss: 0.725769
2023-10-30 13:39:08,662 Epoch: [251/484] Iter:[60/495], Time: 0.38, lr: [0.005176737139761105], Loss: 2.003658, Acc:0.801904, Semantic loss: 0.745858, BCE loss: 0.534140, SB loss: 0.723660
2023-10-30 13:39:12,214 Epoch: [251/484] Iter:[70/495], Time: 0.38, lr: [0.005176332968550097], Loss: 2.014719, Acc:0.802477, Semantic loss: 0.756584, BCE loss: 0.531767, SB loss: 0.726368
2023-10-30 13:39:15,794 Epoch: [251/484] Iter:[80/495], Time: 0.37, lr: [0.005175928793832622], Loss: 2.010515, Acc:0.801664, Semantic loss: 0.756955, BCE loss: 0.527840, SB loss: 0.725719
2023-10-30 13:39:19,400 Epoch: [251/484] Iter:[90/495], Time: 0.37, lr: [0.005175524615608344], Loss: 2.012602, Acc:0.798186, Semantic loss: 0.756944, BCE loss: 0.527175, SB loss: 0.728484
2023-10-30 13:39:22,966 Epoch: [251/484] Iter:[100/495], Time: 0.37, lr: [0.005175120433876928], Loss: 2.019635, Acc:0.797258, Semantic loss: 0.758846, BCE loss: 0.529413, SB loss: 0.731375
2023-10-30 13:39:26,662 Epoch: [251/484] Iter:[110/495], Time: 0.37, lr: [0.005174716248638042], Loss: 2.009208, Acc:0.799750, Semantic loss: 0.754803, BCE loss: 0.526345, SB loss: 0.728060
2023-10-30 13:39:30,346 Epoch: [251/484] Iter:[120/495], Time: 0.37, lr: [0.005174312059891349], Loss: 2.007379, Acc:0.800162, Semantic loss: 0.757431, BCE loss: 0.522282, SB loss: 0.727666
2023-10-30 13:39:33,953 Epoch: [251/484] Iter:[130/495], Time: 0.37, lr: [0.005173907867636516], Loss: 2.002681, Acc:0.800244, Semantic loss: 0.755944, BCE loss: 0.521191, SB loss: 0.725547
2023-10-30 13:39:37,597 Epoch: [251/484] Iter:[140/495], Time: 0.37, lr: [0.005173503671873205], Loss: 1.999171, Acc:0.798640, Semantic loss: 0.754520, BCE loss: 0.518458, SB loss: 0.726192
2023-10-30 13:39:41,199 Epoch: [251/484] Iter:[150/495], Time: 0.37, lr: [0.005173099472601084], Loss: 2.007622, Acc:0.798679, Semantic loss: 0.758293, BCE loss: 0.521595, SB loss: 0.727734
2023-10-30 13:39:44,699 Epoch: [251/484] Iter:[160/495], Time: 0.37, lr: [0.005172695269819816], Loss: 2.005406, Acc:0.801761, Semantic loss: 0.755478, BCE loss: 0.523475, SB loss: 0.726453
2023-10-30 13:39:48,323 Epoch: [251/484] Iter:[170/495], Time: 0.37, lr: [0.005172291063529066], Loss: 1.998376, Acc:0.801893, Semantic loss: 0.751005, BCE loss: 0.522733, SB loss: 0.724638
2023-10-30 13:39:51,904 Epoch: [251/484] Iter:[180/495], Time: 0.37, lr: [0.005171886853728499], Loss: 2.006231, Acc:0.801419, Semantic loss: 0.756016, BCE loss: 0.522839, SB loss: 0.727377
2023-10-30 13:39:55,449 Epoch: [251/484] Iter:[190/495], Time: 0.37, lr: [0.005171482640417782], Loss: 2.006814, Acc:0.803292, Semantic loss: 0.756317, BCE loss: 0.523141, SB loss: 0.727357
2023-10-30 13:39:58,991 Epoch: [251/484] Iter:[200/495], Time: 0.37, lr: [0.005171078423596576], Loss: 2.000722, Acc:0.802386, Semantic loss: 0.755063, BCE loss: 0.520415, SB loss: 0.725244
2023-10-30 13:40:02,546 Epoch: [251/484] Iter:[210/495], Time: 0.36, lr: [0.0051706742032645485], Loss: 2.002848, Acc:0.801942, Semantic loss: 0.757410, BCE loss: 0.519514, SB loss: 0.725924
2023-10-30 13:40:06,200 Epoch: [251/484] Iter:[220/495], Time: 0.36, lr: [0.005170269979421361], Loss: 1.999801, Acc:0.800313, Semantic loss: 0.755010, BCE loss: 0.519779, SB loss: 0.725012
2023-10-30 13:40:09,912 Epoch: [251/484] Iter:[230/495], Time: 0.37, lr: [0.005169865752066681], Loss: 2.004075, Acc:0.802783, Semantic loss: 0.755978, BCE loss: 0.521594, SB loss: 0.726502
2023-10-30 13:40:13,405 Epoch: [251/484] Iter:[240/495], Time: 0.36, lr: [0.005169461521200171], Loss: 2.006098, Acc:0.803710, Semantic loss: 0.756647, BCE loss: 0.521809, SB loss: 0.727641
2023-10-30 13:40:17,078 Epoch: [251/484] Iter:[250/495], Time: 0.36, lr: [0.005169057286821497], Loss: 2.005495, Acc:0.803561, Semantic loss: 0.755511, BCE loss: 0.522298, SB loss: 0.727687
2023-10-30 13:40:20,725 Epoch: [251/484] Iter:[260/495], Time: 0.36, lr: [0.00516865304893032], Loss: 2.008553, Acc:0.802921, Semantic loss: 0.756352, BCE loss: 0.524182, SB loss: 0.728020
2023-10-30 13:40:24,336 Epoch: [251/484] Iter:[270/495], Time: 0.36, lr: [0.005168248807526309], Loss: 2.012346, Acc:0.801141, Semantic loss: 0.759240, BCE loss: 0.524110, SB loss: 0.728996
2023-10-30 13:40:27,982 Epoch: [251/484] Iter:[280/495], Time: 0.36, lr: [0.0051678445626091255], Loss: 2.012127, Acc:0.800183, Semantic loss: 0.758873, BCE loss: 0.523425, SB loss: 0.729829
2023-10-30 13:40:31,479 Epoch: [251/484] Iter:[290/495], Time: 0.36, lr: [0.005167440314178435], Loss: 2.008748, Acc:0.800067, Semantic loss: 0.757313, BCE loss: 0.522088, SB loss: 0.729347
2023-10-30 13:40:35,188 Epoch: [251/484] Iter:[300/495], Time: 0.36, lr: [0.005167036062233898], Loss: 2.011661, Acc:0.799063, Semantic loss: 0.759769, BCE loss: 0.521092, SB loss: 0.730799
2023-10-30 13:40:38,818 Epoch: [251/484] Iter:[310/495], Time: 0.36, lr: [0.005166631806775182], Loss: 2.009888, Acc:0.798476, Semantic loss: 0.758925, BCE loss: 0.520724, SB loss: 0.730239
2023-10-30 13:40:42,459 Epoch: [251/484] Iter:[320/495], Time: 0.36, lr: [0.0051662275478019494], Loss: 2.009472, Acc:0.799937, Semantic loss: 0.758217, BCE loss: 0.521759, SB loss: 0.729496
2023-10-30 13:40:46,204 Epoch: [251/484] Iter:[330/495], Time: 0.36, lr: [0.005165823285313865], Loss: 2.010711, Acc:0.801624, Semantic loss: 0.758381, BCE loss: 0.522557, SB loss: 0.729773
2023-10-30 13:40:49,791 Epoch: [251/484] Iter:[340/495], Time: 0.36, lr: [0.005165419019310592], Loss: 2.007673, Acc:0.802097, Semantic loss: 0.757485, BCE loss: 0.521639, SB loss: 0.728549
2023-10-30 13:40:53,313 Epoch: [251/484] Iter:[350/495], Time: 0.36, lr: [0.0051650147497917945], Loss: 2.012310, Acc:0.802453, Semantic loss: 0.760813, BCE loss: 0.522856, SB loss: 0.728641
2023-10-30 13:40:56,858 Epoch: [251/484] Iter:[360/495], Time: 0.36, lr: [0.005164610476757136], Loss: 2.015881, Acc:0.802228, Semantic loss: 0.763041, BCE loss: 0.522755, SB loss: 0.730084
2023-10-30 13:41:00,494 Epoch: [251/484] Iter:[370/495], Time: 0.36, lr: [0.0051642062002062806], Loss: 2.013376, Acc:0.802535, Semantic loss: 0.761458, BCE loss: 0.522544, SB loss: 0.729374
2023-10-30 13:41:04,117 Epoch: [251/484] Iter:[380/495], Time: 0.36, lr: [0.0051638019201388895], Loss: 2.012872, Acc:0.802912, Semantic loss: 0.762002, BCE loss: 0.521748, SB loss: 0.729123
2023-10-30 13:41:07,797 Epoch: [251/484] Iter:[390/495], Time: 0.36, lr: [0.0051633976365546294], Loss: 2.013186, Acc:0.803328, Semantic loss: 0.762359, BCE loss: 0.521538, SB loss: 0.729289
2023-10-30 13:41:11,550 Epoch: [251/484] Iter:[400/495], Time: 0.36, lr: [0.005162993349453164], Loss: 2.015219, Acc:0.802433, Semantic loss: 0.763426, BCE loss: 0.522153, SB loss: 0.729640
2023-10-30 13:41:15,243 Epoch: [251/484] Iter:[410/495], Time: 0.36, lr: [0.005162589058834154], Loss: 2.017032, Acc:0.801495, Semantic loss: 0.763242, BCE loss: 0.523208, SB loss: 0.730581
2023-10-30 13:41:18,792 Epoch: [251/484] Iter:[420/495], Time: 0.36, lr: [0.005162184764697262], Loss: 2.017365, Acc:0.801248, Semantic loss: 0.762599, BCE loss: 0.524238, SB loss: 0.730528
2023-10-30 13:41:22,405 Epoch: [251/484] Iter:[430/495], Time: 0.36, lr: [0.005161780467042155], Loss: 2.018437, Acc:0.801728, Semantic loss: 0.762647, BCE loss: 0.525472, SB loss: 0.730318
2023-10-30 13:41:26,156 Epoch: [251/484] Iter:[440/495], Time: 0.36, lr: [0.005161376165868494], Loss: 2.017905, Acc:0.801936, Semantic loss: 0.762365, BCE loss: 0.525130, SB loss: 0.730410
2023-10-30 13:41:29,732 Epoch: [251/484] Iter:[450/495], Time: 0.36, lr: [0.0051609718611759425], Loss: 2.018783, Acc:0.802642, Semantic loss: 0.763367, BCE loss: 0.524480, SB loss: 0.730937
2023-10-30 13:41:33,402 Epoch: [251/484] Iter:[460/495], Time: 0.36, lr: [0.005160567552964163], Loss: 2.019855, Acc:0.802464, Semantic loss: 0.763613, BCE loss: 0.525034, SB loss: 0.731208
2023-10-30 13:41:37,044 Epoch: [251/484] Iter:[470/495], Time: 0.36, lr: [0.005160163241232819], Loss: 2.021206, Acc:0.801709, Semantic loss: 0.763705, BCE loss: 0.525901, SB loss: 0.731600
2023-10-30 13:41:40,699 Epoch: [251/484] Iter:[480/495], Time: 0.36, lr: [0.005159758925981574], Loss: 2.022140, Acc:0.800807, Semantic loss: 0.764948, BCE loss: 0.525673, SB loss: 0.731519
2023-10-30 13:41:44,180 Epoch: [251/484] Iter:[490/495], Time: 0.36, lr: [0.005159354607210091], Loss: 2.022903, Acc:0.800910, Semantic loss: 0.765536, BCE loss: 0.525441, SB loss: 0.731926
2023-10-30 13:41:45,576 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:41:45,809 Loss: 2.135, MeanIU:  0.6675, Best_mIoU:  0.7151
2023-10-30 13:41:45,809 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ]
2023-10-30 13:41:47,834 Epoch: [252/484] Iter:[0/495], Time: 1.98, lr: [0.005159152446504152], Loss: 1.856308, Acc:0.792182, Semantic loss: 0.653577, BCE loss: 0.515473, SB loss: 0.687258
2023-10-30 13:41:51,898 Epoch: [252/484] Iter:[10/495], Time: 0.55, lr: [0.0051587481224516785], Loss: 2.073340, Acc:0.794774, Semantic loss: 0.791175, BCE loss: 0.547018, SB loss: 0.735147
2023-10-30 13:41:55,484 Epoch: [252/484] Iter:[20/495], Time: 0.46, lr: [0.0051583437948781235], Loss: 2.102314, Acc:0.805915, Semantic loss: 0.786530, BCE loss: 0.567236, SB loss: 0.748548
2023-10-30 13:41:59,194 Epoch: [252/484] Iter:[30/495], Time: 0.43, lr: [0.005157939463783148], Loss: 2.038973, Acc:0.796860, Semantic loss: 0.768341, BCE loss: 0.536711, SB loss: 0.733921
2023-10-30 13:42:02,878 Epoch: [252/484] Iter:[40/495], Time: 0.42, lr: [0.005157535129166417], Loss: 2.057011, Acc:0.794485, Semantic loss: 0.774033, BCE loss: 0.545211, SB loss: 0.737767
2023-10-30 13:42:06,576 Epoch: [252/484] Iter:[50/495], Time: 0.41, lr: [0.005157130791027591], Loss: 2.063927, Acc:0.789828, Semantic loss: 0.782344, BCE loss: 0.541948, SB loss: 0.739635
2023-10-30 13:42:10,212 Epoch: [252/484] Iter:[60/495], Time: 0.40, lr: [0.0051567264493663344], Loss: 2.047631, Acc:0.794093, Semantic loss: 0.767803, BCE loss: 0.546739, SB loss: 0.733088
2023-10-30 13:42:13,863 Epoch: [252/484] Iter:[70/495], Time: 0.39, lr: [0.005156322104182309], Loss: 2.029637, Acc:0.799782, Semantic loss: 0.762307, BCE loss: 0.536982, SB loss: 0.730348
2023-10-30 13:42:17,606 Epoch: [252/484] Iter:[80/495], Time: 0.39, lr: [0.005155917755475176], Loss: 2.033229, Acc:0.800605, Semantic loss: 0.763812, BCE loss: 0.536981, SB loss: 0.732436
2023-10-30 13:42:21,279 Epoch: [252/484] Iter:[90/495], Time: 0.39, lr: [0.0051555134032446], Loss: 2.027873, Acc:0.803545, Semantic loss: 0.760355, BCE loss: 0.536371, SB loss: 0.731148
2023-10-30 13:42:24,857 Epoch: [252/484] Iter:[100/495], Time: 0.39, lr: [0.0051551090474902415], Loss: 2.016936, Acc:0.800927, Semantic loss: 0.757362, BCE loss: 0.526548, SB loss: 0.733025
2023-10-30 13:42:28,484 Epoch: [252/484] Iter:[110/495], Time: 0.38, lr: [0.005154704688211763], Loss: 2.006973, Acc:0.799344, Semantic loss: 0.752046, BCE loss: 0.523061, SB loss: 0.731865
2023-10-30 13:42:32,228 Epoch: [252/484] Iter:[120/495], Time: 0.38, lr: [0.005154300325408826], Loss: 2.007834, Acc:0.798743, Semantic loss: 0.752147, BCE loss: 0.524124, SB loss: 0.731563
2023-10-30 13:42:35,848 Epoch: [252/484] Iter:[130/495], Time: 0.38, lr: [0.005153895959081094], Loss: 2.012612, Acc:0.799113, Semantic loss: 0.755692, BCE loss: 0.525434, SB loss: 0.731486
2023-10-30 13:42:39,523 Epoch: [252/484] Iter:[140/495], Time: 0.38, lr: [0.005153491589228228], Loss: 2.008452, Acc:0.797344, Semantic loss: 0.755010, BCE loss: 0.524175, SB loss: 0.729267
2023-10-30 13:42:43,150 Epoch: [252/484] Iter:[150/495], Time: 0.38, lr: [0.005153087215849891], Loss: 2.006852, Acc:0.800620, Semantic loss: 0.752848, BCE loss: 0.524819, SB loss: 0.729185
2023-10-30 13:42:46,827 Epoch: [252/484] Iter:[160/495], Time: 0.38, lr: [0.005152682838945742], Loss: 2.014669, Acc:0.799307, Semantic loss: 0.757724, BCE loss: 0.525706, SB loss: 0.731239
2023-10-30 13:42:50,475 Epoch: [252/484] Iter:[170/495], Time: 0.38, lr: [0.005152278458515447], Loss: 2.016970, Acc:0.798533, Semantic loss: 0.759520, BCE loss: 0.525157, SB loss: 0.732294
2023-10-30 13:42:54,104 Epoch: [252/484] Iter:[180/495], Time: 0.38, lr: [0.0051518740745586655], Loss: 2.021312, Acc:0.797842, Semantic loss: 0.762605, BCE loss: 0.524460, SB loss: 0.734247
2023-10-30 13:42:57,702 Epoch: [252/484] Iter:[190/495], Time: 0.38, lr: [0.005151469687075059], Loss: 2.019658, Acc:0.796039, Semantic loss: 0.761329, BCE loss: 0.523694, SB loss: 0.734634
2023-10-30 13:43:01,324 Epoch: [252/484] Iter:[200/495], Time: 0.38, lr: [0.0051510652960642875], Loss: 2.020540, Acc:0.795004, Semantic loss: 0.762195, BCE loss: 0.522571, SB loss: 0.735774
2023-10-30 13:43:04,908 Epoch: [252/484] Iter:[210/495], Time: 0.37, lr: [0.0051506609015260175], Loss: 2.025030, Acc:0.795461, Semantic loss: 0.764511, BCE loss: 0.522934, SB loss: 0.737584
2023-10-30 13:43:08,481 Epoch: [252/484] Iter:[220/495], Time: 0.37, lr: [0.0051502565034599055], Loss: 2.029467, Acc:0.795737, Semantic loss: 0.766358, BCE loss: 0.524007, SB loss: 0.739102
2023-10-30 13:43:12,155 Epoch: [252/484] Iter:[230/495], Time: 0.37, lr: [0.0051498521018656165], Loss: 2.028842, Acc:0.796910, Semantic loss: 0.766583, BCE loss: 0.523507, SB loss: 0.738752
2023-10-30 13:43:15,749 Epoch: [252/484] Iter:[240/495], Time: 0.37, lr: [0.005149447696742808], Loss: 2.024485, Acc:0.796388, Semantic loss: 0.764738, BCE loss: 0.522917, SB loss: 0.736830
2023-10-30 13:43:19,390 Epoch: [252/484] Iter:[250/495], Time: 0.37, lr: [0.005149043288091145], Loss: 2.020437, Acc:0.795752, Semantic loss: 0.763976, BCE loss: 0.519841, SB loss: 0.736621
2023-10-30 13:43:23,031 Epoch: [252/484] Iter:[260/495], Time: 0.37, lr: [0.0051486388759102875], Loss: 2.022941, Acc:0.796440, Semantic loss: 0.763816, BCE loss: 0.523136, SB loss: 0.735989
2023-10-30 13:43:26,651 Epoch: [252/484] Iter:[270/495], Time: 0.37, lr: [0.005148234460199896], Loss: 2.020281, Acc:0.796939, Semantic loss: 0.762514, BCE loss: 0.522879, SB loss: 0.734888
2023-10-30 13:43:30,372 Epoch: [252/484] Iter:[280/495], Time: 0.37, lr: [0.005147830040959632], Loss: 2.021502, Acc:0.797159, Semantic loss: 0.763458, BCE loss: 0.523820, SB loss: 0.734225
2023-10-30 13:43:34,162 Epoch: [252/484] Iter:[290/495], Time: 0.37, lr: [0.005147425618189158], Loss: 2.022630, Acc:0.798071, Semantic loss: 0.764398, BCE loss: 0.523810, SB loss: 0.734422
2023-10-30 13:43:37,842 Epoch: [252/484] Iter:[300/495], Time: 0.37, lr: [0.005147021191888133], Loss: 2.022120, Acc:0.798119, Semantic loss: 0.763887, BCE loss: 0.523860, SB loss: 0.734374
2023-10-30 13:43:41,441 Epoch: [252/484] Iter:[310/495], Time: 0.37, lr: [0.005146616762056219], Loss: 2.021527, Acc:0.799334, Semantic loss: 0.763283, BCE loss: 0.523608, SB loss: 0.734637
2023-10-30 13:43:45,067 Epoch: [252/484] Iter:[320/495], Time: 0.37, lr: [0.005146212328693074], Loss: 2.018855, Acc:0.798711, Semantic loss: 0.762039, BCE loss: 0.523427, SB loss: 0.733389
2023-10-30 13:43:48,739 Epoch: [252/484] Iter:[330/495], Time: 0.37, lr: [0.005145807891798364], Loss: 2.023209, Acc:0.798572, Semantic loss: 0.763952, BCE loss: 0.525451, SB loss: 0.733805
2023-10-30 13:43:52,424 Epoch: [252/484] Iter:[340/495], Time: 0.37, lr: [0.005145403451371746], Loss: 2.022937, Acc:0.797494, Semantic loss: 0.763277, BCE loss: 0.525853, SB loss: 0.733806
2023-10-30 13:43:56,113 Epoch: [252/484] Iter:[350/495], Time: 0.37, lr: [0.005144999007412882], Loss: 2.021874, Acc:0.797569, Semantic loss: 0.762609, BCE loss: 0.526000, SB loss: 0.733264
2023-10-30 13:43:59,811 Epoch: [252/484] Iter:[360/495], Time: 0.37, lr: [0.005144594559921433], Loss: 2.023918, Acc:0.797257, Semantic loss: 0.762559, BCE loss: 0.527845, SB loss: 0.733513
2023-10-30 13:44:03,457 Epoch: [252/484] Iter:[370/495], Time: 0.37, lr: [0.005144190108897058], Loss: 2.022069, Acc:0.796856, Semantic loss: 0.762012, BCE loss: 0.526341, SB loss: 0.733716
2023-10-30 13:44:07,140 Epoch: [252/484] Iter:[380/495], Time: 0.37, lr: [0.005143785654339419], Loss: 2.018099, Acc:0.797946, Semantic loss: 0.760674, BCE loss: 0.524987, SB loss: 0.732438
2023-10-30 13:44:10,730 Epoch: [252/484] Iter:[390/495], Time: 0.37, lr: [0.0051433811962481755], Loss: 2.020480, Acc:0.798550, Semantic loss: 0.761796, BCE loss: 0.525484, SB loss: 0.733201
2023-10-30 13:44:14,383 Epoch: [252/484] Iter:[400/495], Time: 0.37, lr: [0.005142976734622988], Loss: 2.021395, Acc:0.798669, Semantic loss: 0.762678, BCE loss: 0.525273, SB loss: 0.733444
2023-10-30 13:44:17,961 Epoch: [252/484] Iter:[410/495], Time: 0.37, lr: [0.005142572269463519], Loss: 2.019710, Acc:0.797959, Semantic loss: 0.761822, BCE loss: 0.524468, SB loss: 0.733420
2023-10-30 13:44:21,666 Epoch: [252/484] Iter:[420/495], Time: 0.37, lr: [0.005142167800769426], Loss: 2.017998, Acc:0.797311, Semantic loss: 0.761218, BCE loss: 0.523893, SB loss: 0.732887
2023-10-30 13:44:25,324 Epoch: [252/484] Iter:[430/495], Time: 0.37, lr: [0.005141763328540368], Loss: 2.016834, Acc:0.797678, Semantic loss: 0.760214, BCE loss: 0.523514, SB loss: 0.733107
2023-10-30 13:44:28,955 Epoch: [252/484] Iter:[440/495], Time: 0.37, lr: [0.005141358852776009], Loss: 2.017424, Acc:0.798089, Semantic loss: 0.759645, BCE loss: 0.524844, SB loss: 0.732935
2023-10-30 13:44:32,480 Epoch: [252/484] Iter:[450/495], Time: 0.37, lr: [0.005140954373476008], Loss: 2.020608, Acc:0.797646, Semantic loss: 0.761189, BCE loss: 0.525632, SB loss: 0.733787
2023-10-30 13:44:36,051 Epoch: [252/484] Iter:[460/495], Time: 0.37, lr: [0.005140549890640023], Loss: 2.018209, Acc:0.797710, Semantic loss: 0.759903, BCE loss: 0.525255, SB loss: 0.733051
2023-10-30 13:44:39,620 Epoch: [252/484] Iter:[470/495], Time: 0.37, lr: [0.005140145404267714], Loss: 2.017171, Acc:0.798185, Semantic loss: 0.758777, BCE loss: 0.525662, SB loss: 0.732731
2023-10-30 13:44:43,211 Epoch: [252/484] Iter:[480/495], Time: 0.37, lr: [0.005139740914358744], Loss: 2.017687, Acc:0.797923, Semantic loss: 0.759069, BCE loss: 0.525797, SB loss: 0.732821
2023-10-30 13:44:46,661 Epoch: [252/484] Iter:[490/495], Time: 0.37, lr: [0.005139336420912771], Loss: 2.021187, Acc:0.797515, Semantic loss: 0.761340, BCE loss: 0.525748, SB loss: 0.734099
2023-10-30 13:44:48,053 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:44:48,290 Loss: 2.135, MeanIU:  0.6675, Best_mIoU:  0.7151
2023-10-30 13:44:48,290 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ]
2023-10-30 13:44:50,496 Epoch: [253/484] Iter:[0/495], Time: 2.17, lr: [0.005139134172863301], Loss: 2.300497, Acc:0.857059, Semantic loss: 0.686533, BCE loss: 0.917151, SB loss: 0.696813
2023-10-30 13:44:54,552 Epoch: [253/484] Iter:[10/495], Time: 0.57, lr: [0.005138729674111185], Loss: 2.032878, Acc:0.804440, Semantic loss: 0.725618, BCE loss: 0.612766, SB loss: 0.694495
2023-10-30 13:44:58,160 Epoch: [253/484] Iter:[20/495], Time: 0.47, lr: [0.005138325171821214], Loss: 2.023699, Acc:0.809518, Semantic loss: 0.754519, BCE loss: 0.577845, SB loss: 0.691335
2023-10-30 13:45:01,717 Epoch: [253/484] Iter:[30/495], Time: 0.43, lr: [0.00513792066599305], Loss: 2.016585, Acc:0.804200, Semantic loss: 0.741609, BCE loss: 0.574890, SB loss: 0.700086
2023-10-30 13:45:05,403 Epoch: [253/484] Iter:[40/495], Time: 0.42, lr: [0.005137516156626352], Loss: 1.982927, Acc:0.811974, Semantic loss: 0.725828, BCE loss: 0.553598, SB loss: 0.703501
2023-10-30 13:45:09,113 Epoch: [253/484] Iter:[50/495], Time: 0.41, lr: [0.005137111643720778], Loss: 2.003187, Acc:0.811916, Semantic loss: 0.740654, BCE loss: 0.553664, SB loss: 0.708868
2023-10-30 13:45:12,888 Epoch: [253/484] Iter:[60/495], Time: 0.40, lr: [0.005136707127275986], Loss: 2.000151, Acc:0.814660, Semantic loss: 0.738914, BCE loss: 0.549561, SB loss: 0.711676
2023-10-30 13:45:16,490 Epoch: [253/484] Iter:[70/495], Time: 0.40, lr: [0.005136302607291639], Loss: 2.004212, Acc:0.815526, Semantic loss: 0.744532, BCE loss: 0.547117, SB loss: 0.712563
2023-10-30 13:45:20,237 Epoch: [253/484] Iter:[80/495], Time: 0.39, lr: [0.005135898083767395], Loss: 2.006451, Acc:0.811163, Semantic loss: 0.744523, BCE loss: 0.548438, SB loss: 0.713490
2023-10-30 13:45:23,919 Epoch: [253/484] Iter:[90/495], Time: 0.39, lr: [0.0051354935567029135], Loss: 2.010225, Acc:0.810417, Semantic loss: 0.746519, BCE loss: 0.547289, SB loss: 0.716417
2023-10-30 13:45:27,571 Epoch: [253/484] Iter:[100/495], Time: 0.39, lr: [0.005135089026097852], Loss: 2.011856, Acc:0.810505, Semantic loss: 0.748606, BCE loss: 0.545166, SB loss: 0.718083
2023-10-30 13:45:31,421 Epoch: [253/484] Iter:[110/495], Time: 0.39, lr: [0.005134684491951872], Loss: 2.006709, Acc:0.810333, Semantic loss: 0.746523, BCE loss: 0.541877, SB loss: 0.718308
2023-10-30 13:45:35,174 Epoch: [253/484] Iter:[120/495], Time: 0.39, lr: [0.00513427995426463], Loss: 2.011147, Acc:0.813758, Semantic loss: 0.750770, BCE loss: 0.543158, SB loss: 0.717220
2023-10-30 13:45:39,007 Epoch: [253/484] Iter:[130/495], Time: 0.39, lr: [0.005133875413035788], Loss: 2.009869, Acc:0.810447, Semantic loss: 0.750296, BCE loss: 0.542916, SB loss: 0.716657
2023-10-30 13:45:42,821 Epoch: [253/484] Iter:[140/495], Time: 0.39, lr: [0.005133470868265001], Loss: 2.007329, Acc:0.808860, Semantic loss: 0.749279, BCE loss: 0.540816, SB loss: 0.717235
2023-10-30 13:45:46,478 Epoch: [253/484] Iter:[150/495], Time: 0.39, lr: [0.005133066319951931], Loss: 2.008816, Acc:0.807165, Semantic loss: 0.750081, BCE loss: 0.539354, SB loss: 0.719381
2023-10-30 13:45:50,132 Epoch: [253/484] Iter:[160/495], Time: 0.38, lr: [0.005132661768096236], Loss: 2.005828, Acc:0.805100, Semantic loss: 0.747826, BCE loss: 0.538093, SB loss: 0.719909
2023-10-30 13:45:53,929 Epoch: [253/484] Iter:[170/495], Time: 0.38, lr: [0.005132257212697575], Loss: 2.008223, Acc:0.806050, Semantic loss: 0.748697, BCE loss: 0.539503, SB loss: 0.720023
2023-10-30 13:45:57,575 Epoch: [253/484] Iter:[180/495], Time: 0.38, lr: [0.005131852653755605], Loss: 2.005054, Acc:0.806895, Semantic loss: 0.747580, BCE loss: 0.538467, SB loss: 0.719006
2023-10-30 13:46:01,193 Epoch: [253/484] Iter:[190/495], Time: 0.38, lr: [0.005131448091269987], Loss: 1.997292, Acc:0.806614, Semantic loss: 0.743870, BCE loss: 0.534414, SB loss: 0.719008
2023-10-30 13:46:04,926 Epoch: [253/484] Iter:[200/495], Time: 0.38, lr: [0.005131043525240377], Loss: 1.996171, Acc:0.806903, Semantic loss: 0.742661, BCE loss: 0.532666, SB loss: 0.720844
2023-10-30 13:46:08,640 Epoch: [253/484] Iter:[210/495], Time: 0.38, lr: [0.005130638955666435], Loss: 1.999724, Acc:0.805113, Semantic loss: 0.744274, BCE loss: 0.532548, SB loss: 0.722902
2023-10-30 13:46:12,401 Epoch: [253/484] Iter:[220/495], Time: 0.38, lr: [0.005130234382547821], Loss: 1.997998, Acc:0.803509, Semantic loss: 0.742502, BCE loss: 0.532936, SB loss: 0.722559
2023-10-30 13:46:16,023 Epoch: [253/484] Iter:[230/495], Time: 0.38, lr: [0.00512982980588419], Loss: 2.009850, Acc:0.803777, Semantic loss: 0.749251, BCE loss: 0.535398, SB loss: 0.725201
2023-10-30 13:46:19,771 Epoch: [253/484] Iter:[240/495], Time: 0.38, lr: [0.005129425225675202], Loss: 2.009006, Acc:0.803088, Semantic loss: 0.748897, BCE loss: 0.534829, SB loss: 0.725280
2023-10-30 13:46:23,469 Epoch: [253/484] Iter:[250/495], Time: 0.38, lr: [0.005129020641920513], Loss: 2.014376, Acc:0.802236, Semantic loss: 0.752347, BCE loss: 0.534427, SB loss: 0.727601
2023-10-30 13:46:27,218 Epoch: [253/484] Iter:[260/495], Time: 0.38, lr: [0.005128616054619786], Loss: 2.014946, Acc:0.801633, Semantic loss: 0.752215, BCE loss: 0.534764, SB loss: 0.727967
2023-10-30 13:46:30,884 Epoch: [253/484] Iter:[270/495], Time: 0.38, lr: [0.005128211463772675], Loss: 2.020512, Acc:0.801246, Semantic loss: 0.754838, BCE loss: 0.535761, SB loss: 0.729913
2023-10-30 13:46:34,537 Epoch: [253/484] Iter:[280/495], Time: 0.38, lr: [0.00512780686937884], Loss: 2.027222, Acc:0.800624, Semantic loss: 0.759024, BCE loss: 0.535470, SB loss: 0.732728
2023-10-30 13:46:38,210 Epoch: [253/484] Iter:[290/495], Time: 0.38, lr: [0.005127402271437938], Loss: 2.027657, Acc:0.800664, Semantic loss: 0.758660, BCE loss: 0.535417, SB loss: 0.733580
2023-10-30 13:46:41,888 Epoch: [253/484] Iter:[300/495], Time: 0.38, lr: [0.0051269976699496265], Loss: 2.028566, Acc:0.799424, Semantic loss: 0.759553, BCE loss: 0.534531, SB loss: 0.734483
2023-10-30 13:46:45,745 Epoch: [253/484] Iter:[310/495], Time: 0.38, lr: [0.0051265930649135654], Loss: 2.031293, Acc:0.799296, Semantic loss: 0.759161, BCE loss: 0.536280, SB loss: 0.735852
2023-10-30 13:46:49,351 Epoch: [253/484] Iter:[320/495], Time: 0.38, lr: [0.00512618845632941], Loss: 2.029479, Acc:0.800188, Semantic loss: 0.757305, BCE loss: 0.536280, SB loss: 0.735895
2023-10-30 13:46:53,134 Epoch: [253/484] Iter:[330/495], Time: 0.38, lr: [0.005125783844196818], Loss: 2.026956, Acc:0.799327, Semantic loss: 0.756681, BCE loss: 0.534967, SB loss: 0.735307
2023-10-30 13:46:56,778 Epoch: [253/484] Iter:[340/495], Time: 0.38, lr: [0.005125379228515451], Loss: 2.029151, Acc:0.799431, Semantic loss: 0.758392, BCE loss: 0.535585, SB loss: 0.735174
2023-10-30 13:47:00,597 Epoch: [253/484] Iter:[350/495], Time: 0.38, lr: [0.005124974609284963], Loss: 2.031406, Acc:0.799162, Semantic loss: 0.759562, BCE loss: 0.535900, SB loss: 0.735944
2023-10-30 13:47:04,279 Epoch: [253/484] Iter:[360/495], Time: 0.38, lr: [0.005124569986505011], Loss: 2.035890, Acc:0.798740, Semantic loss: 0.762248, BCE loss: 0.535468, SB loss: 0.738175
2023-10-30 13:47:07,992 Epoch: [253/484] Iter:[370/495], Time: 0.38, lr: [0.005124165360175253], Loss: 2.038042, Acc:0.798220, Semantic loss: 0.763881, BCE loss: 0.534689, SB loss: 0.739472
2023-10-30 13:47:11,729 Epoch: [253/484] Iter:[380/495], Time: 0.38, lr: [0.005123760730295349], Loss: 2.046578, Acc:0.796574, Semantic loss: 0.770560, BCE loss: 0.534376, SB loss: 0.741643
2023-10-30 13:47:15,451 Epoch: [253/484] Iter:[390/495], Time: 0.38, lr: [0.005123356096864954], Loss: 2.048223, Acc:0.796891, Semantic loss: 0.771730, BCE loss: 0.534939, SB loss: 0.741554
2023-10-30 13:47:19,166 Epoch: [253/484] Iter:[400/495], Time: 0.38, lr: [0.0051229514598837254], Loss: 2.057549, Acc:0.796010, Semantic loss: 0.777364, BCE loss: 0.535665, SB loss: 0.744520
2023-10-30 13:47:22,798 Epoch: [253/484] Iter:[410/495], Time: 0.38, lr: [0.005122546819351321], Loss: 2.060501, Acc:0.795607, Semantic loss: 0.777529, BCE loss: 0.537153, SB loss: 0.745819
2023-10-30 13:47:26,625 Epoch: [253/484] Iter:[420/495], Time: 0.38, lr: [0.005122142175267397], Loss: 2.061502, Acc:0.794504, Semantic loss: 0.777596, BCE loss: 0.537555, SB loss: 0.746352
2023-10-30 13:47:30,369 Epoch: [253/484] Iter:[430/495], Time: 0.38, lr: [0.005121737527631612], Loss: 2.059608, Acc:0.795245, Semantic loss: 0.774674, BCE loss: 0.539292, SB loss: 0.745642
2023-10-30 13:47:34,074 Epoch: [253/484] Iter:[440/495], Time: 0.38, lr: [0.005121332876443622], Loss: 2.065626, Acc:0.795474, Semantic loss: 0.777069, BCE loss: 0.541366, SB loss: 0.747190
2023-10-30 13:47:37,766 Epoch: [253/484] Iter:[450/495], Time: 0.38, lr: [0.005120928221703082], Loss: 2.064520, Acc:0.795615, Semantic loss: 0.775945, BCE loss: 0.541458, SB loss: 0.747117
2023-10-30 13:47:41,434 Epoch: [253/484] Iter:[460/495], Time: 0.38, lr: [0.005120523563409655], Loss: 2.064950, Acc:0.794837, Semantic loss: 0.777156, BCE loss: 0.540416, SB loss: 0.747378
2023-10-30 13:47:45,217 Epoch: [253/484] Iter:[470/495], Time: 0.38, lr: [0.005120118901562991], Loss: 2.064273, Acc:0.795094, Semantic loss: 0.776963, BCE loss: 0.539811, SB loss: 0.747499
2023-10-30 13:47:48,850 Epoch: [253/484] Iter:[480/495], Time: 0.38, lr: [0.005119714236162752], Loss: 2.067281, Acc:0.795452, Semantic loss: 0.778568, BCE loss: 0.540055, SB loss: 0.748658
2023-10-30 13:47:52,347 Epoch: [253/484] Iter:[490/495], Time: 0.37, lr: [0.005119309567208589], Loss: 2.068048, Acc:0.795718, Semantic loss: 0.778683, BCE loss: 0.540453, SB loss: 0.748912
2023-10-30 13:47:53,749 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:47:53,980 Loss: 2.135, MeanIU:  0.6675, Best_mIoU:  0.7151
2023-10-30 13:47:53,981 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ]
2023-10-30 13:47:55,890 Epoch: [254/484] Iter:[0/495], Time: 1.87, lr: [0.005119107231398681], Loss: 1.873950, Acc:0.744567, Semantic loss: 0.646408, BCE loss: 0.487179, SB loss: 0.740362
2023-10-30 13:47:59,876 Epoch: [254/484] Iter:[10/495], Time: 0.53, lr: [0.005118702557112996], Loss: 2.002944, Acc:0.802787, Semantic loss: 0.752915, BCE loss: 0.521274, SB loss: 0.728755
2023-10-30 13:48:03,563 Epoch: [254/484] Iter:[20/495], Time: 0.45, lr: [0.00511829787927253], Loss: 2.029259, Acc:0.802209, Semantic loss: 0.752850, BCE loss: 0.541335, SB loss: 0.735074
2023-10-30 13:48:07,276 Epoch: [254/484] Iter:[30/495], Time: 0.43, lr: [0.0051178931978769415], Loss: 1.993089, Acc:0.807988, Semantic loss: 0.736582, BCE loss: 0.525953, SB loss: 0.730554
2023-10-30 13:48:10,973 Epoch: [254/484] Iter:[40/495], Time: 0.41, lr: [0.005117488512925887], Loss: 2.053210, Acc:0.803317, Semantic loss: 0.776738, BCE loss: 0.529069, SB loss: 0.747404
2023-10-30 13:48:14,658 Epoch: [254/484] Iter:[50/495], Time: 0.40, lr: [0.005117083824419023], Loss: 2.038082, Acc:0.792040, Semantic loss: 0.768481, BCE loss: 0.526063, SB loss: 0.743538
2023-10-30 13:48:18,382 Epoch: [254/484] Iter:[60/495], Time: 0.40, lr: [0.005116679132356006], Loss: 2.041570, Acc:0.799988, Semantic loss: 0.769718, BCE loss: 0.531204, SB loss: 0.740648
2023-10-30 13:48:22,132 Epoch: [254/484] Iter:[70/495], Time: 0.40, lr: [0.00511627443673649], Loss: 2.035093, Acc:0.801457, Semantic loss: 0.766636, BCE loss: 0.531496, SB loss: 0.736961
2023-10-30 13:48:25,945 Epoch: [254/484] Iter:[80/495], Time: 0.39, lr: [0.005115869737560134], Loss: 2.038438, Acc:0.803449, Semantic loss: 0.766433, BCE loss: 0.532249, SB loss: 0.739756
2023-10-30 13:48:29,733 Epoch: [254/484] Iter:[90/495], Time: 0.39, lr: [0.005115465034826592], Loss: 2.054331, Acc:0.801385, Semantic loss: 0.775357, BCE loss: 0.539390, SB loss: 0.739584
2023-10-30 13:48:33,499 Epoch: [254/484] Iter:[100/495], Time: 0.39, lr: [0.005115060328535521], Loss: 2.057053, Acc:0.798936, Semantic loss: 0.774966, BCE loss: 0.539469, SB loss: 0.742618
2023-10-30 13:48:37,204 Epoch: [254/484] Iter:[110/495], Time: 0.39, lr: [0.005114655618686577], Loss: 2.051100, Acc:0.801777, Semantic loss: 0.770035, BCE loss: 0.538845, SB loss: 0.742219
2023-10-30 13:48:40,896 Epoch: [254/484] Iter:[120/495], Time: 0.39, lr: [0.005114250905279416], Loss: 2.046944, Acc:0.803433, Semantic loss: 0.768093, BCE loss: 0.539264, SB loss: 0.739587
2023-10-30 13:48:44,701 Epoch: [254/484] Iter:[130/495], Time: 0.39, lr: [0.005113846188313694], Loss: 2.050978, Acc:0.804487, Semantic loss: 0.771161, BCE loss: 0.540340, SB loss: 0.739477
2023-10-30 13:48:48,333 Epoch: [254/484] Iter:[140/495], Time: 0.39, lr: [0.005113441467789066], Loss: 2.045420, Acc:0.804315, Semantic loss: 0.766496, BCE loss: 0.539230, SB loss: 0.739694
2023-10-30 13:48:51,995 Epoch: [254/484] Iter:[150/495], Time: 0.38, lr: [0.005113036743705187], Loss: 2.049059, Acc:0.801940, Semantic loss: 0.771506, BCE loss: 0.537608, SB loss: 0.739945
2023-10-30 13:48:55,646 Epoch: [254/484] Iter:[160/495], Time: 0.38, lr: [0.005112632016061714], Loss: 2.048499, Acc:0.800768, Semantic loss: 0.771233, BCE loss: 0.538020, SB loss: 0.739246
2023-10-30 13:48:59,441 Epoch: [254/484] Iter:[170/495], Time: 0.38, lr: [0.005112227284858304], Loss: 2.044170, Acc:0.799949, Semantic loss: 0.771979, BCE loss: 0.532975, SB loss: 0.739216
2023-10-30 13:49:03,160 Epoch: [254/484] Iter:[180/495], Time: 0.38, lr: [0.00511182255009461], Loss: 2.048804, Acc:0.799712, Semantic loss: 0.773465, BCE loss: 0.534119, SB loss: 0.741220
2023-10-30 13:49:06,896 Epoch: [254/484] Iter:[190/495], Time: 0.38, lr: [0.005111417811770288], Loss: 2.050311, Acc:0.798855, Semantic loss: 0.773875, BCE loss: 0.534380, SB loss: 0.742056
2023-10-30 13:49:10,533 Epoch: [254/484] Iter:[200/495], Time: 0.38, lr: [0.005111013069884995], Loss: 2.052836, Acc:0.797292, Semantic loss: 0.774947, BCE loss: 0.534640, SB loss: 0.743250
2023-10-30 13:49:14,283 Epoch: [254/484] Iter:[210/495], Time: 0.38, lr: [0.005110608324438384], Loss: 2.054674, Acc:0.797592, Semantic loss: 0.775988, BCE loss: 0.536516, SB loss: 0.742170
2023-10-30 13:49:18,027 Epoch: [254/484] Iter:[220/495], Time: 0.38, lr: [0.005110203575430111], Loss: 2.050879, Acc:0.798816, Semantic loss: 0.773162, BCE loss: 0.536647, SB loss: 0.741070
2023-10-30 13:49:21,705 Epoch: [254/484] Iter:[230/495], Time: 0.38, lr: [0.005109798822859831], Loss: 2.057577, Acc:0.800031, Semantic loss: 0.777717, BCE loss: 0.536721, SB loss: 0.743139
2023-10-30 13:49:25,331 Epoch: [254/484] Iter:[240/495], Time: 0.38, lr: [0.005109394066727201], Loss: 2.052761, Acc:0.799656, Semantic loss: 0.774589, BCE loss: 0.535602, SB loss: 0.742570
2023-10-30 13:49:29,016 Epoch: [254/484] Iter:[250/495], Time: 0.38, lr: [0.005108989307031875], Loss: 2.054260, Acc:0.798863, Semantic loss: 0.774385, BCE loss: 0.537220, SB loss: 0.742655
2023-10-30 13:49:32,772 Epoch: [254/484] Iter:[260/495], Time: 0.38, lr: [0.005108584543773508], Loss: 2.050801, Acc:0.797660, Semantic loss: 0.772223, BCE loss: 0.535397, SB loss: 0.743181
2023-10-30 13:49:36,580 Epoch: [254/484] Iter:[270/495], Time: 0.38, lr: [0.005108179776951754], Loss: 2.054105, Acc:0.799538, Semantic loss: 0.773932, BCE loss: 0.538557, SB loss: 0.741616
2023-10-30 13:49:40,224 Epoch: [254/484] Iter:[280/495], Time: 0.38, lr: [0.0051077750065662685], Loss: 2.054012, Acc:0.801175, Semantic loss: 0.774100, BCE loss: 0.539356, SB loss: 0.740555
2023-10-30 13:49:43,965 Epoch: [254/484] Iter:[290/495], Time: 0.38, lr: [0.005107370232616707], Loss: 2.051117, Acc:0.801189, Semantic loss: 0.772120, BCE loss: 0.537805, SB loss: 0.741193
2023-10-30 13:49:47,665 Epoch: [254/484] Iter:[300/495], Time: 0.38, lr: [0.005106965455102724], Loss: 2.052252, Acc:0.801994, Semantic loss: 0.773198, BCE loss: 0.537815, SB loss: 0.741240
2023-10-30 13:49:51,301 Epoch: [254/484] Iter:[310/495], Time: 0.38, lr: [0.0051065606740239725], Loss: 2.051259, Acc:0.802113, Semantic loss: 0.772924, BCE loss: 0.537306, SB loss: 0.741028
2023-10-30 13:49:55,020 Epoch: [254/484] Iter:[320/495], Time: 0.38, lr: [0.005106155889380111], Loss: 2.048981, Acc:0.803197, Semantic loss: 0.771384, BCE loss: 0.537633, SB loss: 0.739964
2023-10-30 13:49:58,755 Epoch: [254/484] Iter:[330/495], Time: 0.38, lr: [0.00510575110117079], Loss: 2.046278, Acc:0.803356, Semantic loss: 0.770818, BCE loss: 0.535685, SB loss: 0.739775
2023-10-30 13:50:02,406 Epoch: [254/484] Iter:[340/495], Time: 0.38, lr: [0.005105346309395666], Loss: 2.047469, Acc:0.804043, Semantic loss: 0.772391, BCE loss: 0.534827, SB loss: 0.740251
2023-10-30 13:50:06,088 Epoch: [254/484] Iter:[350/495], Time: 0.38, lr: [0.005104941514054393], Loss: 2.044164, Acc:0.803486, Semantic loss: 0.771051, BCE loss: 0.533530, SB loss: 0.739584
2023-10-30 13:50:09,791 Epoch: [254/484] Iter:[360/495], Time: 0.38, lr: [0.005104536715146626], Loss: 2.044115, Acc:0.803906, Semantic loss: 0.770885, BCE loss: 0.533948, SB loss: 0.739282
2023-10-30 13:50:13,561 Epoch: [254/484] Iter:[370/495], Time: 0.38, lr: [0.005104131912672018], Loss: 2.047517, Acc:0.804151, Semantic loss: 0.771844, BCE loss: 0.535436, SB loss: 0.740237
2023-10-30 13:50:17,340 Epoch: [254/484] Iter:[380/495], Time: 0.38, lr: [0.005103727106630225], Loss: 2.049560, Acc:0.804603, Semantic loss: 0.772594, BCE loss: 0.535950, SB loss: 0.741016
2023-10-30 13:50:21,031 Epoch: [254/484] Iter:[390/495], Time: 0.38, lr: [0.0051033222970209], Loss: 2.050572, Acc:0.804489, Semantic loss: 0.772365, BCE loss: 0.537626, SB loss: 0.740581
2023-10-30 13:50:24,802 Epoch: [254/484] Iter:[400/495], Time: 0.38, lr: [0.005102917483843696], Loss: 2.050391, Acc:0.804904, Semantic loss: 0.771806, BCE loss: 0.538237, SB loss: 0.740348
2023-10-30 13:50:28,562 Epoch: [254/484] Iter:[410/495], Time: 0.38, lr: [0.00510251266709827], Loss: 2.049637, Acc:0.804227, Semantic loss: 0.771705, BCE loss: 0.537837, SB loss: 0.740095
2023-10-30 13:50:32,198 Epoch: [254/484] Iter:[420/495], Time: 0.38, lr: [0.005102107846784275], Loss: 2.050164, Acc:0.803885, Semantic loss: 0.771327, BCE loss: 0.539051, SB loss: 0.739785
2023-10-30 13:50:35,837 Epoch: [254/484] Iter:[430/495], Time: 0.38, lr: [0.005101703022901363], Loss: 2.049086, Acc:0.803413, Semantic loss: 0.770220, BCE loss: 0.538559, SB loss: 0.740307
2023-10-30 13:50:39,515 Epoch: [254/484] Iter:[440/495], Time: 0.38, lr: [0.00510129819544919], Loss: 2.046162, Acc:0.802492, Semantic loss: 0.768931, BCE loss: 0.537194, SB loss: 0.740037
2023-10-30 13:50:43,225 Epoch: [254/484] Iter:[450/495], Time: 0.38, lr: [0.005100893364427409], Loss: 2.046711, Acc:0.802400, Semantic loss: 0.769260, BCE loss: 0.537330, SB loss: 0.740122
2023-10-30 13:50:47,022 Epoch: [254/484] Iter:[460/495], Time: 0.38, lr: [0.005100488529835674], Loss: 2.049729, Acc:0.802838, Semantic loss: 0.770437, BCE loss: 0.538445, SB loss: 0.740847
2023-10-30 13:50:50,663 Epoch: [254/484] Iter:[470/495], Time: 0.38, lr: [0.005100083691673637], Loss: 2.050753, Acc:0.802722, Semantic loss: 0.770094, BCE loss: 0.539932, SB loss: 0.740727
2023-10-30 13:50:54,317 Epoch: [254/484] Iter:[480/495], Time: 0.37, lr: [0.005099678849940954], Loss: 2.052488, Acc:0.802732, Semantic loss: 0.770761, BCE loss: 0.540299, SB loss: 0.741428
2023-10-30 13:50:57,830 Epoch: [254/484] Iter:[490/495], Time: 0.37, lr: [0.005099274004637278], Loss: 2.047946, Acc:0.802280, Semantic loss: 0.768583, BCE loss: 0.539191, SB loss: 0.740172
2023-10-30 13:50:59,231 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:50:59,473 Loss: 2.135, MeanIU:  0.6675, Best_mIoU:  0.7151
2023-10-30 13:50:59,473 [0.966947   0.76381713 0.8875311  0.28039265 0.50055011 0.54889382
 0.61185941 0.66681862 0.896685   0.55516582 0.92957728 0.75880501
 0.52920679 0.92163834 0.58978274 0.69082303 0.47196339 0.41236378
 0.6988485 ]
2023-10-30 13:51:01,511 Epoch: [255/484] Iter:[0/495], Time: 2.00, lr: [0.005099071580646209], Loss: 1.837830, Acc:0.814705, Semantic loss: 0.699530, BCE loss: 0.424991, SB loss: 0.713309
2023-10-30 13:51:05,598 Epoch: [255/484] Iter:[10/495], Time: 0.55, lr: [0.005098666729985392], Loss: 2.114632, Acc:0.799095, Semantic loss: 0.800459, BCE loss: 0.563649, SB loss: 0.750524
2023-10-30 13:51:09,434 Epoch: [255/484] Iter:[20/495], Time: 0.47, lr: [0.0050982618757527175], Loss: 2.021536, Acc:0.799824, Semantic loss: 0.759797, BCE loss: 0.539409, SB loss: 0.722331
2023-10-30 13:51:13,116 Epoch: [255/484] Iter:[30/495], Time: 0.44, lr: [0.005097857017947836], Loss: 1.989719, Acc:0.806348, Semantic loss: 0.744795, BCE loss: 0.526509, SB loss: 0.718415
2023-10-30 13:51:16,921 Epoch: [255/484] Iter:[40/495], Time: 0.42, lr: [0.0050974521565704005], Loss: 2.022342, Acc:0.809462, Semantic loss: 0.755793, BCE loss: 0.541795, SB loss: 0.724754
2023-10-30 13:51:20,656 Epoch: [255/484] Iter:[50/495], Time: 0.41, lr: [0.0050970472916200635], Loss: 2.037507, Acc:0.808361, Semantic loss: 0.761867, BCE loss: 0.545932, SB loss: 0.729709
2023-10-30 13:51:24,328 Epoch: [255/484] Iter:[60/495], Time: 0.41, lr: [0.005096642423096482], Loss: 2.048910, Acc:0.811794, Semantic loss: 0.771796, BCE loss: 0.541485, SB loss: 0.735628
2023-10-30 13:51:27,984 Epoch: [255/484] Iter:[70/495], Time: 0.40, lr: [0.005096237550999305], Loss: 2.027234, Acc:0.807940, Semantic loss: 0.762191, BCE loss: 0.534875, SB loss: 0.730167
2023-10-30 13:51:31,772 Epoch: [255/484] Iter:[80/495], Time: 0.40, lr: [0.005095832675328189], Loss: 2.022794, Acc:0.808460, Semantic loss: 0.758427, BCE loss: 0.535892, SB loss: 0.728475
2023-10-30 13:51:35,473 Epoch: [255/484] Iter:[90/495], Time: 0.40, lr: [0.0050954277960827835], Loss: 2.035044, Acc:0.805750, Semantic loss: 0.764696, BCE loss: 0.536621, SB loss: 0.733727
2023-10-30 13:51:39,088 Epoch: [255/484] Iter:[100/495], Time: 0.39, lr: [0.0050950229132627435], Loss: 2.037084, Acc:0.806463, Semantic loss: 0.767560, BCE loss: 0.536462, SB loss: 0.733062
2023-10-30 13:51:42,754 Epoch: [255/484] Iter:[110/495], Time: 0.39, lr: [0.005094618026867722], Loss: 2.040042, Acc:0.806366, Semantic loss: 0.771603, BCE loss: 0.534834, SB loss: 0.733605
2023-10-30 13:51:46,438 Epoch: [255/484] Iter:[120/495], Time: 0.39, lr: [0.005094213136897371], Loss: 2.031766, Acc:0.804000, Semantic loss: 0.764808, BCE loss: 0.536615, SB loss: 0.730344
2023-10-30 13:51:50,157 Epoch: [255/484] Iter:[130/495], Time: 0.39, lr: [0.0050938082433513426], Loss: 2.043965, Acc:0.801162, Semantic loss: 0.769566, BCE loss: 0.542635, SB loss: 0.731763
2023-10-30 13:51:53,875 Epoch: [255/484] Iter:[140/495], Time: 0.39, lr: [0.00509340334622929], Loss: 2.039999, Acc:0.800458, Semantic loss: 0.769312, BCE loss: 0.539734, SB loss: 0.730954
2023-10-30 13:51:57,581 Epoch: [255/484] Iter:[150/495], Time: 0.38, lr: [0.005092998445530865], Loss: 2.038374, Acc:0.799705, Semantic loss: 0.769321, BCE loss: 0.540673, SB loss: 0.728380
2023-10-30 13:52:01,349 Epoch: [255/484] Iter:[160/495], Time: 0.38, lr: [0.005092593541255724], Loss: 2.038602, Acc:0.801695, Semantic loss: 0.768473, BCE loss: 0.541140, SB loss: 0.728988
2023-10-30 13:52:05,058 Epoch: [255/484] Iter:[170/495], Time: 0.38, lr: [0.005092188633403513], Loss: 2.036542, Acc:0.801234, Semantic loss: 0.766180, BCE loss: 0.540939, SB loss: 0.729423
2023-10-30 13:52:08,695 Epoch: [255/484] Iter:[180/495], Time: 0.38, lr: [0.0050917837219738886], Loss: 2.038506, Acc:0.801346, Semantic loss: 0.769030, BCE loss: 0.537611, SB loss: 0.731865
2023-10-30 13:52:12,620 Epoch: [255/484] Iter:[190/495], Time: 0.38, lr: [0.005091378806966502], Loss: 2.039691, Acc:0.800659, Semantic loss: 0.769765, BCE loss: 0.537235, SB loss: 0.732691
2023-10-30 13:52:16,400 Epoch: [255/484] Iter:[200/495], Time: 0.38, lr: [0.005090973888381006], Loss: 2.038378, Acc:0.802682, Semantic loss: 0.765058, BCE loss: 0.541327, SB loss: 0.731992
2023-10-30 13:52:20,090 Epoch: [255/484] Iter:[210/495], Time: 0.38, lr: [0.005090568966217052], Loss: 2.037356, Acc:0.803462, Semantic loss: 0.762854, BCE loss: 0.543750, SB loss: 0.730753
2023-10-30 13:52:23,751 Epoch: [255/484] Iter:[220/495], Time: 0.38, lr: [0.0050901640404742935], Loss: 2.034515, Acc:0.803386, Semantic loss: 0.763242, BCE loss: 0.539598, SB loss: 0.731675
2023-10-30 13:52:27,425 Epoch: [255/484] Iter:[230/495], Time: 0.38, lr: [0.005089759111152381], Loss: 2.032941, Acc:0.802865, Semantic loss: 0.761891, BCE loss: 0.538759, SB loss: 0.732291
2023-10-30 13:52:31,031 Epoch: [255/484] Iter:[240/495], Time: 0.38, lr: [0.005089354178250967], Loss: 2.031082, Acc:0.803319, Semantic loss: 0.761567, BCE loss: 0.537840, SB loss: 0.731675
2023-10-30 13:52:34,715 Epoch: [255/484] Iter:[250/495], Time: 0.38, lr: [0.005088949241769703], Loss: 2.027049, Acc:0.802760, Semantic loss: 0.759414, BCE loss: 0.537096, SB loss: 0.730539
2023-10-30 13:52:38,473 Epoch: [255/484] Iter:[260/495], Time: 0.38, lr: [0.005088544301708241], Loss: 2.027151, Acc:0.803427, Semantic loss: 0.758500, BCE loss: 0.539032, SB loss: 0.729619
2023-10-30 13:52:42,335 Epoch: [255/484] Iter:[270/495], Time: 0.38, lr: [0.005088139358066233], Loss: 2.019319, Acc:0.804245, Semantic loss: 0.755644, BCE loss: 0.535644, SB loss: 0.728030
2023-10-30 13:52:46,046 Epoch: [255/484] Iter:[280/495], Time: 0.38, lr: [0.005087734410843331], Loss: 2.021707, Acc:0.804701, Semantic loss: 0.758591, BCE loss: 0.534678, SB loss: 0.728438
2023-10-30 13:52:49,789 Epoch: [255/484] Iter:[290/495], Time: 0.38, lr: [0.005087329460039186], Loss: 2.022776, Acc:0.804323, Semantic loss: 0.758481, BCE loss: 0.536024, SB loss: 0.728272
2023-10-30 13:52:53,385 Epoch: [255/484] Iter:[300/495], Time: 0.38, lr: [0.005086924505653451], Loss: 2.025682, Acc:0.803638, Semantic loss: 0.759914, BCE loss: 0.536841, SB loss: 0.728928
2023-10-30 13:52:57,259 Epoch: [255/484] Iter:[310/495], Time: 0.38, lr: [0.0050865195476857755], Loss: 2.027861, Acc:0.803695, Semantic loss: 0.762552, BCE loss: 0.536906, SB loss: 0.728403
2023-10-30 13:53:01,045 Epoch: [255/484] Iter:[320/495], Time: 0.38, lr: [0.005086114586135813], Loss: 2.030733, Acc:0.802963, Semantic loss: 0.762768, BCE loss: 0.539221, SB loss: 0.728745
2023-10-30 13:53:04,720 Epoch: [255/484] Iter:[330/495], Time: 0.38, lr: [0.005085709621003211], Loss: 2.032155, Acc:0.803990, Semantic loss: 0.762581, BCE loss: 0.540988, SB loss: 0.728586
2023-10-30 13:53:08,354 Epoch: [255/484] Iter:[340/495], Time: 0.38, lr: [0.0050853046522876255], Loss: 2.032840, Acc:0.804260, Semantic loss: 0.763507, BCE loss: 0.540468, SB loss: 0.728866
2023-10-30 13:53:12,114 Epoch: [255/484] Iter:[350/495], Time: 0.38, lr: [0.005084899679988706], Loss: 2.029751, Acc:0.803833, Semantic loss: 0.762516, BCE loss: 0.539179, SB loss: 0.728057
2023-10-30 13:53:15,723 Epoch: [255/484] Iter:[360/495], Time: 0.38, lr: [0.005084494704106104], Loss: 2.031973, Acc:0.803791, Semantic loss: 0.763536, BCE loss: 0.539541, SB loss: 0.728896
2023-10-30 13:53:19,436 Epoch: [255/484] Iter:[370/495], Time: 0.38, lr: [0.005084089724639469], Loss: 2.036107, Acc:0.804339, Semantic loss: 0.765362, BCE loss: 0.541038, SB loss: 0.729707
2023-10-30 13:53:23,170 Epoch: [255/484] Iter:[380/495], Time: 0.38, lr: [0.005083684741588454], Loss: 2.035775, Acc:0.804972, Semantic loss: 0.765581, BCE loss: 0.540667, SB loss: 0.729527
2023-10-30 13:53:26,889 Epoch: [255/484] Iter:[390/495], Time: 0.38, lr: [0.005083279754952708], Loss: 2.033465, Acc:0.804687, Semantic loss: 0.765069, BCE loss: 0.538685, SB loss: 0.729711
2023-10-30 13:53:30,520 Epoch: [255/484] Iter:[400/495], Time: 0.38, lr: [0.005082874764731885], Loss: 2.030973, Acc:0.803976, Semantic loss: 0.764387, BCE loss: 0.537446, SB loss: 0.729140
2023-10-30 13:53:34,127 Epoch: [255/484] Iter:[410/495], Time: 0.38, lr: [0.005082469770925633], Loss: 2.030186, Acc:0.804053, Semantic loss: 0.762992, BCE loss: 0.537844, SB loss: 0.729349
2023-10-30 13:53:37,776 Epoch: [255/484] Iter:[420/495], Time: 0.38, lr: [0.005082064773533604], Loss: 2.028644, Acc:0.803727, Semantic loss: 0.762367, BCE loss: 0.536630, SB loss: 0.729647
2023-10-30 13:53:41,417 Epoch: [255/484] Iter:[430/495], Time: 0.38, lr: [0.005081659772555449], Loss: 2.031131, Acc:0.803642, Semantic loss: 0.764251, BCE loss: 0.536746, SB loss: 0.730133
2023-10-30 13:53:45,125 Epoch: [255/484] Iter:[440/495], Time: 0.38, lr: [0.005081254767990818], Loss: 2.032730, Acc:0.803157, Semantic loss: 0.765026, BCE loss: 0.536912, SB loss: 0.730792
2023-10-30 13:53:48,835 Epoch: [255/484] Iter:[450/495], Time: 0.38, lr: [0.0050808497598393626], Loss: 2.031261, Acc:0.803630, Semantic loss: 0.763221, BCE loss: 0.537786, SB loss: 0.730254
2023-10-30 13:53:52,488 Epoch: [255/484] Iter:[460/495], Time: 0.38, lr: [0.005080444748100731], Loss: 2.030960, Acc:0.803358, Semantic loss: 0.763828, BCE loss: 0.537416, SB loss: 0.729716
2023-10-30 13:53:56,129 Epoch: [255/484] Iter:[470/495], Time: 0.37, lr: [0.005080039732774576], Loss: 2.031042, Acc:0.802949, Semantic loss: 0.763648, BCE loss: 0.537483, SB loss: 0.729911
2023-10-30 13:53:59,779 Epoch: [255/484] Iter:[480/495], Time: 0.37, lr: [0.005079634713860548], Loss: 2.031261, Acc:0.803697, Semantic loss: 0.763690, BCE loss: 0.537830, SB loss: 0.729741
2023-10-30 13:54:03,352 Epoch: [255/484] Iter:[490/495], Time: 0.37, lr: [0.0050792296913582955], Loss: 2.033434, Acc:0.803371, Semantic loss: 0.765518, BCE loss: 0.536174, SB loss: 0.731742
2023-10-30 13:57:00,290 0 [0.9199416  0.61434488 0.80002419 0.17313322 0.24627752 0.38305957
 0.39459943 0.51206676 0.88095418 0.4643579  0.87502309 0.3768163
 0.01987053 0.77231084 0.00519753 0.11085972 0.043092   0.07930089
 0.56878022] 0.43368475642872645
2023-10-30 13:57:00,291 1 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951] 0.6849006746163523
2023-10-30 13:57:00,294 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 13:57:00,537 Loss: 2.120, MeanIU:  0.6849, Best_mIoU:  0.7151
2023-10-30 13:57:00,538 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951]
2023-10-30 13:57:02,580 Epoch: [256/484] Iter:[0/495], Time: 2.01, lr: [0.005079027178761477], Loss: 1.809981, Acc:0.719404, Semantic loss: 0.628696, BCE loss: 0.499958, SB loss: 0.681327
2023-10-30 13:57:06,470 Epoch: [256/484] Iter:[10/495], Time: 0.54, lr: [0.005078622150876234], Loss: 1.933928, Acc:0.808831, Semantic loss: 0.734889, BCE loss: 0.491281, SB loss: 0.707757
2023-10-30 13:57:10,138 Epoch: [256/484] Iter:[20/495], Time: 0.46, lr: [0.005078217119401894], Loss: 1.981036, Acc:0.804030, Semantic loss: 0.745064, BCE loss: 0.509290, SB loss: 0.726682
2023-10-30 13:57:13,579 Epoch: [256/484] Iter:[30/495], Time: 0.42, lr: [0.005077812084338106], Loss: 1.995985, Acc:0.809596, Semantic loss: 0.747759, BCE loss: 0.508561, SB loss: 0.739665
2023-10-30 13:57:17,122 Epoch: [256/484] Iter:[40/495], Time: 0.40, lr: [0.00507740704568452], Loss: 2.020397, Acc:0.811405, Semantic loss: 0.760143, BCE loss: 0.518885, SB loss: 0.741369
2023-10-30 13:57:20,642 Epoch: [256/484] Iter:[50/495], Time: 0.39, lr: [0.005077002003440788], Loss: 2.001090, Acc:0.800935, Semantic loss: 0.758767, BCE loss: 0.507379, SB loss: 0.734944
2023-10-30 13:57:24,207 Epoch: [256/484] Iter:[60/495], Time: 0.39, lr: [0.0050765969576065575], Loss: 2.015844, Acc:0.802285, Semantic loss: 0.764468, BCE loss: 0.513537, SB loss: 0.737840
2023-10-30 13:57:27,754 Epoch: [256/484] Iter:[70/495], Time: 0.38, lr: [0.005076191908181478], Loss: 2.031140, Acc:0.801178, Semantic loss: 0.767798, BCE loss: 0.527407, SB loss: 0.735935
2023-10-30 13:57:31,432 Epoch: [256/484] Iter:[80/495], Time: 0.38, lr: [0.005075786855165202], Loss: 2.021656, Acc:0.801900, Semantic loss: 0.760707, BCE loss: 0.527608, SB loss: 0.733341
2023-10-30 13:57:35,050 Epoch: [256/484] Iter:[90/495], Time: 0.38, lr: [0.005075381798557377], Loss: 2.037884, Acc:0.805399, Semantic loss: 0.761577, BCE loss: 0.537097, SB loss: 0.739211
2023-10-30 13:57:38,785 Epoch: [256/484] Iter:[100/495], Time: 0.38, lr: [0.005074976738357654], Loss: 2.028575, Acc:0.807882, Semantic loss: 0.758525, BCE loss: 0.538506, SB loss: 0.731544
2023-10-30 13:57:42,355 Epoch: [256/484] Iter:[110/495], Time: 0.38, lr: [0.005074571674565681], Loss: 2.035026, Acc:0.804688, Semantic loss: 0.768596, BCE loss: 0.534342, SB loss: 0.732089
2023-10-30 13:57:45,882 Epoch: [256/484] Iter:[120/495], Time: 0.37, lr: [0.00507416660718111], Loss: 2.028519, Acc:0.802743, Semantic loss: 0.764974, BCE loss: 0.533274, SB loss: 0.730272
2023-10-30 13:57:49,451 Epoch: [256/484] Iter:[130/495], Time: 0.37, lr: [0.005073761536203588], Loss: 2.025234, Acc:0.803773, Semantic loss: 0.762918, BCE loss: 0.533095, SB loss: 0.729220
2023-10-30 13:57:53,086 Epoch: [256/484] Iter:[140/495], Time: 0.37, lr: [0.005073356461632765], Loss: 2.021091, Acc:0.805778, Semantic loss: 0.759607, BCE loss: 0.533494, SB loss: 0.727990
2023-10-30 13:57:56,672 Epoch: [256/484] Iter:[150/495], Time: 0.37, lr: [0.005072951383468292], Loss: 2.022283, Acc:0.802389, Semantic loss: 0.759626, BCE loss: 0.533135, SB loss: 0.729523
2023-10-30 13:58:00,476 Epoch: [256/484] Iter:[160/495], Time: 0.37, lr: [0.005072546301709816], Loss: 2.021875, Acc:0.802960, Semantic loss: 0.758645, BCE loss: 0.536744, SB loss: 0.726486
2023-10-30 13:58:04,136 Epoch: [256/484] Iter:[170/495], Time: 0.37, lr: [0.005072141216356988], Loss: 2.016611, Acc:0.801203, Semantic loss: 0.756038, BCE loss: 0.533597, SB loss: 0.726975
2023-10-30 13:58:07,819 Epoch: [256/484] Iter:[180/495], Time: 0.37, lr: [0.0050717361274094565], Loss: 2.017835, Acc:0.799328, Semantic loss: 0.754564, BCE loss: 0.536855, SB loss: 0.726416
2023-10-30 13:58:11,421 Epoch: [256/484] Iter:[190/495], Time: 0.37, lr: [0.005071331034866868], Loss: 2.015566, Acc:0.798235, Semantic loss: 0.752593, BCE loss: 0.537061, SB loss: 0.725912
2023-10-30 13:58:15,084 Epoch: [256/484] Iter:[200/495], Time: 0.37, lr: [0.005070925938728877], Loss: 2.015215, Acc:0.799419, Semantic loss: 0.750566, BCE loss: 0.538360, SB loss: 0.726289
2023-10-30 13:58:18,803 Epoch: [256/484] Iter:[210/495], Time: 0.37, lr: [0.005070520838995129], Loss: 2.013293, Acc:0.800806, Semantic loss: 0.750583, BCE loss: 0.537083, SB loss: 0.725627
2023-10-30 13:58:22,456 Epoch: [256/484] Iter:[220/495], Time: 0.37, lr: [0.005070115735665273], Loss: 2.017614, Acc:0.802219, Semantic loss: 0.754827, BCE loss: 0.535823, SB loss: 0.726965
2023-10-30 13:58:26,170 Epoch: [256/484] Iter:[230/495], Time: 0.37, lr: [0.0050697106287389574], Loss: 2.014444, Acc:0.802743, Semantic loss: 0.753581, BCE loss: 0.535550, SB loss: 0.725313
2023-10-30 13:58:29,898 Epoch: [256/484] Iter:[240/495], Time: 0.37, lr: [0.005069305518215832], Loss: 2.017867, Acc:0.803247, Semantic loss: 0.755308, BCE loss: 0.537520, SB loss: 0.725039
2023-10-30 13:58:33,513 Epoch: [256/484] Iter:[250/495], Time: 0.37, lr: [0.0050689004040955455], Loss: 2.019209, Acc:0.804369, Semantic loss: 0.755429, BCE loss: 0.538159, SB loss: 0.725621
2023-10-30 13:58:37,146 Epoch: [256/484] Iter:[260/495], Time: 0.37, lr: [0.005068495286377745], Loss: 2.019752, Acc:0.803925, Semantic loss: 0.755279, BCE loss: 0.538977, SB loss: 0.725496
2023-10-30 13:58:40,714 Epoch: [256/484] Iter:[270/495], Time: 0.37, lr: [0.005068090165062081], Loss: 2.017756, Acc:0.801947, Semantic loss: 0.753897, BCE loss: 0.538639, SB loss: 0.725220
2023-10-30 13:58:44,347 Epoch: [256/484] Iter:[280/495], Time: 0.37, lr: [0.005067685040148202], Loss: 2.015866, Acc:0.801828, Semantic loss: 0.753554, BCE loss: 0.537273, SB loss: 0.725039
2023-10-30 13:58:48,061 Epoch: [256/484] Iter:[290/495], Time: 0.37, lr: [0.005067279911635755], Loss: 2.016889, Acc:0.802475, Semantic loss: 0.754502, BCE loss: 0.537806, SB loss: 0.724581
2023-10-30 13:58:51,748 Epoch: [256/484] Iter:[300/495], Time: 0.37, lr: [0.0050668747795243885], Loss: 2.019013, Acc:0.802631, Semantic loss: 0.755329, BCE loss: 0.538500, SB loss: 0.725185
2023-10-30 13:58:55,443 Epoch: [256/484] Iter:[310/495], Time: 0.37, lr: [0.005066469643813751], Loss: 2.018194, Acc:0.803202, Semantic loss: 0.754878, BCE loss: 0.538106, SB loss: 0.725210
2023-10-30 13:58:59,171 Epoch: [256/484] Iter:[320/495], Time: 0.37, lr: [0.005066064504503492], Loss: 2.017790, Acc:0.804060, Semantic loss: 0.754680, BCE loss: 0.537635, SB loss: 0.725476
2023-10-30 13:59:02,944 Epoch: [256/484] Iter:[330/495], Time: 0.37, lr: [0.005065659361593259], Loss: 2.018457, Acc:0.804342, Semantic loss: 0.754084, BCE loss: 0.538358, SB loss: 0.726014
2023-10-30 13:59:06,789 Epoch: [256/484] Iter:[340/495], Time: 0.37, lr: [0.0050652542150827], Loss: 2.019343, Acc:0.805766, Semantic loss: 0.755159, BCE loss: 0.539010, SB loss: 0.725174
2023-10-30 13:59:10,601 Epoch: [256/484] Iter:[350/495], Time: 0.37, lr: [0.005064849064971461], Loss: 2.018952, Acc:0.805714, Semantic loss: 0.755810, BCE loss: 0.538376, SB loss: 0.724766
2023-10-30 13:59:14,425 Epoch: [256/484] Iter:[360/495], Time: 0.37, lr: [0.005064443911259193], Loss: 2.017609, Acc:0.804821, Semantic loss: 0.755979, BCE loss: 0.536523, SB loss: 0.725108
2023-10-30 13:59:18,089 Epoch: [256/484] Iter:[370/495], Time: 0.37, lr: [0.005064038753945542], Loss: 2.019655, Acc:0.806003, Semantic loss: 0.756312, BCE loss: 0.537300, SB loss: 0.726044
2023-10-30 13:59:21,786 Epoch: [256/484] Iter:[380/495], Time: 0.37, lr: [0.005063633593030157], Loss: 2.018147, Acc:0.805861, Semantic loss: 0.755563, BCE loss: 0.537090, SB loss: 0.725494
2023-10-30 13:59:25,534 Epoch: [256/484] Iter:[390/495], Time: 0.37, lr: [0.005063228428512685], Loss: 2.020593, Acc:0.805545, Semantic loss: 0.757058, BCE loss: 0.536983, SB loss: 0.726552
2023-10-30 13:59:29,258 Epoch: [256/484] Iter:[400/495], Time: 0.37, lr: [0.005062823260392775], Loss: 2.022104, Acc:0.805434, Semantic loss: 0.760121, BCE loss: 0.535745, SB loss: 0.726239
2023-10-30 13:59:32,952 Epoch: [256/484] Iter:[410/495], Time: 0.37, lr: [0.005062418088670072], Loss: 2.019812, Acc:0.805982, Semantic loss: 0.758458, BCE loss: 0.535708, SB loss: 0.725647
2023-10-30 13:59:36,710 Epoch: [256/484] Iter:[420/495], Time: 0.37, lr: [0.005062012913344225], Loss: 2.018566, Acc:0.805045, Semantic loss: 0.758342, BCE loss: 0.534265, SB loss: 0.725960
2023-10-30 13:59:40,361 Epoch: [256/484] Iter:[430/495], Time: 0.37, lr: [0.005061607734414884], Loss: 2.015164, Acc:0.804350, Semantic loss: 0.757009, BCE loss: 0.532598, SB loss: 0.725556
2023-10-30 13:59:43,983 Epoch: [256/484] Iter:[440/495], Time: 0.37, lr: [0.005061202551881692], Loss: 2.015803, Acc:0.804530, Semantic loss: 0.757072, BCE loss: 0.533191, SB loss: 0.725540
2023-10-30 13:59:47,700 Epoch: [256/484] Iter:[450/495], Time: 0.37, lr: [0.0050607973657443], Loss: 2.017319, Acc:0.804911, Semantic loss: 0.757443, BCE loss: 0.533994, SB loss: 0.725882
2023-10-30 13:59:51,381 Epoch: [256/484] Iter:[460/495], Time: 0.37, lr: [0.005060392176002352], Loss: 2.016770, Acc:0.804484, Semantic loss: 0.757995, BCE loss: 0.532341, SB loss: 0.726434
2023-10-30 13:59:55,117 Epoch: [256/484] Iter:[470/495], Time: 0.37, lr: [0.005059986982655498], Loss: 2.019547, Acc:0.804324, Semantic loss: 0.759614, BCE loss: 0.532866, SB loss: 0.727066
2023-10-30 13:59:58,730 Epoch: [256/484] Iter:[480/495], Time: 0.37, lr: [0.005059581785703384], Loss: 2.020834, Acc:0.803779, Semantic loss: 0.759803, BCE loss: 0.533321, SB loss: 0.727710
2023-10-30 14:00:02,191 Epoch: [256/484] Iter:[490/495], Time: 0.37, lr: [0.005059176585145657], Loss: 2.019004, Acc:0.803810, Semantic loss: 0.758490, BCE loss: 0.532935, SB loss: 0.727579
2023-10-30 14:00:03,597 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:00:03,838 Loss: 2.120, MeanIU:  0.6849, Best_mIoU:  0.7151
2023-10-30 14:00:03,838 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951]
2023-10-30 14:00:05,854 Epoch: [257/484] Iter:[0/495], Time: 1.98, lr: [0.00505897398351458], Loss: 2.089026, Acc:0.776369, Semantic loss: 0.783384, BCE loss: 0.559997, SB loss: 0.745644
2023-10-30 14:00:09,997 Epoch: [257/484] Iter:[10/495], Time: 0.56, lr: [0.005058568777547772], Loss: 2.078928, Acc:0.825601, Semantic loss: 0.752790, BCE loss: 0.559696, SB loss: 0.766442
2023-10-30 14:00:13,759 Epoch: [257/484] Iter:[20/495], Time: 0.47, lr: [0.005058163567974469], Loss: 2.083766, Acc:0.813503, Semantic loss: 0.765523, BCE loss: 0.549110, SB loss: 0.769134
2023-10-30 14:00:17,420 Epoch: [257/484] Iter:[30/495], Time: 0.44, lr: [0.005057758354794319], Loss: 2.059407, Acc:0.801880, Semantic loss: 0.766157, BCE loss: 0.544044, SB loss: 0.749207
2023-10-30 14:00:21,093 Epoch: [257/484] Iter:[40/495], Time: 0.42, lr: [0.005057353138006966], Loss: 2.050221, Acc:0.798466, Semantic loss: 0.759136, BCE loss: 0.544724, SB loss: 0.746361
2023-10-30 14:00:24,786 Epoch: [257/484] Iter:[50/495], Time: 0.41, lr: [0.005056947917612057], Loss: 2.028926, Acc:0.802589, Semantic loss: 0.750649, BCE loss: 0.536502, SB loss: 0.741774
2023-10-30 14:00:28,502 Epoch: [257/484] Iter:[60/495], Time: 0.40, lr: [0.005056542693609242], Loss: 2.039734, Acc:0.803671, Semantic loss: 0.759270, BCE loss: 0.534731, SB loss: 0.745733
2023-10-30 14:00:32,257 Epoch: [257/484] Iter:[70/495], Time: 0.40, lr: [0.005056137465998165], Loss: 2.032659, Acc:0.802095, Semantic loss: 0.759220, BCE loss: 0.534817, SB loss: 0.738622
2023-10-30 14:00:35,918 Epoch: [257/484] Iter:[80/495], Time: 0.40, lr: [0.005055732234778474], Loss: 2.037912, Acc:0.800191, Semantic loss: 0.763877, BCE loss: 0.535358, SB loss: 0.738677
2023-10-30 14:00:39,669 Epoch: [257/484] Iter:[90/495], Time: 0.39, lr: [0.005055326999949813], Loss: 2.025816, Acc:0.798415, Semantic loss: 0.756312, BCE loss: 0.530461, SB loss: 0.739042
2023-10-30 14:00:43,382 Epoch: [257/484] Iter:[100/495], Time: 0.39, lr: [0.005054921761511831], Loss: 2.027506, Acc:0.799596, Semantic loss: 0.755876, BCE loss: 0.532882, SB loss: 0.738749
2023-10-30 14:00:47,069 Epoch: [257/484] Iter:[110/495], Time: 0.39, lr: [0.005054516519464173], Loss: 2.030074, Acc:0.800977, Semantic loss: 0.757957, BCE loss: 0.535186, SB loss: 0.736931
2023-10-30 14:00:50,759 Epoch: [257/484] Iter:[120/495], Time: 0.39, lr: [0.005054111273806485], Loss: 2.036586, Acc:0.801566, Semantic loss: 0.758378, BCE loss: 0.540744, SB loss: 0.737464
2023-10-30 14:00:54,553 Epoch: [257/484] Iter:[130/495], Time: 0.39, lr: [0.005053706024538414], Loss: 2.026893, Acc:0.804069, Semantic loss: 0.753068, BCE loss: 0.539948, SB loss: 0.733877
2023-10-30 14:00:58,364 Epoch: [257/484] Iter:[140/495], Time: 0.39, lr: [0.005053300771659606], Loss: 2.022300, Acc:0.804839, Semantic loss: 0.753162, BCE loss: 0.536320, SB loss: 0.732818
2023-10-30 14:01:02,048 Epoch: [257/484] Iter:[150/495], Time: 0.39, lr: [0.005052895515169707], Loss: 2.029470, Acc:0.805595, Semantic loss: 0.756862, BCE loss: 0.539757, SB loss: 0.732850
2023-10-30 14:01:05,688 Epoch: [257/484] Iter:[160/495], Time: 0.38, lr: [0.005052490255068364], Loss: 2.034152, Acc:0.804215, Semantic loss: 0.759806, BCE loss: 0.541190, SB loss: 0.733156
2023-10-30 14:01:09,402 Epoch: [257/484] Iter:[170/495], Time: 0.38, lr: [0.00505208499135522], Loss: 2.026078, Acc:0.803488, Semantic loss: 0.757496, BCE loss: 0.537086, SB loss: 0.731496
2023-10-30 14:01:13,125 Epoch: [257/484] Iter:[180/495], Time: 0.38, lr: [0.005051679724029925], Loss: 2.022358, Acc:0.802104, Semantic loss: 0.757325, BCE loss: 0.534083, SB loss: 0.730951
2023-10-30 14:01:16,932 Epoch: [257/484] Iter:[190/495], Time: 0.38, lr: [0.005051274453092122], Loss: 2.022086, Acc:0.803491, Semantic loss: 0.757199, BCE loss: 0.534676, SB loss: 0.730211
2023-10-30 14:01:20,761 Epoch: [257/484] Iter:[200/495], Time: 0.38, lr: [0.005050869178541456], Loss: 2.022239, Acc:0.805165, Semantic loss: 0.756013, BCE loss: 0.535173, SB loss: 0.731054
2023-10-30 14:01:24,367 Epoch: [257/484] Iter:[210/495], Time: 0.38, lr: [0.005050463900377575], Loss: 2.028523, Acc:0.805577, Semantic loss: 0.757823, BCE loss: 0.538044, SB loss: 0.732657
2023-10-30 14:01:28,096 Epoch: [257/484] Iter:[220/495], Time: 0.38, lr: [0.005050058618600125], Loss: 2.026237, Acc:0.806428, Semantic loss: 0.757084, BCE loss: 0.537592, SB loss: 0.731561
2023-10-30 14:01:31,949 Epoch: [257/484] Iter:[230/495], Time: 0.38, lr: [0.005049653333208749], Loss: 2.029411, Acc:0.807594, Semantic loss: 0.758965, BCE loss: 0.538464, SB loss: 0.731983
2023-10-30 14:01:35,682 Epoch: [257/484] Iter:[240/495], Time: 0.38, lr: [0.005049248044203094], Loss: 2.029689, Acc:0.807172, Semantic loss: 0.759092, BCE loss: 0.538655, SB loss: 0.731942
2023-10-30 14:01:39,388 Epoch: [257/484] Iter:[250/495], Time: 0.38, lr: [0.005048842751582805], Loss: 2.034193, Acc:0.804923, Semantic loss: 0.762850, BCE loss: 0.537703, SB loss: 0.733640
2023-10-30 14:01:43,025 Epoch: [257/484] Iter:[260/495], Time: 0.38, lr: [0.005048437455347529], Loss: 2.037438, Acc:0.804866, Semantic loss: 0.765204, BCE loss: 0.537833, SB loss: 0.734401
2023-10-30 14:01:46,797 Epoch: [257/484] Iter:[270/495], Time: 0.38, lr: [0.005048032155496909], Loss: 2.037422, Acc:0.804772, Semantic loss: 0.765509, BCE loss: 0.537067, SB loss: 0.734846
2023-10-30 14:01:50,575 Epoch: [257/484] Iter:[280/495], Time: 0.38, lr: [0.0050476268520305905], Loss: 2.040487, Acc:0.804331, Semantic loss: 0.766788, BCE loss: 0.538395, SB loss: 0.735303
2023-10-30 14:01:54,297 Epoch: [257/484] Iter:[290/495], Time: 0.38, lr: [0.0050472215449482195], Loss: 2.042121, Acc:0.803926, Semantic loss: 0.769420, BCE loss: 0.536970, SB loss: 0.735731
2023-10-30 14:01:58,030 Epoch: [257/484] Iter:[300/495], Time: 0.38, lr: [0.005046816234249441], Loss: 2.042266, Acc:0.803463, Semantic loss: 0.768799, BCE loss: 0.537679, SB loss: 0.735788
2023-10-30 14:02:01,799 Epoch: [257/484] Iter:[310/495], Time: 0.38, lr: [0.0050464109199339], Loss: 2.042953, Acc:0.804125, Semantic loss: 0.768046, BCE loss: 0.538975, SB loss: 0.735932
2023-10-30 14:02:05,512 Epoch: [257/484] Iter:[320/495], Time: 0.38, lr: [0.00504600560200124], Loss: 2.043455, Acc:0.805258, Semantic loss: 0.768635, BCE loss: 0.538573, SB loss: 0.736247
2023-10-30 14:02:09,141 Epoch: [257/484] Iter:[330/495], Time: 0.38, lr: [0.005045600280451109], Loss: 2.044709, Acc:0.804542, Semantic loss: 0.771105, BCE loss: 0.537433, SB loss: 0.736172
2023-10-30 14:02:12,809 Epoch: [257/484] Iter:[340/495], Time: 0.38, lr: [0.005045194955283149], Loss: 2.043421, Acc:0.804925, Semantic loss: 0.771410, BCE loss: 0.536643, SB loss: 0.735369
2023-10-30 14:02:16,468 Epoch: [257/484] Iter:[350/495], Time: 0.38, lr: [0.005044789626497006], Loss: 2.043068, Acc:0.805511, Semantic loss: 0.770317, BCE loss: 0.536971, SB loss: 0.735780
2023-10-30 14:02:20,162 Epoch: [257/484] Iter:[360/495], Time: 0.38, lr: [0.005044384294092325], Loss: 2.040668, Acc:0.805001, Semantic loss: 0.769403, BCE loss: 0.535921, SB loss: 0.735344
2023-10-30 14:02:23,786 Epoch: [257/484] Iter:[370/495], Time: 0.38, lr: [0.005043978958068749], Loss: 2.038671, Acc:0.804604, Semantic loss: 0.768335, BCE loss: 0.535438, SB loss: 0.734898
2023-10-30 14:02:27,475 Epoch: [257/484] Iter:[380/495], Time: 0.38, lr: [0.005043573618425924], Loss: 2.041805, Acc:0.804292, Semantic loss: 0.769241, BCE loss: 0.536588, SB loss: 0.735976
2023-10-30 14:02:31,181 Epoch: [257/484] Iter:[390/495], Time: 0.38, lr: [0.005043168275163494], Loss: 2.041322, Acc:0.803027, Semantic loss: 0.769837, BCE loss: 0.535868, SB loss: 0.735617
2023-10-30 14:02:34,840 Epoch: [257/484] Iter:[400/495], Time: 0.38, lr: [0.005042762928281104], Loss: 2.040135, Acc:0.802892, Semantic loss: 0.768053, BCE loss: 0.536506, SB loss: 0.735575
2023-10-30 14:02:38,660 Epoch: [257/484] Iter:[410/495], Time: 0.38, lr: [0.005042357577778398], Loss: 2.040778, Acc:0.802272, Semantic loss: 0.769928, BCE loss: 0.534219, SB loss: 0.736631
2023-10-30 14:02:42,359 Epoch: [257/484] Iter:[420/495], Time: 0.38, lr: [0.00504195222365502], Loss: 2.044860, Acc:0.802530, Semantic loss: 0.772209, BCE loss: 0.534498, SB loss: 0.738154
2023-10-30 14:02:46,088 Epoch: [257/484] Iter:[430/495], Time: 0.38, lr: [0.005041546865910614], Loss: 2.046689, Acc:0.802195, Semantic loss: 0.772791, BCE loss: 0.534532, SB loss: 0.739366
2023-10-30 14:02:49,782 Epoch: [257/484] Iter:[440/495], Time: 0.38, lr: [0.005041141504544825], Loss: 2.046502, Acc:0.801796, Semantic loss: 0.772202, BCE loss: 0.534973, SB loss: 0.739326
2023-10-30 14:02:53,480 Epoch: [257/484] Iter:[450/495], Time: 0.38, lr: [0.005040736139557296], Loss: 2.044671, Acc:0.801722, Semantic loss: 0.771147, BCE loss: 0.534779, SB loss: 0.738745
2023-10-30 14:02:57,108 Epoch: [257/484] Iter:[460/495], Time: 0.38, lr: [0.005040330770947673], Loss: 2.041978, Acc:0.800740, Semantic loss: 0.769929, BCE loss: 0.533926, SB loss: 0.738123
2023-10-30 14:03:00,815 Epoch: [257/484] Iter:[470/495], Time: 0.38, lr: [0.005039925398715598], Loss: 2.045151, Acc:0.800608, Semantic loss: 0.772733, BCE loss: 0.533743, SB loss: 0.738675
2023-10-30 14:03:04,483 Epoch: [257/484] Iter:[480/495], Time: 0.38, lr: [0.005039520022860714], Loss: 2.044643, Acc:0.800177, Semantic loss: 0.772530, BCE loss: 0.533303, SB loss: 0.738810
2023-10-30 14:03:08,009 Epoch: [257/484] Iter:[490/495], Time: 0.38, lr: [0.005039114643382668], Loss: 2.043633, Acc:0.799943, Semantic loss: 0.771709, BCE loss: 0.533162, SB loss: 0.738762
2023-10-30 14:03:09,415 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:03:09,655 Loss: 2.120, MeanIU:  0.6849, Best_mIoU:  0.7151
2023-10-30 14:03:09,655 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951]
2023-10-30 14:03:11,849 Epoch: [258/484] Iter:[0/495], Time: 2.16, lr: [0.005038911952284847], Loss: 1.645971, Acc:0.751720, Semantic loss: 0.663738, BCE loss: 0.325130, SB loss: 0.657102
2023-10-30 14:03:15,987 Epoch: [258/484] Iter:[10/495], Time: 0.57, lr: [0.005038506567371387], Loss: 2.024111, Acc:0.821117, Semantic loss: 0.764345, BCE loss: 0.541493, SB loss: 0.718274
2023-10-30 14:03:19,811 Epoch: [258/484] Iter:[20/495], Time: 0.48, lr: [0.005038101178833874], Loss: 2.010949, Acc:0.807666, Semantic loss: 0.759349, BCE loss: 0.532138, SB loss: 0.719462
2023-10-30 14:03:23,540 Epoch: [258/484] Iter:[30/495], Time: 0.45, lr: [0.005037695786671947], Loss: 2.007736, Acc:0.799399, Semantic loss: 0.762549, BCE loss: 0.520967, SB loss: 0.724220
2023-10-30 14:03:27,239 Epoch: [258/484] Iter:[40/495], Time: 0.43, lr: [0.005037290390885255], Loss: 2.014990, Acc:0.801637, Semantic loss: 0.770488, BCE loss: 0.519490, SB loss: 0.725013
2023-10-30 14:03:30,992 Epoch: [258/484] Iter:[50/495], Time: 0.42, lr: [0.005036884991473439], Loss: 2.003926, Acc:0.799120, Semantic loss: 0.765315, BCE loss: 0.511855, SB loss: 0.726756
2023-10-30 14:03:34,658 Epoch: [258/484] Iter:[60/495], Time: 0.41, lr: [0.005036479588436142], Loss: 2.024152, Acc:0.804419, Semantic loss: 0.770913, BCE loss: 0.525103, SB loss: 0.728136
2023-10-30 14:03:38,314 Epoch: [258/484] Iter:[70/495], Time: 0.40, lr: [0.005036074181773008], Loss: 2.022235, Acc:0.810556, Semantic loss: 0.768598, BCE loss: 0.531013, SB loss: 0.722624
2023-10-30 14:03:41,991 Epoch: [258/484] Iter:[80/495], Time: 0.40, lr: [0.005035668771483682], Loss: 2.019243, Acc:0.811885, Semantic loss: 0.769768, BCE loss: 0.526449, SB loss: 0.723027
2023-10-30 14:03:45,674 Epoch: [258/484] Iter:[90/495], Time: 0.40, lr: [0.005035263357567803], Loss: 2.020549, Acc:0.812610, Semantic loss: 0.764429, BCE loss: 0.533452, SB loss: 0.722668
2023-10-30 14:03:49,418 Epoch: [258/484] Iter:[100/495], Time: 0.39, lr: [0.005034857940025016], Loss: 2.030659, Acc:0.807056, Semantic loss: 0.772604, BCE loss: 0.531971, SB loss: 0.726085
2023-10-30 14:03:53,111 Epoch: [258/484] Iter:[110/495], Time: 0.39, lr: [0.005034452518854965], Loss: 2.031580, Acc:0.807778, Semantic loss: 0.769033, BCE loss: 0.535491, SB loss: 0.727056
2023-10-30 14:03:56,774 Epoch: [258/484] Iter:[120/495], Time: 0.39, lr: [0.005034047094057294], Loss: 2.033716, Acc:0.807829, Semantic loss: 0.770728, BCE loss: 0.534626, SB loss: 0.728361
2023-10-30 14:04:00,576 Epoch: [258/484] Iter:[130/495], Time: 0.39, lr: [0.005033641665631643], Loss: 2.031580, Acc:0.806811, Semantic loss: 0.769240, BCE loss: 0.532758, SB loss: 0.729583
2023-10-30 14:04:04,281 Epoch: [258/484] Iter:[140/495], Time: 0.39, lr: [0.005033236233577656], Loss: 2.041099, Acc:0.805570, Semantic loss: 0.772566, BCE loss: 0.535910, SB loss: 0.732624
2023-10-30 14:04:08,012 Epoch: [258/484] Iter:[150/495], Time: 0.39, lr: [0.005032830797894976], Loss: 2.033089, Acc:0.807259, Semantic loss: 0.767931, BCE loss: 0.534044, SB loss: 0.731114
2023-10-30 14:04:11,750 Epoch: [258/484] Iter:[160/495], Time: 0.39, lr: [0.0050324253585832465], Loss: 2.037262, Acc:0.806836, Semantic loss: 0.770697, BCE loss: 0.533216, SB loss: 0.733349
2023-10-30 14:04:15,402 Epoch: [258/484] Iter:[170/495], Time: 0.38, lr: [0.005032019915642109], Loss: 2.034399, Acc:0.805141, Semantic loss: 0.765132, BCE loss: 0.535915, SB loss: 0.733352
2023-10-30 14:04:19,209 Epoch: [258/484] Iter:[180/495], Time: 0.38, lr: [0.005031614469071207], Loss: 2.030674, Acc:0.806214, Semantic loss: 0.763182, BCE loss: 0.535576, SB loss: 0.731916
2023-10-30 14:04:22,939 Epoch: [258/484] Iter:[190/495], Time: 0.38, lr: [0.005031209018870182], Loss: 2.025263, Acc:0.807352, Semantic loss: 0.760665, BCE loss: 0.534066, SB loss: 0.730532
2023-10-30 14:04:26,820 Epoch: [258/484] Iter:[200/495], Time: 0.38, lr: [0.005030803565038676], Loss: 2.024212, Acc:0.809065, Semantic loss: 0.758470, BCE loss: 0.535482, SB loss: 0.730260
2023-10-30 14:04:30,462 Epoch: [258/484] Iter:[210/495], Time: 0.38, lr: [0.005030398107576334], Loss: 2.025848, Acc:0.810073, Semantic loss: 0.759338, BCE loss: 0.536720, SB loss: 0.729790
2023-10-30 14:04:34,193 Epoch: [258/484] Iter:[220/495], Time: 0.38, lr: [0.005029992646482795], Loss: 2.022235, Acc:0.808342, Semantic loss: 0.757066, BCE loss: 0.535387, SB loss: 0.729782
2023-10-30 14:04:37,966 Epoch: [258/484] Iter:[230/495], Time: 0.38, lr: [0.005029587181757705], Loss: 2.023958, Acc:0.807964, Semantic loss: 0.758750, BCE loss: 0.535485, SB loss: 0.729723
2023-10-30 14:04:41,721 Epoch: [258/484] Iter:[240/495], Time: 0.38, lr: [0.005029181713400702], Loss: 2.026081, Acc:0.807706, Semantic loss: 0.760281, BCE loss: 0.536663, SB loss: 0.729138
2023-10-30 14:04:45,385 Epoch: [258/484] Iter:[250/495], Time: 0.38, lr: [0.005028776241411431], Loss: 2.027518, Acc:0.806921, Semantic loss: 0.759479, BCE loss: 0.539730, SB loss: 0.728309
2023-10-30 14:04:49,202 Epoch: [258/484] Iter:[260/495], Time: 0.38, lr: [0.0050283707657895315], Loss: 2.034638, Acc:0.806440, Semantic loss: 0.764432, BCE loss: 0.541761, SB loss: 0.728445
2023-10-30 14:04:52,977 Epoch: [258/484] Iter:[270/495], Time: 0.38, lr: [0.005027965286534649], Loss: 2.030809, Acc:0.805919, Semantic loss: 0.762373, BCE loss: 0.539488, SB loss: 0.728948
2023-10-30 14:04:56,668 Epoch: [258/484] Iter:[280/495], Time: 0.38, lr: [0.005027559803646423], Loss: 2.033248, Acc:0.805338, Semantic loss: 0.763995, BCE loss: 0.539246, SB loss: 0.730007
2023-10-30 14:05:00,414 Epoch: [258/484] Iter:[290/495], Time: 0.38, lr: [0.0050271543171244975], Loss: 2.031251, Acc:0.804614, Semantic loss: 0.763815, BCE loss: 0.537128, SB loss: 0.730308
2023-10-30 14:05:04,072 Epoch: [258/484] Iter:[300/495], Time: 0.38, lr: [0.00502674882696851], Loss: 2.033703, Acc:0.804148, Semantic loss: 0.763674, BCE loss: 0.539201, SB loss: 0.730828
2023-10-30 14:05:07,880 Epoch: [258/484] Iter:[310/495], Time: 0.38, lr: [0.005026343333178106], Loss: 2.037275, Acc:0.802583, Semantic loss: 0.767192, BCE loss: 0.536633, SB loss: 0.733451
2023-10-30 14:05:11,575 Epoch: [258/484] Iter:[320/495], Time: 0.38, lr: [0.005025937835752926], Loss: 2.034629, Acc:0.801103, Semantic loss: 0.766475, BCE loss: 0.534472, SB loss: 0.733683
2023-10-30 14:05:15,308 Epoch: [258/484] Iter:[330/495], Time: 0.38, lr: [0.005025532334692613], Loss: 2.035526, Acc:0.800364, Semantic loss: 0.767226, BCE loss: 0.533695, SB loss: 0.734605
2023-10-30 14:05:19,076 Epoch: [258/484] Iter:[340/495], Time: 0.38, lr: [0.005025126829996804], Loss: 2.038292, Acc:0.799310, Semantic loss: 0.769072, BCE loss: 0.533997, SB loss: 0.735223
2023-10-30 14:05:22,849 Epoch: [258/484] Iter:[350/495], Time: 0.38, lr: [0.005024721321665145], Loss: 2.041218, Acc:0.800540, Semantic loss: 0.769587, BCE loss: 0.535214, SB loss: 0.736417
2023-10-30 14:05:26,535 Epoch: [258/484] Iter:[360/495], Time: 0.38, lr: [0.005024315809697278], Loss: 2.038648, Acc:0.800370, Semantic loss: 0.767155, BCE loss: 0.536018, SB loss: 0.735475
2023-10-30 14:05:30,192 Epoch: [258/484] Iter:[370/495], Time: 0.38, lr: [0.005023910294092841], Loss: 2.039636, Acc:0.800186, Semantic loss: 0.767615, BCE loss: 0.536041, SB loss: 0.735980
2023-10-30 14:05:33,815 Epoch: [258/484] Iter:[380/495], Time: 0.38, lr: [0.005023504774851474], Loss: 2.035665, Acc:0.799806, Semantic loss: 0.766226, BCE loss: 0.533930, SB loss: 0.735510
2023-10-30 14:05:37,422 Epoch: [258/484] Iter:[390/495], Time: 0.38, lr: [0.0050230992519728224], Loss: 2.039679, Acc:0.800161, Semantic loss: 0.767248, BCE loss: 0.536243, SB loss: 0.736188
2023-10-30 14:05:41,153 Epoch: [258/484] Iter:[400/495], Time: 0.38, lr: [0.005022693725456526], Loss: 2.038186, Acc:0.799367, Semantic loss: 0.766560, BCE loss: 0.536043, SB loss: 0.735582
2023-10-30 14:05:45,020 Epoch: [258/484] Iter:[410/495], Time: 0.38, lr: [0.0050222881953022255], Loss: 2.040373, Acc:0.799243, Semantic loss: 0.768237, BCE loss: 0.536002, SB loss: 0.736134
2023-10-30 14:05:48,841 Epoch: [258/484] Iter:[420/495], Time: 0.38, lr: [0.00502188266150956], Loss: 2.042299, Acc:0.799453, Semantic loss: 0.768809, BCE loss: 0.537483, SB loss: 0.736007
2023-10-30 14:05:52,605 Epoch: [258/484] Iter:[430/495], Time: 0.38, lr: [0.005021477124078173], Loss: 2.043706, Acc:0.799541, Semantic loss: 0.769075, BCE loss: 0.538397, SB loss: 0.736233
2023-10-30 14:05:56,288 Epoch: [258/484] Iter:[440/495], Time: 0.38, lr: [0.005021071583007706], Loss: 2.047717, Acc:0.799633, Semantic loss: 0.771898, BCE loss: 0.538690, SB loss: 0.737130
2023-10-30 14:05:59,881 Epoch: [258/484] Iter:[450/495], Time: 0.38, lr: [0.005020666038297796], Loss: 2.049767, Acc:0.798743, Semantic loss: 0.773370, BCE loss: 0.538658, SB loss: 0.737739
2023-10-30 14:06:03,509 Epoch: [258/484] Iter:[460/495], Time: 0.38, lr: [0.005020260489948087], Loss: 2.047311, Acc:0.798433, Semantic loss: 0.771241, BCE loss: 0.538355, SB loss: 0.737716
2023-10-30 14:06:07,304 Epoch: [258/484] Iter:[470/495], Time: 0.38, lr: [0.005019854937958218], Loss: 2.044311, Acc:0.798220, Semantic loss: 0.769252, BCE loss: 0.537904, SB loss: 0.737155
2023-10-30 14:06:11,086 Epoch: [258/484] Iter:[480/495], Time: 0.38, lr: [0.00501944938232783], Loss: 2.044276, Acc:0.798609, Semantic loss: 0.769225, BCE loss: 0.537521, SB loss: 0.737530
2023-10-30 14:06:14,857 Epoch: [258/484] Iter:[490/495], Time: 0.38, lr: [0.005019043823056564], Loss: 2.042323, Acc:0.798702, Semantic loss: 0.768041, BCE loss: 0.537206, SB loss: 0.737077
2023-10-30 14:06:16,256 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:06:16,491 Loss: 2.120, MeanIU:  0.6849, Best_mIoU:  0.7151
2023-10-30 14:06:16,491 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951]
2023-10-30 14:06:18,771 Epoch: [259/484] Iter:[0/495], Time: 2.25, lr: [0.005018841042055489], Loss: 2.449629, Acc:0.753864, Semantic loss: 0.989728, BCE loss: 0.603062, SB loss: 0.856839
2023-10-30 14:06:22,713 Epoch: [259/484] Iter:[10/495], Time: 0.56, lr: [0.005018435477322231], Loss: 2.236538, Acc:0.798580, Semantic loss: 0.832052, BCE loss: 0.618233, SB loss: 0.786254
2023-10-30 14:06:26,465 Epoch: [259/484] Iter:[20/495], Time: 0.47, lr: [0.005018029908947195], Loss: 2.080958, Acc:0.777509, Semantic loss: 0.773733, BCE loss: 0.557703, SB loss: 0.749521
2023-10-30 14:06:30,166 Epoch: [259/484] Iter:[30/495], Time: 0.44, lr: [0.005017624336930022], Loss: 2.040238, Acc:0.791333, Semantic loss: 0.750695, BCE loss: 0.548951, SB loss: 0.740592
2023-10-30 14:06:33,833 Epoch: [259/484] Iter:[40/495], Time: 0.42, lr: [0.005017218761270351], Loss: 2.014915, Acc:0.799764, Semantic loss: 0.736736, BCE loss: 0.543055, SB loss: 0.735124
2023-10-30 14:06:37,478 Epoch: [259/484] Iter:[50/495], Time: 0.41, lr: [0.005016813181967824], Loss: 2.024666, Acc:0.803052, Semantic loss: 0.745557, BCE loss: 0.541346, SB loss: 0.737762
2023-10-30 14:06:41,181 Epoch: [259/484] Iter:[60/495], Time: 0.40, lr: [0.005016407599022081], Loss: 2.017136, Acc:0.797053, Semantic loss: 0.747678, BCE loss: 0.529343, SB loss: 0.740114
2023-10-30 14:06:44,858 Epoch: [259/484] Iter:[70/495], Time: 0.40, lr: [0.00501600201243276], Loss: 2.036760, Acc:0.798218, Semantic loss: 0.754061, BCE loss: 0.540489, SB loss: 0.742209
2023-10-30 14:06:48,577 Epoch: [259/484] Iter:[80/495], Time: 0.40, lr: [0.005015596422199501], Loss: 2.042378, Acc:0.796658, Semantic loss: 0.759882, BCE loss: 0.541223, SB loss: 0.741274
2023-10-30 14:06:52,423 Epoch: [259/484] Iter:[90/495], Time: 0.39, lr: [0.005015190828321946], Loss: 2.050735, Acc:0.796713, Semantic loss: 0.764219, BCE loss: 0.541293, SB loss: 0.745222
2023-10-30 14:06:56,055 Epoch: [259/484] Iter:[100/495], Time: 0.39, lr: [0.005014785230799734], Loss: 2.044517, Acc:0.797067, Semantic loss: 0.759948, BCE loss: 0.539528, SB loss: 0.745041
2023-10-30 14:06:59,820 Epoch: [259/484] Iter:[110/495], Time: 0.39, lr: [0.005014379629632504], Loss: 2.036409, Acc:0.798993, Semantic loss: 0.755092, BCE loss: 0.539816, SB loss: 0.741501
2023-10-30 14:07:03,536 Epoch: [259/484] Iter:[120/495], Time: 0.39, lr: [0.005013974024819895], Loss: 2.038938, Acc:0.797330, Semantic loss: 0.757447, BCE loss: 0.539115, SB loss: 0.742375
2023-10-30 14:07:07,276 Epoch: [259/484] Iter:[130/495], Time: 0.39, lr: [0.005013568416361548], Loss: 2.036976, Acc:0.797974, Semantic loss: 0.761834, BCE loss: 0.533672, SB loss: 0.741470
2023-10-30 14:07:10,908 Epoch: [259/484] Iter:[140/495], Time: 0.39, lr: [0.0050131628042571034], Loss: 2.019454, Acc:0.797233, Semantic loss: 0.754691, BCE loss: 0.527478, SB loss: 0.737285
2023-10-30 14:07:14,690 Epoch: [259/484] Iter:[150/495], Time: 0.39, lr: [0.005012757188506197], Loss: 2.027542, Acc:0.798032, Semantic loss: 0.760093, BCE loss: 0.529195, SB loss: 0.738254
2023-10-30 14:07:18,365 Epoch: [259/484] Iter:[160/495], Time: 0.38, lr: [0.005012351569108471], Loss: 2.038556, Acc:0.798818, Semantic loss: 0.766147, BCE loss: 0.533415, SB loss: 0.738995
2023-10-30 14:07:22,145 Epoch: [259/484] Iter:[170/495], Time: 0.38, lr: [0.0050119459460635655], Loss: 2.037571, Acc:0.799546, Semantic loss: 0.762570, BCE loss: 0.538273, SB loss: 0.736728
2023-10-30 14:07:25,846 Epoch: [259/484] Iter:[180/495], Time: 0.38, lr: [0.005011540319371117], Loss: 2.049135, Acc:0.798238, Semantic loss: 0.771406, BCE loss: 0.541991, SB loss: 0.735739
2023-10-30 14:07:29,601 Epoch: [259/484] Iter:[190/495], Time: 0.38, lr: [0.005011134689030766], Loss: 2.043808, Acc:0.798366, Semantic loss: 0.767493, BCE loss: 0.541013, SB loss: 0.735302
2023-10-30 14:07:33,335 Epoch: [259/484] Iter:[200/495], Time: 0.38, lr: [0.005010729055042152], Loss: 2.055387, Acc:0.799127, Semantic loss: 0.774647, BCE loss: 0.540317, SB loss: 0.740423
2023-10-30 14:07:37,060 Epoch: [259/484] Iter:[210/495], Time: 0.38, lr: [0.005010323417404914], Loss: 2.054266, Acc:0.797634, Semantic loss: 0.774562, BCE loss: 0.539783, SB loss: 0.739921
2023-10-30 14:07:40,671 Epoch: [259/484] Iter:[220/495], Time: 0.38, lr: [0.00500991777611869], Loss: 2.056416, Acc:0.798511, Semantic loss: 0.775189, BCE loss: 0.539453, SB loss: 0.741773
2023-10-30 14:07:44,323 Epoch: [259/484] Iter:[230/495], Time: 0.38, lr: [0.005009512131183121], Loss: 2.058023, Acc:0.797106, Semantic loss: 0.778359, BCE loss: 0.538122, SB loss: 0.741543
2023-10-30 14:07:47,956 Epoch: [259/484] Iter:[240/495], Time: 0.38, lr: [0.005009106482597842], Loss: 2.059406, Acc:0.799112, Semantic loss: 0.778684, BCE loss: 0.539787, SB loss: 0.740935
2023-10-30 14:07:51,649 Epoch: [259/484] Iter:[250/495], Time: 0.38, lr: [0.0050087008303624945], Loss: 2.061384, Acc:0.796837, Semantic loss: 0.782665, BCE loss: 0.537435, SB loss: 0.741283
2023-10-30 14:07:55,294 Epoch: [259/484] Iter:[260/495], Time: 0.38, lr: [0.005008295174476718], Loss: 2.055908, Acc:0.795661, Semantic loss: 0.779686, BCE loss: 0.535881, SB loss: 0.740341
2023-10-30 14:07:59,012 Epoch: [259/484] Iter:[270/495], Time: 0.38, lr: [0.005007889514940149], Loss: 2.062074, Acc:0.795133, Semantic loss: 0.783054, BCE loss: 0.536713, SB loss: 0.742308
2023-10-30 14:08:02,745 Epoch: [259/484] Iter:[280/495], Time: 0.38, lr: [0.0050074838517524265], Loss: 2.058142, Acc:0.796118, Semantic loss: 0.781219, BCE loss: 0.535906, SB loss: 0.741017
2023-10-30 14:08:06,449 Epoch: [259/484] Iter:[290/495], Time: 0.38, lr: [0.0050070781849131905], Loss: 2.060796, Acc:0.797156, Semantic loss: 0.781707, BCE loss: 0.537574, SB loss: 0.741514
2023-10-30 14:08:10,191 Epoch: [259/484] Iter:[300/495], Time: 0.38, lr: [0.005006672514422078], Loss: 2.052652, Acc:0.796721, Semantic loss: 0.778348, BCE loss: 0.533734, SB loss: 0.740571
2023-10-30 14:08:13,987 Epoch: [259/484] Iter:[310/495], Time: 0.38, lr: [0.005006266840278728], Loss: 2.049762, Acc:0.796335, Semantic loss: 0.778447, BCE loss: 0.531735, SB loss: 0.739580
2023-10-30 14:08:17,859 Epoch: [259/484] Iter:[320/495], Time: 0.38, lr: [0.005005861162482778], Loss: 2.049279, Acc:0.796639, Semantic loss: 0.778606, BCE loss: 0.531380, SB loss: 0.739293
2023-10-30 14:08:21,580 Epoch: [259/484] Iter:[330/495], Time: 0.38, lr: [0.005005455481033866], Loss: 2.051848, Acc:0.797905, Semantic loss: 0.780756, BCE loss: 0.531916, SB loss: 0.739175
2023-10-30 14:08:25,294 Epoch: [259/484] Iter:[340/495], Time: 0.38, lr: [0.005005049795931632], Loss: 2.047953, Acc:0.797818, Semantic loss: 0.779457, BCE loss: 0.529925, SB loss: 0.738571
2023-10-30 14:08:29,113 Epoch: [259/484] Iter:[350/495], Time: 0.38, lr: [0.005004644107175712], Loss: 2.047106, Acc:0.797166, Semantic loss: 0.779731, BCE loss: 0.529138, SB loss: 0.738236
2023-10-30 14:08:32,791 Epoch: [259/484] Iter:[360/495], Time: 0.38, lr: [0.005004238414765745], Loss: 2.043883, Acc:0.797204, Semantic loss: 0.777081, BCE loss: 0.529182, SB loss: 0.737619
2023-10-30 14:08:36,431 Epoch: [259/484] Iter:[370/495], Time: 0.38, lr: [0.005003832718701369], Loss: 2.042831, Acc:0.796965, Semantic loss: 0.776051, BCE loss: 0.529097, SB loss: 0.737682
2023-10-30 14:08:40,149 Epoch: [259/484] Iter:[380/495], Time: 0.38, lr: [0.005003427018982222], Loss: 2.040892, Acc:0.796712, Semantic loss: 0.775087, BCE loss: 0.528308, SB loss: 0.737497
2023-10-30 14:08:43,945 Epoch: [259/484] Iter:[390/495], Time: 0.38, lr: [0.005003021315607941], Loss: 2.046673, Acc:0.797424, Semantic loss: 0.776902, BCE loss: 0.531448, SB loss: 0.738323
2023-10-30 14:08:47,581 Epoch: [259/484] Iter:[400/495], Time: 0.38, lr: [0.005002615608578164], Loss: 2.047622, Acc:0.795907, Semantic loss: 0.777398, BCE loss: 0.532136, SB loss: 0.738088
2023-10-30 14:08:51,366 Epoch: [259/484] Iter:[410/495], Time: 0.38, lr: [0.005002209897892529], Loss: 2.047074, Acc:0.795660, Semantic loss: 0.777625, BCE loss: 0.531397, SB loss: 0.738052
2023-10-30 14:08:55,180 Epoch: [259/484] Iter:[420/495], Time: 0.38, lr: [0.005001804183550673], Loss: 2.048474, Acc:0.795992, Semantic loss: 0.778185, BCE loss: 0.531287, SB loss: 0.739002
2023-10-30 14:08:58,834 Epoch: [259/484] Iter:[430/495], Time: 0.38, lr: [0.005001398465552236], Loss: 2.053073, Acc:0.796439, Semantic loss: 0.780020, BCE loss: 0.532388, SB loss: 0.740665
2023-10-30 14:09:02,577 Epoch: [259/484] Iter:[440/495], Time: 0.38, lr: [0.0050009927438968505], Loss: 2.052890, Acc:0.796579, Semantic loss: 0.779040, BCE loss: 0.533454, SB loss: 0.740396
2023-10-30 14:09:06,346 Epoch: [259/484] Iter:[450/495], Time: 0.38, lr: [0.005000587018584158], Loss: 2.052566, Acc:0.797048, Semantic loss: 0.778712, BCE loss: 0.533928, SB loss: 0.739926
2023-10-30 14:09:10,071 Epoch: [259/484] Iter:[460/495], Time: 0.38, lr: [0.005000181289613796], Loss: 2.051825, Acc:0.797392, Semantic loss: 0.778810, BCE loss: 0.533557, SB loss: 0.739459
2023-10-30 14:09:13,770 Epoch: [259/484] Iter:[470/495], Time: 0.38, lr: [0.004999775556985399], Loss: 2.052374, Acc:0.797082, Semantic loss: 0.778633, BCE loss: 0.533779, SB loss: 0.739962
2023-10-30 14:09:17,426 Epoch: [259/484] Iter:[480/495], Time: 0.38, lr: [0.004999369820698605], Loss: 2.051730, Acc:0.797404, Semantic loss: 0.777580, BCE loss: 0.534418, SB loss: 0.739732
2023-10-30 14:09:21,016 Epoch: [259/484] Iter:[490/495], Time: 0.38, lr: [0.0049989640807530525], Loss: 2.051817, Acc:0.797892, Semantic loss: 0.777065, BCE loss: 0.534598, SB loss: 0.740154
2023-10-30 14:09:22,416 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:09:22,650 Loss: 2.120, MeanIU:  0.6849, Best_mIoU:  0.7151
2023-10-30 14:09:22,650 [0.97301043 0.80593082 0.89884925 0.39533578 0.46885148 0.54243148
 0.57338524 0.70665463 0.90411027 0.51913494 0.92932715 0.73011887
 0.53800042 0.90056494 0.66016773 0.80778444 0.70631963 0.23990581
 0.71322951]
2023-10-30 14:09:24,539 Epoch: [260/484] Iter:[0/495], Time: 1.85, lr: [0.004998761209408129], Loss: 1.603817, Acc:0.770211, Semantic loss: 0.550994, BCE loss: 0.389759, SB loss: 0.663064
2023-10-30 14:09:28,505 Epoch: [260/484] Iter:[10/495], Time: 0.53, lr: [0.0049983554639737564], Loss: 2.122608, Acc:0.782823, Semantic loss: 0.779718, BCE loss: 0.588741, SB loss: 0.754149
2023-10-30 14:09:32,295 Epoch: [260/484] Iter:[20/495], Time: 0.46, lr: [0.004997949714879717], Loss: 2.012726, Acc:0.788922, Semantic loss: 0.736475, BCE loss: 0.547025, SB loss: 0.729227
2023-10-30 14:09:36,013 Epoch: [260/484] Iter:[30/495], Time: 0.43, lr: [0.004997543962125648], Loss: 2.042166, Acc:0.804627, Semantic loss: 0.747243, BCE loss: 0.555073, SB loss: 0.739850
2023-10-30 14:09:39,673 Epoch: [260/484] Iter:[40/495], Time: 0.41, lr: [0.004997138205711186], Loss: 2.056720, Acc:0.800154, Semantic loss: 0.755706, BCE loss: 0.555728, SB loss: 0.745286
2023-10-30 14:09:43,351 Epoch: [260/484] Iter:[50/495], Time: 0.41, lr: [0.004996732445635968], Loss: 2.038551, Acc:0.803049, Semantic loss: 0.752327, BCE loss: 0.547606, SB loss: 0.738619
2023-10-30 14:09:47,069 Epoch: [260/484] Iter:[60/495], Time: 0.40, lr: [0.0049963266818996285], Loss: 2.024410, Acc:0.801244, Semantic loss: 0.747168, BCE loss: 0.544889, SB loss: 0.732353
2023-10-30 14:09:50,803 Epoch: [260/484] Iter:[70/495], Time: 0.40, lr: [0.004995920914501807], Loss: 2.029655, Acc:0.796833, Semantic loss: 0.757133, BCE loss: 0.539089, SB loss: 0.733433
2023-10-30 14:09:54,510 Epoch: [260/484] Iter:[80/495], Time: 0.39, lr: [0.004995515143442139], Loss: 2.020173, Acc:0.795183, Semantic loss: 0.756593, BCE loss: 0.533625, SB loss: 0.729955
2023-10-30 14:09:58,193 Epoch: [260/484] Iter:[90/495], Time: 0.39, lr: [0.004995109368720261], Loss: 2.026323, Acc:0.796298, Semantic loss: 0.762155, BCE loss: 0.530265, SB loss: 0.733903
2023-10-30 14:10:01,966 Epoch: [260/484] Iter:[100/495], Time: 0.39, lr: [0.004994703590335808], Loss: 2.026046, Acc:0.797818, Semantic loss: 0.759393, BCE loss: 0.531685, SB loss: 0.734968
2023-10-30 14:10:05,717 Epoch: [260/484] Iter:[110/495], Time: 0.39, lr: [0.004994297808288418], Loss: 2.031512, Acc:0.797760, Semantic loss: 0.762120, BCE loss: 0.533186, SB loss: 0.736206
2023-10-30 14:10:09,430 Epoch: [260/484] Iter:[120/495], Time: 0.39, lr: [0.004993892022577728], Loss: 2.029373, Acc:0.797439, Semantic loss: 0.762351, BCE loss: 0.531232, SB loss: 0.735790
2023-10-30 14:10:13,160 Epoch: [260/484] Iter:[130/495], Time: 0.39, lr: [0.004993486233203372], Loss: 2.020318, Acc:0.801478, Semantic loss: 0.758685, BCE loss: 0.528345, SB loss: 0.733289
2023-10-30 14:10:16,790 Epoch: [260/484] Iter:[140/495], Time: 0.38, lr: [0.004993080440164986], Loss: 2.012715, Acc:0.802265, Semantic loss: 0.755414, BCE loss: 0.527208, SB loss: 0.730093
2023-10-30 14:10:20,544 Epoch: [260/484] Iter:[150/495], Time: 0.38, lr: [0.004992674643462208], Loss: 2.016751, Acc:0.800628, Semantic loss: 0.757876, BCE loss: 0.527748, SB loss: 0.731127
2023-10-30 14:10:24,217 Epoch: [260/484] Iter:[160/495], Time: 0.38, lr: [0.004992268843094673], Loss: 2.022862, Acc:0.799147, Semantic loss: 0.758703, BCE loss: 0.532548, SB loss: 0.731611
2023-10-30 14:10:27,880 Epoch: [260/484] Iter:[170/495], Time: 0.38, lr: [0.0049918630390620175], Loss: 2.018338, Acc:0.797962, Semantic loss: 0.756770, BCE loss: 0.530530, SB loss: 0.731037
2023-10-30 14:10:31,628 Epoch: [260/484] Iter:[180/495], Time: 0.38, lr: [0.0049914572313638755], Loss: 2.020623, Acc:0.798525, Semantic loss: 0.757507, BCE loss: 0.531977, SB loss: 0.731138
2023-10-30 14:10:35,326 Epoch: [260/484] Iter:[190/495], Time: 0.38, lr: [0.004991051419999885], Loss: 2.018370, Acc:0.797808, Semantic loss: 0.755761, BCE loss: 0.532706, SB loss: 0.729902
2023-10-30 14:10:39,054 Epoch: [260/484] Iter:[200/495], Time: 0.38, lr: [0.00499064560496968], Loss: 2.011445, Acc:0.797863, Semantic loss: 0.752767, BCE loss: 0.530027, SB loss: 0.728651
2023-10-30 14:10:42,827 Epoch: [260/484] Iter:[210/495], Time: 0.38, lr: [0.004990239786272899], Loss: 2.005381, Acc:0.797172, Semantic loss: 0.750252, BCE loss: 0.528197, SB loss: 0.726931
2023-10-30 14:10:46,541 Epoch: [260/484] Iter:[220/495], Time: 0.38, lr: [0.004989833963909173], Loss: 2.004015, Acc:0.797095, Semantic loss: 0.750600, BCE loss: 0.525868, SB loss: 0.727548
2023-10-30 14:10:50,271 Epoch: [260/484] Iter:[230/495], Time: 0.38, lr: [0.004989428137878142], Loss: 2.005455, Acc:0.798484, Semantic loss: 0.752408, BCE loss: 0.524276, SB loss: 0.728771
2023-10-30 14:10:53,963 Epoch: [260/484] Iter:[240/495], Time: 0.38, lr: [0.004989022308179438], Loss: 2.008590, Acc:0.799054, Semantic loss: 0.751870, BCE loss: 0.527415, SB loss: 0.729306
2023-10-30 14:10:57,778 Epoch: [260/484] Iter:[250/495], Time: 0.38, lr: [0.004988616474812698], Loss: 2.011195, Acc:0.799363, Semantic loss: 0.754822, BCE loss: 0.527127, SB loss: 0.729246
2023-10-30 14:11:01,486 Epoch: [260/484] Iter:[260/495], Time: 0.38, lr: [0.004988210637777556], Loss: 2.012206, Acc:0.801125, Semantic loss: 0.754770, BCE loss: 0.528806, SB loss: 0.728630
2023-10-30 14:11:05,259 Epoch: [260/484] Iter:[270/495], Time: 0.38, lr: [0.00498780479707365], Loss: 2.009065, Acc:0.799919, Semantic loss: 0.754522, BCE loss: 0.526527, SB loss: 0.728016
2023-10-30 14:11:08,998 Epoch: [260/484] Iter:[280/495], Time: 0.38, lr: [0.004987398952700613], Loss: 2.018880, Acc:0.800654, Semantic loss: 0.760627, BCE loss: 0.527416, SB loss: 0.730836
2023-10-30 14:11:12,756 Epoch: [260/484] Iter:[290/495], Time: 0.38, lr: [0.00498699310465808], Loss: 2.015497, Acc:0.801061, Semantic loss: 0.758573, BCE loss: 0.526804, SB loss: 0.730119
2023-10-30 14:11:16,510 Epoch: [260/484] Iter:[300/495], Time: 0.38, lr: [0.004986587252945686], Loss: 2.016409, Acc:0.801175, Semantic loss: 0.758488, BCE loss: 0.527211, SB loss: 0.730710
2023-10-30 14:11:20,193 Epoch: [260/484] Iter:[310/495], Time: 0.38, lr: [0.004986181397563067], Loss: 2.018146, Acc:0.802058, Semantic loss: 0.759306, BCE loss: 0.527730, SB loss: 0.731110
2023-10-30 14:11:23,972 Epoch: [260/484] Iter:[320/495], Time: 0.38, lr: [0.004985775538509858], Loss: 2.016667, Acc:0.800544, Semantic loss: 0.758316, BCE loss: 0.527855, SB loss: 0.730496
2023-10-30 14:11:27,869 Epoch: [260/484] Iter:[330/495], Time: 0.38, lr: [0.004985369675785693], Loss: 2.015683, Acc:0.800832, Semantic loss: 0.757558, BCE loss: 0.527658, SB loss: 0.730467
2023-10-30 14:11:31,704 Epoch: [260/484] Iter:[340/495], Time: 0.38, lr: [0.004984963809390204], Loss: 2.015084, Acc:0.800807, Semantic loss: 0.755655, BCE loss: 0.529279, SB loss: 0.730151
2023-10-30 14:11:35,346 Epoch: [260/484] Iter:[350/495], Time: 0.38, lr: [0.004984557939323031], Loss: 2.017197, Acc:0.801445, Semantic loss: 0.756526, BCE loss: 0.530078, SB loss: 0.730593
2023-10-30 14:11:39,029 Epoch: [260/484] Iter:[360/495], Time: 0.38, lr: [0.004984152065583806], Loss: 2.015808, Acc:0.801862, Semantic loss: 0.755637, BCE loss: 0.530220, SB loss: 0.729951
2023-10-30 14:11:42,750 Epoch: [260/484] Iter:[370/495], Time: 0.38, lr: [0.004983746188172163], Loss: 2.022676, Acc:0.801612, Semantic loss: 0.760403, BCE loss: 0.531468, SB loss: 0.730805
2023-10-30 14:11:46,604 Epoch: [260/484] Iter:[380/495], Time: 0.38, lr: [0.004983340307087737], Loss: 2.019754, Acc:0.800759, Semantic loss: 0.758836, BCE loss: 0.530784, SB loss: 0.730134
2023-10-30 14:11:50,350 Epoch: [260/484] Iter:[390/495], Time: 0.38, lr: [0.004982934422330163], Loss: 2.017661, Acc:0.801524, Semantic loss: 0.756613, BCE loss: 0.531239, SB loss: 0.729809
2023-10-30 14:11:54,122 Epoch: [260/484] Iter:[400/495], Time: 0.38, lr: [0.004982528533899074], Loss: 2.019686, Acc:0.800992, Semantic loss: 0.757739, BCE loss: 0.531619, SB loss: 0.730328
2023-10-30 14:11:57,872 Epoch: [260/484] Iter:[410/495], Time: 0.38, lr: [0.004982122641794104], Loss: 2.019210, Acc:0.801315, Semantic loss: 0.756145, BCE loss: 0.533223, SB loss: 0.729842
2023-10-30 14:12:01,499 Epoch: [260/484] Iter:[420/495], Time: 0.38, lr: [0.00498171674601489], Loss: 2.021639, Acc:0.800878, Semantic loss: 0.757600, BCE loss: 0.533711, SB loss: 0.730328
2023-10-30 14:12:05,181 Epoch: [260/484] Iter:[430/495], Time: 0.38, lr: [0.0049813108465610635], Loss: 2.026997, Acc:0.800235, Semantic loss: 0.761516, BCE loss: 0.534296, SB loss: 0.731185
2023-10-30 14:12:09,055 Epoch: [260/484] Iter:[440/495], Time: 0.38, lr: [0.00498090494343226], Loss: 2.030499, Acc:0.800632, Semantic loss: 0.762497, BCE loss: 0.536860, SB loss: 0.731143
2023-10-30 14:12:12,768 Epoch: [260/484] Iter:[450/495], Time: 0.38, lr: [0.0049804990366281105], Loss: 2.033118, Acc:0.800616, Semantic loss: 0.764755, BCE loss: 0.535546, SB loss: 0.732816
2023-10-30 14:12:16,566 Epoch: [260/484] Iter:[460/495], Time: 0.38, lr: [0.004980093126148253], Loss: 2.029821, Acc:0.800506, Semantic loss: 0.762334, BCE loss: 0.535438, SB loss: 0.732048
2023-10-30 14:12:20,205 Epoch: [260/484] Iter:[470/495], Time: 0.38, lr: [0.0049796872119923195], Loss: 2.030960, Acc:0.799821, Semantic loss: 0.762406, BCE loss: 0.536492, SB loss: 0.732061
2023-10-30 14:12:23,891 Epoch: [260/484] Iter:[480/495], Time: 0.38, lr: [0.004979281294159943], Loss: 2.032838, Acc:0.800067, Semantic loss: 0.764349, BCE loss: 0.535571, SB loss: 0.732918
2023-10-30 14:12:27,431 Epoch: [260/484] Iter:[490/495], Time: 0.38, lr: [0.004978875372650757], Loss: 2.030755, Acc:0.799581, Semantic loss: 0.762586, BCE loss: 0.535313, SB loss: 0.732856
2023-10-30 14:15:24,874 0 [0.93290159 0.62695533 0.82176995 0.11578061 0.27858679 0.41863769
 0.44990715 0.57593994 0.88569055 0.45803062 0.87636399 0.60319633
 0.0191498  0.8082347  0.00172521 0.1013729  0.02339912 0.0428927
 0.61308385] 0.455453622015806
2023-10-30 14:15:24,875 1 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295] 0.6883240853866665
2023-10-30 14:15:24,879 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:15:25,117 Loss: 1.995, MeanIU:  0.6883, Best_mIoU:  0.7151
2023-10-30 14:15:25,117 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295]
2023-10-30 14:15:27,283 Epoch: [261/484] Iter:[0/495], Time: 2.13, lr: [0.004978672410517248], Loss: 1.905610, Acc:0.778362, Semantic loss: 0.656212, BCE loss: 0.552887, SB loss: 0.696511
2023-10-30 14:15:31,056 Epoch: [261/484] Iter:[10/495], Time: 0.54, lr: [0.004978266483492163], Loss: 2.136826, Acc:0.793496, Semantic loss: 0.876662, BCE loss: 0.503648, SB loss: 0.756517
2023-10-30 14:15:34,615 Epoch: [261/484] Iter:[20/495], Time: 0.45, lr: [0.004977860552789354], Loss: 2.080697, Acc:0.773133, Semantic loss: 0.817122, BCE loss: 0.514102, SB loss: 0.749474
2023-10-30 14:15:38,141 Epoch: [261/484] Iter:[30/495], Time: 0.42, lr: [0.004977454618408453], Loss: 2.067324, Acc:0.774480, Semantic loss: 0.797508, BCE loss: 0.526934, SB loss: 0.742882
2023-10-30 14:15:41,630 Epoch: [261/484] Iter:[40/495], Time: 0.40, lr: [0.0049770486803490934], Loss: 2.094682, Acc:0.777152, Semantic loss: 0.804390, BCE loss: 0.539576, SB loss: 0.750716
2023-10-30 14:15:45,178 Epoch: [261/484] Iter:[50/495], Time: 0.39, lr: [0.004976642738610911], Loss: 2.109945, Acc:0.777157, Semantic loss: 0.815723, BCE loss: 0.536262, SB loss: 0.757960
2023-10-30 14:15:48,648 Epoch: [261/484] Iter:[60/495], Time: 0.39, lr: [0.004976236793193536], Loss: 2.099861, Acc:0.781441, Semantic loss: 0.810895, BCE loss: 0.533458, SB loss: 0.755508
2023-10-30 14:15:52,192 Epoch: [261/484] Iter:[70/495], Time: 0.38, lr: [0.004975830844096604], Loss: 2.089476, Acc:0.778656, Semantic loss: 0.804217, BCE loss: 0.531864, SB loss: 0.753395
2023-10-30 14:15:55,704 Epoch: [261/484] Iter:[80/495], Time: 0.38, lr: [0.004975424891319745], Loss: 2.087518, Acc:0.783086, Semantic loss: 0.798003, BCE loss: 0.537627, SB loss: 0.751887
2023-10-30 14:15:59,368 Epoch: [261/484] Iter:[90/495], Time: 0.38, lr: [0.004975018934862595], Loss: 2.081896, Acc:0.786228, Semantic loss: 0.796275, BCE loss: 0.537798, SB loss: 0.747823
2023-10-30 14:16:03,021 Epoch: [261/484] Iter:[100/495], Time: 0.37, lr: [0.004974612974724787], Loss: 2.085931, Acc:0.792377, Semantic loss: 0.794940, BCE loss: 0.543193, SB loss: 0.747799
2023-10-30 14:16:06,550 Epoch: [261/484] Iter:[110/495], Time: 0.37, lr: [0.004974207010905951], Loss: 2.071045, Acc:0.788686, Semantic loss: 0.785175, BCE loss: 0.540812, SB loss: 0.745058
2023-10-30 14:16:10,417 Epoch: [261/484] Iter:[120/495], Time: 0.37, lr: [0.004973801043405722], Loss: 2.081129, Acc:0.790024, Semantic loss: 0.787987, BCE loss: 0.546365, SB loss: 0.746777
2023-10-30 14:16:14,048 Epoch: [261/484] Iter:[130/495], Time: 0.37, lr: [0.0049733950722237324], Loss: 2.081687, Acc:0.792046, Semantic loss: 0.787109, BCE loss: 0.547701, SB loss: 0.746876
2023-10-30 14:16:17,621 Epoch: [261/484] Iter:[140/495], Time: 0.37, lr: [0.004972989097359615], Loss: 2.071723, Acc:0.791817, Semantic loss: 0.783591, BCE loss: 0.543609, SB loss: 0.744523
2023-10-30 14:16:21,345 Epoch: [261/484] Iter:[150/495], Time: 0.37, lr: [0.004972583118813002], Loss: 2.080035, Acc:0.791035, Semantic loss: 0.791614, BCE loss: 0.543284, SB loss: 0.745136
2023-10-30 14:16:25,021 Epoch: [261/484] Iter:[160/495], Time: 0.37, lr: [0.004972177136583526], Loss: 2.071493, Acc:0.791418, Semantic loss: 0.786698, BCE loss: 0.541619, SB loss: 0.743176
2023-10-30 14:16:28,745 Epoch: [261/484] Iter:[170/495], Time: 0.37, lr: [0.004971771150670819], Loss: 2.078189, Acc:0.793056, Semantic loss: 0.788621, BCE loss: 0.546381, SB loss: 0.743187
2023-10-30 14:16:32,352 Epoch: [261/484] Iter:[180/495], Time: 0.37, lr: [0.004971365161074516], Loss: 2.095284, Acc:0.794129, Semantic loss: 0.794585, BCE loss: 0.551254, SB loss: 0.749444
2023-10-30 14:16:36,110 Epoch: [261/484] Iter:[190/495], Time: 0.37, lr: [0.004970959167794246], Loss: 2.093325, Acc:0.794274, Semantic loss: 0.792847, BCE loss: 0.550860, SB loss: 0.749618
2023-10-30 14:16:39,639 Epoch: [261/484] Iter:[200/495], Time: 0.37, lr: [0.004970553170829642], Loss: 2.087716, Acc:0.795670, Semantic loss: 0.788669, BCE loss: 0.551131, SB loss: 0.747916
2023-10-30 14:16:43,337 Epoch: [261/484] Iter:[210/495], Time: 0.37, lr: [0.004970147170180338], Loss: 2.084974, Acc:0.796724, Semantic loss: 0.786189, BCE loss: 0.552003, SB loss: 0.746782
2023-10-30 14:16:46,869 Epoch: [261/484] Iter:[220/495], Time: 0.37, lr: [0.004969741165845964], Loss: 2.081843, Acc:0.798643, Semantic loss: 0.784739, BCE loss: 0.549665, SB loss: 0.747439
2023-10-30 14:16:50,467 Epoch: [261/484] Iter:[230/495], Time: 0.37, lr: [0.004969335157826153], Loss: 2.077747, Acc:0.798786, Semantic loss: 0.783348, BCE loss: 0.548226, SB loss: 0.746173
2023-10-30 14:16:54,229 Epoch: [261/484] Iter:[240/495], Time: 0.37, lr: [0.004968929146120537], Loss: 2.078422, Acc:0.799651, Semantic loss: 0.784377, BCE loss: 0.548383, SB loss: 0.745662
2023-10-30 14:16:58,000 Epoch: [261/484] Iter:[250/495], Time: 0.37, lr: [0.004968523130728748], Loss: 2.075070, Acc:0.799603, Semantic loss: 0.783749, BCE loss: 0.547054, SB loss: 0.744267
2023-10-30 14:17:01,669 Epoch: [261/484] Iter:[260/495], Time: 0.37, lr: [0.004968117111650418], Loss: 2.079420, Acc:0.799511, Semantic loss: 0.785570, BCE loss: 0.546920, SB loss: 0.746930
2023-10-30 14:17:05,403 Epoch: [261/484] Iter:[270/495], Time: 0.37, lr: [0.004967711088885177], Loss: 2.074535, Acc:0.800317, Semantic loss: 0.782470, BCE loss: 0.545983, SB loss: 0.746082
2023-10-30 14:17:09,023 Epoch: [261/484] Iter:[280/495], Time: 0.37, lr: [0.00496730506243266], Loss: 2.076256, Acc:0.799338, Semantic loss: 0.784158, BCE loss: 0.545367, SB loss: 0.746731
2023-10-30 14:17:12,688 Epoch: [261/484] Iter:[290/495], Time: 0.37, lr: [0.004966899032292495], Loss: 2.078988, Acc:0.797938, Semantic loss: 0.786954, BCE loss: 0.545010, SB loss: 0.747024
2023-10-30 14:17:16,354 Epoch: [261/484] Iter:[300/495], Time: 0.37, lr: [0.004966492998464316], Loss: 2.083213, Acc:0.798365, Semantic loss: 0.789015, BCE loss: 0.546034, SB loss: 0.748164
2023-10-30 14:17:20,043 Epoch: [261/484] Iter:[310/495], Time: 0.37, lr: [0.0049660869609477526], Loss: 2.076589, Acc:0.798113, Semantic loss: 0.785353, BCE loss: 0.545179, SB loss: 0.746056
2023-10-30 14:17:23,730 Epoch: [261/484] Iter:[320/495], Time: 0.37, lr: [0.004965680919742439], Loss: 2.078350, Acc:0.796576, Semantic loss: 0.786698, BCE loss: 0.544668, SB loss: 0.746985
2023-10-30 14:17:27,354 Epoch: [261/484] Iter:[330/495], Time: 0.37, lr: [0.004965274874848004], Loss: 2.077732, Acc:0.796664, Semantic loss: 0.786868, BCE loss: 0.544909, SB loss: 0.745955
2023-10-30 14:17:31,082 Epoch: [261/484] Iter:[340/495], Time: 0.37, lr: [0.0049648688262640805], Loss: 2.078660, Acc:0.797223, Semantic loss: 0.786235, BCE loss: 0.547280, SB loss: 0.745145
2023-10-30 14:17:34,724 Epoch: [261/484] Iter:[350/495], Time: 0.37, lr: [0.004964462773990297], Loss: 2.074718, Acc:0.797822, Semantic loss: 0.783109, BCE loss: 0.546421, SB loss: 0.745189
2023-10-30 14:17:38,393 Epoch: [261/484] Iter:[360/495], Time: 0.37, lr: [0.004964056718026288], Loss: 2.075554, Acc:0.798281, Semantic loss: 0.783466, BCE loss: 0.546539, SB loss: 0.745550
2023-10-30 14:17:42,094 Epoch: [261/484] Iter:[370/495], Time: 0.37, lr: [0.0049636506583716836], Loss: 2.074725, Acc:0.797797, Semantic loss: 0.782911, BCE loss: 0.545749, SB loss: 0.746066
2023-10-30 14:17:45,762 Epoch: [261/484] Iter:[380/495], Time: 0.37, lr: [0.004963244595026115], Loss: 2.074168, Acc:0.797996, Semantic loss: 0.782629, BCE loss: 0.546682, SB loss: 0.744858
2023-10-30 14:17:49,513 Epoch: [261/484] Iter:[390/495], Time: 0.37, lr: [0.00496283852798921], Loss: 2.074657, Acc:0.798567, Semantic loss: 0.782851, BCE loss: 0.546722, SB loss: 0.745085
2023-10-30 14:17:53,260 Epoch: [261/484] Iter:[400/495], Time: 0.37, lr: [0.004962432457260604], Loss: 2.071108, Acc:0.799636, Semantic loss: 0.780384, BCE loss: 0.547110, SB loss: 0.743614
2023-10-30 14:17:56,882 Epoch: [261/484] Iter:[410/495], Time: 0.37, lr: [0.004962026382839924], Loss: 2.068250, Acc:0.799502, Semantic loss: 0.779472, BCE loss: 0.545257, SB loss: 0.743521
2023-10-30 14:18:00,551 Epoch: [261/484] Iter:[420/495], Time: 0.37, lr: [0.004961620304726804], Loss: 2.064828, Acc:0.799517, Semantic loss: 0.778504, BCE loss: 0.543310, SB loss: 0.743014
2023-10-30 14:18:04,274 Epoch: [261/484] Iter:[430/495], Time: 0.37, lr: [0.004961214222920871], Loss: 2.062003, Acc:0.799523, Semantic loss: 0.778479, BCE loss: 0.541170, SB loss: 0.742354
2023-10-30 14:18:08,194 Epoch: [261/484] Iter:[440/495], Time: 0.37, lr: [0.0049608081374217594], Loss: 2.058940, Acc:0.798622, Semantic loss: 0.777739, BCE loss: 0.539426, SB loss: 0.741775
2023-10-30 14:18:11,922 Epoch: [261/484] Iter:[450/495], Time: 0.37, lr: [0.004960402048229097], Loss: 2.058998, Acc:0.799270, Semantic loss: 0.777370, BCE loss: 0.540353, SB loss: 0.741275
2023-10-30 14:18:15,604 Epoch: [261/484] Iter:[460/495], Time: 0.37, lr: [0.004959995955342516], Loss: 2.063017, Acc:0.798785, Semantic loss: 0.780115, BCE loss: 0.541157, SB loss: 0.741745
2023-10-30 14:18:19,408 Epoch: [261/484] Iter:[470/495], Time: 0.37, lr: [0.004959589858761645], Loss: 2.061375, Acc:0.798649, Semantic loss: 0.779433, BCE loss: 0.540103, SB loss: 0.741839
2023-10-30 14:18:23,075 Epoch: [261/484] Iter:[480/495], Time: 0.37, lr: [0.004959183758486115], Loss: 2.059039, Acc:0.798946, Semantic loss: 0.777845, BCE loss: 0.539785, SB loss: 0.741410
2023-10-30 14:18:26,573 Epoch: [261/484] Iter:[490/495], Time: 0.37, lr: [0.004958777654515557], Loss: 2.057119, Acc:0.799143, Semantic loss: 0.776709, BCE loss: 0.539809, SB loss: 0.740602
2023-10-30 14:18:27,972 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:18:28,209 Loss: 1.995, MeanIU:  0.6883, Best_mIoU:  0.7151
2023-10-30 14:18:28,209 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295]
2023-10-30 14:18:30,389 Epoch: [262/484] Iter:[0/495], Time: 2.15, lr: [0.004958574601144527], Loss: 1.856021, Acc:0.761801, Semantic loss: 0.699275, BCE loss: 0.429758, SB loss: 0.726988
2023-10-30 14:18:34,426 Epoch: [262/484] Iter:[10/495], Time: 0.56, lr: [0.004958168491630732], Loss: 1.933607, Acc:0.805849, Semantic loss: 0.692757, BCE loss: 0.522035, SB loss: 0.718815
2023-10-30 14:18:38,136 Epoch: [262/484] Iter:[20/495], Time: 0.47, lr: [0.004957762378420983], Loss: 2.058448, Acc:0.791793, Semantic loss: 0.763634, BCE loss: 0.552606, SB loss: 0.742207
2023-10-30 14:18:41,839 Epoch: [262/484] Iter:[30/495], Time: 0.44, lr: [0.004957356261514912], Loss: 2.064997, Acc:0.801311, Semantic loss: 0.768607, BCE loss: 0.562752, SB loss: 0.733638
2023-10-30 14:18:45,429 Epoch: [262/484] Iter:[40/495], Time: 0.42, lr: [0.004956950140912147], Loss: 2.049434, Acc:0.801996, Semantic loss: 0.759959, BCE loss: 0.548980, SB loss: 0.740495
2023-10-30 14:18:49,088 Epoch: [262/484] Iter:[50/495], Time: 0.41, lr: [0.004956544016612317], Loss: 2.030140, Acc:0.798626, Semantic loss: 0.748860, BCE loss: 0.541124, SB loss: 0.740156
2023-10-30 14:18:52,719 Epoch: [262/484] Iter:[60/495], Time: 0.40, lr: [0.004956137888615054], Loss: 2.052854, Acc:0.798578, Semantic loss: 0.765550, BCE loss: 0.536541, SB loss: 0.750763
2023-10-30 14:18:56,345 Epoch: [262/484] Iter:[70/495], Time: 0.40, lr: [0.004955731756919987], Loss: 2.039252, Acc:0.801326, Semantic loss: 0.759012, BCE loss: 0.529270, SB loss: 0.750969
2023-10-30 14:19:00,084 Epoch: [262/484] Iter:[80/495], Time: 0.39, lr: [0.004955325621526746], Loss: 2.039866, Acc:0.799199, Semantic loss: 0.759643, BCE loss: 0.533270, SB loss: 0.746953
2023-10-30 14:19:03,776 Epoch: [262/484] Iter:[90/495], Time: 0.39, lr: [0.004954919482434958], Loss: 2.058738, Acc:0.796068, Semantic loss: 0.772166, BCE loss: 0.537236, SB loss: 0.749336
2023-10-30 14:19:07,516 Epoch: [262/484] Iter:[100/495], Time: 0.39, lr: [0.004954513339644255], Loss: 2.048046, Acc:0.797533, Semantic loss: 0.765709, BCE loss: 0.539242, SB loss: 0.743096
2023-10-30 14:19:11,172 Epoch: [262/484] Iter:[110/495], Time: 0.39, lr: [0.004954107193154266], Loss: 2.044348, Acc:0.799192, Semantic loss: 0.762723, BCE loss: 0.538967, SB loss: 0.742658
2023-10-30 14:19:14,897 Epoch: [262/484] Iter:[120/495], Time: 0.39, lr: [0.004953701042964621], Loss: 2.031740, Acc:0.797881, Semantic loss: 0.758786, BCE loss: 0.534480, SB loss: 0.738474
2023-10-30 14:19:18,594 Epoch: [262/484] Iter:[130/495], Time: 0.38, lr: [0.004953294889074946], Loss: 2.032034, Acc:0.796374, Semantic loss: 0.758635, BCE loss: 0.534270, SB loss: 0.739128
2023-10-30 14:19:22,332 Epoch: [262/484] Iter:[140/495], Time: 0.38, lr: [0.004952888731484874], Loss: 2.017704, Acc:0.796234, Semantic loss: 0.752300, BCE loss: 0.530023, SB loss: 0.735382
2023-10-30 14:19:26,012 Epoch: [262/484] Iter:[150/495], Time: 0.38, lr: [0.004952482570194033], Loss: 2.023285, Acc:0.796624, Semantic loss: 0.754474, BCE loss: 0.532239, SB loss: 0.736571
2023-10-30 14:19:29,714 Epoch: [262/484] Iter:[160/495], Time: 0.38, lr: [0.004952076405202051], Loss: 2.026799, Acc:0.794904, Semantic loss: 0.756917, BCE loss: 0.532669, SB loss: 0.737212
2023-10-30 14:19:33,467 Epoch: [262/484] Iter:[170/495], Time: 0.38, lr: [0.004951670236508557], Loss: 2.020702, Acc:0.794174, Semantic loss: 0.754766, BCE loss: 0.531475, SB loss: 0.734462
2023-10-30 14:19:37,103 Epoch: [262/484] Iter:[180/495], Time: 0.38, lr: [0.004951264064113181], Loss: 2.017401, Acc:0.793438, Semantic loss: 0.755519, BCE loss: 0.528513, SB loss: 0.733369
2023-10-30 14:19:40,876 Epoch: [262/484] Iter:[190/495], Time: 0.38, lr: [0.004950857888015552], Loss: 2.023928, Acc:0.791403, Semantic loss: 0.760226, BCE loss: 0.527620, SB loss: 0.736081
2023-10-30 14:19:44,611 Epoch: [262/484] Iter:[200/495], Time: 0.38, lr: [0.004950451708215299], Loss: 2.017807, Acc:0.791743, Semantic loss: 0.757494, BCE loss: 0.526695, SB loss: 0.733619
2023-10-30 14:19:48,396 Epoch: [262/484] Iter:[210/495], Time: 0.38, lr: [0.0049500455247120465], Loss: 2.024516, Acc:0.791726, Semantic loss: 0.760144, BCE loss: 0.528938, SB loss: 0.735434
2023-10-30 14:19:52,057 Epoch: [262/484] Iter:[220/495], Time: 0.38, lr: [0.004949639337505429], Loss: 2.028431, Acc:0.791924, Semantic loss: 0.764838, BCE loss: 0.526925, SB loss: 0.736668
2023-10-30 14:19:56,002 Epoch: [262/484] Iter:[230/495], Time: 0.38, lr: [0.004949233146595072], Loss: 2.029259, Acc:0.792687, Semantic loss: 0.766862, BCE loss: 0.526200, SB loss: 0.736196
2023-10-30 14:19:59,742 Epoch: [262/484] Iter:[240/495], Time: 0.38, lr: [0.0049488269519806045], Loss: 2.023414, Acc:0.792288, Semantic loss: 0.764199, BCE loss: 0.524448, SB loss: 0.734767
2023-10-30 14:20:03,379 Epoch: [262/484] Iter:[250/495], Time: 0.38, lr: [0.004948420753661654], Loss: 2.032504, Acc:0.792462, Semantic loss: 0.768247, BCE loss: 0.528337, SB loss: 0.735920
2023-10-30 14:20:06,981 Epoch: [262/484] Iter:[260/495], Time: 0.38, lr: [0.0049480145516378506], Loss: 2.029995, Acc:0.791386, Semantic loss: 0.767057, BCE loss: 0.526663, SB loss: 0.736275
2023-10-30 14:20:10,743 Epoch: [262/484] Iter:[270/495], Time: 0.38, lr: [0.004947608345908822], Loss: 2.024079, Acc:0.790922, Semantic loss: 0.764128, BCE loss: 0.524846, SB loss: 0.735106
2023-10-30 14:20:14,339 Epoch: [262/484] Iter:[280/495], Time: 0.38, lr: [0.004947202136474195], Loss: 2.027163, Acc:0.790370, Semantic loss: 0.767033, BCE loss: 0.524123, SB loss: 0.736007
2023-10-30 14:20:18,063 Epoch: [262/484] Iter:[290/495], Time: 0.38, lr: [0.004946795923333598], Loss: 2.024710, Acc:0.789866, Semantic loss: 0.766360, BCE loss: 0.522684, SB loss: 0.735666
2023-10-30 14:20:22,006 Epoch: [262/484] Iter:[300/495], Time: 0.38, lr: [0.004946389706486662], Loss: 2.024642, Acc:0.788525, Semantic loss: 0.765436, BCE loss: 0.524303, SB loss: 0.734904
2023-10-30 14:20:25,713 Epoch: [262/484] Iter:[310/495], Time: 0.38, lr: [0.004945983485933012], Loss: 2.027920, Acc:0.788939, Semantic loss: 0.767535, BCE loss: 0.524273, SB loss: 0.736113
2023-10-30 14:20:29,474 Epoch: [262/484] Iter:[320/495], Time: 0.38, lr: [0.004945577261672276], Loss: 2.029422, Acc:0.789959, Semantic loss: 0.766972, BCE loss: 0.526202, SB loss: 0.736249
2023-10-30 14:20:33,309 Epoch: [262/484] Iter:[330/495], Time: 0.38, lr: [0.004945171033704083], Loss: 2.027069, Acc:0.791045, Semantic loss: 0.764828, BCE loss: 0.526721, SB loss: 0.735520
2023-10-30 14:20:36,916 Epoch: [262/484] Iter:[340/495], Time: 0.38, lr: [0.00494476480202806], Loss: 2.027631, Acc:0.791667, Semantic loss: 0.764463, BCE loss: 0.527507, SB loss: 0.735662
2023-10-30 14:20:40,551 Epoch: [262/484] Iter:[350/495], Time: 0.38, lr: [0.004944358566643836], Loss: 2.023343, Acc:0.791256, Semantic loss: 0.762989, BCE loss: 0.526479, SB loss: 0.733875
2023-10-30 14:20:44,204 Epoch: [262/484] Iter:[360/495], Time: 0.38, lr: [0.004943952327551037], Loss: 2.025012, Acc:0.792214, Semantic loss: 0.764028, BCE loss: 0.527380, SB loss: 0.733604
2023-10-30 14:20:47,916 Epoch: [262/484] Iter:[370/495], Time: 0.38, lr: [0.004943546084749291], Loss: 2.024364, Acc:0.793528, Semantic loss: 0.763393, BCE loss: 0.527337, SB loss: 0.733634
2023-10-30 14:20:51,606 Epoch: [262/484] Iter:[380/495], Time: 0.38, lr: [0.004943139838238225], Loss: 2.024564, Acc:0.793577, Semantic loss: 0.763324, BCE loss: 0.527469, SB loss: 0.733771
2023-10-30 14:20:55,304 Epoch: [262/484] Iter:[390/495], Time: 0.38, lr: [0.004942733588017468], Loss: 2.024300, Acc:0.793838, Semantic loss: 0.762747, BCE loss: 0.527732, SB loss: 0.733822
2023-10-30 14:20:58,911 Epoch: [262/484] Iter:[400/495], Time: 0.38, lr: [0.004942327334086647], Loss: 2.025402, Acc:0.793308, Semantic loss: 0.764255, BCE loss: 0.527138, SB loss: 0.734009
2023-10-30 14:21:02,577 Epoch: [262/484] Iter:[410/495], Time: 0.38, lr: [0.004941921076445387], Loss: 2.019376, Acc:0.793406, Semantic loss: 0.762328, BCE loss: 0.524176, SB loss: 0.732872
2023-10-30 14:21:06,311 Epoch: [262/484] Iter:[420/495], Time: 0.38, lr: [0.004941514815093318], Loss: 2.019419, Acc:0.792643, Semantic loss: 0.762267, BCE loss: 0.524118, SB loss: 0.733033
2023-10-30 14:21:10,022 Epoch: [262/484] Iter:[430/495], Time: 0.38, lr: [0.004941108550030065], Loss: 2.017481, Acc:0.792986, Semantic loss: 0.761122, BCE loss: 0.524077, SB loss: 0.732282
2023-10-30 14:21:13,719 Epoch: [262/484] Iter:[440/495], Time: 0.38, lr: [0.004940702281255257], Loss: 2.022457, Acc:0.792870, Semantic loss: 0.763538, BCE loss: 0.525224, SB loss: 0.733696
2023-10-30 14:21:17,400 Epoch: [262/484] Iter:[450/495], Time: 0.38, lr: [0.004940296008768519], Loss: 2.019045, Acc:0.792898, Semantic loss: 0.761135, BCE loss: 0.524924, SB loss: 0.732985
2023-10-30 14:21:21,123 Epoch: [262/484] Iter:[460/495], Time: 0.37, lr: [0.004939889732569479], Loss: 2.017229, Acc:0.793510, Semantic loss: 0.760871, BCE loss: 0.524096, SB loss: 0.732263
2023-10-30 14:21:24,878 Epoch: [262/484] Iter:[470/495], Time: 0.38, lr: [0.004939483452657765], Loss: 2.017661, Acc:0.794108, Semantic loss: 0.760133, BCE loss: 0.525016, SB loss: 0.732513
2023-10-30 14:21:28,621 Epoch: [262/484] Iter:[480/495], Time: 0.37, lr: [0.004939077169033002], Loss: 2.018203, Acc:0.794966, Semantic loss: 0.759852, BCE loss: 0.525713, SB loss: 0.732639
2023-10-30 14:21:32,181 Epoch: [262/484] Iter:[490/495], Time: 0.37, lr: [0.004938670881694816], Loss: 2.015958, Acc:0.794905, Semantic loss: 0.758687, BCE loss: 0.524928, SB loss: 0.732344
2023-10-30 14:21:33,605 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:21:33,851 Loss: 1.995, MeanIU:  0.6883, Best_mIoU:  0.7151
2023-10-30 14:21:33,851 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295]
2023-10-30 14:21:35,928 Epoch: [263/484] Iter:[0/495], Time: 2.04, lr: [0.004938467736633074], Loss: 2.121477, Acc:0.871739, Semantic loss: 0.691719, BCE loss: 0.752737, SB loss: 0.677022
2023-10-30 14:21:40,006 Epoch: [263/484] Iter:[10/495], Time: 0.56, lr: [0.004938061443724055], Loss: 1.994572, Acc:0.805750, Semantic loss: 0.736018, BCE loss: 0.523687, SB loss: 0.734867
2023-10-30 14:21:43,700 Epoch: [263/484] Iter:[20/495], Time: 0.47, lr: [0.004937655147100682], Loss: 1.982954, Acc:0.780000, Semantic loss: 0.768724, BCE loss: 0.468067, SB loss: 0.746164
2023-10-30 14:21:47,387 Epoch: [263/484] Iter:[30/495], Time: 0.44, lr: [0.004937248846762579], Loss: 1.993144, Acc:0.786433, Semantic loss: 0.761852, BCE loss: 0.484921, SB loss: 0.746371
2023-10-30 14:21:51,024 Epoch: [263/484] Iter:[40/495], Time: 0.42, lr: [0.004936842542709374], Loss: 1.996089, Acc:0.787012, Semantic loss: 0.771830, BCE loss: 0.481779, SB loss: 0.742480
2023-10-30 14:21:54,773 Epoch: [263/484] Iter:[50/495], Time: 0.41, lr: [0.004936436234940693], Loss: 1.996714, Acc:0.786193, Semantic loss: 0.769178, BCE loss: 0.488634, SB loss: 0.738902
2023-10-30 14:21:58,467 Epoch: [263/484] Iter:[60/495], Time: 0.40, lr: [0.004936029923456162], Loss: 1.998349, Acc:0.790781, Semantic loss: 0.761245, BCE loss: 0.493471, SB loss: 0.743633
2023-10-30 14:22:02,215 Epoch: [263/484] Iter:[70/495], Time: 0.40, lr: [0.004935623608255406], Loss: 1.987141, Acc:0.789438, Semantic loss: 0.750560, BCE loss: 0.494365, SB loss: 0.742216
2023-10-30 14:22:05,938 Epoch: [263/484] Iter:[80/495], Time: 0.40, lr: [0.004935217289338053], Loss: 2.015370, Acc:0.788413, Semantic loss: 0.762375, BCE loss: 0.506623, SB loss: 0.746372
2023-10-30 14:22:09,599 Epoch: [263/484] Iter:[90/495], Time: 0.39, lr: [0.004934810966703728], Loss: 2.000628, Acc:0.791716, Semantic loss: 0.755063, BCE loss: 0.501156, SB loss: 0.744409
2023-10-30 14:22:13,346 Epoch: [263/484] Iter:[100/495], Time: 0.39, lr: [0.004934404640352058], Loss: 2.014797, Acc:0.797165, Semantic loss: 0.762292, BCE loss: 0.507544, SB loss: 0.744961
2023-10-30 14:22:17,057 Epoch: [263/484] Iter:[110/495], Time: 0.39, lr: [0.004933998310282666], Loss: 2.005241, Acc:0.798344, Semantic loss: 0.756318, BCE loss: 0.507388, SB loss: 0.741534
2023-10-30 14:22:20,785 Epoch: [263/484] Iter:[120/495], Time: 0.39, lr: [0.004933591976495181], Loss: 2.003014, Acc:0.797007, Semantic loss: 0.759889, BCE loss: 0.503085, SB loss: 0.740040
2023-10-30 14:22:24,465 Epoch: [263/484] Iter:[130/495], Time: 0.39, lr: [0.0049331856389892275], Loss: 1.995768, Acc:0.797483, Semantic loss: 0.754490, BCE loss: 0.503228, SB loss: 0.738050
2023-10-30 14:22:28,157 Epoch: [263/484] Iter:[140/495], Time: 0.38, lr: [0.004932779297764431], Loss: 1.994005, Acc:0.797077, Semantic loss: 0.752816, BCE loss: 0.504609, SB loss: 0.736580
2023-10-30 14:22:31,824 Epoch: [263/484] Iter:[150/495], Time: 0.38, lr: [0.004932372952820416], Loss: 2.000586, Acc:0.799978, Semantic loss: 0.755684, BCE loss: 0.507013, SB loss: 0.737889
2023-10-30 14:22:35,454 Epoch: [263/484] Iter:[160/495], Time: 0.38, lr: [0.004931966604156811], Loss: 1.997680, Acc:0.800087, Semantic loss: 0.754487, BCE loss: 0.506945, SB loss: 0.736247
2023-10-30 14:22:39,148 Epoch: [263/484] Iter:[170/495], Time: 0.38, lr: [0.004931560251773239], Loss: 2.004063, Acc:0.800976, Semantic loss: 0.755850, BCE loss: 0.510894, SB loss: 0.737319
2023-10-30 14:22:42,737 Epoch: [263/484] Iter:[180/495], Time: 0.38, lr: [0.004931153895669327], Loss: 2.017495, Acc:0.801348, Semantic loss: 0.760186, BCE loss: 0.518764, SB loss: 0.738545
2023-10-30 14:22:46,526 Epoch: [263/484] Iter:[190/495], Time: 0.38, lr: [0.004930747535844697], Loss: 2.013945, Acc:0.800528, Semantic loss: 0.758662, BCE loss: 0.517528, SB loss: 0.737755
2023-10-30 14:22:50,156 Epoch: [263/484] Iter:[200/495], Time: 0.38, lr: [0.004930341172298978], Loss: 2.012693, Acc:0.799990, Semantic loss: 0.758905, BCE loss: 0.516975, SB loss: 0.736813
2023-10-30 14:22:53,876 Epoch: [263/484] Iter:[210/495], Time: 0.38, lr: [0.004929934805031793], Loss: 2.007065, Acc:0.799746, Semantic loss: 0.756525, BCE loss: 0.514915, SB loss: 0.735626
2023-10-30 14:22:57,634 Epoch: [263/484] Iter:[220/495], Time: 0.38, lr: [0.004929528434042769], Loss: 2.005667, Acc:0.800152, Semantic loss: 0.753802, BCE loss: 0.516813, SB loss: 0.735051
2023-10-30 14:23:01,272 Epoch: [263/484] Iter:[230/495], Time: 0.38, lr: [0.004929122059331529], Loss: 2.006122, Acc:0.799059, Semantic loss: 0.753642, BCE loss: 0.517665, SB loss: 0.734815
2023-10-30 14:23:04,937 Epoch: [263/484] Iter:[240/495], Time: 0.38, lr: [0.004928715680897698], Loss: 1.998268, Acc:0.798959, Semantic loss: 0.749847, BCE loss: 0.515846, SB loss: 0.732575
2023-10-30 14:23:08,655 Epoch: [263/484] Iter:[250/495], Time: 0.38, lr: [0.004928309298740902], Loss: 1.999063, Acc:0.800009, Semantic loss: 0.749454, BCE loss: 0.515971, SB loss: 0.733637
2023-10-30 14:23:12,460 Epoch: [263/484] Iter:[260/495], Time: 0.38, lr: [0.004927902912860766], Loss: 1.997468, Acc:0.800363, Semantic loss: 0.749363, BCE loss: 0.514343, SB loss: 0.733761
2023-10-30 14:23:16,182 Epoch: [263/484] Iter:[270/495], Time: 0.38, lr: [0.004927496523256913], Loss: 1.998869, Acc:0.801186, Semantic loss: 0.749938, BCE loss: 0.514799, SB loss: 0.734132
2023-10-30 14:23:20,040 Epoch: [263/484] Iter:[280/495], Time: 0.38, lr: [0.00492709012992897], Loss: 2.001491, Acc:0.802551, Semantic loss: 0.749857, BCE loss: 0.517422, SB loss: 0.734212
2023-10-30 14:23:23,731 Epoch: [263/484] Iter:[290/495], Time: 0.38, lr: [0.004926683732876559], Loss: 2.004098, Acc:0.803377, Semantic loss: 0.750180, BCE loss: 0.519185, SB loss: 0.734733
2023-10-30 14:23:27,424 Epoch: [263/484] Iter:[300/495], Time: 0.38, lr: [0.004926277332099306], Loss: 2.001273, Acc:0.802319, Semantic loss: 0.750247, BCE loss: 0.517800, SB loss: 0.733227
2023-10-30 14:23:31,070 Epoch: [263/484] Iter:[310/495], Time: 0.38, lr: [0.004925870927596835], Loss: 2.000998, Acc:0.803047, Semantic loss: 0.749505, BCE loss: 0.519299, SB loss: 0.732193
2023-10-30 14:23:34,686 Epoch: [263/484] Iter:[320/495], Time: 0.38, lr: [0.004925464519368771], Loss: 2.001695, Acc:0.801505, Semantic loss: 0.750049, BCE loss: 0.518868, SB loss: 0.732778
2023-10-30 14:23:38,319 Epoch: [263/484] Iter:[330/495], Time: 0.38, lr: [0.004925058107414738], Loss: 2.002279, Acc:0.802006, Semantic loss: 0.750515, BCE loss: 0.518746, SB loss: 0.733018
2023-10-30 14:23:42,017 Epoch: [263/484] Iter:[340/495], Time: 0.38, lr: [0.004924651691734359], Loss: 2.002058, Acc:0.801742, Semantic loss: 0.750847, BCE loss: 0.518294, SB loss: 0.732917
2023-10-30 14:23:45,774 Epoch: [263/484] Iter:[350/495], Time: 0.38, lr: [0.0049242452723272595], Loss: 2.004680, Acc:0.801524, Semantic loss: 0.753057, BCE loss: 0.518060, SB loss: 0.733564
2023-10-30 14:23:49,475 Epoch: [263/484] Iter:[360/495], Time: 0.38, lr: [0.004923838849193064], Loss: 2.002890, Acc:0.802188, Semantic loss: 0.752782, BCE loss: 0.517379, SB loss: 0.732729
2023-10-30 14:23:53,156 Epoch: [263/484] Iter:[370/495], Time: 0.38, lr: [0.004923432422331395], Loss: 2.002812, Acc:0.801043, Semantic loss: 0.753324, BCE loss: 0.517283, SB loss: 0.732205
2023-10-30 14:23:56,901 Epoch: [263/484] Iter:[380/495], Time: 0.38, lr: [0.004923025991741877], Loss: 2.000843, Acc:0.800405, Semantic loss: 0.752855, BCE loss: 0.516655, SB loss: 0.731333
2023-10-30 14:24:00,717 Epoch: [263/484] Iter:[390/495], Time: 0.38, lr: [0.004922619557424134], Loss: 2.007965, Acc:0.801028, Semantic loss: 0.757198, BCE loss: 0.517807, SB loss: 0.732960
2023-10-30 14:24:04,499 Epoch: [263/484] Iter:[400/495], Time: 0.38, lr: [0.00492221311937779], Loss: 2.009410, Acc:0.800805, Semantic loss: 0.757752, BCE loss: 0.518270, SB loss: 0.733387
2023-10-30 14:24:08,141 Epoch: [263/484] Iter:[410/495], Time: 0.38, lr: [0.004921806677602468], Loss: 2.005824, Acc:0.800473, Semantic loss: 0.755495, BCE loss: 0.517483, SB loss: 0.732846
2023-10-30 14:24:11,871 Epoch: [263/484] Iter:[420/495], Time: 0.38, lr: [0.004921400232097793], Loss: 2.006294, Acc:0.800831, Semantic loss: 0.755293, BCE loss: 0.518511, SB loss: 0.732490
2023-10-30 14:24:15,554 Epoch: [263/484] Iter:[430/495], Time: 0.38, lr: [0.004920993782863386], Loss: 2.010637, Acc:0.801060, Semantic loss: 0.757097, BCE loss: 0.520561, SB loss: 0.732979
2023-10-30 14:24:19,286 Epoch: [263/484] Iter:[440/495], Time: 0.38, lr: [0.0049205873298988735], Loss: 2.009427, Acc:0.801497, Semantic loss: 0.756480, BCE loss: 0.520347, SB loss: 0.732600
2023-10-30 14:24:23,043 Epoch: [263/484] Iter:[450/495], Time: 0.38, lr: [0.004920180873203877], Loss: 2.009475, Acc:0.800962, Semantic loss: 0.756109, BCE loss: 0.520944, SB loss: 0.732422
2023-10-30 14:24:26,893 Epoch: [263/484] Iter:[460/495], Time: 0.38, lr: [0.004919774412778021], Loss: 2.011148, Acc:0.801422, Semantic loss: 0.755498, BCE loss: 0.523478, SB loss: 0.732173
2023-10-30 14:24:30,551 Epoch: [263/484] Iter:[470/495], Time: 0.38, lr: [0.004919367948620927], Loss: 2.011339, Acc:0.802396, Semantic loss: 0.754621, BCE loss: 0.524777, SB loss: 0.731941
2023-10-30 14:24:34,179 Epoch: [263/484] Iter:[480/495], Time: 0.37, lr: [0.004918961480732219], Loss: 2.011508, Acc:0.802357, Semantic loss: 0.755112, BCE loss: 0.524538, SB loss: 0.731859
2023-10-30 14:24:37,686 Epoch: [263/484] Iter:[490/495], Time: 0.37, lr: [0.004918555009111521], Loss: 2.009701, Acc:0.802636, Semantic loss: 0.753443, BCE loss: 0.525002, SB loss: 0.731256
2023-10-30 14:24:39,082 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:24:39,319 Loss: 1.995, MeanIU:  0.6883, Best_mIoU:  0.7151
2023-10-30 14:24:39,319 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295]
2023-10-30 14:24:41,203 Epoch: [264/484] Iter:[0/495], Time: 1.85, lr: [0.004918351771901559], Loss: 1.966259, Acc:0.807951, Semantic loss: 0.700629, BCE loss: 0.526931, SB loss: 0.738699
2023-10-30 14:24:45,115 Epoch: [264/484] Iter:[10/495], Time: 0.52, lr: [0.0049179452946821675], Loss: 2.065521, Acc:0.806014, Semantic loss: 0.765950, BCE loss: 0.565268, SB loss: 0.734302
2023-10-30 14:24:48,934 Epoch: [264/484] Iter:[20/495], Time: 0.46, lr: [0.004917538813729844], Loss: 2.096238, Acc:0.801561, Semantic loss: 0.806482, BCE loss: 0.554342, SB loss: 0.735415
2023-10-30 14:24:52,751 Epoch: [264/484] Iter:[30/495], Time: 0.43, lr: [0.00491713232904421], Loss: 2.083310, Acc:0.820865, Semantic loss: 0.799466, BCE loss: 0.558574, SB loss: 0.725270
2023-10-30 14:24:56,416 Epoch: [264/484] Iter:[40/495], Time: 0.42, lr: [0.0049167258406248885], Loss: 2.037630, Acc:0.813281, Semantic loss: 0.765940, BCE loss: 0.556195, SB loss: 0.715495
2023-10-30 14:25:00,118 Epoch: [264/484] Iter:[50/495], Time: 0.41, lr: [0.004916319348471502], Loss: 2.039245, Acc:0.801875, Semantic loss: 0.770925, BCE loss: 0.548296, SB loss: 0.720024
2023-10-30 14:25:03,804 Epoch: [264/484] Iter:[60/495], Time: 0.40, lr: [0.004915912852583674], Loss: 2.039034, Acc:0.806173, Semantic loss: 0.760635, BCE loss: 0.555482, SB loss: 0.722918
2023-10-30 14:25:07,432 Epoch: [264/484] Iter:[70/495], Time: 0.40, lr: [0.004915506352961027], Loss: 2.047035, Acc:0.805240, Semantic loss: 0.770050, BCE loss: 0.547325, SB loss: 0.729661
2023-10-30 14:25:11,135 Epoch: [264/484] Iter:[80/495], Time: 0.39, lr: [0.004915099849603182], Loss: 2.061779, Acc:0.799290, Semantic loss: 0.778725, BCE loss: 0.547080, SB loss: 0.735974
2023-10-30 14:25:14,830 Epoch: [264/484] Iter:[90/495], Time: 0.39, lr: [0.004914693342509762], Loss: 2.041663, Acc:0.796919, Semantic loss: 0.770181, BCE loss: 0.540727, SB loss: 0.730754
2023-10-30 14:25:18,629 Epoch: [264/484] Iter:[100/495], Time: 0.39, lr: [0.004914286831680391], Loss: 2.045357, Acc:0.796884, Semantic loss: 0.771734, BCE loss: 0.541641, SB loss: 0.731983
2023-10-30 14:25:22,323 Epoch: [264/484] Iter:[110/495], Time: 0.39, lr: [0.004913880317114689], Loss: 2.048807, Acc:0.798361, Semantic loss: 0.777499, BCE loss: 0.539370, SB loss: 0.731939
2023-10-30 14:25:26,102 Epoch: [264/484] Iter:[120/495], Time: 0.39, lr: [0.004913473798812281], Loss: 2.040420, Acc:0.802312, Semantic loss: 0.771015, BCE loss: 0.539484, SB loss: 0.729921
2023-10-30 14:25:29,723 Epoch: [264/484] Iter:[130/495], Time: 0.38, lr: [0.004913067276772785], Loss: 2.029236, Acc:0.803435, Semantic loss: 0.767666, BCE loss: 0.534256, SB loss: 0.727315
2023-10-30 14:25:33,503 Epoch: [264/484] Iter:[140/495], Time: 0.38, lr: [0.004912660750995827], Loss: 2.025241, Acc:0.802962, Semantic loss: 0.768920, BCE loss: 0.531943, SB loss: 0.724378
2023-10-30 14:25:37,236 Epoch: [264/484] Iter:[150/495], Time: 0.38, lr: [0.0049122542214810275], Loss: 2.021614, Acc:0.805281, Semantic loss: 0.764096, BCE loss: 0.533870, SB loss: 0.723648
2023-10-30 14:25:40,898 Epoch: [264/484] Iter:[160/495], Time: 0.38, lr: [0.004911847688228008], Loss: 2.011923, Acc:0.800722, Semantic loss: 0.759928, BCE loss: 0.530417, SB loss: 0.721577
2023-10-30 14:25:44,532 Epoch: [264/484] Iter:[170/495], Time: 0.38, lr: [0.00491144115123639], Loss: 2.010981, Acc:0.800070, Semantic loss: 0.759985, BCE loss: 0.527860, SB loss: 0.723136
2023-10-30 14:25:48,138 Epoch: [264/484] Iter:[180/495], Time: 0.38, lr: [0.004911034610505797], Loss: 2.013728, Acc:0.799572, Semantic loss: 0.761721, BCE loss: 0.527698, SB loss: 0.724310
2023-10-30 14:25:51,818 Epoch: [264/484] Iter:[190/495], Time: 0.38, lr: [0.00491062806603585], Loss: 2.016125, Acc:0.798583, Semantic loss: 0.761967, BCE loss: 0.528568, SB loss: 0.725589
2023-10-30 14:25:55,649 Epoch: [264/484] Iter:[200/495], Time: 0.38, lr: [0.004910221517826169], Loss: 2.019345, Acc:0.797720, Semantic loss: 0.764831, BCE loss: 0.528137, SB loss: 0.726377
2023-10-30 14:25:59,315 Epoch: [264/484] Iter:[210/495], Time: 0.38, lr: [0.0049098149658763765], Loss: 2.022150, Acc:0.798180, Semantic loss: 0.767224, BCE loss: 0.528488, SB loss: 0.726438
2023-10-30 14:26:02,984 Epoch: [264/484] Iter:[220/495], Time: 0.38, lr: [0.0049094084101860965], Loss: 2.020294, Acc:0.799217, Semantic loss: 0.765549, BCE loss: 0.528246, SB loss: 0.726499
2023-10-30 14:26:06,680 Epoch: [264/484] Iter:[230/495], Time: 0.38, lr: [0.004909001850754947], Loss: 2.021326, Acc:0.799737, Semantic loss: 0.765019, BCE loss: 0.528946, SB loss: 0.727362
2023-10-30 14:26:10,378 Epoch: [264/484] Iter:[240/495], Time: 0.38, lr: [0.0049085952875825515], Loss: 2.016199, Acc:0.799243, Semantic loss: 0.762051, BCE loss: 0.527491, SB loss: 0.726657
2023-10-30 14:26:14,112 Epoch: [264/484] Iter:[250/495], Time: 0.38, lr: [0.004908188720668528], Loss: 2.021726, Acc:0.799059, Semantic loss: 0.764093, BCE loss: 0.528928, SB loss: 0.728705
2023-10-30 14:26:17,756 Epoch: [264/484] Iter:[260/495], Time: 0.38, lr: [0.004907782150012503], Loss: 2.021865, Acc:0.799942, Semantic loss: 0.760856, BCE loss: 0.532981, SB loss: 0.728027
2023-10-30 14:26:21,452 Epoch: [264/484] Iter:[270/495], Time: 0.38, lr: [0.004907375575614092], Loss: 2.027222, Acc:0.800858, Semantic loss: 0.763029, BCE loss: 0.536145, SB loss: 0.728048
2023-10-30 14:26:25,191 Epoch: [264/484] Iter:[280/495], Time: 0.38, lr: [0.0049069689974729205], Loss: 2.028776, Acc:0.799850, Semantic loss: 0.765726, BCE loss: 0.534666, SB loss: 0.728384
2023-10-30 14:26:28,955 Epoch: [264/484] Iter:[290/495], Time: 0.38, lr: [0.004906562415588607], Loss: 2.024206, Acc:0.800102, Semantic loss: 0.762441, BCE loss: 0.533971, SB loss: 0.727794
2023-10-30 14:26:32,634 Epoch: [264/484] Iter:[300/495], Time: 0.38, lr: [0.0049061558299607734], Loss: 2.022711, Acc:0.801129, Semantic loss: 0.760994, BCE loss: 0.534038, SB loss: 0.727680
2023-10-30 14:26:36,372 Epoch: [264/484] Iter:[310/495], Time: 0.38, lr: [0.00490574924058904], Loss: 2.020516, Acc:0.801885, Semantic loss: 0.760277, BCE loss: 0.533605, SB loss: 0.726634
2023-10-30 14:26:40,041 Epoch: [264/484] Iter:[320/495], Time: 0.38, lr: [0.0049053426474730275], Loss: 2.021319, Acc:0.802845, Semantic loss: 0.760457, BCE loss: 0.534143, SB loss: 0.726719
2023-10-30 14:26:43,696 Epoch: [264/484] Iter:[330/495], Time: 0.38, lr: [0.004904936050612357], Loss: 2.029540, Acc:0.803492, Semantic loss: 0.765075, BCE loss: 0.535534, SB loss: 0.728931
2023-10-30 14:26:47,426 Epoch: [264/484] Iter:[340/495], Time: 0.38, lr: [0.004904529450006649], Loss: 2.030608, Acc:0.802443, Semantic loss: 0.765676, BCE loss: 0.535004, SB loss: 0.729927
2023-10-30 14:26:51,236 Epoch: [264/484] Iter:[350/495], Time: 0.38, lr: [0.004904122845655523], Loss: 2.031285, Acc:0.803012, Semantic loss: 0.765540, BCE loss: 0.535617, SB loss: 0.730129
2023-10-30 14:26:55,008 Epoch: [264/484] Iter:[360/495], Time: 0.38, lr: [0.004903716237558601], Loss: 2.034804, Acc:0.802214, Semantic loss: 0.766559, BCE loss: 0.537294, SB loss: 0.730952
2023-10-30 14:26:58,668 Epoch: [264/484] Iter:[370/495], Time: 0.38, lr: [0.004903309625715503], Loss: 2.039312, Acc:0.801889, Semantic loss: 0.769799, BCE loss: 0.538098, SB loss: 0.731416
2023-10-30 14:27:02,301 Epoch: [264/484] Iter:[380/495], Time: 0.38, lr: [0.004902903010125849], Loss: 2.038182, Acc:0.802143, Semantic loss: 0.769039, BCE loss: 0.538360, SB loss: 0.730784
2023-10-30 14:27:05,968 Epoch: [264/484] Iter:[390/495], Time: 0.37, lr: [0.004902496390789259], Loss: 2.034540, Acc:0.802276, Semantic loss: 0.766731, BCE loss: 0.537960, SB loss: 0.729848
2023-10-30 14:27:09,589 Epoch: [264/484] Iter:[400/495], Time: 0.37, lr: [0.0049020897677053525], Loss: 2.036438, Acc:0.801921, Semantic loss: 0.766937, BCE loss: 0.538888, SB loss: 0.730612
2023-10-30 14:27:13,332 Epoch: [264/484] Iter:[410/495], Time: 0.37, lr: [0.004901683140873752], Loss: 2.036043, Acc:0.801869, Semantic loss: 0.766026, BCE loss: 0.539116, SB loss: 0.730901
2023-10-30 14:27:17,043 Epoch: [264/484] Iter:[420/495], Time: 0.37, lr: [0.004901276510294076], Loss: 2.035370, Acc:0.802285, Semantic loss: 0.765239, BCE loss: 0.539199, SB loss: 0.730932
2023-10-30 14:27:20,708 Epoch: [264/484] Iter:[430/495], Time: 0.37, lr: [0.004900869875965944], Loss: 2.036149, Acc:0.801586, Semantic loss: 0.766241, BCE loss: 0.538311, SB loss: 0.731596
2023-10-30 14:27:24,488 Epoch: [264/484] Iter:[440/495], Time: 0.37, lr: [0.004900463237888977], Loss: 2.034332, Acc:0.801103, Semantic loss: 0.764463, BCE loss: 0.538625, SB loss: 0.731244
2023-10-30 14:27:28,285 Epoch: [264/484] Iter:[450/495], Time: 0.37, lr: [0.004900056596062793], Loss: 2.035096, Acc:0.801713, Semantic loss: 0.763688, BCE loss: 0.539475, SB loss: 0.731933
2023-10-30 14:27:31,948 Epoch: [264/484] Iter:[460/495], Time: 0.37, lr: [0.004899649950487014], Loss: 2.033308, Acc:0.802312, Semantic loss: 0.763321, BCE loss: 0.537955, SB loss: 0.732031
2023-10-30 14:27:35,694 Epoch: [264/484] Iter:[470/495], Time: 0.37, lr: [0.004899243301161258], Loss: 2.031154, Acc:0.802253, Semantic loss: 0.761953, BCE loss: 0.537134, SB loss: 0.732067
2023-10-30 14:27:39,351 Epoch: [264/484] Iter:[480/495], Time: 0.37, lr: [0.004898836648085144], Loss: 2.030215, Acc:0.802127, Semantic loss: 0.762291, BCE loss: 0.536394, SB loss: 0.731530
2023-10-30 14:27:42,879 Epoch: [264/484] Iter:[490/495], Time: 0.37, lr: [0.004898429991258294], Loss: 2.028539, Acc:0.802124, Semantic loss: 0.761265, BCE loss: 0.535943, SB loss: 0.731332
2023-10-30 14:27:44,278 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:27:44,520 Loss: 1.995, MeanIU:  0.6883, Best_mIoU:  0.7151
2023-10-30 14:27:44,520 [0.97305237 0.80061749 0.91167214 0.44078522 0.53421226 0.58859709
 0.64893701 0.74595446 0.90887143 0.5666487  0.93895601 0.76860146
 0.55563242 0.92206704 0.56537506 0.69206756 0.26188627 0.52402068
 0.73020295]
2023-10-30 14:27:46,649 Epoch: [265/484] Iter:[0/495], Time: 2.10, lr: [0.004898226661438224], Loss: 1.488227, Acc:0.886124, Semantic loss: 0.551820, BCE loss: 0.384075, SB loss: 0.552332
2023-10-30 14:27:50,577 Epoch: [265/484] Iter:[10/495], Time: 0.55, lr: [0.004897819998984554], Loss: 1.805279, Acc:0.820879, Semantic loss: 0.686192, BCE loss: 0.445247, SB loss: 0.673839
2023-10-30 14:27:54,190 Epoch: [265/484] Iter:[20/495], Time: 0.46, lr: [0.004897413332779195], Loss: 1.919773, Acc:0.790755, Semantic loss: 0.743771, BCE loss: 0.473606, SB loss: 0.702396
2023-10-30 14:27:57,838 Epoch: [265/484] Iter:[30/495], Time: 0.43, lr: [0.004897006662821765], Loss: 1.968699, Acc:0.786798, Semantic loss: 0.766589, BCE loss: 0.472175, SB loss: 0.729935
2023-10-30 14:28:01,578 Epoch: [265/484] Iter:[40/495], Time: 0.42, lr: [0.004896599989111886], Loss: 1.969463, Acc:0.796355, Semantic loss: 0.758415, BCE loss: 0.484412, SB loss: 0.726636
2023-10-30 14:28:05,267 Epoch: [265/484] Iter:[50/495], Time: 0.41, lr: [0.004896193311649175], Loss: 1.984670, Acc:0.797831, Semantic loss: 0.757419, BCE loss: 0.493015, SB loss: 0.734236
2023-10-30 14:28:09,030 Epoch: [265/484] Iter:[60/495], Time: 0.40, lr: [0.0048957866304332525], Loss: 1.974260, Acc:0.799372, Semantic loss: 0.751537, BCE loss: 0.492206, SB loss: 0.730517
2023-10-30 14:28:12,691 Epoch: [265/484] Iter:[70/495], Time: 0.40, lr: [0.004895379945463734], Loss: 1.978710, Acc:0.804052, Semantic loss: 0.750839, BCE loss: 0.493354, SB loss: 0.734518
2023-10-30 14:28:16,357 Epoch: [265/484] Iter:[80/495], Time: 0.39, lr: [0.004894973256740243], Loss: 1.986166, Acc:0.803664, Semantic loss: 0.755460, BCE loss: 0.495966, SB loss: 0.734740
2023-10-30 14:28:20,134 Epoch: [265/484] Iter:[90/495], Time: 0.39, lr: [0.004894566564262396], Loss: 2.005072, Acc:0.802443, Semantic loss: 0.764018, BCE loss: 0.505292, SB loss: 0.735762
2023-10-30 14:28:23,907 Epoch: [265/484] Iter:[100/495], Time: 0.39, lr: [0.004894159868029811], Loss: 2.002708, Acc:0.803712, Semantic loss: 0.760208, BCE loss: 0.508303, SB loss: 0.734197
2023-10-30 14:28:27,651 Epoch: [265/484] Iter:[110/495], Time: 0.39, lr: [0.004893753168042107], Loss: 2.010842, Acc:0.803694, Semantic loss: 0.763487, BCE loss: 0.513215, SB loss: 0.734140
2023-10-30 14:28:31,283 Epoch: [265/484] Iter:[120/495], Time: 0.39, lr: [0.004893346464298904], Loss: 2.001079, Acc:0.806434, Semantic loss: 0.759345, BCE loss: 0.510925, SB loss: 0.730809
2023-10-30 14:28:34,975 Epoch: [265/484] Iter:[130/495], Time: 0.38, lr: [0.004892939756799819], Loss: 2.010392, Acc:0.806485, Semantic loss: 0.762164, BCE loss: 0.515915, SB loss: 0.732313
2023-10-30 14:28:38,725 Epoch: [265/484] Iter:[140/495], Time: 0.38, lr: [0.004892533045544472], Loss: 2.010621, Acc:0.806757, Semantic loss: 0.759713, BCE loss: 0.518761, SB loss: 0.732147
2023-10-30 14:28:42,468 Epoch: [265/484] Iter:[150/495], Time: 0.38, lr: [0.004892126330532479], Loss: 2.008070, Acc:0.807670, Semantic loss: 0.757935, BCE loss: 0.518690, SB loss: 0.731445
2023-10-30 14:28:46,158 Epoch: [265/484] Iter:[160/495], Time: 0.38, lr: [0.00489171961176346], Loss: 2.015046, Acc:0.809713, Semantic loss: 0.759383, BCE loss: 0.522642, SB loss: 0.733020
2023-10-30 14:28:49,832 Epoch: [265/484] Iter:[170/495], Time: 0.38, lr: [0.004891312889237033], Loss: 2.024988, Acc:0.807576, Semantic loss: 0.766900, BCE loss: 0.522748, SB loss: 0.735340
2023-10-30 14:28:53,583 Epoch: [265/484] Iter:[180/495], Time: 0.38, lr: [0.004890906162952817], Loss: 2.029362, Acc:0.806405, Semantic loss: 0.769783, BCE loss: 0.521432, SB loss: 0.738147
2023-10-30 14:28:57,299 Epoch: [265/484] Iter:[190/495], Time: 0.38, lr: [0.004890499432910427], Loss: 2.031056, Acc:0.805620, Semantic loss: 0.771492, BCE loss: 0.520224, SB loss: 0.739341
2023-10-30 14:29:00,952 Epoch: [265/484] Iter:[200/495], Time: 0.38, lr: [0.004890092699109484], Loss: 2.033085, Acc:0.808402, Semantic loss: 0.771897, BCE loss: 0.522657, SB loss: 0.738532
2023-10-30 14:29:04,553 Epoch: [265/484] Iter:[210/495], Time: 0.38, lr: [0.004889685961549605], Loss: 2.022904, Acc:0.808006, Semantic loss: 0.766898, BCE loss: 0.519939, SB loss: 0.736067
2023-10-30 14:29:08,216 Epoch: [265/484] Iter:[220/495], Time: 0.38, lr: [0.004889279220230407], Loss: 2.024515, Acc:0.806890, Semantic loss: 0.768842, BCE loss: 0.518946, SB loss: 0.736727
2023-10-30 14:29:11,952 Epoch: [265/484] Iter:[230/495], Time: 0.38, lr: [0.00488887247515151], Loss: 2.021876, Acc:0.805748, Semantic loss: 0.765894, BCE loss: 0.520468, SB loss: 0.735513
2023-10-30 14:29:15,617 Epoch: [265/484] Iter:[240/495], Time: 0.38, lr: [0.004888465726312529], Loss: 2.025250, Acc:0.804436, Semantic loss: 0.768153, BCE loss: 0.521163, SB loss: 0.735934
2023-10-30 14:29:19,322 Epoch: [265/484] Iter:[250/495], Time: 0.38, lr: [0.004888058973713084], Loss: 2.028021, Acc:0.803681, Semantic loss: 0.769805, BCE loss: 0.520750, SB loss: 0.737466
2023-10-30 14:29:23,061 Epoch: [265/484] Iter:[260/495], Time: 0.38, lr: [0.0048876522173527896], Loss: 2.025788, Acc:0.803465, Semantic loss: 0.769601, BCE loss: 0.519014, SB loss: 0.737174
2023-10-30 14:29:26,731 Epoch: [265/484] Iter:[270/495], Time: 0.38, lr: [0.004887245457231266], Loss: 2.029667, Acc:0.803776, Semantic loss: 0.769376, BCE loss: 0.522891, SB loss: 0.737400
2023-10-30 14:29:30,442 Epoch: [265/484] Iter:[280/495], Time: 0.38, lr: [0.004886838693348129], Loss: 2.028650, Acc:0.803547, Semantic loss: 0.768881, BCE loss: 0.522020, SB loss: 0.737748
2023-10-30 14:29:34,128 Epoch: [265/484] Iter:[290/495], Time: 0.38, lr: [0.004886431925702998], Loss: 2.024665, Acc:0.802172, Semantic loss: 0.765926, BCE loss: 0.520601, SB loss: 0.738137
2023-10-30 14:29:37,808 Epoch: [265/484] Iter:[300/495], Time: 0.38, lr: [0.0048860251542954865], Loss: 2.020348, Acc:0.802275, Semantic loss: 0.764016, BCE loss: 0.519662, SB loss: 0.736670
2023-10-30 14:29:41,528 Epoch: [265/484] Iter:[310/495], Time: 0.38, lr: [0.004885618379125215], Loss: 2.021384, Acc:0.801694, Semantic loss: 0.765634, BCE loss: 0.519306, SB loss: 0.736444
2023-10-30 14:29:45,335 Epoch: [265/484] Iter:[320/495], Time: 0.38, lr: [0.0048852116001917995], Loss: 2.023466, Acc:0.801633, Semantic loss: 0.764951, BCE loss: 0.522041, SB loss: 0.736474
2023-10-30 14:29:49,114 Epoch: [265/484] Iter:[330/495], Time: 0.38, lr: [0.004884804817494857], Loss: 2.026012, Acc:0.801816, Semantic loss: 0.766675, BCE loss: 0.522001, SB loss: 0.737335
2023-10-30 14:29:52,782 Epoch: [265/484] Iter:[340/495], Time: 0.38, lr: [0.004884398031034004], Loss: 2.025436, Acc:0.801719, Semantic loss: 0.766751, BCE loss: 0.521397, SB loss: 0.737288
2023-10-30 14:29:56,588 Epoch: [265/484] Iter:[350/495], Time: 0.38, lr: [0.004883991240808858], Loss: 2.022670, Acc:0.802141, Semantic loss: 0.765924, BCE loss: 0.521257, SB loss: 0.735489
2023-10-30 14:30:00,306 Epoch: [265/484] Iter:[360/495], Time: 0.38, lr: [0.0048835844468190365], Loss: 2.026005, Acc:0.802066, Semantic loss: 0.767745, BCE loss: 0.522442, SB loss: 0.735819
2023-10-30 14:30:03,988 Epoch: [265/484] Iter:[370/495], Time: 0.38, lr: [0.004883177649064155], Loss: 2.031251, Acc:0.801616, Semantic loss: 0.770332, BCE loss: 0.523402, SB loss: 0.737516
2023-10-30 14:30:07,536 Epoch: [265/484] Iter:[380/495], Time: 0.38, lr: [0.004882770847543829], Loss: 2.030562, Acc:0.801657, Semantic loss: 0.770145, BCE loss: 0.523032, SB loss: 0.737385
2023-10-30 14:30:11,265 Epoch: [265/484] Iter:[390/495], Time: 0.38, lr: [0.004882364042257678], Loss: 2.029141, Acc:0.802012, Semantic loss: 0.768171, BCE loss: 0.523698, SB loss: 0.737272
2023-10-30 14:30:14,903 Epoch: [265/484] Iter:[400/495], Time: 0.37, lr: [0.004881957233205317], Loss: 2.030748, Acc:0.801538, Semantic loss: 0.768919, BCE loss: 0.523708, SB loss: 0.738121
2023-10-30 14:30:18,503 Epoch: [265/484] Iter:[410/495], Time: 0.37, lr: [0.004881550420386362], Loss: 2.032480, Acc:0.800867, Semantic loss: 0.769591, BCE loss: 0.523892, SB loss: 0.738997
2023-10-30 14:30:22,177 Epoch: [265/484] Iter:[420/495], Time: 0.37, lr: [0.00488114360380043], Loss: 2.033291, Acc:0.800744, Semantic loss: 0.769276, BCE loss: 0.524262, SB loss: 0.739752
2023-10-30 14:30:25,895 Epoch: [265/484] Iter:[430/495], Time: 0.37, lr: [0.004880736783447136], Loss: 2.033051, Acc:0.799788, Semantic loss: 0.769840, BCE loss: 0.524042, SB loss: 0.739169
2023-10-30 14:30:29,713 Epoch: [265/484] Iter:[440/495], Time: 0.37, lr: [0.0048803299593260996], Loss: 2.033631, Acc:0.800027, Semantic loss: 0.769639, BCE loss: 0.524806, SB loss: 0.739186
2023-10-30 14:30:33,528 Epoch: [265/484] Iter:[450/495], Time: 0.37, lr: [0.004879923131436934], Loss: 2.033254, Acc:0.800269, Semantic loss: 0.768639, BCE loss: 0.524932, SB loss: 0.739683
2023-10-30 14:30:37,211 Epoch: [265/484] Iter:[460/495], Time: 0.37, lr: [0.004879516299779254], Loss: 2.034952, Acc:0.800440, Semantic loss: 0.768909, BCE loss: 0.526189, SB loss: 0.739854
2023-10-30 14:30:40,923 Epoch: [265/484] Iter:[470/495], Time: 0.37, lr: [0.004879109464352678], Loss: 2.035873, Acc:0.800049, Semantic loss: 0.769698, BCE loss: 0.525828, SB loss: 0.740347
2023-10-30 14:30:44,559 Epoch: [265/484] Iter:[480/495], Time: 0.37, lr: [0.0048787026251568225], Loss: 2.035205, Acc:0.799227, Semantic loss: 0.769109, BCE loss: 0.525954, SB loss: 0.740142
2023-10-30 14:30:48,073 Epoch: [265/484] Iter:[490/495], Time: 0.37, lr: [0.004878295782191302], Loss: 2.035940, Acc:0.799079, Semantic loss: 0.769529, BCE loss: 0.526460, SB loss: 0.739952
2023-10-30 14:33:44,785 0 [0.93754799 0.65851404 0.82347771 0.14321069 0.21439596 0.40119383
 0.45211961 0.58926786 0.88373951 0.4401555  0.83485622 0.61589673
 0.05491397 0.74234247 0.00164186 0.08249167 0.04422367 0.06410311
 0.59311274] 0.45143184876447195
2023-10-30 14:33:44,786 1 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692] 0.680612506038239
2023-10-30 14:33:44,790 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:33:45,026 Loss: 2.027, MeanIU:  0.6806, Best_mIoU:  0.7151
2023-10-30 14:33:45,026 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692]
2023-10-30 14:33:47,354 Epoch: [266/484] Iter:[0/495], Time: 2.30, lr: [0.004878092359294797], Loss: 1.653570, Acc:0.816371, Semantic loss: 0.631123, BCE loss: 0.411278, SB loss: 0.611169
2023-10-30 14:33:50,990 Epoch: [266/484] Iter:[10/495], Time: 0.54, lr: [0.004877685510674057], Loss: 1.964531, Acc:0.789881, Semantic loss: 0.743988, BCE loss: 0.518191, SB loss: 0.702352
2023-10-30 14:33:54,583 Epoch: [266/484] Iter:[20/495], Time: 0.45, lr: [0.004877278658282693], Loss: 1.909017, Acc:0.781102, Semantic loss: 0.718365, BCE loss: 0.489918, SB loss: 0.700735
2023-10-30 14:33:58,011 Epoch: [266/484] Iter:[30/495], Time: 0.42, lr: [0.004876871802120319], Loss: 1.975450, Acc:0.784696, Semantic loss: 0.741721, BCE loss: 0.518474, SB loss: 0.715255
2023-10-30 14:34:01,493 Epoch: [266/484] Iter:[40/495], Time: 0.40, lr: [0.004876464942186549], Loss: 2.000685, Acc:0.784078, Semantic loss: 0.757446, BCE loss: 0.521393, SB loss: 0.721845
2023-10-30 14:34:04,994 Epoch: [266/484] Iter:[50/495], Time: 0.39, lr: [0.004876058078481], Loss: 2.009092, Acc:0.791865, Semantic loss: 0.758316, BCE loss: 0.530040, SB loss: 0.720736
2023-10-30 14:34:08,500 Epoch: [266/484] Iter:[60/495], Time: 0.38, lr: [0.004875651211003289], Loss: 2.011441, Acc:0.793838, Semantic loss: 0.759434, BCE loss: 0.526603, SB loss: 0.725404
2023-10-30 14:34:12,008 Epoch: [266/484] Iter:[70/495], Time: 0.38, lr: [0.004875244339753028], Loss: 2.016448, Acc:0.796404, Semantic loss: 0.764544, BCE loss: 0.525512, SB loss: 0.726392
2023-10-30 14:34:15,549 Epoch: [266/484] Iter:[80/495], Time: 0.38, lr: [0.004874837464729833], Loss: 2.019860, Acc:0.798852, Semantic loss: 0.760094, BCE loss: 0.532508, SB loss: 0.727258
2023-10-30 14:34:19,113 Epoch: [266/484] Iter:[90/495], Time: 0.37, lr: [0.004874430585933321], Loss: 2.036773, Acc:0.800060, Semantic loss: 0.773598, BCE loss: 0.535438, SB loss: 0.727737
2023-10-30 14:34:22,623 Epoch: [266/484] Iter:[100/495], Time: 0.37, lr: [0.0048740237033631055], Loss: 2.059204, Acc:0.800367, Semantic loss: 0.788189, BCE loss: 0.533739, SB loss: 0.737277
2023-10-30 14:34:26,156 Epoch: [266/484] Iter:[110/495], Time: 0.37, lr: [0.0048736168170188015], Loss: 2.057521, Acc:0.800471, Semantic loss: 0.784741, BCE loss: 0.534244, SB loss: 0.738536
2023-10-30 14:34:29,762 Epoch: [266/484] Iter:[120/495], Time: 0.37, lr: [0.004873209926900024], Loss: 2.059710, Acc:0.796205, Semantic loss: 0.787521, BCE loss: 0.532906, SB loss: 0.739284
2023-10-30 14:34:33,417 Epoch: [266/484] Iter:[130/495], Time: 0.37, lr: [0.004872803033006388], Loss: 2.060906, Acc:0.791867, Semantic loss: 0.788944, BCE loss: 0.528905, SB loss: 0.743056
2023-10-30 14:34:36,976 Epoch: [266/484] Iter:[140/495], Time: 0.37, lr: [0.004872396135337508], Loss: 2.063762, Acc:0.791654, Semantic loss: 0.789203, BCE loss: 0.529665, SB loss: 0.744894
2023-10-30 14:34:40,573 Epoch: [266/484] Iter:[150/495], Time: 0.37, lr: [0.004871989233893], Loss: 2.061835, Acc:0.789471, Semantic loss: 0.786746, BCE loss: 0.529131, SB loss: 0.745958
2023-10-30 14:34:44,151 Epoch: [266/484] Iter:[160/495], Time: 0.37, lr: [0.004871582328672475], Loss: 2.060164, Acc:0.787026, Semantic loss: 0.786735, BCE loss: 0.528908, SB loss: 0.744521
2023-10-30 14:34:47,754 Epoch: [266/484] Iter:[170/495], Time: 0.37, lr: [0.004871175419675551], Loss: 2.061487, Acc:0.785756, Semantic loss: 0.785586, BCE loss: 0.529429, SB loss: 0.746472
2023-10-30 14:34:51,304 Epoch: [266/484] Iter:[180/495], Time: 0.37, lr: [0.004870768506901842], Loss: 2.062280, Acc:0.784761, Semantic loss: 0.788178, BCE loss: 0.528964, SB loss: 0.745137
2023-10-30 14:34:54,961 Epoch: [266/484] Iter:[190/495], Time: 0.37, lr: [0.004870361590350962], Loss: 2.061311, Acc:0.785235, Semantic loss: 0.788001, BCE loss: 0.526483, SB loss: 0.746827
2023-10-30 14:34:58,571 Epoch: [266/484] Iter:[200/495], Time: 0.37, lr: [0.004869954670022524], Loss: 2.067580, Acc:0.786412, Semantic loss: 0.789158, BCE loss: 0.532445, SB loss: 0.745978
2023-10-30 14:35:02,306 Epoch: [266/484] Iter:[210/495], Time: 0.37, lr: [0.004869547745916143], Loss: 2.065654, Acc:0.786225, Semantic loss: 0.789908, BCE loss: 0.529369, SB loss: 0.746377
2023-10-30 14:35:05,912 Epoch: [266/484] Iter:[220/495], Time: 0.37, lr: [0.004869140818031434], Loss: 2.068348, Acc:0.786720, Semantic loss: 0.790661, BCE loss: 0.531521, SB loss: 0.746167
2023-10-30 14:35:09,566 Epoch: [266/484] Iter:[230/495], Time: 0.37, lr: [0.004868733886368011], Loss: 2.063808, Acc:0.788915, Semantic loss: 0.786239, BCE loss: 0.533023, SB loss: 0.744546
2023-10-30 14:35:13,302 Epoch: [266/484] Iter:[240/495], Time: 0.37, lr: [0.004868326950925486], Loss: 2.070178, Acc:0.791069, Semantic loss: 0.787290, BCE loss: 0.537161, SB loss: 0.745727
2023-10-30 14:35:16,943 Epoch: [266/484] Iter:[250/495], Time: 0.37, lr: [0.004867920011703475], Loss: 2.068212, Acc:0.790133, Semantic loss: 0.785635, BCE loss: 0.535972, SB loss: 0.746605
2023-10-30 14:35:20,552 Epoch: [266/484] Iter:[260/495], Time: 0.37, lr: [0.004867513068701592], Loss: 2.061032, Acc:0.790213, Semantic loss: 0.780451, BCE loss: 0.535766, SB loss: 0.744815
2023-10-30 14:35:24,180 Epoch: [266/484] Iter:[270/495], Time: 0.37, lr: [0.004867106121919449], Loss: 2.054375, Acc:0.791317, Semantic loss: 0.776638, BCE loss: 0.534838, SB loss: 0.742899
2023-10-30 14:35:27,762 Epoch: [266/484] Iter:[280/495], Time: 0.37, lr: [0.00486669917135666], Loss: 2.052882, Acc:0.790415, Semantic loss: 0.776068, BCE loss: 0.533833, SB loss: 0.742982
2023-10-30 14:35:31,366 Epoch: [266/484] Iter:[290/495], Time: 0.37, lr: [0.0048662922170128395], Loss: 2.049266, Acc:0.790456, Semantic loss: 0.773784, BCE loss: 0.533724, SB loss: 0.741758
2023-10-30 14:35:34,918 Epoch: [266/484] Iter:[300/495], Time: 0.36, lr: [0.004865885258887602], Loss: 2.048630, Acc:0.790391, Semantic loss: 0.773840, BCE loss: 0.533243, SB loss: 0.741547
2023-10-30 14:35:38,642 Epoch: [266/484] Iter:[310/495], Time: 0.37, lr: [0.0048654782969805585], Loss: 2.048816, Acc:0.791273, Semantic loss: 0.775028, BCE loss: 0.532072, SB loss: 0.741717
2023-10-30 14:35:42,340 Epoch: [266/484] Iter:[320/495], Time: 0.37, lr: [0.004865071331291323], Loss: 2.044702, Acc:0.790556, Semantic loss: 0.773752, BCE loss: 0.530360, SB loss: 0.740590
2023-10-30 14:35:45,987 Epoch: [266/484] Iter:[330/495], Time: 0.37, lr: [0.00486466436181951], Loss: 2.044768, Acc:0.789878, Semantic loss: 0.775852, BCE loss: 0.528495, SB loss: 0.740421
2023-10-30 14:35:49,721 Epoch: [266/484] Iter:[340/495], Time: 0.37, lr: [0.004864257388564733], Loss: 2.041210, Acc:0.789544, Semantic loss: 0.774244, BCE loss: 0.528255, SB loss: 0.738711
2023-10-30 14:35:53,396 Epoch: [266/484] Iter:[350/495], Time: 0.37, lr: [0.004863850411526604], Loss: 2.038958, Acc:0.788622, Semantic loss: 0.772912, BCE loss: 0.527276, SB loss: 0.738771
2023-10-30 14:35:57,090 Epoch: [266/484] Iter:[360/495], Time: 0.37, lr: [0.004863443430704735], Loss: 2.037033, Acc:0.789889, Semantic loss: 0.771306, BCE loss: 0.528011, SB loss: 0.737717
2023-10-30 14:36:00,684 Epoch: [266/484] Iter:[370/495], Time: 0.37, lr: [0.004863036446098741], Loss: 2.040823, Acc:0.790372, Semantic loss: 0.772461, BCE loss: 0.529640, SB loss: 0.738722
2023-10-30 14:36:04,300 Epoch: [266/484] Iter:[380/495], Time: 0.37, lr: [0.004862629457708234], Loss: 2.040540, Acc:0.790031, Semantic loss: 0.771496, BCE loss: 0.529653, SB loss: 0.739391
2023-10-30 14:36:07,977 Epoch: [266/484] Iter:[390/495], Time: 0.37, lr: [0.004862222465532829], Loss: 2.042396, Acc:0.790713, Semantic loss: 0.773623, BCE loss: 0.529290, SB loss: 0.739483
2023-10-30 14:36:11,626 Epoch: [266/484] Iter:[400/495], Time: 0.37, lr: [0.004861815469572135], Loss: 2.041221, Acc:0.790615, Semantic loss: 0.773290, BCE loss: 0.528825, SB loss: 0.739105
2023-10-30 14:36:15,306 Epoch: [266/484] Iter:[410/495], Time: 0.37, lr: [0.004861408469825766], Loss: 2.041257, Acc:0.791269, Semantic loss: 0.773593, BCE loss: 0.528379, SB loss: 0.739284
2023-10-30 14:36:19,017 Epoch: [266/484] Iter:[420/495], Time: 0.37, lr: [0.0048610014662933375], Loss: 2.045330, Acc:0.790849, Semantic loss: 0.776807, BCE loss: 0.528509, SB loss: 0.740014
2023-10-30 14:36:22,771 Epoch: [266/484] Iter:[430/495], Time: 0.37, lr: [0.0048605944589744585], Loss: 2.047933, Acc:0.791041, Semantic loss: 0.778510, BCE loss: 0.529018, SB loss: 0.740405
2023-10-30 14:36:26,438 Epoch: [266/484] Iter:[440/495], Time: 0.37, lr: [0.004860187447868742], Loss: 2.047640, Acc:0.791470, Semantic loss: 0.777911, BCE loss: 0.529423, SB loss: 0.740305
2023-10-30 14:36:30,285 Epoch: [266/484] Iter:[450/495], Time: 0.37, lr: [0.004859780432975802], Loss: 2.044718, Acc:0.790971, Semantic loss: 0.776488, BCE loss: 0.527954, SB loss: 0.740277
2023-10-30 14:36:34,004 Epoch: [266/484] Iter:[460/495], Time: 0.37, lr: [0.00485937341429525], Loss: 2.044327, Acc:0.790609, Semantic loss: 0.776377, BCE loss: 0.527555, SB loss: 0.740396
2023-10-30 14:36:37,677 Epoch: [266/484] Iter:[470/495], Time: 0.37, lr: [0.004858966391826699], Loss: 2.042973, Acc:0.791195, Semantic loss: 0.776006, BCE loss: 0.527197, SB loss: 0.739771
2023-10-30 14:36:41,277 Epoch: [266/484] Iter:[480/495], Time: 0.37, lr: [0.0048585593655697595], Loss: 2.039023, Acc:0.791127, Semantic loss: 0.774182, BCE loss: 0.525468, SB loss: 0.739373
2023-10-30 14:36:44,734 Epoch: [266/484] Iter:[490/495], Time: 0.37, lr: [0.0048581523355240444], Loss: 2.037715, Acc:0.790680, Semantic loss: 0.773680, BCE loss: 0.524739, SB loss: 0.739297
2023-10-30 14:36:46,147 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:36:46,380 Loss: 2.027, MeanIU:  0.6806, Best_mIoU:  0.7151
2023-10-30 14:36:46,381 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692]
2023-10-30 14:36:48,301 Epoch: [267/484] Iter:[0/495], Time: 1.89, lr: [0.004857948819080275], Loss: 1.807776, Acc:0.898480, Semantic loss: 0.658005, BCE loss: 0.425492, SB loss: 0.724279
2023-10-30 14:36:52,296 Epoch: [267/484] Iter:[10/495], Time: 0.53, lr: [0.00485754178335067], Loss: 2.041108, Acc:0.828339, Semantic loss: 0.771049, BCE loss: 0.542735, SB loss: 0.727324
2023-10-30 14:36:55,921 Epoch: [267/484] Iter:[20/495], Time: 0.45, lr: [0.004857134743831318], Loss: 2.115853, Acc:0.841048, Semantic loss: 0.820998, BCE loss: 0.544625, SB loss: 0.750230
2023-10-30 14:36:59,574 Epoch: [267/484] Iter:[30/495], Time: 0.42, lr: [0.004856727700521833], Loss: 2.082708, Acc:0.822439, Semantic loss: 0.814922, BCE loss: 0.521897, SB loss: 0.745888
2023-10-30 14:37:03,288 Epoch: [267/484] Iter:[40/495], Time: 0.41, lr: [0.004856320653421826], Loss: 2.054026, Acc:0.812609, Semantic loss: 0.784939, BCE loss: 0.524842, SB loss: 0.744244
2023-10-30 14:37:07,056 Epoch: [267/484] Iter:[50/495], Time: 0.40, lr: [0.00485591360253091], Loss: 2.032627, Acc:0.811464, Semantic loss: 0.771201, BCE loss: 0.521381, SB loss: 0.740045
2023-10-30 14:37:10,731 Epoch: [267/484] Iter:[60/495], Time: 0.40, lr: [0.0048555065478486925], Loss: 2.034901, Acc:0.817753, Semantic loss: 0.762496, BCE loss: 0.535160, SB loss: 0.737245
2023-10-30 14:37:14,364 Epoch: [267/484] Iter:[70/495], Time: 0.39, lr: [0.00485509948937479], Loss: 2.034794, Acc:0.811197, Semantic loss: 0.764239, BCE loss: 0.535535, SB loss: 0.735020
2023-10-30 14:37:17,991 Epoch: [267/484] Iter:[80/495], Time: 0.39, lr: [0.004854692427108811], Loss: 2.032395, Acc:0.806197, Semantic loss: 0.767676, BCE loss: 0.529040, SB loss: 0.735678
2023-10-30 14:37:21,606 Epoch: [267/484] Iter:[90/495], Time: 0.39, lr: [0.004854285361050368], Loss: 2.033182, Acc:0.800254, Semantic loss: 0.769368, BCE loss: 0.526367, SB loss: 0.737447
2023-10-30 14:37:25,318 Epoch: [267/484] Iter:[100/495], Time: 0.39, lr: [0.00485387829119907], Loss: 2.018639, Acc:0.800761, Semantic loss: 0.762481, BCE loss: 0.521733, SB loss: 0.734425
2023-10-30 14:37:29,029 Epoch: [267/484] Iter:[110/495], Time: 0.38, lr: [0.004853471217554532], Loss: 2.020182, Acc:0.797634, Semantic loss: 0.766002, BCE loss: 0.520696, SB loss: 0.733484
2023-10-30 14:37:32,643 Epoch: [267/484] Iter:[120/495], Time: 0.38, lr: [0.004853064140116364], Loss: 2.034089, Acc:0.798443, Semantic loss: 0.771498, BCE loss: 0.524606, SB loss: 0.737985
2023-10-30 14:37:36,299 Epoch: [267/484] Iter:[130/495], Time: 0.38, lr: [0.004852657058884176], Loss: 2.033719, Acc:0.796851, Semantic loss: 0.769945, BCE loss: 0.525391, SB loss: 0.738383
2023-10-30 14:37:40,032 Epoch: [267/484] Iter:[140/495], Time: 0.38, lr: [0.004852249973857577], Loss: 2.041844, Acc:0.796078, Semantic loss: 0.772189, BCE loss: 0.529411, SB loss: 0.740244
2023-10-30 14:37:43,740 Epoch: [267/484] Iter:[150/495], Time: 0.38, lr: [0.004851842885036183], Loss: 2.043500, Acc:0.798918, Semantic loss: 0.772359, BCE loss: 0.532205, SB loss: 0.738936
2023-10-30 14:37:47,429 Epoch: [267/484] Iter:[160/495], Time: 0.38, lr: [0.004851435792419602], Loss: 2.035193, Acc:0.798754, Semantic loss: 0.767542, BCE loss: 0.530588, SB loss: 0.737063
2023-10-30 14:37:51,057 Epoch: [267/484] Iter:[170/495], Time: 0.38, lr: [0.004851028696007444], Loss: 2.039784, Acc:0.799693, Semantic loss: 0.769884, BCE loss: 0.531137, SB loss: 0.738763
2023-10-30 14:37:54,677 Epoch: [267/484] Iter:[180/495], Time: 0.38, lr: [0.00485062159579932], Loss: 2.030190, Acc:0.799294, Semantic loss: 0.766041, BCE loss: 0.526425, SB loss: 0.737724
2023-10-30 14:37:58,365 Epoch: [267/484] Iter:[190/495], Time: 0.38, lr: [0.004850214491794842], Loss: 2.027536, Acc:0.799076, Semantic loss: 0.766276, BCE loss: 0.524153, SB loss: 0.737107
2023-10-30 14:38:01,990 Epoch: [267/484] Iter:[200/495], Time: 0.38, lr: [0.00484980738399362], Loss: 2.024779, Acc:0.798914, Semantic loss: 0.763699, BCE loss: 0.524479, SB loss: 0.736601
2023-10-30 14:38:05,698 Epoch: [267/484] Iter:[210/495], Time: 0.38, lr: [0.004849400272395264], Loss: 2.019849, Acc:0.800053, Semantic loss: 0.760059, BCE loss: 0.525149, SB loss: 0.734640
2023-10-30 14:38:09,369 Epoch: [267/484] Iter:[220/495], Time: 0.38, lr: [0.004848993156999384], Loss: 2.021133, Acc:0.800938, Semantic loss: 0.759192, BCE loss: 0.528603, SB loss: 0.733338
2023-10-30 14:38:13,053 Epoch: [267/484] Iter:[230/495], Time: 0.38, lr: [0.004848586037805591], Loss: 2.020614, Acc:0.798852, Semantic loss: 0.758889, BCE loss: 0.528959, SB loss: 0.732766
2023-10-30 14:38:16,650 Epoch: [267/484] Iter:[240/495], Time: 0.37, lr: [0.004848178914813496], Loss: 2.019845, Acc:0.799277, Semantic loss: 0.759216, BCE loss: 0.527979, SB loss: 0.732650
2023-10-30 14:38:20,392 Epoch: [267/484] Iter:[250/495], Time: 0.37, lr: [0.004847771788022708], Loss: 2.019349, Acc:0.799740, Semantic loss: 0.757853, BCE loss: 0.529884, SB loss: 0.731611
2023-10-30 14:38:24,039 Epoch: [267/484] Iter:[260/495], Time: 0.37, lr: [0.004847364657432836], Loss: 2.025356, Acc:0.800347, Semantic loss: 0.762128, BCE loss: 0.531374, SB loss: 0.731854
2023-10-30 14:38:27,752 Epoch: [267/484] Iter:[270/495], Time: 0.37, lr: [0.004846957523043493], Loss: 2.025921, Acc:0.800223, Semantic loss: 0.761540, BCE loss: 0.531854, SB loss: 0.732527
2023-10-30 14:38:31,477 Epoch: [267/484] Iter:[280/495], Time: 0.37, lr: [0.004846550384854287], Loss: 2.024744, Acc:0.799685, Semantic loss: 0.760620, BCE loss: 0.530140, SB loss: 0.733983
2023-10-30 14:38:35,163 Epoch: [267/484] Iter:[290/495], Time: 0.37, lr: [0.004846143242864829], Loss: 2.025056, Acc:0.799365, Semantic loss: 0.759200, BCE loss: 0.531102, SB loss: 0.734755
2023-10-30 14:38:38,799 Epoch: [267/484] Iter:[300/495], Time: 0.37, lr: [0.004845736097074726], Loss: 2.026545, Acc:0.797718, Semantic loss: 0.760236, BCE loss: 0.530751, SB loss: 0.735557
2023-10-30 14:38:42,486 Epoch: [267/484] Iter:[310/495], Time: 0.37, lr: [0.00484532894748359], Loss: 2.027587, Acc:0.798242, Semantic loss: 0.760545, BCE loss: 0.531578, SB loss: 0.735463
2023-10-30 14:38:46,204 Epoch: [267/484] Iter:[320/495], Time: 0.37, lr: [0.004844921794091031], Loss: 2.025688, Acc:0.797739, Semantic loss: 0.759581, BCE loss: 0.530534, SB loss: 0.735573
2023-10-30 14:38:49,877 Epoch: [267/484] Iter:[330/495], Time: 0.37, lr: [0.004844514636896657], Loss: 2.026145, Acc:0.797685, Semantic loss: 0.759577, BCE loss: 0.531466, SB loss: 0.735102
2023-10-30 14:38:53,567 Epoch: [267/484] Iter:[340/495], Time: 0.37, lr: [0.004844107475900078], Loss: 2.026037, Acc:0.797296, Semantic loss: 0.759010, BCE loss: 0.531978, SB loss: 0.735048
2023-10-30 14:38:57,237 Epoch: [267/484] Iter:[350/495], Time: 0.37, lr: [0.004843700311100906], Loss: 2.028531, Acc:0.797692, Semantic loss: 0.760505, BCE loss: 0.532147, SB loss: 0.735880
2023-10-30 14:39:01,003 Epoch: [267/484] Iter:[360/495], Time: 0.37, lr: [0.004843293142498746], Loss: 2.027800, Acc:0.797613, Semantic loss: 0.760037, BCE loss: 0.532595, SB loss: 0.735169
2023-10-30 14:39:04,826 Epoch: [267/484] Iter:[370/495], Time: 0.37, lr: [0.00484288597009321], Loss: 2.028748, Acc:0.797473, Semantic loss: 0.762478, BCE loss: 0.531413, SB loss: 0.734856
2023-10-30 14:39:08,478 Epoch: [267/484] Iter:[380/495], Time: 0.37, lr: [0.004842478793883905], Loss: 2.028280, Acc:0.796560, Semantic loss: 0.762664, BCE loss: 0.530566, SB loss: 0.735050
2023-10-30 14:39:12,190 Epoch: [267/484] Iter:[390/495], Time: 0.37, lr: [0.004842071613870442], Loss: 2.026545, Acc:0.796589, Semantic loss: 0.762291, BCE loss: 0.529093, SB loss: 0.735162
2023-10-30 14:39:15,899 Epoch: [267/484] Iter:[400/495], Time: 0.37, lr: [0.00484166443005243], Loss: 2.021953, Acc:0.797025, Semantic loss: 0.759522, BCE loss: 0.527563, SB loss: 0.734868
2023-10-30 14:39:19,520 Epoch: [267/484] Iter:[410/495], Time: 0.37, lr: [0.004841257242429477], Loss: 2.024073, Acc:0.797852, Semantic loss: 0.760101, BCE loss: 0.529507, SB loss: 0.734466
2023-10-30 14:39:23,134 Epoch: [267/484] Iter:[420/495], Time: 0.37, lr: [0.004840850051001192], Loss: 2.024250, Acc:0.797961, Semantic loss: 0.760750, BCE loss: 0.529200, SB loss: 0.734299
2023-10-30 14:39:26,843 Epoch: [267/484] Iter:[430/495], Time: 0.37, lr: [0.004840442855767184], Loss: 2.022730, Acc:0.797772, Semantic loss: 0.760033, BCE loss: 0.528217, SB loss: 0.734479
2023-10-30 14:39:30,550 Epoch: [267/484] Iter:[440/495], Time: 0.37, lr: [0.004840035656727063], Loss: 2.027377, Acc:0.797914, Semantic loss: 0.762667, BCE loss: 0.529617, SB loss: 0.735093
2023-10-30 14:39:34,222 Epoch: [267/484] Iter:[450/495], Time: 0.37, lr: [0.004839628453880435], Loss: 2.030456, Acc:0.797583, Semantic loss: 0.764931, BCE loss: 0.529948, SB loss: 0.735578
2023-10-30 14:39:37,797 Epoch: [267/484] Iter:[460/495], Time: 0.37, lr: [0.004839221247226909], Loss: 2.026539, Acc:0.798088, Semantic loss: 0.762048, BCE loss: 0.529361, SB loss: 0.735130
2023-10-30 14:39:41,452 Epoch: [267/484] Iter:[470/495], Time: 0.37, lr: [0.0048388140367660966], Loss: 2.024956, Acc:0.797180, Semantic loss: 0.761558, BCE loss: 0.528348, SB loss: 0.735050
2023-10-30 14:39:45,250 Epoch: [267/484] Iter:[480/495], Time: 0.37, lr: [0.004838406822497603], Loss: 2.024142, Acc:0.797740, Semantic loss: 0.760509, BCE loss: 0.528642, SB loss: 0.734991
2023-10-30 14:39:48,899 Epoch: [267/484] Iter:[490/495], Time: 0.37, lr: [0.0048379996044210375], Loss: 2.027179, Acc:0.798534, Semantic loss: 0.761129, BCE loss: 0.531006, SB loss: 0.735045
2023-10-30 14:39:50,297 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:39:50,533 Loss: 2.027, MeanIU:  0.6806, Best_mIoU:  0.7151
2023-10-30 14:39:50,533 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692]
2023-10-30 14:39:52,358 Epoch: [268/484] Iter:[0/495], Time: 1.80, lr: [0.004837795993954604], Loss: 1.974287, Acc:0.854719, Semantic loss: 0.659045, BCE loss: 0.634560, SB loss: 0.680681
2023-10-30 14:39:56,282 Epoch: [268/484] Iter:[10/495], Time: 0.52, lr: [0.004837388770165196], Loss: 2.203173, Acc:0.793156, Semantic loss: 0.861694, BCE loss: 0.587479, SB loss: 0.754000
2023-10-30 14:39:59,913 Epoch: [268/484] Iter:[20/495], Time: 0.45, lr: [0.004836981542566738], Loss: 2.190737, Acc:0.786866, Semantic loss: 0.830726, BCE loss: 0.580933, SB loss: 0.779078
2023-10-30 14:40:03,566 Epoch: [268/484] Iter:[30/495], Time: 0.42, lr: [0.0048365743111588345], Loss: 2.128480, Acc:0.782109, Semantic loss: 0.804267, BCE loss: 0.558496, SB loss: 0.765718
2023-10-30 14:40:07,210 Epoch: [268/484] Iter:[40/495], Time: 0.41, lr: [0.004836167075941095], Loss: 2.089939, Acc:0.781590, Semantic loss: 0.786673, BCE loss: 0.539595, SB loss: 0.763671
2023-10-30 14:40:10,877 Epoch: [268/484] Iter:[50/495], Time: 0.40, lr: [0.004835759836913129], Loss: 2.079719, Acc:0.787501, Semantic loss: 0.778084, BCE loss: 0.547288, SB loss: 0.754347
2023-10-30 14:40:14,533 Epoch: [268/484] Iter:[60/495], Time: 0.39, lr: [0.004835352594074543], Loss: 2.061102, Acc:0.790433, Semantic loss: 0.773786, BCE loss: 0.538166, SB loss: 0.749150
2023-10-30 14:40:18,194 Epoch: [268/484] Iter:[70/495], Time: 0.39, lr: [0.004834945347424946], Loss: 2.055834, Acc:0.789086, Semantic loss: 0.776099, BCE loss: 0.529831, SB loss: 0.749904
2023-10-30 14:40:21,842 Epoch: [268/484] Iter:[80/495], Time: 0.39, lr: [0.004834538096963943], Loss: 2.053380, Acc:0.791712, Semantic loss: 0.774670, BCE loss: 0.533669, SB loss: 0.745041
2023-10-30 14:40:25,471 Epoch: [268/484] Iter:[90/495], Time: 0.38, lr: [0.004834130842691144], Loss: 2.039570, Acc:0.790263, Semantic loss: 0.766461, BCE loss: 0.529916, SB loss: 0.743193
2023-10-30 14:40:29,067 Epoch: [268/484] Iter:[100/495], Time: 0.38, lr: [0.004833723584606156], Loss: 2.045914, Acc:0.788272, Semantic loss: 0.775171, BCE loss: 0.530640, SB loss: 0.740103
2023-10-30 14:40:32,710 Epoch: [268/484] Iter:[110/495], Time: 0.38, lr: [0.004833316322708586], Loss: 2.038287, Acc:0.788180, Semantic loss: 0.770607, BCE loss: 0.526654, SB loss: 0.741026
2023-10-30 14:40:36,369 Epoch: [268/484] Iter:[120/495], Time: 0.38, lr: [0.004832909056998041], Loss: 2.026556, Acc:0.787171, Semantic loss: 0.764929, BCE loss: 0.521061, SB loss: 0.740566
2023-10-30 14:40:40,040 Epoch: [268/484] Iter:[130/495], Time: 0.38, lr: [0.00483250178747413], Loss: 2.023968, Acc:0.786055, Semantic loss: 0.763582, BCE loss: 0.519291, SB loss: 0.741095
2023-10-30 14:40:43,741 Epoch: [268/484] Iter:[140/495], Time: 0.38, lr: [0.004832094514136458], Loss: 2.026406, Acc:0.789543, Semantic loss: 0.763180, BCE loss: 0.522634, SB loss: 0.740592
2023-10-30 14:40:47,500 Epoch: [268/484] Iter:[150/495], Time: 0.38, lr: [0.004831687236984634], Loss: 2.022782, Acc:0.792012, Semantic loss: 0.763165, BCE loss: 0.520994, SB loss: 0.738623
2023-10-30 14:40:51,094 Epoch: [268/484] Iter:[160/495], Time: 0.38, lr: [0.004831279956018263], Loss: 2.026350, Acc:0.792521, Semantic loss: 0.763953, BCE loss: 0.524101, SB loss: 0.738297
2023-10-30 14:40:54,774 Epoch: [268/484] Iter:[170/495], Time: 0.38, lr: [0.004830872671236953], Loss: 2.027175, Acc:0.792176, Semantic loss: 0.765596, BCE loss: 0.524725, SB loss: 0.736854
2023-10-30 14:40:58,456 Epoch: [268/484] Iter:[180/495], Time: 0.38, lr: [0.004830465382640312], Loss: 2.020191, Acc:0.790722, Semantic loss: 0.762292, BCE loss: 0.522345, SB loss: 0.735555
2023-10-30 14:41:02,139 Epoch: [268/484] Iter:[190/495], Time: 0.37, lr: [0.004830058090227946], Loss: 2.020803, Acc:0.792176, Semantic loss: 0.762548, BCE loss: 0.522471, SB loss: 0.735785
2023-10-30 14:41:05,756 Epoch: [268/484] Iter:[200/495], Time: 0.37, lr: [0.00482965079399946], Loss: 2.015894, Acc:0.792952, Semantic loss: 0.759773, BCE loss: 0.521510, SB loss: 0.734611
2023-10-30 14:41:09,398 Epoch: [268/484] Iter:[210/495], Time: 0.37, lr: [0.004829243493954464], Loss: 2.011708, Acc:0.794800, Semantic loss: 0.757656, BCE loss: 0.521365, SB loss: 0.732687
2023-10-30 14:41:12,948 Epoch: [268/484] Iter:[220/495], Time: 0.37, lr: [0.004828836190092562], Loss: 2.005405, Acc:0.792686, Semantic loss: 0.754851, BCE loss: 0.517366, SB loss: 0.733187
2023-10-30 14:41:16,633 Epoch: [268/484] Iter:[230/495], Time: 0.37, lr: [0.004828428882413361], Loss: 2.007451, Acc:0.793152, Semantic loss: 0.754999, BCE loss: 0.519511, SB loss: 0.732940
2023-10-30 14:41:20,362 Epoch: [268/484] Iter:[240/495], Time: 0.37, lr: [0.004828021570916467], Loss: 2.010587, Acc:0.791476, Semantic loss: 0.759033, BCE loss: 0.516939, SB loss: 0.734616
2023-10-30 14:41:24,029 Epoch: [268/484] Iter:[250/495], Time: 0.37, lr: [0.004827614255601489], Loss: 2.011662, Acc:0.791735, Semantic loss: 0.761045, BCE loss: 0.515624, SB loss: 0.734993
2023-10-30 14:41:27,747 Epoch: [268/484] Iter:[260/495], Time: 0.37, lr: [0.00482720693646803], Loss: 2.013652, Acc:0.791525, Semantic loss: 0.762686, BCE loss: 0.515861, SB loss: 0.735106
2023-10-30 14:41:31,370 Epoch: [268/484] Iter:[270/495], Time: 0.37, lr: [0.004826799613515698], Loss: 2.006843, Acc:0.792462, Semantic loss: 0.758440, BCE loss: 0.515261, SB loss: 0.733141
2023-10-30 14:41:35,124 Epoch: [268/484] Iter:[280/495], Time: 0.37, lr: [0.004826392286744099], Loss: 2.005960, Acc:0.793828, Semantic loss: 0.758077, BCE loss: 0.514725, SB loss: 0.733158
2023-10-30 14:41:38,736 Epoch: [268/484] Iter:[290/495], Time: 0.37, lr: [0.004825984956152838], Loss: 2.012956, Acc:0.793508, Semantic loss: 0.764360, BCE loss: 0.513444, SB loss: 0.735152
2023-10-30 14:41:42,438 Epoch: [268/484] Iter:[300/495], Time: 0.37, lr: [0.004825577621741522], Loss: 2.017355, Acc:0.793309, Semantic loss: 0.767337, BCE loss: 0.513635, SB loss: 0.736383
2023-10-30 14:41:46,094 Epoch: [268/484] Iter:[310/495], Time: 0.37, lr: [0.004825170283509757], Loss: 2.017082, Acc:0.792465, Semantic loss: 0.765868, BCE loss: 0.514930, SB loss: 0.736284
2023-10-30 14:41:49,740 Epoch: [268/484] Iter:[320/495], Time: 0.37, lr: [0.004824762941457147], Loss: 2.010787, Acc:0.792983, Semantic loss: 0.760964, BCE loss: 0.515104, SB loss: 0.734719
2023-10-30 14:41:53,320 Epoch: [268/484] Iter:[330/495], Time: 0.37, lr: [0.0048243555955833], Loss: 2.011643, Acc:0.793338, Semantic loss: 0.761044, BCE loss: 0.516383, SB loss: 0.734216
2023-10-30 14:41:57,031 Epoch: [268/484] Iter:[340/495], Time: 0.37, lr: [0.004823948245887821], Loss: 2.013626, Acc:0.793830, Semantic loss: 0.761710, BCE loss: 0.517211, SB loss: 0.734704
2023-10-30 14:42:00,702 Epoch: [268/484] Iter:[350/495], Time: 0.37, lr: [0.004823540892370315], Loss: 2.013287, Acc:0.793778, Semantic loss: 0.760976, BCE loss: 0.517235, SB loss: 0.735076
2023-10-30 14:42:04,392 Epoch: [268/484] Iter:[360/495], Time: 0.37, lr: [0.004823133535030387], Loss: 2.014601, Acc:0.794533, Semantic loss: 0.760627, BCE loss: 0.518789, SB loss: 0.735185
2023-10-30 14:42:08,020 Epoch: [268/484] Iter:[370/495], Time: 0.37, lr: [0.0048227261738676445], Loss: 2.013208, Acc:0.793751, Semantic loss: 0.759992, BCE loss: 0.518879, SB loss: 0.734338
2023-10-30 14:42:11,654 Epoch: [268/484] Iter:[380/495], Time: 0.37, lr: [0.004822318808881691], Loss: 2.009145, Acc:0.794290, Semantic loss: 0.758190, BCE loss: 0.518594, SB loss: 0.732362
2023-10-30 14:42:15,306 Epoch: [268/484] Iter:[390/495], Time: 0.37, lr: [0.0048219114400721306], Loss: 2.017464, Acc:0.794630, Semantic loss: 0.764905, BCE loss: 0.518428, SB loss: 0.734131
2023-10-30 14:42:19,135 Epoch: [268/484] Iter:[400/495], Time: 0.37, lr: [0.004821504067438572], Loss: 2.023190, Acc:0.795037, Semantic loss: 0.766116, BCE loss: 0.521513, SB loss: 0.735561
2023-10-30 14:42:22,942 Epoch: [268/484] Iter:[410/495], Time: 0.37, lr: [0.0048210966909806195], Loss: 2.025600, Acc:0.794749, Semantic loss: 0.767002, BCE loss: 0.522575, SB loss: 0.736024
2023-10-30 14:42:26,597 Epoch: [268/484] Iter:[420/495], Time: 0.37, lr: [0.004820689310697876], Loss: 2.027046, Acc:0.794723, Semantic loss: 0.766867, BCE loss: 0.523645, SB loss: 0.736534
2023-10-30 14:42:30,334 Epoch: [268/484] Iter:[430/495], Time: 0.37, lr: [0.004820281926589946], Loss: 2.027193, Acc:0.795375, Semantic loss: 0.765707, BCE loss: 0.525423, SB loss: 0.736063
2023-10-30 14:42:34,091 Epoch: [268/484] Iter:[440/495], Time: 0.37, lr: [0.004819874538656438], Loss: 2.029500, Acc:0.796134, Semantic loss: 0.766015, BCE loss: 0.526961, SB loss: 0.736523
2023-10-30 14:42:37,787 Epoch: [268/484] Iter:[450/495], Time: 0.37, lr: [0.004819467146896954], Loss: 2.033489, Acc:0.796911, Semantic loss: 0.767917, BCE loss: 0.528149, SB loss: 0.737423
2023-10-30 14:42:41,417 Epoch: [268/484] Iter:[460/495], Time: 0.37, lr: [0.0048190597513111], Loss: 2.035113, Acc:0.796822, Semantic loss: 0.769017, BCE loss: 0.528471, SB loss: 0.737625
2023-10-30 14:42:45,101 Epoch: [268/484] Iter:[470/495], Time: 0.37, lr: [0.00481865235189848], Loss: 2.037275, Acc:0.797205, Semantic loss: 0.769351, BCE loss: 0.530210, SB loss: 0.737715
2023-10-30 14:42:48,858 Epoch: [268/484] Iter:[480/495], Time: 0.37, lr: [0.004818244948658698], Loss: 2.036893, Acc:0.796100, Semantic loss: 0.769587, BCE loss: 0.529185, SB loss: 0.738120
2023-10-30 14:42:52,344 Epoch: [268/484] Iter:[490/495], Time: 0.37, lr: [0.00481783754159136], Loss: 2.034768, Acc:0.795694, Semantic loss: 0.768371, BCE loss: 0.528829, SB loss: 0.737568
2023-10-30 14:42:53,729 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:42:53,971 Loss: 2.027, MeanIU:  0.6806, Best_mIoU:  0.7151
2023-10-30 14:42:53,971 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692]
2023-10-30 14:42:55,964 Epoch: [269/484] Iter:[0/495], Time: 1.96, lr: [0.004817633836622232], Loss: 2.454712, Acc:0.700396, Semantic loss: 0.993351, BCE loss: 0.643377, SB loss: 0.817984
2023-10-30 14:42:59,833 Epoch: [269/484] Iter:[10/495], Time: 0.53, lr: [0.004817226423812817], Loss: 2.147144, Acc:0.762395, Semantic loss: 0.869286, BCE loss: 0.526760, SB loss: 0.751098
2023-10-30 14:43:03,459 Epoch: [269/484] Iter:[20/495], Time: 0.45, lr: [0.004816819007174854], Loss: 2.113657, Acc:0.789692, Semantic loss: 0.819440, BCE loss: 0.557322, SB loss: 0.736895
2023-10-30 14:43:07,113 Epoch: [269/484] Iter:[30/495], Time: 0.42, lr: [0.004816411586707952], Loss: 2.141132, Acc:0.808901, Semantic loss: 0.819792, BCE loss: 0.560373, SB loss: 0.760967
2023-10-30 14:43:10,819 Epoch: [269/484] Iter:[40/495], Time: 0.41, lr: [0.00481600416241171], Loss: 2.095449, Acc:0.810456, Semantic loss: 0.791440, BCE loss: 0.556998, SB loss: 0.747011
2023-10-30 14:43:14,448 Epoch: [269/484] Iter:[50/495], Time: 0.40, lr: [0.004815596734285736], Loss: 2.068569, Acc:0.809096, Semantic loss: 0.778843, BCE loss: 0.549691, SB loss: 0.740035
2023-10-30 14:43:18,064 Epoch: [269/484] Iter:[60/495], Time: 0.39, lr: [0.00481518930232963], Loss: 2.055887, Acc:0.806007, Semantic loss: 0.777582, BCE loss: 0.539780, SB loss: 0.738526
2023-10-30 14:43:21,798 Epoch: [269/484] Iter:[70/495], Time: 0.39, lr: [0.004814781866543], Loss: 2.037761, Acc:0.803902, Semantic loss: 0.768363, BCE loss: 0.534852, SB loss: 0.734545
2023-10-30 14:43:25,483 Epoch: [269/484] Iter:[80/495], Time: 0.39, lr: [0.004814374426925449], Loss: 2.028526, Acc:0.801623, Semantic loss: 0.763151, BCE loss: 0.533627, SB loss: 0.731748
2023-10-30 14:43:29,191 Epoch: [269/484] Iter:[90/495], Time: 0.39, lr: [0.004813966983476579], Loss: 2.027881, Acc:0.798825, Semantic loss: 0.769468, BCE loss: 0.526897, SB loss: 0.731516
2023-10-30 14:43:32,861 Epoch: [269/484] Iter:[100/495], Time: 0.38, lr: [0.004813559536195992], Loss: 2.020028, Acc:0.800334, Semantic loss: 0.765008, BCE loss: 0.525294, SB loss: 0.729726
2023-10-30 14:43:36,513 Epoch: [269/484] Iter:[110/495], Time: 0.38, lr: [0.004813152085083297], Loss: 2.004214, Acc:0.799888, Semantic loss: 0.758466, BCE loss: 0.519972, SB loss: 0.725776
2023-10-30 14:43:40,154 Epoch: [269/484] Iter:[120/495], Time: 0.38, lr: [0.004812744630138094], Loss: 2.018205, Acc:0.801064, Semantic loss: 0.772695, BCE loss: 0.519268, SB loss: 0.726242
2023-10-30 14:43:43,807 Epoch: [269/484] Iter:[130/495], Time: 0.38, lr: [0.004812337171359988], Loss: 2.022283, Acc:0.797886, Semantic loss: 0.772018, BCE loss: 0.522813, SB loss: 0.727452
2023-10-30 14:43:47,539 Epoch: [269/484] Iter:[140/495], Time: 0.38, lr: [0.0048119297087485784], Loss: 2.025780, Acc:0.798888, Semantic loss: 0.771819, BCE loss: 0.524258, SB loss: 0.729703
2023-10-30 14:43:51,205 Epoch: [269/484] Iter:[150/495], Time: 0.38, lr: [0.004811522242303474], Loss: 2.034528, Acc:0.800082, Semantic loss: 0.780341, BCE loss: 0.523376, SB loss: 0.730812
2023-10-30 14:43:54,927 Epoch: [269/484] Iter:[160/495], Time: 0.38, lr: [0.0048111147720242735], Loss: 2.038966, Acc:0.801213, Semantic loss: 0.780366, BCE loss: 0.526551, SB loss: 0.732049
2023-10-30 14:43:58,603 Epoch: [269/484] Iter:[170/495], Time: 0.38, lr: [0.004810707297910583], Loss: 2.046663, Acc:0.799084, Semantic loss: 0.784582, BCE loss: 0.528658, SB loss: 0.733423
2023-10-30 14:44:02,268 Epoch: [269/484] Iter:[180/495], Time: 0.38, lr: [0.004810299819962004], Loss: 2.043782, Acc:0.797337, Semantic loss: 0.784598, BCE loss: 0.525142, SB loss: 0.734042
2023-10-30 14:44:06,107 Epoch: [269/484] Iter:[190/495], Time: 0.38, lr: [0.0048098923381781405], Loss: 2.038434, Acc:0.797555, Semantic loss: 0.782529, BCE loss: 0.522315, SB loss: 0.733589
2023-10-30 14:44:09,767 Epoch: [269/484] Iter:[200/495], Time: 0.38, lr: [0.004809484852558594], Loss: 2.040548, Acc:0.797980, Semantic loss: 0.780286, BCE loss: 0.525400, SB loss: 0.734862
2023-10-30 14:44:13,474 Epoch: [269/484] Iter:[210/495], Time: 0.38, lr: [0.004809077363102968], Loss: 2.038952, Acc:0.797615, Semantic loss: 0.778996, BCE loss: 0.525714, SB loss: 0.734242
2023-10-30 14:44:17,112 Epoch: [269/484] Iter:[220/495], Time: 0.38, lr: [0.004808669869810866], Loss: 2.035784, Acc:0.799964, Semantic loss: 0.776054, BCE loss: 0.526987, SB loss: 0.732744
2023-10-30 14:44:20,773 Epoch: [269/484] Iter:[230/495], Time: 0.38, lr: [0.0048082623726818895], Loss: 2.038925, Acc:0.800757, Semantic loss: 0.779722, BCE loss: 0.526111, SB loss: 0.733092
2023-10-30 14:44:24,451 Epoch: [269/484] Iter:[240/495], Time: 0.38, lr: [0.004807854871715643], Loss: 2.040813, Acc:0.799880, Semantic loss: 0.781107, BCE loss: 0.525589, SB loss: 0.734117
2023-10-30 14:44:28,152 Epoch: [269/484] Iter:[250/495], Time: 0.38, lr: [0.004807447366911724], Loss: 2.036892, Acc:0.800136, Semantic loss: 0.777588, BCE loss: 0.527107, SB loss: 0.732197
2023-10-30 14:44:31,931 Epoch: [269/484] Iter:[260/495], Time: 0.38, lr: [0.004807039858269741], Loss: 2.039947, Acc:0.801477, Semantic loss: 0.778808, BCE loss: 0.529179, SB loss: 0.731959
2023-10-30 14:44:35,581 Epoch: [269/484] Iter:[270/495], Time: 0.37, lr: [0.004806632345789294], Loss: 2.036582, Acc:0.802568, Semantic loss: 0.776926, BCE loss: 0.527848, SB loss: 0.731808
2023-10-30 14:44:39,268 Epoch: [269/484] Iter:[280/495], Time: 0.37, lr: [0.004806224829469984], Loss: 2.032067, Acc:0.803713, Semantic loss: 0.773883, BCE loss: 0.527832, SB loss: 0.730353
2023-10-30 14:44:42,940 Epoch: [269/484] Iter:[290/495], Time: 0.37, lr: [0.004805817309311413], Loss: 2.030716, Acc:0.803642, Semantic loss: 0.773876, BCE loss: 0.526639, SB loss: 0.730200
2023-10-30 14:44:46,793 Epoch: [269/484] Iter:[300/495], Time: 0.37, lr: [0.004805409785313186], Loss: 2.030479, Acc:0.802641, Semantic loss: 0.772675, BCE loss: 0.527634, SB loss: 0.730170
2023-10-30 14:44:50,536 Epoch: [269/484] Iter:[310/495], Time: 0.37, lr: [0.0048050022574749034], Loss: 2.029721, Acc:0.803018, Semantic loss: 0.772734, BCE loss: 0.526555, SB loss: 0.730432
2023-10-30 14:44:54,201 Epoch: [269/484] Iter:[320/495], Time: 0.37, lr: [0.004804594725796166], Loss: 2.035127, Acc:0.802081, Semantic loss: 0.776269, BCE loss: 0.527095, SB loss: 0.731764
2023-10-30 14:44:57,984 Epoch: [269/484] Iter:[330/495], Time: 0.37, lr: [0.004804187190276576], Loss: 2.036363, Acc:0.802220, Semantic loss: 0.777679, BCE loss: 0.526579, SB loss: 0.732105
2023-10-30 14:45:01,694 Epoch: [269/484] Iter:[340/495], Time: 0.37, lr: [0.004803779650915737], Loss: 2.040545, Acc:0.802178, Semantic loss: 0.779585, BCE loss: 0.527034, SB loss: 0.733926
2023-10-30 14:45:05,450 Epoch: [269/484] Iter:[350/495], Time: 0.37, lr: [0.004803372107713249], Loss: 2.044903, Acc:0.802369, Semantic loss: 0.781909, BCE loss: 0.528802, SB loss: 0.734191
2023-10-30 14:45:09,127 Epoch: [269/484] Iter:[360/495], Time: 0.37, lr: [0.004802964560668715], Loss: 2.042198, Acc:0.801635, Semantic loss: 0.781041, BCE loss: 0.527592, SB loss: 0.733565
2023-10-30 14:45:12,721 Epoch: [269/484] Iter:[370/495], Time: 0.37, lr: [0.004802557009781734], Loss: 2.044292, Acc:0.802367, Semantic loss: 0.780806, BCE loss: 0.529818, SB loss: 0.733667
2023-10-30 14:45:16,372 Epoch: [269/484] Iter:[380/495], Time: 0.37, lr: [0.0048021494550519106], Loss: 2.045363, Acc:0.801376, Semantic loss: 0.780796, BCE loss: 0.529130, SB loss: 0.735437
2023-10-30 14:45:20,127 Epoch: [269/484] Iter:[390/495], Time: 0.37, lr: [0.004801741896478844], Loss: 2.049311, Acc:0.801809, Semantic loss: 0.781101, BCE loss: 0.531908, SB loss: 0.736302
2023-10-30 14:45:23,922 Epoch: [269/484] Iter:[400/495], Time: 0.37, lr: [0.0048013343340621364], Loss: 2.045543, Acc:0.801466, Semantic loss: 0.778101, BCE loss: 0.532399, SB loss: 0.735043
2023-10-30 14:45:27,672 Epoch: [269/484] Iter:[410/495], Time: 0.37, lr: [0.004800926767801388], Loss: 2.047296, Acc:0.802298, Semantic loss: 0.779700, BCE loss: 0.532076, SB loss: 0.735520
2023-10-30 14:45:31,395 Epoch: [269/484] Iter:[420/495], Time: 0.37, lr: [0.004800519197696202], Loss: 2.050021, Acc:0.802490, Semantic loss: 0.781676, BCE loss: 0.532657, SB loss: 0.735688
2023-10-30 14:45:35,131 Epoch: [269/484] Iter:[430/495], Time: 0.37, lr: [0.004800111623746178], Loss: 2.044746, Acc:0.801812, Semantic loss: 0.778986, BCE loss: 0.531208, SB loss: 0.734552
2023-10-30 14:45:38,903 Epoch: [269/484] Iter:[440/495], Time: 0.37, lr: [0.004799704045950917], Loss: 2.045418, Acc:0.801382, Semantic loss: 0.779168, BCE loss: 0.530750, SB loss: 0.735500
2023-10-30 14:45:42,569 Epoch: [269/484] Iter:[450/495], Time: 0.37, lr: [0.004799296464310019], Loss: 2.048830, Acc:0.800387, Semantic loss: 0.780612, BCE loss: 0.531376, SB loss: 0.736843
2023-10-30 14:45:46,148 Epoch: [269/484] Iter:[460/495], Time: 0.37, lr: [0.0047988888788230875], Loss: 2.046436, Acc:0.799775, Semantic loss: 0.779417, BCE loss: 0.530805, SB loss: 0.736215
2023-10-30 14:45:49,987 Epoch: [269/484] Iter:[470/495], Time: 0.37, lr: [0.0047984812894897215], Loss: 2.045383, Acc:0.799741, Semantic loss: 0.778152, BCE loss: 0.531741, SB loss: 0.735490
2023-10-30 14:45:53,702 Epoch: [269/484] Iter:[480/495], Time: 0.37, lr: [0.004798073696309522], Loss: 2.044906, Acc:0.799823, Semantic loss: 0.777661, BCE loss: 0.531751, SB loss: 0.735495
2023-10-30 14:45:57,197 Epoch: [269/484] Iter:[490/495], Time: 0.37, lr: [0.004797666099282088], Loss: 2.046468, Acc:0.800445, Semantic loss: 0.778497, BCE loss: 0.532901, SB loss: 0.735070
2023-10-30 14:45:58,604 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:45:58,839 Loss: 2.027, MeanIU:  0.6806, Best_mIoU:  0.7151
2023-10-30 14:45:58,839 [0.96972477 0.78793013 0.90610766 0.44962557 0.52573415 0.56314619
 0.65246601 0.73684681 0.91003624 0.58137329 0.91685701 0.7578317
 0.49573988 0.91484501 0.55559667 0.72033786 0.45991299 0.32969875
 0.69782692]
2023-10-30 14:46:00,691 Epoch: [270/484] Iter:[0/495], Time: 1.82, lr: [0.004797462299325534], Loss: 1.668246, Acc:0.824118, Semantic loss: 0.611346, BCE loss: 0.414134, SB loss: 0.642766
2023-10-30 14:46:04,877 Epoch: [270/484] Iter:[10/495], Time: 0.55, lr: [0.0047970546965265025], Loss: 2.047573, Acc:0.797778, Semantic loss: 0.784602, BCE loss: 0.531062, SB loss: 0.731908
2023-10-30 14:46:08,582 Epoch: [270/484] Iter:[20/495], Time: 0.46, lr: [0.00479664708987924], Loss: 2.098149, Acc:0.793020, Semantic loss: 0.794317, BCE loss: 0.557072, SB loss: 0.746760
2023-10-30 14:46:12,305 Epoch: [270/484] Iter:[30/495], Time: 0.43, lr: [0.0047962394793833445], Loss: 2.075157, Acc:0.778364, Semantic loss: 0.786446, BCE loss: 0.540842, SB loss: 0.747869
2023-10-30 14:46:15,925 Epoch: [270/484] Iter:[40/495], Time: 0.42, lr: [0.004795831865038417], Loss: 2.072764, Acc:0.777068, Semantic loss: 0.790066, BCE loss: 0.524146, SB loss: 0.758553
2023-10-30 14:46:19,514 Epoch: [270/484] Iter:[50/495], Time: 0.40, lr: [0.00479542424684406], Loss: 2.047478, Acc:0.780031, Semantic loss: 0.776867, BCE loss: 0.525481, SB loss: 0.745130
2023-10-30 14:46:23,161 Epoch: [270/484] Iter:[60/495], Time: 0.40, lr: [0.004795016624799871], Loss: 2.043410, Acc:0.782747, Semantic loss: 0.777012, BCE loss: 0.522019, SB loss: 0.744379
2023-10-30 14:46:26,871 Epoch: [270/484] Iter:[70/495], Time: 0.39, lr: [0.00479460899890545], Loss: 2.021193, Acc:0.779693, Semantic loss: 0.768077, BCE loss: 0.514875, SB loss: 0.738241
2023-10-30 14:46:30,737 Epoch: [270/484] Iter:[80/495], Time: 0.39, lr: [0.0047942013691604], Loss: 1.994670, Acc:0.783946, Semantic loss: 0.748105, BCE loss: 0.514172, SB loss: 0.732393
2023-10-30 14:46:34,515 Epoch: [270/484] Iter:[90/495], Time: 0.39, lr: [0.004793793735564317], Loss: 1.984530, Acc:0.786564, Semantic loss: 0.743250, BCE loss: 0.511795, SB loss: 0.729486
2023-10-30 14:46:38,162 Epoch: [270/484] Iter:[100/495], Time: 0.39, lr: [0.004793386098116803], Loss: 1.974181, Acc:0.781025, Semantic loss: 0.740295, BCE loss: 0.507683, SB loss: 0.726203
2023-10-30 14:46:41,953 Epoch: [270/484] Iter:[110/495], Time: 0.39, lr: [0.004792978456817457], Loss: 1.988404, Acc:0.781270, Semantic loss: 0.749566, BCE loss: 0.507346, SB loss: 0.731492
2023-10-30 14:46:45,633 Epoch: [270/484] Iter:[120/495], Time: 0.39, lr: [0.004792570811665878], Loss: 1.999052, Acc:0.784114, Semantic loss: 0.755181, BCE loss: 0.512163, SB loss: 0.731708
2023-10-30 14:46:49,339 Epoch: [270/484] Iter:[130/495], Time: 0.39, lr: [0.0047921631626616674], Loss: 1.999363, Acc:0.785323, Semantic loss: 0.757983, BCE loss: 0.511567, SB loss: 0.729812
2023-10-30 14:46:53,062 Epoch: [270/484] Iter:[140/495], Time: 0.38, lr: [0.004791755509804423], Loss: 1.997601, Acc:0.787623, Semantic loss: 0.754664, BCE loss: 0.514692, SB loss: 0.728245
2023-10-30 14:46:56,830 Epoch: [270/484] Iter:[150/495], Time: 0.38, lr: [0.004791347853093743], Loss: 2.000065, Acc:0.787321, Semantic loss: 0.754263, BCE loss: 0.516388, SB loss: 0.729415
2023-10-30 14:47:00,547 Epoch: [270/484] Iter:[160/495], Time: 0.38, lr: [0.00479094019252923], Loss: 1.997366, Acc:0.789709, Semantic loss: 0.752419, BCE loss: 0.517116, SB loss: 0.727831
2023-10-30 14:47:04,440 Epoch: [270/484] Iter:[170/495], Time: 0.38, lr: [0.004790532528110482], Loss: 2.002859, Acc:0.789006, Semantic loss: 0.754803, BCE loss: 0.519852, SB loss: 0.728205
2023-10-30 14:47:08,140 Epoch: [270/484] Iter:[180/495], Time: 0.38, lr: [0.004790124859837096], Loss: 2.010470, Acc:0.790830, Semantic loss: 0.758778, BCE loss: 0.523048, SB loss: 0.728644
2023-10-30 14:47:11,830 Epoch: [270/484] Iter:[190/495], Time: 0.38, lr: [0.004789717187708673], Loss: 2.006212, Acc:0.790301, Semantic loss: 0.755279, BCE loss: 0.523885, SB loss: 0.727048
2023-10-30 14:47:15,637 Epoch: [270/484] Iter:[200/495], Time: 0.38, lr: [0.004789309511724812], Loss: 2.010618, Acc:0.789926, Semantic loss: 0.757382, BCE loss: 0.524505, SB loss: 0.728731
2023-10-30 14:47:19,377 Epoch: [270/484] Iter:[210/495], Time: 0.38, lr: [0.004788901831885112], Loss: 2.014971, Acc:0.790300, Semantic loss: 0.758385, BCE loss: 0.526721, SB loss: 0.729865
2023-10-30 14:47:23,020 Epoch: [270/484] Iter:[220/495], Time: 0.38, lr: [0.004788494148189171], Loss: 2.018350, Acc:0.790539, Semantic loss: 0.758293, BCE loss: 0.529129, SB loss: 0.730928
2023-10-30 14:47:26,712 Epoch: [270/484] Iter:[230/495], Time: 0.38, lr: [0.004788086460636587], Loss: 2.020751, Acc:0.791336, Semantic loss: 0.761178, BCE loss: 0.528258, SB loss: 0.731315
2023-10-30 14:47:30,453 Epoch: [270/484] Iter:[240/495], Time: 0.38, lr: [0.00478767876922696], Loss: 2.019004, Acc:0.791742, Semantic loss: 0.760362, BCE loss: 0.528933, SB loss: 0.729709
2023-10-30 14:47:34,258 Epoch: [270/484] Iter:[250/495], Time: 0.38, lr: [0.004787271073959889], Loss: 2.016506, Acc:0.789450, Semantic loss: 0.758256, BCE loss: 0.528068, SB loss: 0.730182
2023-10-30 14:47:37,935 Epoch: [270/484] Iter:[260/495], Time: 0.38, lr: [0.004786863374834972], Loss: 2.019954, Acc:0.789335, Semantic loss: 0.761178, BCE loss: 0.526856, SB loss: 0.731919
2023-10-30 14:47:41,690 Epoch: [270/484] Iter:[270/495], Time: 0.38, lr: [0.0047864556718518044], Loss: 2.027532, Acc:0.789241, Semantic loss: 0.765757, BCE loss: 0.529005, SB loss: 0.732770
2023-10-30 14:47:45,414 Epoch: [270/484] Iter:[280/495], Time: 0.38, lr: [0.00478604796500999], Loss: 2.026991, Acc:0.789310, Semantic loss: 0.764659, BCE loss: 0.528824, SB loss: 0.733508
2023-10-30 14:47:49,111 Epoch: [270/484] Iter:[290/495], Time: 0.38, lr: [0.004785640254309124], Loss: 2.029379, Acc:0.790817, Semantic loss: 0.765635, BCE loss: 0.530632, SB loss: 0.733112
2023-10-30 14:47:52,787 Epoch: [270/484] Iter:[300/495], Time: 0.38, lr: [0.004785232539748804], Loss: 2.029025, Acc:0.789611, Semantic loss: 0.763890, BCE loss: 0.532633, SB loss: 0.732502
2023-10-30 14:47:56,469 Epoch: [270/484] Iter:[310/495], Time: 0.38, lr: [0.004784824821328629], Loss: 2.025678, Acc:0.790071, Semantic loss: 0.763290, BCE loss: 0.530929, SB loss: 0.731460
2023-10-30 14:48:00,202 Epoch: [270/484] Iter:[320/495], Time: 0.38, lr: [0.004784417099048198], Loss: 2.023825, Acc:0.790771, Semantic loss: 0.762892, BCE loss: 0.529745, SB loss: 0.731188
2023-10-30 14:48:04,008 Epoch: [270/484] Iter:[330/495], Time: 0.38, lr: [0.004784009372907107], Loss: 2.022279, Acc:0.790544, Semantic loss: 0.762336, BCE loss: 0.529592, SB loss: 0.730351
2023-10-30 14:48:07,817 Epoch: [270/484] Iter:[340/495], Time: 0.38, lr: [0.004783601642904954], Loss: 2.030908, Acc:0.790044, Semantic loss: 0.766885, BCE loss: 0.532081, SB loss: 0.731941
2023-10-30 14:48:11,602 Epoch: [270/484] Iter:[350/495], Time: 0.38, lr: [0.004783193909041338], Loss: 2.030043, Acc:0.790936, Semantic loss: 0.766282, BCE loss: 0.531872, SB loss: 0.731888
2023-10-30 14:48:15,194 Epoch: [270/484] Iter:[360/495], Time: 0.38, lr: [0.004782786171315856], Loss: 2.029023, Acc:0.790533, Semantic loss: 0.766598, BCE loss: 0.530966, SB loss: 0.731460
2023-10-30 14:48:18,929 Epoch: [270/484] Iter:[370/495], Time: 0.38, lr: [0.004782378429728107], Loss: 2.029769, Acc:0.790667, Semantic loss: 0.766399, BCE loss: 0.531674, SB loss: 0.731696
2023-10-30 14:48:22,574 Epoch: [270/484] Iter:[380/495], Time: 0.38, lr: [0.004781970684277687], Loss: 2.029711, Acc:0.791465, Semantic loss: 0.767130, BCE loss: 0.531705, SB loss: 0.730876
2023-10-30 14:48:26,247 Epoch: [270/484] Iter:[390/495], Time: 0.38, lr: [0.004781562934964192], Loss: 2.025605, Acc:0.792041, Semantic loss: 0.764698, BCE loss: 0.531545, SB loss: 0.729361
2023-10-30 14:48:29,967 Epoch: [270/484] Iter:[400/495], Time: 0.38, lr: [0.004781155181787223], Loss: 2.027110, Acc:0.791374, Semantic loss: 0.764858, BCE loss: 0.532174, SB loss: 0.730078
2023-10-30 14:48:33,840 Epoch: [270/484] Iter:[410/495], Time: 0.38, lr: [0.0047807474247463745], Loss: 2.024991, Acc:0.791875, Semantic loss: 0.764061, BCE loss: 0.531030, SB loss: 0.729900
2023-10-30 14:48:37,542 Epoch: [270/484] Iter:[420/495], Time: 0.38, lr: [0.004780339663841245], Loss: 2.027361, Acc:0.791852, Semantic loss: 0.765580, BCE loss: 0.531283, SB loss: 0.730497
2023-10-30 14:48:41,307 Epoch: [270/484] Iter:[430/495], Time: 0.38, lr: [0.0047799318990714304], Loss: 2.025329, Acc:0.792168, Semantic loss: 0.764448, BCE loss: 0.531458, SB loss: 0.729422
2023-10-30 14:48:44,991 Epoch: [270/484] Iter:[440/495], Time: 0.38, lr: [0.004779524130436529], Loss: 2.022435, Acc:0.792473, Semantic loss: 0.763498, BCE loss: 0.529970, SB loss: 0.728966
2023-10-30 14:48:48,690 Epoch: [270/484] Iter:[450/495], Time: 0.38, lr: [0.004779116357936138], Loss: 2.028835, Acc:0.792456, Semantic loss: 0.767666, BCE loss: 0.530851, SB loss: 0.730319
2023-10-30 14:48:52,344 Epoch: [270/484] Iter:[460/495], Time: 0.38, lr: [0.0047787085815698535], Loss: 2.027435, Acc:0.792310, Semantic loss: 0.765917, BCE loss: 0.531106, SB loss: 0.730413
2023-10-30 14:48:56,076 Epoch: [270/484] Iter:[470/495], Time: 0.38, lr: [0.004778300801337272], Loss: 2.029308, Acc:0.792552, Semantic loss: 0.767064, BCE loss: 0.531029, SB loss: 0.731215
2023-10-30 14:48:59,754 Epoch: [270/484] Iter:[480/495], Time: 0.38, lr: [0.004777893017237991], Loss: 2.028700, Acc:0.792772, Semantic loss: 0.767192, BCE loss: 0.530491, SB loss: 0.731017
2023-10-30 14:49:03,289 Epoch: [270/484] Iter:[490/495], Time: 0.38, lr: [0.004777485229271606], Loss: 2.028142, Acc:0.793446, Semantic loss: 0.766753, BCE loss: 0.530863, SB loss: 0.730526
2023-10-30 14:51:59,010 0 [0.93455517 0.61989266 0.81159199 0.13204378 0.22562567 0.40414667
 0.44851219 0.54897986 0.88083662 0.41319408 0.84868333 0.56675983
 0.01187032 0.77004146 0.0019735  0.07224973 0.04769057 0.02689815
 0.54588073] 0.4374434914367794
2023-10-30 14:51:59,010 1 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841] 0.6803049607941531
2023-10-30 14:51:59,014 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:51:59,248 Loss: 2.074, MeanIU:  0.6803, Best_mIoU:  0.7151
2023-10-30 14:51:59,248 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841]
2023-10-30 14:52:01,192 Epoch: [271/484] Iter:[0/495], Time: 1.91, lr: [0.004777281333838124], Loss: 1.636341, Acc:0.798872, Semantic loss: 0.541352, BCE loss: 0.515653, SB loss: 0.579336
2023-10-30 14:52:04,942 Epoch: [271/484] Iter:[10/495], Time: 0.51, lr: [0.004776873540070327], Loss: 1.929117, Acc:0.764000, Semantic loss: 0.744972, BCE loss: 0.491235, SB loss: 0.692910
2023-10-30 14:52:08,480 Epoch: [271/484] Iter:[20/495], Time: 0.44, lr: [0.00477646574243442], Loss: 2.027881, Acc:0.780619, Semantic loss: 0.777736, BCE loss: 0.532052, SB loss: 0.718092
2023-10-30 14:52:11,962 Epoch: [271/484] Iter:[30/495], Time: 0.41, lr: [0.004776057940929997], Loss: 2.027807, Acc:0.794359, Semantic loss: 0.761494, BCE loss: 0.544235, SB loss: 0.722077
2023-10-30 14:52:15,285 Epoch: [271/484] Iter:[40/495], Time: 0.39, lr: [0.004775650135556655], Loss: 1.998127, Acc:0.798656, Semantic loss: 0.751830, BCE loss: 0.528446, SB loss: 0.717852
2023-10-30 14:52:18,845 Epoch: [271/484] Iter:[50/495], Time: 0.38, lr: [0.004775242326313988], Loss: 2.013961, Acc:0.799151, Semantic loss: 0.763584, BCE loss: 0.527820, SB loss: 0.722557
2023-10-30 14:52:22,432 Epoch: [271/484] Iter:[60/495], Time: 0.38, lr: [0.004774834513201595], Loss: 1.987529, Acc:0.796450, Semantic loss: 0.746223, BCE loss: 0.524633, SB loss: 0.716673
2023-10-30 14:52:25,995 Epoch: [271/484] Iter:[70/495], Time: 0.38, lr: [0.004774426696219072], Loss: 1.999464, Acc:0.797634, Semantic loss: 0.753654, BCE loss: 0.528997, SB loss: 0.716813
2023-10-30 14:52:29,637 Epoch: [271/484] Iter:[80/495], Time: 0.37, lr: [0.004774018875366014], Loss: 1.999469, Acc:0.798215, Semantic loss: 0.754270, BCE loss: 0.528287, SB loss: 0.716912
2023-10-30 14:52:33,209 Epoch: [271/484] Iter:[90/495], Time: 0.37, lr: [0.0047736110506420145], Loss: 2.011322, Acc:0.799700, Semantic loss: 0.758925, BCE loss: 0.533861, SB loss: 0.718535
2023-10-30 14:52:36,725 Epoch: [271/484] Iter:[100/495], Time: 0.37, lr: [0.004773203222046675], Loss: 2.041029, Acc:0.796970, Semantic loss: 0.787650, BCE loss: 0.528617, SB loss: 0.724761
2023-10-30 14:52:40,348 Epoch: [271/484] Iter:[110/495], Time: 0.37, lr: [0.004772795389579586], Loss: 2.029272, Acc:0.794743, Semantic loss: 0.778764, BCE loss: 0.524019, SB loss: 0.726489
2023-10-30 14:52:43,963 Epoch: [271/484] Iter:[120/495], Time: 0.37, lr: [0.004772387553240345], Loss: 2.050056, Acc:0.794198, Semantic loss: 0.782144, BCE loss: 0.533700, SB loss: 0.734212
2023-10-30 14:52:47,584 Epoch: [271/484] Iter:[130/495], Time: 0.37, lr: [0.004771979713028548], Loss: 2.048465, Acc:0.792552, Semantic loss: 0.782604, BCE loss: 0.528383, SB loss: 0.737478
2023-10-30 14:52:51,268 Epoch: [271/484] Iter:[140/495], Time: 0.37, lr: [0.004771571868943791], Loss: 2.056521, Acc:0.791091, Semantic loss: 0.786133, BCE loss: 0.530987, SB loss: 0.739401
2023-10-30 14:52:54,915 Epoch: [271/484] Iter:[150/495], Time: 0.37, lr: [0.004771164020985667], Loss: 2.056939, Acc:0.792162, Semantic loss: 0.785166, BCE loss: 0.530362, SB loss: 0.741411
2023-10-30 14:52:58,543 Epoch: [271/484] Iter:[160/495], Time: 0.37, lr: [0.004770756169153774], Loss: 2.052308, Acc:0.790075, Semantic loss: 0.783302, BCE loss: 0.527961, SB loss: 0.741046
2023-10-30 14:53:02,295 Epoch: [271/484] Iter:[170/495], Time: 0.37, lr: [0.004770348313447704], Loss: 2.056391, Acc:0.790385, Semantic loss: 0.784824, BCE loss: 0.528967, SB loss: 0.742601
2023-10-30 14:53:05,909 Epoch: [271/484] Iter:[180/495], Time: 0.37, lr: [0.004769940453867056], Loss: 2.053121, Acc:0.790460, Semantic loss: 0.780943, BCE loss: 0.530269, SB loss: 0.741910
2023-10-30 14:53:09,523 Epoch: [271/484] Iter:[190/495], Time: 0.37, lr: [0.004769532590411424], Loss: 2.042137, Acc:0.790650, Semantic loss: 0.774872, BCE loss: 0.527585, SB loss: 0.739681
2023-10-30 14:53:13,165 Epoch: [271/484] Iter:[200/495], Time: 0.37, lr: [0.004769124723080401], Loss: 2.046592, Acc:0.789914, Semantic loss: 0.777183, BCE loss: 0.528735, SB loss: 0.740674
2023-10-30 14:53:16,774 Epoch: [271/484] Iter:[210/495], Time: 0.37, lr: [0.004768716851873582], Loss: 2.043067, Acc:0.789855, Semantic loss: 0.775720, BCE loss: 0.527621, SB loss: 0.739727
2023-10-30 14:53:20,460 Epoch: [271/484] Iter:[220/495], Time: 0.37, lr: [0.004768308976790565], Loss: 2.053313, Acc:0.791043, Semantic loss: 0.780406, BCE loss: 0.531417, SB loss: 0.741490
2023-10-30 14:53:24,139 Epoch: [271/484] Iter:[230/495], Time: 0.37, lr: [0.004767901097830942], Loss: 2.048424, Acc:0.792330, Semantic loss: 0.777118, BCE loss: 0.531542, SB loss: 0.739764
2023-10-30 14:53:27,817 Epoch: [271/484] Iter:[240/495], Time: 0.37, lr: [0.004767493214994308], Loss: 2.050510, Acc:0.793434, Semantic loss: 0.776447, BCE loss: 0.532428, SB loss: 0.741635
2023-10-30 14:53:31,398 Epoch: [271/484] Iter:[250/495], Time: 0.37, lr: [0.004767085328280258], Loss: 2.042819, Acc:0.793884, Semantic loss: 0.772637, BCE loss: 0.529976, SB loss: 0.740206
2023-10-30 14:53:35,006 Epoch: [271/484] Iter:[260/495], Time: 0.37, lr: [0.004766677437688388], Loss: 2.040536, Acc:0.793884, Semantic loss: 0.771425, BCE loss: 0.530011, SB loss: 0.739101
2023-10-30 14:53:38,782 Epoch: [271/484] Iter:[270/495], Time: 0.37, lr: [0.00476626954321829], Loss: 2.041511, Acc:0.793886, Semantic loss: 0.770441, BCE loss: 0.532457, SB loss: 0.738612
2023-10-30 14:53:42,420 Epoch: [271/484] Iter:[280/495], Time: 0.37, lr: [0.004765861644869559], Loss: 2.043860, Acc:0.792831, Semantic loss: 0.772287, BCE loss: 0.532231, SB loss: 0.739342
2023-10-30 14:53:46,165 Epoch: [271/484] Iter:[290/495], Time: 0.37, lr: [0.0047654537426417886], Loss: 2.041185, Acc:0.793412, Semantic loss: 0.769963, BCE loss: 0.532360, SB loss: 0.738862
2023-10-30 14:53:49,975 Epoch: [271/484] Iter:[300/495], Time: 0.37, lr: [0.004765045836534576], Loss: 2.040654, Acc:0.793066, Semantic loss: 0.769424, BCE loss: 0.531510, SB loss: 0.739719
2023-10-30 14:53:53,593 Epoch: [271/484] Iter:[310/495], Time: 0.37, lr: [0.004764637926547512], Loss: 2.038237, Acc:0.793588, Semantic loss: 0.767904, BCE loss: 0.531690, SB loss: 0.738643
2023-10-30 14:53:57,290 Epoch: [271/484] Iter:[320/495], Time: 0.37, lr: [0.004764230012680192], Loss: 2.039410, Acc:0.793768, Semantic loss: 0.767797, BCE loss: 0.532712, SB loss: 0.738900
2023-10-30 14:54:01,012 Epoch: [271/484] Iter:[330/495], Time: 0.37, lr: [0.004763822094932209], Loss: 2.043007, Acc:0.794894, Semantic loss: 0.769590, BCE loss: 0.535110, SB loss: 0.738306
2023-10-30 14:54:04,578 Epoch: [271/484] Iter:[340/495], Time: 0.37, lr: [0.00476341417330316], Loss: 2.041631, Acc:0.794106, Semantic loss: 0.768359, BCE loss: 0.535585, SB loss: 0.737687
2023-10-30 14:54:08,309 Epoch: [271/484] Iter:[350/495], Time: 0.37, lr: [0.004763006247792635], Loss: 2.041685, Acc:0.794201, Semantic loss: 0.767432, BCE loss: 0.536737, SB loss: 0.737516
2023-10-30 14:54:12,040 Epoch: [271/484] Iter:[360/495], Time: 0.37, lr: [0.004762598318400229], Loss: 2.041348, Acc:0.795868, Semantic loss: 0.766167, BCE loss: 0.537856, SB loss: 0.737325
2023-10-30 14:54:15,621 Epoch: [271/484] Iter:[370/495], Time: 0.37, lr: [0.004762190385125535], Loss: 2.041283, Acc:0.796348, Semantic loss: 0.766142, BCE loss: 0.538108, SB loss: 0.737033
2023-10-30 14:54:19,320 Epoch: [271/484] Iter:[380/495], Time: 0.37, lr: [0.004761782447968148], Loss: 2.037847, Acc:0.796857, Semantic loss: 0.763972, BCE loss: 0.538095, SB loss: 0.735781
2023-10-30 14:54:23,070 Epoch: [271/484] Iter:[390/495], Time: 0.37, lr: [0.004761374506927662], Loss: 2.036461, Acc:0.797242, Semantic loss: 0.763118, BCE loss: 0.538115, SB loss: 0.735228
2023-10-30 14:54:26,699 Epoch: [271/484] Iter:[400/495], Time: 0.37, lr: [0.004760966562003668], Loss: 2.035674, Acc:0.797165, Semantic loss: 0.763044, BCE loss: 0.537049, SB loss: 0.735581
2023-10-30 14:54:30,373 Epoch: [271/484] Iter:[410/495], Time: 0.37, lr: [0.004760558613195759], Loss: 2.034789, Acc:0.797638, Semantic loss: 0.763443, BCE loss: 0.535365, SB loss: 0.735981
2023-10-30 14:54:33,972 Epoch: [271/484] Iter:[420/495], Time: 0.37, lr: [0.004760150660503531], Loss: 2.033702, Acc:0.797453, Semantic loss: 0.763553, BCE loss: 0.534477, SB loss: 0.735672
2023-10-30 14:54:37,696 Epoch: [271/484] Iter:[430/495], Time: 0.37, lr: [0.004759742703926576], Loss: 2.033798, Acc:0.796682, Semantic loss: 0.763858, BCE loss: 0.533869, SB loss: 0.736071
2023-10-30 14:54:41,404 Epoch: [271/484] Iter:[440/495], Time: 0.37, lr: [0.004759334743464487], Loss: 2.032291, Acc:0.797032, Semantic loss: 0.763368, BCE loss: 0.533046, SB loss: 0.735876
2023-10-30 14:54:45,076 Epoch: [271/484] Iter:[450/495], Time: 0.37, lr: [0.004758926779116855], Loss: 2.030611, Acc:0.797044, Semantic loss: 0.763354, BCE loss: 0.531247, SB loss: 0.736010
2023-10-30 14:54:48,871 Epoch: [271/484] Iter:[460/495], Time: 0.37, lr: [0.004758518810883276], Loss: 2.028527, Acc:0.796452, Semantic loss: 0.762265, BCE loss: 0.530683, SB loss: 0.735578
2023-10-30 14:54:52,591 Epoch: [271/484] Iter:[470/495], Time: 0.37, lr: [0.004758110838763341], Loss: 2.028807, Acc:0.797077, Semantic loss: 0.762059, BCE loss: 0.531219, SB loss: 0.735529
2023-10-30 14:54:56,359 Epoch: [271/484] Iter:[480/495], Time: 0.37, lr: [0.004757702862756644], Loss: 2.030762, Acc:0.797377, Semantic loss: 0.763158, BCE loss: 0.531301, SB loss: 0.736303
2023-10-30 14:54:59,811 Epoch: [271/484] Iter:[490/495], Time: 0.37, lr: [0.004757294882862775], Loss: 2.034468, Acc:0.797970, Semantic loss: 0.766244, BCE loss: 0.531688, SB loss: 0.736536
2023-10-30 14:55:01,236 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:55:01,480 Loss: 2.074, MeanIU:  0.6803, Best_mIoU:  0.7151
2023-10-30 14:55:01,481 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841]
2023-10-30 14:55:03,694 Epoch: [272/484] Iter:[0/495], Time: 2.18, lr: [0.004757090891458025], Loss: 1.854262, Acc:0.822502, Semantic loss: 0.629545, BCE loss: 0.477770, SB loss: 0.746947
2023-10-30 14:55:07,590 Epoch: [272/484] Iter:[10/495], Time: 0.55, lr: [0.004756682905732638], Loss: 2.023569, Acc:0.810983, Semantic loss: 0.759545, BCE loss: 0.533625, SB loss: 0.730399
2023-10-30 14:55:11,374 Epoch: [272/484] Iter:[20/495], Time: 0.47, lr: [0.004756274916119062], Loss: 2.013103, Acc:0.815326, Semantic loss: 0.758382, BCE loss: 0.525741, SB loss: 0.728980
2023-10-30 14:55:15,035 Epoch: [272/484] Iter:[30/495], Time: 0.44, lr: [0.004755866922616888], Loss: 2.051881, Acc:0.817389, Semantic loss: 0.767371, BCE loss: 0.542647, SB loss: 0.741863
2023-10-30 14:55:18,812 Epoch: [272/484] Iter:[40/495], Time: 0.42, lr: [0.004755458925225712], Loss: 2.041895, Acc:0.808623, Semantic loss: 0.755640, BCE loss: 0.547269, SB loss: 0.738987
2023-10-30 14:55:22,448 Epoch: [272/484] Iter:[50/495], Time: 0.41, lr: [0.004755050923945122], Loss: 2.011215, Acc:0.803421, Semantic loss: 0.737621, BCE loss: 0.537707, SB loss: 0.735886
2023-10-30 14:55:26,109 Epoch: [272/484] Iter:[60/495], Time: 0.40, lr: [0.004754642918774713], Loss: 2.009879, Acc:0.807426, Semantic loss: 0.736873, BCE loss: 0.538467, SB loss: 0.734539
2023-10-30 14:55:29,719 Epoch: [272/484] Iter:[70/495], Time: 0.40, lr: [0.0047542349097140744], Loss: 2.024622, Acc:0.802318, Semantic loss: 0.747390, BCE loss: 0.541870, SB loss: 0.735363
2023-10-30 14:55:33,421 Epoch: [272/484] Iter:[80/495], Time: 0.39, lr: [0.004753826896762801], Loss: 2.010490, Acc:0.798788, Semantic loss: 0.742650, BCE loss: 0.534065, SB loss: 0.733774
2023-10-30 14:55:37,142 Epoch: [272/484] Iter:[90/495], Time: 0.39, lr: [0.004753418879920483], Loss: 2.010652, Acc:0.793612, Semantic loss: 0.745331, BCE loss: 0.530703, SB loss: 0.734618
2023-10-30 14:55:40,826 Epoch: [272/484] Iter:[100/495], Time: 0.39, lr: [0.004753010859186714], Loss: 2.012913, Acc:0.800683, Semantic loss: 0.745915, BCE loss: 0.535950, SB loss: 0.731048
2023-10-30 14:55:44,570 Epoch: [272/484] Iter:[110/495], Time: 0.39, lr: [0.0047526028345610824], Loss: 2.001179, Acc:0.804489, Semantic loss: 0.740668, BCE loss: 0.531700, SB loss: 0.728811
2023-10-30 14:55:48,206 Epoch: [272/484] Iter:[120/495], Time: 0.39, lr: [0.004752194806043182], Loss: 2.002443, Acc:0.804869, Semantic loss: 0.741415, BCE loss: 0.533610, SB loss: 0.727418
2023-10-30 14:55:51,870 Epoch: [272/484] Iter:[130/495], Time: 0.38, lr: [0.004751786773632605], Loss: 2.003998, Acc:0.804614, Semantic loss: 0.742970, BCE loss: 0.532848, SB loss: 0.728179
2023-10-30 14:55:55,482 Epoch: [272/484] Iter:[140/495], Time: 0.38, lr: [0.0047513787373289415], Loss: 2.003290, Acc:0.806402, Semantic loss: 0.740287, BCE loss: 0.535912, SB loss: 0.727091
2023-10-30 14:55:59,195 Epoch: [272/484] Iter:[150/495], Time: 0.38, lr: [0.004750970697131782], Loss: 2.003801, Acc:0.805257, Semantic loss: 0.741798, BCE loss: 0.535918, SB loss: 0.726084
2023-10-30 14:56:02,957 Epoch: [272/484] Iter:[160/495], Time: 0.38, lr: [0.004750562653040719], Loss: 2.010622, Acc:0.803334, Semantic loss: 0.751318, BCE loss: 0.531090, SB loss: 0.728214
2023-10-30 14:56:06,639 Epoch: [272/484] Iter:[170/495], Time: 0.38, lr: [0.004750154605055346], Loss: 2.007348, Acc:0.802702, Semantic loss: 0.749568, BCE loss: 0.529094, SB loss: 0.728686
2023-10-30 14:56:10,247 Epoch: [272/484] Iter:[180/495], Time: 0.38, lr: [0.00474974655317525], Loss: 1.994966, Acc:0.801073, Semantic loss: 0.743388, BCE loss: 0.525693, SB loss: 0.725885
2023-10-30 14:56:13,930 Epoch: [272/484] Iter:[190/495], Time: 0.38, lr: [0.0047493384974000245], Loss: 1.996765, Acc:0.800571, Semantic loss: 0.745435, BCE loss: 0.524364, SB loss: 0.726966
2023-10-30 14:56:17,544 Epoch: [272/484] Iter:[200/495], Time: 0.38, lr: [0.00474893043772926], Loss: 1.999880, Acc:0.801632, Semantic loss: 0.747318, BCE loss: 0.525172, SB loss: 0.727391
2023-10-30 14:56:21,202 Epoch: [272/484] Iter:[210/495], Time: 0.38, lr: [0.004748522374162547], Loss: 2.003408, Acc:0.801118, Semantic loss: 0.750097, BCE loss: 0.524787, SB loss: 0.728525
2023-10-30 14:56:24,907 Epoch: [272/484] Iter:[220/495], Time: 0.38, lr: [0.004748114306699477], Loss: 2.000499, Acc:0.799230, Semantic loss: 0.748666, BCE loss: 0.523423, SB loss: 0.728411
2023-10-30 14:56:28,649 Epoch: [272/484] Iter:[230/495], Time: 0.38, lr: [0.004747706235339639], Loss: 1.994939, Acc:0.800156, Semantic loss: 0.747404, BCE loss: 0.520742, SB loss: 0.726793
2023-10-30 14:56:32,372 Epoch: [272/484] Iter:[240/495], Time: 0.38, lr: [0.004747298160082626], Loss: 1.994375, Acc:0.799514, Semantic loss: 0.747704, BCE loss: 0.519067, SB loss: 0.727604
2023-10-30 14:56:36,049 Epoch: [272/484] Iter:[250/495], Time: 0.38, lr: [0.0047468900809280274], Loss: 1.990141, Acc:0.800308, Semantic loss: 0.744358, BCE loss: 0.519344, SB loss: 0.726439
2023-10-30 14:56:39,737 Epoch: [272/484] Iter:[260/495], Time: 0.38, lr: [0.004746481997875434], Loss: 1.996132, Acc:0.801107, Semantic loss: 0.747939, BCE loss: 0.521787, SB loss: 0.726406
2023-10-30 14:56:43,335 Epoch: [272/484] Iter:[270/495], Time: 0.38, lr: [0.004746073910924435], Loss: 1.997288, Acc:0.800476, Semantic loss: 0.748515, BCE loss: 0.522082, SB loss: 0.726691
2023-10-30 14:56:47,169 Epoch: [272/484] Iter:[280/495], Time: 0.38, lr: [0.0047456658200746215], Loss: 1.995422, Acc:0.801684, Semantic loss: 0.747378, BCE loss: 0.522770, SB loss: 0.725275
2023-10-30 14:56:50,799 Epoch: [272/484] Iter:[290/495], Time: 0.38, lr: [0.004745257725325585], Loss: 1.995793, Acc:0.801106, Semantic loss: 0.746988, BCE loss: 0.523262, SB loss: 0.725543
2023-10-30 14:56:54,507 Epoch: [272/484] Iter:[300/495], Time: 0.38, lr: [0.004744849626676914], Loss: 1.999253, Acc:0.799830, Semantic loss: 0.750909, BCE loss: 0.522166, SB loss: 0.726177
2023-10-30 14:56:58,103 Epoch: [272/484] Iter:[310/495], Time: 0.37, lr: [0.004744441524128199], Loss: 1.997928, Acc:0.800004, Semantic loss: 0.750004, BCE loss: 0.521580, SB loss: 0.726343
2023-10-30 14:57:01,797 Epoch: [272/484] Iter:[320/495], Time: 0.37, lr: [0.004744033417679029], Loss: 1.995502, Acc:0.799632, Semantic loss: 0.748494, BCE loss: 0.521246, SB loss: 0.725761
2023-10-30 14:57:05,526 Epoch: [272/484] Iter:[330/495], Time: 0.37, lr: [0.004743625307328997], Loss: 1.997673, Acc:0.799612, Semantic loss: 0.750880, BCE loss: 0.521850, SB loss: 0.724943
2023-10-30 14:57:09,139 Epoch: [272/484] Iter:[340/495], Time: 0.37, lr: [0.004743217193077689], Loss: 1.999086, Acc:0.798663, Semantic loss: 0.752274, BCE loss: 0.522013, SB loss: 0.724800
2023-10-30 14:57:12,802 Epoch: [272/484] Iter:[350/495], Time: 0.37, lr: [0.004742809074924697], Loss: 2.003940, Acc:0.798078, Semantic loss: 0.756699, BCE loss: 0.521167, SB loss: 0.726074
2023-10-30 14:57:16,619 Epoch: [272/484] Iter:[360/495], Time: 0.37, lr: [0.00474240095286961], Loss: 2.005716, Acc:0.797559, Semantic loss: 0.757164, BCE loss: 0.520758, SB loss: 0.727794
2023-10-30 14:57:20,245 Epoch: [272/484] Iter:[370/495], Time: 0.37, lr: [0.0047419928269120185], Loss: 2.004649, Acc:0.798409, Semantic loss: 0.754464, BCE loss: 0.522131, SB loss: 0.728054
2023-10-30 14:57:23,980 Epoch: [272/484] Iter:[380/495], Time: 0.37, lr: [0.0047415846970515095], Loss: 2.007677, Acc:0.798243, Semantic loss: 0.755760, BCE loss: 0.522507, SB loss: 0.729411
2023-10-30 14:57:27,712 Epoch: [272/484] Iter:[390/495], Time: 0.37, lr: [0.004741176563287676], Loss: 2.008072, Acc:0.798088, Semantic loss: 0.756193, BCE loss: 0.522495, SB loss: 0.729385
2023-10-30 14:57:31,491 Epoch: [272/484] Iter:[400/495], Time: 0.37, lr: [0.0047407684256201045], Loss: 2.005790, Acc:0.799056, Semantic loss: 0.755008, BCE loss: 0.521500, SB loss: 0.729282
2023-10-30 14:57:35,213 Epoch: [272/484] Iter:[410/495], Time: 0.37, lr: [0.004740360284048385], Loss: 2.003820, Acc:0.798842, Semantic loss: 0.753107, BCE loss: 0.522218, SB loss: 0.728495
2023-10-30 14:57:38,822 Epoch: [272/484] Iter:[420/495], Time: 0.37, lr: [0.0047399521385721064], Loss: 2.004773, Acc:0.799042, Semantic loss: 0.753048, BCE loss: 0.522661, SB loss: 0.729065
2023-10-30 14:57:42,515 Epoch: [272/484] Iter:[430/495], Time: 0.37, lr: [0.004739543989190859], Loss: 2.005315, Acc:0.800069, Semantic loss: 0.753009, BCE loss: 0.523766, SB loss: 0.728540
2023-10-30 14:57:46,120 Epoch: [272/484] Iter:[440/495], Time: 0.37, lr: [0.004739135835904231], Loss: 2.006151, Acc:0.800328, Semantic loss: 0.753437, BCE loss: 0.524392, SB loss: 0.728321
2023-10-30 14:57:49,831 Epoch: [272/484] Iter:[450/495], Time: 0.37, lr: [0.004738727678711811], Loss: 2.006151, Acc:0.799451, Semantic loss: 0.754095, BCE loss: 0.523460, SB loss: 0.728595
2023-10-30 14:57:53,533 Epoch: [272/484] Iter:[460/495], Time: 0.37, lr: [0.004738319517613186], Loss: 2.004717, Acc:0.800433, Semantic loss: 0.753147, BCE loss: 0.523589, SB loss: 0.727981
2023-10-30 14:57:57,127 Epoch: [272/484] Iter:[470/495], Time: 0.37, lr: [0.004737911352607949], Loss: 2.004710, Acc:0.800480, Semantic loss: 0.752857, BCE loss: 0.524044, SB loss: 0.727810
2023-10-30 14:58:00,733 Epoch: [272/484] Iter:[480/495], Time: 0.37, lr: [0.004737503183695687], Loss: 2.005206, Acc:0.800891, Semantic loss: 0.753808, BCE loss: 0.523966, SB loss: 0.727432
2023-10-30 14:58:04,218 Epoch: [272/484] Iter:[490/495], Time: 0.37, lr: [0.004737095010875987], Loss: 2.003618, Acc:0.799795, Semantic loss: 0.753829, BCE loss: 0.522459, SB loss: 0.727330
2023-10-30 14:58:05,619 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 14:58:05,856 Loss: 2.074, MeanIU:  0.6803, Best_mIoU:  0.7151
2023-10-30 14:58:05,856 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841]
2023-10-30 14:58:07,762 Epoch: [273/484] Iter:[0/495], Time: 1.87, lr: [0.00473689092300072], Loss: 1.687070, Acc:0.761146, Semantic loss: 0.591579, BCE loss: 0.443809, SB loss: 0.651683
2023-10-30 14:58:11,799 Epoch: [273/484] Iter:[10/495], Time: 0.54, lr: [0.004736482744319092], Loss: 2.075646, Acc:0.821173, Semantic loss: 0.788783, BCE loss: 0.535550, SB loss: 0.751313
2023-10-30 14:58:15,419 Epoch: [273/484] Iter:[20/495], Time: 0.45, lr: [0.004736074561728999], Loss: 2.062429, Acc:0.802451, Semantic loss: 0.780642, BCE loss: 0.537296, SB loss: 0.744491
2023-10-30 14:58:18,988 Epoch: [273/484] Iter:[30/495], Time: 0.42, lr: [0.004735666375230029], Loss: 2.035542, Acc:0.793629, Semantic loss: 0.768511, BCE loss: 0.528774, SB loss: 0.738257
2023-10-30 14:58:22,698 Epoch: [273/484] Iter:[40/495], Time: 0.41, lr: [0.004735258184821769], Loss: 2.020516, Acc:0.789240, Semantic loss: 0.770182, BCE loss: 0.524399, SB loss: 0.725936
2023-10-30 14:58:26,394 Epoch: [273/484] Iter:[50/495], Time: 0.40, lr: [0.004734849990503808], Loss: 2.057395, Acc:0.786512, Semantic loss: 0.779498, BCE loss: 0.545234, SB loss: 0.732664
2023-10-30 14:58:30,192 Epoch: [273/484] Iter:[60/495], Time: 0.40, lr: [0.004734441792275733], Loss: 2.034658, Acc:0.786937, Semantic loss: 0.771451, BCE loss: 0.533620, SB loss: 0.729586
2023-10-30 14:58:33,775 Epoch: [273/484] Iter:[70/495], Time: 0.39, lr: [0.004734033590137133], Loss: 2.023219, Acc:0.789270, Semantic loss: 0.762174, BCE loss: 0.535400, SB loss: 0.725645
2023-10-30 14:58:37,401 Epoch: [273/484] Iter:[80/495], Time: 0.39, lr: [0.004733625384087597], Loss: 2.031349, Acc:0.786357, Semantic loss: 0.766265, BCE loss: 0.539213, SB loss: 0.725871
2023-10-30 14:58:40,993 Epoch: [273/484] Iter:[90/495], Time: 0.39, lr: [0.004733217174126709], Loss: 2.030599, Acc:0.787639, Semantic loss: 0.763987, BCE loss: 0.538593, SB loss: 0.728019
2023-10-30 14:58:44,569 Epoch: [273/484] Iter:[100/495], Time: 0.38, lr: [0.00473280896025406], Loss: 2.058684, Acc:0.786201, Semantic loss: 0.776474, BCE loss: 0.549435, SB loss: 0.732776
2023-10-30 14:58:48,387 Epoch: [273/484] Iter:[110/495], Time: 0.38, lr: [0.0047324007424692375], Loss: 2.050904, Acc:0.789026, Semantic loss: 0.771762, BCE loss: 0.550268, SB loss: 0.728873
2023-10-30 14:58:52,012 Epoch: [273/484] Iter:[120/495], Time: 0.38, lr: [0.0047319925207718275], Loss: 2.043325, Acc:0.791525, Semantic loss: 0.762999, BCE loss: 0.553265, SB loss: 0.727061
2023-10-30 14:58:55,614 Epoch: [273/484] Iter:[130/495], Time: 0.38, lr: [0.0047315842951614175], Loss: 2.025446, Acc:0.790538, Semantic loss: 0.755115, BCE loss: 0.546423, SB loss: 0.723908
2023-10-30 14:58:59,255 Epoch: [273/484] Iter:[140/495], Time: 0.38, lr: [0.004731176065637596], Loss: 2.019482, Acc:0.788844, Semantic loss: 0.753069, BCE loss: 0.544631, SB loss: 0.721782
2023-10-30 14:59:03,040 Epoch: [273/484] Iter:[150/495], Time: 0.38, lr: [0.004730767832199951], Loss: 2.030407, Acc:0.789357, Semantic loss: 0.759193, BCE loss: 0.547004, SB loss: 0.724210
2023-10-30 14:59:06,685 Epoch: [273/484] Iter:[160/495], Time: 0.38, lr: [0.0047303595948480675], Loss: 2.031209, Acc:0.791696, Semantic loss: 0.757248, BCE loss: 0.549338, SB loss: 0.724624
2023-10-30 14:59:10,272 Epoch: [273/484] Iter:[170/495], Time: 0.38, lr: [0.0047299513535815334], Loss: 2.030760, Acc:0.791410, Semantic loss: 0.757719, BCE loss: 0.547906, SB loss: 0.725135
2023-10-30 14:59:13,939 Epoch: [273/484] Iter:[180/495], Time: 0.38, lr: [0.004729543108399937], Loss: 2.029718, Acc:0.792263, Semantic loss: 0.756185, BCE loss: 0.549495, SB loss: 0.724038
2023-10-30 14:59:17,556 Epoch: [273/484] Iter:[190/495], Time: 0.38, lr: [0.0047291348593028635], Loss: 2.034849, Acc:0.791575, Semantic loss: 0.761335, BCE loss: 0.547124, SB loss: 0.726390
2023-10-30 14:59:21,203 Epoch: [273/484] Iter:[200/495], Time: 0.37, lr: [0.004728726606289901], Loss: 2.036711, Acc:0.790512, Semantic loss: 0.763059, BCE loss: 0.545875, SB loss: 0.727777
2023-10-30 14:59:24,924 Epoch: [273/484] Iter:[210/495], Time: 0.37, lr: [0.004728318349360635], Loss: 2.040598, Acc:0.792162, Semantic loss: 0.763869, BCE loss: 0.548795, SB loss: 0.727934
2023-10-30 14:59:28,570 Epoch: [273/484] Iter:[220/495], Time: 0.37, lr: [0.004727910088514654], Loss: 2.035636, Acc:0.791987, Semantic loss: 0.762093, BCE loss: 0.545581, SB loss: 0.727961
2023-10-30 14:59:32,173 Epoch: [273/484] Iter:[230/495], Time: 0.37, lr: [0.004727501823751543], Loss: 2.028430, Acc:0.791243, Semantic loss: 0.760508, BCE loss: 0.541155, SB loss: 0.726767
2023-10-30 14:59:35,818 Epoch: [273/484] Iter:[240/495], Time: 0.37, lr: [0.0047270935550708885], Loss: 2.020005, Acc:0.791738, Semantic loss: 0.756583, BCE loss: 0.538223, SB loss: 0.725200
2023-10-30 14:59:39,537 Epoch: [273/484] Iter:[250/495], Time: 0.37, lr: [0.0047266852824722795], Loss: 2.020939, Acc:0.792094, Semantic loss: 0.756545, BCE loss: 0.538746, SB loss: 0.725648
2023-10-30 14:59:43,342 Epoch: [273/484] Iter:[260/495], Time: 0.37, lr: [0.0047262770059553], Loss: 2.020286, Acc:0.791996, Semantic loss: 0.760186, BCE loss: 0.533654, SB loss: 0.726445
2023-10-30 14:59:47,083 Epoch: [273/484] Iter:[270/495], Time: 0.37, lr: [0.004725868725519536], Loss: 2.033274, Acc:0.790578, Semantic loss: 0.768470, BCE loss: 0.534803, SB loss: 0.730001
2023-10-30 14:59:50,925 Epoch: [273/484] Iter:[280/495], Time: 0.37, lr: [0.004725460441164574], Loss: 2.031336, Acc:0.792705, Semantic loss: 0.766650, BCE loss: 0.534883, SB loss: 0.729803
2023-10-30 14:59:54,613 Epoch: [273/484] Iter:[290/495], Time: 0.37, lr: [0.004725052152890002], Loss: 2.027522, Acc:0.792921, Semantic loss: 0.764413, BCE loss: 0.534160, SB loss: 0.728950
2023-10-30 14:59:58,302 Epoch: [273/484] Iter:[300/495], Time: 0.37, lr: [0.004724643860695405], Loss: 2.025653, Acc:0.792038, Semantic loss: 0.762881, BCE loss: 0.533797, SB loss: 0.728975
2023-10-30 15:00:01,905 Epoch: [273/484] Iter:[310/495], Time: 0.37, lr: [0.004724235564580369], Loss: 2.020667, Acc:0.791393, Semantic loss: 0.760626, BCE loss: 0.531627, SB loss: 0.728414
2023-10-30 15:00:05,545 Epoch: [273/484] Iter:[320/495], Time: 0.37, lr: [0.004723827264544477], Loss: 2.023265, Acc:0.791877, Semantic loss: 0.760323, BCE loss: 0.534323, SB loss: 0.728620
2023-10-30 15:00:09,175 Epoch: [273/484] Iter:[330/495], Time: 0.37, lr: [0.00472341896058732], Loss: 2.024729, Acc:0.792596, Semantic loss: 0.762363, BCE loss: 0.532514, SB loss: 0.729852
2023-10-30 15:00:12,962 Epoch: [273/484] Iter:[340/495], Time: 0.37, lr: [0.00472301065270848], Loss: 2.023868, Acc:0.792332, Semantic loss: 0.763321, BCE loss: 0.531696, SB loss: 0.728850
2023-10-30 15:00:16,743 Epoch: [273/484] Iter:[350/495], Time: 0.37, lr: [0.004722602340907544], Loss: 2.026296, Acc:0.792386, Semantic loss: 0.765073, BCE loss: 0.532667, SB loss: 0.728556
2023-10-30 15:00:20,388 Epoch: [273/484] Iter:[360/495], Time: 0.37, lr: [0.004722194025184096], Loss: 2.022391, Acc:0.793405, Semantic loss: 0.763011, BCE loss: 0.531255, SB loss: 0.728126
2023-10-30 15:00:24,094 Epoch: [273/484] Iter:[370/495], Time: 0.37, lr: [0.004721785705537724], Loss: 2.020843, Acc:0.793433, Semantic loss: 0.762155, BCE loss: 0.530659, SB loss: 0.728029
2023-10-30 15:00:27,765 Epoch: [273/484] Iter:[380/495], Time: 0.37, lr: [0.004721377381968011], Loss: 2.023391, Acc:0.793639, Semantic loss: 0.762549, BCE loss: 0.531827, SB loss: 0.729015
2023-10-30 15:00:31,459 Epoch: [273/484] Iter:[390/495], Time: 0.37, lr: [0.004720969054474544], Loss: 2.027265, Acc:0.794351, Semantic loss: 0.763752, BCE loss: 0.533988, SB loss: 0.729525
2023-10-30 15:00:35,274 Epoch: [273/484] Iter:[400/495], Time: 0.37, lr: [0.004720560723056906], Loss: 2.025160, Acc:0.793479, Semantic loss: 0.762536, BCE loss: 0.533549, SB loss: 0.729075
2023-10-30 15:00:39,012 Epoch: [273/484] Iter:[410/495], Time: 0.37, lr: [0.004720152387714686], Loss: 2.024484, Acc:0.794198, Semantic loss: 0.762367, BCE loss: 0.532965, SB loss: 0.729152
2023-10-30 15:00:42,667 Epoch: [273/484] Iter:[420/495], Time: 0.37, lr: [0.004719744048447465], Loss: 2.021686, Acc:0.794937, Semantic loss: 0.760948, BCE loss: 0.532104, SB loss: 0.728633
2023-10-30 15:00:46,490 Epoch: [273/484] Iter:[430/495], Time: 0.37, lr: [0.004719335705254831], Loss: 2.023292, Acc:0.794675, Semantic loss: 0.761077, BCE loss: 0.532792, SB loss: 0.729423
2023-10-30 15:00:50,316 Epoch: [273/484] Iter:[440/495], Time: 0.37, lr: [0.0047189273581363655], Loss: 2.021460, Acc:0.794285, Semantic loss: 0.760153, BCE loss: 0.532153, SB loss: 0.729153
2023-10-30 15:00:54,005 Epoch: [273/484] Iter:[450/495], Time: 0.37, lr: [0.004718519007091657], Loss: 2.022226, Acc:0.795165, Semantic loss: 0.760528, BCE loss: 0.531680, SB loss: 0.730018
2023-10-30 15:00:57,611 Epoch: [273/484] Iter:[460/495], Time: 0.37, lr: [0.0047181106521202885], Loss: 2.026181, Acc:0.794879, Semantic loss: 0.763432, BCE loss: 0.531538, SB loss: 0.731211
2023-10-30 15:01:01,182 Epoch: [273/484] Iter:[470/495], Time: 0.37, lr: [0.004717702293221844], Loss: 2.027156, Acc:0.795185, Semantic loss: 0.764592, BCE loss: 0.531424, SB loss: 0.731140
2023-10-30 15:01:04,885 Epoch: [273/484] Iter:[480/495], Time: 0.37, lr: [0.004717293930395908], Loss: 2.031575, Acc:0.796017, Semantic loss: 0.767862, BCE loss: 0.532499, SB loss: 0.731214
2023-10-30 15:01:08,400 Epoch: [273/484] Iter:[490/495], Time: 0.37, lr: [0.004716885563642066], Loss: 2.034521, Acc:0.796151, Semantic loss: 0.769971, BCE loss: 0.532519, SB loss: 0.732031
2023-10-30 15:01:09,804 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:01:10,041 Loss: 2.074, MeanIU:  0.6803, Best_mIoU:  0.7151
2023-10-30 15:01:10,041 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841]
2023-10-30 15:01:12,082 Epoch: [274/484] Iter:[0/495], Time: 2.01, lr: [0.004716681378792051], Loss: 2.203971, Acc:0.817165, Semantic loss: 0.800003, BCE loss: 0.666901, SB loss: 0.737067
2023-10-30 15:01:16,103 Epoch: [274/484] Iter:[10/495], Time: 0.55, lr: [0.00471627300614557], Loss: 2.151919, Acc:0.786626, Semantic loss: 0.824938, BCE loss: 0.560685, SB loss: 0.766297
2023-10-30 15:01:19,793 Epoch: [274/484] Iter:[20/495], Time: 0.46, lr: [0.0047158646295701444], Loss: 2.198632, Acc:0.782844, Semantic loss: 0.873582, BCE loss: 0.572172, SB loss: 0.752878
2023-10-30 15:01:23,399 Epoch: [274/484] Iter:[30/495], Time: 0.43, lr: [0.004715456249065355], Loss: 2.131765, Acc:0.787663, Semantic loss: 0.828611, BCE loss: 0.561141, SB loss: 0.742013
2023-10-30 15:01:27,104 Epoch: [274/484] Iter:[40/495], Time: 0.42, lr: [0.0047150478646307906], Loss: 2.103638, Acc:0.796587, Semantic loss: 0.806162, BCE loss: 0.557225, SB loss: 0.740251
2023-10-30 15:01:30,808 Epoch: [274/484] Iter:[50/495], Time: 0.41, lr: [0.0047146394762660315], Loss: 2.060537, Acc:0.795126, Semantic loss: 0.776486, BCE loss: 0.546401, SB loss: 0.737649
2023-10-30 15:01:34,622 Epoch: [274/484] Iter:[60/495], Time: 0.40, lr: [0.004714231083970662], Loss: 2.047664, Acc:0.787036, Semantic loss: 0.773210, BCE loss: 0.537899, SB loss: 0.736555
2023-10-30 15:01:38,367 Epoch: [274/484] Iter:[70/495], Time: 0.40, lr: [0.004713822687744269], Loss: 2.057649, Acc:0.789140, Semantic loss: 0.774326, BCE loss: 0.541671, SB loss: 0.741652
2023-10-30 15:01:42,044 Epoch: [274/484] Iter:[80/495], Time: 0.39, lr: [0.004713414287586433], Loss: 2.042010, Acc:0.792478, Semantic loss: 0.759925, BCE loss: 0.545469, SB loss: 0.736615
2023-10-30 15:01:45,772 Epoch: [274/484] Iter:[90/495], Time: 0.39, lr: [0.0047130058834967395], Loss: 2.045112, Acc:0.791392, Semantic loss: 0.760414, BCE loss: 0.546196, SB loss: 0.738502
2023-10-30 15:01:49,492 Epoch: [274/484] Iter:[100/495], Time: 0.39, lr: [0.004712597475474769], Loss: 2.031458, Acc:0.794320, Semantic loss: 0.756331, BCE loss: 0.542665, SB loss: 0.732462
2023-10-30 15:01:53,199 Epoch: [274/484] Iter:[110/495], Time: 0.39, lr: [0.00471218906352011], Loss: 2.019939, Acc:0.797917, Semantic loss: 0.750863, BCE loss: 0.537915, SB loss: 0.731162
2023-10-30 15:01:56,815 Epoch: [274/484] Iter:[120/495], Time: 0.39, lr: [0.0047117806476323415], Loss: 2.016276, Acc:0.797907, Semantic loss: 0.749750, BCE loss: 0.536779, SB loss: 0.729747
2023-10-30 15:02:00,516 Epoch: [274/484] Iter:[130/495], Time: 0.39, lr: [0.004711372227811049], Loss: 2.014804, Acc:0.797553, Semantic loss: 0.751754, BCE loss: 0.533331, SB loss: 0.729719
2023-10-30 15:02:04,184 Epoch: [274/484] Iter:[140/495], Time: 0.38, lr: [0.0047109638040558136], Loss: 2.010919, Acc:0.799227, Semantic loss: 0.751618, BCE loss: 0.531379, SB loss: 0.727921
2023-10-30 15:02:07,893 Epoch: [274/484] Iter:[150/495], Time: 0.38, lr: [0.004710555376366222], Loss: 2.013657, Acc:0.801152, Semantic loss: 0.753485, BCE loss: 0.533159, SB loss: 0.727012
2023-10-30 15:02:11,565 Epoch: [274/484] Iter:[160/495], Time: 0.38, lr: [0.004710146944741855], Loss: 2.016646, Acc:0.801801, Semantic loss: 0.754307, BCE loss: 0.534539, SB loss: 0.727800
2023-10-30 15:02:15,455 Epoch: [274/484] Iter:[170/495], Time: 0.38, lr: [0.004709738509182295], Loss: 2.012123, Acc:0.801797, Semantic loss: 0.751302, BCE loss: 0.533681, SB loss: 0.727140
2023-10-30 15:02:19,116 Epoch: [274/484] Iter:[180/495], Time: 0.38, lr: [0.004709330069687126], Loss: 2.011628, Acc:0.801781, Semantic loss: 0.749103, BCE loss: 0.535917, SB loss: 0.726608
2023-10-30 15:02:22,855 Epoch: [274/484] Iter:[190/495], Time: 0.38, lr: [0.004708921626255931], Loss: 2.013108, Acc:0.803419, Semantic loss: 0.749829, BCE loss: 0.536716, SB loss: 0.726562
2023-10-30 15:02:26,562 Epoch: [274/484] Iter:[200/495], Time: 0.38, lr: [0.004708513178888292], Loss: 2.013459, Acc:0.805213, Semantic loss: 0.749014, BCE loss: 0.538043, SB loss: 0.726402
2023-10-30 15:02:30,241 Epoch: [274/484] Iter:[210/495], Time: 0.38, lr: [0.004708104727583792], Loss: 2.007782, Acc:0.806342, Semantic loss: 0.745393, BCE loss: 0.537991, SB loss: 0.724398
2023-10-30 15:02:34,080 Epoch: [274/484] Iter:[220/495], Time: 0.38, lr: [0.0047076962723420135], Loss: 2.012333, Acc:0.804880, Semantic loss: 0.748234, BCE loss: 0.537853, SB loss: 0.726245
2023-10-30 15:02:37,830 Epoch: [274/484] Iter:[230/495], Time: 0.38, lr: [0.004707287813162538], Loss: 2.023691, Acc:0.806078, Semantic loss: 0.753506, BCE loss: 0.541818, SB loss: 0.728367
2023-10-30 15:02:41,506 Epoch: [274/484] Iter:[240/495], Time: 0.38, lr: [0.004706879350044951], Loss: 2.022263, Acc:0.806487, Semantic loss: 0.753776, BCE loss: 0.541332, SB loss: 0.727156
2023-10-30 15:02:45,196 Epoch: [274/484] Iter:[250/495], Time: 0.38, lr: [0.004706470882988831], Loss: 2.019109, Acc:0.805872, Semantic loss: 0.752224, BCE loss: 0.539576, SB loss: 0.727309
2023-10-30 15:02:48,862 Epoch: [274/484] Iter:[260/495], Time: 0.38, lr: [0.004706062411993762], Loss: 2.020626, Acc:0.805426, Semantic loss: 0.754831, BCE loss: 0.537577, SB loss: 0.728217
2023-10-30 15:02:52,545 Epoch: [274/484] Iter:[270/495], Time: 0.38, lr: [0.004705653937059326], Loss: 2.023193, Acc:0.805452, Semantic loss: 0.754329, BCE loss: 0.540016, SB loss: 0.728848
2023-10-30 15:02:56,162 Epoch: [274/484] Iter:[280/495], Time: 0.38, lr: [0.004705245458185106], Loss: 2.017650, Acc:0.804958, Semantic loss: 0.750781, BCE loss: 0.539696, SB loss: 0.727174
2023-10-30 15:02:59,947 Epoch: [274/484] Iter:[290/495], Time: 0.38, lr: [0.004704836975370682], Loss: 2.023472, Acc:0.803773, Semantic loss: 0.753336, BCE loss: 0.540031, SB loss: 0.730105
2023-10-30 15:03:03,596 Epoch: [274/484] Iter:[300/495], Time: 0.38, lr: [0.004704428488615637], Loss: 2.022436, Acc:0.804760, Semantic loss: 0.751017, BCE loss: 0.541630, SB loss: 0.729789
2023-10-30 15:03:07,447 Epoch: [274/484] Iter:[310/495], Time: 0.38, lr: [0.004704019997919553], Loss: 2.028304, Acc:0.803669, Semantic loss: 0.756112, BCE loss: 0.539249, SB loss: 0.732943
2023-10-30 15:03:11,101 Epoch: [274/484] Iter:[320/495], Time: 0.38, lr: [0.004703611503282011], Loss: 2.029900, Acc:0.803838, Semantic loss: 0.754245, BCE loss: 0.540296, SB loss: 0.735359
2023-10-30 15:03:14,811 Epoch: [274/484] Iter:[330/495], Time: 0.38, lr: [0.004703203004702594], Loss: 2.026710, Acc:0.803236, Semantic loss: 0.753125, BCE loss: 0.539546, SB loss: 0.734039
2023-10-30 15:03:18,441 Epoch: [274/484] Iter:[340/495], Time: 0.38, lr: [0.004702794502180881], Loss: 2.030412, Acc:0.802918, Semantic loss: 0.756438, BCE loss: 0.539285, SB loss: 0.734689
2023-10-30 15:03:22,126 Epoch: [274/484] Iter:[350/495], Time: 0.38, lr: [0.004702385995716455], Loss: 2.029230, Acc:0.802242, Semantic loss: 0.756221, BCE loss: 0.538517, SB loss: 0.734492
2023-10-30 15:03:25,804 Epoch: [274/484] Iter:[360/495], Time: 0.38, lr: [0.0047019774853088985], Loss: 2.022146, Acc:0.800698, Semantic loss: 0.754420, BCE loss: 0.535034, SB loss: 0.732692
2023-10-30 15:03:29,510 Epoch: [274/484] Iter:[370/495], Time: 0.38, lr: [0.004701568970957792], Loss: 2.025220, Acc:0.800799, Semantic loss: 0.756984, BCE loss: 0.534768, SB loss: 0.733468
2023-10-30 15:03:33,198 Epoch: [274/484] Iter:[380/495], Time: 0.38, lr: [0.004701160452662715], Loss: 2.028251, Acc:0.800033, Semantic loss: 0.759718, BCE loss: 0.533833, SB loss: 0.734701
2023-10-30 15:03:36,962 Epoch: [274/484] Iter:[390/495], Time: 0.38, lr: [0.00470075193042325], Loss: 2.028831, Acc:0.799871, Semantic loss: 0.759488, BCE loss: 0.534205, SB loss: 0.735138
2023-10-30 15:03:40,577 Epoch: [274/484] Iter:[400/495], Time: 0.38, lr: [0.004700343404238979], Loss: 2.025605, Acc:0.799952, Semantic loss: 0.757837, BCE loss: 0.533817, SB loss: 0.733950
2023-10-30 15:03:44,158 Epoch: [274/484] Iter:[410/495], Time: 0.37, lr: [0.004699934874109482], Loss: 2.023748, Acc:0.799989, Semantic loss: 0.757523, BCE loss: 0.532891, SB loss: 0.733335
2023-10-30 15:03:47,820 Epoch: [274/484] Iter:[420/495], Time: 0.37, lr: [0.004699526340034338], Loss: 2.023171, Acc:0.800498, Semantic loss: 0.756953, BCE loss: 0.533091, SB loss: 0.733127
2023-10-30 15:03:51,417 Epoch: [274/484] Iter:[430/495], Time: 0.37, lr: [0.004699117802013132], Loss: 2.021265, Acc:0.800692, Semantic loss: 0.755679, BCE loss: 0.532455, SB loss: 0.733131
2023-10-30 15:03:55,048 Epoch: [274/484] Iter:[440/495], Time: 0.37, lr: [0.0046987092600454415], Loss: 2.021944, Acc:0.800114, Semantic loss: 0.756775, BCE loss: 0.531966, SB loss: 0.733203
2023-10-30 15:03:58,760 Epoch: [274/484] Iter:[450/495], Time: 0.37, lr: [0.004698300714130847], Loss: 2.022111, Acc:0.800073, Semantic loss: 0.756882, BCE loss: 0.532598, SB loss: 0.732631
2023-10-30 15:04:02,529 Epoch: [274/484] Iter:[460/495], Time: 0.37, lr: [0.0046978921642689304], Loss: 2.019863, Acc:0.800017, Semantic loss: 0.755551, BCE loss: 0.531785, SB loss: 0.732526
2023-10-30 15:04:06,240 Epoch: [274/484] Iter:[470/495], Time: 0.37, lr: [0.004697483610459271], Loss: 2.018705, Acc:0.800469, Semantic loss: 0.754117, BCE loss: 0.532327, SB loss: 0.732261
2023-10-30 15:04:09,994 Epoch: [274/484] Iter:[480/495], Time: 0.37, lr: [0.004697075052701452], Loss: 2.017090, Acc:0.800338, Semantic loss: 0.753907, BCE loss: 0.531364, SB loss: 0.731818
2023-10-30 15:04:13,481 Epoch: [274/484] Iter:[490/495], Time: 0.37, lr: [0.0046966664909950506], Loss: 2.018899, Acc:0.800470, Semantic loss: 0.755014, BCE loss: 0.532062, SB loss: 0.731824
2023-10-30 15:04:14,879 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:04:15,116 Loss: 2.074, MeanIU:  0.6803, Best_mIoU:  0.7151
2023-10-30 15:04:15,116 [0.97411969 0.80830421 0.89314337 0.36388211 0.48696838 0.57728003
 0.65723379 0.67509681 0.9044329  0.57554219 0.93399221 0.77101824
 0.52843447 0.92402755 0.56201663 0.72929814 0.33033068 0.50287446
 0.72779841]
2023-10-30 15:04:17,184 Epoch: [275/484] Iter:[0/495], Time: 2.03, lr: [0.004696462208660998], Loss: 2.013288, Acc:0.809496, Semantic loss: 0.593902, BCE loss: 0.707190, SB loss: 0.712196
2023-10-30 15:04:21,244 Epoch: [275/484] Iter:[10/495], Time: 0.55, lr: [0.004696053641030937], Loss: 1.936468, Acc:0.787061, Semantic loss: 0.663908, BCE loss: 0.555516, SB loss: 0.717044
2023-10-30 15:04:24,939 Epoch: [275/484] Iter:[20/495], Time: 0.47, lr: [0.004695645069451245], Loss: 1.870770, Acc:0.783874, Semantic loss: 0.651802, BCE loss: 0.525626, SB loss: 0.693343
2023-10-30 15:04:28,628 Epoch: [275/484] Iter:[30/495], Time: 0.43, lr: [0.004695236493921501], Loss: 1.910895, Acc:0.794646, Semantic loss: 0.690228, BCE loss: 0.519566, SB loss: 0.701102
2023-10-30 15:04:32,212 Epoch: [275/484] Iter:[40/495], Time: 0.42, lr: [0.004694827914441284], Loss: 1.931197, Acc:0.792350, Semantic loss: 0.708766, BCE loss: 0.513690, SB loss: 0.708741
2023-10-30 15:04:35,964 Epoch: [275/484] Iter:[50/495], Time: 0.41, lr: [0.004694419331010178], Loss: 1.934956, Acc:0.799994, Semantic loss: 0.711924, BCE loss: 0.516648, SB loss: 0.706383
2023-10-30 15:04:39,656 Epoch: [275/484] Iter:[60/495], Time: 0.40, lr: [0.004694010743627759], Loss: 1.947970, Acc:0.805480, Semantic loss: 0.716955, BCE loss: 0.519601, SB loss: 0.711414
2023-10-30 15:04:43,204 Epoch: [275/484] Iter:[70/495], Time: 0.40, lr: [0.004693602152293608], Loss: 1.959686, Acc:0.804634, Semantic loss: 0.728090, BCE loss: 0.517052, SB loss: 0.714544
2023-10-30 15:04:46,839 Epoch: [275/484] Iter:[80/495], Time: 0.39, lr: [0.004693193557007303], Loss: 1.957666, Acc:0.802679, Semantic loss: 0.731105, BCE loss: 0.512611, SB loss: 0.713951
2023-10-30 15:04:50,622 Epoch: [275/484] Iter:[90/495], Time: 0.39, lr: [0.004692784957768426], Loss: 1.948661, Acc:0.803951, Semantic loss: 0.727328, BCE loss: 0.510713, SB loss: 0.710620
2023-10-30 15:04:54,225 Epoch: [275/484] Iter:[100/495], Time: 0.39, lr: [0.0046923763545765555], Loss: 1.964188, Acc:0.803651, Semantic loss: 0.736261, BCE loss: 0.512928, SB loss: 0.715000
2023-10-30 15:04:57,887 Epoch: [275/484] Iter:[110/495], Time: 0.38, lr: [0.00469196774743127], Loss: 1.964421, Acc:0.803471, Semantic loss: 0.737094, BCE loss: 0.511725, SB loss: 0.715601
2023-10-30 15:05:01,588 Epoch: [275/484] Iter:[120/495], Time: 0.38, lr: [0.0046915591363321475], Loss: 1.974664, Acc:0.804621, Semantic loss: 0.738174, BCE loss: 0.517667, SB loss: 0.718823
2023-10-30 15:05:05,227 Epoch: [275/484] Iter:[130/495], Time: 0.38, lr: [0.00469115052127877], Loss: 1.977538, Acc:0.804545, Semantic loss: 0.739282, BCE loss: 0.518839, SB loss: 0.719417
2023-10-30 15:05:08,823 Epoch: [275/484] Iter:[140/495], Time: 0.38, lr: [0.004690741902270716], Loss: 1.970622, Acc:0.803881, Semantic loss: 0.738687, BCE loss: 0.512562, SB loss: 0.719373
2023-10-30 15:05:12,564 Epoch: [275/484] Iter:[150/495], Time: 0.38, lr: [0.004690333279307563], Loss: 1.966822, Acc:0.803562, Semantic loss: 0.736930, BCE loss: 0.511697, SB loss: 0.718195
2023-10-30 15:05:16,248 Epoch: [275/484] Iter:[160/495], Time: 0.38, lr: [0.004689924652388889], Loss: 1.973330, Acc:0.801884, Semantic loss: 0.739534, BCE loss: 0.515146, SB loss: 0.718650
2023-10-30 15:05:19,926 Epoch: [275/484] Iter:[170/495], Time: 0.38, lr: [0.004689516021514276], Loss: 1.973403, Acc:0.800239, Semantic loss: 0.740504, BCE loss: 0.513123, SB loss: 0.719775
2023-10-30 15:05:23,700 Epoch: [275/484] Iter:[180/495], Time: 0.38, lr: [0.0046891073866833005], Loss: 1.976139, Acc:0.799624, Semantic loss: 0.741669, BCE loss: 0.513477, SB loss: 0.720993
2023-10-30 15:05:27,378 Epoch: [275/484] Iter:[190/495], Time: 0.38, lr: [0.004688698747895541], Loss: 1.979671, Acc:0.799153, Semantic loss: 0.743705, BCE loss: 0.515245, SB loss: 0.720721
2023-10-30 15:05:31,084 Epoch: [275/484] Iter:[200/495], Time: 0.38, lr: [0.004688290105150577], Loss: 1.976690, Acc:0.798893, Semantic loss: 0.742942, BCE loss: 0.513099, SB loss: 0.720649
2023-10-30 15:05:34,827 Epoch: [275/484] Iter:[210/495], Time: 0.38, lr: [0.004687881458447987], Loss: 1.981396, Acc:0.798402, Semantic loss: 0.744951, BCE loss: 0.514634, SB loss: 0.721811
2023-10-30 15:05:38,432 Epoch: [275/484] Iter:[220/495], Time: 0.38, lr: [0.004687472807787348], Loss: 1.980817, Acc:0.798040, Semantic loss: 0.745679, BCE loss: 0.513049, SB loss: 0.722089
2023-10-30 15:05:42,182 Epoch: [275/484] Iter:[230/495], Time: 0.38, lr: [0.004687064153168241], Loss: 1.978682, Acc:0.799412, Semantic loss: 0.743789, BCE loss: 0.513015, SB loss: 0.721878
2023-10-30 15:05:45,843 Epoch: [275/484] Iter:[240/495], Time: 0.38, lr: [0.00468665549459024], Loss: 1.977355, Acc:0.799431, Semantic loss: 0.741382, BCE loss: 0.513551, SB loss: 0.722422
2023-10-30 15:05:49,509 Epoch: [275/484] Iter:[250/495], Time: 0.38, lr: [0.0046862468320529255], Loss: 1.977524, Acc:0.799198, Semantic loss: 0.742087, BCE loss: 0.513145, SB loss: 0.722291
2023-10-30 15:05:53,214 Epoch: [275/484] Iter:[260/495], Time: 0.38, lr: [0.004685838165555877], Loss: 1.973652, Acc:0.799229, Semantic loss: 0.740255, BCE loss: 0.511550, SB loss: 0.721848
2023-10-30 15:05:56,849 Epoch: [275/484] Iter:[270/495], Time: 0.38, lr: [0.00468542949509867], Loss: 1.974527, Acc:0.799327, Semantic loss: 0.740516, BCE loss: 0.512414, SB loss: 0.721597
2023-10-30 15:06:00,785 Epoch: [275/484] Iter:[280/495], Time: 0.38, lr: [0.004685020820680882], Loss: 1.974814, Acc:0.800893, Semantic loss: 0.741107, BCE loss: 0.512193, SB loss: 0.721513
2023-10-30 15:06:04,433 Epoch: [275/484] Iter:[290/495], Time: 0.38, lr: [0.004684612142302092], Loss: 1.981150, Acc:0.801932, Semantic loss: 0.742768, BCE loss: 0.516394, SB loss: 0.721987
2023-10-30 15:06:08,149 Epoch: [275/484] Iter:[300/495], Time: 0.38, lr: [0.004684203459961879], Loss: 1.979968, Acc:0.802265, Semantic loss: 0.742606, BCE loss: 0.515290, SB loss: 0.722072
2023-10-30 15:06:11,825 Epoch: [275/484] Iter:[310/495], Time: 0.38, lr: [0.004683794773659818], Loss: 1.982130, Acc:0.802320, Semantic loss: 0.743602, BCE loss: 0.515847, SB loss: 0.722681
2023-10-30 15:06:15,511 Epoch: [275/484] Iter:[320/495], Time: 0.37, lr: [0.004683386083395487], Loss: 1.982348, Acc:0.802253, Semantic loss: 0.743883, BCE loss: 0.515723, SB loss: 0.722742
2023-10-30 15:06:19,303 Epoch: [275/484] Iter:[330/495], Time: 0.38, lr: [0.004682977389168465], Loss: 1.982123, Acc:0.802236, Semantic loss: 0.744710, BCE loss: 0.514685, SB loss: 0.722728
2023-10-30 15:06:23,005 Epoch: [275/484] Iter:[340/495], Time: 0.37, lr: [0.004682568690978328], Loss: 1.984837, Acc:0.802292, Semantic loss: 0.746009, BCE loss: 0.515286, SB loss: 0.723542
2023-10-30 15:06:26,650 Epoch: [275/484] Iter:[350/495], Time: 0.37, lr: [0.004682159988824654], Loss: 1.984621, Acc:0.801860, Semantic loss: 0.744272, BCE loss: 0.515944, SB loss: 0.724405
2023-10-30 15:06:30,267 Epoch: [275/484] Iter:[360/495], Time: 0.37, lr: [0.004681751282707019], Loss: 1.986165, Acc:0.801862, Semantic loss: 0.743867, BCE loss: 0.518079, SB loss: 0.724219
2023-10-30 15:06:33,965 Epoch: [275/484] Iter:[370/495], Time: 0.37, lr: [0.004681342572625], Loss: 1.985988, Acc:0.802877, Semantic loss: 0.743010, BCE loss: 0.518649, SB loss: 0.724329
2023-10-30 15:06:37,830 Epoch: [275/484] Iter:[380/495], Time: 0.37, lr: [0.0046809338585781755], Loss: 1.986277, Acc:0.802520, Semantic loss: 0.743845, BCE loss: 0.517826, SB loss: 0.724605
2023-10-30 15:06:41,459 Epoch: [275/484] Iter:[390/495], Time: 0.37, lr: [0.004680525140566122], Loss: 1.985523, Acc:0.803054, Semantic loss: 0.743098, BCE loss: 0.517809, SB loss: 0.724615
2023-10-30 15:06:45,205 Epoch: [275/484] Iter:[400/495], Time: 0.37, lr: [0.004680116418588415], Loss: 1.988117, Acc:0.802493, Semantic loss: 0.744694, BCE loss: 0.518192, SB loss: 0.725232
2023-10-30 15:06:48,976 Epoch: [275/484] Iter:[410/495], Time: 0.37, lr: [0.004679707692644632], Loss: 1.991321, Acc:0.802664, Semantic loss: 0.746590, BCE loss: 0.518275, SB loss: 0.726456
2023-10-30 15:06:52,622 Epoch: [275/484] Iter:[420/495], Time: 0.37, lr: [0.00467929896273435], Loss: 1.994795, Acc:0.801998, Semantic loss: 0.749647, BCE loss: 0.517879, SB loss: 0.727270
2023-10-30 15:06:56,351 Epoch: [275/484] Iter:[430/495], Time: 0.37, lr: [0.004678890228857145], Loss: 1.991995, Acc:0.801689, Semantic loss: 0.747296, BCE loss: 0.517766, SB loss: 0.726934
2023-10-30 15:07:00,069 Epoch: [275/484] Iter:[440/495], Time: 0.37, lr: [0.0046784814910125925], Loss: 1.994118, Acc:0.801924, Semantic loss: 0.747765, BCE loss: 0.518780, SB loss: 0.727573
2023-10-30 15:07:03,804 Epoch: [275/484] Iter:[450/495], Time: 0.37, lr: [0.004678072749200271], Loss: 1.995020, Acc:0.801662, Semantic loss: 0.748002, BCE loss: 0.518347, SB loss: 0.728670
2023-10-30 15:07:07,565 Epoch: [275/484] Iter:[460/495], Time: 0.37, lr: [0.004677664003419756], Loss: 2.004547, Acc:0.801404, Semantic loss: 0.754221, BCE loss: 0.519385, SB loss: 0.730942
2023-10-30 15:07:11,280 Epoch: [275/484] Iter:[470/495], Time: 0.37, lr: [0.0046772552536706235], Loss: 2.011698, Acc:0.800948, Semantic loss: 0.757736, BCE loss: 0.521086, SB loss: 0.732877
2023-10-30 15:07:14,984 Epoch: [275/484] Iter:[480/495], Time: 0.37, lr: [0.0046768464999524485], Loss: 2.008187, Acc:0.800374, Semantic loss: 0.755898, BCE loss: 0.520314, SB loss: 0.731975
2023-10-30 15:07:18,482 Epoch: [275/484] Iter:[490/495], Time: 0.37, lr: [0.004676437742264809], Loss: 2.011110, Acc:0.799996, Semantic loss: 0.757517, BCE loss: 0.520250, SB loss: 0.733343
2023-10-30 15:10:15,844 0 [9.30979671e-01 6.36478448e-01 8.15696722e-01 1.45450714e-01
 2.65038262e-01 3.93413271e-01 4.44770095e-01 5.68752010e-01
 8.73638909e-01 4.71252185e-01 8.55113036e-01 5.91308476e-01
 1.72845922e-02 7.86853174e-01 3.60994393e-04 6.99093598e-02
 3.19733227e-02 1.66470047e-02 5.41293696e-01] 0.4450638918310901
2023-10-30 15:10:15,844 1 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694] 0.6271666689409543
2023-10-30 15:10:15,848 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:10:16,090 Loss: 2.146, MeanIU:  0.6272, Best_mIoU:  0.7151
2023-10-30 15:10:16,090 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694]
2023-10-30 15:10:18,099 Epoch: [276/484] Iter:[0/495], Time: 1.98, lr: [0.004676233361932307], Loss: 2.128915, Acc:0.756585, Semantic loss: 0.718190, BCE loss: 0.653151, SB loss: 0.757573
2023-10-30 15:10:21,800 Epoch: [276/484] Iter:[10/495], Time: 0.52, lr: [0.004675824598289675], Loss: 2.093039, Acc:0.770933, Semantic loss: 0.845794, BCE loss: 0.502672, SB loss: 0.744572
2023-10-30 15:10:25,364 Epoch: [276/484] Iter:[20/495], Time: 0.44, lr: [0.004675415830676515], Loss: 2.145591, Acc:0.793512, Semantic loss: 0.844839, BCE loss: 0.525738, SB loss: 0.775014
2023-10-30 15:10:28,839 Epoch: [276/484] Iter:[30/495], Time: 0.41, lr: [0.004675007059092406], Loss: 2.121008, Acc:0.795093, Semantic loss: 0.830604, BCE loss: 0.527899, SB loss: 0.762505
2023-10-30 15:10:32,321 Epoch: [276/484] Iter:[40/495], Time: 0.40, lr: [0.004674598283536923], Loss: 2.109738, Acc:0.800919, Semantic loss: 0.811539, BCE loss: 0.539677, SB loss: 0.758523
2023-10-30 15:10:35,832 Epoch: [276/484] Iter:[50/495], Time: 0.39, lr: [0.004674189504009641], Loss: 2.072564, Acc:0.807470, Semantic loss: 0.789223, BCE loss: 0.532521, SB loss: 0.750820
2023-10-30 15:10:39,277 Epoch: [276/484] Iter:[60/495], Time: 0.38, lr: [0.004673780720510135], Loss: 2.084345, Acc:0.804900, Semantic loss: 0.790309, BCE loss: 0.539299, SB loss: 0.754737
2023-10-30 15:10:42,737 Epoch: [276/484] Iter:[70/495], Time: 0.37, lr: [0.004673371933037982], Loss: 2.058649, Acc:0.802411, Semantic loss: 0.779168, BCE loss: 0.532912, SB loss: 0.746569
2023-10-30 15:10:46,245 Epoch: [276/484] Iter:[80/495], Time: 0.37, lr: [0.004672963141592755], Loss: 2.058732, Acc:0.800500, Semantic loss: 0.783175, BCE loss: 0.529246, SB loss: 0.746311
2023-10-30 15:10:49,855 Epoch: [276/484] Iter:[90/495], Time: 0.37, lr: [0.004672554346174031], Loss: 2.038314, Acc:0.805393, Semantic loss: 0.773019, BCE loss: 0.523746, SB loss: 0.741550
2023-10-30 15:10:53,443 Epoch: [276/484] Iter:[100/495], Time: 0.37, lr: [0.004672145546781384], Loss: 2.051101, Acc:0.802332, Semantic loss: 0.779856, BCE loss: 0.525803, SB loss: 0.745442
2023-10-30 15:10:57,047 Epoch: [276/484] Iter:[110/495], Time: 0.37, lr: [0.00467173674341439], Loss: 2.051904, Acc:0.803372, Semantic loss: 0.775675, BCE loss: 0.531723, SB loss: 0.744505
2023-10-30 15:11:00,725 Epoch: [276/484] Iter:[120/495], Time: 0.37, lr: [0.004671327936072624], Loss: 2.048628, Acc:0.800996, Semantic loss: 0.774016, BCE loss: 0.530252, SB loss: 0.744359
2023-10-30 15:11:04,347 Epoch: [276/484] Iter:[130/495], Time: 0.37, lr: [0.00467091912475566], Loss: 2.052196, Acc:0.802831, Semantic loss: 0.774814, BCE loss: 0.532300, SB loss: 0.745081
2023-10-30 15:11:07,877 Epoch: [276/484] Iter:[140/495], Time: 0.37, lr: [0.004670510309463072], Loss: 2.052173, Acc:0.804178, Semantic loss: 0.775741, BCE loss: 0.532572, SB loss: 0.743859
2023-10-30 15:11:11,449 Epoch: [276/484] Iter:[150/495], Time: 0.37, lr: [0.0046701014901944365], Loss: 2.044617, Acc:0.803350, Semantic loss: 0.773179, BCE loss: 0.530793, SB loss: 0.740645
2023-10-30 15:11:15,080 Epoch: [276/484] Iter:[160/495], Time: 0.37, lr: [0.004669692666949328], Loss: 2.039839, Acc:0.801981, Semantic loss: 0.773764, BCE loss: 0.526973, SB loss: 0.739101
2023-10-30 15:11:18,785 Epoch: [276/484] Iter:[170/495], Time: 0.37, lr: [0.0046692838397273196], Loss: 2.048531, Acc:0.799900, Semantic loss: 0.781337, BCE loss: 0.526001, SB loss: 0.741193
2023-10-30 15:11:22,467 Epoch: [276/484] Iter:[180/495], Time: 0.37, lr: [0.004668875008527986], Loss: 2.060901, Acc:0.799351, Semantic loss: 0.786824, BCE loss: 0.529148, SB loss: 0.744930
2023-10-30 15:11:26,176 Epoch: [276/484] Iter:[190/495], Time: 0.37, lr: [0.004668466173350903], Loss: 2.068664, Acc:0.800515, Semantic loss: 0.790699, BCE loss: 0.532782, SB loss: 0.745183
2023-10-30 15:11:29,808 Epoch: [276/484] Iter:[200/495], Time: 0.37, lr: [0.004668057334195643], Loss: 2.065399, Acc:0.800314, Semantic loss: 0.786262, BCE loss: 0.534064, SB loss: 0.745073
2023-10-30 15:11:33,443 Epoch: [276/484] Iter:[210/495], Time: 0.37, lr: [0.0046676484910617815], Loss: 2.067569, Acc:0.799490, Semantic loss: 0.786521, BCE loss: 0.536277, SB loss: 0.744771
2023-10-30 15:11:37,087 Epoch: [276/484] Iter:[220/495], Time: 0.37, lr: [0.004667239643948891], Loss: 2.062207, Acc:0.800919, Semantic loss: 0.781410, BCE loss: 0.537988, SB loss: 0.742809
2023-10-30 15:11:40,748 Epoch: [276/484] Iter:[230/495], Time: 0.37, lr: [0.004666830792856548], Loss: 2.055279, Acc:0.801994, Semantic loss: 0.776436, BCE loss: 0.537761, SB loss: 0.741082
2023-10-30 15:11:44,477 Epoch: [276/484] Iter:[240/495], Time: 0.37, lr: [0.004666421937784325], Loss: 2.054391, Acc:0.803796, Semantic loss: 0.773875, BCE loss: 0.539483, SB loss: 0.741033
2023-10-30 15:11:48,159 Epoch: [276/484] Iter:[250/495], Time: 0.37, lr: [0.004666013078731795], Loss: 2.048229, Acc:0.803232, Semantic loss: 0.770903, BCE loss: 0.537147, SB loss: 0.740179
2023-10-30 15:11:51,740 Epoch: [276/484] Iter:[260/495], Time: 0.37, lr: [0.004665604215698531], Loss: 2.052820, Acc:0.802602, Semantic loss: 0.774032, BCE loss: 0.537472, SB loss: 0.741317
2023-10-30 15:11:55,369 Epoch: [276/484] Iter:[270/495], Time: 0.37, lr: [0.00466519534868411], Loss: 2.044281, Acc:0.802511, Semantic loss: 0.769830, BCE loss: 0.535599, SB loss: 0.738852
2023-10-30 15:11:59,089 Epoch: [276/484] Iter:[280/495], Time: 0.37, lr: [0.004664786477688103], Loss: 2.041565, Acc:0.803296, Semantic loss: 0.768363, BCE loss: 0.535305, SB loss: 0.737897
2023-10-30 15:12:02,785 Epoch: [276/484] Iter:[290/495], Time: 0.37, lr: [0.004664377602710085], Loss: 2.041188, Acc:0.802852, Semantic loss: 0.767269, BCE loss: 0.536857, SB loss: 0.737061
2023-10-30 15:12:06,368 Epoch: [276/484] Iter:[300/495], Time: 0.37, lr: [0.004663968723749626], Loss: 2.036927, Acc:0.801596, Semantic loss: 0.766007, BCE loss: 0.533375, SB loss: 0.737545
2023-10-30 15:12:10,048 Epoch: [276/484] Iter:[310/495], Time: 0.37, lr: [0.004663559840806303], Loss: 2.037776, Acc:0.801380, Semantic loss: 0.766062, BCE loss: 0.533382, SB loss: 0.738332
2023-10-30 15:12:13,755 Epoch: [276/484] Iter:[320/495], Time: 0.37, lr: [0.004663150953879689], Loss: 2.034423, Acc:0.802155, Semantic loss: 0.763878, BCE loss: 0.532827, SB loss: 0.737719
2023-10-30 15:12:17,361 Epoch: [276/484] Iter:[330/495], Time: 0.37, lr: [0.0046627420629693555], Loss: 2.039546, Acc:0.802823, Semantic loss: 0.767093, BCE loss: 0.533519, SB loss: 0.738935
2023-10-30 15:12:21,001 Epoch: [276/484] Iter:[340/495], Time: 0.37, lr: [0.004662333168074875], Loss: 2.046803, Acc:0.803328, Semantic loss: 0.771238, BCE loss: 0.533611, SB loss: 0.741954
2023-10-30 15:12:24,668 Epoch: [276/484] Iter:[350/495], Time: 0.37, lr: [0.004661924269195822], Loss: 2.049909, Acc:0.803244, Semantic loss: 0.771633, BCE loss: 0.535788, SB loss: 0.742488
2023-10-30 15:12:28,360 Epoch: [276/484] Iter:[360/495], Time: 0.37, lr: [0.0046615153663317685], Loss: 2.045966, Acc:0.802703, Semantic loss: 0.770123, BCE loss: 0.534509, SB loss: 0.741334
2023-10-30 15:12:31,914 Epoch: [276/484] Iter:[370/495], Time: 0.37, lr: [0.004661106459482288], Loss: 2.045456, Acc:0.802107, Semantic loss: 0.770132, BCE loss: 0.534306, SB loss: 0.741018
2023-10-30 15:12:35,619 Epoch: [276/484] Iter:[380/495], Time: 0.37, lr: [0.004660697548646952], Loss: 2.044072, Acc:0.802350, Semantic loss: 0.769986, BCE loss: 0.533513, SB loss: 0.740573
2023-10-30 15:12:39,287 Epoch: [276/484] Iter:[390/495], Time: 0.37, lr: [0.0046602886338253345], Loss: 2.044689, Acc:0.801857, Semantic loss: 0.772079, BCE loss: 0.531741, SB loss: 0.740868
2023-10-30 15:12:42,908 Epoch: [276/484] Iter:[400/495], Time: 0.37, lr: [0.004659879715017008], Loss: 2.044415, Acc:0.800679, Semantic loss: 0.771775, BCE loss: 0.531219, SB loss: 0.741421
2023-10-30 15:12:46,627 Epoch: [276/484] Iter:[410/495], Time: 0.37, lr: [0.004659470792221542], Loss: 2.039534, Acc:0.800362, Semantic loss: 0.769223, BCE loss: 0.530185, SB loss: 0.740126
2023-10-30 15:12:50,252 Epoch: [276/484] Iter:[420/495], Time: 0.37, lr: [0.0046590618654385125], Loss: 2.040436, Acc:0.800148, Semantic loss: 0.769564, BCE loss: 0.530480, SB loss: 0.740392
2023-10-30 15:12:53,885 Epoch: [276/484] Iter:[430/495], Time: 0.37, lr: [0.00465865293466749], Loss: 2.039117, Acc:0.800160, Semantic loss: 0.769384, BCE loss: 0.529902, SB loss: 0.739830
2023-10-30 15:12:57,524 Epoch: [276/484] Iter:[440/495], Time: 0.37, lr: [0.004658243999908047], Loss: 2.037752, Acc:0.800701, Semantic loss: 0.768218, BCE loss: 0.529740, SB loss: 0.739794
2023-10-30 15:13:01,187 Epoch: [276/484] Iter:[450/495], Time: 0.37, lr: [0.004657835061159755], Loss: 2.037735, Acc:0.799523, Semantic loss: 0.768225, BCE loss: 0.529405, SB loss: 0.740104
2023-10-30 15:13:04,820 Epoch: [276/484] Iter:[460/495], Time: 0.37, lr: [0.004657426118422187], Loss: 2.035817, Acc:0.799601, Semantic loss: 0.766842, BCE loss: 0.529951, SB loss: 0.739024
2023-10-30 15:13:08,427 Epoch: [276/484] Iter:[470/495], Time: 0.37, lr: [0.004657017171694914], Loss: 2.034618, Acc:0.799287, Semantic loss: 0.766287, BCE loss: 0.529797, SB loss: 0.738535
2023-10-30 15:13:12,137 Epoch: [276/484] Iter:[480/495], Time: 0.37, lr: [0.0046566082209775084], Loss: 2.033292, Acc:0.799585, Semantic loss: 0.765747, BCE loss: 0.529799, SB loss: 0.737745
2023-10-30 15:13:15,716 Epoch: [276/484] Iter:[490/495], Time: 0.37, lr: [0.004656199266269541], Loss: 2.035409, Acc:0.799773, Semantic loss: 0.765963, BCE loss: 0.532002, SB loss: 0.737444
2023-10-30 15:13:17,121 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:13:17,357 Loss: 2.146, MeanIU:  0.6272, Best_mIoU:  0.7151
2023-10-30 15:13:17,357 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694]
2023-10-30 15:13:19,334 Epoch: [277/484] Iter:[0/495], Time: 1.94, lr: [0.004655994787418963], Loss: 2.349905, Acc:0.711640, Semantic loss: 0.946581, BCE loss: 0.499723, SB loss: 0.903601
2023-10-30 15:13:23,259 Epoch: [277/484] Iter:[10/495], Time: 0.53, lr: [0.004655585826724352], Loss: 2.054366, Acc:0.812546, Semantic loss: 0.738632, BCE loss: 0.585761, SB loss: 0.729973
2023-10-30 15:13:26,947 Epoch: [277/484] Iter:[20/495], Time: 0.45, lr: [0.004655176862038107], Loss: 1.988188, Acc:0.812656, Semantic loss: 0.724615, BCE loss: 0.543578, SB loss: 0.719995
2023-10-30 15:13:30,527 Epoch: [277/484] Iter:[30/495], Time: 0.42, lr: [0.004654767893359802], Loss: 1.993114, Acc:0.812352, Semantic loss: 0.730815, BCE loss: 0.535778, SB loss: 0.726520
2023-10-30 15:13:34,354 Epoch: [277/484] Iter:[40/495], Time: 0.41, lr: [0.004654358920689006], Loss: 2.032205, Acc:0.810586, Semantic loss: 0.741149, BCE loss: 0.547711, SB loss: 0.743345
2023-10-30 15:13:38,060 Epoch: [277/484] Iter:[50/495], Time: 0.41, lr: [0.004653949944025292], Loss: 2.028415, Acc:0.812130, Semantic loss: 0.740615, BCE loss: 0.548652, SB loss: 0.739148
2023-10-30 15:13:41,805 Epoch: [277/484] Iter:[60/495], Time: 0.40, lr: [0.004653540963368232], Loss: 2.028197, Acc:0.815228, Semantic loss: 0.744265, BCE loss: 0.547114, SB loss: 0.736817
2023-10-30 15:13:45,477 Epoch: [277/484] Iter:[70/495], Time: 0.40, lr: [0.004653131978717396], Loss: 2.025546, Acc:0.819800, Semantic loss: 0.743232, BCE loss: 0.551209, SB loss: 0.731106
2023-10-30 15:13:49,119 Epoch: [277/484] Iter:[80/495], Time: 0.39, lr: [0.004652722990072352], Loss: 2.032354, Acc:0.817255, Semantic loss: 0.751787, BCE loss: 0.551956, SB loss: 0.728612
2023-10-30 15:13:52,784 Epoch: [277/484] Iter:[90/495], Time: 0.39, lr: [0.0046523139974326755], Loss: 2.028207, Acc:0.815845, Semantic loss: 0.752188, BCE loss: 0.547660, SB loss: 0.728359
2023-10-30 15:13:56,485 Epoch: [277/484] Iter:[100/495], Time: 0.39, lr: [0.004651905000797936], Loss: 2.025761, Acc:0.815321, Semantic loss: 0.750711, BCE loss: 0.544814, SB loss: 0.730236
2023-10-30 15:14:00,189 Epoch: [277/484] Iter:[110/495], Time: 0.39, lr: [0.004651496000167702], Loss: 2.038835, Acc:0.814776, Semantic loss: 0.757953, BCE loss: 0.549280, SB loss: 0.731603
2023-10-30 15:14:03,882 Epoch: [277/484] Iter:[120/495], Time: 0.38, lr: [0.004651086995541546], Loss: 2.035736, Acc:0.812858, Semantic loss: 0.755600, BCE loss: 0.549310, SB loss: 0.730826
2023-10-30 15:14:07,563 Epoch: [277/484] Iter:[130/495], Time: 0.38, lr: [0.004650677986919039], Loss: 2.030252, Acc:0.813570, Semantic loss: 0.751557, BCE loss: 0.549705, SB loss: 0.728989
2023-10-30 15:14:11,266 Epoch: [277/484] Iter:[140/495], Time: 0.38, lr: [0.00465026897429975], Loss: 2.032211, Acc:0.811014, Semantic loss: 0.754696, BCE loss: 0.547614, SB loss: 0.729901
2023-10-30 15:14:14,978 Epoch: [277/484] Iter:[150/495], Time: 0.38, lr: [0.004649859957683251], Loss: 2.031095, Acc:0.807402, Semantic loss: 0.756015, BCE loss: 0.546258, SB loss: 0.728823
2023-10-30 15:14:18,634 Epoch: [277/484] Iter:[160/495], Time: 0.38, lr: [0.00464945093706911], Loss: 2.031820, Acc:0.806098, Semantic loss: 0.754575, BCE loss: 0.549593, SB loss: 0.727653
2023-10-30 15:14:22,475 Epoch: [277/484] Iter:[170/495], Time: 0.38, lr: [0.0046490419124568996], Loss: 2.024994, Acc:0.806732, Semantic loss: 0.752077, BCE loss: 0.547957, SB loss: 0.724960
2023-10-30 15:14:26,093 Epoch: [277/484] Iter:[180/495], Time: 0.38, lr: [0.004648632883846188], Loss: 2.027550, Acc:0.807971, Semantic loss: 0.752817, BCE loss: 0.547799, SB loss: 0.726933
2023-10-30 15:14:29,768 Epoch: [277/484] Iter:[190/495], Time: 0.38, lr: [0.004648223851236546], Loss: 2.018951, Acc:0.807006, Semantic loss: 0.748194, BCE loss: 0.544106, SB loss: 0.726652
2023-10-30 15:14:33,414 Epoch: [277/484] Iter:[200/495], Time: 0.38, lr: [0.004647814814627543], Loss: 2.019120, Acc:0.805249, Semantic loss: 0.749374, BCE loss: 0.544015, SB loss: 0.725732
2023-10-30 15:14:37,059 Epoch: [277/484] Iter:[210/495], Time: 0.38, lr: [0.004647405774018749], Loss: 2.012096, Acc:0.805171, Semantic loss: 0.747840, BCE loss: 0.540138, SB loss: 0.724118
2023-10-30 15:14:40,719 Epoch: [277/484] Iter:[220/495], Time: 0.38, lr: [0.0046469967294097345], Loss: 2.011018, Acc:0.806292, Semantic loss: 0.747658, BCE loss: 0.539477, SB loss: 0.723883
2023-10-30 15:14:44,323 Epoch: [277/484] Iter:[230/495], Time: 0.38, lr: [0.004646587680800067], Loss: 2.010646, Acc:0.805793, Semantic loss: 0.747537, BCE loss: 0.539617, SB loss: 0.723492
2023-10-30 15:14:47,972 Epoch: [277/484] Iter:[240/495], Time: 0.38, lr: [0.004646178628189319], Loss: 2.007588, Acc:0.805492, Semantic loss: 0.747244, BCE loss: 0.537222, SB loss: 0.723122
2023-10-30 15:14:51,691 Epoch: [277/484] Iter:[250/495], Time: 0.38, lr: [0.004645769571577058], Loss: 2.005009, Acc:0.804234, Semantic loss: 0.745739, BCE loss: 0.537451, SB loss: 0.721820
2023-10-30 15:14:55,394 Epoch: [277/484] Iter:[260/495], Time: 0.38, lr: [0.004645360510962856], Loss: 2.007499, Acc:0.805069, Semantic loss: 0.745459, BCE loss: 0.540342, SB loss: 0.721697
2023-10-30 15:14:59,158 Epoch: [277/484] Iter:[270/495], Time: 0.38, lr: [0.004644951446346277], Loss: 2.006235, Acc:0.805062, Semantic loss: 0.745059, BCE loss: 0.540628, SB loss: 0.720548
2023-10-30 15:15:02,809 Epoch: [277/484] Iter:[280/495], Time: 0.38, lr: [0.0046445423777268955], Loss: 2.006183, Acc:0.806403, Semantic loss: 0.747329, BCE loss: 0.538694, SB loss: 0.720160
2023-10-30 15:15:06,526 Epoch: [277/484] Iter:[290/495], Time: 0.38, lr: [0.004644133305104278], Loss: 2.004471, Acc:0.804793, Semantic loss: 0.749291, BCE loss: 0.535628, SB loss: 0.719552
2023-10-30 15:15:10,255 Epoch: [277/484] Iter:[300/495], Time: 0.37, lr: [0.004643724228477994], Loss: 2.003800, Acc:0.804303, Semantic loss: 0.748710, BCE loss: 0.535116, SB loss: 0.719973
2023-10-30 15:15:13,967 Epoch: [277/484] Iter:[310/495], Time: 0.37, lr: [0.004643315147847611], Loss: 2.003396, Acc:0.805246, Semantic loss: 0.748377, BCE loss: 0.535467, SB loss: 0.719552
2023-10-30 15:15:17,917 Epoch: [277/484] Iter:[320/495], Time: 0.38, lr: [0.0046429060632127], Loss: 2.002900, Acc:0.804661, Semantic loss: 0.749197, BCE loss: 0.534729, SB loss: 0.718974
2023-10-30 15:15:21,727 Epoch: [277/484] Iter:[330/495], Time: 0.38, lr: [0.004642496974572831], Loss: 2.002112, Acc:0.805907, Semantic loss: 0.749021, BCE loss: 0.534724, SB loss: 0.718367
2023-10-30 15:15:25,678 Epoch: [277/484] Iter:[340/495], Time: 0.38, lr: [0.004642087881927569], Loss: 2.002422, Acc:0.806070, Semantic loss: 0.749609, BCE loss: 0.534233, SB loss: 0.718580
2023-10-30 15:15:29,456 Epoch: [277/484] Iter:[350/495], Time: 0.38, lr: [0.004641678785276483], Loss: 2.006796, Acc:0.806082, Semantic loss: 0.753443, BCE loss: 0.534158, SB loss: 0.719195
2023-10-30 15:15:33,284 Epoch: [277/484] Iter:[360/495], Time: 0.38, lr: [0.004641269684619145], Loss: 2.008066, Acc:0.805654, Semantic loss: 0.753776, BCE loss: 0.533842, SB loss: 0.720449
2023-10-30 15:15:37,021 Epoch: [277/484] Iter:[370/495], Time: 0.38, lr: [0.0046408605799551205], Loss: 2.008377, Acc:0.806231, Semantic loss: 0.754446, BCE loss: 0.532582, SB loss: 0.721350
2023-10-30 15:15:40,759 Epoch: [277/484] Iter:[380/495], Time: 0.38, lr: [0.004640451471283978], Loss: 2.009269, Acc:0.805784, Semantic loss: 0.754063, BCE loss: 0.533913, SB loss: 0.721293
2023-10-30 15:15:44,412 Epoch: [277/484] Iter:[390/495], Time: 0.38, lr: [0.004640042358605286], Loss: 2.013283, Acc:0.805489, Semantic loss: 0.756110, BCE loss: 0.534624, SB loss: 0.722549
2023-10-30 15:15:48,147 Epoch: [277/484] Iter:[400/495], Time: 0.38, lr: [0.004639633241918613], Loss: 2.016036, Acc:0.804883, Semantic loss: 0.757438, BCE loss: 0.534761, SB loss: 0.723837
2023-10-30 15:15:51,821 Epoch: [277/484] Iter:[410/495], Time: 0.38, lr: [0.004639224121223528], Loss: 2.019261, Acc:0.804525, Semantic loss: 0.757611, BCE loss: 0.537174, SB loss: 0.724476
2023-10-30 15:15:55,597 Epoch: [277/484] Iter:[420/495], Time: 0.38, lr: [0.004638814996519597], Loss: 2.023362, Acc:0.804440, Semantic loss: 0.759375, BCE loss: 0.538290, SB loss: 0.725697
2023-10-30 15:15:59,198 Epoch: [277/484] Iter:[430/495], Time: 0.38, lr: [0.004638405867806387], Loss: 2.021413, Acc:0.804275, Semantic loss: 0.758542, BCE loss: 0.537398, SB loss: 0.725473
2023-10-30 15:16:02,888 Epoch: [277/484] Iter:[440/495], Time: 0.38, lr: [0.004637996735083469], Loss: 2.023892, Acc:0.803433, Semantic loss: 0.760092, BCE loss: 0.537398, SB loss: 0.726402
2023-10-30 15:16:06,674 Epoch: [277/484] Iter:[450/495], Time: 0.38, lr: [0.004637587598350409], Loss: 2.025701, Acc:0.803678, Semantic loss: 0.759879, BCE loss: 0.539201, SB loss: 0.726621
2023-10-30 15:16:10,335 Epoch: [277/484] Iter:[460/495], Time: 0.38, lr: [0.004637178457606775], Loss: 2.026031, Acc:0.803977, Semantic loss: 0.759928, BCE loss: 0.539217, SB loss: 0.726886
2023-10-30 15:16:13,969 Epoch: [277/484] Iter:[470/495], Time: 0.37, lr: [0.004636769312852133], Loss: 2.022724, Acc:0.803952, Semantic loss: 0.757525, BCE loss: 0.538801, SB loss: 0.726398
2023-10-30 15:16:17,762 Epoch: [277/484] Iter:[480/495], Time: 0.37, lr: [0.004636360164086052], Loss: 2.020616, Acc:0.803473, Semantic loss: 0.757108, BCE loss: 0.537576, SB loss: 0.725932
2023-10-30 15:16:21,341 Epoch: [277/484] Iter:[490/495], Time: 0.37, lr: [0.0046359510113080996], Loss: 2.023491, Acc:0.803523, Semantic loss: 0.759103, BCE loss: 0.537256, SB loss: 0.727132
2023-10-30 15:16:22,746 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:16:22,982 Loss: 2.146, MeanIU:  0.6272, Best_mIoU:  0.7151
2023-10-30 15:16:22,982 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694]
2023-10-30 15:16:25,035 Epoch: [278/484] Iter:[0/495], Time: 2.02, lr: [0.004635746433414536], Loss: 2.593614, Acc:0.695682, Semantic loss: 1.139066, BCE loss: 0.673247, SB loss: 0.781301
2023-10-30 15:16:29,048 Epoch: [278/484] Iter:[10/495], Time: 0.55, lr: [0.004635337274617964], Loss: 1.919133, Acc:0.785168, Semantic loss: 0.715464, BCE loss: 0.504765, SB loss: 0.698903
2023-10-30 15:16:32,707 Epoch: [278/484] Iter:[20/495], Time: 0.46, lr: [0.004634928111808437], Loss: 1.985811, Acc:0.783465, Semantic loss: 0.740646, BCE loss: 0.529042, SB loss: 0.716123
2023-10-30 15:16:36,312 Epoch: [278/484] Iter:[30/495], Time: 0.43, lr: [0.004634518944985524], Loss: 1.980173, Acc:0.788496, Semantic loss: 0.741615, BCE loss: 0.524957, SB loss: 0.713601
2023-10-30 15:16:39,948 Epoch: [278/484] Iter:[40/495], Time: 0.41, lr: [0.00463410977414879], Loss: 1.988885, Acc:0.787697, Semantic loss: 0.749156, BCE loss: 0.518118, SB loss: 0.721611
2023-10-30 15:16:43,631 Epoch: [278/484] Iter:[50/495], Time: 0.40, lr: [0.0046337005992978025], Loss: 1.995721, Acc:0.792724, Semantic loss: 0.745829, BCE loss: 0.522610, SB loss: 0.727282
2023-10-30 15:16:47,375 Epoch: [278/484] Iter:[60/495], Time: 0.40, lr: [0.004633291420432129], Loss: 2.004778, Acc:0.797212, Semantic loss: 0.747128, BCE loss: 0.530363, SB loss: 0.727286
2023-10-30 15:16:50,998 Epoch: [278/484] Iter:[70/495], Time: 0.39, lr: [0.004632882237551335], Loss: 1.999357, Acc:0.798513, Semantic loss: 0.743202, BCE loss: 0.530495, SB loss: 0.725660
2023-10-30 15:16:54,811 Epoch: [278/484] Iter:[80/495], Time: 0.39, lr: [0.004632473050654989], Loss: 2.002569, Acc:0.804065, Semantic loss: 0.742361, BCE loss: 0.536774, SB loss: 0.723433
2023-10-30 15:16:58,505 Epoch: [278/484] Iter:[90/495], Time: 0.39, lr: [0.0046320638597426534], Loss: 1.993084, Acc:0.804818, Semantic loss: 0.740355, BCE loss: 0.529884, SB loss: 0.722845
2023-10-30 15:17:02,159 Epoch: [278/484] Iter:[100/495], Time: 0.39, lr: [0.004631654664813899], Loss: 1.993535, Acc:0.808305, Semantic loss: 0.741051, BCE loss: 0.533074, SB loss: 0.719411
2023-10-30 15:17:05,880 Epoch: [278/484] Iter:[110/495], Time: 0.39, lr: [0.004631245465868291], Loss: 1.996510, Acc:0.806128, Semantic loss: 0.744101, BCE loss: 0.531082, SB loss: 0.721327
2023-10-30 15:17:09,538 Epoch: [278/484] Iter:[120/495], Time: 0.38, lr: [0.004630836262905394], Loss: 2.004573, Acc:0.808408, Semantic loss: 0.744535, BCE loss: 0.537901, SB loss: 0.722137
2023-10-30 15:17:13,214 Epoch: [278/484] Iter:[130/495], Time: 0.38, lr: [0.004630427055924775], Loss: 2.005381, Acc:0.809019, Semantic loss: 0.746840, BCE loss: 0.538232, SB loss: 0.720309
2023-10-30 15:17:16,910 Epoch: [278/484] Iter:[140/495], Time: 0.38, lr: [0.004630017844926001], Loss: 1.995571, Acc:0.805969, Semantic loss: 0.743901, BCE loss: 0.532796, SB loss: 0.718875
2023-10-30 15:17:20,512 Epoch: [278/484] Iter:[150/495], Time: 0.38, lr: [0.004629608629908637], Loss: 1.996616, Acc:0.805719, Semantic loss: 0.744849, BCE loss: 0.532027, SB loss: 0.719740
2023-10-30 15:17:24,134 Epoch: [278/484] Iter:[160/495], Time: 0.38, lr: [0.004629199410872248], Loss: 1.998153, Acc:0.805447, Semantic loss: 0.746351, BCE loss: 0.530306, SB loss: 0.721496
2023-10-30 15:17:27,726 Epoch: [278/484] Iter:[170/495], Time: 0.38, lr: [0.004628790187816401], Loss: 2.000720, Acc:0.803388, Semantic loss: 0.748297, BCE loss: 0.528776, SB loss: 0.723646
2023-10-30 15:17:31,501 Epoch: [278/484] Iter:[180/495], Time: 0.38, lr: [0.004628380960740662], Loss: 2.001690, Acc:0.802895, Semantic loss: 0.750760, BCE loss: 0.527597, SB loss: 0.723333
2023-10-30 15:17:35,133 Epoch: [278/484] Iter:[190/495], Time: 0.38, lr: [0.004627971729644596], Loss: 1.999506, Acc:0.801966, Semantic loss: 0.748930, BCE loss: 0.528773, SB loss: 0.721802
2023-10-30 15:17:38,873 Epoch: [278/484] Iter:[200/495], Time: 0.38, lr: [0.0046275624945277686], Loss: 2.000979, Acc:0.801273, Semantic loss: 0.751268, BCE loss: 0.527411, SB loss: 0.722300
2023-10-30 15:17:42,527 Epoch: [278/484] Iter:[210/495], Time: 0.38, lr: [0.004627153255389744], Loss: 2.003362, Acc:0.800885, Semantic loss: 0.751765, BCE loss: 0.527260, SB loss: 0.724336
2023-10-30 15:17:46,165 Epoch: [278/484] Iter:[220/495], Time: 0.38, lr: [0.0046267440122300905], Loss: 2.001034, Acc:0.801675, Semantic loss: 0.749193, BCE loss: 0.527103, SB loss: 0.724737
2023-10-30 15:17:49,937 Epoch: [278/484] Iter:[230/495], Time: 0.38, lr: [0.00462633476504837], Loss: 2.000386, Acc:0.801467, Semantic loss: 0.748598, BCE loss: 0.527965, SB loss: 0.723824
2023-10-30 15:17:53,686 Epoch: [278/484] Iter:[240/495], Time: 0.38, lr: [0.00462592551384415], Loss: 1.999672, Acc:0.800941, Semantic loss: 0.749299, BCE loss: 0.526322, SB loss: 0.724051
2023-10-30 15:17:57,387 Epoch: [278/484] Iter:[250/495], Time: 0.38, lr: [0.004625516258616993], Loss: 1.998712, Acc:0.801308, Semantic loss: 0.749953, BCE loss: 0.524925, SB loss: 0.723834
2023-10-30 15:18:01,054 Epoch: [278/484] Iter:[260/495], Time: 0.38, lr: [0.004625106999366467], Loss: 2.003584, Acc:0.801012, Semantic loss: 0.752728, BCE loss: 0.524550, SB loss: 0.726306
2023-10-30 15:18:04,842 Epoch: [278/484] Iter:[270/495], Time: 0.38, lr: [0.004624697736092135], Loss: 2.005522, Acc:0.801290, Semantic loss: 0.751837, BCE loss: 0.526052, SB loss: 0.727632
2023-10-30 15:18:08,502 Epoch: [278/484] Iter:[280/495], Time: 0.38, lr: [0.004624288468793563], Loss: 2.004485, Acc:0.801219, Semantic loss: 0.751264, BCE loss: 0.525295, SB loss: 0.727925
2023-10-30 15:18:12,170 Epoch: [278/484] Iter:[290/495], Time: 0.38, lr: [0.004623879197470313], Loss: 2.004139, Acc:0.800999, Semantic loss: 0.751706, BCE loss: 0.525532, SB loss: 0.726902
2023-10-30 15:18:15,848 Epoch: [278/484] Iter:[300/495], Time: 0.37, lr: [0.004623469922121952], Loss: 2.000209, Acc:0.800063, Semantic loss: 0.750271, BCE loss: 0.523295, SB loss: 0.726643
2023-10-30 15:18:19,581 Epoch: [278/484] Iter:[310/495], Time: 0.37, lr: [0.004623060642748046], Loss: 2.008668, Acc:0.799525, Semantic loss: 0.756017, BCE loss: 0.525202, SB loss: 0.727448
2023-10-30 15:18:23,245 Epoch: [278/484] Iter:[320/495], Time: 0.37, lr: [0.0046226513593481565], Loss: 2.009552, Acc:0.799409, Semantic loss: 0.755476, BCE loss: 0.527074, SB loss: 0.727002
2023-10-30 15:18:26,858 Epoch: [278/484] Iter:[330/495], Time: 0.37, lr: [0.004622242071921847], Loss: 2.006226, Acc:0.798498, Semantic loss: 0.753836, BCE loss: 0.525202, SB loss: 0.727187
2023-10-30 15:18:30,430 Epoch: [278/484] Iter:[340/495], Time: 0.37, lr: [0.0046218327804686855], Loss: 2.011247, Acc:0.797943, Semantic loss: 0.758341, BCE loss: 0.524437, SB loss: 0.728469
2023-10-30 15:18:34,020 Epoch: [278/484] Iter:[350/495], Time: 0.37, lr: [0.004621423484988234], Loss: 2.010136, Acc:0.797016, Semantic loss: 0.757212, BCE loss: 0.524359, SB loss: 0.728565
2023-10-30 15:18:37,619 Epoch: [278/484] Iter:[360/495], Time: 0.37, lr: [0.0046210141854800555], Loss: 2.012406, Acc:0.796540, Semantic loss: 0.757765, BCE loss: 0.525455, SB loss: 0.729185
2023-10-30 15:18:41,356 Epoch: [278/484] Iter:[370/495], Time: 0.37, lr: [0.0046206048819437155], Loss: 2.013627, Acc:0.796470, Semantic loss: 0.759645, BCE loss: 0.524596, SB loss: 0.729386
2023-10-30 15:18:44,989 Epoch: [278/484] Iter:[380/495], Time: 0.37, lr: [0.004620195574378779], Loss: 2.019131, Acc:0.796281, Semantic loss: 0.764208, BCE loss: 0.524563, SB loss: 0.730360
2023-10-30 15:18:48,703 Epoch: [278/484] Iter:[390/495], Time: 0.37, lr: [0.004619786262784807], Loss: 2.024444, Acc:0.795875, Semantic loss: 0.767699, BCE loss: 0.525471, SB loss: 0.731275
2023-10-30 15:18:52,379 Epoch: [278/484] Iter:[400/495], Time: 0.37, lr: [0.004619376947161365], Loss: 2.030724, Acc:0.795042, Semantic loss: 0.770469, BCE loss: 0.526550, SB loss: 0.733705
2023-10-30 15:18:56,260 Epoch: [278/484] Iter:[410/495], Time: 0.37, lr: [0.004618967627508015], Loss: 2.032570, Acc:0.794522, Semantic loss: 0.771439, BCE loss: 0.526714, SB loss: 0.734418
2023-10-30 15:18:59,956 Epoch: [278/484] Iter:[420/495], Time: 0.37, lr: [0.004618558303824323], Loss: 2.033185, Acc:0.794913, Semantic loss: 0.772007, BCE loss: 0.525906, SB loss: 0.735273
2023-10-30 15:19:03,726 Epoch: [278/484] Iter:[430/495], Time: 0.37, lr: [0.004618148976109851], Loss: 2.031515, Acc:0.795133, Semantic loss: 0.769716, BCE loss: 0.526464, SB loss: 0.735335
2023-10-30 15:19:07,461 Epoch: [278/484] Iter:[440/495], Time: 0.37, lr: [0.004617739644364163], Loss: 2.034122, Acc:0.795310, Semantic loss: 0.770052, BCE loss: 0.527485, SB loss: 0.736585
2023-10-30 15:19:11,053 Epoch: [278/484] Iter:[450/495], Time: 0.37, lr: [0.0046173303085868195], Loss: 2.033612, Acc:0.795849, Semantic loss: 0.769176, BCE loss: 0.528206, SB loss: 0.736231
2023-10-30 15:19:14,714 Epoch: [278/484] Iter:[460/495], Time: 0.37, lr: [0.004616920968777387], Loss: 2.032406, Acc:0.795843, Semantic loss: 0.768211, BCE loss: 0.528363, SB loss: 0.735831
2023-10-30 15:19:18,482 Epoch: [278/484] Iter:[470/495], Time: 0.37, lr: [0.004616511624935428], Loss: 2.033000, Acc:0.796500, Semantic loss: 0.767746, BCE loss: 0.529411, SB loss: 0.735843
2023-10-30 15:19:22,162 Epoch: [278/484] Iter:[480/495], Time: 0.37, lr: [0.004616102277060505], Loss: 2.032096, Acc:0.796772, Semantic loss: 0.767931, BCE loss: 0.528713, SB loss: 0.735451
2023-10-30 15:19:25,659 Epoch: [278/484] Iter:[490/495], Time: 0.37, lr: [0.00461569292515218], Loss: 2.032970, Acc:0.796936, Semantic loss: 0.768867, BCE loss: 0.527526, SB loss: 0.736576
2023-10-30 15:19:27,079 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:19:27,322 Loss: 2.146, MeanIU:  0.6272, Best_mIoU:  0.7151
2023-10-30 15:19:27,322 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694]
2023-10-30 15:19:29,458 Epoch: [279/484] Iter:[0/495], Time: 2.10, lr: [0.004615488247685355], Loss: 2.122451, Acc:0.863486, Semantic loss: 0.726113, BCE loss: 0.721783, SB loss: 0.674555
2023-10-30 15:19:33,610 Epoch: [279/484] Iter:[10/495], Time: 0.57, lr: [0.004615078889726109], Loss: 2.047335, Acc:0.807693, Semantic loss: 0.752056, BCE loss: 0.584128, SB loss: 0.711151
2023-10-30 15:19:37,315 Epoch: [279/484] Iter:[20/495], Time: 0.47, lr: [0.004614669527732368], Loss: 2.010824, Acc:0.826539, Semantic loss: 0.738344, BCE loss: 0.565535, SB loss: 0.706945
2023-10-30 15:19:40,974 Epoch: [279/484] Iter:[30/495], Time: 0.44, lr: [0.004614260161703695], Loss: 1.966288, Acc:0.817368, Semantic loss: 0.727645, BCE loss: 0.529448, SB loss: 0.709195
2023-10-30 15:19:44,685 Epoch: [279/484] Iter:[40/495], Time: 0.42, lr: [0.004613850791639652], Loss: 1.980464, Acc:0.823321, Semantic loss: 0.733402, BCE loss: 0.537015, SB loss: 0.710047
2023-10-30 15:19:48,334 Epoch: [279/484] Iter:[50/495], Time: 0.41, lr: [0.004613441417539804], Loss: 1.996334, Acc:0.815438, Semantic loss: 0.745960, BCE loss: 0.536164, SB loss: 0.714210
2023-10-30 15:19:52,013 Epoch: [279/484] Iter:[60/495], Time: 0.40, lr: [0.004613032039403711], Loss: 1.975254, Acc:0.809037, Semantic loss: 0.743526, BCE loss: 0.520870, SB loss: 0.710859
2023-10-30 15:19:55,662 Epoch: [279/484] Iter:[70/495], Time: 0.40, lr: [0.004612622657230933], Loss: 1.985559, Acc:0.805129, Semantic loss: 0.755348, BCE loss: 0.517534, SB loss: 0.712676
2023-10-30 15:19:59,384 Epoch: [279/484] Iter:[80/495], Time: 0.40, lr: [0.004612213271021037], Loss: 1.987074, Acc:0.806180, Semantic loss: 0.757187, BCE loss: 0.514142, SB loss: 0.715745
2023-10-30 15:20:03,164 Epoch: [279/484] Iter:[90/495], Time: 0.39, lr: [0.004611803880773583], Loss: 1.983299, Acc:0.810232, Semantic loss: 0.754172, BCE loss: 0.515516, SB loss: 0.713612
2023-10-30 15:20:06,834 Epoch: [279/484] Iter:[100/495], Time: 0.39, lr: [0.004611394486488131], Loss: 1.996105, Acc:0.807708, Semantic loss: 0.756811, BCE loss: 0.519979, SB loss: 0.719315
2023-10-30 15:20:10,620 Epoch: [279/484] Iter:[110/495], Time: 0.39, lr: [0.004610985088164244], Loss: 1.991079, Acc:0.809631, Semantic loss: 0.757989, BCE loss: 0.514658, SB loss: 0.718432
2023-10-30 15:20:14,286 Epoch: [279/484] Iter:[120/495], Time: 0.39, lr: [0.0046105756858014855], Loss: 1.991169, Acc:0.811159, Semantic loss: 0.754761, BCE loss: 0.517835, SB loss: 0.718572
2023-10-30 15:20:18,064 Epoch: [279/484] Iter:[130/495], Time: 0.39, lr: [0.004610166279399416], Loss: 1.994120, Acc:0.814656, Semantic loss: 0.757443, BCE loss: 0.517600, SB loss: 0.719077
2023-10-30 15:20:21,706 Epoch: [279/484] Iter:[140/495], Time: 0.39, lr: [0.004609756868957596], Loss: 1.996467, Acc:0.813497, Semantic loss: 0.756098, BCE loss: 0.522814, SB loss: 0.717554
2023-10-30 15:20:25,464 Epoch: [279/484] Iter:[150/495], Time: 0.38, lr: [0.004609347454475588], Loss: 1.999578, Acc:0.813207, Semantic loss: 0.755993, BCE loss: 0.523608, SB loss: 0.719977
2023-10-30 15:20:29,173 Epoch: [279/484] Iter:[160/495], Time: 0.38, lr: [0.004608938035952954], Loss: 1.994660, Acc:0.811881, Semantic loss: 0.752891, BCE loss: 0.522873, SB loss: 0.718896
2023-10-30 15:20:33,118 Epoch: [279/484] Iter:[170/495], Time: 0.38, lr: [0.004608528613389254], Loss: 1.997649, Acc:0.810681, Semantic loss: 0.755149, BCE loss: 0.522879, SB loss: 0.719620
2023-10-30 15:20:36,910 Epoch: [279/484] Iter:[180/495], Time: 0.38, lr: [0.00460811918678405], Loss: 2.002606, Acc:0.812493, Semantic loss: 0.755653, BCE loss: 0.527954, SB loss: 0.718999
2023-10-30 15:20:40,724 Epoch: [279/484] Iter:[190/495], Time: 0.38, lr: [0.004607709756136902], Loss: 2.015897, Acc:0.809842, Semantic loss: 0.763522, BCE loss: 0.529512, SB loss: 0.722863
2023-10-30 15:20:44,492 Epoch: [279/484] Iter:[200/495], Time: 0.38, lr: [0.004607300321447373], Loss: 2.011682, Acc:0.807174, Semantic loss: 0.760750, BCE loss: 0.528453, SB loss: 0.722478
2023-10-30 15:20:48,228 Epoch: [279/484] Iter:[210/495], Time: 0.38, lr: [0.004606890882715022], Loss: 2.016162, Acc:0.807334, Semantic loss: 0.763190, BCE loss: 0.529546, SB loss: 0.723426
2023-10-30 15:20:51,991 Epoch: [279/484] Iter:[220/495], Time: 0.38, lr: [0.004606481439939412], Loss: 2.014557, Acc:0.805477, Semantic loss: 0.762564, BCE loss: 0.527399, SB loss: 0.724594
2023-10-30 15:20:55,750 Epoch: [279/484] Iter:[230/495], Time: 0.38, lr: [0.0046060719931201016], Loss: 2.024878, Acc:0.804457, Semantic loss: 0.770294, BCE loss: 0.527853, SB loss: 0.726731
2023-10-30 15:20:59,389 Epoch: [279/484] Iter:[240/495], Time: 0.38, lr: [0.004605662542256652], Loss: 2.024800, Acc:0.801930, Semantic loss: 0.770341, BCE loss: 0.528085, SB loss: 0.726373
2023-10-30 15:21:03,117 Epoch: [279/484] Iter:[250/495], Time: 0.38, lr: [0.004605253087348625], Loss: 2.025870, Acc:0.799986, Semantic loss: 0.771306, BCE loss: 0.526415, SB loss: 0.728148
2023-10-30 15:21:06,848 Epoch: [279/484] Iter:[260/495], Time: 0.38, lr: [0.0046048436283955795], Loss: 2.034949, Acc:0.801204, Semantic loss: 0.773136, BCE loss: 0.531532, SB loss: 0.730281
2023-10-30 15:21:10,578 Epoch: [279/484] Iter:[270/495], Time: 0.38, lr: [0.004604434165397076], Loss: 2.034964, Acc:0.800507, Semantic loss: 0.772995, BCE loss: 0.531046, SB loss: 0.730924
2023-10-30 15:21:14,222 Epoch: [279/484] Iter:[280/495], Time: 0.38, lr: [0.004604024698352676], Loss: 2.045375, Acc:0.800869, Semantic loss: 0.778513, BCE loss: 0.534473, SB loss: 0.732389
2023-10-30 15:21:17,901 Epoch: [279/484] Iter:[290/495], Time: 0.38, lr: [0.0046036152272619394], Loss: 2.042311, Acc:0.799700, Semantic loss: 0.776445, BCE loss: 0.533628, SB loss: 0.732238
2023-10-30 15:21:21,584 Epoch: [279/484] Iter:[300/495], Time: 0.38, lr: [0.004603205752124426], Loss: 2.040538, Acc:0.799778, Semantic loss: 0.773365, BCE loss: 0.535986, SB loss: 0.731187
2023-10-30 15:21:25,244 Epoch: [279/484] Iter:[310/495], Time: 0.38, lr: [0.004602796272939695], Loss: 2.038363, Acc:0.798881, Semantic loss: 0.772823, BCE loss: 0.534438, SB loss: 0.731102
2023-10-30 15:21:28,933 Epoch: [279/484] Iter:[320/495], Time: 0.38, lr: [0.004602386789707307], Loss: 2.038588, Acc:0.797950, Semantic loss: 0.773378, BCE loss: 0.533786, SB loss: 0.731423
2023-10-30 15:21:32,592 Epoch: [279/484] Iter:[330/495], Time: 0.38, lr: [0.004601977302426823], Loss: 2.038648, Acc:0.798098, Semantic loss: 0.772220, BCE loss: 0.535434, SB loss: 0.730994
2023-10-30 15:21:36,379 Epoch: [279/484] Iter:[340/495], Time: 0.38, lr: [0.004601567811097802], Loss: 2.030474, Acc:0.798283, Semantic loss: 0.768394, BCE loss: 0.532435, SB loss: 0.729645
2023-10-30 15:21:40,173 Epoch: [279/484] Iter:[350/495], Time: 0.38, lr: [0.004601158315719801], Loss: 2.032218, Acc:0.798671, Semantic loss: 0.769795, BCE loss: 0.533024, SB loss: 0.729400
2023-10-30 15:21:43,819 Epoch: [279/484] Iter:[360/495], Time: 0.38, lr: [0.0046007488162923835], Loss: 2.034361, Acc:0.799055, Semantic loss: 0.771654, BCE loss: 0.533028, SB loss: 0.729679
2023-10-30 15:21:47,534 Epoch: [279/484] Iter:[370/495], Time: 0.38, lr: [0.004600339312815108], Loss: 2.034170, Acc:0.798891, Semantic loss: 0.770621, BCE loss: 0.533315, SB loss: 0.730234
2023-10-30 15:21:51,283 Epoch: [279/484] Iter:[380/495], Time: 0.38, lr: [0.004599929805287533], Loss: 2.043135, Acc:0.798375, Semantic loss: 0.775128, BCE loss: 0.534189, SB loss: 0.733818
2023-10-30 15:21:55,139 Epoch: [279/484] Iter:[390/495], Time: 0.38, lr: [0.004599520293709217], Loss: 2.045321, Acc:0.798296, Semantic loss: 0.774694, BCE loss: 0.536080, SB loss: 0.734547
2023-10-30 15:21:58,965 Epoch: [279/484] Iter:[400/495], Time: 0.38, lr: [0.004599110778079721], Loss: 2.043010, Acc:0.797888, Semantic loss: 0.773036, BCE loss: 0.535072, SB loss: 0.734902
2023-10-30 15:22:02,666 Epoch: [279/484] Iter:[410/495], Time: 0.38, lr: [0.004598701258398603], Loss: 2.046521, Acc:0.797993, Semantic loss: 0.774451, BCE loss: 0.535589, SB loss: 0.736481
2023-10-30 15:22:06,334 Epoch: [279/484] Iter:[420/495], Time: 0.38, lr: [0.004598291734665423], Loss: 2.047911, Acc:0.796772, Semantic loss: 0.775944, BCE loss: 0.534844, SB loss: 0.737124
2023-10-30 15:22:09,984 Epoch: [279/484] Iter:[430/495], Time: 0.38, lr: [0.004597882206879739], Loss: 2.045355, Acc:0.796570, Semantic loss: 0.773608, BCE loss: 0.534665, SB loss: 0.737082
2023-10-30 15:22:13,700 Epoch: [279/484] Iter:[440/495], Time: 0.38, lr: [0.00459747267504111], Loss: 2.044597, Acc:0.796753, Semantic loss: 0.773714, BCE loss: 0.533966, SB loss: 0.736916
2023-10-30 15:22:17,404 Epoch: [279/484] Iter:[450/495], Time: 0.38, lr: [0.004597063139149095], Loss: 2.046003, Acc:0.797011, Semantic loss: 0.774172, BCE loss: 0.534675, SB loss: 0.737156
2023-10-30 15:22:21,195 Epoch: [279/484] Iter:[460/495], Time: 0.38, lr: [0.004596653599203253], Loss: 2.048111, Acc:0.797217, Semantic loss: 0.774042, BCE loss: 0.536706, SB loss: 0.737363
2023-10-30 15:22:24,932 Epoch: [279/484] Iter:[470/495], Time: 0.38, lr: [0.004596244055203141], Loss: 2.051251, Acc:0.796776, Semantic loss: 0.776281, BCE loss: 0.537327, SB loss: 0.737644
2023-10-30 15:22:28,568 Epoch: [279/484] Iter:[480/495], Time: 0.38, lr: [0.004595834507148319], Loss: 2.050330, Acc:0.797732, Semantic loss: 0.774964, BCE loss: 0.538128, SB loss: 0.737239
2023-10-30 15:22:32,066 Epoch: [279/484] Iter:[490/495], Time: 0.38, lr: [0.004595424955038346], Loss: 2.048476, Acc:0.797612, Semantic loss: 0.773670, BCE loss: 0.538114, SB loss: 0.736692
2023-10-30 15:22:33,486 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:22:33,714 Loss: 2.146, MeanIU:  0.6272, Best_mIoU:  0.7151
2023-10-30 15:22:33,714 [0.97267507 0.80567635 0.86712239 0.37097127 0.3213073  0.54126984
 0.61827222 0.66189816 0.90461151 0.62600645 0.9273301  0.75636986
 0.54700807 0.88233107 0.27400224 0.37056973 0.40830478 0.35638335
 0.70405694]
2023-10-30 15:22:35,753 Epoch: [280/484] Iter:[0/495], Time: 2.01, lr: [0.004595220177462539], Loss: 1.684152, Acc:0.791629, Semantic loss: 0.645207, BCE loss: 0.379546, SB loss: 0.659399
2023-10-30 15:22:39,747 Epoch: [280/484] Iter:[10/495], Time: 0.55, lr: [0.004594810619269008], Loss: 2.135853, Acc:0.784346, Semantic loss: 0.878332, BCE loss: 0.513914, SB loss: 0.743607
2023-10-30 15:22:43,431 Epoch: [280/484] Iter:[20/495], Time: 0.46, lr: [0.0045944010570192215], Loss: 2.101505, Acc:0.797417, Semantic loss: 0.841578, BCE loss: 0.521339, SB loss: 0.738588
2023-10-30 15:22:47,006 Epoch: [280/484] Iter:[30/495], Time: 0.43, lr: [0.0045939914907127365], Loss: 2.116002, Acc:0.796124, Semantic loss: 0.825946, BCE loss: 0.557585, SB loss: 0.732471
2023-10-30 15:22:50,759 Epoch: [280/484] Iter:[40/495], Time: 0.41, lr: [0.0045935819203491105], Loss: 2.098147, Acc:0.807902, Semantic loss: 0.805844, BCE loss: 0.558868, SB loss: 0.733435
2023-10-30 15:22:54,350 Epoch: [280/484] Iter:[50/495], Time: 0.40, lr: [0.004593172345927902], Loss: 2.093673, Acc:0.804618, Semantic loss: 0.799850, BCE loss: 0.557352, SB loss: 0.736470
2023-10-30 15:22:57,974 Epoch: [280/484] Iter:[60/495], Time: 0.40, lr: [0.004592762767448669], Loss: 2.068471, Acc:0.801567, Semantic loss: 0.792537, BCE loss: 0.540400, SB loss: 0.735534
2023-10-30 15:23:01,538 Epoch: [280/484] Iter:[70/495], Time: 0.39, lr: [0.004592353184910968], Loss: 2.053689, Acc:0.800704, Semantic loss: 0.783788, BCE loss: 0.539039, SB loss: 0.730862
2023-10-30 15:23:05,291 Epoch: [280/484] Iter:[80/495], Time: 0.39, lr: [0.004591943598314358], Loss: 2.058188, Acc:0.806542, Semantic loss: 0.784070, BCE loss: 0.545967, SB loss: 0.728151
2023-10-30 15:23:08,913 Epoch: [280/484] Iter:[90/495], Time: 0.39, lr: [0.004591534007658395], Loss: 2.052007, Acc:0.809082, Semantic loss: 0.778725, BCE loss: 0.545621, SB loss: 0.727660
2023-10-30 15:23:12,600 Epoch: [280/484] Iter:[100/495], Time: 0.38, lr: [0.004591124412942639], Loss: 2.052517, Acc:0.806405, Semantic loss: 0.778417, BCE loss: 0.544365, SB loss: 0.729736
2023-10-30 15:23:16,378 Epoch: [280/484] Iter:[110/495], Time: 0.38, lr: [0.004590714814166645], Loss: 2.051859, Acc:0.805398, Semantic loss: 0.781946, BCE loss: 0.538408, SB loss: 0.731505
2023-10-30 15:23:19,965 Epoch: [280/484] Iter:[120/495], Time: 0.38, lr: [0.004590305211329971], Loss: 2.055270, Acc:0.804991, Semantic loss: 0.783476, BCE loss: 0.539584, SB loss: 0.732210
2023-10-30 15:23:23,615 Epoch: [280/484] Iter:[130/495], Time: 0.38, lr: [0.004589895604432173], Loss: 2.053974, Acc:0.801202, Semantic loss: 0.786537, BCE loss: 0.533480, SB loss: 0.733957
2023-10-30 15:23:27,257 Epoch: [280/484] Iter:[140/495], Time: 0.38, lr: [0.004589485993472809], Loss: 2.055041, Acc:0.800887, Semantic loss: 0.783509, BCE loss: 0.535699, SB loss: 0.735833
2023-10-30 15:23:30,873 Epoch: [280/484] Iter:[150/495], Time: 0.38, lr: [0.004589076378451437], Loss: 2.051771, Acc:0.799630, Semantic loss: 0.782837, BCE loss: 0.532370, SB loss: 0.736564
2023-10-30 15:23:34,593 Epoch: [280/484] Iter:[160/495], Time: 0.38, lr: [0.004588666759367613], Loss: 2.045185, Acc:0.798525, Semantic loss: 0.779802, BCE loss: 0.530182, SB loss: 0.735201
2023-10-30 15:23:38,352 Epoch: [280/484] Iter:[170/495], Time: 0.38, lr: [0.004588257136220892], Loss: 2.046030, Acc:0.799196, Semantic loss: 0.777983, BCE loss: 0.532371, SB loss: 0.735676
2023-10-30 15:23:42,186 Epoch: [280/484] Iter:[180/495], Time: 0.38, lr: [0.004587847509010833], Loss: 2.042681, Acc:0.799100, Semantic loss: 0.776363, BCE loss: 0.530874, SB loss: 0.735444
2023-10-30 15:23:45,821 Epoch: [280/484] Iter:[190/495], Time: 0.38, lr: [0.004587437877736993], Loss: 2.044868, Acc:0.797934, Semantic loss: 0.777429, BCE loss: 0.531302, SB loss: 0.736137
2023-10-30 15:23:49,458 Epoch: [280/484] Iter:[200/495], Time: 0.38, lr: [0.004587028242398926], Loss: 2.039277, Acc:0.798268, Semantic loss: 0.773315, BCE loss: 0.530560, SB loss: 0.735402
2023-10-30 15:23:53,157 Epoch: [280/484] Iter:[210/495], Time: 0.38, lr: [0.00458661860299619], Loss: 2.037611, Acc:0.798329, Semantic loss: 0.771902, BCE loss: 0.531791, SB loss: 0.733918
2023-10-30 15:23:56,794 Epoch: [280/484] Iter:[220/495], Time: 0.38, lr: [0.004586208959528341], Loss: 2.041558, Acc:0.798253, Semantic loss: 0.775844, BCE loss: 0.531045, SB loss: 0.734669
2023-10-30 15:24:00,406 Epoch: [280/484] Iter:[230/495], Time: 0.38, lr: [0.004585799311994936], Loss: 2.041445, Acc:0.798066, Semantic loss: 0.775544, BCE loss: 0.532567, SB loss: 0.733334
2023-10-30 15:24:04,004 Epoch: [280/484] Iter:[240/495], Time: 0.37, lr: [0.0045853896603955295], Loss: 2.034047, Acc:0.798531, Semantic loss: 0.770870, BCE loss: 0.531041, SB loss: 0.732137
2023-10-30 15:24:07,683 Epoch: [280/484] Iter:[250/495], Time: 0.37, lr: [0.004584980004729678], Loss: 2.046543, Acc:0.799581, Semantic loss: 0.777629, BCE loss: 0.533460, SB loss: 0.735454
2023-10-30 15:24:11,476 Epoch: [280/484] Iter:[260/495], Time: 0.37, lr: [0.004584570344996939], Loss: 2.041037, Acc:0.798586, Semantic loss: 0.775802, BCE loss: 0.531527, SB loss: 0.733708
2023-10-30 15:24:15,244 Epoch: [280/484] Iter:[270/495], Time: 0.37, lr: [0.004584160681196866], Loss: 2.039126, Acc:0.799790, Semantic loss: 0.774652, BCE loss: 0.532285, SB loss: 0.732188
2023-10-30 15:24:18,881 Epoch: [280/484] Iter:[280/495], Time: 0.37, lr: [0.004583751013329016], Loss: 2.037094, Acc:0.799913, Semantic loss: 0.773255, BCE loss: 0.531576, SB loss: 0.732262
2023-10-30 15:24:22,577 Epoch: [280/484] Iter:[290/495], Time: 0.37, lr: [0.004583341341392945], Loss: 2.031843, Acc:0.799563, Semantic loss: 0.771145, BCE loss: 0.529457, SB loss: 0.731241
2023-10-30 15:24:26,399 Epoch: [280/484] Iter:[300/495], Time: 0.37, lr: [0.004582931665388207], Loss: 2.028767, Acc:0.800702, Semantic loss: 0.768848, BCE loss: 0.529382, SB loss: 0.730536
2023-10-30 15:24:30,109 Epoch: [280/484] Iter:[310/495], Time: 0.37, lr: [0.0045825219853143605], Loss: 2.035246, Acc:0.800421, Semantic loss: 0.771115, BCE loss: 0.532189, SB loss: 0.731942
2023-10-30 15:24:33,835 Epoch: [280/484] Iter:[320/495], Time: 0.37, lr: [0.004582112301170958], Loss: 2.030729, Acc:0.801052, Semantic loss: 0.767953, BCE loss: 0.532308, SB loss: 0.730467
2023-10-30 15:24:37,580 Epoch: [280/484] Iter:[330/495], Time: 0.37, lr: [0.004581702612957555], Loss: 2.035195, Acc:0.800450, Semantic loss: 0.770359, BCE loss: 0.533426, SB loss: 0.731411
2023-10-30 15:24:41,337 Epoch: [280/484] Iter:[340/495], Time: 0.37, lr: [0.004581292920673708], Loss: 2.033782, Acc:0.799873, Semantic loss: 0.769356, BCE loss: 0.533386, SB loss: 0.731040
2023-10-30 15:24:45,027 Epoch: [280/484] Iter:[350/495], Time: 0.37, lr: [0.004580883224318972], Loss: 2.033680, Acc:0.799320, Semantic loss: 0.769570, BCE loss: 0.533008, SB loss: 0.731102
2023-10-30 15:24:48,767 Epoch: [280/484] Iter:[360/495], Time: 0.37, lr: [0.004580473523892901], Loss: 2.035161, Acc:0.799616, Semantic loss: 0.770259, BCE loss: 0.534852, SB loss: 0.730050
2023-10-30 15:24:52,508 Epoch: [280/484] Iter:[370/495], Time: 0.37, lr: [0.00458006381939505], Loss: 2.034114, Acc:0.799475, Semantic loss: 0.770520, BCE loss: 0.533760, SB loss: 0.729834
2023-10-30 15:24:56,192 Epoch: [280/484] Iter:[380/495], Time: 0.37, lr: [0.004579654110824975], Loss: 2.031984, Acc:0.798934, Semantic loss: 0.770100, BCE loss: 0.532322, SB loss: 0.729563
2023-10-30 15:25:00,025 Epoch: [280/484] Iter:[390/495], Time: 0.37, lr: [0.004579244398182229], Loss: 2.033493, Acc:0.799119, Semantic loss: 0.771269, BCE loss: 0.531837, SB loss: 0.730388
2023-10-30 15:25:03,732 Epoch: [280/484] Iter:[400/495], Time: 0.37, lr: [0.004578834681466367], Loss: 2.029488, Acc:0.799521, Semantic loss: 0.768516, BCE loss: 0.531073, SB loss: 0.729899
2023-10-30 15:25:07,442 Epoch: [280/484] Iter:[410/495], Time: 0.37, lr: [0.004578424960676946], Loss: 2.028960, Acc:0.799442, Semantic loss: 0.768105, BCE loss: 0.530930, SB loss: 0.729924
2023-10-30 15:25:11,182 Epoch: [280/484] Iter:[420/495], Time: 0.37, lr: [0.004578015235813518], Loss: 2.026533, Acc:0.798862, Semantic loss: 0.767666, BCE loss: 0.529034, SB loss: 0.729833
2023-10-30 15:25:14,835 Epoch: [280/484] Iter:[430/495], Time: 0.37, lr: [0.004577605506875638], Loss: 2.023443, Acc:0.798967, Semantic loss: 0.765966, BCE loss: 0.528549, SB loss: 0.728927
2023-10-30 15:25:18,487 Epoch: [280/484] Iter:[440/495], Time: 0.37, lr: [0.004577195773862859], Loss: 2.020736, Acc:0.799261, Semantic loss: 0.764290, BCE loss: 0.527909, SB loss: 0.728536
2023-10-30 15:25:22,200 Epoch: [280/484] Iter:[450/495], Time: 0.37, lr: [0.004576786036774738], Loss: 2.019955, Acc:0.799184, Semantic loss: 0.763906, BCE loss: 0.527530, SB loss: 0.728520
2023-10-30 15:25:25,874 Epoch: [280/484] Iter:[460/495], Time: 0.37, lr: [0.004576376295610827], Loss: 2.017502, Acc:0.799167, Semantic loss: 0.762531, BCE loss: 0.526658, SB loss: 0.728312
2023-10-30 15:25:29,535 Epoch: [280/484] Iter:[470/495], Time: 0.37, lr: [0.0045759665503706795], Loss: 2.015640, Acc:0.798562, Semantic loss: 0.761545, BCE loss: 0.526423, SB loss: 0.727671
2023-10-30 15:25:33,288 Epoch: [280/484] Iter:[480/495], Time: 0.37, lr: [0.004575556801053851], Loss: 2.015524, Acc:0.798709, Semantic loss: 0.761427, BCE loss: 0.526875, SB loss: 0.727223
2023-10-30 15:25:36,909 Epoch: [280/484] Iter:[490/495], Time: 0.37, lr: [0.004575147047659894], Loss: 2.022325, Acc:0.798585, Semantic loss: 0.764903, BCE loss: 0.529083, SB loss: 0.728339
2023-10-30 15:28:33,934 0 [0.9331442  0.6330242  0.82243633 0.08056967 0.24373285 0.41262303
 0.4376128  0.59200154 0.87417817 0.42450968 0.83891348 0.59940721
 0.03264983 0.81334263 0.00223431 0.10805763 0.05427645 0.02821264
 0.6012846 ] 0.44906374947816385
2023-10-30 15:28:33,934 1 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466] 0.6928823061510554
2023-10-30 15:28:33,938 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:28:34,174 Loss: 2.168, MeanIU:  0.6929, Best_mIoU:  0.7151
2023-10-30 15:28:34,175 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466]
2023-10-30 15:28:36,152 Epoch: [281/484] Iter:[0/495], Time: 1.94, lr: [0.0045749421694338535], Loss: 1.890890, Acc:0.818667, Semantic loss: 0.656021, BCE loss: 0.545469, SB loss: 0.689401
2023-10-30 15:28:40,009 Epoch: [281/484] Iter:[10/495], Time: 0.53, lr: [0.004574532409923368], Loss: 1.898744, Acc:0.797505, Semantic loss: 0.702102, BCE loss: 0.494195, SB loss: 0.702446
2023-10-30 15:28:43,531 Epoch: [281/484] Iter:[20/495], Time: 0.44, lr: [0.004574122646334639], Loss: 1.955519, Acc:0.814004, Semantic loss: 0.723951, BCE loss: 0.518355, SB loss: 0.713213
2023-10-30 15:28:47,045 Epoch: [281/484] Iter:[30/495], Time: 0.41, lr: [0.0045737128786672195], Loss: 1.990718, Acc:0.801687, Semantic loss: 0.751106, BCE loss: 0.520747, SB loss: 0.718865
2023-10-30 15:28:50,525 Epoch: [281/484] Iter:[40/495], Time: 0.40, lr: [0.004573303106920663], Loss: 2.056569, Acc:0.802993, Semantic loss: 0.785740, BCE loss: 0.534034, SB loss: 0.736796
2023-10-30 15:28:54,171 Epoch: [281/484] Iter:[50/495], Time: 0.39, lr: [0.004572893331094523], Loss: 2.025440, Acc:0.801392, Semantic loss: 0.772578, BCE loss: 0.522242, SB loss: 0.730619
2023-10-30 15:28:57,602 Epoch: [281/484] Iter:[60/495], Time: 0.38, lr: [0.004572483551188352], Loss: 2.061103, Acc:0.801062, Semantic loss: 0.780738, BCE loss: 0.546979, SB loss: 0.733386
2023-10-30 15:29:01,082 Epoch: [281/484] Iter:[70/495], Time: 0.38, lr: [0.0045720737672017035], Loss: 2.044958, Acc:0.808364, Semantic loss: 0.770980, BCE loss: 0.544110, SB loss: 0.729868
2023-10-30 15:29:04,670 Epoch: [281/484] Iter:[80/495], Time: 0.38, lr: [0.004571663979134131], Loss: 2.036343, Acc:0.804876, Semantic loss: 0.767331, BCE loss: 0.540569, SB loss: 0.728443
2023-10-30 15:29:08,208 Epoch: [281/484] Iter:[90/495], Time: 0.37, lr: [0.004571254186985187], Loss: 2.025580, Acc:0.808107, Semantic loss: 0.759366, BCE loss: 0.539687, SB loss: 0.726527
2023-10-30 15:29:11,785 Epoch: [281/484] Iter:[100/495], Time: 0.37, lr: [0.004570844390754425], Loss: 2.020961, Acc:0.805997, Semantic loss: 0.755882, BCE loss: 0.540287, SB loss: 0.724792
2023-10-30 15:29:15,434 Epoch: [281/484] Iter:[110/495], Time: 0.37, lr: [0.0045704345904413945], Loss: 2.022130, Acc:0.803997, Semantic loss: 0.756416, BCE loss: 0.540166, SB loss: 0.725549
2023-10-30 15:29:18,992 Epoch: [281/484] Iter:[120/495], Time: 0.37, lr: [0.004570024786045652], Loss: 2.017516, Acc:0.804583, Semantic loss: 0.755647, BCE loss: 0.534971, SB loss: 0.726898
2023-10-30 15:29:22,646 Epoch: [281/484] Iter:[130/495], Time: 0.37, lr: [0.004569614977566749], Loss: 2.008678, Acc:0.806214, Semantic loss: 0.750683, BCE loss: 0.533480, SB loss: 0.724514
2023-10-30 15:29:26,260 Epoch: [281/484] Iter:[140/495], Time: 0.37, lr: [0.004569205165004238], Loss: 2.009602, Acc:0.808541, Semantic loss: 0.751204, BCE loss: 0.532510, SB loss: 0.725887
2023-10-30 15:29:29,977 Epoch: [281/484] Iter:[150/495], Time: 0.37, lr: [0.00456879534835767], Loss: 1.999795, Acc:0.810643, Semantic loss: 0.745896, BCE loss: 0.531464, SB loss: 0.722435
2023-10-30 15:29:33,522 Epoch: [281/484] Iter:[160/495], Time: 0.37, lr: [0.004568385527626599], Loss: 1.998287, Acc:0.809014, Semantic loss: 0.746372, BCE loss: 0.530655, SB loss: 0.721259
2023-10-30 15:29:37,111 Epoch: [281/484] Iter:[170/495], Time: 0.37, lr: [0.004567975702810576], Loss: 1.993031, Acc:0.808701, Semantic loss: 0.743327, BCE loss: 0.530746, SB loss: 0.718958
2023-10-30 15:29:40,691 Epoch: [281/484] Iter:[180/495], Time: 0.37, lr: [0.004567565873909153], Loss: 1.988289, Acc:0.808502, Semantic loss: 0.739878, BCE loss: 0.530436, SB loss: 0.717975
2023-10-30 15:29:44,346 Epoch: [281/484] Iter:[190/495], Time: 0.37, lr: [0.004567156040921882], Loss: 1.990884, Acc:0.806451, Semantic loss: 0.743167, BCE loss: 0.527981, SB loss: 0.719737
2023-10-30 15:29:47,929 Epoch: [281/484] Iter:[200/495], Time: 0.37, lr: [0.004566746203848317], Loss: 1.990989, Acc:0.805725, Semantic loss: 0.743973, BCE loss: 0.524541, SB loss: 0.722474
2023-10-30 15:29:51,556 Epoch: [281/484] Iter:[210/495], Time: 0.37, lr: [0.004566336362688007], Loss: 1.991384, Acc:0.804825, Semantic loss: 0.745602, BCE loss: 0.523996, SB loss: 0.721785
2023-10-30 15:29:55,208 Epoch: [281/484] Iter:[220/495], Time: 0.37, lr: [0.004565926517440504], Loss: 1.992469, Acc:0.806267, Semantic loss: 0.746179, BCE loss: 0.524305, SB loss: 0.721985
2023-10-30 15:29:58,827 Epoch: [281/484] Iter:[230/495], Time: 0.37, lr: [0.004565516668105361], Loss: 1.994866, Acc:0.805793, Semantic loss: 0.748341, BCE loss: 0.523881, SB loss: 0.722644
2023-10-30 15:30:02,479 Epoch: [281/484] Iter:[240/495], Time: 0.37, lr: [0.004565106814682129], Loss: 1.997484, Acc:0.806673, Semantic loss: 0.748469, BCE loss: 0.526131, SB loss: 0.722884
2023-10-30 15:30:06,109 Epoch: [281/484] Iter:[250/495], Time: 0.37, lr: [0.00456469695717036], Loss: 1.991297, Acc:0.806741, Semantic loss: 0.745157, BCE loss: 0.525142, SB loss: 0.720997
2023-10-30 15:30:09,770 Epoch: [281/484] Iter:[260/495], Time: 0.37, lr: [0.004564287095569603], Loss: 1.993285, Acc:0.806140, Semantic loss: 0.746676, BCE loss: 0.525083, SB loss: 0.721526
2023-10-30 15:30:13,408 Epoch: [281/484] Iter:[270/495], Time: 0.37, lr: [0.0045638772298794116], Loss: 1.992666, Acc:0.805641, Semantic loss: 0.746409, BCE loss: 0.523619, SB loss: 0.722638
2023-10-30 15:30:17,083 Epoch: [281/484] Iter:[280/495], Time: 0.37, lr: [0.0045634673600993365], Loss: 1.998899, Acc:0.806162, Semantic loss: 0.748629, BCE loss: 0.526723, SB loss: 0.723547
2023-10-30 15:30:20,634 Epoch: [281/484] Iter:[290/495], Time: 0.37, lr: [0.0045630574862289275], Loss: 1.995855, Acc:0.806382, Semantic loss: 0.746562, BCE loss: 0.526765, SB loss: 0.722528
2023-10-30 15:30:24,223 Epoch: [281/484] Iter:[300/495], Time: 0.37, lr: [0.004562647608267736], Loss: 1.997426, Acc:0.805817, Semantic loss: 0.746976, BCE loss: 0.527852, SB loss: 0.722599
2023-10-30 15:30:27,949 Epoch: [281/484] Iter:[310/495], Time: 0.37, lr: [0.004562237726215314], Loss: 2.002081, Acc:0.804038, Semantic loss: 0.751835, BCE loss: 0.526178, SB loss: 0.724067
2023-10-30 15:30:31,658 Epoch: [281/484] Iter:[320/495], Time: 0.37, lr: [0.0045618278400712114], Loss: 2.005071, Acc:0.804984, Semantic loss: 0.754742, BCE loss: 0.525955, SB loss: 0.724374
2023-10-30 15:30:35,391 Epoch: [281/484] Iter:[330/495], Time: 0.37, lr: [0.00456141794983498], Loss: 2.004509, Acc:0.805027, Semantic loss: 0.754461, BCE loss: 0.525081, SB loss: 0.724967
2023-10-30 15:30:38,995 Epoch: [281/484] Iter:[340/495], Time: 0.37, lr: [0.004561008055506167], Loss: 2.000617, Acc:0.805054, Semantic loss: 0.752737, BCE loss: 0.523833, SB loss: 0.724046
2023-10-30 15:30:42,776 Epoch: [281/484] Iter:[350/495], Time: 0.37, lr: [0.004560598157084326], Loss: 2.002590, Acc:0.804354, Semantic loss: 0.753689, BCE loss: 0.524566, SB loss: 0.724335
2023-10-30 15:30:46,483 Epoch: [281/484] Iter:[360/495], Time: 0.37, lr: [0.004560188254569007], Loss: 2.001714, Acc:0.804763, Semantic loss: 0.752907, BCE loss: 0.524291, SB loss: 0.724515
2023-10-30 15:30:50,266 Epoch: [281/484] Iter:[370/495], Time: 0.37, lr: [0.0045597783479597595], Loss: 2.005635, Acc:0.805080, Semantic loss: 0.754647, BCE loss: 0.525719, SB loss: 0.725268
2023-10-30 15:30:53,982 Epoch: [281/484] Iter:[380/495], Time: 0.37, lr: [0.0045593684372561335], Loss: 2.011567, Acc:0.804473, Semantic loss: 0.758460, BCE loss: 0.526805, SB loss: 0.726302
2023-10-30 15:30:57,701 Epoch: [281/484] Iter:[390/495], Time: 0.37, lr: [0.0045589585224576805], Loss: 2.014844, Acc:0.804081, Semantic loss: 0.760169, BCE loss: 0.527671, SB loss: 0.727005
2023-10-30 15:31:01,372 Epoch: [281/484] Iter:[400/495], Time: 0.37, lr: [0.004558548603563949], Loss: 2.022010, Acc:0.803857, Semantic loss: 0.763733, BCE loss: 0.528914, SB loss: 0.729363
2023-10-30 15:31:05,079 Epoch: [281/484] Iter:[410/495], Time: 0.37, lr: [0.00455813868057449], Loss: 2.025876, Acc:0.804162, Semantic loss: 0.765131, BCE loss: 0.530469, SB loss: 0.730276
2023-10-30 15:31:08,718 Epoch: [281/484] Iter:[420/495], Time: 0.37, lr: [0.004557728753488851], Loss: 2.027514, Acc:0.802603, Semantic loss: 0.765792, BCE loss: 0.529758, SB loss: 0.731964
2023-10-30 15:31:12,458 Epoch: [281/484] Iter:[430/495], Time: 0.37, lr: [0.004557318822306585], Loss: 2.025877, Acc:0.802439, Semantic loss: 0.765697, BCE loss: 0.528412, SB loss: 0.731767
2023-10-30 15:31:16,098 Epoch: [281/484] Iter:[440/495], Time: 0.37, lr: [0.00455690888702724], Loss: 2.024446, Acc:0.802103, Semantic loss: 0.764412, BCE loss: 0.528608, SB loss: 0.731425
2023-10-30 15:31:19,727 Epoch: [281/484] Iter:[450/495], Time: 0.37, lr: [0.004556498947650366], Loss: 2.026581, Acc:0.801702, Semantic loss: 0.765791, BCE loss: 0.528919, SB loss: 0.731871
2023-10-30 15:31:23,393 Epoch: [281/484] Iter:[460/495], Time: 0.37, lr: [0.004556089004175511], Loss: 2.027427, Acc:0.801316, Semantic loss: 0.766025, BCE loss: 0.529065, SB loss: 0.732337
2023-10-30 15:31:27,111 Epoch: [281/484] Iter:[470/495], Time: 0.37, lr: [0.0045556790566022255], Loss: 2.026169, Acc:0.801307, Semantic loss: 0.764851, BCE loss: 0.528990, SB loss: 0.732328
2023-10-30 15:31:30,713 Epoch: [281/484] Iter:[480/495], Time: 0.37, lr: [0.004555269104930059], Loss: 2.027059, Acc:0.800883, Semantic loss: 0.766817, BCE loss: 0.527846, SB loss: 0.732395
2023-10-30 15:31:34,268 Epoch: [281/484] Iter:[490/495], Time: 0.37, lr: [0.004554859149158561], Loss: 2.027146, Acc:0.800725, Semantic loss: 0.767964, BCE loss: 0.526666, SB loss: 0.732516
2023-10-30 15:31:35,677 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:31:35,912 Loss: 2.168, MeanIU:  0.6929, Best_mIoU:  0.7151
2023-10-30 15:31:35,913 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466]
2023-10-30 15:31:38,128 Epoch: [282/484] Iter:[0/495], Time: 2.18, lr: [0.004554654169735421], Loss: 1.549202, Acc:0.833488, Semantic loss: 0.566793, BCE loss: 0.342180, SB loss: 0.640229
2023-10-30 15:31:42,231 Epoch: [282/484] Iter:[10/495], Time: 0.57, lr: [0.004554244207814077], Loss: 1.943939, Acc:0.806916, Semantic loss: 0.707646, BCE loss: 0.524222, SB loss: 0.712071
2023-10-30 15:31:45,964 Epoch: [282/484] Iter:[20/495], Time: 0.48, lr: [0.004553834241792274], Loss: 1.984414, Acc:0.811315, Semantic loss: 0.726345, BCE loss: 0.548797, SB loss: 0.709272
2023-10-30 15:31:49,625 Epoch: [282/484] Iter:[30/495], Time: 0.44, lr: [0.004553424271669561], Loss: 1.985232, Acc:0.792643, Semantic loss: 0.739078, BCE loss: 0.523555, SB loss: 0.722598
2023-10-30 15:31:53,242 Epoch: [282/484] Iter:[40/495], Time: 0.42, lr: [0.004553014297445486], Loss: 1.975736, Acc:0.801156, Semantic loss: 0.736023, BCE loss: 0.515309, SB loss: 0.724404
2023-10-30 15:31:56,901 Epoch: [282/484] Iter:[50/495], Time: 0.41, lr: [0.004552604319119595], Loss: 1.982613, Acc:0.804785, Semantic loss: 0.736334, BCE loss: 0.522700, SB loss: 0.723579
2023-10-30 15:32:00,555 Epoch: [282/484] Iter:[60/495], Time: 0.40, lr: [0.004552194336691441], Loss: 1.987154, Acc:0.803705, Semantic loss: 0.734972, BCE loss: 0.525006, SB loss: 0.727176
2023-10-30 15:32:04,261 Epoch: [282/484] Iter:[70/495], Time: 0.40, lr: [0.0045517843501605695], Loss: 1.975797, Acc:0.802666, Semantic loss: 0.737664, BCE loss: 0.516233, SB loss: 0.721900
2023-10-30 15:32:07,946 Epoch: [282/484] Iter:[80/495], Time: 0.40, lr: [0.004551374359526529], Loss: 1.974061, Acc:0.798220, Semantic loss: 0.735731, BCE loss: 0.512838, SB loss: 0.725492
2023-10-30 15:32:11,749 Epoch: [282/484] Iter:[90/495], Time: 0.39, lr: [0.0045509643647888695], Loss: 1.972781, Acc:0.800761, Semantic loss: 0.734090, BCE loss: 0.513624, SB loss: 0.725067
2023-10-30 15:32:15,386 Epoch: [282/484] Iter:[100/495], Time: 0.39, lr: [0.004550554365947138], Loss: 1.971390, Acc:0.802341, Semantic loss: 0.731949, BCE loss: 0.515753, SB loss: 0.723688
2023-10-30 15:32:19,141 Epoch: [282/484] Iter:[110/495], Time: 0.39, lr: [0.004550144363000882], Loss: 1.992369, Acc:0.803751, Semantic loss: 0.740710, BCE loss: 0.523541, SB loss: 0.728118
2023-10-30 15:32:22,801 Epoch: [282/484] Iter:[120/495], Time: 0.39, lr: [0.00454973435594965], Loss: 1.993692, Acc:0.803139, Semantic loss: 0.739178, BCE loss: 0.527372, SB loss: 0.727142
2023-10-30 15:32:26,512 Epoch: [282/484] Iter:[130/495], Time: 0.39, lr: [0.00454932434479299], Loss: 1.986801, Acc:0.803585, Semantic loss: 0.735725, BCE loss: 0.527046, SB loss: 0.724030
2023-10-30 15:32:30,181 Epoch: [282/484] Iter:[140/495], Time: 0.38, lr: [0.00454891432953045], Loss: 1.992499, Acc:0.802541, Semantic loss: 0.740326, BCE loss: 0.528156, SB loss: 0.724016
2023-10-30 15:32:33,894 Epoch: [282/484] Iter:[150/495], Time: 0.38, lr: [0.004548504310161577], Loss: 1.991561, Acc:0.799965, Semantic loss: 0.739977, BCE loss: 0.526294, SB loss: 0.725289
2023-10-30 15:32:37,642 Epoch: [282/484] Iter:[160/495], Time: 0.38, lr: [0.004548094286685918], Loss: 1.994940, Acc:0.799975, Semantic loss: 0.743716, BCE loss: 0.525135, SB loss: 0.726089
2023-10-30 15:32:41,326 Epoch: [282/484] Iter:[170/495], Time: 0.38, lr: [0.0045476842591030235], Loss: 1.985088, Acc:0.798470, Semantic loss: 0.736877, BCE loss: 0.523469, SB loss: 0.724742
2023-10-30 15:32:45,152 Epoch: [282/484] Iter:[180/495], Time: 0.38, lr: [0.004547274227412437], Loss: 1.985275, Acc:0.798434, Semantic loss: 0.735900, BCE loss: 0.525148, SB loss: 0.724228
2023-10-30 15:32:48,891 Epoch: [282/484] Iter:[190/495], Time: 0.38, lr: [0.004546864191613709], Loss: 1.982361, Acc:0.799975, Semantic loss: 0.734392, BCE loss: 0.525597, SB loss: 0.722373
2023-10-30 15:32:52,524 Epoch: [282/484] Iter:[200/495], Time: 0.38, lr: [0.004546454151706384], Loss: 1.981230, Acc:0.798366, Semantic loss: 0.735036, BCE loss: 0.524422, SB loss: 0.721771
2023-10-30 15:32:56,208 Epoch: [282/484] Iter:[210/495], Time: 0.38, lr: [0.004546044107690011], Loss: 1.981698, Acc:0.796583, Semantic loss: 0.736188, BCE loss: 0.522082, SB loss: 0.723428
2023-10-30 15:32:59,875 Epoch: [282/484] Iter:[220/495], Time: 0.38, lr: [0.004545634059564136], Loss: 1.984130, Acc:0.796477, Semantic loss: 0.739830, BCE loss: 0.521387, SB loss: 0.722913
2023-10-30 15:33:03,520 Epoch: [282/484] Iter:[230/495], Time: 0.38, lr: [0.004545224007328308], Loss: 1.981191, Acc:0.797421, Semantic loss: 0.739434, BCE loss: 0.520117, SB loss: 0.721641
2023-10-30 15:33:07,139 Epoch: [282/484] Iter:[240/495], Time: 0.38, lr: [0.004544813950982069], Loss: 1.982941, Acc:0.795645, Semantic loss: 0.742309, BCE loss: 0.517668, SB loss: 0.722964
2023-10-30 15:33:10,866 Epoch: [282/484] Iter:[250/495], Time: 0.38, lr: [0.00454440389052497], Loss: 1.979118, Acc:0.796621, Semantic loss: 0.741138, BCE loss: 0.516152, SB loss: 0.721828
2023-10-30 15:33:14,633 Epoch: [282/484] Iter:[260/495], Time: 0.38, lr: [0.004543993825956558], Loss: 1.978590, Acc:0.797533, Semantic loss: 0.742760, BCE loss: 0.513886, SB loss: 0.721944
2023-10-30 15:33:18,188 Epoch: [282/484] Iter:[270/495], Time: 0.38, lr: [0.004543583757276377], Loss: 1.990925, Acc:0.797899, Semantic loss: 0.750467, BCE loss: 0.515152, SB loss: 0.725306
2023-10-30 15:33:21,953 Epoch: [282/484] Iter:[280/495], Time: 0.38, lr: [0.004543173684483974], Loss: 1.993640, Acc:0.798474, Semantic loss: 0.750210, BCE loss: 0.517708, SB loss: 0.725722
2023-10-30 15:33:25,651 Epoch: [282/484] Iter:[290/495], Time: 0.38, lr: [0.004542763607578896], Loss: 1.996947, Acc:0.796977, Semantic loss: 0.750699, BCE loss: 0.519788, SB loss: 0.726460
2023-10-30 15:33:29,447 Epoch: [282/484] Iter:[300/495], Time: 0.38, lr: [0.00454235352656069], Loss: 1.999069, Acc:0.796255, Semantic loss: 0.751519, BCE loss: 0.520671, SB loss: 0.726878
2023-10-30 15:33:33,119 Epoch: [282/484] Iter:[310/495], Time: 0.38, lr: [0.0045419434414289], Loss: 1.995182, Acc:0.795316, Semantic loss: 0.749604, BCE loss: 0.519631, SB loss: 0.725948
2023-10-30 15:33:36,731 Epoch: [282/484] Iter:[320/495], Time: 0.38, lr: [0.004541533352183073], Loss: 1.997520, Acc:0.795161, Semantic loss: 0.750799, BCE loss: 0.520477, SB loss: 0.726244
2023-10-30 15:33:40,441 Epoch: [282/484] Iter:[330/495], Time: 0.38, lr: [0.004541123258822755], Loss: 1.994258, Acc:0.794740, Semantic loss: 0.749957, BCE loss: 0.518791, SB loss: 0.725509
2023-10-30 15:33:44,204 Epoch: [282/484] Iter:[340/495], Time: 0.38, lr: [0.004540713161347494], Loss: 1.997550, Acc:0.793928, Semantic loss: 0.751511, BCE loss: 0.519955, SB loss: 0.726085
2023-10-30 15:33:47,851 Epoch: [282/484] Iter:[350/495], Time: 0.38, lr: [0.004540303059756832], Loss: 1.997756, Acc:0.793856, Semantic loss: 0.751720, BCE loss: 0.519865, SB loss: 0.726171
2023-10-30 15:33:51,579 Epoch: [282/484] Iter:[360/495], Time: 0.38, lr: [0.0045398929540503155], Loss: 1.999205, Acc:0.794818, Semantic loss: 0.752501, BCE loss: 0.520555, SB loss: 0.726150
2023-10-30 15:33:55,314 Epoch: [282/484] Iter:[370/495], Time: 0.38, lr: [0.004539482844227493], Loss: 2.004685, Acc:0.794209, Semantic loss: 0.755025, BCE loss: 0.522141, SB loss: 0.727519
2023-10-30 15:33:59,086 Epoch: [282/484] Iter:[380/495], Time: 0.38, lr: [0.004539072730287907], Loss: 2.001237, Acc:0.795567, Semantic loss: 0.752672, BCE loss: 0.521694, SB loss: 0.726871
2023-10-30 15:34:02,744 Epoch: [282/484] Iter:[390/495], Time: 0.38, lr: [0.004538662612231105], Loss: 2.007575, Acc:0.795660, Semantic loss: 0.754833, BCE loss: 0.524526, SB loss: 0.728216
2023-10-30 15:34:06,465 Epoch: [282/484] Iter:[400/495], Time: 0.38, lr: [0.004538252490056629], Loss: 2.008704, Acc:0.795841, Semantic loss: 0.755336, BCE loss: 0.524563, SB loss: 0.728805
2023-10-30 15:34:10,195 Epoch: [282/484] Iter:[410/495], Time: 0.38, lr: [0.004537842363764028], Loss: 2.006175, Acc:0.794938, Semantic loss: 0.754368, BCE loss: 0.523453, SB loss: 0.728355
2023-10-30 15:34:13,897 Epoch: [282/484] Iter:[420/495], Time: 0.38, lr: [0.004537432233352845], Loss: 2.007267, Acc:0.795438, Semantic loss: 0.755164, BCE loss: 0.523789, SB loss: 0.728315
2023-10-30 15:34:17,583 Epoch: [282/484] Iter:[430/495], Time: 0.38, lr: [0.004537022098822625], Loss: 2.009274, Acc:0.795945, Semantic loss: 0.755523, BCE loss: 0.525513, SB loss: 0.728237
2023-10-30 15:34:21,268 Epoch: [282/484] Iter:[440/495], Time: 0.37, lr: [0.004536611960172914], Loss: 2.010129, Acc:0.796852, Semantic loss: 0.755763, BCE loss: 0.525951, SB loss: 0.728416
2023-10-30 15:34:25,016 Epoch: [282/484] Iter:[450/495], Time: 0.37, lr: [0.004536201817403256], Loss: 2.016301, Acc:0.796770, Semantic loss: 0.758815, BCE loss: 0.527774, SB loss: 0.729713
2023-10-30 15:34:28,702 Epoch: [282/484] Iter:[460/495], Time: 0.37, lr: [0.004535791670513196], Loss: 2.012987, Acc:0.796511, Semantic loss: 0.756411, BCE loss: 0.528103, SB loss: 0.728474
2023-10-30 15:34:32,421 Epoch: [282/484] Iter:[470/495], Time: 0.37, lr: [0.004535381519502279], Loss: 2.012427, Acc:0.796675, Semantic loss: 0.757000, BCE loss: 0.527185, SB loss: 0.728242
2023-10-30 15:34:36,115 Epoch: [282/484] Iter:[480/495], Time: 0.37, lr: [0.004534971364370047], Loss: 2.012802, Acc:0.796770, Semantic loss: 0.756710, BCE loss: 0.528466, SB loss: 0.727627
2023-10-30 15:34:39,651 Epoch: [282/484] Iter:[490/495], Time: 0.37, lr: [0.004534561205116048], Loss: 2.010147, Acc:0.796188, Semantic loss: 0.754853, BCE loss: 0.528388, SB loss: 0.726905
2023-10-30 15:34:41,047 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:34:41,284 Loss: 2.168, MeanIU:  0.6929, Best_mIoU:  0.7151
2023-10-30 15:34:41,284 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466]
2023-10-30 15:34:43,312 Epoch: [283/484] Iter:[0/495], Time: 1.99, lr: [0.004534356123943243], Loss: 2.086781, Acc:0.866558, Semantic loss: 0.768008, BCE loss: 0.582539, SB loss: 0.736234
2023-10-30 15:34:47,426 Epoch: [283/484] Iter:[10/495], Time: 0.56, lr: [0.004533945958505736], Loss: 2.011039, Acc:0.812960, Semantic loss: 0.759959, BCE loss: 0.505245, SB loss: 0.745836
2023-10-30 15:34:51,144 Epoch: [283/484] Iter:[20/495], Time: 0.47, lr: [0.0045335357889453205], Loss: 1.986508, Acc:0.803572, Semantic loss: 0.760455, BCE loss: 0.497129, SB loss: 0.728925
2023-10-30 15:34:54,835 Epoch: [283/484] Iter:[30/495], Time: 0.44, lr: [0.004533125615261542], Loss: 2.005406, Acc:0.800580, Semantic loss: 0.762484, BCE loss: 0.518323, SB loss: 0.724600
2023-10-30 15:34:58,492 Epoch: [283/484] Iter:[40/495], Time: 0.42, lr: [0.004532715437453943], Loss: 2.034114, Acc:0.798601, Semantic loss: 0.771918, BCE loss: 0.531679, SB loss: 0.730517
2023-10-30 15:35:02,224 Epoch: [283/484] Iter:[50/495], Time: 0.41, lr: [0.004532305255522069], Loss: 2.029126, Acc:0.796116, Semantic loss: 0.768644, BCE loss: 0.534489, SB loss: 0.725992
2023-10-30 15:35:05,868 Epoch: [283/484] Iter:[60/495], Time: 0.40, lr: [0.004531895069465462], Loss: 2.049848, Acc:0.798242, Semantic loss: 0.774143, BCE loss: 0.545303, SB loss: 0.730402
2023-10-30 15:35:09,506 Epoch: [283/484] Iter:[70/495], Time: 0.40, lr: [0.004531484879283667], Loss: 2.036812, Acc:0.795108, Semantic loss: 0.770369, BCE loss: 0.536552, SB loss: 0.729892
2023-10-30 15:35:13,270 Epoch: [283/484] Iter:[80/495], Time: 0.39, lr: [0.004531074684976227], Loss: 2.028024, Acc:0.799992, Semantic loss: 0.765579, BCE loss: 0.529916, SB loss: 0.732529
2023-10-30 15:35:17,044 Epoch: [283/484] Iter:[90/495], Time: 0.39, lr: [0.004530664486542686], Loss: 2.018707, Acc:0.799878, Semantic loss: 0.761682, BCE loss: 0.528031, SB loss: 0.728995
2023-10-30 15:35:20,776 Epoch: [283/484] Iter:[100/495], Time: 0.39, lr: [0.004530254283982586], Loss: 2.025861, Acc:0.802108, Semantic loss: 0.764308, BCE loss: 0.530764, SB loss: 0.730789
2023-10-30 15:35:24,575 Epoch: [283/484] Iter:[110/495], Time: 0.39, lr: [0.004529844077295471], Loss: 2.024548, Acc:0.803944, Semantic loss: 0.763269, BCE loss: 0.529597, SB loss: 0.731682
2023-10-30 15:35:28,186 Epoch: [283/484] Iter:[120/495], Time: 0.39, lr: [0.0045294338664808855], Loss: 2.024001, Acc:0.802110, Semantic loss: 0.761420, BCE loss: 0.529889, SB loss: 0.732692
2023-10-30 15:35:31,920 Epoch: [283/484] Iter:[130/495], Time: 0.39, lr: [0.004529023651538372], Loss: 2.019889, Acc:0.800430, Semantic loss: 0.758468, BCE loss: 0.530405, SB loss: 0.731015
2023-10-30 15:35:35,641 Epoch: [283/484] Iter:[140/495], Time: 0.39, lr: [0.004528613432467472], Loss: 2.019689, Acc:0.801518, Semantic loss: 0.759960, BCE loss: 0.528448, SB loss: 0.731281
2023-10-30 15:35:39,363 Epoch: [283/484] Iter:[150/495], Time: 0.38, lr: [0.0045282032092677305], Loss: 2.012070, Acc:0.801059, Semantic loss: 0.758308, BCE loss: 0.523219, SB loss: 0.730544
2023-10-30 15:35:42,998 Epoch: [283/484] Iter:[160/495], Time: 0.38, lr: [0.004527792981938689], Loss: 2.004316, Acc:0.802378, Semantic loss: 0.755459, BCE loss: 0.520409, SB loss: 0.728448
2023-10-30 15:35:46,784 Epoch: [283/484] Iter:[170/495], Time: 0.38, lr: [0.004527382750479892], Loss: 2.007212, Acc:0.800848, Semantic loss: 0.757578, BCE loss: 0.521308, SB loss: 0.728326
2023-10-30 15:35:50,495 Epoch: [283/484] Iter:[180/495], Time: 0.38, lr: [0.004526972514890878], Loss: 2.014682, Acc:0.801599, Semantic loss: 0.760198, BCE loss: 0.523886, SB loss: 0.730598
2023-10-30 15:35:54,149 Epoch: [283/484] Iter:[190/495], Time: 0.38, lr: [0.0045265622751711945], Loss: 2.020252, Acc:0.800105, Semantic loss: 0.765841, BCE loss: 0.523630, SB loss: 0.730781
2023-10-30 15:35:57,818 Epoch: [283/484] Iter:[200/495], Time: 0.38, lr: [0.0045261520313203815], Loss: 2.026312, Acc:0.800418, Semantic loss: 0.768726, BCE loss: 0.523769, SB loss: 0.733816
2023-10-30 15:36:01,435 Epoch: [283/484] Iter:[210/495], Time: 0.38, lr: [0.004525741783337982], Loss: 2.029000, Acc:0.800358, Semantic loss: 0.770092, BCE loss: 0.524946, SB loss: 0.733963
2023-10-30 15:36:05,150 Epoch: [283/484] Iter:[220/495], Time: 0.38, lr: [0.004525331531223536], Loss: 2.044315, Acc:0.800059, Semantic loss: 0.779704, BCE loss: 0.527394, SB loss: 0.737217
2023-10-30 15:36:08,899 Epoch: [283/484] Iter:[230/495], Time: 0.38, lr: [0.00452492127497659], Loss: 2.057975, Acc:0.799244, Semantic loss: 0.786591, BCE loss: 0.529607, SB loss: 0.741777
2023-10-30 15:36:12,592 Epoch: [283/484] Iter:[240/495], Time: 0.38, lr: [0.0045245110145966825], Loss: 2.066632, Acc:0.799050, Semantic loss: 0.789216, BCE loss: 0.531851, SB loss: 0.745565
2023-10-30 15:36:16,198 Epoch: [283/484] Iter:[250/495], Time: 0.38, lr: [0.004524100750083356], Loss: 2.071295, Acc:0.799185, Semantic loss: 0.790123, BCE loss: 0.535425, SB loss: 0.745747
2023-10-30 15:36:19,935 Epoch: [283/484] Iter:[260/495], Time: 0.38, lr: [0.004523690481436153], Loss: 2.069179, Acc:0.800411, Semantic loss: 0.788883, BCE loss: 0.535270, SB loss: 0.745026
2023-10-30 15:36:23,650 Epoch: [283/484] Iter:[270/495], Time: 0.38, lr: [0.004523280208654616], Loss: 2.065632, Acc:0.800778, Semantic loss: 0.785941, BCE loss: 0.535093, SB loss: 0.744597
2023-10-30 15:36:27,345 Epoch: [283/484] Iter:[280/495], Time: 0.38, lr: [0.004522869931738285], Loss: 2.069913, Acc:0.800848, Semantic loss: 0.787528, BCE loss: 0.536974, SB loss: 0.745411
2023-10-30 15:36:31,187 Epoch: [283/484] Iter:[290/495], Time: 0.38, lr: [0.004522459650686704], Loss: 2.068601, Acc:0.802193, Semantic loss: 0.785817, BCE loss: 0.537906, SB loss: 0.744878
2023-10-30 15:36:34,920 Epoch: [283/484] Iter:[300/495], Time: 0.38, lr: [0.004522049365499411], Loss: 2.064917, Acc:0.802005, Semantic loss: 0.784225, BCE loss: 0.536648, SB loss: 0.744044
2023-10-30 15:36:38,560 Epoch: [283/484] Iter:[310/495], Time: 0.38, lr: [0.00452163907617595], Loss: 2.068872, Acc:0.801548, Semantic loss: 0.786254, BCE loss: 0.537173, SB loss: 0.745446
2023-10-30 15:36:42,289 Epoch: [283/484] Iter:[320/495], Time: 0.38, lr: [0.004521228782715862], Loss: 2.068249, Acc:0.801331, Semantic loss: 0.786131, BCE loss: 0.537089, SB loss: 0.745029
2023-10-30 15:36:45,940 Epoch: [283/484] Iter:[330/495], Time: 0.38, lr: [0.004520818485118688], Loss: 2.065601, Acc:0.802351, Semantic loss: 0.784753, BCE loss: 0.536608, SB loss: 0.744241
2023-10-30 15:36:49,549 Epoch: [283/484] Iter:[340/495], Time: 0.38, lr: [0.004520408183383967], Loss: 2.068109, Acc:0.801608, Semantic loss: 0.786760, BCE loss: 0.537045, SB loss: 0.744303
2023-10-30 15:36:53,225 Epoch: [283/484] Iter:[350/495], Time: 0.38, lr: [0.004519997877511243], Loss: 2.062913, Acc:0.800777, Semantic loss: 0.783137, BCE loss: 0.535787, SB loss: 0.743989
2023-10-30 15:36:56,925 Epoch: [283/484] Iter:[360/495], Time: 0.38, lr: [0.004519587567500057], Loss: 2.063053, Acc:0.801710, Semantic loss: 0.782551, BCE loss: 0.536364, SB loss: 0.744137
2023-10-30 15:37:00,800 Epoch: [283/484] Iter:[370/495], Time: 0.38, lr: [0.004519177253349947], Loss: 2.065391, Acc:0.802076, Semantic loss: 0.783659, BCE loss: 0.537750, SB loss: 0.743983
2023-10-30 15:37:04,466 Epoch: [283/484] Iter:[380/495], Time: 0.38, lr: [0.004518766935060455], Loss: 2.069290, Acc:0.802803, Semantic loss: 0.784564, BCE loss: 0.539875, SB loss: 0.744851
2023-10-30 15:37:08,197 Epoch: [283/484] Iter:[390/495], Time: 0.38, lr: [0.004518356612631122], Loss: 2.067583, Acc:0.803400, Semantic loss: 0.783490, BCE loss: 0.540312, SB loss: 0.743780
2023-10-30 15:37:11,846 Epoch: [283/484] Iter:[400/495], Time: 0.38, lr: [0.004517946286061489], Loss: 2.067558, Acc:0.803447, Semantic loss: 0.783433, BCE loss: 0.540958, SB loss: 0.743167
2023-10-30 15:37:15,666 Epoch: [283/484] Iter:[410/495], Time: 0.38, lr: [0.004517535955351096], Loss: 2.062969, Acc:0.803502, Semantic loss: 0.780566, BCE loss: 0.540201, SB loss: 0.742201
2023-10-30 15:37:19,503 Epoch: [283/484] Iter:[420/495], Time: 0.38, lr: [0.004517125620499481], Loss: 2.065677, Acc:0.803121, Semantic loss: 0.784087, BCE loss: 0.539115, SB loss: 0.742475
2023-10-30 15:37:23,186 Epoch: [283/484] Iter:[430/495], Time: 0.38, lr: [0.004516715281506188], Loss: 2.068180, Acc:0.803396, Semantic loss: 0.786213, BCE loss: 0.539284, SB loss: 0.742683
2023-10-30 15:37:26,805 Epoch: [283/484] Iter:[440/495], Time: 0.38, lr: [0.004516304938370755], Loss: 2.066020, Acc:0.803125, Semantic loss: 0.784960, BCE loss: 0.538726, SB loss: 0.742335
2023-10-30 15:37:30,493 Epoch: [283/484] Iter:[450/495], Time: 0.38, lr: [0.004515894591092722], Loss: 2.063949, Acc:0.802140, Semantic loss: 0.784695, BCE loss: 0.537202, SB loss: 0.742051
2023-10-30 15:37:34,186 Epoch: [283/484] Iter:[460/495], Time: 0.37, lr: [0.004515484239671629], Loss: 2.061595, Acc:0.802146, Semantic loss: 0.783340, BCE loss: 0.536863, SB loss: 0.741393
2023-10-30 15:37:37,872 Epoch: [283/484] Iter:[470/495], Time: 0.37, lr: [0.004515073884107017], Loss: 2.059855, Acc:0.802296, Semantic loss: 0.781264, BCE loss: 0.537908, SB loss: 0.740683
2023-10-30 15:37:41,551 Epoch: [283/484] Iter:[480/495], Time: 0.37, lr: [0.004514663524398424], Loss: 2.061817, Acc:0.801586, Semantic loss: 0.783205, BCE loss: 0.537319, SB loss: 0.741293
2023-10-30 15:37:45,047 Epoch: [283/484] Iter:[490/495], Time: 0.37, lr: [0.004514253160545391], Loss: 2.061690, Acc:0.800880, Semantic loss: 0.782434, BCE loss: 0.537851, SB loss: 0.741406
2023-10-30 15:37:46,465 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:37:46,704 Loss: 2.168, MeanIU:  0.6929, Best_mIoU:  0.7151
2023-10-30 15:37:46,704 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466]
2023-10-30 15:37:48,709 Epoch: [284/484] Iter:[0/495], Time: 1.97, lr: [0.004514047977064566], Loss: 2.504914, Acc:0.723701, Semantic loss: 1.008377, BCE loss: 0.595881, SB loss: 0.900657
2023-10-30 15:37:52,836 Epoch: [284/484] Iter:[10/495], Time: 0.55, lr: [0.004513637606994008], Loss: 2.036984, Acc:0.821034, Semantic loss: 0.774551, BCE loss: 0.538135, SB loss: 0.724299
2023-10-30 15:37:56,525 Epoch: [284/484] Iter:[20/495], Time: 0.47, lr: [0.004513227232777859], Loss: 2.081135, Acc:0.797764, Semantic loss: 0.794066, BCE loss: 0.546558, SB loss: 0.740511
2023-10-30 15:38:00,272 Epoch: [284/484] Iter:[30/495], Time: 0.44, lr: [0.004512816854415658], Loss: 2.039308, Acc:0.775010, Semantic loss: 0.776679, BCE loss: 0.527201, SB loss: 0.735428
2023-10-30 15:38:04,091 Epoch: [284/484] Iter:[40/495], Time: 0.42, lr: [0.0045124064719069415], Loss: 2.028375, Acc:0.782077, Semantic loss: 0.764771, BCE loss: 0.529726, SB loss: 0.733877
2023-10-30 15:38:07,722 Epoch: [284/484] Iter:[50/495], Time: 0.41, lr: [0.004511996085251252], Loss: 2.022224, Acc:0.784406, Semantic loss: 0.758268, BCE loss: 0.525965, SB loss: 0.737992
2023-10-30 15:38:11,330 Epoch: [284/484] Iter:[60/495], Time: 0.40, lr: [0.004511585694448127], Loss: 2.022044, Acc:0.784648, Semantic loss: 0.758686, BCE loss: 0.527132, SB loss: 0.736226
2023-10-30 15:38:15,003 Epoch: [284/484] Iter:[70/495], Time: 0.40, lr: [0.004511175299497106], Loss: 1.999781, Acc:0.782185, Semantic loss: 0.750734, BCE loss: 0.517621, SB loss: 0.731426
2023-10-30 15:38:18,825 Epoch: [284/484] Iter:[80/495], Time: 0.40, lr: [0.004510764900397726], Loss: 1.991986, Acc:0.786750, Semantic loss: 0.743293, BCE loss: 0.516099, SB loss: 0.732595
2023-10-30 15:38:22,655 Epoch: [284/484] Iter:[90/495], Time: 0.39, lr: [0.0045103544971495275], Loss: 1.988629, Acc:0.789546, Semantic loss: 0.744342, BCE loss: 0.512792, SB loss: 0.731495
2023-10-30 15:38:26,384 Epoch: [284/484] Iter:[100/495], Time: 0.39, lr: [0.00450994408975205], Loss: 1.984786, Acc:0.793025, Semantic loss: 0.741004, BCE loss: 0.515241, SB loss: 0.728541
2023-10-30 15:38:30,020 Epoch: [284/484] Iter:[110/495], Time: 0.39, lr: [0.004509533678204829], Loss: 1.992370, Acc:0.793706, Semantic loss: 0.747216, BCE loss: 0.516084, SB loss: 0.729070
2023-10-30 15:38:33,790 Epoch: [284/484] Iter:[120/495], Time: 0.39, lr: [0.004509123262507404], Loss: 1.995410, Acc:0.797383, Semantic loss: 0.753654, BCE loss: 0.513831, SB loss: 0.727925
2023-10-30 15:38:37,472 Epoch: [284/484] Iter:[130/495], Time: 0.39, lr: [0.004508712842659315], Loss: 1.994708, Acc:0.798344, Semantic loss: 0.754806, BCE loss: 0.512166, SB loss: 0.727736
2023-10-30 15:38:41,221 Epoch: [284/484] Iter:[140/495], Time: 0.39, lr: [0.004508302418660099], Loss: 1.994189, Acc:0.796690, Semantic loss: 0.755960, BCE loss: 0.508803, SB loss: 0.729426
2023-10-30 15:38:44,910 Epoch: [284/484] Iter:[150/495], Time: 0.39, lr: [0.004507891990509294], Loss: 2.004080, Acc:0.797689, Semantic loss: 0.759992, BCE loss: 0.513071, SB loss: 0.731018
2023-10-30 15:38:48,533 Epoch: [284/484] Iter:[160/495], Time: 0.38, lr: [0.0045074815582064375], Loss: 2.011677, Acc:0.796724, Semantic loss: 0.766820, BCE loss: 0.511791, SB loss: 0.733066
2023-10-30 15:38:52,322 Epoch: [284/484] Iter:[170/495], Time: 0.38, lr: [0.004507071121751069], Loss: 2.007395, Acc:0.796624, Semantic loss: 0.760861, BCE loss: 0.514129, SB loss: 0.732405
2023-10-30 15:38:56,012 Epoch: [284/484] Iter:[180/495], Time: 0.38, lr: [0.0045066606811427256], Loss: 2.017345, Acc:0.797520, Semantic loss: 0.768160, BCE loss: 0.513907, SB loss: 0.735277
2023-10-30 15:38:59,677 Epoch: [284/484] Iter:[190/495], Time: 0.38, lr: [0.004506250236380944], Loss: 2.022383, Acc:0.796517, Semantic loss: 0.770278, BCE loss: 0.516401, SB loss: 0.735704
2023-10-30 15:39:03,433 Epoch: [284/484] Iter:[200/495], Time: 0.38, lr: [0.0045058397874652625], Loss: 2.020254, Acc:0.797287, Semantic loss: 0.768131, BCE loss: 0.516864, SB loss: 0.735259
2023-10-30 15:39:07,114 Epoch: [284/484] Iter:[210/495], Time: 0.38, lr: [0.004505429334395219], Loss: 2.018008, Acc:0.798966, Semantic loss: 0.766876, BCE loss: 0.516389, SB loss: 0.734743
2023-10-30 15:39:10,831 Epoch: [284/484] Iter:[220/495], Time: 0.38, lr: [0.004505018877170351], Loss: 2.021536, Acc:0.800237, Semantic loss: 0.766622, BCE loss: 0.519783, SB loss: 0.735131
2023-10-30 15:39:14,537 Epoch: [284/484] Iter:[230/495], Time: 0.38, lr: [0.004504608415790195], Loss: 2.023885, Acc:0.799452, Semantic loss: 0.767440, BCE loss: 0.521696, SB loss: 0.734749
2023-10-30 15:39:18,229 Epoch: [284/484] Iter:[240/495], Time: 0.38, lr: [0.004504197950254288], Loss: 2.018572, Acc:0.798407, Semantic loss: 0.765679, BCE loss: 0.518976, SB loss: 0.733917
2023-10-30 15:39:22,013 Epoch: [284/484] Iter:[250/495], Time: 0.38, lr: [0.0045037874805621695], Loss: 2.025697, Acc:0.798983, Semantic loss: 0.767858, BCE loss: 0.522187, SB loss: 0.735652
2023-10-30 15:39:25,772 Epoch: [284/484] Iter:[260/495], Time: 0.38, lr: [0.004503377006713374], Loss: 2.024915, Acc:0.797562, Semantic loss: 0.766790, BCE loss: 0.522365, SB loss: 0.735760
2023-10-30 15:39:29,418 Epoch: [284/484] Iter:[270/495], Time: 0.38, lr: [0.004502966528707439], Loss: 2.030237, Acc:0.797392, Semantic loss: 0.770565, BCE loss: 0.522663, SB loss: 0.737009
2023-10-30 15:39:33,152 Epoch: [284/484] Iter:[280/495], Time: 0.38, lr: [0.004502556046543901], Loss: 2.028736, Acc:0.797201, Semantic loss: 0.769702, BCE loss: 0.523336, SB loss: 0.735697
2023-10-30 15:39:36,981 Epoch: [284/484] Iter:[290/495], Time: 0.38, lr: [0.004502145560222298], Loss: 2.024101, Acc:0.798393, Semantic loss: 0.767565, BCE loss: 0.521900, SB loss: 0.734636
2023-10-30 15:39:40,753 Epoch: [284/484] Iter:[300/495], Time: 0.38, lr: [0.004501735069742167], Loss: 2.023113, Acc:0.797829, Semantic loss: 0.767193, BCE loss: 0.522232, SB loss: 0.733688
2023-10-30 15:39:44,500 Epoch: [284/484] Iter:[310/495], Time: 0.38, lr: [0.004501324575103043], Loss: 2.021026, Acc:0.799122, Semantic loss: 0.766033, BCE loss: 0.522267, SB loss: 0.732727
2023-10-30 15:39:48,201 Epoch: [284/484] Iter:[320/495], Time: 0.38, lr: [0.004500914076304461], Loss: 2.020285, Acc:0.798582, Semantic loss: 0.765083, BCE loss: 0.522364, SB loss: 0.732839
2023-10-30 15:39:51,898 Epoch: [284/484] Iter:[330/495], Time: 0.38, lr: [0.004500503573345961], Loss: 2.017879, Acc:0.798874, Semantic loss: 0.764383, BCE loss: 0.521052, SB loss: 0.732444
2023-10-30 15:39:55,620 Epoch: [284/484] Iter:[340/495], Time: 0.38, lr: [0.004500093066227078], Loss: 2.020026, Acc:0.798342, Semantic loss: 0.765517, BCE loss: 0.521810, SB loss: 0.732699
2023-10-30 15:39:59,220 Epoch: [284/484] Iter:[350/495], Time: 0.38, lr: [0.004499682554947347], Loss: 2.018794, Acc:0.798105, Semantic loss: 0.765545, BCE loss: 0.521542, SB loss: 0.731707
2023-10-30 15:40:02,944 Epoch: [284/484] Iter:[360/495], Time: 0.38, lr: [0.004499272039506304], Loss: 2.014518, Acc:0.795997, Semantic loss: 0.762861, BCE loss: 0.521170, SB loss: 0.730487
2023-10-30 15:40:06,709 Epoch: [284/484] Iter:[370/495], Time: 0.38, lr: [0.004498861519903486], Loss: 2.014375, Acc:0.797114, Semantic loss: 0.762170, BCE loss: 0.522409, SB loss: 0.729796
2023-10-30 15:40:10,464 Epoch: [284/484] Iter:[380/495], Time: 0.38, lr: [0.004498450996138429], Loss: 2.010118, Acc:0.797374, Semantic loss: 0.760512, BCE loss: 0.520389, SB loss: 0.729217
2023-10-30 15:40:14,159 Epoch: [284/484] Iter:[390/495], Time: 0.38, lr: [0.004498040468210667], Loss: 2.015886, Acc:0.797040, Semantic loss: 0.763568, BCE loss: 0.521866, SB loss: 0.730452
2023-10-30 15:40:17,803 Epoch: [284/484] Iter:[400/495], Time: 0.38, lr: [0.0044976299361197385], Loss: 2.017792, Acc:0.796285, Semantic loss: 0.764564, BCE loss: 0.522628, SB loss: 0.730600
2023-10-30 15:40:21,523 Epoch: [284/484] Iter:[410/495], Time: 0.38, lr: [0.004497219399865177], Loss: 2.017172, Acc:0.795480, Semantic loss: 0.764034, BCE loss: 0.522001, SB loss: 0.731138
2023-10-30 15:40:25,333 Epoch: [284/484] Iter:[420/495], Time: 0.38, lr: [0.004496808859446518], Loss: 2.016503, Acc:0.795632, Semantic loss: 0.762865, BCE loss: 0.522240, SB loss: 0.731398
2023-10-30 15:40:28,995 Epoch: [284/484] Iter:[430/495], Time: 0.38, lr: [0.0044963983148632964], Loss: 2.015226, Acc:0.794997, Semantic loss: 0.762349, BCE loss: 0.521753, SB loss: 0.731124
2023-10-30 15:40:32,724 Epoch: [284/484] Iter:[440/495], Time: 0.38, lr: [0.00449598776611505], Loss: 2.015691, Acc:0.794596, Semantic loss: 0.762897, BCE loss: 0.521639, SB loss: 0.731155
2023-10-30 15:40:36,473 Epoch: [284/484] Iter:[450/495], Time: 0.38, lr: [0.0044955772132013105], Loss: 2.016223, Acc:0.795541, Semantic loss: 0.762500, BCE loss: 0.522527, SB loss: 0.731196
2023-10-30 15:40:40,151 Epoch: [284/484] Iter:[460/495], Time: 0.38, lr: [0.004495166656121616], Loss: 2.016395, Acc:0.795437, Semantic loss: 0.762502, BCE loss: 0.522419, SB loss: 0.731474
2023-10-30 15:40:43,915 Epoch: [284/484] Iter:[470/495], Time: 0.38, lr: [0.004494756094875499], Loss: 2.016825, Acc:0.795111, Semantic loss: 0.762652, BCE loss: 0.522016, SB loss: 0.732157
2023-10-30 15:40:47,672 Epoch: [284/484] Iter:[480/495], Time: 0.38, lr: [0.004494345529462497], Loss: 2.015560, Acc:0.794985, Semantic loss: 0.761675, BCE loss: 0.521772, SB loss: 0.732113
2023-10-30 15:40:51,214 Epoch: [284/484] Iter:[490/495], Time: 0.38, lr: [0.004493934959882141], Loss: 2.017569, Acc:0.795505, Semantic loss: 0.762191, BCE loss: 0.523061, SB loss: 0.732318
2023-10-30 15:40:52,627 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:40:52,862 Loss: 2.168, MeanIU:  0.6929, Best_mIoU:  0.7151
2023-10-30 15:40:52,862 [0.96903237 0.76718026 0.89423891 0.27737494 0.48025258 0.55597744
 0.62488266 0.72806699 0.89559655 0.46878824 0.92608992 0.77827266
 0.56276511 0.92973219 0.5721279  0.76590688 0.73905901 0.51234454
 0.71707466]
2023-10-30 15:40:54,933 Epoch: [285/484] Iter:[0/495], Time: 2.04, lr: [0.004493729673529062], Loss: 2.112758, Acc:0.846017, Semantic loss: 0.721228, BCE loss: 0.582913, SB loss: 0.808616
2023-10-30 15:40:58,897 Epoch: [285/484] Iter:[10/495], Time: 0.55, lr: [0.004493319097696807], Loss: 1.952565, Acc:0.814855, Semantic loss: 0.692789, BCE loss: 0.522849, SB loss: 0.736927
2023-10-30 15:41:02,601 Epoch: [285/484] Iter:[20/495], Time: 0.46, lr: [0.004492908517696036], Loss: 1.939792, Acc:0.805375, Semantic loss: 0.705522, BCE loss: 0.519885, SB loss: 0.714385
2023-10-30 15:41:06,273 Epoch: [285/484] Iter:[30/495], Time: 0.43, lr: [0.004492497933526285], Loss: 1.926021, Acc:0.813459, Semantic loss: 0.717007, BCE loss: 0.497100, SB loss: 0.711913
2023-10-30 15:41:09,908 Epoch: [285/484] Iter:[40/495], Time: 0.41, lr: [0.004492087345187088], Loss: 1.926182, Acc:0.805779, Semantic loss: 0.724555, BCE loss: 0.486295, SB loss: 0.715332
2023-10-30 15:41:13,606 Epoch: [285/484] Iter:[50/495], Time: 0.41, lr: [0.004491676752677978], Loss: 1.944804, Acc:0.797814, Semantic loss: 0.730011, BCE loss: 0.497496, SB loss: 0.717297
2023-10-30 15:41:17,267 Epoch: [285/484] Iter:[60/495], Time: 0.40, lr: [0.004491266155998488], Loss: 1.935227, Acc:0.794083, Semantic loss: 0.724457, BCE loss: 0.492724, SB loss: 0.718046
2023-10-30 15:41:20,984 Epoch: [285/484] Iter:[70/495], Time: 0.40, lr: [0.004490855555148156], Loss: 1.922900, Acc:0.796400, Semantic loss: 0.718930, BCE loss: 0.493045, SB loss: 0.710926
2023-10-30 15:41:24,684 Epoch: [285/484] Iter:[80/495], Time: 0.39, lr: [0.004490444950126513], Loss: 1.930544, Acc:0.795747, Semantic loss: 0.720035, BCE loss: 0.499677, SB loss: 0.710832
2023-10-30 15:41:28,293 Epoch: [285/484] Iter:[90/495], Time: 0.39, lr: [0.004490034340933094], Loss: 1.948319, Acc:0.797582, Semantic loss: 0.729171, BCE loss: 0.502201, SB loss: 0.716947
2023-10-30 15:41:32,049 Epoch: [285/484] Iter:[100/495], Time: 0.39, lr: [0.00448962372756743], Loss: 1.955336, Acc:0.797151, Semantic loss: 0.733016, BCE loss: 0.502774, SB loss: 0.719547
2023-10-30 15:41:35,758 Epoch: [285/484] Iter:[110/495], Time: 0.39, lr: [0.0044892131100290585], Loss: 1.955094, Acc:0.798463, Semantic loss: 0.733389, BCE loss: 0.501948, SB loss: 0.719757
2023-10-30 15:41:39,418 Epoch: [285/484] Iter:[120/495], Time: 0.38, lr: [0.004488802488317511], Loss: 1.968415, Acc:0.798639, Semantic loss: 0.744042, BCE loss: 0.502568, SB loss: 0.721804
2023-10-30 15:41:43,165 Epoch: [285/484] Iter:[130/495], Time: 0.38, lr: [0.004488391862432321], Loss: 1.987864, Acc:0.797408, Semantic loss: 0.757005, BCE loss: 0.506203, SB loss: 0.724656
2023-10-30 15:41:46,872 Epoch: [285/484] Iter:[140/495], Time: 0.38, lr: [0.004487981232373022], Loss: 1.993431, Acc:0.798052, Semantic loss: 0.758673, BCE loss: 0.508250, SB loss: 0.726508
2023-10-30 15:41:50,737 Epoch: [285/484] Iter:[150/495], Time: 0.38, lr: [0.004487570598139147], Loss: 1.998150, Acc:0.798764, Semantic loss: 0.758913, BCE loss: 0.511329, SB loss: 0.727908
2023-10-30 15:41:54,470 Epoch: [285/484] Iter:[160/495], Time: 0.38, lr: [0.004487159959730229], Loss: 2.006015, Acc:0.798028, Semantic loss: 0.766965, BCE loss: 0.509925, SB loss: 0.729124
2023-10-30 15:41:58,201 Epoch: [285/484] Iter:[170/495], Time: 0.38, lr: [0.0044867493171458035], Loss: 2.004239, Acc:0.798705, Semantic loss: 0.764762, BCE loss: 0.512096, SB loss: 0.727381
2023-10-30 15:42:02,034 Epoch: [285/484] Iter:[180/495], Time: 0.38, lr: [0.0044863386703853985], Loss: 2.006720, Acc:0.799343, Semantic loss: 0.764110, BCE loss: 0.514977, SB loss: 0.727633
2023-10-30 15:42:05,827 Epoch: [285/484] Iter:[190/495], Time: 0.38, lr: [0.004485928019448551], Loss: 2.010454, Acc:0.800035, Semantic loss: 0.766109, BCE loss: 0.516105, SB loss: 0.728240
2023-10-30 15:42:09,470 Epoch: [285/484] Iter:[200/495], Time: 0.38, lr: [0.004485517364334793], Loss: 2.016599, Acc:0.801267, Semantic loss: 0.767964, BCE loss: 0.518782, SB loss: 0.729853
2023-10-30 15:42:13,208 Epoch: [285/484] Iter:[210/495], Time: 0.38, lr: [0.004485106705043655], Loss: 2.018872, Acc:0.803099, Semantic loss: 0.767409, BCE loss: 0.522218, SB loss: 0.729245
2023-10-30 15:42:16,992 Epoch: [285/484] Iter:[220/495], Time: 0.38, lr: [0.0044846960415746715], Loss: 2.017146, Acc:0.800966, Semantic loss: 0.766411, BCE loss: 0.521142, SB loss: 0.729592
2023-10-30 15:42:20,694 Epoch: [285/484] Iter:[230/495], Time: 0.38, lr: [0.0044842853739273745], Loss: 2.021935, Acc:0.803163, Semantic loss: 0.767060, BCE loss: 0.524412, SB loss: 0.730464
2023-10-30 15:42:24,370 Epoch: [285/484] Iter:[240/495], Time: 0.38, lr: [0.004483874702101296], Loss: 2.020601, Acc:0.803920, Semantic loss: 0.764956, BCE loss: 0.526440, SB loss: 0.729204
2023-10-30 15:42:28,139 Epoch: [285/484] Iter:[250/495], Time: 0.38, lr: [0.004483464026095967], Loss: 2.026507, Acc:0.804680, Semantic loss: 0.767671, BCE loss: 0.529762, SB loss: 0.729075
2023-10-30 15:42:31,894 Epoch: [285/484] Iter:[260/495], Time: 0.38, lr: [0.004483053345910922], Loss: 2.024903, Acc:0.804714, Semantic loss: 0.765325, BCE loss: 0.531636, SB loss: 0.727943
2023-10-30 15:42:35,586 Epoch: [285/484] Iter:[270/495], Time: 0.38, lr: [0.0044826426615456934], Loss: 2.025673, Acc:0.803840, Semantic loss: 0.764572, BCE loss: 0.532702, SB loss: 0.728399
2023-10-30 15:42:39,230 Epoch: [285/484] Iter:[280/495], Time: 0.38, lr: [0.004482231972999811], Loss: 2.025392, Acc:0.803080, Semantic loss: 0.763538, BCE loss: 0.532834, SB loss: 0.729021
2023-10-30 15:42:42,953 Epoch: [285/484] Iter:[290/495], Time: 0.38, lr: [0.004481821280272805], Loss: 2.024969, Acc:0.802705, Semantic loss: 0.764046, BCE loss: 0.532024, SB loss: 0.728899
2023-10-30 15:42:46,533 Epoch: [285/484] Iter:[300/495], Time: 0.38, lr: [0.004481410583364212], Loss: 2.029073, Acc:0.801517, Semantic loss: 0.766843, BCE loss: 0.533053, SB loss: 0.729177
2023-10-30 15:42:50,531 Epoch: [285/484] Iter:[310/495], Time: 0.38, lr: [0.004480999882273561], Loss: 2.032375, Acc:0.801094, Semantic loss: 0.767738, BCE loss: 0.533907, SB loss: 0.730731
2023-10-30 15:42:54,213 Epoch: [285/484] Iter:[320/495], Time: 0.38, lr: [0.004480589177000383], Loss: 2.032023, Acc:0.801571, Semantic loss: 0.766020, BCE loss: 0.535839, SB loss: 0.730164
2023-10-30 15:42:57,943 Epoch: [285/484] Iter:[330/495], Time: 0.38, lr: [0.0044801784675442095], Loss: 2.026699, Acc:0.801030, Semantic loss: 0.763525, BCE loss: 0.534275, SB loss: 0.728899
2023-10-30 15:43:01,645 Epoch: [285/484] Iter:[340/495], Time: 0.38, lr: [0.004479767753904572], Loss: 2.019493, Acc:0.801751, Semantic loss: 0.759513, BCE loss: 0.533198, SB loss: 0.726782
2023-10-30 15:43:05,318 Epoch: [285/484] Iter:[350/495], Time: 0.38, lr: [0.004479357036081003], Loss: 2.018816, Acc:0.803054, Semantic loss: 0.758351, BCE loss: 0.534027, SB loss: 0.726438
2023-10-30 15:43:09,112 Epoch: [285/484] Iter:[360/495], Time: 0.38, lr: [0.004478946314073033], Loss: 2.019303, Acc:0.803134, Semantic loss: 0.758043, BCE loss: 0.534656, SB loss: 0.726604
2023-10-30 15:43:12,761 Epoch: [285/484] Iter:[370/495], Time: 0.38, lr: [0.004478535587880191], Loss: 2.015855, Acc:0.803600, Semantic loss: 0.756552, BCE loss: 0.533168, SB loss: 0.726134
2023-10-30 15:43:16,443 Epoch: [285/484] Iter:[380/495], Time: 0.38, lr: [0.004478124857502011], Loss: 2.016324, Acc:0.804096, Semantic loss: 0.757232, BCE loss: 0.532990, SB loss: 0.726103
2023-10-30 15:43:20,098 Epoch: [285/484] Iter:[390/495], Time: 0.38, lr: [0.0044777141229380224], Loss: 2.016516, Acc:0.803729, Semantic loss: 0.758028, BCE loss: 0.533252, SB loss: 0.725237
2023-10-30 15:43:23,756 Epoch: [285/484] Iter:[400/495], Time: 0.38, lr: [0.004477303384187756], Loss: 2.020751, Acc:0.803655, Semantic loss: 0.759896, BCE loss: 0.533582, SB loss: 0.727272
2023-10-30 15:43:27,441 Epoch: [285/484] Iter:[410/495], Time: 0.38, lr: [0.0044768926412507406], Loss: 2.017581, Acc:0.802983, Semantic loss: 0.758984, BCE loss: 0.531822, SB loss: 0.726774
2023-10-30 15:43:31,097 Epoch: [285/484] Iter:[420/495], Time: 0.38, lr: [0.00447648189412651], Loss: 2.016516, Acc:0.802623, Semantic loss: 0.758610, BCE loss: 0.530931, SB loss: 0.726975
2023-10-30 15:43:34,837 Epoch: [285/484] Iter:[430/495], Time: 0.38, lr: [0.0044760711428145925], Loss: 2.015760, Acc:0.802246, Semantic loss: 0.757744, BCE loss: 0.531545, SB loss: 0.726471
2023-10-30 15:43:38,543 Epoch: [285/484] Iter:[440/495], Time: 0.38, lr: [0.004475660387314519], Loss: 2.014879, Acc:0.802817, Semantic loss: 0.757075, BCE loss: 0.531853, SB loss: 0.725951
2023-10-30 15:43:42,188 Epoch: [285/484] Iter:[450/495], Time: 0.38, lr: [0.004475249627625819], Loss: 2.017084, Acc:0.803038, Semantic loss: 0.758643, BCE loss: 0.532173, SB loss: 0.726269
2023-10-30 15:43:45,997 Epoch: [285/484] Iter:[460/495], Time: 0.38, lr: [0.004474838863748025], Loss: 2.014979, Acc:0.803608, Semantic loss: 0.757200, BCE loss: 0.531978, SB loss: 0.725801
2023-10-30 15:43:49,778 Epoch: [285/484] Iter:[470/495], Time: 0.38, lr: [0.004474428095680664], Loss: 2.016700, Acc:0.803923, Semantic loss: 0.757410, BCE loss: 0.533361, SB loss: 0.725929
2023-10-30 15:43:53,427 Epoch: [285/484] Iter:[480/495], Time: 0.38, lr: [0.004474017323423268], Loss: 2.014636, Acc:0.804140, Semantic loss: 0.756039, BCE loss: 0.533141, SB loss: 0.725456
2023-10-30 15:43:56,968 Epoch: [285/484] Iter:[490/495], Time: 0.37, lr: [0.004473606546975363], Loss: 2.014506, Acc:0.803600, Semantic loss: 0.756379, BCE loss: 0.532942, SB loss: 0.725185
2023-10-30 15:46:54,311 0 [0.94758522 0.68553494 0.83732051 0.16672907 0.27589762 0.43512655
 0.50479868 0.58932072 0.889226   0.47177954 0.86978753 0.61523421
 0.03357577 0.83019563 0.00340484 0.16226868 0.02642009 0.03823949
 0.60964946] 0.4732681336963635
2023-10-30 15:46:54,311 1 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176] 0.7108909340529591
2023-10-30 15:46:54,315 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:46:54,552 Loss: 2.014, MeanIU:  0.7109, Best_mIoU:  0.7151
2023-10-30 15:46:54,552 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176]
2023-10-30 15:46:56,688 Epoch: [286/484] Iter:[0/495], Time: 2.10, lr: [0.004473401157179826], Loss: 2.268121, Acc:0.840362, Semantic loss: 0.853621, BCE loss: 0.617791, SB loss: 0.796710
2023-10-30 15:47:00,441 Epoch: [286/484] Iter:[10/495], Time: 0.53, lr: [0.0044729903744452825], Loss: 1.957817, Acc:0.779926, Semantic loss: 0.754267, BCE loss: 0.476984, SB loss: 0.726566
2023-10-30 15:47:03,979 Epoch: [286/484] Iter:[20/495], Time: 0.45, lr: [0.004472579587519057], Loss: 2.009368, Acc:0.796648, Semantic loss: 0.768898, BCE loss: 0.513261, SB loss: 0.727210
2023-10-30 15:47:07,480 Epoch: [286/484] Iter:[30/495], Time: 0.42, lr: [0.004472168796400679], Loss: 2.031748, Acc:0.796762, Semantic loss: 0.764210, BCE loss: 0.533205, SB loss: 0.734333
2023-10-30 15:47:11,097 Epoch: [286/484] Iter:[40/495], Time: 0.40, lr: [0.004471758001089677], Loss: 1.984779, Acc:0.789321, Semantic loss: 0.746094, BCE loss: 0.510992, SB loss: 0.727694
2023-10-30 15:47:14,649 Epoch: [286/484] Iter:[50/495], Time: 0.39, lr: [0.004471347201585582], Loss: 2.027625, Acc:0.792388, Semantic loss: 0.770207, BCE loss: 0.524901, SB loss: 0.732517
2023-10-30 15:47:18,278 Epoch: [286/484] Iter:[60/495], Time: 0.39, lr: [0.004470936397887922], Loss: 2.036535, Acc:0.795293, Semantic loss: 0.772228, BCE loss: 0.531202, SB loss: 0.733106
2023-10-30 15:47:21,838 Epoch: [286/484] Iter:[70/495], Time: 0.38, lr: [0.004470525589996226], Loss: 2.030564, Acc:0.794038, Semantic loss: 0.764852, BCE loss: 0.535990, SB loss: 0.729722
2023-10-30 15:47:25,416 Epoch: [286/484] Iter:[80/495], Time: 0.38, lr: [0.0044701147779100244], Loss: 2.063108, Acc:0.789449, Semantic loss: 0.778034, BCE loss: 0.549684, SB loss: 0.735391
2023-10-30 15:47:28,940 Epoch: [286/484] Iter:[90/495], Time: 0.38, lr: [0.0044697039616288445], Loss: 2.080492, Acc:0.789649, Semantic loss: 0.788409, BCE loss: 0.551235, SB loss: 0.740848
2023-10-30 15:47:32,584 Epoch: [286/484] Iter:[100/495], Time: 0.38, lr: [0.004469293141152215], Loss: 2.067124, Acc:0.789797, Semantic loss: 0.776560, BCE loss: 0.549406, SB loss: 0.741158
2023-10-30 15:47:36,279 Epoch: [286/484] Iter:[110/495], Time: 0.38, lr: [0.004468882316479665], Loss: 2.067998, Acc:0.790901, Semantic loss: 0.776163, BCE loss: 0.551986, SB loss: 0.739849
2023-10-30 15:47:39,858 Epoch: [286/484] Iter:[120/495], Time: 0.37, lr: [0.004468471487610723], Loss: 2.062562, Acc:0.793418, Semantic loss: 0.771604, BCE loss: 0.552427, SB loss: 0.738531
2023-10-30 15:47:43,346 Epoch: [286/484] Iter:[130/495], Time: 0.37, lr: [0.0044680606545449185], Loss: 2.048946, Acc:0.794667, Semantic loss: 0.767371, BCE loss: 0.545384, SB loss: 0.736192
2023-10-30 15:47:46,875 Epoch: [286/484] Iter:[140/495], Time: 0.37, lr: [0.0044676498172817785], Loss: 2.043866, Acc:0.792856, Semantic loss: 0.768297, BCE loss: 0.539824, SB loss: 0.735745
2023-10-30 15:47:50,415 Epoch: [286/484] Iter:[150/495], Time: 0.37, lr: [0.00446723897582083], Loss: 2.034377, Acc:0.794656, Semantic loss: 0.763832, BCE loss: 0.537118, SB loss: 0.733427
2023-10-30 15:47:53,986 Epoch: [286/484] Iter:[160/495], Time: 0.37, lr: [0.0044668281301616045], Loss: 2.039374, Acc:0.796008, Semantic loss: 0.766611, BCE loss: 0.538030, SB loss: 0.734734
2023-10-30 15:47:57,666 Epoch: [286/484] Iter:[170/495], Time: 0.37, lr: [0.004466417280303628], Loss: 2.035766, Acc:0.798251, Semantic loss: 0.762423, BCE loss: 0.539484, SB loss: 0.733859
2023-10-30 15:48:01,221 Epoch: [286/484] Iter:[180/495], Time: 0.37, lr: [0.004466006426246429], Loss: 2.031876, Acc:0.798849, Semantic loss: 0.760939, BCE loss: 0.536902, SB loss: 0.734035
2023-10-30 15:48:04,941 Epoch: [286/484] Iter:[190/495], Time: 0.37, lr: [0.004465595567989533], Loss: 2.031928, Acc:0.800220, Semantic loss: 0.761462, BCE loss: 0.536657, SB loss: 0.733809
2023-10-30 15:48:08,659 Epoch: [286/484] Iter:[200/495], Time: 0.37, lr: [0.0044651847055324715], Loss: 2.030424, Acc:0.799230, Semantic loss: 0.762648, BCE loss: 0.533768, SB loss: 0.734008
2023-10-30 15:48:12,280 Epoch: [286/484] Iter:[210/495], Time: 0.37, lr: [0.004464773838874771], Loss: 2.036420, Acc:0.799523, Semantic loss: 0.765742, BCE loss: 0.535058, SB loss: 0.735619
2023-10-30 15:48:16,002 Epoch: [286/484] Iter:[220/495], Time: 0.37, lr: [0.004464362968015957], Loss: 2.037582, Acc:0.800683, Semantic loss: 0.764988, BCE loss: 0.536266, SB loss: 0.736328
2023-10-30 15:48:19,611 Epoch: [286/484] Iter:[230/495], Time: 0.37, lr: [0.004463952092955558], Loss: 2.032864, Acc:0.800737, Semantic loss: 0.762135, BCE loss: 0.534905, SB loss: 0.735824
2023-10-30 15:48:23,381 Epoch: [286/484] Iter:[240/495], Time: 0.37, lr: [0.004463541213693103], Loss: 2.033410, Acc:0.801658, Semantic loss: 0.761234, BCE loss: 0.537498, SB loss: 0.734679
2023-10-30 15:48:27,037 Epoch: [286/484] Iter:[250/495], Time: 0.37, lr: [0.0044631303302281175], Loss: 2.027119, Acc:0.801342, Semantic loss: 0.759352, BCE loss: 0.534525, SB loss: 0.733242
2023-10-30 15:48:30,720 Epoch: [286/484] Iter:[260/495], Time: 0.37, lr: [0.0044627194425601304], Loss: 2.030534, Acc:0.802527, Semantic loss: 0.761450, BCE loss: 0.536115, SB loss: 0.732970
2023-10-30 15:48:34,337 Epoch: [286/484] Iter:[270/495], Time: 0.37, lr: [0.004462308550688666], Loss: 2.031491, Acc:0.802233, Semantic loss: 0.762507, BCE loss: 0.535880, SB loss: 0.733103
2023-10-30 15:48:37,943 Epoch: [286/484] Iter:[280/495], Time: 0.37, lr: [0.004461897654613252], Loss: 2.025131, Acc:0.802780, Semantic loss: 0.758713, BCE loss: 0.534843, SB loss: 0.731576
2023-10-30 15:48:41,588 Epoch: [286/484] Iter:[290/495], Time: 0.37, lr: [0.004461486754333417], Loss: 2.028436, Acc:0.803448, Semantic loss: 0.758834, BCE loss: 0.538438, SB loss: 0.731163
2023-10-30 15:48:45,242 Epoch: [286/484] Iter:[300/495], Time: 0.37, lr: [0.004461075849848686], Loss: 2.029729, Acc:0.802141, Semantic loss: 0.759294, BCE loss: 0.539030, SB loss: 0.731405
2023-10-30 15:48:48,935 Epoch: [286/484] Iter:[310/495], Time: 0.37, lr: [0.0044606649411585856], Loss: 2.028309, Acc:0.801992, Semantic loss: 0.759371, BCE loss: 0.537976, SB loss: 0.730963
2023-10-30 15:48:52,576 Epoch: [286/484] Iter:[320/495], Time: 0.37, lr: [0.004460254028262644], Loss: 2.028052, Acc:0.802814, Semantic loss: 0.759598, BCE loss: 0.537854, SB loss: 0.730600
2023-10-30 15:48:56,167 Epoch: [286/484] Iter:[330/495], Time: 0.37, lr: [0.004459843111160386], Loss: 2.029457, Acc:0.803518, Semantic loss: 0.759785, BCE loss: 0.538641, SB loss: 0.731030
2023-10-30 15:48:59,967 Epoch: [286/484] Iter:[340/495], Time: 0.37, lr: [0.004459432189851339], Loss: 2.025652, Acc:0.803477, Semantic loss: 0.758951, BCE loss: 0.536476, SB loss: 0.730225
2023-10-30 15:49:03,634 Epoch: [286/484] Iter:[350/495], Time: 0.37, lr: [0.0044590212643350275], Loss: 2.023996, Acc:0.804336, Semantic loss: 0.757860, BCE loss: 0.535952, SB loss: 0.730184
2023-10-30 15:49:07,349 Epoch: [286/484] Iter:[360/495], Time: 0.37, lr: [0.0044586103346109796], Loss: 2.021766, Acc:0.804306, Semantic loss: 0.756777, BCE loss: 0.534906, SB loss: 0.730083
2023-10-30 15:49:10,983 Epoch: [286/484] Iter:[370/495], Time: 0.37, lr: [0.004458199400678721], Loss: 2.020313, Acc:0.804424, Semantic loss: 0.756119, BCE loss: 0.534241, SB loss: 0.729952
2023-10-30 15:49:14,598 Epoch: [286/484] Iter:[380/495], Time: 0.37, lr: [0.004457788462537776], Loss: 2.019425, Acc:0.804023, Semantic loss: 0.756201, BCE loss: 0.533554, SB loss: 0.729671
2023-10-30 15:49:18,245 Epoch: [286/484] Iter:[390/495], Time: 0.37, lr: [0.004457377520187671], Loss: 2.018213, Acc:0.804821, Semantic loss: 0.756151, BCE loss: 0.532981, SB loss: 0.729081
2023-10-30 15:49:21,898 Epoch: [286/484] Iter:[400/495], Time: 0.37, lr: [0.004456966573627933], Loss: 2.017518, Acc:0.804922, Semantic loss: 0.756701, BCE loss: 0.532197, SB loss: 0.728621
2023-10-30 15:49:25,550 Epoch: [286/484] Iter:[410/495], Time: 0.37, lr: [0.004456555622858087], Loss: 2.020830, Acc:0.804872, Semantic loss: 0.758929, BCE loss: 0.532868, SB loss: 0.729033
2023-10-30 15:49:29,222 Epoch: [286/484] Iter:[420/495], Time: 0.37, lr: [0.004456144667877658], Loss: 2.019411, Acc:0.804811, Semantic loss: 0.758592, BCE loss: 0.531356, SB loss: 0.729463
2023-10-30 15:49:32,919 Epoch: [286/484] Iter:[430/495], Time: 0.37, lr: [0.004455733708686171], Loss: 2.018673, Acc:0.805320, Semantic loss: 0.759070, BCE loss: 0.530276, SB loss: 0.729328
2023-10-30 15:49:36,636 Epoch: [286/484] Iter:[440/495], Time: 0.37, lr: [0.004455322745283153], Loss: 2.015705, Acc:0.805714, Semantic loss: 0.758025, BCE loss: 0.529145, SB loss: 0.728535
2023-10-30 15:49:40,348 Epoch: [286/484] Iter:[450/495], Time: 0.37, lr: [0.004454911777668128], Loss: 2.015497, Acc:0.805728, Semantic loss: 0.757306, BCE loss: 0.530138, SB loss: 0.728053
2023-10-30 15:49:43,959 Epoch: [286/484] Iter:[460/495], Time: 0.37, lr: [0.004454500805840621], Loss: 2.013346, Acc:0.805663, Semantic loss: 0.756258, BCE loss: 0.529159, SB loss: 0.727928
2023-10-30 15:49:47,520 Epoch: [286/484] Iter:[470/495], Time: 0.37, lr: [0.004454089829800156], Loss: 2.012639, Acc:0.804854, Semantic loss: 0.756156, BCE loss: 0.528637, SB loss: 0.727847
2023-10-30 15:49:51,224 Epoch: [286/484] Iter:[480/495], Time: 0.37, lr: [0.004453678849546261], Loss: 2.012290, Acc:0.804802, Semantic loss: 0.755782, BCE loss: 0.528570, SB loss: 0.727937
2023-10-30 15:49:54,745 Epoch: [286/484] Iter:[490/495], Time: 0.37, lr: [0.004453267865078457], Loss: 2.011514, Acc:0.804476, Semantic loss: 0.754918, BCE loss: 0.528545, SB loss: 0.728051
2023-10-30 15:49:56,148 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:49:56,389 Loss: 2.014, MeanIU:  0.7109, Best_mIoU:  0.7151
2023-10-30 15:49:56,389 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176]
2023-10-30 15:49:58,277 Epoch: [287/484] Iter:[0/495], Time: 1.85, lr: [0.004453062371264193], Loss: 1.631806, Acc:0.830939, Semantic loss: 0.611383, BCE loss: 0.419761, SB loss: 0.600661
2023-10-30 15:50:02,298 Epoch: [287/484] Iter:[10/495], Time: 0.53, lr: [0.004452651380474637], Loss: 1.984275, Acc:0.779282, Semantic loss: 0.773257, BCE loss: 0.509210, SB loss: 0.701808
2023-10-30 15:50:05,930 Epoch: [287/484] Iter:[20/495], Time: 0.45, lr: [0.004452240385469986], Loss: 1.964929, Acc:0.786341, Semantic loss: 0.749627, BCE loss: 0.516967, SB loss: 0.698335
2023-10-30 15:50:09,676 Epoch: [287/484] Iter:[30/495], Time: 0.43, lr: [0.004451829386249766], Loss: 1.972028, Acc:0.778511, Semantic loss: 0.754042, BCE loss: 0.512269, SB loss: 0.705716
2023-10-30 15:50:13,319 Epoch: [287/484] Iter:[40/495], Time: 0.41, lr: [0.004451418382813497], Loss: 1.983992, Acc:0.790639, Semantic loss: 0.749648, BCE loss: 0.523677, SB loss: 0.710667
2023-10-30 15:50:16,956 Epoch: [287/484] Iter:[50/495], Time: 0.40, lr: [0.004451007375160705], Loss: 2.006536, Acc:0.795554, Semantic loss: 0.761755, BCE loss: 0.529852, SB loss: 0.714929
2023-10-30 15:50:20,677 Epoch: [287/484] Iter:[60/495], Time: 0.40, lr: [0.004450596363290916], Loss: 2.004198, Acc:0.798434, Semantic loss: 0.764705, BCE loss: 0.526242, SB loss: 0.713251
2023-10-30 15:50:24,345 Epoch: [287/484] Iter:[70/495], Time: 0.39, lr: [0.004450185347203651], Loss: 1.987730, Acc:0.799666, Semantic loss: 0.756705, BCE loss: 0.521755, SB loss: 0.709270
2023-10-30 15:50:28,012 Epoch: [287/484] Iter:[80/495], Time: 0.39, lr: [0.004449774326898437], Loss: 1.980549, Acc:0.798712, Semantic loss: 0.750394, BCE loss: 0.521086, SB loss: 0.709068
2023-10-30 15:50:31,694 Epoch: [287/484] Iter:[90/495], Time: 0.39, lr: [0.004449363302374794], Loss: 1.971024, Acc:0.802599, Semantic loss: 0.743481, BCE loss: 0.520044, SB loss: 0.707500
2023-10-30 15:50:35,304 Epoch: [287/484] Iter:[100/495], Time: 0.38, lr: [0.0044489522736322505], Loss: 1.970807, Acc:0.801514, Semantic loss: 0.740522, BCE loss: 0.521913, SB loss: 0.708371
2023-10-30 15:50:38,932 Epoch: [287/484] Iter:[110/495], Time: 0.38, lr: [0.004448541240670326], Loss: 1.976896, Acc:0.799520, Semantic loss: 0.743284, BCE loss: 0.523451, SB loss: 0.710161
2023-10-30 15:50:42,599 Epoch: [287/484] Iter:[120/495], Time: 0.38, lr: [0.004448130203488546], Loss: 1.977694, Acc:0.800616, Semantic loss: 0.744525, BCE loss: 0.522206, SB loss: 0.710963
2023-10-30 15:50:46,283 Epoch: [287/484] Iter:[130/495], Time: 0.38, lr: [0.004447719162086432], Loss: 1.986216, Acc:0.798546, Semantic loss: 0.748151, BCE loss: 0.524321, SB loss: 0.713744
2023-10-30 15:50:49,907 Epoch: [287/484] Iter:[140/495], Time: 0.38, lr: [0.00444730811646351], Loss: 1.990417, Acc:0.799066, Semantic loss: 0.746776, BCE loss: 0.526942, SB loss: 0.716699
2023-10-30 15:50:53,597 Epoch: [287/484] Iter:[150/495], Time: 0.38, lr: [0.004446897066619303], Loss: 1.993572, Acc:0.798558, Semantic loss: 0.746601, BCE loss: 0.530172, SB loss: 0.716799
2023-10-30 15:50:57,291 Epoch: [287/484] Iter:[160/495], Time: 0.38, lr: [0.004446486012553331], Loss: 2.003767, Acc:0.799008, Semantic loss: 0.749887, BCE loss: 0.531512, SB loss: 0.722368
2023-10-30 15:51:00,931 Epoch: [287/484] Iter:[170/495], Time: 0.38, lr: [0.0044460749542651196], Loss: 2.006509, Acc:0.799018, Semantic loss: 0.751287, BCE loss: 0.531681, SB loss: 0.723541
2023-10-30 15:51:04,609 Epoch: [287/484] Iter:[180/495], Time: 0.38, lr: [0.004445663891754191], Loss: 2.004379, Acc:0.798824, Semantic loss: 0.751413, BCE loss: 0.529830, SB loss: 0.723136
2023-10-30 15:51:08,460 Epoch: [287/484] Iter:[190/495], Time: 0.38, lr: [0.004445252825020069], Loss: 2.001680, Acc:0.799181, Semantic loss: 0.747783, BCE loss: 0.531141, SB loss: 0.722757
2023-10-30 15:51:12,145 Epoch: [287/484] Iter:[200/495], Time: 0.38, lr: [0.004444841754062274], Loss: 2.002311, Acc:0.800153, Semantic loss: 0.747140, BCE loss: 0.532438, SB loss: 0.722732
2023-10-30 15:51:15,965 Epoch: [287/484] Iter:[210/495], Time: 0.38, lr: [0.0044444306788803305], Loss: 1.999561, Acc:0.799314, Semantic loss: 0.747694, BCE loss: 0.530949, SB loss: 0.720918
2023-10-30 15:51:19,726 Epoch: [287/484] Iter:[220/495], Time: 0.38, lr: [0.00444401959947376], Loss: 1.999465, Acc:0.801799, Semantic loss: 0.747952, BCE loss: 0.530673, SB loss: 0.720841
2023-10-30 15:51:23,435 Epoch: [287/484] Iter:[230/495], Time: 0.38, lr: [0.004443608515842086], Loss: 1.995657, Acc:0.800541, Semantic loss: 0.746191, BCE loss: 0.529449, SB loss: 0.720017
2023-10-30 15:51:27,110 Epoch: [287/484] Iter:[240/495], Time: 0.38, lr: [0.00444319742798483], Loss: 1.995145, Acc:0.800472, Semantic loss: 0.747216, BCE loss: 0.528344, SB loss: 0.719585
2023-10-30 15:51:30,793 Epoch: [287/484] Iter:[250/495], Time: 0.38, lr: [0.004442786335901512], Loss: 1.997698, Acc:0.800570, Semantic loss: 0.749525, BCE loss: 0.527803, SB loss: 0.720371
2023-10-30 15:51:34,576 Epoch: [287/484] Iter:[260/495], Time: 0.38, lr: [0.004442375239591659], Loss: 2.000134, Acc:0.799425, Semantic loss: 0.750438, BCE loss: 0.528698, SB loss: 0.720998
2023-10-30 15:51:38,258 Epoch: [287/484] Iter:[270/495], Time: 0.38, lr: [0.004441964139054789], Loss: 2.002024, Acc:0.800122, Semantic loss: 0.751914, BCE loss: 0.528643, SB loss: 0.721466
2023-10-30 15:51:41,927 Epoch: [287/484] Iter:[280/495], Time: 0.38, lr: [0.0044415530342904255], Loss: 2.004300, Acc:0.800331, Semantic loss: 0.753932, BCE loss: 0.528184, SB loss: 0.722184
2023-10-30 15:51:45,610 Epoch: [287/484] Iter:[290/495], Time: 0.38, lr: [0.004441141925298088], Loss: 2.003450, Acc:0.800293, Semantic loss: 0.752405, BCE loss: 0.527881, SB loss: 0.723164
2023-10-30 15:51:49,332 Epoch: [287/484] Iter:[300/495], Time: 0.38, lr: [0.0044407308120773025], Loss: 2.007155, Acc:0.800762, Semantic loss: 0.754384, BCE loss: 0.528617, SB loss: 0.724154
2023-10-30 15:51:53,017 Epoch: [287/484] Iter:[310/495], Time: 0.37, lr: [0.004440319694627586], Loss: 2.005147, Acc:0.800483, Semantic loss: 0.752604, BCE loss: 0.528785, SB loss: 0.723759
2023-10-30 15:51:56,692 Epoch: [287/484] Iter:[320/495], Time: 0.37, lr: [0.004439908572948463], Loss: 2.007502, Acc:0.798986, Semantic loss: 0.754675, BCE loss: 0.527397, SB loss: 0.725431
2023-10-30 15:52:00,469 Epoch: [287/484] Iter:[330/495], Time: 0.37, lr: [0.004439497447039454], Loss: 2.009101, Acc:0.799381, Semantic loss: 0.755799, BCE loss: 0.527233, SB loss: 0.726069
2023-10-30 15:52:04,133 Epoch: [287/484] Iter:[340/495], Time: 0.37, lr: [0.004439086316900079], Loss: 2.010575, Acc:0.798728, Semantic loss: 0.756702, BCE loss: 0.527757, SB loss: 0.726115
2023-10-30 15:52:07,846 Epoch: [287/484] Iter:[350/495], Time: 0.37, lr: [0.004438675182529861], Loss: 2.006229, Acc:0.799902, Semantic loss: 0.754633, BCE loss: 0.526781, SB loss: 0.724815
2023-10-30 15:52:11,642 Epoch: [287/484] Iter:[360/495], Time: 0.37, lr: [0.004438264043928319], Loss: 2.003337, Acc:0.800748, Semantic loss: 0.752973, BCE loss: 0.526407, SB loss: 0.723957
2023-10-30 15:52:15,255 Epoch: [287/484] Iter:[370/495], Time: 0.37, lr: [0.0044378529010949755], Loss: 2.006407, Acc:0.800875, Semantic loss: 0.754185, BCE loss: 0.527231, SB loss: 0.724991
2023-10-30 15:52:18,996 Epoch: [287/484] Iter:[380/495], Time: 0.37, lr: [0.004437441754029351], Loss: 2.003656, Acc:0.801301, Semantic loss: 0.752611, BCE loss: 0.526452, SB loss: 0.724593
2023-10-30 15:52:22,781 Epoch: [287/484] Iter:[390/495], Time: 0.37, lr: [0.0044370306027309665], Loss: 2.007301, Acc:0.801210, Semantic loss: 0.753987, BCE loss: 0.527972, SB loss: 0.725342
2023-10-30 15:52:26,560 Epoch: [287/484] Iter:[400/495], Time: 0.37, lr: [0.004436619447199342], Loss: 2.006215, Acc:0.801793, Semantic loss: 0.753641, BCE loss: 0.528164, SB loss: 0.724410
2023-10-30 15:52:30,243 Epoch: [287/484] Iter:[410/495], Time: 0.37, lr: [0.004436208287433997], Loss: 2.010362, Acc:0.802070, Semantic loss: 0.755406, BCE loss: 0.530201, SB loss: 0.724756
2023-10-30 15:52:33,946 Epoch: [287/484] Iter:[420/495], Time: 0.37, lr: [0.0044357971234344545], Loss: 2.009561, Acc:0.801590, Semantic loss: 0.753741, BCE loss: 0.530262, SB loss: 0.725559
2023-10-30 15:52:37,594 Epoch: [287/484] Iter:[430/495], Time: 0.37, lr: [0.004435385955200233], Loss: 2.013176, Acc:0.800944, Semantic loss: 0.756635, BCE loss: 0.530196, SB loss: 0.726345
2023-10-30 15:52:41,313 Epoch: [287/484] Iter:[440/495], Time: 0.37, lr: [0.004434974782730854], Loss: 2.012991, Acc:0.801310, Semantic loss: 0.756465, BCE loss: 0.531082, SB loss: 0.725444
2023-10-30 15:52:45,081 Epoch: [287/484] Iter:[450/495], Time: 0.37, lr: [0.004434563606025835], Loss: 2.011142, Acc:0.802262, Semantic loss: 0.754486, BCE loss: 0.531717, SB loss: 0.724939
2023-10-30 15:52:48,893 Epoch: [287/484] Iter:[460/495], Time: 0.37, lr: [0.004434152425084699], Loss: 2.009816, Acc:0.802544, Semantic loss: 0.753834, BCE loss: 0.531023, SB loss: 0.724959
2023-10-30 15:52:52,664 Epoch: [287/484] Iter:[470/495], Time: 0.37, lr: [0.004433741239906965], Loss: 2.011579, Acc:0.802034, Semantic loss: 0.754110, BCE loss: 0.531253, SB loss: 0.726215
2023-10-30 15:52:56,350 Epoch: [287/484] Iter:[480/495], Time: 0.37, lr: [0.0044333300504921505], Loss: 2.009041, Acc:0.801920, Semantic loss: 0.752942, BCE loss: 0.530451, SB loss: 0.725647
2023-10-30 15:52:59,823 Epoch: [287/484] Iter:[490/495], Time: 0.37, lr: [0.004432918856839778], Loss: 2.009321, Acc:0.801734, Semantic loss: 0.754050, BCE loss: 0.529480, SB loss: 0.725790
2023-10-30 15:53:01,219 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:53:01,454 Loss: 2.014, MeanIU:  0.7109, Best_mIoU:  0.7151
2023-10-30 15:53:01,454 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176]
2023-10-30 15:53:03,677 Epoch: [288/484] Iter:[0/495], Time: 2.19, lr: [0.004432713258424357], Loss: 2.201013, Acc:0.856742, Semantic loss: 0.721671, BCE loss: 0.761979, SB loss: 0.717364
2023-10-30 15:53:07,585 Epoch: [288/484] Iter:[10/495], Time: 0.55, lr: [0.004432302058414745], Loss: 1.964948, Acc:0.821692, Semantic loss: 0.713626, BCE loss: 0.545432, SB loss: 0.705890
2023-10-30 15:53:11,220 Epoch: [288/484] Iter:[20/495], Time: 0.46, lr: [0.004431890854166373], Loss: 1.979562, Acc:0.820690, Semantic loss: 0.732153, BCE loss: 0.530429, SB loss: 0.716980
2023-10-30 15:53:14,942 Epoch: [288/484] Iter:[30/495], Time: 0.43, lr: [0.00443147964567876], Loss: 1.978887, Acc:0.817296, Semantic loss: 0.735115, BCE loss: 0.523770, SB loss: 0.720003
2023-10-30 15:53:18,616 Epoch: [288/484] Iter:[40/495], Time: 0.42, lr: [0.004431068432951425], Loss: 1.972574, Acc:0.822909, Semantic loss: 0.732433, BCE loss: 0.521719, SB loss: 0.718422
2023-10-30 15:53:22,223 Epoch: [288/484] Iter:[50/495], Time: 0.41, lr: [0.004430657215983888], Loss: 2.007185, Acc:0.818621, Semantic loss: 0.751753, BCE loss: 0.532495, SB loss: 0.722937
2023-10-30 15:53:25,980 Epoch: [288/484] Iter:[60/495], Time: 0.40, lr: [0.004430245994775668], Loss: 2.002890, Acc:0.814356, Semantic loss: 0.754771, BCE loss: 0.527212, SB loss: 0.720906
2023-10-30 15:53:29,574 Epoch: [288/484] Iter:[70/495], Time: 0.40, lr: [0.004429834769326281], Loss: 1.996468, Acc:0.810433, Semantic loss: 0.750546, BCE loss: 0.527119, SB loss: 0.718803
2023-10-30 15:53:33,246 Epoch: [288/484] Iter:[80/495], Time: 0.39, lr: [0.004429423539635251], Loss: 1.988060, Acc:0.808153, Semantic loss: 0.747769, BCE loss: 0.522150, SB loss: 0.718141
2023-10-30 15:53:36,948 Epoch: [288/484] Iter:[90/495], Time: 0.39, lr: [0.004429012305702092], Loss: 1.979169, Acc:0.812183, Semantic loss: 0.740829, BCE loss: 0.522961, SB loss: 0.715379
2023-10-30 15:53:40,635 Epoch: [288/484] Iter:[100/495], Time: 0.39, lr: [0.004428601067526325], Loss: 1.993394, Acc:0.811070, Semantic loss: 0.749494, BCE loss: 0.526474, SB loss: 0.717426
2023-10-30 15:53:44,316 Epoch: [288/484] Iter:[110/495], Time: 0.39, lr: [0.004428189825107467], Loss: 1.985680, Acc:0.810288, Semantic loss: 0.742830, BCE loss: 0.525079, SB loss: 0.717771
2023-10-30 15:53:47,994 Epoch: [288/484] Iter:[120/495], Time: 0.38, lr: [0.004427778578445038], Loss: 1.989639, Acc:0.810003, Semantic loss: 0.743434, BCE loss: 0.528457, SB loss: 0.717749
2023-10-30 15:53:51,642 Epoch: [288/484] Iter:[130/495], Time: 0.38, lr: [0.004427367327538555], Loss: 1.982641, Acc:0.809303, Semantic loss: 0.741843, BCE loss: 0.525077, SB loss: 0.715722
2023-10-30 15:53:55,397 Epoch: [288/484] Iter:[140/495], Time: 0.38, lr: [0.004426956072387537], Loss: 1.989885, Acc:0.808863, Semantic loss: 0.749531, BCE loss: 0.523484, SB loss: 0.716871
2023-10-30 15:53:59,078 Epoch: [288/484] Iter:[150/495], Time: 0.38, lr: [0.0044265448129915015], Loss: 1.996294, Acc:0.811089, Semantic loss: 0.749630, BCE loss: 0.530691, SB loss: 0.715973
2023-10-30 15:54:02,837 Epoch: [288/484] Iter:[160/495], Time: 0.38, lr: [0.004426133549349966], Loss: 1.992665, Acc:0.809641, Semantic loss: 0.747166, BCE loss: 0.528816, SB loss: 0.716683
2023-10-30 15:54:06,545 Epoch: [288/484] Iter:[170/495], Time: 0.38, lr: [0.0044257222814624506], Loss: 1.991783, Acc:0.810757, Semantic loss: 0.751299, BCE loss: 0.526786, SB loss: 0.713697
2023-10-30 15:54:10,117 Epoch: [288/484] Iter:[180/495], Time: 0.38, lr: [0.0044253110093284715], Loss: 1.996280, Acc:0.812152, Semantic loss: 0.753868, BCE loss: 0.526225, SB loss: 0.716187
2023-10-30 15:54:13,771 Epoch: [288/484] Iter:[190/495], Time: 0.38, lr: [0.004424899732947544], Loss: 1.993066, Acc:0.811520, Semantic loss: 0.752044, BCE loss: 0.525110, SB loss: 0.715912
2023-10-30 15:54:17,564 Epoch: [288/484] Iter:[200/495], Time: 0.38, lr: [0.004424488452319191], Loss: 1.992673, Acc:0.810783, Semantic loss: 0.750102, BCE loss: 0.526411, SB loss: 0.716160
2023-10-30 15:54:21,276 Epoch: [288/484] Iter:[210/495], Time: 0.38, lr: [0.004424077167442925], Loss: 1.990462, Acc:0.809894, Semantic loss: 0.748758, BCE loss: 0.524776, SB loss: 0.716928
2023-10-30 15:54:24,916 Epoch: [288/484] Iter:[220/495], Time: 0.38, lr: [0.004423665878318266], Loss: 1.993893, Acc:0.809719, Semantic loss: 0.749157, BCE loss: 0.527505, SB loss: 0.717231
2023-10-30 15:54:28,562 Epoch: [288/484] Iter:[230/495], Time: 0.38, lr: [0.0044232545849447295], Loss: 1.992190, Acc:0.807524, Semantic loss: 0.749673, BCE loss: 0.524314, SB loss: 0.718203
2023-10-30 15:54:32,307 Epoch: [288/484] Iter:[240/495], Time: 0.38, lr: [0.004422843287321834], Loss: 1.990896, Acc:0.808013, Semantic loss: 0.748152, BCE loss: 0.525486, SB loss: 0.717258
2023-10-30 15:54:35,951 Epoch: [288/484] Iter:[250/495], Time: 0.38, lr: [0.0044224319854490966], Loss: 1.991628, Acc:0.807045, Semantic loss: 0.748577, BCE loss: 0.525690, SB loss: 0.717361
2023-10-30 15:54:39,735 Epoch: [288/484] Iter:[260/495], Time: 0.38, lr: [0.004422020679326033], Loss: 1.992481, Acc:0.806616, Semantic loss: 0.749676, BCE loss: 0.523881, SB loss: 0.718923
2023-10-30 15:54:43,316 Epoch: [288/484] Iter:[270/495], Time: 0.38, lr: [0.0044216093689521604], Loss: 1.993724, Acc:0.806573, Semantic loss: 0.750950, BCE loss: 0.523556, SB loss: 0.719217
2023-10-30 15:54:46,955 Epoch: [288/484] Iter:[280/495], Time: 0.38, lr: [0.004421198054326997], Loss: 1.991262, Acc:0.806287, Semantic loss: 0.750628, BCE loss: 0.520822, SB loss: 0.719812
2023-10-30 15:54:50,678 Epoch: [288/484] Iter:[290/495], Time: 0.38, lr: [0.004420786735450058], Loss: 1.993601, Acc:0.804986, Semantic loss: 0.752218, BCE loss: 0.520644, SB loss: 0.720739
2023-10-30 15:54:54,393 Epoch: [288/484] Iter:[300/495], Time: 0.38, lr: [0.0044203754123208604], Loss: 1.998254, Acc:0.803381, Semantic loss: 0.754333, BCE loss: 0.522915, SB loss: 0.721006
2023-10-30 15:54:58,095 Epoch: [288/484] Iter:[310/495], Time: 0.37, lr: [0.004419964084938918], Loss: 1.997668, Acc:0.804390, Semantic loss: 0.753103, BCE loss: 0.524167, SB loss: 0.720398
2023-10-30 15:55:01,812 Epoch: [288/484] Iter:[320/495], Time: 0.37, lr: [0.004419552753303752], Loss: 1.996809, Acc:0.804919, Semantic loss: 0.751627, BCE loss: 0.524887, SB loss: 0.720294
2023-10-30 15:55:05,547 Epoch: [288/484] Iter:[330/495], Time: 0.37, lr: [0.004419141417414875], Loss: 1.994362, Acc:0.805324, Semantic loss: 0.750745, BCE loss: 0.523767, SB loss: 0.719850
2023-10-30 15:55:09,221 Epoch: [288/484] Iter:[340/495], Time: 0.37, lr: [0.0044187300772718045], Loss: 1.993876, Acc:0.805038, Semantic loss: 0.750498, BCE loss: 0.523500, SB loss: 0.719878
2023-10-30 15:55:12,944 Epoch: [288/484] Iter:[350/495], Time: 0.37, lr: [0.004418318732874054], Loss: 1.994808, Acc:0.805930, Semantic loss: 0.750724, BCE loss: 0.523980, SB loss: 0.720104
2023-10-30 15:55:16,622 Epoch: [288/484] Iter:[360/495], Time: 0.37, lr: [0.004417907384221143], Loss: 1.991624, Acc:0.804505, Semantic loss: 0.748899, BCE loss: 0.523463, SB loss: 0.719263
2023-10-30 15:55:20,312 Epoch: [288/484] Iter:[370/495], Time: 0.37, lr: [0.004417496031312585], Loss: 1.992843, Acc:0.805081, Semantic loss: 0.748344, BCE loss: 0.524522, SB loss: 0.719978
2023-10-30 15:55:24,032 Epoch: [288/484] Iter:[380/495], Time: 0.37, lr: [0.004417084674147898], Loss: 1.993109, Acc:0.805696, Semantic loss: 0.749224, BCE loss: 0.524360, SB loss: 0.719525
2023-10-30 15:55:27,743 Epoch: [288/484] Iter:[390/495], Time: 0.37, lr: [0.004416673312726593], Loss: 1.994768, Acc:0.806033, Semantic loss: 0.749686, BCE loss: 0.524714, SB loss: 0.720368
2023-10-30 15:55:31,388 Epoch: [288/484] Iter:[400/495], Time: 0.37, lr: [0.00441626194704819], Loss: 1.995142, Acc:0.805345, Semantic loss: 0.749025, BCE loss: 0.526240, SB loss: 0.719876
2023-10-30 15:55:35,124 Epoch: [288/484] Iter:[410/495], Time: 0.37, lr: [0.0044158505771122025], Loss: 1.999134, Acc:0.804495, Semantic loss: 0.750926, BCE loss: 0.526117, SB loss: 0.722091
2023-10-30 15:55:38,946 Epoch: [288/484] Iter:[420/495], Time: 0.37, lr: [0.004415439202918144], Loss: 2.000101, Acc:0.803954, Semantic loss: 0.750706, BCE loss: 0.527222, SB loss: 0.722174
2023-10-30 15:55:42,624 Epoch: [288/484] Iter:[430/495], Time: 0.37, lr: [0.004415027824465534], Loss: 1.997983, Acc:0.803418, Semantic loss: 0.750364, BCE loss: 0.526005, SB loss: 0.721614
2023-10-30 15:55:46,318 Epoch: [288/484] Iter:[440/495], Time: 0.37, lr: [0.004414616441753884], Loss: 1.996203, Acc:0.804372, Semantic loss: 0.748464, BCE loss: 0.526847, SB loss: 0.720893
2023-10-30 15:55:50,105 Epoch: [288/484] Iter:[450/495], Time: 0.37, lr: [0.00441420505478271], Loss: 1.997463, Acc:0.804796, Semantic loss: 0.749328, BCE loss: 0.526713, SB loss: 0.721422
2023-10-30 15:55:53,808 Epoch: [288/484] Iter:[460/495], Time: 0.37, lr: [0.004413793663551525], Loss: 1.995043, Acc:0.804314, Semantic loss: 0.748172, BCE loss: 0.525720, SB loss: 0.721151
2023-10-30 15:55:57,469 Epoch: [288/484] Iter:[470/495], Time: 0.37, lr: [0.004413382268059847], Loss: 1.995357, Acc:0.804337, Semantic loss: 0.748709, BCE loss: 0.525757, SB loss: 0.720890
2023-10-30 15:56:01,309 Epoch: [288/484] Iter:[480/495], Time: 0.37, lr: [0.00441297086830719], Loss: 1.996646, Acc:0.805209, Semantic loss: 0.749340, BCE loss: 0.525889, SB loss: 0.721416
2023-10-30 15:56:04,822 Epoch: [288/484] Iter:[490/495], Time: 0.37, lr: [0.004412559464293066], Loss: 1.996423, Acc:0.805841, Semantic loss: 0.748395, BCE loss: 0.526973, SB loss: 0.721056
2023-10-30 15:56:06,238 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:56:06,476 Loss: 2.014, MeanIU:  0.7109, Best_mIoU:  0.7151
2023-10-30 15:56:06,476 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176]
2023-10-30 15:56:08,560 Epoch: [289/484] Iter:[0/495], Time: 2.05, lr: [0.004412353760687803], Loss: 2.081323, Acc:0.791072, Semantic loss: 0.742076, BCE loss: 0.522421, SB loss: 0.816826
2023-10-30 15:56:12,474 Epoch: [289/484] Iter:[10/495], Time: 0.54, lr: [0.004411942350280569], Loss: 1.900293, Acc:0.813141, Semantic loss: 0.719525, BCE loss: 0.496466, SB loss: 0.684303
2023-10-30 15:56:16,064 Epoch: [289/484] Iter:[20/495], Time: 0.45, lr: [0.004411530935610657], Loss: 1.912355, Acc:0.801611, Semantic loss: 0.713661, BCE loss: 0.502438, SB loss: 0.696256
2023-10-30 15:56:19,790 Epoch: [289/484] Iter:[30/495], Time: 0.43, lr: [0.004411119516677579], Loss: 1.918214, Acc:0.813773, Semantic loss: 0.711349, BCE loss: 0.506882, SB loss: 0.699983
2023-10-30 15:56:23,553 Epoch: [289/484] Iter:[40/495], Time: 0.42, lr: [0.004410708093480849], Loss: 1.964379, Acc:0.806525, Semantic loss: 0.726319, BCE loss: 0.526674, SB loss: 0.711386
2023-10-30 15:56:27,287 Epoch: [289/484] Iter:[50/495], Time: 0.41, lr: [0.004410296666019981], Loss: 1.954101, Acc:0.806531, Semantic loss: 0.719149, BCE loss: 0.529656, SB loss: 0.705296
2023-10-30 15:56:31,019 Epoch: [289/484] Iter:[60/495], Time: 0.40, lr: [0.00440988523429449], Loss: 1.957907, Acc:0.802114, Semantic loss: 0.723059, BCE loss: 0.529274, SB loss: 0.705574
2023-10-30 15:56:34,706 Epoch: [289/484] Iter:[70/495], Time: 0.40, lr: [0.004409473798303888], Loss: 1.959100, Acc:0.802977, Semantic loss: 0.726581, BCE loss: 0.526292, SB loss: 0.706227
2023-10-30 15:56:38,414 Epoch: [289/484] Iter:[80/495], Time: 0.39, lr: [0.0044090623580476905], Loss: 1.960304, Acc:0.801987, Semantic loss: 0.732068, BCE loss: 0.522209, SB loss: 0.706027
2023-10-30 15:56:42,134 Epoch: [289/484] Iter:[90/495], Time: 0.39, lr: [0.004408650913525407], Loss: 1.969047, Acc:0.802624, Semantic loss: 0.734413, BCE loss: 0.524920, SB loss: 0.709714
2023-10-30 15:56:45,967 Epoch: [289/484] Iter:[100/495], Time: 0.39, lr: [0.004408239464736556], Loss: 1.981012, Acc:0.802712, Semantic loss: 0.740163, BCE loss: 0.530310, SB loss: 0.710539
2023-10-30 15:56:49,619 Epoch: [289/484] Iter:[110/495], Time: 0.39, lr: [0.004407828011680649], Loss: 1.984173, Acc:0.801767, Semantic loss: 0.740243, BCE loss: 0.531286, SB loss: 0.712644
2023-10-30 15:56:53,264 Epoch: [289/484] Iter:[120/495], Time: 0.39, lr: [0.004407416554357198], Loss: 1.996983, Acc:0.801522, Semantic loss: 0.749990, BCE loss: 0.529614, SB loss: 0.717378
2023-10-30 15:56:57,039 Epoch: [289/484] Iter:[130/495], Time: 0.39, lr: [0.0044070050927657155], Loss: 1.995223, Acc:0.800435, Semantic loss: 0.748291, BCE loss: 0.525472, SB loss: 0.721460
2023-10-30 15:57:00,793 Epoch: [289/484] Iter:[140/495], Time: 0.38, lr: [0.004406593626905717], Loss: 2.003445, Acc:0.802183, Semantic loss: 0.752368, BCE loss: 0.527364, SB loss: 0.723713
2023-10-30 15:57:04,571 Epoch: [289/484] Iter:[150/495], Time: 0.38, lr: [0.004406182156776715], Loss: 2.008656, Acc:0.802105, Semantic loss: 0.754660, BCE loss: 0.528890, SB loss: 0.725106
2023-10-30 15:57:08,266 Epoch: [289/484] Iter:[160/495], Time: 0.38, lr: [0.00440577068237822], Loss: 2.001292, Acc:0.803169, Semantic loss: 0.749697, BCE loss: 0.528786, SB loss: 0.722809
2023-10-30 15:57:12,186 Epoch: [289/484] Iter:[170/495], Time: 0.38, lr: [0.0044053592037097454], Loss: 1.997483, Acc:0.802424, Semantic loss: 0.748970, BCE loss: 0.526040, SB loss: 0.722473
2023-10-30 15:57:15,809 Epoch: [289/484] Iter:[180/495], Time: 0.38, lr: [0.004404947720770804], Loss: 1.994827, Acc:0.804852, Semantic loss: 0.747906, BCE loss: 0.524024, SB loss: 0.722898
2023-10-30 15:57:19,502 Epoch: [289/484] Iter:[190/495], Time: 0.38, lr: [0.00440453623356091], Loss: 1.991230, Acc:0.806390, Semantic loss: 0.746298, BCE loss: 0.523315, SB loss: 0.721617
2023-10-30 15:57:23,170 Epoch: [289/484] Iter:[200/495], Time: 0.38, lr: [0.004404124742079574], Loss: 1.987988, Acc:0.804161, Semantic loss: 0.743632, BCE loss: 0.523006, SB loss: 0.721350
2023-10-30 15:57:26,862 Epoch: [289/484] Iter:[210/495], Time: 0.38, lr: [0.004403713246326307], Loss: 1.988269, Acc:0.803589, Semantic loss: 0.744561, BCE loss: 0.522119, SB loss: 0.721590
2023-10-30 15:57:30,724 Epoch: [289/484] Iter:[220/495], Time: 0.38, lr: [0.004403301746300624], Loss: 1.983206, Acc:0.805586, Semantic loss: 0.742401, BCE loss: 0.520144, SB loss: 0.720661
2023-10-30 15:57:34,341 Epoch: [289/484] Iter:[230/495], Time: 0.38, lr: [0.004402890242002035], Loss: 1.984964, Acc:0.805145, Semantic loss: 0.743746, BCE loss: 0.520923, SB loss: 0.720296
2023-10-30 15:57:38,098 Epoch: [289/484] Iter:[240/495], Time: 0.38, lr: [0.0044024787334300515], Loss: 1.985662, Acc:0.806084, Semantic loss: 0.745236, BCE loss: 0.520169, SB loss: 0.720257
2023-10-30 15:57:41,794 Epoch: [289/484] Iter:[250/495], Time: 0.38, lr: [0.004402067220584187], Loss: 1.985290, Acc:0.807050, Semantic loss: 0.745585, BCE loss: 0.519260, SB loss: 0.720446
2023-10-30 15:57:45,430 Epoch: [289/484] Iter:[260/495], Time: 0.38, lr: [0.004401655703463953], Loss: 1.987612, Acc:0.806245, Semantic loss: 0.746683, BCE loss: 0.520121, SB loss: 0.720809
2023-10-30 15:57:49,032 Epoch: [289/484] Iter:[270/495], Time: 0.38, lr: [0.0044012441820688595], Loss: 1.985262, Acc:0.806101, Semantic loss: 0.745928, BCE loss: 0.518641, SB loss: 0.720693
2023-10-30 15:57:52,713 Epoch: [289/484] Iter:[280/495], Time: 0.38, lr: [0.0044008326563984195], Loss: 1.982745, Acc:0.805946, Semantic loss: 0.744054, BCE loss: 0.517751, SB loss: 0.720940
2023-10-30 15:57:56,364 Epoch: [289/484] Iter:[290/495], Time: 0.38, lr: [0.004400421126452143], Loss: 1.985877, Acc:0.805334, Semantic loss: 0.746144, BCE loss: 0.517599, SB loss: 0.722134
2023-10-30 15:58:00,186 Epoch: [289/484] Iter:[300/495], Time: 0.38, lr: [0.004400009592229543], Loss: 1.985039, Acc:0.805049, Semantic loss: 0.744556, BCE loss: 0.518381, SB loss: 0.722101
2023-10-30 15:58:03,940 Epoch: [289/484] Iter:[310/495], Time: 0.38, lr: [0.004399598053730129], Loss: 1.984895, Acc:0.805264, Semantic loss: 0.744450, BCE loss: 0.518500, SB loss: 0.721946
2023-10-30 15:58:07,604 Epoch: [289/484] Iter:[320/495], Time: 0.38, lr: [0.004399186510953413], Loss: 1.986359, Acc:0.804194, Semantic loss: 0.743913, BCE loss: 0.520645, SB loss: 0.721801
2023-10-30 15:58:11,275 Epoch: [289/484] Iter:[330/495], Time: 0.38, lr: [0.004398774963898905], Loss: 1.988218, Acc:0.803201, Semantic loss: 0.745530, BCE loss: 0.520141, SB loss: 0.722548
2023-10-30 15:58:14,876 Epoch: [289/484] Iter:[340/495], Time: 0.38, lr: [0.004398363412566118], Loss: 1.992286, Acc:0.803755, Semantic loss: 0.746723, BCE loss: 0.522765, SB loss: 0.722798
2023-10-30 15:58:18,566 Epoch: [289/484] Iter:[350/495], Time: 0.38, lr: [0.004397951856954561], Loss: 1.992003, Acc:0.803548, Semantic loss: 0.745597, BCE loss: 0.524124, SB loss: 0.722282
2023-10-30 15:58:22,360 Epoch: [289/484] Iter:[360/495], Time: 0.38, lr: [0.004397540297063743], Loss: 1.992221, Acc:0.803659, Semantic loss: 0.744797, BCE loss: 0.525379, SB loss: 0.722045
2023-10-30 15:58:26,213 Epoch: [289/484] Iter:[370/495], Time: 0.38, lr: [0.004397128732893178], Loss: 1.991175, Acc:0.804422, Semantic loss: 0.743153, BCE loss: 0.526433, SB loss: 0.721590
2023-10-30 15:58:29,885 Epoch: [289/484] Iter:[380/495], Time: 0.38, lr: [0.004396717164442374], Loss: 1.990137, Acc:0.805151, Semantic loss: 0.742758, BCE loss: 0.526051, SB loss: 0.721328
2023-10-30 15:58:33,621 Epoch: [289/484] Iter:[390/495], Time: 0.38, lr: [0.004396305591710842], Loss: 1.992793, Acc:0.804565, Semantic loss: 0.744840, BCE loss: 0.526206, SB loss: 0.721746
2023-10-30 15:58:37,354 Epoch: [289/484] Iter:[400/495], Time: 0.38, lr: [0.004395894014698093], Loss: 1.996480, Acc:0.804409, Semantic loss: 0.746037, BCE loss: 0.527819, SB loss: 0.722624
2023-10-30 15:58:41,139 Epoch: [289/484] Iter:[410/495], Time: 0.38, lr: [0.004395482433403635], Loss: 1.997380, Acc:0.803793, Semantic loss: 0.746357, BCE loss: 0.527738, SB loss: 0.723286
2023-10-30 15:58:44,971 Epoch: [289/484] Iter:[420/495], Time: 0.38, lr: [0.0043950708478269805], Loss: 2.000936, Acc:0.804587, Semantic loss: 0.748154, BCE loss: 0.529345, SB loss: 0.723436
2023-10-30 15:58:48,792 Epoch: [289/484] Iter:[430/495], Time: 0.38, lr: [0.004394659257967637], Loss: 1.998309, Acc:0.804916, Semantic loss: 0.747054, BCE loss: 0.528425, SB loss: 0.722830
2023-10-30 15:58:52,607 Epoch: [289/484] Iter:[440/495], Time: 0.38, lr: [0.004394247663825116], Loss: 1.996660, Acc:0.804810, Semantic loss: 0.746339, BCE loss: 0.527313, SB loss: 0.723008
2023-10-30 15:58:56,315 Epoch: [289/484] Iter:[450/495], Time: 0.38, lr: [0.004393836065398927], Loss: 1.998841, Acc:0.805330, Semantic loss: 0.747400, BCE loss: 0.528235, SB loss: 0.723206
2023-10-30 15:58:59,995 Epoch: [289/484] Iter:[460/495], Time: 0.38, lr: [0.004393424462688578], Loss: 2.002187, Acc:0.805479, Semantic loss: 0.748495, BCE loss: 0.529317, SB loss: 0.724375
2023-10-30 15:59:03,700 Epoch: [289/484] Iter:[470/495], Time: 0.38, lr: [0.00439301285569358], Loss: 2.004392, Acc:0.805064, Semantic loss: 0.750051, BCE loss: 0.529435, SB loss: 0.724907
2023-10-30 15:59:07,456 Epoch: [289/484] Iter:[480/495], Time: 0.38, lr: [0.004392601244413442], Loss: 2.001638, Acc:0.805496, Semantic loss: 0.747672, BCE loss: 0.529978, SB loss: 0.723988
2023-10-30 15:59:10,980 Epoch: [289/484] Iter:[490/495], Time: 0.38, lr: [0.004392189628847673], Loss: 2.001277, Acc:0.806115, Semantic loss: 0.747485, BCE loss: 0.529924, SB loss: 0.723868
2023-10-30 15:59:12,377 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 15:59:12,614 Loss: 2.014, MeanIU:  0.7109, Best_mIoU:  0.7151
2023-10-30 15:59:12,614 [0.97601493 0.81931717 0.90997897 0.41968878 0.49522145 0.59180388
 0.68041558 0.71877384 0.9127465  0.59058889 0.92873838 0.78487992
 0.57184456 0.92935451 0.54505599 0.76199864 0.70207553 0.44520846
 0.72322176]
2023-10-30 15:59:14,926 Epoch: [290/484] Iter:[0/495], Time: 2.28, lr: [0.004391983819457524], Loss: 2.227093, Acc:0.800326, Semantic loss: 0.793381, BCE loss: 0.766574, SB loss: 0.667138
2023-10-30 15:59:18,934 Epoch: [290/484] Iter:[10/495], Time: 0.57, lr: [0.004391572197462388], Loss: 1.968557, Acc:0.813014, Semantic loss: 0.752356, BCE loss: 0.492513, SB loss: 0.723689
2023-10-30 15:59:22,510 Epoch: [290/484] Iter:[20/495], Time: 0.47, lr: [0.0043911605711803945], Loss: 2.004018, Acc:0.813480, Semantic loss: 0.741414, BCE loss: 0.546454, SB loss: 0.716151
2023-10-30 15:59:26,130 Epoch: [290/484] Iter:[30/495], Time: 0.43, lr: [0.00439074894061105], Loss: 1.967547, Acc:0.808752, Semantic loss: 0.723595, BCE loss: 0.535372, SB loss: 0.708580
2023-10-30 15:59:29,717 Epoch: [290/484] Iter:[40/495], Time: 0.42, lr: [0.004390337305753865], Loss: 1.954832, Acc:0.804768, Semantic loss: 0.727355, BCE loss: 0.521570, SB loss: 0.705907
2023-10-30 15:59:33,382 Epoch: [290/484] Iter:[50/495], Time: 0.41, lr: [0.004389925666608349], Loss: 1.969076, Acc:0.809172, Semantic loss: 0.734740, BCE loss: 0.529538, SB loss: 0.704799
2023-10-30 15:59:37,054 Epoch: [290/484] Iter:[60/495], Time: 0.40, lr: [0.0043895140231740085], Loss: 1.968186, Acc:0.802657, Semantic loss: 0.736166, BCE loss: 0.520120, SB loss: 0.711900
2023-10-30 15:59:40,842 Epoch: [290/484] Iter:[70/495], Time: 0.40, lr: [0.004389102375450352], Loss: 1.960340, Acc:0.802509, Semantic loss: 0.733157, BCE loss: 0.515444, SB loss: 0.711739
2023-10-30 15:59:44,381 Epoch: [290/484] Iter:[80/495], Time: 0.39, lr: [0.00438869072343689], Loss: 1.970678, Acc:0.803282, Semantic loss: 0.738773, BCE loss: 0.517599, SB loss: 0.714306
2023-10-30 15:59:48,023 Epoch: [290/484] Iter:[90/495], Time: 0.39, lr: [0.00438827906713313], Loss: 1.958044, Acc:0.797483, Semantic loss: 0.733057, BCE loss: 0.513432, SB loss: 0.711555
2023-10-30 15:59:51,731 Epoch: [290/484] Iter:[100/495], Time: 0.39, lr: [0.004387867406538577], Loss: 1.975710, Acc:0.798985, Semantic loss: 0.740581, BCE loss: 0.516490, SB loss: 0.718639
2023-10-30 15:59:55,441 Epoch: [290/484] Iter:[110/495], Time: 0.39, lr: [0.004387455741652743], Loss: 1.969321, Acc:0.799211, Semantic loss: 0.741473, BCE loss: 0.510881, SB loss: 0.716967
2023-10-30 15:59:59,125 Epoch: [290/484] Iter:[120/495], Time: 0.38, lr: [0.004387044072475134], Loss: 1.958957, Acc:0.803130, Semantic loss: 0.735212, BCE loss: 0.509447, SB loss: 0.714298
2023-10-30 16:00:02,887 Epoch: [290/484] Iter:[130/495], Time: 0.38, lr: [0.004386632399005258], Loss: 1.958939, Acc:0.802647, Semantic loss: 0.734851, BCE loss: 0.509496, SB loss: 0.714592
2023-10-30 16:00:06,615 Epoch: [290/484] Iter:[140/495], Time: 0.38, lr: [0.004386220721242623], Loss: 1.968405, Acc:0.804819, Semantic loss: 0.739510, BCE loss: 0.511344, SB loss: 0.717551
2023-10-30 16:00:10,324 Epoch: [290/484] Iter:[150/495], Time: 0.38, lr: [0.0043858090391867355], Loss: 1.973642, Acc:0.802875, Semantic loss: 0.742481, BCE loss: 0.512365, SB loss: 0.718796
2023-10-30 16:00:14,054 Epoch: [290/484] Iter:[160/495], Time: 0.38, lr: [0.004385397352837104], Loss: 1.976247, Acc:0.801136, Semantic loss: 0.743727, BCE loss: 0.511475, SB loss: 0.721045
2023-10-30 16:00:17,753 Epoch: [290/484] Iter:[170/495], Time: 0.38, lr: [0.004384985662193237], Loss: 1.971271, Acc:0.802883, Semantic loss: 0.740054, BCE loss: 0.512645, SB loss: 0.718573
2023-10-30 16:00:21,550 Epoch: [290/484] Iter:[180/495], Time: 0.38, lr: [0.004384573967254638], Loss: 1.973511, Acc:0.803315, Semantic loss: 0.740044, BCE loss: 0.514215, SB loss: 0.719252
2023-10-30 16:00:25,257 Epoch: [290/484] Iter:[190/495], Time: 0.38, lr: [0.004384162268020817], Loss: 1.968088, Acc:0.803227, Semantic loss: 0.737744, BCE loss: 0.512853, SB loss: 0.717491
2023-10-30 16:00:29,000 Epoch: [290/484] Iter:[200/495], Time: 0.38, lr: [0.0043837505644912815], Loss: 1.964691, Acc:0.803867, Semantic loss: 0.737940, BCE loss: 0.510010, SB loss: 0.716741
2023-10-30 16:00:32,666 Epoch: [290/484] Iter:[210/495], Time: 0.38, lr: [0.004383338856665537], Loss: 1.973003, Acc:0.803364, Semantic loss: 0.742660, BCE loss: 0.513792, SB loss: 0.716552
2023-10-30 16:00:36,376 Epoch: [290/484] Iter:[220/495], Time: 0.38, lr: [0.004382927144543089], Loss: 1.970806, Acc:0.804383, Semantic loss: 0.742139, BCE loss: 0.512907, SB loss: 0.715760
2023-10-30 16:00:40,148 Epoch: [290/484] Iter:[230/495], Time: 0.38, lr: [0.004382515428123447], Loss: 1.970523, Acc:0.803860, Semantic loss: 0.741230, BCE loss: 0.512387, SB loss: 0.716906
2023-10-30 16:00:43,912 Epoch: [290/484] Iter:[240/495], Time: 0.38, lr: [0.004382103707406116], Loss: 1.974962, Acc:0.804571, Semantic loss: 0.741920, BCE loss: 0.516018, SB loss: 0.717024
2023-10-30 16:00:47,661 Epoch: [290/484] Iter:[250/495], Time: 0.38, lr: [0.004381691982390605], Loss: 1.974769, Acc:0.804397, Semantic loss: 0.741216, BCE loss: 0.516507, SB loss: 0.717047
2023-10-30 16:00:51,400 Epoch: [290/484] Iter:[260/495], Time: 0.38, lr: [0.004381280253076415], Loss: 1.974510, Acc:0.804946, Semantic loss: 0.739360, BCE loss: 0.517822, SB loss: 0.717328
2023-10-30 16:00:55,334 Epoch: [290/484] Iter:[270/495], Time: 0.38, lr: [0.004380868519463057], Loss: 1.974247, Acc:0.805443, Semantic loss: 0.739902, BCE loss: 0.517380, SB loss: 0.716965
2023-10-30 16:00:59,053 Epoch: [290/484] Iter:[280/495], Time: 0.38, lr: [0.004380456781550036], Loss: 1.979605, Acc:0.806114, Semantic loss: 0.741709, BCE loss: 0.520314, SB loss: 0.717582
2023-10-30 16:01:02,778 Epoch: [290/484] Iter:[290/495], Time: 0.38, lr: [0.0043800450393368575], Loss: 1.978057, Acc:0.805426, Semantic loss: 0.741071, BCE loss: 0.520145, SB loss: 0.716841
2023-10-30 16:01:06,466 Epoch: [290/484] Iter:[300/495], Time: 0.38, lr: [0.004379633292823026], Loss: 1.978750, Acc:0.805389, Semantic loss: 0.739811, BCE loss: 0.522667, SB loss: 0.716272
2023-10-30 16:01:10,332 Epoch: [290/484] Iter:[310/495], Time: 0.38, lr: [0.004379221542008051], Loss: 1.978491, Acc:0.804755, Semantic loss: 0.740191, BCE loss: 0.521250, SB loss: 0.717049
2023-10-30 16:01:13,984 Epoch: [290/484] Iter:[320/495], Time: 0.38, lr: [0.004378809786891436], Loss: 1.978711, Acc:0.803345, Semantic loss: 0.740970, BCE loss: 0.520761, SB loss: 0.716981
2023-10-30 16:01:17,744 Epoch: [290/484] Iter:[330/495], Time: 0.38, lr: [0.004378398027472687], Loss: 1.977464, Acc:0.804183, Semantic loss: 0.740146, BCE loss: 0.519961, SB loss: 0.717356
2023-10-30 16:01:21,492 Epoch: [290/484] Iter:[340/495], Time: 0.38, lr: [0.004377986263751307], Loss: 1.978191, Acc:0.803923, Semantic loss: 0.739821, BCE loss: 0.521193, SB loss: 0.717178
2023-10-30 16:01:25,131 Epoch: [290/484] Iter:[350/495], Time: 0.38, lr: [0.0043775744957268055], Loss: 1.980821, Acc:0.802835, Semantic loss: 0.741378, BCE loss: 0.521516, SB loss: 0.717927
2023-10-30 16:01:29,017 Epoch: [290/484] Iter:[360/495], Time: 0.38, lr: [0.004377162723398685], Loss: 1.979771, Acc:0.802991, Semantic loss: 0.740135, BCE loss: 0.522213, SB loss: 0.717422
2023-10-30 16:01:32,699 Epoch: [290/484] Iter:[370/495], Time: 0.38, lr: [0.004376750946766453], Loss: 1.983986, Acc:0.802327, Semantic loss: 0.742723, BCE loss: 0.523099, SB loss: 0.718164
2023-10-30 16:01:36,467 Epoch: [290/484] Iter:[380/495], Time: 0.38, lr: [0.004376339165829611], Loss: 1.984133, Acc:0.801928, Semantic loss: 0.742974, BCE loss: 0.523147, SB loss: 0.718013
2023-10-30 16:01:40,193 Epoch: [290/484] Iter:[390/495], Time: 0.38, lr: [0.004375927380587668], Loss: 1.982179, Acc:0.801618, Semantic loss: 0.741935, BCE loss: 0.521859, SB loss: 0.718385
2023-10-30 16:01:43,921 Epoch: [290/484] Iter:[400/495], Time: 0.38, lr: [0.0043755155910401265], Loss: 1.984266, Acc:0.802054, Semantic loss: 0.743458, BCE loss: 0.521102, SB loss: 0.719706
2023-10-30 16:01:47,730 Epoch: [290/484] Iter:[410/495], Time: 0.38, lr: [0.004375103797186492], Loss: 1.986548, Acc:0.801314, Semantic loss: 0.743264, BCE loss: 0.522397, SB loss: 0.720887
2023-10-30 16:01:51,440 Epoch: [290/484] Iter:[420/495], Time: 0.38, lr: [0.004374691999026268], Loss: 1.983194, Acc:0.801976, Semantic loss: 0.741576, BCE loss: 0.521826, SB loss: 0.719791
2023-10-30 16:01:55,195 Epoch: [290/484] Iter:[430/495], Time: 0.38, lr: [0.0043742801965589604], Loss: 1.982495, Acc:0.801712, Semantic loss: 0.741867, BCE loss: 0.521498, SB loss: 0.719130
2023-10-30 16:01:58,992 Epoch: [290/484] Iter:[440/495], Time: 0.38, lr: [0.0043738683897840734], Loss: 1.982061, Acc:0.801483, Semantic loss: 0.741555, BCE loss: 0.520927, SB loss: 0.719578
2023-10-30 16:02:02,669 Epoch: [290/484] Iter:[450/495], Time: 0.38, lr: [0.004373456578701111], Loss: 1.984738, Acc:0.801487, Semantic loss: 0.743232, BCE loss: 0.521578, SB loss: 0.719929
2023-10-30 16:02:06,458 Epoch: [290/484] Iter:[460/495], Time: 0.38, lr: [0.004373044763309576], Loss: 1.986203, Acc:0.800985, Semantic loss: 0.743994, BCE loss: 0.521842, SB loss: 0.720367
2023-10-30 16:02:10,211 Epoch: [290/484] Iter:[470/495], Time: 0.38, lr: [0.004372632943608974], Loss: 1.982096, Acc:0.800989, Semantic loss: 0.741882, BCE loss: 0.520493, SB loss: 0.719721
2023-10-30 16:02:14,157 Epoch: [290/484] Iter:[480/495], Time: 0.38, lr: [0.004372221119598811], Loss: 1.981265, Acc:0.800854, Semantic loss: 0.741197, BCE loss: 0.520688, SB loss: 0.719380
2023-10-30 16:02:17,693 Epoch: [290/484] Iter:[490/495], Time: 0.38, lr: [0.004371809291278587], Loss: 1.979630, Acc:0.801526, Semantic loss: 0.740727, BCE loss: 0.519784, SB loss: 0.719119
2023-10-30 16:05:15,199 0 [9.33793311e-01 6.11810676e-01 8.30801853e-01 1.58428043e-01
 2.51000470e-01 4.25287169e-01 4.79583390e-01 5.60476749e-01
 8.80748553e-01 4.57507506e-01 8.86933823e-01 5.95172746e-01
 1.88674968e-02 7.97279733e-01 3.94548361e-04 1.03125793e-01
 6.83756349e-02 4.88078076e-02 5.82839847e-01] 0.45743342892861844
2023-10-30 16:05:15,199 1 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085] 0.697089409803581
2023-10-30 16:05:15,203 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:05:15,439 Loss: 2.052, MeanIU:  0.6971, Best_mIoU:  0.7151
2023-10-30 16:05:15,440 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085]
2023-10-30 16:05:17,415 Epoch: [291/484] Iter:[0/495], Time: 1.94, lr: [0.004371603375502047], Loss: 1.790227, Acc:0.777594, Semantic loss: 0.631442, BCE loss: 0.521127, SB loss: 0.637657
2023-10-30 16:05:21,232 Epoch: [291/484] Iter:[10/495], Time: 0.52, lr: [0.0043711915407158046], Loss: 1.964052, Acc:0.799574, Semantic loss: 0.754577, BCE loss: 0.498696, SB loss: 0.710779
2023-10-30 16:05:24,715 Epoch: [291/484] Iter:[20/495], Time: 0.44, lr: [0.004370779701618261], Loss: 1.978064, Acc:0.804973, Semantic loss: 0.762316, BCE loss: 0.505581, SB loss: 0.710167
2023-10-30 16:05:28,232 Epoch: [291/484] Iter:[30/495], Time: 0.41, lr: [0.0043703678582089215], Loss: 1.950778, Acc:0.803987, Semantic loss: 0.739163, BCE loss: 0.507800, SB loss: 0.703815
2023-10-30 16:05:31,743 Epoch: [291/484] Iter:[40/495], Time: 0.40, lr: [0.004369956010487288], Loss: 1.968747, Acc:0.807942, Semantic loss: 0.753614, BCE loss: 0.501230, SB loss: 0.713902
2023-10-30 16:05:35,185 Epoch: [291/484] Iter:[50/495], Time: 0.39, lr: [0.004369544158452865], Loss: 1.972576, Acc:0.807485, Semantic loss: 0.749825, BCE loss: 0.502654, SB loss: 0.720096
2023-10-30 16:05:38,640 Epoch: [291/484] Iter:[60/495], Time: 0.38, lr: [0.0043691323021051555], Loss: 1.982598, Acc:0.809135, Semantic loss: 0.751964, BCE loss: 0.506181, SB loss: 0.724453
2023-10-30 16:05:42,131 Epoch: [291/484] Iter:[70/495], Time: 0.38, lr: [0.004368720441443662], Loss: 1.984180, Acc:0.809370, Semantic loss: 0.749694, BCE loss: 0.510136, SB loss: 0.724350
2023-10-30 16:05:45,677 Epoch: [291/484] Iter:[80/495], Time: 0.37, lr: [0.004368308576467887], Loss: 1.982503, Acc:0.809844, Semantic loss: 0.751319, BCE loss: 0.508789, SB loss: 0.722394
2023-10-30 16:05:49,255 Epoch: [291/484] Iter:[90/495], Time: 0.37, lr: [0.0043678967071773345], Loss: 1.979467, Acc:0.808722, Semantic loss: 0.750820, BCE loss: 0.506465, SB loss: 0.722182
2023-10-30 16:05:52,842 Epoch: [291/484] Iter:[100/495], Time: 0.37, lr: [0.0043674848335715066], Loss: 1.973639, Acc:0.806996, Semantic loss: 0.748608, BCE loss: 0.505275, SB loss: 0.719756
2023-10-30 16:05:56,485 Epoch: [291/484] Iter:[110/495], Time: 0.37, lr: [0.004367072955649907], Loss: 1.970170, Acc:0.806376, Semantic loss: 0.748092, BCE loss: 0.504941, SB loss: 0.717137
2023-10-30 16:06:00,164 Epoch: [291/484] Iter:[120/495], Time: 0.37, lr: [0.004366661073412035], Loss: 1.974208, Acc:0.803057, Semantic loss: 0.748832, BCE loss: 0.506803, SB loss: 0.718573
2023-10-30 16:06:03,739 Epoch: [291/484] Iter:[130/495], Time: 0.37, lr: [0.004366249186857398], Loss: 1.989451, Acc:0.802327, Semantic loss: 0.752903, BCE loss: 0.513443, SB loss: 0.723104
2023-10-30 16:06:07,293 Epoch: [291/484] Iter:[140/495], Time: 0.37, lr: [0.004365837295985494], Loss: 1.979555, Acc:0.802631, Semantic loss: 0.748470, BCE loss: 0.510719, SB loss: 0.720366
2023-10-30 16:06:10,894 Epoch: [291/484] Iter:[150/495], Time: 0.37, lr: [0.004365425400795826], Loss: 1.980364, Acc:0.801969, Semantic loss: 0.750018, BCE loss: 0.509973, SB loss: 0.720373
2023-10-30 16:06:14,562 Epoch: [291/484] Iter:[160/495], Time: 0.37, lr: [0.0043650135012878975], Loss: 1.981416, Acc:0.803573, Semantic loss: 0.749042, BCE loss: 0.511686, SB loss: 0.720688
2023-10-30 16:06:18,215 Epoch: [291/484] Iter:[170/495], Time: 0.37, lr: [0.00436460159746121], Loss: 1.983418, Acc:0.802021, Semantic loss: 0.752999, BCE loss: 0.510711, SB loss: 0.719708
2023-10-30 16:06:21,861 Epoch: [291/484] Iter:[180/495], Time: 0.37, lr: [0.004364189689315265], Loss: 1.989221, Acc:0.801588, Semantic loss: 0.753032, BCE loss: 0.515767, SB loss: 0.720422
2023-10-30 16:06:25,509 Epoch: [291/484] Iter:[190/495], Time: 0.37, lr: [0.004363777776849565], Loss: 1.986478, Acc:0.800510, Semantic loss: 0.751790, BCE loss: 0.514337, SB loss: 0.720351
2023-10-30 16:06:29,118 Epoch: [291/484] Iter:[200/495], Time: 0.37, lr: [0.004363365860063609], Loss: 1.983599, Acc:0.801080, Semantic loss: 0.748462, BCE loss: 0.516034, SB loss: 0.719103
2023-10-30 16:06:32,865 Epoch: [291/484] Iter:[210/495], Time: 0.37, lr: [0.004362953938956901], Loss: 1.984169, Acc:0.801955, Semantic loss: 0.749300, BCE loss: 0.515813, SB loss: 0.719056
2023-10-30 16:06:36,488 Epoch: [291/484] Iter:[220/495], Time: 0.37, lr: [0.004362542013528943], Loss: 1.975301, Acc:0.802020, Semantic loss: 0.744352, BCE loss: 0.513608, SB loss: 0.717341
2023-10-30 16:06:40,147 Epoch: [291/484] Iter:[230/495], Time: 0.37, lr: [0.004362130083779234], Loss: 1.974318, Acc:0.800948, Semantic loss: 0.743384, BCE loss: 0.514230, SB loss: 0.716705
2023-10-30 16:06:43,945 Epoch: [291/484] Iter:[240/495], Time: 0.37, lr: [0.004361718149707276], Loss: 1.980299, Acc:0.801186, Semantic loss: 0.746468, BCE loss: 0.515848, SB loss: 0.717983
2023-10-30 16:06:47,567 Epoch: [291/484] Iter:[250/495], Time: 0.37, lr: [0.004361306211312572], Loss: 1.987538, Acc:0.799829, Semantic loss: 0.749456, BCE loss: 0.519119, SB loss: 0.718962
2023-10-30 16:06:51,247 Epoch: [291/484] Iter:[260/495], Time: 0.37, lr: [0.00436089426859462], Loss: 1.989335, Acc:0.797690, Semantic loss: 0.750971, BCE loss: 0.518680, SB loss: 0.719684
2023-10-30 16:06:54,870 Epoch: [291/484] Iter:[270/495], Time: 0.37, lr: [0.004360482321552923], Loss: 1.997421, Acc:0.799822, Semantic loss: 0.753734, BCE loss: 0.522248, SB loss: 0.721438
2023-10-30 16:06:58,607 Epoch: [291/484] Iter:[280/495], Time: 0.37, lr: [0.00436007037018698], Loss: 2.000417, Acc:0.800253, Semantic loss: 0.753418, BCE loss: 0.524179, SB loss: 0.722821
2023-10-30 16:07:02,227 Epoch: [291/484] Iter:[290/495], Time: 0.37, lr: [0.004359658414496294], Loss: 1.996065, Acc:0.799800, Semantic loss: 0.751066, BCE loss: 0.523943, SB loss: 0.721056
2023-10-30 16:07:05,842 Epoch: [291/484] Iter:[300/495], Time: 0.37, lr: [0.004359246454480363], Loss: 1.992333, Acc:0.800284, Semantic loss: 0.750118, BCE loss: 0.521625, SB loss: 0.720590
2023-10-30 16:07:09,562 Epoch: [291/484] Iter:[310/495], Time: 0.37, lr: [0.004358834490138689], Loss: 1.994407, Acc:0.799718, Semantic loss: 0.751112, BCE loss: 0.522294, SB loss: 0.721001
2023-10-30 16:07:13,230 Epoch: [291/484] Iter:[320/495], Time: 0.37, lr: [0.004358422521470771], Loss: 1.993568, Acc:0.799840, Semantic loss: 0.749587, BCE loss: 0.523140, SB loss: 0.720841
2023-10-30 16:07:16,993 Epoch: [291/484] Iter:[330/495], Time: 0.37, lr: [0.004358010548476111], Loss: 1.986553, Acc:0.800480, Semantic loss: 0.746307, BCE loss: 0.522000, SB loss: 0.718246
2023-10-30 16:07:20,682 Epoch: [291/484] Iter:[340/495], Time: 0.37, lr: [0.004357598571154208], Loss: 1.986812, Acc:0.800578, Semantic loss: 0.746024, BCE loss: 0.522222, SB loss: 0.718566
2023-10-30 16:07:24,400 Epoch: [291/484] Iter:[350/495], Time: 0.37, lr: [0.004357186589504562], Loss: 1.989471, Acc:0.801094, Semantic loss: 0.748076, BCE loss: 0.522502, SB loss: 0.718893
2023-10-30 16:07:28,030 Epoch: [291/484] Iter:[360/495], Time: 0.37, lr: [0.004356774603526672], Loss: 1.988381, Acc:0.801535, Semantic loss: 0.747674, BCE loss: 0.521965, SB loss: 0.718741
2023-10-30 16:07:31,705 Epoch: [291/484] Iter:[370/495], Time: 0.37, lr: [0.00435636261322004], Loss: 1.990673, Acc:0.800127, Semantic loss: 0.749528, BCE loss: 0.522161, SB loss: 0.718984
2023-10-30 16:07:35,372 Epoch: [291/484] Iter:[380/495], Time: 0.37, lr: [0.004355950618584164], Loss: 1.992016, Acc:0.799548, Semantic loss: 0.749075, BCE loss: 0.523859, SB loss: 0.719081
2023-10-30 16:07:39,012 Epoch: [291/484] Iter:[390/495], Time: 0.37, lr: [0.004355538619618544], Loss: 1.994006, Acc:0.800163, Semantic loss: 0.748123, BCE loss: 0.526278, SB loss: 0.719605
2023-10-30 16:07:42,668 Epoch: [291/484] Iter:[400/495], Time: 0.37, lr: [0.004355126616322679], Loss: 1.990705, Acc:0.800476, Semantic loss: 0.746195, BCE loss: 0.525253, SB loss: 0.719257
2023-10-30 16:07:46,344 Epoch: [291/484] Iter:[410/495], Time: 0.37, lr: [0.004354714608696068], Loss: 1.989224, Acc:0.800707, Semantic loss: 0.745666, BCE loss: 0.524371, SB loss: 0.719187
2023-10-30 16:07:50,050 Epoch: [291/484] Iter:[420/495], Time: 0.37, lr: [0.004354302596738212], Loss: 1.989555, Acc:0.801615, Semantic loss: 0.745517, BCE loss: 0.525601, SB loss: 0.718436
2023-10-30 16:07:53,739 Epoch: [291/484] Iter:[430/495], Time: 0.37, lr: [0.0043538905804486085], Loss: 1.987744, Acc:0.801113, Semantic loss: 0.744819, BCE loss: 0.524953, SB loss: 0.717972
2023-10-30 16:07:57,406 Epoch: [291/484] Iter:[440/495], Time: 0.37, lr: [0.004353478559826755], Loss: 1.988087, Acc:0.800928, Semantic loss: 0.745387, BCE loss: 0.524861, SB loss: 0.717840
2023-10-30 16:08:01,121 Epoch: [291/484] Iter:[450/495], Time: 0.37, lr: [0.004353066534872155], Loss: 1.992079, Acc:0.801754, Semantic loss: 0.746810, BCE loss: 0.527226, SB loss: 0.718043
2023-10-30 16:08:04,832 Epoch: [291/484] Iter:[460/495], Time: 0.37, lr: [0.0043526545055843045], Loss: 1.991483, Acc:0.802163, Semantic loss: 0.746022, BCE loss: 0.527866, SB loss: 0.717595
2023-10-30 16:08:08,600 Epoch: [291/484] Iter:[470/495], Time: 0.37, lr: [0.004352242471962702], Loss: 1.988332, Acc:0.802070, Semantic loss: 0.744487, BCE loss: 0.526679, SB loss: 0.717165
2023-10-30 16:08:12,258 Epoch: [291/484] Iter:[480/495], Time: 0.37, lr: [0.004351830434006844], Loss: 1.989527, Acc:0.802822, Semantic loss: 0.744428, BCE loss: 0.527983, SB loss: 0.717116
2023-10-30 16:08:15,825 Epoch: [291/484] Iter:[490/495], Time: 0.37, lr: [0.0043514183917162325], Loss: 1.988612, Acc:0.802671, Semantic loss: 0.744209, BCE loss: 0.527457, SB loss: 0.716946
2023-10-30 16:08:17,215 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:08:17,452 Loss: 2.052, MeanIU:  0.6971, Best_mIoU:  0.7151
2023-10-30 16:08:17,452 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085]
2023-10-30 16:08:19,375 Epoch: [292/484] Iter:[0/495], Time: 1.89, lr: [0.004351212368945237], Loss: 2.295376, Acc:0.835120, Semantic loss: 0.950851, BCE loss: 0.591630, SB loss: 0.752895
2023-10-30 16:08:23,308 Epoch: [292/484] Iter:[10/495], Time: 0.53, lr: [0.004350800320151553], Loss: 2.130542, Acc:0.785590, Semantic loss: 0.825207, BCE loss: 0.547166, SB loss: 0.758169
2023-10-30 16:08:26,977 Epoch: [292/484] Iter:[20/495], Time: 0.45, lr: [0.004350388267021858], Loss: 2.105178, Acc:0.787530, Semantic loss: 0.807599, BCE loss: 0.549679, SB loss: 0.747901
2023-10-30 16:08:30,643 Epoch: [292/484] Iter:[30/495], Time: 0.42, lr: [0.004349976209555654], Loss: 2.045774, Acc:0.794017, Semantic loss: 0.781420, BCE loss: 0.535295, SB loss: 0.729059
2023-10-30 16:08:34,281 Epoch: [292/484] Iter:[40/495], Time: 0.41, lr: [0.0043495641477524355], Loss: 2.014243, Acc:0.798399, Semantic loss: 0.756038, BCE loss: 0.535184, SB loss: 0.723022
2023-10-30 16:08:38,058 Epoch: [292/484] Iter:[50/495], Time: 0.40, lr: [0.004349152081611702], Loss: 2.010017, Acc:0.801008, Semantic loss: 0.753878, BCE loss: 0.534639, SB loss: 0.721500
2023-10-30 16:08:41,688 Epoch: [292/484] Iter:[60/495], Time: 0.40, lr: [0.00434874001113295], Loss: 2.008935, Acc:0.807816, Semantic loss: 0.747960, BCE loss: 0.543514, SB loss: 0.717462
2023-10-30 16:08:45,402 Epoch: [292/484] Iter:[70/495], Time: 0.39, lr: [0.004348327936315678], Loss: 1.979450, Acc:0.803022, Semantic loss: 0.736817, BCE loss: 0.532405, SB loss: 0.710228
2023-10-30 16:08:49,144 Epoch: [292/484] Iter:[80/495], Time: 0.39, lr: [0.004347915857159384], Loss: 1.981869, Acc:0.800046, Semantic loss: 0.739915, BCE loss: 0.529213, SB loss: 0.712741
2023-10-30 16:08:52,875 Epoch: [292/484] Iter:[90/495], Time: 0.39, lr: [0.004347503773663565], Loss: 1.995258, Acc:0.801062, Semantic loss: 0.745027, BCE loss: 0.533705, SB loss: 0.716526
2023-10-30 16:08:56,550 Epoch: [292/484] Iter:[100/495], Time: 0.39, lr: [0.004347091685827716], Loss: 2.005650, Acc:0.800323, Semantic loss: 0.748667, BCE loss: 0.538773, SB loss: 0.718210
2023-10-30 16:09:00,189 Epoch: [292/484] Iter:[110/495], Time: 0.38, lr: [0.004346679593651337], Loss: 2.012652, Acc:0.801299, Semantic loss: 0.752452, BCE loss: 0.538249, SB loss: 0.721952
2023-10-30 16:09:03,944 Epoch: [292/484] Iter:[120/495], Time: 0.38, lr: [0.004346267497133924], Loss: 2.007789, Acc:0.801676, Semantic loss: 0.747024, BCE loss: 0.541156, SB loss: 0.719610
2023-10-30 16:09:07,616 Epoch: [292/484] Iter:[130/495], Time: 0.38, lr: [0.0043458553962749755], Loss: 2.000549, Acc:0.798691, Semantic loss: 0.747230, BCE loss: 0.535880, SB loss: 0.717439
2023-10-30 16:09:11,345 Epoch: [292/484] Iter:[140/495], Time: 0.38, lr: [0.004345443291073984], Loss: 1.997524, Acc:0.799877, Semantic loss: 0.743277, BCE loss: 0.535935, SB loss: 0.718312
2023-10-30 16:09:15,060 Epoch: [292/484] Iter:[150/495], Time: 0.38, lr: [0.004345031181530451], Loss: 1.993197, Acc:0.800617, Semantic loss: 0.742162, BCE loss: 0.532406, SB loss: 0.718629
2023-10-30 16:09:18,619 Epoch: [292/484] Iter:[160/495], Time: 0.38, lr: [0.0043446190676438715], Loss: 1.998871, Acc:0.801385, Semantic loss: 0.746931, BCE loss: 0.533284, SB loss: 0.718656
2023-10-30 16:09:22,266 Epoch: [292/484] Iter:[170/495], Time: 0.38, lr: [0.004344206949413741], Loss: 1.994375, Acc:0.799430, Semantic loss: 0.748160, BCE loss: 0.527415, SB loss: 0.718800
2023-10-30 16:09:25,963 Epoch: [292/484] Iter:[180/495], Time: 0.38, lr: [0.004343794826839556], Loss: 1.996852, Acc:0.797353, Semantic loss: 0.750789, BCE loss: 0.525300, SB loss: 0.720763
2023-10-30 16:09:29,615 Epoch: [292/484] Iter:[190/495], Time: 0.38, lr: [0.004343382699920814], Loss: 2.016162, Acc:0.796861, Semantic loss: 0.762273, BCE loss: 0.527525, SB loss: 0.726364
2023-10-30 16:09:33,317 Epoch: [292/484] Iter:[200/495], Time: 0.38, lr: [0.00434297056865701], Loss: 2.023960, Acc:0.797354, Semantic loss: 0.765495, BCE loss: 0.531385, SB loss: 0.727079
2023-10-30 16:09:36,970 Epoch: [292/484] Iter:[210/495], Time: 0.38, lr: [0.004342558433047641], Loss: 2.022214, Acc:0.797910, Semantic loss: 0.765892, BCE loss: 0.531079, SB loss: 0.725242
2023-10-30 16:09:40,626 Epoch: [292/484] Iter:[220/495], Time: 0.38, lr: [0.004342146293092201], Loss: 2.032383, Acc:0.798172, Semantic loss: 0.769327, BCE loss: 0.534804, SB loss: 0.728252
2023-10-30 16:09:44,301 Epoch: [292/484] Iter:[230/495], Time: 0.38, lr: [0.004341734148790188], Loss: 2.025134, Acc:0.799120, Semantic loss: 0.764748, BCE loss: 0.532687, SB loss: 0.727698
2023-10-30 16:09:48,038 Epoch: [292/484] Iter:[240/495], Time: 0.38, lr: [0.004341322000141097], Loss: 2.024424, Acc:0.799979, Semantic loss: 0.762990, BCE loss: 0.534482, SB loss: 0.726952
2023-10-30 16:09:51,671 Epoch: [292/484] Iter:[250/495], Time: 0.38, lr: [0.0043409098471444245], Loss: 2.030488, Acc:0.799843, Semantic loss: 0.765271, BCE loss: 0.536473, SB loss: 0.728745
2023-10-30 16:09:55,347 Epoch: [292/484] Iter:[260/495], Time: 0.37, lr: [0.004340497689799663], Loss: 2.025454, Acc:0.800524, Semantic loss: 0.763172, BCE loss: 0.533560, SB loss: 0.728722
2023-10-30 16:09:59,032 Epoch: [292/484] Iter:[270/495], Time: 0.37, lr: [0.004340085528106311], Loss: 2.022095, Acc:0.800415, Semantic loss: 0.761787, BCE loss: 0.531185, SB loss: 0.729123
2023-10-30 16:10:02,742 Epoch: [292/484] Iter:[280/495], Time: 0.37, lr: [0.004339673362063862], Loss: 2.017093, Acc:0.799996, Semantic loss: 0.760254, BCE loss: 0.528997, SB loss: 0.727843
2023-10-30 16:10:06,332 Epoch: [292/484] Iter:[290/495], Time: 0.37, lr: [0.004339261191671813], Loss: 2.016572, Acc:0.800404, Semantic loss: 0.759860, BCE loss: 0.529556, SB loss: 0.727156
2023-10-30 16:10:10,014 Epoch: [292/484] Iter:[300/495], Time: 0.37, lr: [0.004338849016929656], Loss: 2.016209, Acc:0.801243, Semantic loss: 0.759023, BCE loss: 0.530428, SB loss: 0.726758
2023-10-30 16:10:13,735 Epoch: [292/484] Iter:[310/495], Time: 0.37, lr: [0.004338436837836889], Loss: 2.012470, Acc:0.802068, Semantic loss: 0.758063, BCE loss: 0.528484, SB loss: 0.725923
2023-10-30 16:10:17,547 Epoch: [292/484] Iter:[320/495], Time: 0.37, lr: [0.004338024654393004], Loss: 2.007731, Acc:0.801951, Semantic loss: 0.755156, BCE loss: 0.528313, SB loss: 0.724263
2023-10-30 16:10:21,241 Epoch: [292/484] Iter:[330/495], Time: 0.37, lr: [0.004337612466597499], Loss: 2.013533, Acc:0.802793, Semantic loss: 0.758839, BCE loss: 0.529939, SB loss: 0.724754
2023-10-30 16:10:24,873 Epoch: [292/484] Iter:[340/495], Time: 0.37, lr: [0.004337200274449865], Loss: 2.015410, Acc:0.803317, Semantic loss: 0.759416, BCE loss: 0.531800, SB loss: 0.724194
2023-10-30 16:10:28,654 Epoch: [292/484] Iter:[350/495], Time: 0.37, lr: [0.0043367880779495984], Loss: 2.015922, Acc:0.803136, Semantic loss: 0.760627, BCE loss: 0.530485, SB loss: 0.724810
2023-10-30 16:10:32,374 Epoch: [292/484] Iter:[360/495], Time: 0.37, lr: [0.004336375877096195], Loss: 2.014349, Acc:0.803532, Semantic loss: 0.760361, BCE loss: 0.529373, SB loss: 0.724615
2023-10-30 16:10:36,031 Epoch: [292/484] Iter:[370/495], Time: 0.37, lr: [0.004335963671889147], Loss: 2.012157, Acc:0.803169, Semantic loss: 0.758532, BCE loss: 0.529385, SB loss: 0.724240
2023-10-30 16:10:39,660 Epoch: [292/484] Iter:[380/495], Time: 0.37, lr: [0.004335551462327948], Loss: 2.009203, Acc:0.804055, Semantic loss: 0.757614, BCE loss: 0.527920, SB loss: 0.723669
2023-10-30 16:10:43,344 Epoch: [292/484] Iter:[390/495], Time: 0.37, lr: [0.004335139248412093], Loss: 2.012977, Acc:0.803697, Semantic loss: 0.759005, BCE loss: 0.529450, SB loss: 0.724522
2023-10-30 16:10:47,034 Epoch: [292/484] Iter:[400/495], Time: 0.37, lr: [0.004334727030141076], Loss: 2.011010, Acc:0.803062, Semantic loss: 0.758624, BCE loss: 0.528354, SB loss: 0.724031
2023-10-30 16:10:50,833 Epoch: [292/484] Iter:[410/495], Time: 0.37, lr: [0.00433431480751439], Loss: 2.008264, Acc:0.803020, Semantic loss: 0.757152, BCE loss: 0.527187, SB loss: 0.723925
2023-10-30 16:10:54,482 Epoch: [292/484] Iter:[420/495], Time: 0.37, lr: [0.0043339025805315306], Loss: 2.013191, Acc:0.802840, Semantic loss: 0.761760, BCE loss: 0.526587, SB loss: 0.724843
2023-10-30 16:10:58,245 Epoch: [292/484] Iter:[430/495], Time: 0.37, lr: [0.00433349034919199], Loss: 2.011739, Acc:0.802655, Semantic loss: 0.760773, BCE loss: 0.526057, SB loss: 0.724909
2023-10-30 16:11:02,034 Epoch: [292/484] Iter:[440/495], Time: 0.37, lr: [0.004333078113495262], Loss: 2.018150, Acc:0.802200, Semantic loss: 0.766207, BCE loss: 0.524989, SB loss: 0.726954
2023-10-30 16:11:05,860 Epoch: [292/484] Iter:[450/495], Time: 0.37, lr: [0.004332665873440839], Loss: 2.017321, Acc:0.802788, Semantic loss: 0.765226, BCE loss: 0.525681, SB loss: 0.726414
2023-10-30 16:11:09,561 Epoch: [292/484] Iter:[460/495], Time: 0.37, lr: [0.004332253629028215], Loss: 2.016571, Acc:0.802445, Semantic loss: 0.764414, BCE loss: 0.525810, SB loss: 0.726348
2023-10-30 16:11:13,274 Epoch: [292/484] Iter:[470/495], Time: 0.37, lr: [0.004331841380256884], Loss: 2.019666, Acc:0.801772, Semantic loss: 0.765555, BCE loss: 0.527666, SB loss: 0.726445
2023-10-30 16:11:17,046 Epoch: [292/484] Iter:[480/495], Time: 0.37, lr: [0.004331429127126338], Loss: 2.021310, Acc:0.801837, Semantic loss: 0.765363, BCE loss: 0.528285, SB loss: 0.727662
2023-10-30 16:11:20,539 Epoch: [292/484] Iter:[490/495], Time: 0.37, lr: [0.004331016869636069], Loss: 2.021743, Acc:0.801158, Semantic loss: 0.765245, BCE loss: 0.528080, SB loss: 0.728418
2023-10-30 16:11:21,939 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:11:22,172 Loss: 2.052, MeanIU:  0.6971, Best_mIoU:  0.7151
2023-10-30 16:11:22,172 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085]
2023-10-30 16:11:24,155 Epoch: [293/484] Iter:[0/495], Time: 1.95, lr: [0.00433081073925588], Loss: 2.296300, Acc:0.902809, Semantic loss: 0.792245, BCE loss: 0.720818, SB loss: 0.783237
2023-10-30 16:11:28,119 Epoch: [293/484] Iter:[10/495], Time: 0.54, lr: [0.004330398475225078], Loss: 1.869988, Acc:0.799049, Semantic loss: 0.712518, BCE loss: 0.454061, SB loss: 0.703410
2023-10-30 16:11:31,845 Epoch: [293/484] Iter:[20/495], Time: 0.46, lr: [0.004329986206833285], Loss: 1.952186, Acc:0.800417, Semantic loss: 0.740990, BCE loss: 0.492359, SB loss: 0.718838
2023-10-30 16:11:35,489 Epoch: [293/484] Iter:[30/495], Time: 0.43, lr: [0.004329573934079995], Loss: 1.976220, Acc:0.794880, Semantic loss: 0.750562, BCE loss: 0.502946, SB loss: 0.722711
2023-10-30 16:11:39,135 Epoch: [293/484] Iter:[40/495], Time: 0.41, lr: [0.0043291616569646986], Loss: 1.977700, Acc:0.797574, Semantic loss: 0.744759, BCE loss: 0.508668, SB loss: 0.724273
2023-10-30 16:11:42,830 Epoch: [293/484] Iter:[50/495], Time: 0.40, lr: [0.0043287493754868905], Loss: 1.959324, Acc:0.795896, Semantic loss: 0.737210, BCE loss: 0.503223, SB loss: 0.718891
2023-10-30 16:11:46,543 Epoch: [293/484] Iter:[60/495], Time: 0.40, lr: [0.00432833708964606], Loss: 1.971222, Acc:0.795714, Semantic loss: 0.742955, BCE loss: 0.509458, SB loss: 0.718809
2023-10-30 16:11:50,182 Epoch: [293/484] Iter:[70/495], Time: 0.39, lr: [0.004327924799441702], Loss: 2.011872, Acc:0.793013, Semantic loss: 0.769890, BCE loss: 0.518039, SB loss: 0.723943
2023-10-30 16:11:53,925 Epoch: [293/484] Iter:[80/495], Time: 0.39, lr: [0.004327512504873306], Loss: 2.008192, Acc:0.798429, Semantic loss: 0.766163, BCE loss: 0.516349, SB loss: 0.725680
2023-10-30 16:11:57,716 Epoch: [293/484] Iter:[90/495], Time: 0.39, lr: [0.004327100205940365], Loss: 2.046789, Acc:0.795599, Semantic loss: 0.785042, BCE loss: 0.529332, SB loss: 0.732415
2023-10-30 16:12:01,513 Epoch: [293/484] Iter:[100/495], Time: 0.39, lr: [0.0043266879026423715], Loss: 2.041113, Acc:0.794113, Semantic loss: 0.776965, BCE loss: 0.530332, SB loss: 0.733817
2023-10-30 16:12:05,206 Epoch: [293/484] Iter:[110/495], Time: 0.39, lr: [0.004326275594978816], Loss: 2.062941, Acc:0.790698, Semantic loss: 0.793415, BCE loss: 0.528938, SB loss: 0.740588
2023-10-30 16:12:08,881 Epoch: [293/484] Iter:[120/495], Time: 0.39, lr: [0.004325863282949189], Loss: 2.066602, Acc:0.789497, Semantic loss: 0.791725, BCE loss: 0.531800, SB loss: 0.743076
2023-10-30 16:12:12,490 Epoch: [293/484] Iter:[130/495], Time: 0.38, lr: [0.004325450966552984], Loss: 2.071235, Acc:0.788754, Semantic loss: 0.796207, BCE loss: 0.531378, SB loss: 0.743650
2023-10-30 16:12:16,204 Epoch: [293/484] Iter:[140/495], Time: 0.38, lr: [0.004325038645789692], Loss: 2.080611, Acc:0.787485, Semantic loss: 0.803491, BCE loss: 0.533632, SB loss: 0.743488
2023-10-30 16:12:19,871 Epoch: [293/484] Iter:[150/495], Time: 0.38, lr: [0.004324626320658803], Loss: 2.088603, Acc:0.788324, Semantic loss: 0.809066, BCE loss: 0.533670, SB loss: 0.745867
2023-10-30 16:12:23,577 Epoch: [293/484] Iter:[160/495], Time: 0.38, lr: [0.004324213991159807], Loss: 2.101451, Acc:0.787146, Semantic loss: 0.815264, BCE loss: 0.536455, SB loss: 0.749732
2023-10-30 16:12:27,202 Epoch: [293/484] Iter:[170/495], Time: 0.38, lr: [0.004323801657292199], Loss: 2.097656, Acc:0.785075, Semantic loss: 0.812228, BCE loss: 0.534801, SB loss: 0.750626
2023-10-30 16:12:30,826 Epoch: [293/484] Iter:[180/495], Time: 0.38, lr: [0.0043233893190554665], Loss: 2.105985, Acc:0.783704, Semantic loss: 0.817149, BCE loss: 0.536123, SB loss: 0.752713
2023-10-30 16:12:34,534 Epoch: [293/484] Iter:[190/495], Time: 0.38, lr: [0.0043229769764491005], Loss: 2.098612, Acc:0.783909, Semantic loss: 0.812218, BCE loss: 0.534396, SB loss: 0.751998
2023-10-30 16:12:38,156 Epoch: [293/484] Iter:[200/495], Time: 0.38, lr: [0.004322564629472592], Loss: 2.093616, Acc:0.783637, Semantic loss: 0.808918, BCE loss: 0.534200, SB loss: 0.750498
2023-10-30 16:12:41,776 Epoch: [293/484] Iter:[210/495], Time: 0.38, lr: [0.004322152278125432], Loss: 2.090471, Acc:0.784169, Semantic loss: 0.806963, BCE loss: 0.534866, SB loss: 0.748642
2023-10-30 16:12:45,417 Epoch: [293/484] Iter:[220/495], Time: 0.38, lr: [0.00432173992240711], Loss: 2.083446, Acc:0.783195, Semantic loss: 0.803008, BCE loss: 0.532626, SB loss: 0.747812
2023-10-30 16:12:49,116 Epoch: [293/484] Iter:[230/495], Time: 0.38, lr: [0.004321327562317116], Loss: 2.086986, Acc:0.782421, Semantic loss: 0.804493, BCE loss: 0.534612, SB loss: 0.747882
2023-10-30 16:12:52,789 Epoch: [293/484] Iter:[240/495], Time: 0.38, lr: [0.0043209151978549415], Loss: 2.082389, Acc:0.783142, Semantic loss: 0.800736, BCE loss: 0.535142, SB loss: 0.746510
2023-10-30 16:12:56,480 Epoch: [293/484] Iter:[250/495], Time: 0.38, lr: [0.004320502829020075], Loss: 2.080896, Acc:0.783347, Semantic loss: 0.799928, BCE loss: 0.534951, SB loss: 0.746017
2023-10-30 16:13:00,100 Epoch: [293/484] Iter:[260/495], Time: 0.38, lr: [0.004320090455812008], Loss: 2.073986, Acc:0.784112, Semantic loss: 0.794694, BCE loss: 0.534938, SB loss: 0.744355
2023-10-30 16:13:03,786 Epoch: [293/484] Iter:[270/495], Time: 0.37, lr: [0.004319678078230228], Loss: 2.079439, Acc:0.784061, Semantic loss: 0.799215, BCE loss: 0.534723, SB loss: 0.745501
2023-10-30 16:13:07,531 Epoch: [293/484] Iter:[280/495], Time: 0.37, lr: [0.004319265696274228], Loss: 2.078011, Acc:0.785825, Semantic loss: 0.796094, BCE loss: 0.537258, SB loss: 0.744659
2023-10-30 16:13:11,202 Epoch: [293/484] Iter:[290/495], Time: 0.37, lr: [0.0043188533099434954], Loss: 2.074045, Acc:0.785384, Semantic loss: 0.794582, BCE loss: 0.536135, SB loss: 0.743328
2023-10-30 16:13:14,841 Epoch: [293/484] Iter:[300/495], Time: 0.37, lr: [0.004318440919237519], Loss: 2.073462, Acc:0.785782, Semantic loss: 0.793658, BCE loss: 0.536292, SB loss: 0.743511
2023-10-30 16:13:18,499 Epoch: [293/484] Iter:[310/495], Time: 0.37, lr: [0.004318028524155789], Loss: 2.070210, Acc:0.786785, Semantic loss: 0.790925, BCE loss: 0.536747, SB loss: 0.742538
2023-10-30 16:13:22,215 Epoch: [293/484] Iter:[320/495], Time: 0.37, lr: [0.004317616124697795], Loss: 2.066484, Acc:0.787422, Semantic loss: 0.788587, BCE loss: 0.536441, SB loss: 0.741457
2023-10-30 16:13:25,912 Epoch: [293/484] Iter:[330/495], Time: 0.37, lr: [0.004317203720863027], Loss: 2.065610, Acc:0.788093, Semantic loss: 0.787087, BCE loss: 0.537506, SB loss: 0.741017
2023-10-30 16:13:29,523 Epoch: [293/484] Iter:[340/495], Time: 0.37, lr: [0.0043167913126509715], Loss: 2.062050, Acc:0.787210, Semantic loss: 0.785989, BCE loss: 0.535372, SB loss: 0.740689
2023-10-30 16:13:33,262 Epoch: [293/484] Iter:[350/495], Time: 0.37, lr: [0.004316378900061118], Loss: 2.060551, Acc:0.787530, Semantic loss: 0.785471, BCE loss: 0.535029, SB loss: 0.740051
2023-10-30 16:13:37,076 Epoch: [293/484] Iter:[360/495], Time: 0.37, lr: [0.004315966483092956], Loss: 2.057366, Acc:0.788834, Semantic loss: 0.783787, BCE loss: 0.533868, SB loss: 0.739712
2023-10-30 16:13:40,820 Epoch: [293/484] Iter:[370/495], Time: 0.37, lr: [0.004315554061745976], Loss: 2.054083, Acc:0.790254, Semantic loss: 0.781691, BCE loss: 0.533216, SB loss: 0.739177
2023-10-30 16:13:44,526 Epoch: [293/484] Iter:[380/495], Time: 0.37, lr: [0.004315141636019663], Loss: 2.055056, Acc:0.789873, Semantic loss: 0.782851, BCE loss: 0.532824, SB loss: 0.739381
2023-10-30 16:13:48,173 Epoch: [293/484] Iter:[390/495], Time: 0.37, lr: [0.0043147292059135065], Loss: 2.053808, Acc:0.789931, Semantic loss: 0.781864, BCE loss: 0.532365, SB loss: 0.739579
2023-10-30 16:13:51,955 Epoch: [293/484] Iter:[400/495], Time: 0.37, lr: [0.004314316771426996], Loss: 2.050623, Acc:0.790003, Semantic loss: 0.780574, BCE loss: 0.531262, SB loss: 0.738787
2023-10-30 16:13:55,628 Epoch: [293/484] Iter:[410/495], Time: 0.37, lr: [0.004313904332559619], Loss: 2.047895, Acc:0.790403, Semantic loss: 0.778800, BCE loss: 0.530967, SB loss: 0.738127
2023-10-30 16:13:59,313 Epoch: [293/484] Iter:[420/495], Time: 0.37, lr: [0.004313491889310864], Loss: 2.050235, Acc:0.790883, Semantic loss: 0.779894, BCE loss: 0.531573, SB loss: 0.738768
2023-10-30 16:14:02,939 Epoch: [293/484] Iter:[430/495], Time: 0.37, lr: [0.004313079441680217], Loss: 2.051252, Acc:0.790933, Semantic loss: 0.780195, BCE loss: 0.532075, SB loss: 0.738982
2023-10-30 16:14:06,690 Epoch: [293/484] Iter:[440/495], Time: 0.37, lr: [0.004312666989667169], Loss: 2.046039, Acc:0.792085, Semantic loss: 0.776909, BCE loss: 0.531769, SB loss: 0.737362
2023-10-30 16:14:10,304 Epoch: [293/484] Iter:[450/495], Time: 0.37, lr: [0.004312254533271206], Loss: 2.045558, Acc:0.792339, Semantic loss: 0.777123, BCE loss: 0.531169, SB loss: 0.737267
2023-10-30 16:14:13,919 Epoch: [293/484] Iter:[460/495], Time: 0.37, lr: [0.004311842072491815], Loss: 2.044472, Acc:0.792857, Semantic loss: 0.775937, BCE loss: 0.531792, SB loss: 0.736743
2023-10-30 16:14:17,711 Epoch: [293/484] Iter:[470/495], Time: 0.37, lr: [0.004311429607328484], Loss: 2.043895, Acc:0.792858, Semantic loss: 0.775995, BCE loss: 0.531542, SB loss: 0.736358
2023-10-30 16:14:21,491 Epoch: [293/484] Iter:[480/495], Time: 0.37, lr: [0.004311017137780701], Loss: 2.047790, Acc:0.793375, Semantic loss: 0.777684, BCE loss: 0.532992, SB loss: 0.737115
2023-10-30 16:14:25,009 Epoch: [293/484] Iter:[490/495], Time: 0.37, lr: [0.004310604663847953], Loss: 2.049156, Acc:0.793150, Semantic loss: 0.777672, BCE loss: 0.534147, SB loss: 0.737337
2023-10-30 16:14:26,430 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:14:26,672 Loss: 2.052, MeanIU:  0.6971, Best_mIoU:  0.7151
2023-10-30 16:14:26,672 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085]
2023-10-30 16:14:28,917 Epoch: [294/484] Iter:[0/495], Time: 2.21, lr: [0.004310398425237057], Loss: 1.903762, Acc:0.860904, Semantic loss: 0.727152, BCE loss: 0.485964, SB loss: 0.690646
2023-10-30 16:14:33,099 Epoch: [294/484] Iter:[10/495], Time: 0.58, lr: [0.0043099859447259005], Loss: 1.983955, Acc:0.793090, Semantic loss: 0.790270, BCE loss: 0.470321, SB loss: 0.723363
2023-10-30 16:14:36,782 Epoch: [294/484] Iter:[20/495], Time: 0.48, lr: [0.004309573459828495], Loss: 2.017205, Acc:0.814227, Semantic loss: 0.778868, BCE loss: 0.518469, SB loss: 0.719867
2023-10-30 16:14:40,560 Epoch: [294/484] Iter:[30/495], Time: 0.45, lr: [0.00430916097054433], Loss: 2.045354, Acc:0.814894, Semantic loss: 0.773325, BCE loss: 0.530533, SB loss: 0.741495
2023-10-30 16:14:44,348 Epoch: [294/484] Iter:[40/495], Time: 0.43, lr: [0.004308748476872892], Loss: 2.056321, Acc:0.820000, Semantic loss: 0.772141, BCE loss: 0.542289, SB loss: 0.741892
2023-10-30 16:14:48,074 Epoch: [294/484] Iter:[50/495], Time: 0.42, lr: [0.004308335978813666], Loss: 2.078788, Acc:0.813660, Semantic loss: 0.791093, BCE loss: 0.545218, SB loss: 0.742478
2023-10-30 16:14:51,762 Epoch: [294/484] Iter:[60/495], Time: 0.41, lr: [0.004307923476366138], Loss: 2.079539, Acc:0.810974, Semantic loss: 0.791556, BCE loss: 0.545232, SB loss: 0.742751
2023-10-30 16:14:55,409 Epoch: [294/484] Iter:[70/495], Time: 0.40, lr: [0.004307510969529798], Loss: 2.075096, Acc:0.813062, Semantic loss: 0.791914, BCE loss: 0.543164, SB loss: 0.740018
2023-10-30 16:14:59,083 Epoch: [294/484] Iter:[80/495], Time: 0.40, lr: [0.00430709845830413], Loss: 2.059549, Acc:0.811946, Semantic loss: 0.788672, BCE loss: 0.537150, SB loss: 0.733727
2023-10-30 16:15:02,844 Epoch: [294/484] Iter:[90/495], Time: 0.40, lr: [0.004306685942688619], Loss: 2.043195, Acc:0.807139, Semantic loss: 0.781949, BCE loss: 0.528613, SB loss: 0.732633
2023-10-30 16:15:06,485 Epoch: [294/484] Iter:[100/495], Time: 0.39, lr: [0.004306273422682754], Loss: 2.049031, Acc:0.807741, Semantic loss: 0.788111, BCE loss: 0.528937, SB loss: 0.731984
2023-10-30 16:15:10,163 Epoch: [294/484] Iter:[110/495], Time: 0.39, lr: [0.004305860898286018], Loss: 2.050986, Acc:0.809211, Semantic loss: 0.786186, BCE loss: 0.532497, SB loss: 0.732303
2023-10-30 16:15:13,843 Epoch: [294/484] Iter:[120/495], Time: 0.39, lr: [0.004305448369497899], Loss: 2.057458, Acc:0.808555, Semantic loss: 0.786744, BCE loss: 0.537819, SB loss: 0.732896
2023-10-30 16:15:17,531 Epoch: [294/484] Iter:[130/495], Time: 0.39, lr: [0.004305035836317881], Loss: 2.050800, Acc:0.810049, Semantic loss: 0.782215, BCE loss: 0.538867, SB loss: 0.729718
2023-10-30 16:15:21,160 Epoch: [294/484] Iter:[140/495], Time: 0.39, lr: [0.004304623298745452], Loss: 2.040496, Acc:0.807534, Semantic loss: 0.776381, BCE loss: 0.533147, SB loss: 0.730968
2023-10-30 16:15:25,017 Epoch: [294/484] Iter:[150/495], Time: 0.39, lr: [0.004304210756780095], Loss: 2.035614, Acc:0.804785, Semantic loss: 0.771667, BCE loss: 0.533967, SB loss: 0.729980
2023-10-30 16:15:28,774 Epoch: [294/484] Iter:[160/495], Time: 0.39, lr: [0.004303798210421297], Loss: 2.043080, Acc:0.803559, Semantic loss: 0.773156, BCE loss: 0.539024, SB loss: 0.730900
2023-10-30 16:15:32,634 Epoch: [294/484] Iter:[170/495], Time: 0.39, lr: [0.004303385659668542], Loss: 2.044906, Acc:0.803299, Semantic loss: 0.774261, BCE loss: 0.539076, SB loss: 0.731568
2023-10-30 16:15:36,412 Epoch: [294/484] Iter:[180/495], Time: 0.39, lr: [0.004302973104521317], Loss: 2.035822, Acc:0.804625, Semantic loss: 0.769548, BCE loss: 0.537394, SB loss: 0.728880
2023-10-30 16:15:40,067 Epoch: [294/484] Iter:[190/495], Time: 0.38, lr: [0.004302560544979105], Loss: 2.035464, Acc:0.804184, Semantic loss: 0.770107, BCE loss: 0.537204, SB loss: 0.728153
2023-10-30 16:15:43,779 Epoch: [294/484] Iter:[200/495], Time: 0.38, lr: [0.004302147981041392], Loss: 2.035059, Acc:0.803909, Semantic loss: 0.769452, BCE loss: 0.537331, SB loss: 0.728276
2023-10-30 16:15:47,492 Epoch: [294/484] Iter:[210/495], Time: 0.38, lr: [0.0043017354127076616], Loss: 2.032975, Acc:0.803625, Semantic loss: 0.769191, BCE loss: 0.535644, SB loss: 0.728140
2023-10-30 16:15:51,303 Epoch: [294/484] Iter:[220/495], Time: 0.38, lr: [0.004301322839977402], Loss: 2.034854, Acc:0.805136, Semantic loss: 0.772190, BCE loss: 0.534629, SB loss: 0.728035
2023-10-30 16:15:55,082 Epoch: [294/484] Iter:[230/495], Time: 0.38, lr: [0.004300910262850093], Loss: 2.027143, Acc:0.806029, Semantic loss: 0.767996, BCE loss: 0.532816, SB loss: 0.726331
2023-10-30 16:15:58,765 Epoch: [294/484] Iter:[240/495], Time: 0.38, lr: [0.004300497681325223], Loss: 2.022218, Acc:0.806117, Semantic loss: 0.765717, BCE loss: 0.531419, SB loss: 0.725081
2023-10-30 16:16:02,504 Epoch: [294/484] Iter:[250/495], Time: 0.38, lr: [0.004300085095402273], Loss: 2.029300, Acc:0.806546, Semantic loss: 0.771251, BCE loss: 0.532281, SB loss: 0.725768
2023-10-30 16:16:06,121 Epoch: [294/484] Iter:[260/495], Time: 0.38, lr: [0.00429967250508073], Loss: 2.023198, Acc:0.806495, Semantic loss: 0.768118, BCE loss: 0.530064, SB loss: 0.725016
2023-10-30 16:16:09,812 Epoch: [294/484] Iter:[270/495], Time: 0.38, lr: [0.004299259910360077], Loss: 2.018827, Acc:0.805692, Semantic loss: 0.765662, BCE loss: 0.528574, SB loss: 0.724591
2023-10-30 16:16:13,517 Epoch: [294/484] Iter:[280/495], Time: 0.38, lr: [0.004298847311239798], Loss: 2.018614, Acc:0.806522, Semantic loss: 0.764885, BCE loss: 0.529278, SB loss: 0.724450
2023-10-30 16:16:17,223 Epoch: [294/484] Iter:[290/495], Time: 0.38, lr: [0.0042984347077193764], Loss: 2.016743, Acc:0.806490, Semantic loss: 0.762844, BCE loss: 0.529765, SB loss: 0.724134
2023-10-30 16:16:20,976 Epoch: [294/484] Iter:[300/495], Time: 0.38, lr: [0.0042980220997982975], Loss: 2.016443, Acc:0.807258, Semantic loss: 0.763232, BCE loss: 0.529000, SB loss: 0.724211
2023-10-30 16:16:24,657 Epoch: [294/484] Iter:[310/495], Time: 0.38, lr: [0.004297609487476044], Loss: 2.013508, Acc:0.806810, Semantic loss: 0.761891, BCE loss: 0.527726, SB loss: 0.723891
2023-10-30 16:16:28,407 Epoch: [294/484] Iter:[320/495], Time: 0.38, lr: [0.004297196870752099], Loss: 2.014109, Acc:0.805663, Semantic loss: 0.762592, BCE loss: 0.527267, SB loss: 0.724250
2023-10-30 16:16:32,111 Epoch: [294/484] Iter:[330/495], Time: 0.38, lr: [0.0042967842496259455], Loss: 2.016555, Acc:0.805489, Semantic loss: 0.764503, BCE loss: 0.527100, SB loss: 0.724952
2023-10-30 16:16:35,812 Epoch: [294/484] Iter:[340/495], Time: 0.38, lr: [0.0042963716240970685], Loss: 2.018835, Acc:0.803869, Semantic loss: 0.767394, BCE loss: 0.525543, SB loss: 0.725898
2023-10-30 16:16:39,551 Epoch: [294/484] Iter:[350/495], Time: 0.38, lr: [0.00429595899416495], Loss: 2.018256, Acc:0.803974, Semantic loss: 0.767412, BCE loss: 0.524987, SB loss: 0.725857
2023-10-30 16:16:43,184 Epoch: [294/484] Iter:[360/495], Time: 0.38, lr: [0.004295546359829074], Loss: 2.017854, Acc:0.803950, Semantic loss: 0.766252, BCE loss: 0.525296, SB loss: 0.726305
2023-10-30 16:16:46,928 Epoch: [294/484] Iter:[370/495], Time: 0.38, lr: [0.004295133721088922], Loss: 2.024194, Acc:0.803226, Semantic loss: 0.769209, BCE loss: 0.526425, SB loss: 0.728560
2023-10-30 16:16:50,687 Epoch: [294/484] Iter:[380/495], Time: 0.38, lr: [0.004294721077943978], Loss: 2.024906, Acc:0.802091, Semantic loss: 0.768615, BCE loss: 0.527397, SB loss: 0.728894
2023-10-30 16:16:54,470 Epoch: [294/484] Iter:[390/495], Time: 0.38, lr: [0.004294308430393724], Loss: 2.026374, Acc:0.801909, Semantic loss: 0.769395, BCE loss: 0.528201, SB loss: 0.728778
2023-10-30 16:16:58,198 Epoch: [294/484] Iter:[400/495], Time: 0.38, lr: [0.004293895778437645], Loss: 2.023915, Acc:0.801751, Semantic loss: 0.767605, BCE loss: 0.528267, SB loss: 0.728043
2023-10-30 16:17:01,873 Epoch: [294/484] Iter:[410/495], Time: 0.38, lr: [0.004293483122075219], Loss: 2.022602, Acc:0.802036, Semantic loss: 0.766389, BCE loss: 0.528305, SB loss: 0.727908
2023-10-30 16:17:05,549 Epoch: [294/484] Iter:[420/495], Time: 0.38, lr: [0.004293070461305932], Loss: 2.020791, Acc:0.801467, Semantic loss: 0.765740, BCE loss: 0.527295, SB loss: 0.727756
2023-10-30 16:17:09,402 Epoch: [294/484] Iter:[430/495], Time: 0.38, lr: [0.004292657796129266], Loss: 2.017674, Acc:0.801543, Semantic loss: 0.764319, BCE loss: 0.526175, SB loss: 0.727180
2023-10-30 16:17:13,200 Epoch: [294/484] Iter:[440/495], Time: 0.38, lr: [0.004292245126544701], Loss: 2.016930, Acc:0.801442, Semantic loss: 0.764289, BCE loss: 0.525804, SB loss: 0.726837
2023-10-30 16:17:16,898 Epoch: [294/484] Iter:[450/495], Time: 0.38, lr: [0.00429183245255172], Loss: 2.022430, Acc:0.802455, Semantic loss: 0.767658, BCE loss: 0.526986, SB loss: 0.727786
2023-10-30 16:17:20,597 Epoch: [294/484] Iter:[460/495], Time: 0.38, lr: [0.004291419774149806], Loss: 2.021922, Acc:0.801842, Semantic loss: 0.767923, BCE loss: 0.526252, SB loss: 0.727747
2023-10-30 16:17:24,294 Epoch: [294/484] Iter:[470/495], Time: 0.38, lr: [0.004291007091338441], Loss: 2.021316, Acc:0.801602, Semantic loss: 0.767881, BCE loss: 0.525649, SB loss: 0.727785
2023-10-30 16:17:28,094 Epoch: [294/484] Iter:[480/495], Time: 0.38, lr: [0.004290594404117104], Loss: 2.024174, Acc:0.801529, Semantic loss: 0.769625, BCE loss: 0.525984, SB loss: 0.728565
2023-10-30 16:17:31,667 Epoch: [294/484] Iter:[490/495], Time: 0.38, lr: [0.00429018171248528], Loss: 2.022685, Acc:0.801844, Semantic loss: 0.769175, BCE loss: 0.525305, SB loss: 0.728205
2023-10-30 16:17:33,083 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:17:33,319 Loss: 2.052, MeanIU:  0.6971, Best_mIoU:  0.7151
2023-10-30 16:17:33,319 [0.96637633 0.75565294 0.91193907 0.34711118 0.52400191 0.5898099
 0.66621672 0.70601768 0.91419094 0.57169723 0.94282654 0.77218671
 0.51440093 0.92989174 0.64001332 0.67154489 0.58176192 0.50188799
 0.73717085]
2023-10-30 16:17:35,428 Epoch: [295/484] Iter:[0/495], Time: 2.07, lr: [0.004289975365015272], Loss: 2.026973, Acc:0.919374, Semantic loss: 0.701343, BCE loss: 0.585616, SB loss: 0.740013
2023-10-30 16:17:39,618 Epoch: [295/484] Iter:[10/495], Time: 0.57, lr: [0.004289562666766742], Loss: 1.942737, Acc:0.791760, Semantic loss: 0.721710, BCE loss: 0.513094, SB loss: 0.707933
2023-10-30 16:17:43,303 Epoch: [295/484] Iter:[20/495], Time: 0.47, lr: [0.0042891499641064266], Loss: 1.960803, Acc:0.799404, Semantic loss: 0.733715, BCE loss: 0.517438, SB loss: 0.709650
2023-10-30 16:17:46,897 Epoch: [295/484] Iter:[30/495], Time: 0.44, lr: [0.004288737257033806], Loss: 2.026740, Acc:0.792991, Semantic loss: 0.757789, BCE loss: 0.551214, SB loss: 0.717738
2023-10-30 16:17:50,643 Epoch: [295/484] Iter:[40/495], Time: 0.42, lr: [0.004288324545548363], Loss: 2.054568, Acc:0.784080, Semantic loss: 0.776997, BCE loss: 0.549608, SB loss: 0.727964
2023-10-30 16:17:54,363 Epoch: [295/484] Iter:[50/495], Time: 0.41, lr: [0.004287911829649579], Loss: 2.074154, Acc:0.788551, Semantic loss: 0.776421, BCE loss: 0.564979, SB loss: 0.732754
2023-10-30 16:17:58,058 Epoch: [295/484] Iter:[60/495], Time: 0.40, lr: [0.004287499109336933], Loss: 2.069511, Acc:0.791245, Semantic loss: 0.774576, BCE loss: 0.563770, SB loss: 0.731165
2023-10-30 16:18:01,875 Epoch: [295/484] Iter:[70/495], Time: 0.40, lr: [0.004287086384609905], Loss: 2.037790, Acc:0.798764, Semantic loss: 0.755237, BCE loss: 0.559514, SB loss: 0.723039
2023-10-30 16:18:05,564 Epoch: [295/484] Iter:[80/495], Time: 0.40, lr: [0.004286673655467978], Loss: 2.028119, Acc:0.802740, Semantic loss: 0.754487, BCE loss: 0.549874, SB loss: 0.723758
2023-10-30 16:18:09,313 Epoch: [295/484] Iter:[90/495], Time: 0.40, lr: [0.004286260921910632], Loss: 2.015745, Acc:0.804840, Semantic loss: 0.751416, BCE loss: 0.545598, SB loss: 0.718732
2023-10-30 16:18:13,046 Epoch: [295/484] Iter:[100/495], Time: 0.39, lr: [0.0042858481839373455], Loss: 2.007072, Acc:0.804503, Semantic loss: 0.748883, BCE loss: 0.539004, SB loss: 0.719185
2023-10-30 16:18:16,687 Epoch: [295/484] Iter:[110/495], Time: 0.39, lr: [0.0042854354415476], Loss: 2.011053, Acc:0.806129, Semantic loss: 0.749355, BCE loss: 0.541305, SB loss: 0.720393
2023-10-30 16:18:20,442 Epoch: [295/484] Iter:[120/495], Time: 0.39, lr: [0.004285022694740876], Loss: 2.017640, Acc:0.806338, Semantic loss: 0.756518, BCE loss: 0.539904, SB loss: 0.721218
2023-10-30 16:18:24,133 Epoch: [295/484] Iter:[130/495], Time: 0.39, lr: [0.004284609943516654], Loss: 2.021234, Acc:0.806788, Semantic loss: 0.756424, BCE loss: 0.542026, SB loss: 0.722784
2023-10-30 16:18:27,865 Epoch: [295/484] Iter:[140/495], Time: 0.39, lr: [0.004284197187874412], Loss: 2.014972, Acc:0.805158, Semantic loss: 0.752283, BCE loss: 0.541420, SB loss: 0.721269
2023-10-30 16:18:31,587 Epoch: [295/484] Iter:[150/495], Time: 0.39, lr: [0.00428378442781363], Loss: 2.012062, Acc:0.806054, Semantic loss: 0.750223, BCE loss: 0.542734, SB loss: 0.719105
2023-10-30 16:18:35,320 Epoch: [295/484] Iter:[160/495], Time: 0.38, lr: [0.004283371663333789], Loss: 2.006111, Acc:0.806071, Semantic loss: 0.749631, BCE loss: 0.537767, SB loss: 0.718713
2023-10-30 16:18:39,133 Epoch: [295/484] Iter:[170/495], Time: 0.38, lr: [0.004282958894434368], Loss: 2.001554, Acc:0.806355, Semantic loss: 0.747521, BCE loss: 0.536209, SB loss: 0.717824
2023-10-30 16:18:42,833 Epoch: [295/484] Iter:[180/495], Time: 0.38, lr: [0.0042825461211148455], Loss: 2.003952, Acc:0.805854, Semantic loss: 0.750283, BCE loss: 0.535351, SB loss: 0.718317
2023-10-30 16:18:46,538 Epoch: [295/484] Iter:[190/495], Time: 0.38, lr: [0.0042821333433747015], Loss: 2.006717, Acc:0.805070, Semantic loss: 0.753614, BCE loss: 0.534216, SB loss: 0.718887
2023-10-30 16:18:50,353 Epoch: [295/484] Iter:[200/495], Time: 0.38, lr: [0.004281720561213416], Loss: 2.009080, Acc:0.806087, Semantic loss: 0.753920, BCE loss: 0.536809, SB loss: 0.718351
2023-10-30 16:18:54,060 Epoch: [295/484] Iter:[210/495], Time: 0.38, lr: [0.004281307774630467], Loss: 2.007701, Acc:0.806469, Semantic loss: 0.754686, BCE loss: 0.534823, SB loss: 0.718191
2023-10-30 16:18:57,815 Epoch: [295/484] Iter:[220/495], Time: 0.38, lr: [0.004280894983625334], Loss: 2.009450, Acc:0.806576, Semantic loss: 0.754758, BCE loss: 0.536280, SB loss: 0.718412
2023-10-30 16:19:01,478 Epoch: [295/484] Iter:[230/495], Time: 0.38, lr: [0.004280482188197494], Loss: 2.009852, Acc:0.806094, Semantic loss: 0.755045, BCE loss: 0.534525, SB loss: 0.720281
2023-10-30 16:19:05,203 Epoch: [295/484] Iter:[240/495], Time: 0.38, lr: [0.004280069388346429], Loss: 2.007289, Acc:0.806449, Semantic loss: 0.754420, BCE loss: 0.532980, SB loss: 0.719889
2023-10-30 16:19:08,853 Epoch: [295/484] Iter:[250/495], Time: 0.38, lr: [0.0042796565840716155], Loss: 2.003653, Acc:0.806287, Semantic loss: 0.752418, BCE loss: 0.531953, SB loss: 0.719283
2023-10-30 16:19:12,653 Epoch: [295/484] Iter:[260/495], Time: 0.38, lr: [0.004279243775372532], Loss: 2.000427, Acc:0.806456, Semantic loss: 0.750773, BCE loss: 0.530352, SB loss: 0.719302
2023-10-30 16:19:16,436 Epoch: [295/484] Iter:[270/495], Time: 0.38, lr: [0.004278830962248656], Loss: 2.001281, Acc:0.807832, Semantic loss: 0.750471, BCE loss: 0.531229, SB loss: 0.719581
2023-10-30 16:19:20,130 Epoch: [295/484] Iter:[280/495], Time: 0.38, lr: [0.004278418144699468], Loss: 2.003724, Acc:0.808705, Semantic loss: 0.751074, BCE loss: 0.532938, SB loss: 0.719712
2023-10-30 16:19:23,882 Epoch: [295/484] Iter:[290/495], Time: 0.38, lr: [0.004278005322724445], Loss: 2.004106, Acc:0.808625, Semantic loss: 0.750576, BCE loss: 0.534470, SB loss: 0.719060
2023-10-30 16:19:27,633 Epoch: [295/484] Iter:[300/495], Time: 0.38, lr: [0.004277592496323065], Loss: 2.008890, Acc:0.807856, Semantic loss: 0.755464, BCE loss: 0.534081, SB loss: 0.719344
2023-10-30 16:19:31,306 Epoch: [295/484] Iter:[310/495], Time: 0.38, lr: [0.004277179665494805], Loss: 2.008202, Acc:0.807440, Semantic loss: 0.755229, BCE loss: 0.532980, SB loss: 0.719993
2023-10-30 16:19:35,040 Epoch: [295/484] Iter:[320/495], Time: 0.38, lr: [0.004276766830239144], Loss: 2.005972, Acc:0.807119, Semantic loss: 0.754249, BCE loss: 0.531417, SB loss: 0.720307
2023-10-30 16:19:38,836 Epoch: [295/484] Iter:[330/495], Time: 0.38, lr: [0.00427635399055556], Loss: 2.004581, Acc:0.806190, Semantic loss: 0.754869, BCE loss: 0.529951, SB loss: 0.719761
2023-10-30 16:19:42,552 Epoch: [295/484] Iter:[340/495], Time: 0.38, lr: [0.00427594114644353], Loss: 2.009766, Acc:0.805146, Semantic loss: 0.756619, BCE loss: 0.532303, SB loss: 0.720844
2023-10-30 16:19:46,194 Epoch: [295/484] Iter:[350/495], Time: 0.38, lr: [0.00427552829790253], Loss: 2.006120, Acc:0.805573, Semantic loss: 0.754636, BCE loss: 0.531270, SB loss: 0.720214
2023-10-30 16:19:49,996 Epoch: [295/484] Iter:[360/495], Time: 0.38, lr: [0.004275115444932039], Loss: 2.004371, Acc:0.803887, Semantic loss: 0.754632, BCE loss: 0.529875, SB loss: 0.719865
2023-10-30 16:19:53,704 Epoch: [295/484] Iter:[370/495], Time: 0.38, lr: [0.004274702587531534], Loss: 2.004049, Acc:0.804589, Semantic loss: 0.754376, BCE loss: 0.530324, SB loss: 0.719348
2023-10-30 16:19:57,389 Epoch: [295/484] Iter:[380/495], Time: 0.38, lr: [0.004274289725700491], Loss: 2.004890, Acc:0.804373, Semantic loss: 0.754282, BCE loss: 0.530358, SB loss: 0.720250
2023-10-30 16:20:01,106 Epoch: [295/484] Iter:[390/495], Time: 0.38, lr: [0.004273876859438387], Loss: 2.004437, Acc:0.804220, Semantic loss: 0.754235, BCE loss: 0.529873, SB loss: 0.720330
2023-10-30 16:20:04,901 Epoch: [295/484] Iter:[400/495], Time: 0.38, lr: [0.004273463988744701], Loss: 2.001758, Acc:0.803739, Semantic loss: 0.753221, BCE loss: 0.528415, SB loss: 0.720122
2023-10-30 16:20:08,593 Epoch: [295/484] Iter:[410/495], Time: 0.38, lr: [0.004273051113618908], Loss: 2.004260, Acc:0.803924, Semantic loss: 0.755037, BCE loss: 0.527992, SB loss: 0.721231
2023-10-30 16:20:12,282 Epoch: [295/484] Iter:[420/495], Time: 0.38, lr: [0.004272638234060485], Loss: 2.000926, Acc:0.803738, Semantic loss: 0.753333, BCE loss: 0.526790, SB loss: 0.720804
2023-10-30 16:20:15,939 Epoch: [295/484] Iter:[430/495], Time: 0.38, lr: [0.004272225350068906], Loss: 2.001794, Acc:0.802383, Semantic loss: 0.754070, BCE loss: 0.526517, SB loss: 0.721207
2023-10-30 16:20:19,682 Epoch: [295/484] Iter:[440/495], Time: 0.38, lr: [0.004271812461643652], Loss: 2.001821, Acc:0.803367, Semantic loss: 0.753759, BCE loss: 0.526683, SB loss: 0.721378
2023-10-30 16:20:23,525 Epoch: [295/484] Iter:[450/495], Time: 0.38, lr: [0.004271399568784196], Loss: 2.000754, Acc:0.803383, Semantic loss: 0.752788, BCE loss: 0.526898, SB loss: 0.721068
2023-10-30 16:20:27,164 Epoch: [295/484] Iter:[460/495], Time: 0.38, lr: [0.0042709866714900156], Loss: 2.000672, Acc:0.803583, Semantic loss: 0.752064, BCE loss: 0.526540, SB loss: 0.722069
2023-10-30 16:20:30,987 Epoch: [295/484] Iter:[470/495], Time: 0.38, lr: [0.004270573769760585], Loss: 1.999822, Acc:0.803062, Semantic loss: 0.751972, BCE loss: 0.526112, SB loss: 0.721739
2023-10-30 16:20:34,754 Epoch: [295/484] Iter:[480/495], Time: 0.38, lr: [0.004270160863595381], Loss: 2.001773, Acc:0.802386, Semantic loss: 0.753219, BCE loss: 0.526030, SB loss: 0.722525
2023-10-30 16:20:38,407 Epoch: [295/484] Iter:[490/495], Time: 0.38, lr: [0.004269747952993881], Loss: 2.000337, Acc:0.802514, Semantic loss: 0.752208, BCE loss: 0.526519, SB loss: 0.721609
2023-10-30 16:23:35,234 0 [0.94298168 0.65542659 0.83665963 0.20289099 0.29547738 0.43666748
 0.4872307  0.60206776 0.88476572 0.46347642 0.87395898 0.60054768
 0.04326932 0.83234187 0.00456566 0.10581017 0.04713901 0.06995495
 0.61141232] 0.473507596245737
2023-10-30 16:23:35,235 1 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ] 0.7308588219543837
2023-10-30 16:23:35,238 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:23:35,601 Loss: 2.031, MeanIU:  0.7309, Best_mIoU:  0.7309
2023-10-30 16:23:35,601 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ]
2023-10-30 16:23:37,865 Epoch: [296/484] Iter:[0/495], Time: 2.23, lr: [0.004269541496029355], Loss: 2.224925, Acc:0.832662, Semantic loss: 0.843921, BCE loss: 0.505259, SB loss: 0.875744
2023-10-30 16:23:41,703 Epoch: [296/484] Iter:[10/495], Time: 0.55, lr: [0.004269128578772425], Loss: 2.115194, Acc:0.799251, Semantic loss: 0.778627, BCE loss: 0.576325, SB loss: 0.760242
2023-10-30 16:23:45,199 Epoch: [296/484] Iter:[20/495], Time: 0.46, lr: [0.004268715657077885], Loss: 2.028665, Acc:0.807667, Semantic loss: 0.756628, BCE loss: 0.537590, SB loss: 0.734448
2023-10-30 16:23:48,651 Epoch: [296/484] Iter:[30/495], Time: 0.42, lr: [0.004268302730945215], Loss: 2.052264, Acc:0.796144, Semantic loss: 0.764654, BCE loss: 0.544550, SB loss: 0.743060
2023-10-30 16:23:52,118 Epoch: [296/484] Iter:[40/495], Time: 0.40, lr: [0.004267889800373885], Loss: 2.023948, Acc:0.797303, Semantic loss: 0.746280, BCE loss: 0.545101, SB loss: 0.732567
2023-10-30 16:23:55,523 Epoch: [296/484] Iter:[50/495], Time: 0.39, lr: [0.004267476865363371], Loss: 2.025242, Acc:0.796581, Semantic loss: 0.753065, BCE loss: 0.543334, SB loss: 0.728843
2023-10-30 16:23:59,016 Epoch: [296/484] Iter:[60/495], Time: 0.38, lr: [0.004267063925913151], Loss: 2.002024, Acc:0.795876, Semantic loss: 0.746649, BCE loss: 0.530350, SB loss: 0.725025
2023-10-30 16:24:02,605 Epoch: [296/484] Iter:[70/495], Time: 0.38, lr: [0.004266650982022697], Loss: 2.021574, Acc:0.803021, Semantic loss: 0.755930, BCE loss: 0.534657, SB loss: 0.730987
2023-10-30 16:24:06,128 Epoch: [296/484] Iter:[80/495], Time: 0.38, lr: [0.004266238033691485], Loss: 2.023011, Acc:0.799488, Semantic loss: 0.756983, BCE loss: 0.536014, SB loss: 0.730015
2023-10-30 16:24:09,656 Epoch: [296/484] Iter:[90/495], Time: 0.37, lr: [0.004265825080918989], Loss: 2.014444, Acc:0.803296, Semantic loss: 0.751958, BCE loss: 0.536241, SB loss: 0.726246
2023-10-30 16:24:13,310 Epoch: [296/484] Iter:[100/495], Time: 0.37, lr: [0.004265412123704684], Loss: 2.006489, Acc:0.800072, Semantic loss: 0.749702, BCE loss: 0.529917, SB loss: 0.726870
2023-10-30 16:24:16,892 Epoch: [296/484] Iter:[110/495], Time: 0.37, lr: [0.004264999162048045], Loss: 2.010770, Acc:0.800263, Semantic loss: 0.754158, BCE loss: 0.527344, SB loss: 0.729268
2023-10-30 16:24:20,507 Epoch: [296/484] Iter:[120/495], Time: 0.37, lr: [0.0042645861959485455], Loss: 2.009259, Acc:0.798638, Semantic loss: 0.757601, BCE loss: 0.523859, SB loss: 0.727799
2023-10-30 16:24:24,166 Epoch: [296/484] Iter:[130/495], Time: 0.37, lr: [0.004264173225405659], Loss: 2.004851, Acc:0.797031, Semantic loss: 0.756799, BCE loss: 0.521643, SB loss: 0.726409
2023-10-30 16:24:27,915 Epoch: [296/484] Iter:[140/495], Time: 0.37, lr: [0.00426376025041886], Loss: 1.998513, Acc:0.797179, Semantic loss: 0.754155, BCE loss: 0.518276, SB loss: 0.726082
2023-10-30 16:24:31,461 Epoch: [296/484] Iter:[150/495], Time: 0.37, lr: [0.004263347270987624], Loss: 1.994287, Acc:0.796706, Semantic loss: 0.749417, BCE loss: 0.519330, SB loss: 0.725540
2023-10-30 16:24:35,295 Epoch: [296/484] Iter:[160/495], Time: 0.37, lr: [0.004262934287111423], Loss: 1.995582, Acc:0.797689, Semantic loss: 0.749303, BCE loss: 0.521857, SB loss: 0.724422
2023-10-30 16:24:39,032 Epoch: [296/484] Iter:[170/495], Time: 0.37, lr: [0.00426252129878973], Loss: 1.999035, Acc:0.797945, Semantic loss: 0.751888, BCE loss: 0.521204, SB loss: 0.725944
2023-10-30 16:24:42,662 Epoch: [296/484] Iter:[180/495], Time: 0.37, lr: [0.004262108306022021], Loss: 2.007726, Acc:0.798988, Semantic loss: 0.761346, BCE loss: 0.521039, SB loss: 0.725341
2023-10-30 16:24:46,309 Epoch: [296/484] Iter:[190/495], Time: 0.37, lr: [0.004261695308807768], Loss: 2.016141, Acc:0.799173, Semantic loss: 0.767180, BCE loss: 0.523055, SB loss: 0.725907
2023-10-30 16:24:50,029 Epoch: [296/484] Iter:[200/495], Time: 0.37, lr: [0.0042612823071464445], Loss: 2.015416, Acc:0.800352, Semantic loss: 0.766561, BCE loss: 0.523163, SB loss: 0.725692
2023-10-30 16:24:53,716 Epoch: [296/484] Iter:[210/495], Time: 0.37, lr: [0.004260869301037522], Loss: 2.008020, Acc:0.798550, Semantic loss: 0.761977, BCE loss: 0.522154, SB loss: 0.723889
2023-10-30 16:24:57,555 Epoch: [296/484] Iter:[220/495], Time: 0.37, lr: [0.0042604562904804775], Loss: 2.003089, Acc:0.799423, Semantic loss: 0.759256, BCE loss: 0.520884, SB loss: 0.722949
2023-10-30 16:25:01,195 Epoch: [296/484] Iter:[230/495], Time: 0.37, lr: [0.004260043275474781], Loss: 2.004084, Acc:0.799789, Semantic loss: 0.759402, BCE loss: 0.521472, SB loss: 0.723210
2023-10-30 16:25:04,767 Epoch: [296/484] Iter:[240/495], Time: 0.37, lr: [0.004259630256019906], Loss: 2.005271, Acc:0.798703, Semantic loss: 0.760113, BCE loss: 0.521102, SB loss: 0.724056
2023-10-30 16:25:08,418 Epoch: [296/484] Iter:[250/495], Time: 0.37, lr: [0.004259217232115324], Loss: 2.004776, Acc:0.797816, Semantic loss: 0.759037, BCE loss: 0.521358, SB loss: 0.724381
2023-10-30 16:25:12,050 Epoch: [296/484] Iter:[260/495], Time: 0.37, lr: [0.004258804203760512], Loss: 2.002176, Acc:0.797540, Semantic loss: 0.757700, BCE loss: 0.521428, SB loss: 0.723048
2023-10-30 16:25:15,758 Epoch: [296/484] Iter:[270/495], Time: 0.37, lr: [0.004258391170954937], Loss: 1.998566, Acc:0.797534, Semantic loss: 0.755221, BCE loss: 0.520509, SB loss: 0.722836
2023-10-30 16:25:19,462 Epoch: [296/484] Iter:[280/495], Time: 0.37, lr: [0.004257978133698075], Loss: 2.000893, Acc:0.797603, Semantic loss: 0.755761, BCE loss: 0.520606, SB loss: 0.724526
2023-10-30 16:25:23,077 Epoch: [296/484] Iter:[290/495], Time: 0.37, lr: [0.004257565091989396], Loss: 2.009906, Acc:0.798586, Semantic loss: 0.761195, BCE loss: 0.523306, SB loss: 0.725406
2023-10-30 16:25:26,759 Epoch: [296/484] Iter:[300/495], Time: 0.37, lr: [0.004257152045828373], Loss: 2.008631, Acc:0.798227, Semantic loss: 0.761104, BCE loss: 0.522765, SB loss: 0.724763
2023-10-30 16:25:30,517 Epoch: [296/484] Iter:[310/495], Time: 0.37, lr: [0.00425673899521448], Loss: 2.012462, Acc:0.799109, Semantic loss: 0.762470, BCE loss: 0.524879, SB loss: 0.725113
2023-10-30 16:25:34,230 Epoch: [296/484] Iter:[320/495], Time: 0.37, lr: [0.004256325940147186], Loss: 2.008854, Acc:0.799189, Semantic loss: 0.760228, BCE loss: 0.524489, SB loss: 0.724137
2023-10-30 16:25:37,807 Epoch: [296/484] Iter:[330/495], Time: 0.37, lr: [0.004255912880625963], Loss: 2.004824, Acc:0.799011, Semantic loss: 0.758241, BCE loss: 0.523009, SB loss: 0.723574
2023-10-30 16:25:41,560 Epoch: [296/484] Iter:[340/495], Time: 0.37, lr: [0.004255499816650285], Loss: 2.009957, Acc:0.798998, Semantic loss: 0.760721, BCE loss: 0.523560, SB loss: 0.725675
2023-10-30 16:25:45,221 Epoch: [296/484] Iter:[350/495], Time: 0.37, lr: [0.0042550867482196225], Loss: 2.013020, Acc:0.798853, Semantic loss: 0.761234, BCE loss: 0.525398, SB loss: 0.726387
2023-10-30 16:25:48,931 Epoch: [296/484] Iter:[360/495], Time: 0.37, lr: [0.004254673675333445], Loss: 2.008349, Acc:0.798064, Semantic loss: 0.759325, BCE loss: 0.523619, SB loss: 0.725406
2023-10-30 16:25:52,595 Epoch: [296/484] Iter:[370/495], Time: 0.37, lr: [0.004254260597991224], Loss: 2.006830, Acc:0.798726, Semantic loss: 0.757748, BCE loss: 0.524351, SB loss: 0.724731
2023-10-30 16:25:56,297 Epoch: [296/484] Iter:[380/495], Time: 0.37, lr: [0.004253847516192435], Loss: 2.008279, Acc:0.798195, Semantic loss: 0.758331, BCE loss: 0.524240, SB loss: 0.725709
2023-10-30 16:25:59,979 Epoch: [296/484] Iter:[390/495], Time: 0.37, lr: [0.004253434429936544], Loss: 2.012343, Acc:0.798502, Semantic loss: 0.759574, BCE loss: 0.526080, SB loss: 0.726689
2023-10-30 16:26:03,571 Epoch: [296/484] Iter:[400/495], Time: 0.37, lr: [0.004253021339223026], Loss: 2.011569, Acc:0.798404, Semantic loss: 0.758870, BCE loss: 0.525666, SB loss: 0.727034
2023-10-30 16:26:07,331 Epoch: [296/484] Iter:[410/495], Time: 0.37, lr: [0.004252608244051347], Loss: 2.008820, Acc:0.799059, Semantic loss: 0.757451, BCE loss: 0.525445, SB loss: 0.725924
2023-10-30 16:26:11,121 Epoch: [296/484] Iter:[420/495], Time: 0.37, lr: [0.004252195144420982], Loss: 2.008337, Acc:0.799119, Semantic loss: 0.757791, BCE loss: 0.525063, SB loss: 0.725483
2023-10-30 16:26:14,808 Epoch: [296/484] Iter:[430/495], Time: 0.37, lr: [0.0042517820403314], Loss: 2.007438, Acc:0.799447, Semantic loss: 0.756740, BCE loss: 0.525557, SB loss: 0.725141
2023-10-30 16:26:18,501 Epoch: [296/484] Iter:[440/495], Time: 0.37, lr: [0.004251368931782071], Loss: 2.007304, Acc:0.798903, Semantic loss: 0.756799, BCE loss: 0.525562, SB loss: 0.724943
2023-10-30 16:26:22,100 Epoch: [296/484] Iter:[450/495], Time: 0.37, lr: [0.004250955818772466], Loss: 2.002732, Acc:0.798759, Semantic loss: 0.755031, BCE loss: 0.523619, SB loss: 0.724083
2023-10-30 16:26:25,741 Epoch: [296/484] Iter:[460/495], Time: 0.37, lr: [0.004250542701302055], Loss: 2.001200, Acc:0.799269, Semantic loss: 0.754347, BCE loss: 0.523442, SB loss: 0.723410
2023-10-30 16:26:29,401 Epoch: [296/484] Iter:[470/495], Time: 0.37, lr: [0.00425012957937031], Loss: 2.001300, Acc:0.798804, Semantic loss: 0.755059, BCE loss: 0.523534, SB loss: 0.722708
2023-10-30 16:26:33,085 Epoch: [296/484] Iter:[480/495], Time: 0.37, lr: [0.004249716452976696], Loss: 2.001186, Acc:0.798282, Semantic loss: 0.754343, BCE loss: 0.523903, SB loss: 0.722940
2023-10-30 16:26:36,590 Epoch: [296/484] Iter:[490/495], Time: 0.37, lr: [0.004249303322120687], Loss: 2.000645, Acc:0.797064, Semantic loss: 0.754294, BCE loss: 0.523285, SB loss: 0.723066
2023-10-30 16:26:38,001 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:26:38,236 Loss: 2.031, MeanIU:  0.7309, Best_mIoU:  0.7309
2023-10-30 16:26:38,236 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ]
2023-10-30 16:26:40,211 Epoch: [297/484] Iter:[0/495], Time: 1.94, lr: [0.004249096755019119], Loss: 2.428919, Acc:0.820618, Semantic loss: 1.099893, BCE loss: 0.476247, SB loss: 0.852778
2023-10-30 16:26:44,235 Epoch: [297/484] Iter:[10/495], Time: 0.54, lr: [0.004248683617468522], Loss: 2.132148, Acc:0.778584, Semantic loss: 0.850496, BCE loss: 0.539418, SB loss: 0.742234
2023-10-30 16:26:47,990 Epoch: [297/484] Iter:[20/495], Time: 0.46, lr: [0.004248270475454203], Loss: 2.060827, Acc:0.804317, Semantic loss: 0.779698, BCE loss: 0.539059, SB loss: 0.742071
2023-10-30 16:26:51,683 Epoch: [297/484] Iter:[30/495], Time: 0.43, lr: [0.004247857328975631], Loss: 2.035891, Acc:0.797148, Semantic loss: 0.762537, BCE loss: 0.540469, SB loss: 0.732885
2023-10-30 16:26:55,420 Epoch: [297/484] Iter:[40/495], Time: 0.42, lr: [0.004247444178032277], Loss: 2.016685, Acc:0.803554, Semantic loss: 0.753275, BCE loss: 0.536845, SB loss: 0.726565
2023-10-30 16:26:59,139 Epoch: [297/484] Iter:[50/495], Time: 0.41, lr: [0.004247031022623608], Loss: 2.010813, Acc:0.795832, Semantic loss: 0.753985, BCE loss: 0.528909, SB loss: 0.727919
2023-10-30 16:27:02,883 Epoch: [297/484] Iter:[60/495], Time: 0.40, lr: [0.0042466178627490955], Loss: 2.001897, Acc:0.801667, Semantic loss: 0.746438, BCE loss: 0.534248, SB loss: 0.721211
2023-10-30 16:27:06,546 Epoch: [297/484] Iter:[70/495], Time: 0.40, lr: [0.0042462046984082045], Loss: 2.000254, Acc:0.803872, Semantic loss: 0.747627, BCE loss: 0.530396, SB loss: 0.722231
2023-10-30 16:27:10,246 Epoch: [297/484] Iter:[80/495], Time: 0.39, lr: [0.004245791529600408], Loss: 1.992755, Acc:0.801767, Semantic loss: 0.738956, BCE loss: 0.533206, SB loss: 0.720593
2023-10-30 16:27:13,948 Epoch: [297/484] Iter:[90/495], Time: 0.39, lr: [0.0042453783563251735], Loss: 1.994085, Acc:0.799066, Semantic loss: 0.747331, BCE loss: 0.526105, SB loss: 0.720649
2023-10-30 16:27:17,490 Epoch: [297/484] Iter:[100/495], Time: 0.39, lr: [0.0042449651785819685], Loss: 1.973444, Acc:0.794825, Semantic loss: 0.739026, BCE loss: 0.517310, SB loss: 0.717109
2023-10-30 16:27:21,152 Epoch: [297/484] Iter:[110/495], Time: 0.39, lr: [0.0042445519963702615], Loss: 1.971985, Acc:0.794920, Semantic loss: 0.739258, BCE loss: 0.516640, SB loss: 0.716087
2023-10-30 16:27:24,849 Epoch: [297/484] Iter:[120/495], Time: 0.38, lr: [0.004244138809689523], Loss: 1.976385, Acc:0.798052, Semantic loss: 0.741587, BCE loss: 0.517023, SB loss: 0.717774
2023-10-30 16:27:28,626 Epoch: [297/484] Iter:[130/495], Time: 0.38, lr: [0.004243725618539219], Loss: 1.987895, Acc:0.798555, Semantic loss: 0.749033, BCE loss: 0.517682, SB loss: 0.721179
2023-10-30 16:27:32,384 Epoch: [297/484] Iter:[140/495], Time: 0.38, lr: [0.004243312422918819], Loss: 1.993498, Acc:0.800416, Semantic loss: 0.747823, BCE loss: 0.524963, SB loss: 0.720712
2023-10-30 16:27:36,086 Epoch: [297/484] Iter:[150/495], Time: 0.38, lr: [0.004242899222827789], Loss: 1.984445, Acc:0.803081, Semantic loss: 0.743640, BCE loss: 0.523431, SB loss: 0.717374
2023-10-30 16:27:39,823 Epoch: [297/484] Iter:[160/495], Time: 0.38, lr: [0.004242486018265598], Loss: 1.985959, Acc:0.803872, Semantic loss: 0.745300, BCE loss: 0.523092, SB loss: 0.717566
2023-10-30 16:27:43,542 Epoch: [297/484] Iter:[170/495], Time: 0.38, lr: [0.004242072809231716], Loss: 1.981099, Acc:0.805942, Semantic loss: 0.742215, BCE loss: 0.522798, SB loss: 0.716087
2023-10-30 16:27:47,173 Epoch: [297/484] Iter:[180/495], Time: 0.38, lr: [0.004241659595725607], Loss: 1.985567, Acc:0.805968, Semantic loss: 0.744964, BCE loss: 0.523814, SB loss: 0.716789
2023-10-30 16:27:50,869 Epoch: [297/484] Iter:[190/495], Time: 0.38, lr: [0.004241246377746739], Loss: 1.980652, Acc:0.804002, Semantic loss: 0.742408, BCE loss: 0.522876, SB loss: 0.715367
2023-10-30 16:27:54,570 Epoch: [297/484] Iter:[200/495], Time: 0.38, lr: [0.004240833155294582], Loss: 1.980030, Acc:0.804440, Semantic loss: 0.741948, BCE loss: 0.522134, SB loss: 0.715948
2023-10-30 16:27:58,250 Epoch: [297/484] Iter:[210/495], Time: 0.38, lr: [0.004240419928368602], Loss: 1.982519, Acc:0.804483, Semantic loss: 0.742284, BCE loss: 0.522060, SB loss: 0.718175
2023-10-30 16:28:02,017 Epoch: [297/484] Iter:[220/495], Time: 0.38, lr: [0.004240006696968265], Loss: 1.983121, Acc:0.804692, Semantic loss: 0.743703, BCE loss: 0.521033, SB loss: 0.718385
2023-10-30 16:28:05,788 Epoch: [297/484] Iter:[230/495], Time: 0.38, lr: [0.004239593461093039], Loss: 1.987613, Acc:0.805313, Semantic loss: 0.746711, BCE loss: 0.521413, SB loss: 0.719489
2023-10-30 16:28:09,574 Epoch: [297/484] Iter:[240/495], Time: 0.38, lr: [0.004239180220742391], Loss: 1.984010, Acc:0.806459, Semantic loss: 0.742340, BCE loss: 0.522875, SB loss: 0.718796
2023-10-30 16:28:13,178 Epoch: [297/484] Iter:[250/495], Time: 0.38, lr: [0.004238766975915788], Loss: 1.981559, Acc:0.806066, Semantic loss: 0.741051, BCE loss: 0.521834, SB loss: 0.718674
2023-10-30 16:28:16,845 Epoch: [297/484] Iter:[260/495], Time: 0.38, lr: [0.004238353726612694], Loss: 1.986180, Acc:0.805298, Semantic loss: 0.744047, BCE loss: 0.522575, SB loss: 0.719557
2023-10-30 16:28:20,661 Epoch: [297/484] Iter:[270/495], Time: 0.38, lr: [0.00423794047283258], Loss: 1.990888, Acc:0.805520, Semantic loss: 0.745467, BCE loss: 0.525884, SB loss: 0.719537
2023-10-30 16:28:24,328 Epoch: [297/484] Iter:[280/495], Time: 0.38, lr: [0.0042375272145749095], Loss: 1.993720, Acc:0.805182, Semantic loss: 0.747643, BCE loss: 0.525987, SB loss: 0.720090
2023-10-30 16:28:28,209 Epoch: [297/484] Iter:[290/495], Time: 0.38, lr: [0.004237113951839149], Loss: 1.993053, Acc:0.805145, Semantic loss: 0.747695, BCE loss: 0.525824, SB loss: 0.719534
2023-10-30 16:28:31,888 Epoch: [297/484] Iter:[300/495], Time: 0.38, lr: [0.004236700684624765], Loss: 1.985522, Acc:0.805484, Semantic loss: 0.744304, BCE loss: 0.522812, SB loss: 0.718406
2023-10-30 16:28:35,531 Epoch: [297/484] Iter:[310/495], Time: 0.38, lr: [0.004236287412931224], Loss: 1.983739, Acc:0.805395, Semantic loss: 0.742655, BCE loss: 0.522324, SB loss: 0.718759
2023-10-30 16:28:39,070 Epoch: [297/484] Iter:[320/495], Time: 0.38, lr: [0.004235874136757993], Loss: 1.980621, Acc:0.804709, Semantic loss: 0.741228, BCE loss: 0.520680, SB loss: 0.718713
2023-10-30 16:28:42,831 Epoch: [297/484] Iter:[330/495], Time: 0.38, lr: [0.004235460856104534], Loss: 1.981637, Acc:0.805345, Semantic loss: 0.741906, BCE loss: 0.520601, SB loss: 0.719131
2023-10-30 16:28:46,568 Epoch: [297/484] Iter:[340/495], Time: 0.38, lr: [0.004235047570970315], Loss: 1.985569, Acc:0.805245, Semantic loss: 0.743122, BCE loss: 0.522420, SB loss: 0.720027
2023-10-30 16:28:50,344 Epoch: [297/484] Iter:[350/495], Time: 0.38, lr: [0.004234634281354803], Loss: 1.986152, Acc:0.805627, Semantic loss: 0.744111, BCE loss: 0.521322, SB loss: 0.720719
2023-10-30 16:28:54,051 Epoch: [297/484] Iter:[360/495], Time: 0.38, lr: [0.004234220987257462], Loss: 1.988449, Acc:0.805959, Semantic loss: 0.744835, BCE loss: 0.522332, SB loss: 0.721282
2023-10-30 16:28:57,755 Epoch: [297/484] Iter:[370/495], Time: 0.38, lr: [0.004233807688677757], Loss: 1.985845, Acc:0.805778, Semantic loss: 0.744466, BCE loss: 0.520439, SB loss: 0.720940
2023-10-30 16:29:01,373 Epoch: [297/484] Iter:[380/495], Time: 0.38, lr: [0.004233394385615153], Loss: 1.985730, Acc:0.805680, Semantic loss: 0.744103, BCE loss: 0.521039, SB loss: 0.720588
2023-10-30 16:29:05,182 Epoch: [297/484] Iter:[390/495], Time: 0.38, lr: [0.0042329810780691165], Loss: 1.983348, Acc:0.805241, Semantic loss: 0.743951, BCE loss: 0.519731, SB loss: 0.719666
2023-10-30 16:29:08,874 Epoch: [297/484] Iter:[400/495], Time: 0.38, lr: [0.004232567766039112], Loss: 1.986327, Acc:0.804724, Semantic loss: 0.745238, BCE loss: 0.519880, SB loss: 0.721209
2023-10-30 16:29:12,505 Epoch: [297/484] Iter:[410/495], Time: 0.38, lr: [0.0042321544495246026], Loss: 1.985490, Acc:0.804179, Semantic loss: 0.744894, BCE loss: 0.519223, SB loss: 0.721373
2023-10-30 16:29:16,161 Epoch: [297/484] Iter:[420/495], Time: 0.38, lr: [0.004231741128525054], Loss: 1.985000, Acc:0.803989, Semantic loss: 0.745040, BCE loss: 0.518741, SB loss: 0.721219
2023-10-30 16:29:19,951 Epoch: [297/484] Iter:[430/495], Time: 0.38, lr: [0.004231327803039932], Loss: 1.988834, Acc:0.803907, Semantic loss: 0.746396, BCE loss: 0.519984, SB loss: 0.722455
2023-10-30 16:29:23,676 Epoch: [297/484] Iter:[440/495], Time: 0.38, lr: [0.004230914473068701], Loss: 1.990645, Acc:0.804427, Semantic loss: 0.747238, BCE loss: 0.520704, SB loss: 0.722703
2023-10-30 16:29:27,398 Epoch: [297/484] Iter:[450/495], Time: 0.37, lr: [0.004230501138610824], Loss: 1.990651, Acc:0.805054, Semantic loss: 0.746733, BCE loss: 0.521514, SB loss: 0.722405
2023-10-30 16:29:31,086 Epoch: [297/484] Iter:[460/495], Time: 0.37, lr: [0.004230087799665765], Loss: 1.991852, Acc:0.804734, Semantic loss: 0.746899, BCE loss: 0.522380, SB loss: 0.722573
2023-10-30 16:29:34,807 Epoch: [297/484] Iter:[470/495], Time: 0.37, lr: [0.004229674456232989], Loss: 1.989149, Acc:0.803805, Semantic loss: 0.746228, BCE loss: 0.520923, SB loss: 0.721997
2023-10-30 16:29:38,463 Epoch: [297/484] Iter:[480/495], Time: 0.37, lr: [0.004229261108311961], Loss: 1.988850, Acc:0.803913, Semantic loss: 0.746056, BCE loss: 0.520795, SB loss: 0.721998
2023-10-30 16:29:41,985 Epoch: [297/484] Iter:[490/495], Time: 0.37, lr: [0.004228847755902142], Loss: 1.988083, Acc:0.803338, Semantic loss: 0.745523, BCE loss: 0.520416, SB loss: 0.722144
2023-10-30 16:29:43,402 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:29:43,642 Loss: 2.031, MeanIU:  0.7309, Best_mIoU:  0.7309
2023-10-30 16:29:43,642 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ]
2023-10-30 16:29:45,647 Epoch: [298/484] Iter:[0/495], Time: 1.97, lr: [0.00422864107801377], Loss: 1.995054, Acc:0.707545, Semantic loss: 0.711045, BCE loss: 0.526700, SB loss: 0.757309
2023-10-30 16:29:49,610 Epoch: [298/484] Iter:[10/495], Time: 0.54, lr: [0.004228227718869761], Loss: 2.127761, Acc:0.786631, Semantic loss: 0.785579, BCE loss: 0.593567, SB loss: 0.748614
2023-10-30 16:29:53,262 Epoch: [298/484] Iter:[20/495], Time: 0.46, lr: [0.004227814355235623], Loss: 2.198542, Acc:0.786780, Semantic loss: 0.858071, BCE loss: 0.571722, SB loss: 0.768749
2023-10-30 16:29:56,824 Epoch: [298/484] Iter:[30/495], Time: 0.42, lr: [0.0042274009871108185], Loss: 2.129758, Acc:0.786720, Semantic loss: 0.811970, BCE loss: 0.563565, SB loss: 0.754224
2023-10-30 16:30:00,507 Epoch: [298/484] Iter:[40/495], Time: 0.41, lr: [0.00422698761449481], Loss: 2.071729, Acc:0.792407, Semantic loss: 0.778237, BCE loss: 0.552394, SB loss: 0.741098
2023-10-30 16:30:04,147 Epoch: [298/484] Iter:[50/495], Time: 0.40, lr: [0.00422657423738706], Loss: 2.078624, Acc:0.793809, Semantic loss: 0.777045, BCE loss: 0.559652, SB loss: 0.741927
2023-10-30 16:30:07,816 Epoch: [298/484] Iter:[60/495], Time: 0.40, lr: [0.004226160855787035], Loss: 2.074756, Acc:0.795869, Semantic loss: 0.776384, BCE loss: 0.563242, SB loss: 0.735130
2023-10-30 16:30:11,523 Epoch: [298/484] Iter:[70/495], Time: 0.39, lr: [0.004225747469694194], Loss: 2.065737, Acc:0.796608, Semantic loss: 0.774254, BCE loss: 0.556920, SB loss: 0.734563
2023-10-30 16:30:15,199 Epoch: [298/484] Iter:[80/495], Time: 0.39, lr: [0.004225334079108002], Loss: 2.059666, Acc:0.797379, Semantic loss: 0.771112, BCE loss: 0.556853, SB loss: 0.731701
2023-10-30 16:30:18,890 Epoch: [298/484] Iter:[90/495], Time: 0.39, lr: [0.004224920684027921], Loss: 2.049655, Acc:0.795868, Semantic loss: 0.769728, BCE loss: 0.547815, SB loss: 0.732112
2023-10-30 16:30:22,521 Epoch: [298/484] Iter:[100/495], Time: 0.38, lr: [0.0042245072844534146], Loss: 2.046022, Acc:0.797444, Semantic loss: 0.769111, BCE loss: 0.548650, SB loss: 0.728261
2023-10-30 16:30:26,246 Epoch: [298/484] Iter:[110/495], Time: 0.38, lr: [0.004224093880383944], Loss: 2.044274, Acc:0.799506, Semantic loss: 0.766603, BCE loss: 0.552071, SB loss: 0.725600
2023-10-30 16:30:29,969 Epoch: [298/484] Iter:[120/495], Time: 0.38, lr: [0.004223680471818971], Loss: 2.021508, Acc:0.799010, Semantic loss: 0.756302, BCE loss: 0.545545, SB loss: 0.719662
2023-10-30 16:30:33,713 Epoch: [298/484] Iter:[130/495], Time: 0.38, lr: [0.00422326705875796], Loss: 2.013309, Acc:0.799519, Semantic loss: 0.752288, BCE loss: 0.541431, SB loss: 0.719591
2023-10-30 16:30:37,348 Epoch: [298/484] Iter:[140/495], Time: 0.38, lr: [0.004222853641200371], Loss: 2.017454, Acc:0.800068, Semantic loss: 0.753079, BCE loss: 0.543120, SB loss: 0.721255
2023-10-30 16:30:41,048 Epoch: [298/484] Iter:[150/495], Time: 0.38, lr: [0.004222440219145667], Loss: 2.020599, Acc:0.800521, Semantic loss: 0.753931, BCE loss: 0.542987, SB loss: 0.723682
2023-10-30 16:30:44,810 Epoch: [298/484] Iter:[160/495], Time: 0.38, lr: [0.004222026792593309], Loss: 2.013381, Acc:0.800300, Semantic loss: 0.751183, BCE loss: 0.540385, SB loss: 0.721814
2023-10-30 16:30:48,539 Epoch: [298/484] Iter:[170/495], Time: 0.38, lr: [0.00422161336154276], Loss: 2.016746, Acc:0.801433, Semantic loss: 0.754132, BCE loss: 0.540593, SB loss: 0.722021
2023-10-30 16:30:52,376 Epoch: [298/484] Iter:[180/495], Time: 0.38, lr: [0.004221199925993481], Loss: 2.012806, Acc:0.801102, Semantic loss: 0.751616, BCE loss: 0.539582, SB loss: 0.721608
2023-10-30 16:30:56,077 Epoch: [298/484] Iter:[190/495], Time: 0.38, lr: [0.004220786485944933], Loss: 2.013875, Acc:0.803104, Semantic loss: 0.749895, BCE loss: 0.541268, SB loss: 0.722713
2023-10-30 16:30:59,788 Epoch: [298/484] Iter:[200/495], Time: 0.38, lr: [0.004220373041396577], Loss: 2.003114, Acc:0.804104, Semantic loss: 0.745966, BCE loss: 0.536324, SB loss: 0.720824
2023-10-30 16:31:03,596 Epoch: [298/484] Iter:[210/495], Time: 0.38, lr: [0.004219959592347875], Loss: 2.002071, Acc:0.804404, Semantic loss: 0.746691, BCE loss: 0.534541, SB loss: 0.720839
2023-10-30 16:31:07,288 Epoch: [298/484] Iter:[220/495], Time: 0.38, lr: [0.004219546138798289], Loss: 2.005090, Acc:0.806508, Semantic loss: 0.747559, BCE loss: 0.537220, SB loss: 0.720312
2023-10-30 16:31:10,957 Epoch: [298/484] Iter:[230/495], Time: 0.38, lr: [0.0042191326807472776], Loss: 2.002912, Acc:0.807217, Semantic loss: 0.746728, BCE loss: 0.536876, SB loss: 0.719307
2023-10-30 16:31:14,644 Epoch: [298/484] Iter:[240/495], Time: 0.38, lr: [0.004218719218194304], Loss: 2.005602, Acc:0.806573, Semantic loss: 0.750366, BCE loss: 0.534463, SB loss: 0.720773
2023-10-30 16:31:18,254 Epoch: [298/484] Iter:[250/495], Time: 0.38, lr: [0.004218305751138828], Loss: 2.010806, Acc:0.804721, Semantic loss: 0.754255, BCE loss: 0.535020, SB loss: 0.721531
2023-10-30 16:31:21,931 Epoch: [298/484] Iter:[260/495], Time: 0.38, lr: [0.0042178922795803086], Loss: 2.009143, Acc:0.804329, Semantic loss: 0.753177, BCE loss: 0.534837, SB loss: 0.721129
2023-10-30 16:31:25,636 Epoch: [298/484] Iter:[270/495], Time: 0.38, lr: [0.00421747880351821], Loss: 2.013946, Acc:0.803340, Semantic loss: 0.756761, BCE loss: 0.534623, SB loss: 0.722562
2023-10-30 16:31:29,271 Epoch: [298/484] Iter:[280/495], Time: 0.38, lr: [0.004217065322951988], Loss: 2.011968, Acc:0.803451, Semantic loss: 0.755828, BCE loss: 0.534109, SB loss: 0.722030
2023-10-30 16:31:32,912 Epoch: [298/484] Iter:[290/495], Time: 0.38, lr: [0.004216651837881107], Loss: 2.018259, Acc:0.803750, Semantic loss: 0.760458, BCE loss: 0.534050, SB loss: 0.723751
2023-10-30 16:31:36,680 Epoch: [298/484] Iter:[300/495], Time: 0.38, lr: [0.004216238348305024], Loss: 2.020000, Acc:0.804868, Semantic loss: 0.762581, BCE loss: 0.532851, SB loss: 0.724568
2023-10-30 16:31:40,319 Epoch: [298/484] Iter:[310/495], Time: 0.38, lr: [0.004215824854223201], Loss: 2.022223, Acc:0.804376, Semantic loss: 0.763864, BCE loss: 0.532394, SB loss: 0.725965
2023-10-30 16:31:44,025 Epoch: [298/484] Iter:[320/495], Time: 0.37, lr: [0.004215411355635096], Loss: 2.027598, Acc:0.804525, Semantic loss: 0.765815, BCE loss: 0.534646, SB loss: 0.727137
2023-10-30 16:31:47,736 Epoch: [298/484] Iter:[330/495], Time: 0.37, lr: [0.004214997852540171], Loss: 2.027449, Acc:0.804321, Semantic loss: 0.765431, BCE loss: 0.535367, SB loss: 0.726651
2023-10-30 16:31:51,410 Epoch: [298/484] Iter:[340/495], Time: 0.37, lr: [0.004214584344937884], Loss: 2.026139, Acc:0.803465, Semantic loss: 0.764222, BCE loss: 0.535927, SB loss: 0.725989
2023-10-30 16:31:55,073 Epoch: [298/484] Iter:[350/495], Time: 0.37, lr: [0.004214170832827695], Loss: 2.028053, Acc:0.801957, Semantic loss: 0.764203, BCE loss: 0.537250, SB loss: 0.726600
2023-10-30 16:31:58,805 Epoch: [298/484] Iter:[360/495], Time: 0.37, lr: [0.0042137573162090635], Loss: 2.025326, Acc:0.802283, Semantic loss: 0.762502, BCE loss: 0.536355, SB loss: 0.726469
2023-10-30 16:32:02,484 Epoch: [298/484] Iter:[370/495], Time: 0.37, lr: [0.004213343795081448], Loss: 2.023021, Acc:0.801377, Semantic loss: 0.761028, BCE loss: 0.536258, SB loss: 0.725735
2023-10-30 16:32:06,185 Epoch: [298/484] Iter:[380/495], Time: 0.37, lr: [0.004212930269444309], Loss: 2.023425, Acc:0.801760, Semantic loss: 0.761421, BCE loss: 0.535661, SB loss: 0.726344
2023-10-30 16:32:09,898 Epoch: [298/484] Iter:[390/495], Time: 0.37, lr: [0.004212516739297105], Loss: 2.020492, Acc:0.800975, Semantic loss: 0.760076, BCE loss: 0.534497, SB loss: 0.725919
2023-10-30 16:32:13,510 Epoch: [298/484] Iter:[400/495], Time: 0.37, lr: [0.0042121032046392925], Loss: 2.020889, Acc:0.799809, Semantic loss: 0.760904, BCE loss: 0.533277, SB loss: 0.726709
2023-10-30 16:32:17,205 Epoch: [298/484] Iter:[410/495], Time: 0.37, lr: [0.004211689665470334], Loss: 2.019743, Acc:0.799781, Semantic loss: 0.760055, BCE loss: 0.533177, SB loss: 0.726512
2023-10-30 16:32:20,890 Epoch: [298/484] Iter:[420/495], Time: 0.37, lr: [0.004211276121789686], Loss: 2.018082, Acc:0.800320, Semantic loss: 0.759930, BCE loss: 0.531908, SB loss: 0.726244
2023-10-30 16:32:24,631 Epoch: [298/484] Iter:[430/495], Time: 0.37, lr: [0.004210862573596807], Loss: 2.018365, Acc:0.800026, Semantic loss: 0.760443, BCE loss: 0.531261, SB loss: 0.726660
2023-10-30 16:32:28,183 Epoch: [298/484] Iter:[440/495], Time: 0.37, lr: [0.004210449020891155], Loss: 2.017661, Acc:0.799776, Semantic loss: 0.760168, BCE loss: 0.530904, SB loss: 0.726588
2023-10-30 16:32:31,906 Epoch: [298/484] Iter:[450/495], Time: 0.37, lr: [0.00421003546367219], Loss: 2.013909, Acc:0.799584, Semantic loss: 0.758132, BCE loss: 0.530496, SB loss: 0.725281
2023-10-30 16:32:35,682 Epoch: [298/484] Iter:[460/495], Time: 0.37, lr: [0.00420962190193937], Loss: 2.013207, Acc:0.800180, Semantic loss: 0.757433, BCE loss: 0.530914, SB loss: 0.724860
2023-10-30 16:32:39,417 Epoch: [298/484] Iter:[470/495], Time: 0.37, lr: [0.004209208335692151], Loss: 2.012279, Acc:0.800718, Semantic loss: 0.757519, BCE loss: 0.530075, SB loss: 0.724686
2023-10-30 16:32:43,023 Epoch: [298/484] Iter:[480/495], Time: 0.37, lr: [0.004208794764929991], Loss: 2.008970, Acc:0.800668, Semantic loss: 0.756459, BCE loss: 0.528573, SB loss: 0.723938
2023-10-30 16:32:46,526 Epoch: [298/484] Iter:[490/495], Time: 0.37, lr: [0.00420838118965235], Loss: 2.007983, Acc:0.801015, Semantic loss: 0.756329, BCE loss: 0.528258, SB loss: 0.723396
2023-10-30 16:32:47,929 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:32:48,172 Loss: 2.031, MeanIU:  0.7309, Best_mIoU:  0.7309
2023-10-30 16:32:48,172 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ]
2023-10-30 16:32:50,369 Epoch: [299/484] Iter:[0/495], Time: 2.16, lr: [0.004208174400320054], Loss: 2.383981, Acc:0.801729, Semantic loss: 1.002122, BCE loss: 0.554578, SB loss: 0.827281
2023-10-30 16:32:54,429 Epoch: [299/484] Iter:[10/495], Time: 0.57, lr: [0.004207760818268173], Loss: 2.132238, Acc:0.807616, Semantic loss: 0.815990, BCE loss: 0.587063, SB loss: 0.729185
2023-10-30 16:32:58,173 Epoch: [299/484] Iter:[20/495], Time: 0.47, lr: [0.004207347231699452], Loss: 2.129964, Acc:0.801703, Semantic loss: 0.822738, BCE loss: 0.570636, SB loss: 0.736591
2023-10-30 16:33:01,795 Epoch: [299/484] Iter:[30/495], Time: 0.44, lr: [0.004206933640613351], Loss: 2.053866, Acc:0.806392, Semantic loss: 0.786027, BCE loss: 0.540770, SB loss: 0.727069
2023-10-30 16:33:05,515 Epoch: [299/484] Iter:[40/495], Time: 0.42, lr: [0.004206520045009327], Loss: 2.038324, Acc:0.806016, Semantic loss: 0.786061, BCE loss: 0.529209, SB loss: 0.723054
2023-10-30 16:33:09,138 Epoch: [299/484] Iter:[50/495], Time: 0.41, lr: [0.004206106444886835], Loss: 2.011772, Acc:0.806244, Semantic loss: 0.768020, BCE loss: 0.528234, SB loss: 0.715518
2023-10-30 16:33:12,787 Epoch: [299/484] Iter:[60/495], Time: 0.40, lr: [0.004205692840245332], Loss: 1.991401, Acc:0.803537, Semantic loss: 0.757078, BCE loss: 0.524596, SB loss: 0.709727
2023-10-30 16:33:16,409 Epoch: [299/484] Iter:[70/495], Time: 0.40, lr: [0.004205279231084278], Loss: 2.004188, Acc:0.801546, Semantic loss: 0.754086, BCE loss: 0.531562, SB loss: 0.718540
2023-10-30 16:33:20,238 Epoch: [299/484] Iter:[80/495], Time: 0.40, lr: [0.004204865617403126], Loss: 1.997088, Acc:0.804774, Semantic loss: 0.746063, BCE loss: 0.535504, SB loss: 0.715521
2023-10-30 16:33:23,977 Epoch: [299/484] Iter:[90/495], Time: 0.39, lr: [0.004204451999201335], Loss: 1.993412, Acc:0.802401, Semantic loss: 0.742974, BCE loss: 0.535254, SB loss: 0.715185
2023-10-30 16:33:27,748 Epoch: [299/484] Iter:[100/495], Time: 0.39, lr: [0.00420403837647836], Loss: 1.990024, Acc:0.800868, Semantic loss: 0.742266, BCE loss: 0.531335, SB loss: 0.716422
2023-10-30 16:33:31,383 Epoch: [299/484] Iter:[110/495], Time: 0.39, lr: [0.004203624749233659], Loss: 2.001756, Acc:0.805388, Semantic loss: 0.746415, BCE loss: 0.537626, SB loss: 0.717714
2023-10-30 16:33:35,065 Epoch: [299/484] Iter:[120/495], Time: 0.39, lr: [0.004203211117466686], Loss: 2.005877, Acc:0.805027, Semantic loss: 0.748584, BCE loss: 0.538559, SB loss: 0.718734
2023-10-30 16:33:38,754 Epoch: [299/484] Iter:[130/495], Time: 0.39, lr: [0.004202797481176899], Loss: 2.006612, Acc:0.802290, Semantic loss: 0.750329, BCE loss: 0.537041, SB loss: 0.719242
2023-10-30 16:33:42,521 Epoch: [299/484] Iter:[140/495], Time: 0.39, lr: [0.004202383840363752], Loss: 2.019010, Acc:0.803913, Semantic loss: 0.758333, BCE loss: 0.538526, SB loss: 0.722152
2023-10-30 16:33:46,157 Epoch: [299/484] Iter:[150/495], Time: 0.38, lr: [0.004201970195026703], Loss: 2.027263, Acc:0.801256, Semantic loss: 0.763058, BCE loss: 0.539968, SB loss: 0.724237
2023-10-30 16:33:49,850 Epoch: [299/484] Iter:[160/495], Time: 0.38, lr: [0.004201556545165207], Loss: 2.016145, Acc:0.800576, Semantic loss: 0.757920, BCE loss: 0.534859, SB loss: 0.723366
2023-10-30 16:33:53,665 Epoch: [299/484] Iter:[170/495], Time: 0.38, lr: [0.004201142890778719], Loss: 2.017560, Acc:0.798892, Semantic loss: 0.758382, BCE loss: 0.536704, SB loss: 0.722474
2023-10-30 16:33:57,395 Epoch: [299/484] Iter:[180/495], Time: 0.38, lr: [0.004200729231866693], Loss: 2.017517, Acc:0.798234, Semantic loss: 0.758841, BCE loss: 0.534115, SB loss: 0.724561
2023-10-30 16:34:01,084 Epoch: [299/484] Iter:[190/495], Time: 0.38, lr: [0.004200315568428587], Loss: 2.013548, Acc:0.799263, Semantic loss: 0.757809, BCE loss: 0.532879, SB loss: 0.722859
2023-10-30 16:34:04,932 Epoch: [299/484] Iter:[200/495], Time: 0.38, lr: [0.004199901900463855], Loss: 2.007900, Acc:0.801245, Semantic loss: 0.755293, BCE loss: 0.531556, SB loss: 0.721051
2023-10-30 16:34:08,690 Epoch: [299/484] Iter:[210/495], Time: 0.38, lr: [0.004199488227971953], Loss: 2.011326, Acc:0.802655, Semantic loss: 0.754647, BCE loss: 0.534950, SB loss: 0.721728
2023-10-30 16:34:12,486 Epoch: [299/484] Iter:[220/495], Time: 0.38, lr: [0.004199074550952335], Loss: 2.009289, Acc:0.803193, Semantic loss: 0.753975, BCE loss: 0.534107, SB loss: 0.721207
2023-10-30 16:34:16,151 Epoch: [299/484] Iter:[230/495], Time: 0.38, lr: [0.0041986608694044554], Loss: 2.019763, Acc:0.803424, Semantic loss: 0.757912, BCE loss: 0.538502, SB loss: 0.723348
2023-10-30 16:34:19,866 Epoch: [299/484] Iter:[240/495], Time: 0.38, lr: [0.00419824718332777], Loss: 2.020227, Acc:0.803562, Semantic loss: 0.757668, BCE loss: 0.539100, SB loss: 0.723459
2023-10-30 16:34:23,585 Epoch: [299/484] Iter:[250/495], Time: 0.38, lr: [0.004197833492721733], Loss: 2.018319, Acc:0.803456, Semantic loss: 0.756951, BCE loss: 0.537556, SB loss: 0.723812
2023-10-30 16:34:27,276 Epoch: [299/484] Iter:[260/495], Time: 0.38, lr: [0.004197419797585798], Loss: 2.022050, Acc:0.801586, Semantic loss: 0.759276, BCE loss: 0.537270, SB loss: 0.725504
2023-10-30 16:34:30,996 Epoch: [299/484] Iter:[270/495], Time: 0.38, lr: [0.00419700609791942], Loss: 2.021394, Acc:0.801123, Semantic loss: 0.758882, BCE loss: 0.536312, SB loss: 0.726200
2023-10-30 16:34:34,718 Epoch: [299/484] Iter:[280/495], Time: 0.38, lr: [0.004196592393722053], Loss: 2.017112, Acc:0.802683, Semantic loss: 0.755529, BCE loss: 0.536824, SB loss: 0.724759
2023-10-30 16:34:38,440 Epoch: [299/484] Iter:[290/495], Time: 0.38, lr: [0.0041961786849931525], Loss: 2.014796, Acc:0.803066, Semantic loss: 0.754361, BCE loss: 0.536358, SB loss: 0.724077
2023-10-30 16:34:42,219 Epoch: [299/484] Iter:[300/495], Time: 0.38, lr: [0.00419576497173217], Loss: 2.015417, Acc:0.802822, Semantic loss: 0.755922, BCE loss: 0.534933, SB loss: 0.724562
2023-10-30 16:34:45,898 Epoch: [299/484] Iter:[310/495], Time: 0.38, lr: [0.004195351253938561], Loss: 2.014929, Acc:0.802318, Semantic loss: 0.755636, BCE loss: 0.535025, SB loss: 0.724269
2023-10-30 16:34:49,620 Epoch: [299/484] Iter:[320/495], Time: 0.38, lr: [0.004194937531611779], Loss: 2.012409, Acc:0.801514, Semantic loss: 0.754441, BCE loss: 0.533772, SB loss: 0.724195
2023-10-30 16:34:53,317 Epoch: [299/484] Iter:[330/495], Time: 0.38, lr: [0.004194523804751277], Loss: 2.012506, Acc:0.800926, Semantic loss: 0.755736, BCE loss: 0.532930, SB loss: 0.723840
2023-10-30 16:34:56,928 Epoch: [299/484] Iter:[340/495], Time: 0.38, lr: [0.004194110073356508], Loss: 2.012638, Acc:0.801771, Semantic loss: 0.755361, BCE loss: 0.533671, SB loss: 0.723605
2023-10-30 16:35:00,657 Epoch: [299/484] Iter:[350/495], Time: 0.38, lr: [0.004193696337426927], Loss: 2.009224, Acc:0.801935, Semantic loss: 0.753045, BCE loss: 0.533032, SB loss: 0.723148
2023-10-30 16:35:04,441 Epoch: [299/484] Iter:[360/495], Time: 0.38, lr: [0.004193282596961986], Loss: 2.005330, Acc:0.802199, Semantic loss: 0.751810, BCE loss: 0.531734, SB loss: 0.721787
2023-10-30 16:35:08,190 Epoch: [299/484] Iter:[370/495], Time: 0.38, lr: [0.0041928688519611386], Loss: 2.009107, Acc:0.802179, Semantic loss: 0.754184, BCE loss: 0.531583, SB loss: 0.723340
2023-10-30 16:35:11,914 Epoch: [299/484] Iter:[380/495], Time: 0.38, lr: [0.004192455102423836], Loss: 2.004218, Acc:0.802261, Semantic loss: 0.751830, BCE loss: 0.530170, SB loss: 0.722218
2023-10-30 16:35:15,670 Epoch: [299/484] Iter:[390/495], Time: 0.38, lr: [0.004192041348349534], Loss: 2.006598, Acc:0.802415, Semantic loss: 0.752428, BCE loss: 0.531376, SB loss: 0.722793
2023-10-30 16:35:19,356 Epoch: [299/484] Iter:[400/495], Time: 0.38, lr: [0.004191627589737683], Loss: 2.003793, Acc:0.801912, Semantic loss: 0.751649, BCE loss: 0.530840, SB loss: 0.721304
2023-10-30 16:35:23,071 Epoch: [299/484] Iter:[410/495], Time: 0.38, lr: [0.004191213826587737], Loss: 2.002597, Acc:0.802942, Semantic loss: 0.751246, BCE loss: 0.530883, SB loss: 0.720468
2023-10-30 16:35:26,676 Epoch: [299/484] Iter:[420/495], Time: 0.38, lr: [0.004190800058899145], Loss: 2.000655, Acc:0.802887, Semantic loss: 0.750429, BCE loss: 0.529576, SB loss: 0.720650
2023-10-30 16:35:30,403 Epoch: [299/484] Iter:[430/495], Time: 0.38, lr: [0.0041903862866713645], Loss: 2.001744, Acc:0.802931, Semantic loss: 0.750956, BCE loss: 0.529044, SB loss: 0.721744
2023-10-30 16:35:34,105 Epoch: [299/484] Iter:[440/495], Time: 0.38, lr: [0.004189972509903845], Loss: 2.010652, Acc:0.803083, Semantic loss: 0.756428, BCE loss: 0.531038, SB loss: 0.723187
2023-10-30 16:35:37,799 Epoch: [299/484] Iter:[450/495], Time: 0.38, lr: [0.004189558728596038], Loss: 2.009537, Acc:0.803455, Semantic loss: 0.754826, BCE loss: 0.532411, SB loss: 0.722300
2023-10-30 16:35:41,562 Epoch: [299/484] Iter:[460/495], Time: 0.38, lr: [0.0041891449427473955], Loss: 2.010443, Acc:0.803520, Semantic loss: 0.755381, BCE loss: 0.533013, SB loss: 0.722049
2023-10-30 16:35:45,236 Epoch: [299/484] Iter:[470/495], Time: 0.38, lr: [0.004188731152357371], Loss: 2.009145, Acc:0.803979, Semantic loss: 0.753823, BCE loss: 0.533603, SB loss: 0.721719
2023-10-30 16:35:48,962 Epoch: [299/484] Iter:[480/495], Time: 0.38, lr: [0.004188317357425415], Loss: 2.007326, Acc:0.804122, Semantic loss: 0.753286, BCE loss: 0.533050, SB loss: 0.720990
2023-10-30 16:35:52,486 Epoch: [299/484] Iter:[490/495], Time: 0.38, lr: [0.0041879035579509795], Loss: 2.008642, Acc:0.804650, Semantic loss: 0.755183, BCE loss: 0.532351, SB loss: 0.721108
2023-10-30 16:35:53,889 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:35:54,122 Loss: 2.031, MeanIU:  0.7309, Best_mIoU:  0.7309
2023-10-30 16:35:54,122 [0.9772959  0.82635536 0.90529589 0.47965598 0.56144042 0.5828767
 0.66686121 0.73721483 0.90651799 0.6098917  0.93679499 0.79101592
 0.59104528 0.9369791  0.6992461  0.79994618 0.6587325  0.48996766
 0.7291839 ]
2023-10-30 16:35:56,086 Epoch: [300/484] Iter:[0/495], Time: 1.93, lr: [0.004187696656510159], Loss: 1.601563, Acc:0.907100, Semantic loss: 0.533430, BCE loss: 0.443702, SB loss: 0.624431
2023-10-30 16:36:00,110 Epoch: [300/484] Iter:[10/495], Time: 0.54, lr: [0.004187282850220975], Loss: 2.132118, Acc:0.810443, Semantic loss: 0.757174, BCE loss: 0.608134, SB loss: 0.766810
2023-10-30 16:36:03,910 Epoch: [300/484] Iter:[20/495], Time: 0.46, lr: [0.004186869039387939], Loss: 2.112475, Acc:0.813285, Semantic loss: 0.751131, BCE loss: 0.608574, SB loss: 0.752770
2023-10-30 16:36:07,596 Epoch: [300/484] Iter:[30/495], Time: 0.43, lr: [0.004186455224010502], Loss: 2.092779, Acc:0.817147, Semantic loss: 0.759312, BCE loss: 0.591812, SB loss: 0.741655
2023-10-30 16:36:11,323 Epoch: [300/484] Iter:[40/495], Time: 0.42, lr: [0.004186041404088116], Loss: 2.067111, Acc:0.810255, Semantic loss: 0.755518, BCE loss: 0.572523, SB loss: 0.739069
2023-10-30 16:36:14,958 Epoch: [300/484] Iter:[50/495], Time: 0.41, lr: [0.004185627579620231], Loss: 2.077571, Acc:0.807032, Semantic loss: 0.777112, BCE loss: 0.558163, SB loss: 0.742295
2023-10-30 16:36:18,614 Epoch: [300/484] Iter:[60/495], Time: 0.40, lr: [0.004185213750606299], Loss: 2.067758, Acc:0.805953, Semantic loss: 0.772282, BCE loss: 0.552824, SB loss: 0.742652
2023-10-30 16:36:22,270 Epoch: [300/484] Iter:[70/495], Time: 0.40, lr: [0.004184799917045769], Loss: 2.063155, Acc:0.806402, Semantic loss: 0.765297, BCE loss: 0.555333, SB loss: 0.742525
2023-10-30 16:36:25,932 Epoch: [300/484] Iter:[80/495], Time: 0.39, lr: [0.004184386078938091], Loss: 2.062784, Acc:0.805352, Semantic loss: 0.765516, BCE loss: 0.554732, SB loss: 0.742536
2023-10-30 16:36:29,606 Epoch: [300/484] Iter:[90/495], Time: 0.39, lr: [0.004183972236282718], Loss: 2.069442, Acc:0.800075, Semantic loss: 0.770462, BCE loss: 0.556219, SB loss: 0.742761
2023-10-30 16:36:33,408 Epoch: [300/484] Iter:[100/495], Time: 0.39, lr: [0.004183558389079099], Loss: 2.064766, Acc:0.802489, Semantic loss: 0.766999, BCE loss: 0.555084, SB loss: 0.742683
2023-10-30 16:36:37,093 Epoch: [300/484] Iter:[110/495], Time: 0.39, lr: [0.004183144537326684], Loss: 2.074580, Acc:0.800506, Semantic loss: 0.774275, BCE loss: 0.556570, SB loss: 0.743735
2023-10-30 16:36:40,673 Epoch: [300/484] Iter:[120/495], Time: 0.38, lr: [0.0041827306810249204], Loss: 2.056437, Acc:0.794632, Semantic loss: 0.768041, BCE loss: 0.548956, SB loss: 0.739440
2023-10-30 16:36:44,349 Epoch: [300/484] Iter:[130/495], Time: 0.38, lr: [0.004182316820173263], Loss: 2.056355, Acc:0.793782, Semantic loss: 0.769399, BCE loss: 0.545041, SB loss: 0.741915
2023-10-30 16:36:48,039 Epoch: [300/484] Iter:[140/495], Time: 0.38, lr: [0.0041819029547711575], Loss: 2.048958, Acc:0.796264, Semantic loss: 0.766033, BCE loss: 0.543628, SB loss: 0.739297
2023-10-30 16:36:51,913 Epoch: [300/484] Iter:[150/495], Time: 0.38, lr: [0.004181489084818055], Loss: 2.051663, Acc:0.797363, Semantic loss: 0.768018, BCE loss: 0.544987, SB loss: 0.738657
2023-10-30 16:36:55,643 Epoch: [300/484] Iter:[160/495], Time: 0.38, lr: [0.004181075210313405], Loss: 2.043419, Acc:0.799449, Semantic loss: 0.765281, BCE loss: 0.542470, SB loss: 0.735668
2023-10-30 16:36:59,433 Epoch: [300/484] Iter:[170/495], Time: 0.38, lr: [0.004180661331256656], Loss: 2.033495, Acc:0.798129, Semantic loss: 0.761225, BCE loss: 0.538075, SB loss: 0.734194
2023-10-30 16:37:03,155 Epoch: [300/484] Iter:[180/495], Time: 0.38, lr: [0.004180247447647259], Loss: 2.024688, Acc:0.797861, Semantic loss: 0.754087, BCE loss: 0.538722, SB loss: 0.731879
2023-10-30 16:37:06,864 Epoch: [300/484] Iter:[190/495], Time: 0.38, lr: [0.004179833559484662], Loss: 2.022763, Acc:0.796920, Semantic loss: 0.753033, BCE loss: 0.538773, SB loss: 0.730957
2023-10-30 16:37:10,533 Epoch: [300/484] Iter:[200/495], Time: 0.38, lr: [0.004179419666768313], Loss: 2.017778, Acc:0.796895, Semantic loss: 0.753732, BCE loss: 0.533939, SB loss: 0.730108
2023-10-30 16:37:14,227 Epoch: [300/484] Iter:[210/495], Time: 0.38, lr: [0.004179005769497662], Loss: 2.019712, Acc:0.795831, Semantic loss: 0.753978, BCE loss: 0.535214, SB loss: 0.730521
2023-10-30 16:37:17,926 Epoch: [300/484] Iter:[220/495], Time: 0.38, lr: [0.004178591867672158], Loss: 2.021803, Acc:0.795162, Semantic loss: 0.756381, BCE loss: 0.533089, SB loss: 0.732332
2023-10-30 16:37:21,783 Epoch: [300/484] Iter:[230/495], Time: 0.38, lr: [0.004178177961291249], Loss: 2.021658, Acc:0.796556, Semantic loss: 0.755524, BCE loss: 0.533980, SB loss: 0.732154
2023-10-30 16:37:25,507 Epoch: [300/484] Iter:[240/495], Time: 0.38, lr: [0.004177764050354381], Loss: 2.017090, Acc:0.798416, Semantic loss: 0.753391, BCE loss: 0.533518, SB loss: 0.730181
2023-10-30 16:37:29,194 Epoch: [300/484] Iter:[250/495], Time: 0.38, lr: [0.004177350134861007], Loss: 2.017692, Acc:0.798726, Semantic loss: 0.752688, BCE loss: 0.534824, SB loss: 0.730180
2023-10-30 16:37:32,906 Epoch: [300/484] Iter:[260/495], Time: 0.38, lr: [0.004176936214810572], Loss: 2.019800, Acc:0.798335, Semantic loss: 0.753273, BCE loss: 0.536910, SB loss: 0.729616
2023-10-30 16:37:36,586 Epoch: [300/484] Iter:[270/495], Time: 0.38, lr: [0.004176522290202525], Loss: 2.017229, Acc:0.797750, Semantic loss: 0.753011, BCE loss: 0.533867, SB loss: 0.730352
2023-10-30 16:37:40,395 Epoch: [300/484] Iter:[280/495], Time: 0.38, lr: [0.004176108361036314], Loss: 2.021233, Acc:0.798557, Semantic loss: 0.755901, BCE loss: 0.534550, SB loss: 0.730782
2023-10-30 16:37:44,175 Epoch: [300/484] Iter:[290/495], Time: 0.38, lr: [0.0041756944273113866], Loss: 2.018336, Acc:0.797838, Semantic loss: 0.755458, BCE loss: 0.532734, SB loss: 0.730144
2023-10-30 16:37:47,861 Epoch: [300/484] Iter:[300/495], Time: 0.38, lr: [0.004175280489027191], Loss: 2.017972, Acc:0.797806, Semantic loss: 0.755817, BCE loss: 0.531538, SB loss: 0.730618
2023-10-30 16:37:51,564 Epoch: [300/484] Iter:[310/495], Time: 0.38, lr: [0.004174866546183174], Loss: 2.015898, Acc:0.797485, Semantic loss: 0.754789, BCE loss: 0.531082, SB loss: 0.730027
2023-10-30 16:37:55,230 Epoch: [300/484] Iter:[320/495], Time: 0.38, lr: [0.004174452598778782], Loss: 2.016905, Acc:0.798286, Semantic loss: 0.755608, BCE loss: 0.531314, SB loss: 0.729983
2023-10-30 16:37:58,907 Epoch: [300/484] Iter:[330/495], Time: 0.38, lr: [0.004174038646813465], Loss: 2.013760, Acc:0.796565, Semantic loss: 0.754694, BCE loss: 0.529675, SB loss: 0.729391
2023-10-30 16:38:02,560 Epoch: [300/484] Iter:[340/495], Time: 0.38, lr: [0.004173624690286669], Loss: 2.012196, Acc:0.796653, Semantic loss: 0.754180, BCE loss: 0.528784, SB loss: 0.729232
2023-10-30 16:38:06,306 Epoch: [300/484] Iter:[350/495], Time: 0.38, lr: [0.004173210729197839], Loss: 2.014218, Acc:0.796812, Semantic loss: 0.755838, BCE loss: 0.529641, SB loss: 0.728740
2023-10-30 16:38:10,080 Epoch: [300/484] Iter:[360/495], Time: 0.38, lr: [0.004172796763546424], Loss: 2.013734, Acc:0.796676, Semantic loss: 0.754818, BCE loss: 0.530445, SB loss: 0.728470
2023-10-30 16:38:13,965 Epoch: [300/484] Iter:[370/495], Time: 0.38, lr: [0.004172382793331871], Loss: 2.014575, Acc:0.796756, Semantic loss: 0.753722, BCE loss: 0.532061, SB loss: 0.728791
2023-10-30 16:38:17,641 Epoch: [300/484] Iter:[380/495], Time: 0.38, lr: [0.004171968818553627], Loss: 2.014623, Acc:0.797404, Semantic loss: 0.754324, BCE loss: 0.531565, SB loss: 0.728735
2023-10-30 16:38:21,399 Epoch: [300/484] Iter:[390/495], Time: 0.38, lr: [0.004171554839211137], Loss: 2.016059, Acc:0.797359, Semantic loss: 0.756466, BCE loss: 0.530781, SB loss: 0.728813
2023-10-30 16:38:25,105 Epoch: [300/484] Iter:[400/495], Time: 0.38, lr: [0.004171140855303846], Loss: 2.016160, Acc:0.797265, Semantic loss: 0.755873, BCE loss: 0.530996, SB loss: 0.729291
2023-10-30 16:38:28,962 Epoch: [300/484] Iter:[410/495], Time: 0.38, lr: [0.0041707268668312045], Loss: 2.016029, Acc:0.796964, Semantic loss: 0.756431, BCE loss: 0.530404, SB loss: 0.729194
2023-10-30 16:38:32,742 Epoch: [300/484] Iter:[420/495], Time: 0.38, lr: [0.004170312873792656], Loss: 2.019130, Acc:0.798208, Semantic loss: 0.758137, BCE loss: 0.531587, SB loss: 0.729406
2023-10-30 16:38:36,489 Epoch: [300/484] Iter:[430/495], Time: 0.38, lr: [0.004169898876187646], Loss: 2.019233, Acc:0.799282, Semantic loss: 0.758165, BCE loss: 0.531371, SB loss: 0.729696
2023-10-30 16:38:40,357 Epoch: [300/484] Iter:[440/495], Time: 0.38, lr: [0.004169484874015621], Loss: 2.020198, Acc:0.799161, Semantic loss: 0.759177, BCE loss: 0.530608, SB loss: 0.730413
2023-10-30 16:38:44,231 Epoch: [300/484] Iter:[450/495], Time: 0.38, lr: [0.004169070867276028], Loss: 2.020250, Acc:0.799878, Semantic loss: 0.758806, BCE loss: 0.531390, SB loss: 0.730053
2023-10-30 16:38:47,941 Epoch: [300/484] Iter:[460/495], Time: 0.38, lr: [0.004168656855968312], Loss: 2.017804, Acc:0.800407, Semantic loss: 0.757511, BCE loss: 0.531008, SB loss: 0.729285
2023-10-30 16:38:51,644 Epoch: [300/484] Iter:[470/495], Time: 0.38, lr: [0.004168242840091916], Loss: 2.021848, Acc:0.800769, Semantic loss: 0.759044, BCE loss: 0.532599, SB loss: 0.730205
2023-10-30 16:38:55,411 Epoch: [300/484] Iter:[480/495], Time: 0.38, lr: [0.004167828819646289], Loss: 2.020422, Acc:0.801050, Semantic loss: 0.758332, BCE loss: 0.532018, SB loss: 0.730072
2023-10-30 16:38:58,907 Epoch: [300/484] Iter:[490/495], Time: 0.38, lr: [0.004167414794630875], Loss: 2.024081, Acc:0.801120, Semantic loss: 0.760867, BCE loss: 0.533321, SB loss: 0.729892
2023-10-30 16:41:56,449 0 [0.94394439 0.67973806 0.83268648 0.17504403 0.25785739 0.42918163
 0.47988598 0.59514469 0.88779244 0.47721467 0.84975829 0.59577355
 0.0183642  0.81786061 0.00182738 0.16061429 0.07799574 0.06312701
 0.61430445] 0.4714797516394481
2023-10-30 16:41:56,449 1 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439] 0.7004764308803993
2023-10-30 16:41:56,453 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:41:56,705 Loss: 1.998, MeanIU:  0.7005, Best_mIoU:  0.7309
2023-10-30 16:41:56,705 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439]
2023-10-30 16:41:58,545 Epoch: [301/484] Iter:[0/495], Time: 1.80, lr: [0.004167207780409325], Loss: 1.437704, Acc:0.733286, Semantic loss: 0.545628, BCE loss: 0.289103, SB loss: 0.602973
2023-10-30 16:42:02,404 Epoch: [301/484] Iter:[10/495], Time: 0.51, lr: [0.004166793748538188], Loss: 1.909593, Acc:0.802331, Semantic loss: 0.675846, BCE loss: 0.539169, SB loss: 0.694577
2023-10-30 16:42:06,042 Epoch: [301/484] Iter:[20/495], Time: 0.44, lr: [0.004166379712095877], Loss: 1.938421, Acc:0.809432, Semantic loss: 0.706492, BCE loss: 0.517606, SB loss: 0.714322
2023-10-30 16:42:09,469 Epoch: [301/484] Iter:[30/495], Time: 0.41, lr: [0.004165965671081836], Loss: 1.930253, Acc:0.806389, Semantic loss: 0.706536, BCE loss: 0.514668, SB loss: 0.709050
2023-10-30 16:42:13,078 Epoch: [301/484] Iter:[40/495], Time: 0.40, lr: [0.00416555162549551], Loss: 2.028465, Acc:0.806303, Semantic loss: 0.772426, BCE loss: 0.521630, SB loss: 0.734409
2023-10-30 16:42:16,649 Epoch: [301/484] Iter:[50/495], Time: 0.39, lr: [0.004165137575336344], Loss: 2.036710, Acc:0.809082, Semantic loss: 0.764834, BCE loss: 0.534130, SB loss: 0.737745
2023-10-30 16:42:20,303 Epoch: [301/484] Iter:[60/495], Time: 0.39, lr: [0.004164723520603779], Loss: 2.020072, Acc:0.806438, Semantic loss: 0.759604, BCE loss: 0.523139, SB loss: 0.737329
2023-10-30 16:42:23,855 Epoch: [301/484] Iter:[70/495], Time: 0.38, lr: [0.004164309461297264], Loss: 2.045282, Acc:0.809995, Semantic loss: 0.769833, BCE loss: 0.534643, SB loss: 0.740807
2023-10-30 16:42:27,432 Epoch: [301/484] Iter:[80/495], Time: 0.38, lr: [0.0041638953974162405], Loss: 2.029475, Acc:0.808053, Semantic loss: 0.760613, BCE loss: 0.527096, SB loss: 0.741765
2023-10-30 16:42:31,031 Epoch: [301/484] Iter:[90/495], Time: 0.38, lr: [0.004163481328960153], Loss: 2.034743, Acc:0.805343, Semantic loss: 0.763675, BCE loss: 0.525828, SB loss: 0.745240
2023-10-30 16:42:34,664 Epoch: [301/484] Iter:[100/495], Time: 0.38, lr: [0.0041630672559284446], Loss: 2.037355, Acc:0.807767, Semantic loss: 0.763169, BCE loss: 0.530165, SB loss: 0.744022
2023-10-30 16:42:38,231 Epoch: [301/484] Iter:[110/495], Time: 0.37, lr: [0.00416265317832056], Loss: 2.056912, Acc:0.805925, Semantic loss: 0.773859, BCE loss: 0.535967, SB loss: 0.747085
2023-10-30 16:42:41,876 Epoch: [301/484] Iter:[120/495], Time: 0.37, lr: [0.004162239096135944], Loss: 2.043775, Acc:0.804856, Semantic loss: 0.769018, BCE loss: 0.528839, SB loss: 0.745917
2023-10-30 16:42:45,407 Epoch: [301/484] Iter:[130/495], Time: 0.37, lr: [0.004161825009374038], Loss: 2.042011, Acc:0.802638, Semantic loss: 0.766695, BCE loss: 0.529545, SB loss: 0.745771
2023-10-30 16:42:49,100 Epoch: [301/484] Iter:[140/495], Time: 0.37, lr: [0.004161410918034285], Loss: 2.034898, Acc:0.804309, Semantic loss: 0.763299, BCE loss: 0.527105, SB loss: 0.744493
2023-10-30 16:42:52,769 Epoch: [301/484] Iter:[150/495], Time: 0.37, lr: [0.0041609968221161305], Loss: 2.038435, Acc:0.804867, Semantic loss: 0.765759, BCE loss: 0.527895, SB loss: 0.744781
2023-10-30 16:42:56,470 Epoch: [301/484] Iter:[160/495], Time: 0.37, lr: [0.004160582721619016], Loss: 2.030426, Acc:0.807519, Semantic loss: 0.759043, BCE loss: 0.530032, SB loss: 0.741351
2023-10-30 16:43:00,065 Epoch: [301/484] Iter:[170/495], Time: 0.37, lr: [0.004160168616542385], Loss: 2.037223, Acc:0.806873, Semantic loss: 0.761269, BCE loss: 0.533651, SB loss: 0.742304
2023-10-30 16:43:03,658 Epoch: [301/484] Iter:[180/495], Time: 0.37, lr: [0.004159754506885679], Loss: 2.038467, Acc:0.804866, Semantic loss: 0.762792, BCE loss: 0.532267, SB loss: 0.743408
2023-10-30 16:43:07,211 Epoch: [301/484] Iter:[190/495], Time: 0.37, lr: [0.0041593403926483445], Loss: 2.026841, Acc:0.804950, Semantic loss: 0.756129, BCE loss: 0.530982, SB loss: 0.739730
2023-10-30 16:43:10,763 Epoch: [301/484] Iter:[200/495], Time: 0.37, lr: [0.00415892627382982], Loss: 2.024184, Acc:0.803373, Semantic loss: 0.755201, BCE loss: 0.529474, SB loss: 0.739508
2023-10-30 16:43:14,403 Epoch: [301/484] Iter:[210/495], Time: 0.37, lr: [0.00415851215042955], Loss: 2.025197, Acc:0.803873, Semantic loss: 0.757469, BCE loss: 0.529251, SB loss: 0.738478
2023-10-30 16:43:17,973 Epoch: [301/484] Iter:[220/495], Time: 0.37, lr: [0.0041580980224469755], Loss: 2.024814, Acc:0.804652, Semantic loss: 0.757730, BCE loss: 0.529363, SB loss: 0.737720
2023-10-30 16:43:21,607 Epoch: [301/484] Iter:[230/495], Time: 0.37, lr: [0.0041576838898815405], Loss: 2.024704, Acc:0.803024, Semantic loss: 0.759092, BCE loss: 0.527464, SB loss: 0.738149
2023-10-30 16:43:25,300 Epoch: [301/484] Iter:[240/495], Time: 0.37, lr: [0.004157269752732686], Loss: 2.020671, Acc:0.802932, Semantic loss: 0.757774, BCE loss: 0.525748, SB loss: 0.737150
2023-10-30 16:43:28,961 Epoch: [301/484] Iter:[250/495], Time: 0.37, lr: [0.004156855610999853], Loss: 2.023521, Acc:0.803775, Semantic loss: 0.758586, BCE loss: 0.527619, SB loss: 0.737316
2023-10-30 16:43:32,496 Epoch: [301/484] Iter:[260/495], Time: 0.37, lr: [0.0041564414646824855], Loss: 2.026170, Acc:0.803392, Semantic loss: 0.759679, BCE loss: 0.529726, SB loss: 0.736765
2023-10-30 16:43:36,205 Epoch: [301/484] Iter:[270/495], Time: 0.37, lr: [0.004156027313780024], Loss: 2.023207, Acc:0.804233, Semantic loss: 0.758270, BCE loss: 0.529135, SB loss: 0.735801
2023-10-30 16:43:39,789 Epoch: [301/484] Iter:[280/495], Time: 0.37, lr: [0.004155613158291911], Loss: 2.023679, Acc:0.804410, Semantic loss: 0.758477, BCE loss: 0.529158, SB loss: 0.736044
2023-10-30 16:43:43,443 Epoch: [301/484] Iter:[290/495], Time: 0.37, lr: [0.004155198998217585], Loss: 2.017688, Acc:0.805610, Semantic loss: 0.756524, BCE loss: 0.527568, SB loss: 0.733597
2023-10-30 16:43:47,073 Epoch: [301/484] Iter:[300/495], Time: 0.37, lr: [0.00415478483355649], Loss: 2.016160, Acc:0.805365, Semantic loss: 0.755751, BCE loss: 0.528184, SB loss: 0.732226
2023-10-30 16:43:50,689 Epoch: [301/484] Iter:[310/495], Time: 0.37, lr: [0.004154370664308067], Loss: 2.013979, Acc:0.805129, Semantic loss: 0.754921, BCE loss: 0.527102, SB loss: 0.731956
2023-10-30 16:43:54,428 Epoch: [301/484] Iter:[320/495], Time: 0.37, lr: [0.004153956490471756], Loss: 2.018427, Acc:0.804511, Semantic loss: 0.755797, BCE loss: 0.530090, SB loss: 0.732539
2023-10-30 16:43:58,057 Epoch: [301/484] Iter:[330/495], Time: 0.37, lr: [0.004153542312046998], Loss: 2.020659, Acc:0.804405, Semantic loss: 0.756862, BCE loss: 0.529889, SB loss: 0.733908
2023-10-30 16:44:01,743 Epoch: [301/484] Iter:[340/495], Time: 0.37, lr: [0.004153128129033235], Loss: 2.027019, Acc:0.804505, Semantic loss: 0.761552, BCE loss: 0.531113, SB loss: 0.734353
2023-10-30 16:44:05,400 Epoch: [301/484] Iter:[350/495], Time: 0.37, lr: [0.004152713941429908], Loss: 2.029727, Acc:0.804309, Semantic loss: 0.763085, BCE loss: 0.531600, SB loss: 0.735042
2023-10-30 16:44:09,023 Epoch: [301/484] Iter:[360/495], Time: 0.37, lr: [0.004152299749236454], Loss: 2.028721, Acc:0.803641, Semantic loss: 0.761888, BCE loss: 0.531779, SB loss: 0.735055
2023-10-30 16:44:12,669 Epoch: [301/484] Iter:[370/495], Time: 0.37, lr: [0.004151885552452317], Loss: 2.029804, Acc:0.803688, Semantic loss: 0.762244, BCE loss: 0.532396, SB loss: 0.735164
2023-10-30 16:44:16,356 Epoch: [301/484] Iter:[380/495], Time: 0.37, lr: [0.004151471351076935], Loss: 2.031444, Acc:0.804179, Semantic loss: 0.762533, BCE loss: 0.533972, SB loss: 0.734939
2023-10-30 16:44:20,209 Epoch: [301/484] Iter:[390/495], Time: 0.37, lr: [0.00415105714510975], Loss: 2.032847, Acc:0.803668, Semantic loss: 0.764268, BCE loss: 0.533310, SB loss: 0.735269
2023-10-30 16:44:23,891 Epoch: [301/484] Iter:[400/495], Time: 0.37, lr: [0.0041506429345502015], Loss: 2.033641, Acc:0.804122, Semantic loss: 0.763636, BCE loss: 0.534662, SB loss: 0.735343
2023-10-30 16:44:27,563 Epoch: [301/484] Iter:[410/495], Time: 0.37, lr: [0.004150228719397727], Loss: 2.035087, Acc:0.804058, Semantic loss: 0.764041, BCE loss: 0.536201, SB loss: 0.734845
2023-10-30 16:44:31,280 Epoch: [301/484] Iter:[420/495], Time: 0.37, lr: [0.00414981449965177], Loss: 2.034183, Acc:0.804085, Semantic loss: 0.762698, BCE loss: 0.536898, SB loss: 0.734586
2023-10-30 16:44:34,939 Epoch: [301/484] Iter:[430/495], Time: 0.37, lr: [0.004149400275311768], Loss: 2.036665, Acc:0.804287, Semantic loss: 0.763883, BCE loss: 0.537562, SB loss: 0.735219
2023-10-30 16:44:38,505 Epoch: [301/484] Iter:[440/495], Time: 0.37, lr: [0.00414898604637716], Loss: 2.033490, Acc:0.804505, Semantic loss: 0.762680, BCE loss: 0.536239, SB loss: 0.734571
2023-10-30 16:44:42,166 Epoch: [301/484] Iter:[450/495], Time: 0.37, lr: [0.004148571812847387], Loss: 2.036150, Acc:0.803875, Semantic loss: 0.764825, BCE loss: 0.536082, SB loss: 0.735244
2023-10-30 16:44:45,789 Epoch: [301/484] Iter:[460/495], Time: 0.37, lr: [0.004148157574721886], Loss: 2.034399, Acc:0.802761, Semantic loss: 0.764127, BCE loss: 0.535202, SB loss: 0.735070
2023-10-30 16:44:49,506 Epoch: [301/484] Iter:[470/495], Time: 0.37, lr: [0.004147743332000099], Loss: 2.035341, Acc:0.803108, Semantic loss: 0.764187, BCE loss: 0.535601, SB loss: 0.735553
2023-10-30 16:44:53,237 Epoch: [301/484] Iter:[480/495], Time: 0.37, lr: [0.004147329084681462], Loss: 2.035325, Acc:0.802679, Semantic loss: 0.763992, BCE loss: 0.536068, SB loss: 0.735265
2023-10-30 16:44:56,752 Epoch: [301/484] Iter:[490/495], Time: 0.37, lr: [0.004146914832765415], Loss: 2.034628, Acc:0.802926, Semantic loss: 0.764232, BCE loss: 0.535580, SB loss: 0.734816
2023-10-30 16:44:58,154 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:44:58,393 Loss: 1.998, MeanIU:  0.7005, Best_mIoU:  0.7309
2023-10-30 16:44:58,393 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439]
2023-10-30 16:45:00,621 Epoch: [302/484] Iter:[0/495], Time: 2.19, lr: [0.004146707705083188], Loss: 2.158874, Acc:0.858729, Semantic loss: 0.848375, BCE loss: 0.490614, SB loss: 0.819885
2023-10-30 16:45:04,481 Epoch: [302/484] Iter:[10/495], Time: 0.55, lr: [0.004146293446269974], Loss: 2.308802, Acc:0.828484, Semantic loss: 0.973646, BCE loss: 0.556017, SB loss: 0.779139
2023-10-30 16:45:08,277 Epoch: [302/484] Iter:[20/495], Time: 0.47, lr: [0.004145879182857947], Loss: 2.154629, Acc:0.792432, Semantic loss: 0.861564, BCE loss: 0.537263, SB loss: 0.755802
2023-10-30 16:45:12,099 Epoch: [302/484] Iter:[30/495], Time: 0.44, lr: [0.0041454649148465455], Loss: 2.094322, Acc:0.799979, Semantic loss: 0.834925, BCE loss: 0.521611, SB loss: 0.737786
2023-10-30 16:45:15,833 Epoch: [302/484] Iter:[40/495], Time: 0.42, lr: [0.004145050642235205], Loss: 2.060548, Acc:0.805704, Semantic loss: 0.809897, BCE loss: 0.517693, SB loss: 0.732958
2023-10-30 16:45:19,521 Epoch: [302/484] Iter:[50/495], Time: 0.41, lr: [0.004144636365023368], Loss: 2.078570, Acc:0.800642, Semantic loss: 0.824443, BCE loss: 0.516737, SB loss: 0.737390
2023-10-30 16:45:23,395 Epoch: [302/484] Iter:[60/495], Time: 0.41, lr: [0.004144222083210468], Loss: 2.069709, Acc:0.796358, Semantic loss: 0.809462, BCE loss: 0.527102, SB loss: 0.733146
2023-10-30 16:45:27,067 Epoch: [302/484] Iter:[70/495], Time: 0.40, lr: [0.004143807796795947], Loss: 2.055195, Acc:0.797940, Semantic loss: 0.792748, BCE loss: 0.530695, SB loss: 0.731751
2023-10-30 16:45:30,736 Epoch: [302/484] Iter:[80/495], Time: 0.40, lr: [0.00414339350577924], Loss: 2.035897, Acc:0.795330, Semantic loss: 0.777928, BCE loss: 0.529045, SB loss: 0.728925
2023-10-30 16:45:34,528 Epoch: [302/484] Iter:[90/495], Time: 0.40, lr: [0.004142979210159786], Loss: 2.031193, Acc:0.798494, Semantic loss: 0.773329, BCE loss: 0.530573, SB loss: 0.727291
2023-10-30 16:45:38,223 Epoch: [302/484] Iter:[100/495], Time: 0.39, lr: [0.004142564909937021], Loss: 2.023471, Acc:0.798190, Semantic loss: 0.769691, BCE loss: 0.526178, SB loss: 0.727602
2023-10-30 16:45:41,795 Epoch: [302/484] Iter:[110/495], Time: 0.39, lr: [0.004142150605110383], Loss: 2.016378, Acc:0.799468, Semantic loss: 0.768075, BCE loss: 0.518819, SB loss: 0.729484
2023-10-30 16:45:45,603 Epoch: [302/484] Iter:[120/495], Time: 0.39, lr: [0.004141736295679309], Loss: 2.021182, Acc:0.800826, Semantic loss: 0.768828, BCE loss: 0.524011, SB loss: 0.728343
2023-10-30 16:45:49,318 Epoch: [302/484] Iter:[130/495], Time: 0.39, lr: [0.004141321981643237], Loss: 2.018517, Acc:0.801656, Semantic loss: 0.766339, BCE loss: 0.524918, SB loss: 0.727261
2023-10-30 16:45:53,018 Epoch: [302/484] Iter:[140/495], Time: 0.39, lr: [0.004140907663001603], Loss: 2.018037, Acc:0.801987, Semantic loss: 0.762666, BCE loss: 0.528884, SB loss: 0.726487
2023-10-30 16:45:56,656 Epoch: [302/484] Iter:[150/495], Time: 0.39, lr: [0.004140493339753843], Loss: 2.010015, Acc:0.800501, Semantic loss: 0.759690, BCE loss: 0.524028, SB loss: 0.726298
2023-10-30 16:46:00,298 Epoch: [302/484] Iter:[160/495], Time: 0.38, lr: [0.004140079011899396], Loss: 2.003775, Acc:0.800730, Semantic loss: 0.757397, BCE loss: 0.521550, SB loss: 0.724828
2023-10-30 16:46:03,974 Epoch: [302/484] Iter:[170/495], Time: 0.38, lr: [0.004139664679437697], Loss: 1.999695, Acc:0.800888, Semantic loss: 0.754005, BCE loss: 0.521697, SB loss: 0.723993
2023-10-30 16:46:07,871 Epoch: [302/484] Iter:[180/495], Time: 0.38, lr: [0.004139250342368183], Loss: 2.000173, Acc:0.800523, Semantic loss: 0.752700, BCE loss: 0.523642, SB loss: 0.723831
2023-10-30 16:46:11,602 Epoch: [302/484] Iter:[190/495], Time: 0.38, lr: [0.004138836000690287], Loss: 1.998916, Acc:0.801471, Semantic loss: 0.754241, BCE loss: 0.521723, SB loss: 0.722952
2023-10-30 16:46:15,262 Epoch: [302/484] Iter:[200/495], Time: 0.38, lr: [0.0041384216544034505], Loss: 1.995680, Acc:0.799638, Semantic loss: 0.753154, BCE loss: 0.519452, SB loss: 0.723074
2023-10-30 16:46:18,914 Epoch: [302/484] Iter:[210/495], Time: 0.38, lr: [0.004138007303507107], Loss: 1.995023, Acc:0.800267, Semantic loss: 0.752423, BCE loss: 0.520148, SB loss: 0.722451
2023-10-30 16:46:22,633 Epoch: [302/484] Iter:[220/495], Time: 0.38, lr: [0.004137592948000692], Loss: 1.994608, Acc:0.801555, Semantic loss: 0.752675, BCE loss: 0.519147, SB loss: 0.722786
2023-10-30 16:46:26,281 Epoch: [302/484] Iter:[230/495], Time: 0.38, lr: [0.00413717858788364], Loss: 1.995140, Acc:0.800720, Semantic loss: 0.752116, BCE loss: 0.519381, SB loss: 0.723643
2023-10-30 16:46:29,952 Epoch: [302/484] Iter:[240/495], Time: 0.38, lr: [0.004136764223155389], Loss: 1.995307, Acc:0.800183, Semantic loss: 0.752332, BCE loss: 0.518677, SB loss: 0.724297
2023-10-30 16:46:33,722 Epoch: [302/484] Iter:[250/495], Time: 0.38, lr: [0.004136349853815375], Loss: 1.992140, Acc:0.801228, Semantic loss: 0.750234, BCE loss: 0.518384, SB loss: 0.723522
2023-10-30 16:46:37,505 Epoch: [302/484] Iter:[260/495], Time: 0.38, lr: [0.004135935479863031], Loss: 1.992632, Acc:0.800985, Semantic loss: 0.752788, BCE loss: 0.517615, SB loss: 0.722229
2023-10-30 16:46:41,321 Epoch: [302/484] Iter:[270/495], Time: 0.38, lr: [0.004135521101297792], Loss: 1.993980, Acc:0.801872, Semantic loss: 0.752448, BCE loss: 0.518972, SB loss: 0.722560
2023-10-30 16:46:45,040 Epoch: [302/484] Iter:[280/495], Time: 0.38, lr: [0.004135106718119094], Loss: 1.996301, Acc:0.801929, Semantic loss: 0.752796, BCE loss: 0.521229, SB loss: 0.722276
2023-10-30 16:46:48,725 Epoch: [302/484] Iter:[290/495], Time: 0.38, lr: [0.004134692330326374], Loss: 1.993442, Acc:0.801045, Semantic loss: 0.750644, BCE loss: 0.521354, SB loss: 0.721443
2023-10-30 16:46:52,340 Epoch: [302/484] Iter:[300/495], Time: 0.38, lr: [0.004134277937919064], Loss: 1.993466, Acc:0.799872, Semantic loss: 0.750810, BCE loss: 0.521449, SB loss: 0.721208
2023-10-30 16:46:56,015 Epoch: [302/484] Iter:[310/495], Time: 0.38, lr: [0.004133863540896598], Loss: 1.987017, Acc:0.798819, Semantic loss: 0.748582, BCE loss: 0.518054, SB loss: 0.720382
2023-10-30 16:46:59,745 Epoch: [302/484] Iter:[320/495], Time: 0.38, lr: [0.004133449139258415], Loss: 1.986778, Acc:0.799954, Semantic loss: 0.748608, BCE loss: 0.517392, SB loss: 0.720778
2023-10-30 16:47:03,559 Epoch: [302/484] Iter:[330/495], Time: 0.38, lr: [0.004133034733003945], Loss: 1.988997, Acc:0.800307, Semantic loss: 0.750066, BCE loss: 0.516317, SB loss: 0.722613
2023-10-30 16:47:07,283 Epoch: [302/484] Iter:[340/495], Time: 0.38, lr: [0.0041326203221326244], Loss: 1.986387, Acc:0.800727, Semantic loss: 0.748775, BCE loss: 0.515886, SB loss: 0.721726
2023-10-30 16:47:10,948 Epoch: [302/484] Iter:[350/495], Time: 0.38, lr: [0.004132205906643885], Loss: 1.985421, Acc:0.801286, Semantic loss: 0.747349, BCE loss: 0.516447, SB loss: 0.721625
2023-10-30 16:47:14,682 Epoch: [302/484] Iter:[360/495], Time: 0.38, lr: [0.004131791486537164], Loss: 1.984661, Acc:0.801165, Semantic loss: 0.746504, BCE loss: 0.517472, SB loss: 0.720686
2023-10-30 16:47:18,344 Epoch: [302/484] Iter:[370/495], Time: 0.38, lr: [0.004131377061811894], Loss: 1.988212, Acc:0.801400, Semantic loss: 0.747957, BCE loss: 0.519487, SB loss: 0.720768
2023-10-30 16:47:22,076 Epoch: [302/484] Iter:[380/495], Time: 0.38, lr: [0.004130962632467509], Loss: 1.984457, Acc:0.802640, Semantic loss: 0.745487, BCE loss: 0.519255, SB loss: 0.719716
2023-10-30 16:47:25,692 Epoch: [302/484] Iter:[390/495], Time: 0.38, lr: [0.004130548198503441], Loss: 1.985473, Acc:0.802138, Semantic loss: 0.746965, BCE loss: 0.518624, SB loss: 0.719885
2023-10-30 16:47:29,472 Epoch: [302/484] Iter:[400/495], Time: 0.38, lr: [0.004130133759919124], Loss: 1.986475, Acc:0.801587, Semantic loss: 0.746832, BCE loss: 0.519126, SB loss: 0.720517
2023-10-30 16:47:33,254 Epoch: [302/484] Iter:[410/495], Time: 0.38, lr: [0.004129719316713994], Loss: 1.989870, Acc:0.801130, Semantic loss: 0.748340, BCE loss: 0.519846, SB loss: 0.721684
2023-10-30 16:47:36,815 Epoch: [302/484] Iter:[420/495], Time: 0.38, lr: [0.004129304868887481], Loss: 1.992878, Acc:0.800767, Semantic loss: 0.748678, BCE loss: 0.521595, SB loss: 0.722605
2023-10-30 16:47:40,517 Epoch: [302/484] Iter:[430/495], Time: 0.38, lr: [0.004128890416439019], Loss: 1.994257, Acc:0.800527, Semantic loss: 0.749925, BCE loss: 0.522288, SB loss: 0.722044
2023-10-30 16:47:44,348 Epoch: [302/484] Iter:[440/495], Time: 0.38, lr: [0.004128475959368043], Loss: 1.993951, Acc:0.800798, Semantic loss: 0.748647, BCE loss: 0.523182, SB loss: 0.722122
2023-10-30 16:47:48,075 Epoch: [302/484] Iter:[450/495], Time: 0.38, lr: [0.0041280614976739825], Loss: 1.994436, Acc:0.800856, Semantic loss: 0.749476, BCE loss: 0.523514, SB loss: 0.721446
2023-10-30 16:47:51,709 Epoch: [302/484] Iter:[460/495], Time: 0.38, lr: [0.004127647031356273], Loss: 1.992780, Acc:0.800248, Semantic loss: 0.749639, BCE loss: 0.521642, SB loss: 0.721500
2023-10-30 16:47:55,294 Epoch: [302/484] Iter:[470/495], Time: 0.38, lr: [0.004127232560414344], Loss: 1.991239, Acc:0.800371, Semantic loss: 0.748712, BCE loss: 0.521380, SB loss: 0.721147
2023-10-30 16:47:58,941 Epoch: [302/484] Iter:[480/495], Time: 0.38, lr: [0.0041268180848476315], Loss: 1.991454, Acc:0.800546, Semantic loss: 0.748975, BCE loss: 0.521060, SB loss: 0.721419
2023-10-30 16:48:02,506 Epoch: [302/484] Iter:[490/495], Time: 0.37, lr: [0.004126403604655565], Loss: 1.989131, Acc:0.800255, Semantic loss: 0.747954, BCE loss: 0.520034, SB loss: 0.721143
2023-10-30 16:48:03,905 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:48:04,142 Loss: 1.998, MeanIU:  0.7005, Best_mIoU:  0.7309
2023-10-30 16:48:04,143 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439]
2023-10-30 16:48:06,275 Epoch: [303/484] Iter:[0/495], Time: 2.10, lr: [0.004126196362824848], Loss: 1.846428, Acc:0.777451, Semantic loss: 0.677600, BCE loss: 0.425963, SB loss: 0.742865
2023-10-30 16:48:10,264 Epoch: [303/484] Iter:[10/495], Time: 0.55, lr: [0.004125781875693686], Loss: 1.980898, Acc:0.800792, Semantic loss: 0.707276, BCE loss: 0.569309, SB loss: 0.704314
2023-10-30 16:48:14,024 Epoch: [303/484] Iter:[20/495], Time: 0.47, lr: [0.004125367383935753], Loss: 1.952080, Acc:0.808680, Semantic loss: 0.712457, BCE loss: 0.538312, SB loss: 0.701311
2023-10-30 16:48:17,704 Epoch: [303/484] Iter:[30/495], Time: 0.44, lr: [0.00412495288755048], Loss: 2.002531, Acc:0.807802, Semantic loss: 0.747768, BCE loss: 0.534340, SB loss: 0.720424
2023-10-30 16:48:21,453 Epoch: [303/484] Iter:[40/495], Time: 0.42, lr: [0.004124538386537296], Loss: 2.057071, Acc:0.805130, Semantic loss: 0.779845, BCE loss: 0.547614, SB loss: 0.729612
2023-10-30 16:48:25,170 Epoch: [303/484] Iter:[50/495], Time: 0.41, lr: [0.004124123880895634], Loss: 2.029033, Acc:0.800702, Semantic loss: 0.763017, BCE loss: 0.547029, SB loss: 0.718987
2023-10-30 16:48:28,824 Epoch: [303/484] Iter:[60/495], Time: 0.40, lr: [0.004123709370624926], Loss: 2.029125, Acc:0.806487, Semantic loss: 0.752708, BCE loss: 0.556187, SB loss: 0.720231
2023-10-30 16:48:32,648 Epoch: [303/484] Iter:[70/495], Time: 0.40, lr: [0.004123294855724604], Loss: 2.014233, Acc:0.804428, Semantic loss: 0.744798, BCE loss: 0.554991, SB loss: 0.714444
2023-10-30 16:48:36,364 Epoch: [303/484] Iter:[80/495], Time: 0.40, lr: [0.0041228803361940975], Loss: 2.011873, Acc:0.802633, Semantic loss: 0.740923, BCE loss: 0.553468, SB loss: 0.717481
2023-10-30 16:48:40,034 Epoch: [303/484] Iter:[90/495], Time: 0.39, lr: [0.0041224658120328364], Loss: 2.001842, Acc:0.802268, Semantic loss: 0.740495, BCE loss: 0.544599, SB loss: 0.716748
2023-10-30 16:48:43,681 Epoch: [303/484] Iter:[100/495], Time: 0.39, lr: [0.004122051283240256], Loss: 2.008530, Acc:0.798377, Semantic loss: 0.747566, BCE loss: 0.541424, SB loss: 0.719539
2023-10-30 16:48:47,415 Epoch: [303/484] Iter:[110/495], Time: 0.39, lr: [0.004121636749815782], Loss: 1.994493, Acc:0.798824, Semantic loss: 0.741899, BCE loss: 0.535464, SB loss: 0.717131
2023-10-30 16:48:51,171 Epoch: [303/484] Iter:[120/495], Time: 0.39, lr: [0.004121222211758849], Loss: 1.985796, Acc:0.800581, Semantic loss: 0.738927, BCE loss: 0.531505, SB loss: 0.715364
2023-10-30 16:48:54,849 Epoch: [303/484] Iter:[130/495], Time: 0.39, lr: [0.004120807669068885], Loss: 1.976814, Acc:0.802643, Semantic loss: 0.736141, BCE loss: 0.526231, SB loss: 0.714443
2023-10-30 16:48:58,647 Epoch: [303/484] Iter:[140/495], Time: 0.39, lr: [0.004120393121745321], Loss: 1.978844, Acc:0.801457, Semantic loss: 0.736521, BCE loss: 0.528235, SB loss: 0.714089
2023-10-30 16:49:02,335 Epoch: [303/484] Iter:[150/495], Time: 0.39, lr: [0.0041199785697875885], Loss: 1.981608, Acc:0.804427, Semantic loss: 0.737268, BCE loss: 0.530128, SB loss: 0.714213
2023-10-30 16:49:05,979 Epoch: [303/484] Iter:[160/495], Time: 0.38, lr: [0.004119564013195116], Loss: 1.990067, Acc:0.806454, Semantic loss: 0.741813, BCE loss: 0.529236, SB loss: 0.719018
2023-10-30 16:49:09,698 Epoch: [303/484] Iter:[170/495], Time: 0.38, lr: [0.004119149451967332], Loss: 1.987914, Acc:0.805972, Semantic loss: 0.739072, BCE loss: 0.529407, SB loss: 0.719435
2023-10-30 16:49:13,422 Epoch: [303/484] Iter:[180/495], Time: 0.38, lr: [0.004118734886103671], Loss: 1.989404, Acc:0.806320, Semantic loss: 0.740082, BCE loss: 0.530087, SB loss: 0.719236
2023-10-30 16:49:17,184 Epoch: [303/484] Iter:[190/495], Time: 0.38, lr: [0.004118320315603559], Loss: 1.995272, Acc:0.803692, Semantic loss: 0.743172, BCE loss: 0.531023, SB loss: 0.721077
2023-10-30 16:49:20,794 Epoch: [303/484] Iter:[200/495], Time: 0.38, lr: [0.004117905740466428], Loss: 2.000331, Acc:0.804776, Semantic loss: 0.745384, BCE loss: 0.533748, SB loss: 0.721200
2023-10-30 16:49:24,420 Epoch: [303/484] Iter:[210/495], Time: 0.38, lr: [0.004117491160691702], Loss: 1.997467, Acc:0.802854, Semantic loss: 0.744380, BCE loss: 0.532621, SB loss: 0.720466
2023-10-30 16:49:28,116 Epoch: [303/484] Iter:[220/495], Time: 0.38, lr: [0.004117076576278817], Loss: 1.994143, Acc:0.803681, Semantic loss: 0.743932, BCE loss: 0.530316, SB loss: 0.719895
2023-10-30 16:49:32,004 Epoch: [303/484] Iter:[230/495], Time: 0.38, lr: [0.004116661987227199], Loss: 1.992397, Acc:0.805054, Semantic loss: 0.743288, BCE loss: 0.530155, SB loss: 0.718954
2023-10-30 16:49:35,612 Epoch: [303/484] Iter:[240/495], Time: 0.38, lr: [0.004116247393536277], Loss: 1.989560, Acc:0.805454, Semantic loss: 0.742040, BCE loss: 0.528843, SB loss: 0.718678
2023-10-30 16:49:39,373 Epoch: [303/484] Iter:[250/495], Time: 0.38, lr: [0.00411583279520548], Loss: 1.985972, Acc:0.805733, Semantic loss: 0.742340, BCE loss: 0.525443, SB loss: 0.718189
2023-10-30 16:49:43,309 Epoch: [303/484] Iter:[260/495], Time: 0.38, lr: [0.004115418192234237], Loss: 1.985740, Acc:0.805654, Semantic loss: 0.741660, BCE loss: 0.526431, SB loss: 0.717650
2023-10-30 16:49:47,009 Epoch: [303/484] Iter:[270/495], Time: 0.38, lr: [0.0041150035846219775], Loss: 1.990145, Acc:0.805467, Semantic loss: 0.744163, BCE loss: 0.527080, SB loss: 0.718902
2023-10-30 16:49:50,727 Epoch: [303/484] Iter:[280/495], Time: 0.38, lr: [0.004114588972368129], Loss: 1.990329, Acc:0.804860, Semantic loss: 0.745183, BCE loss: 0.526315, SB loss: 0.718831
2023-10-30 16:49:54,441 Epoch: [303/484] Iter:[290/495], Time: 0.38, lr: [0.004114174355472119], Loss: 1.986764, Acc:0.804895, Semantic loss: 0.743576, BCE loss: 0.525380, SB loss: 0.717809
2023-10-30 16:49:58,109 Epoch: [303/484] Iter:[300/495], Time: 0.38, lr: [0.0041137597339333766], Loss: 1.986713, Acc:0.804980, Semantic loss: 0.744767, BCE loss: 0.524577, SB loss: 0.717369
2023-10-30 16:50:01,778 Epoch: [303/484] Iter:[310/495], Time: 0.38, lr: [0.0041133451077513304], Loss: 1.981332, Acc:0.804749, Semantic loss: 0.743669, BCE loss: 0.521059, SB loss: 0.716603
2023-10-30 16:50:05,660 Epoch: [303/484] Iter:[320/495], Time: 0.38, lr: [0.004112930476925407], Loss: 1.982019, Acc:0.803683, Semantic loss: 0.744847, BCE loss: 0.520127, SB loss: 0.717045
2023-10-30 16:50:09,404 Epoch: [303/484] Iter:[330/495], Time: 0.38, lr: [0.004112515841455035], Loss: 1.987749, Acc:0.804256, Semantic loss: 0.747167, BCE loss: 0.522115, SB loss: 0.718468
2023-10-30 16:50:13,157 Epoch: [303/484] Iter:[340/495], Time: 0.38, lr: [0.004112101201339643], Loss: 1.987251, Acc:0.805151, Semantic loss: 0.746656, BCE loss: 0.522607, SB loss: 0.717987
2023-10-30 16:50:16,865 Epoch: [303/484] Iter:[350/495], Time: 0.38, lr: [0.004111686556578657], Loss: 1.982748, Acc:0.803820, Semantic loss: 0.744110, BCE loss: 0.521855, SB loss: 0.716782
2023-10-30 16:50:20,626 Epoch: [303/484] Iter:[360/495], Time: 0.38, lr: [0.004111271907171506], Loss: 1.984959, Acc:0.804941, Semantic loss: 0.744517, BCE loss: 0.523040, SB loss: 0.717401
2023-10-30 16:50:24,337 Epoch: [303/484] Iter:[370/495], Time: 0.38, lr: [0.004110857253117614], Loss: 1.984262, Acc:0.804633, Semantic loss: 0.744461, BCE loss: 0.522651, SB loss: 0.717151
2023-10-30 16:50:28,033 Epoch: [303/484] Iter:[380/495], Time: 0.38, lr: [0.0041104425944164125], Loss: 1.982181, Acc:0.804376, Semantic loss: 0.743585, BCE loss: 0.521450, SB loss: 0.717146
2023-10-30 16:50:31,711 Epoch: [303/484] Iter:[390/495], Time: 0.38, lr: [0.004110027931067326], Loss: 1.980975, Acc:0.804426, Semantic loss: 0.742992, BCE loss: 0.521281, SB loss: 0.716701
2023-10-30 16:50:35,455 Epoch: [303/484] Iter:[400/495], Time: 0.38, lr: [0.004109613263069781], Loss: 1.981138, Acc:0.803943, Semantic loss: 0.744011, BCE loss: 0.520436, SB loss: 0.716691
2023-10-30 16:50:39,160 Epoch: [303/484] Iter:[410/495], Time: 0.38, lr: [0.004109198590423205], Loss: 1.985540, Acc:0.803625, Semantic loss: 0.747309, BCE loss: 0.520913, SB loss: 0.717318
2023-10-30 16:50:42,804 Epoch: [303/484] Iter:[420/495], Time: 0.38, lr: [0.004108783913127026], Loss: 1.989911, Acc:0.803716, Semantic loss: 0.749192, BCE loss: 0.521975, SB loss: 0.718744
2023-10-30 16:50:46,509 Epoch: [303/484] Iter:[430/495], Time: 0.38, lr: [0.004108369231180667], Loss: 1.993090, Acc:0.803103, Semantic loss: 0.750317, BCE loss: 0.523384, SB loss: 0.719389
2023-10-30 16:50:50,341 Epoch: [303/484] Iter:[440/495], Time: 0.38, lr: [0.004107954544583558], Loss: 1.993020, Acc:0.803348, Semantic loss: 0.749946, BCE loss: 0.523534, SB loss: 0.719540
2023-10-30 16:50:54,122 Epoch: [303/484] Iter:[450/495], Time: 0.38, lr: [0.0041075398533351225], Loss: 1.996098, Acc:0.803927, Semantic loss: 0.751130, BCE loss: 0.524755, SB loss: 0.720213
2023-10-30 16:50:57,747 Epoch: [303/484] Iter:[460/495], Time: 0.38, lr: [0.004107125157434788], Loss: 1.995269, Acc:0.802973, Semantic loss: 0.751137, BCE loss: 0.523440, SB loss: 0.720692
2023-10-30 16:51:01,437 Epoch: [303/484] Iter:[470/495], Time: 0.38, lr: [0.00410671045688198], Loss: 1.994287, Acc:0.802930, Semantic loss: 0.750844, BCE loss: 0.522948, SB loss: 0.720494
2023-10-30 16:51:05,292 Epoch: [303/484] Iter:[480/495], Time: 0.38, lr: [0.004106295751676124], Loss: 1.994008, Acc:0.803100, Semantic loss: 0.750360, BCE loss: 0.523511, SB loss: 0.720137
2023-10-30 16:51:08,777 Epoch: [303/484] Iter:[490/495], Time: 0.38, lr: [0.004105881041816645], Loss: 1.994599, Acc:0.803437, Semantic loss: 0.750926, BCE loss: 0.523736, SB loss: 0.719937
2023-10-30 16:51:10,194 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:51:10,432 Loss: 1.998, MeanIU:  0.7005, Best_mIoU:  0.7309
2023-10-30 16:51:10,432 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439]
2023-10-30 16:51:12,391 Epoch: [304/484] Iter:[0/495], Time: 1.92, lr: [0.004105673685141619], Loss: 2.192938, Acc:0.684596, Semantic loss: 0.822062, BCE loss: 0.640879, SB loss: 0.729997
2023-10-30 16:51:16,436 Epoch: [304/484] Iter:[10/495], Time: 0.54, lr: [0.00410525896830063], Loss: 2.004919, Acc:0.763037, Semantic loss: 0.728870, BCE loss: 0.523885, SB loss: 0.752164
2023-10-30 16:51:20,241 Epoch: [304/484] Iter:[20/495], Time: 0.47, lr: [0.004104844246804584], Loss: 2.307373, Acc:0.773790, Semantic loss: 0.963032, BCE loss: 0.533130, SB loss: 0.811210
2023-10-30 16:51:24,138 Epoch: [304/484] Iter:[30/495], Time: 0.44, lr: [0.0041044295206529025], Loss: 2.269158, Acc:0.784708, Semantic loss: 0.905753, BCE loss: 0.560426, SB loss: 0.802978
2023-10-30 16:51:27,922 Epoch: [304/484] Iter:[40/495], Time: 0.43, lr: [0.0041040147898450145], Loss: 2.257437, Acc:0.786837, Semantic loss: 0.900510, BCE loss: 0.557398, SB loss: 0.799529
2023-10-30 16:51:31,654 Epoch: [304/484] Iter:[50/495], Time: 0.42, lr: [0.004103600054380342], Loss: 2.279301, Acc:0.782050, Semantic loss: 0.916784, BCE loss: 0.560497, SB loss: 0.802020
2023-10-30 16:51:35,372 Epoch: [304/484] Iter:[60/495], Time: 0.41, lr: [0.004103185314258312], Loss: 2.228420, Acc:0.787342, Semantic loss: 0.875057, BCE loss: 0.561714, SB loss: 0.791649
2023-10-30 16:51:39,086 Epoch: [304/484] Iter:[70/495], Time: 0.40, lr: [0.004102770569478346], Loss: 2.222767, Acc:0.785889, Semantic loss: 0.874810, BCE loss: 0.562451, SB loss: 0.785505
2023-10-30 16:51:42,692 Epoch: [304/484] Iter:[80/495], Time: 0.40, lr: [0.004102355820039871], Loss: 2.203090, Acc:0.786943, Semantic loss: 0.862145, BCE loss: 0.564157, SB loss: 0.776788
2023-10-30 16:51:46,365 Epoch: [304/484] Iter:[90/495], Time: 0.39, lr: [0.004101941065942312], Loss: 2.162308, Acc:0.780737, Semantic loss: 0.842453, BCE loss: 0.551310, SB loss: 0.768545
2023-10-30 16:51:50,059 Epoch: [304/484] Iter:[100/495], Time: 0.39, lr: [0.00410152630718509], Loss: 2.151369, Acc:0.786793, Semantic loss: 0.833162, BCE loss: 0.548801, SB loss: 0.769405
2023-10-30 16:51:53,834 Epoch: [304/484] Iter:[110/495], Time: 0.39, lr: [0.004101111543767632], Loss: 2.143689, Acc:0.788722, Semantic loss: 0.826936, BCE loss: 0.553127, SB loss: 0.763627
2023-10-30 16:51:57,535 Epoch: [304/484] Iter:[120/495], Time: 0.39, lr: [0.004100696775689362], Loss: 2.128062, Acc:0.790490, Semantic loss: 0.817935, BCE loss: 0.549434, SB loss: 0.760694
2023-10-30 16:52:01,321 Epoch: [304/484] Iter:[130/495], Time: 0.39, lr: [0.0041002820029497015], Loss: 2.132787, Acc:0.791810, Semantic loss: 0.823070, BCE loss: 0.549964, SB loss: 0.759752
2023-10-30 16:52:04,935 Epoch: [304/484] Iter:[140/495], Time: 0.39, lr: [0.004099867225548076], Loss: 2.126287, Acc:0.792100, Semantic loss: 0.818783, BCE loss: 0.549739, SB loss: 0.757765
2023-10-30 16:52:08,555 Epoch: [304/484] Iter:[150/495], Time: 0.38, lr: [0.004099452443483908], Loss: 2.116666, Acc:0.793448, Semantic loss: 0.812987, BCE loss: 0.549237, SB loss: 0.754441
2023-10-30 16:52:12,255 Epoch: [304/484] Iter:[160/495], Time: 0.38, lr: [0.004099037656756622], Loss: 2.109800, Acc:0.794267, Semantic loss: 0.808076, BCE loss: 0.549546, SB loss: 0.752177
2023-10-30 16:52:15,949 Epoch: [304/484] Iter:[170/495], Time: 0.38, lr: [0.004098622865365641], Loss: 2.107652, Acc:0.794800, Semantic loss: 0.808590, BCE loss: 0.548314, SB loss: 0.750748
2023-10-30 16:52:19,612 Epoch: [304/484] Iter:[180/495], Time: 0.38, lr: [0.004098208069310387], Loss: 2.098655, Acc:0.795497, Semantic loss: 0.803874, BCE loss: 0.546368, SB loss: 0.748413
2023-10-30 16:52:23,233 Epoch: [304/484] Iter:[190/495], Time: 0.38, lr: [0.004097793268590284], Loss: 2.090795, Acc:0.793702, Semantic loss: 0.801323, BCE loss: 0.542700, SB loss: 0.746772
2023-10-30 16:52:26,948 Epoch: [304/484] Iter:[200/495], Time: 0.38, lr: [0.004097378463204755], Loss: 2.087751, Acc:0.794655, Semantic loss: 0.798516, BCE loss: 0.543288, SB loss: 0.745947
2023-10-30 16:52:30,656 Epoch: [304/484] Iter:[210/495], Time: 0.38, lr: [0.004096963653153223], Loss: 2.084175, Acc:0.794941, Semantic loss: 0.796229, BCE loss: 0.542704, SB loss: 0.745242
2023-10-30 16:52:34,333 Epoch: [304/484] Iter:[220/495], Time: 0.38, lr: [0.004096548838435109], Loss: 2.080748, Acc:0.794420, Semantic loss: 0.793444, BCE loss: 0.541978, SB loss: 0.745325
2023-10-30 16:52:37,981 Epoch: [304/484] Iter:[230/495], Time: 0.38, lr: [0.004096134019049837], Loss: 2.079097, Acc:0.794364, Semantic loss: 0.792164, BCE loss: 0.543157, SB loss: 0.743776
2023-10-30 16:52:41,697 Epoch: [304/484] Iter:[240/495], Time: 0.38, lr: [0.004095719194996828], Loss: 2.072609, Acc:0.793644, Semantic loss: 0.787153, BCE loss: 0.543408, SB loss: 0.742048
2023-10-30 16:52:45,405 Epoch: [304/484] Iter:[250/495], Time: 0.38, lr: [0.004095304366275506], Loss: 2.072105, Acc:0.793829, Semantic loss: 0.786504, BCE loss: 0.543183, SB loss: 0.742418
2023-10-30 16:52:49,154 Epoch: [304/484] Iter:[260/495], Time: 0.38, lr: [0.0040948895328852914], Loss: 2.073911, Acc:0.796323, Semantic loss: 0.786274, BCE loss: 0.545861, SB loss: 0.741777
2023-10-30 16:52:52,917 Epoch: [304/484] Iter:[270/495], Time: 0.38, lr: [0.004094474694825606], Loss: 2.066487, Acc:0.796323, Semantic loss: 0.783649, BCE loss: 0.541733, SB loss: 0.741105
2023-10-30 16:52:56,582 Epoch: [304/484] Iter:[280/495], Time: 0.38, lr: [0.004094059852095873], Loss: 2.063478, Acc:0.796706, Semantic loss: 0.782790, BCE loss: 0.539816, SB loss: 0.740873
2023-10-30 16:53:00,336 Epoch: [304/484] Iter:[290/495], Time: 0.38, lr: [0.004093645004695514], Loss: 2.064711, Acc:0.796315, Semantic loss: 0.782758, BCE loss: 0.540648, SB loss: 0.741306
2023-10-30 16:53:04,014 Epoch: [304/484] Iter:[300/495], Time: 0.38, lr: [0.004093230152623949], Loss: 2.062660, Acc:0.797308, Semantic loss: 0.781529, BCE loss: 0.539798, SB loss: 0.741333
2023-10-30 16:53:07,670 Epoch: [304/484] Iter:[310/495], Time: 0.38, lr: [0.004092815295880599], Loss: 2.062353, Acc:0.798512, Semantic loss: 0.781140, BCE loss: 0.540208, SB loss: 0.741006
2023-10-30 16:53:11,333 Epoch: [304/484] Iter:[320/495], Time: 0.38, lr: [0.004092400434464887], Loss: 2.062667, Acc:0.799951, Semantic loss: 0.782169, BCE loss: 0.540380, SB loss: 0.740118
2023-10-30 16:53:15,093 Epoch: [304/484] Iter:[330/495], Time: 0.38, lr: [0.004091985568376234], Loss: 2.057928, Acc:0.799770, Semantic loss: 0.780309, BCE loss: 0.538526, SB loss: 0.739093
2023-10-30 16:53:18,839 Epoch: [304/484] Iter:[340/495], Time: 0.38, lr: [0.004091570697614061], Loss: 2.051757, Acc:0.800089, Semantic loss: 0.776569, BCE loss: 0.538072, SB loss: 0.737116
2023-10-30 16:53:22,466 Epoch: [304/484] Iter:[350/495], Time: 0.38, lr: [0.004091155822177787], Loss: 2.046440, Acc:0.799774, Semantic loss: 0.774130, BCE loss: 0.536797, SB loss: 0.735513
2023-10-30 16:53:26,209 Epoch: [304/484] Iter:[360/495], Time: 0.38, lr: [0.004090740942066835], Loss: 2.042593, Acc:0.800005, Semantic loss: 0.772291, BCE loss: 0.535820, SB loss: 0.734481
2023-10-30 16:53:29,861 Epoch: [304/484] Iter:[370/495], Time: 0.38, lr: [0.004090326057280623], Loss: 2.042450, Acc:0.800701, Semantic loss: 0.771589, BCE loss: 0.536603, SB loss: 0.734258
2023-10-30 16:53:33,560 Epoch: [304/484] Iter:[380/495], Time: 0.38, lr: [0.004089911167818574], Loss: 2.048406, Acc:0.800288, Semantic loss: 0.778279, BCE loss: 0.535588, SB loss: 0.734539
2023-10-30 16:53:37,265 Epoch: [304/484] Iter:[390/495], Time: 0.38, lr: [0.004089496273680105], Loss: 2.046202, Acc:0.799562, Semantic loss: 0.776330, BCE loss: 0.535944, SB loss: 0.733929
2023-10-30 16:53:41,052 Epoch: [304/484] Iter:[400/495], Time: 0.38, lr: [0.004089081374864641], Loss: 2.046185, Acc:0.800329, Semantic loss: 0.776106, BCE loss: 0.536024, SB loss: 0.734056
2023-10-30 16:53:44,704 Epoch: [304/484] Iter:[410/495], Time: 0.38, lr: [0.0040886664713715975], Loss: 2.043862, Acc:0.800551, Semantic loss: 0.774638, BCE loss: 0.536135, SB loss: 0.733090
2023-10-30 16:53:48,353 Epoch: [304/484] Iter:[420/495], Time: 0.38, lr: [0.004088251563200395], Loss: 2.040831, Acc:0.800736, Semantic loss: 0.772941, BCE loss: 0.535784, SB loss: 0.732106
2023-10-30 16:53:52,087 Epoch: [304/484] Iter:[430/495], Time: 0.37, lr: [0.004087836650350456], Loss: 2.039520, Acc:0.801246, Semantic loss: 0.771656, BCE loss: 0.536228, SB loss: 0.731636
2023-10-30 16:53:55,818 Epoch: [304/484] Iter:[440/495], Time: 0.37, lr: [0.004087421732821199], Loss: 2.042140, Acc:0.800611, Semantic loss: 0.773188, BCE loss: 0.536464, SB loss: 0.732488
2023-10-30 16:53:59,579 Epoch: [304/484] Iter:[450/495], Time: 0.37, lr: [0.004087006810612041], Loss: 2.040351, Acc:0.801636, Semantic loss: 0.771507, BCE loss: 0.537457, SB loss: 0.731387
2023-10-30 16:54:03,235 Epoch: [304/484] Iter:[460/495], Time: 0.37, lr: [0.004086591883722402], Loss: 2.039169, Acc:0.801862, Semantic loss: 0.771008, BCE loss: 0.537375, SB loss: 0.730786
2023-10-30 16:54:06,846 Epoch: [304/484] Iter:[470/495], Time: 0.37, lr: [0.004086176952151704], Loss: 2.040179, Acc:0.802586, Semantic loss: 0.771165, BCE loss: 0.538025, SB loss: 0.730988
2023-10-30 16:54:10,517 Epoch: [304/484] Iter:[480/495], Time: 0.37, lr: [0.004085762015899365], Loss: 2.038313, Acc:0.801802, Semantic loss: 0.770774, BCE loss: 0.536875, SB loss: 0.730663
2023-10-30 16:54:14,007 Epoch: [304/484] Iter:[490/495], Time: 0.37, lr: [0.004085347074964802], Loss: 2.037559, Acc:0.802121, Semantic loss: 0.770089, BCE loss: 0.537123, SB loss: 0.730347
2023-10-30 16:54:15,411 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 16:54:15,638 Loss: 1.998, MeanIU:  0.7005, Best_mIoU:  0.7309
2023-10-30 16:54:15,638 [0.97300331 0.79789595 0.90567819 0.28690787 0.53814184 0.59160055
 0.67348004 0.74565133 0.91564397 0.58553341 0.93626216 0.78174026
 0.59951032 0.93594648 0.61382571 0.7385236  0.39602325 0.55435954
 0.73932439]
2023-10-30 16:54:17,624 Epoch: [305/484] Iter:[0/495], Time: 1.95, lr: [0.004085139602741506], Loss: 1.909133, Acc:0.889280, Semantic loss: 0.658545, BCE loss: 0.578410, SB loss: 0.672178
2023-10-30 16:54:21,510 Epoch: [305/484] Iter:[10/495], Time: 0.53, lr: [0.004084724654782517], Loss: 2.038078, Acc:0.783564, Semantic loss: 0.791228, BCE loss: 0.514658, SB loss: 0.732192
2023-10-30 16:54:25,202 Epoch: [305/484] Iter:[20/495], Time: 0.45, lr: [0.004084309702139854], Loss: 2.011567, Acc:0.796300, Semantic loss: 0.770897, BCE loss: 0.516368, SB loss: 0.724302
2023-10-30 16:54:28,830 Epoch: [305/484] Iter:[30/495], Time: 0.42, lr: [0.004083894744812933], Loss: 1.994824, Acc:0.783840, Semantic loss: 0.771515, BCE loss: 0.496064, SB loss: 0.727245
2023-10-30 16:54:32,513 Epoch: [305/484] Iter:[40/495], Time: 0.41, lr: [0.004083479782801172], Loss: 1.984102, Acc:0.788758, Semantic loss: 0.758971, BCE loss: 0.504992, SB loss: 0.720139
2023-10-30 16:54:36,222 Epoch: [305/484] Iter:[50/495], Time: 0.40, lr: [0.004083064816103988], Loss: 1.989513, Acc:0.783468, Semantic loss: 0.759950, BCE loss: 0.504640, SB loss: 0.724923
2023-10-30 16:54:39,949 Epoch: [305/484] Iter:[60/495], Time: 0.40, lr: [0.004082649844720803], Loss: 2.020861, Acc:0.790260, Semantic loss: 0.779889, BCE loss: 0.511822, SB loss: 0.729151
2023-10-30 16:54:43,623 Epoch: [305/484] Iter:[70/495], Time: 0.39, lr: [0.004082234868651031], Loss: 2.019837, Acc:0.789684, Semantic loss: 0.776831, BCE loss: 0.519295, SB loss: 0.723711
2023-10-30 16:54:47,333 Epoch: [305/484] Iter:[80/495], Time: 0.39, lr: [0.004081819887894091], Loss: 2.022352, Acc:0.793540, Semantic loss: 0.775340, BCE loss: 0.522475, SB loss: 0.724538
2023-10-30 16:54:51,065 Epoch: [305/484] Iter:[90/495], Time: 0.39, lr: [0.004081404902449401], Loss: 2.020382, Acc:0.796224, Semantic loss: 0.773926, BCE loss: 0.524153, SB loss: 0.722303
2023-10-30 16:54:54,704 Epoch: [305/484] Iter:[100/495], Time: 0.39, lr: [0.004080989912316378], Loss: 2.018662, Acc:0.793618, Semantic loss: 0.771476, BCE loss: 0.524752, SB loss: 0.722434
2023-10-30 16:54:58,371 Epoch: [305/484] Iter:[110/495], Time: 0.38, lr: [0.00408057491749444], Loss: 2.018402, Acc:0.793806, Semantic loss: 0.769690, BCE loss: 0.525482, SB loss: 0.723229
2023-10-30 16:55:02,015 Epoch: [305/484] Iter:[120/495], Time: 0.38, lr: [0.004080159917983003], Loss: 2.013332, Acc:0.796697, Semantic loss: 0.762358, BCE loss: 0.529769, SB loss: 0.721205
2023-10-30 16:55:05,680 Epoch: [305/484] Iter:[130/495], Time: 0.38, lr: [0.004079744913781483], Loss: 2.001542, Acc:0.795407, Semantic loss: 0.757609, BCE loss: 0.525220, SB loss: 0.718712
2023-10-30 16:55:09,348 Epoch: [305/484] Iter:[140/495], Time: 0.38, lr: [0.0040793299048893], Loss: 2.008813, Acc:0.795404, Semantic loss: 0.760163, BCE loss: 0.527765, SB loss: 0.720886
2023-10-30 16:55:13,043 Epoch: [305/484] Iter:[150/495], Time: 0.38, lr: [0.00407891489130587], Loss: 2.009519, Acc:0.797266, Semantic loss: 0.759632, BCE loss: 0.528396, SB loss: 0.721491
2023-10-30 16:55:16,663 Epoch: [305/484] Iter:[160/495], Time: 0.38, lr: [0.004078499873030608], Loss: 2.001117, Acc:0.798993, Semantic loss: 0.756341, BCE loss: 0.525572, SB loss: 0.719205
2023-10-30 16:55:20,351 Epoch: [305/484] Iter:[170/495], Time: 0.38, lr: [0.00407808485006293], Loss: 2.002609, Acc:0.798153, Semantic loss: 0.757218, BCE loss: 0.524888, SB loss: 0.720503
2023-10-30 16:55:24,042 Epoch: [305/484] Iter:[180/495], Time: 0.38, lr: [0.004077669822402255], Loss: 2.003011, Acc:0.799194, Semantic loss: 0.755864, BCE loss: 0.526624, SB loss: 0.720523
2023-10-30 16:55:27,835 Epoch: [305/484] Iter:[190/495], Time: 0.38, lr: [0.004077254790047997], Loss: 2.004812, Acc:0.801001, Semantic loss: 0.757499, BCE loss: 0.526153, SB loss: 0.721160
2023-10-30 16:55:31,534 Epoch: [305/484] Iter:[200/495], Time: 0.38, lr: [0.004076839752999574], Loss: 2.002667, Acc:0.800740, Semantic loss: 0.756214, BCE loss: 0.525560, SB loss: 0.720892
2023-10-30 16:55:35,238 Epoch: [305/484] Iter:[210/495], Time: 0.38, lr: [0.004076424711256399], Loss: 2.003407, Acc:0.800344, Semantic loss: 0.758853, BCE loss: 0.524257, SB loss: 0.720297
2023-10-30 16:55:39,025 Epoch: [305/484] Iter:[220/495], Time: 0.38, lr: [0.004076009664817891], Loss: 2.000687, Acc:0.800791, Semantic loss: 0.755872, BCE loss: 0.525808, SB loss: 0.719008
2023-10-30 16:55:42,689 Epoch: [305/484] Iter:[230/495], Time: 0.38, lr: [0.0040755946136834635], Loss: 1.999572, Acc:0.803238, Semantic loss: 0.754649, BCE loss: 0.526376, SB loss: 0.718546
2023-10-30 16:55:46,430 Epoch: [305/484] Iter:[240/495], Time: 0.38, lr: [0.004075179557852533], Loss: 2.000257, Acc:0.802957, Semantic loss: 0.753849, BCE loss: 0.528486, SB loss: 0.717922
2023-10-30 16:55:50,061 Epoch: [305/484] Iter:[250/495], Time: 0.38, lr: [0.004074764497324514], Loss: 1.997267, Acc:0.800626, Semantic loss: 0.753046, BCE loss: 0.526569, SB loss: 0.717652
2023-10-30 16:55:53,661 Epoch: [305/484] Iter:[260/495], Time: 0.38, lr: [0.0040743494320988225], Loss: 1.994061, Acc:0.799930, Semantic loss: 0.753001, BCE loss: 0.524121, SB loss: 0.716939
2023-10-30 16:55:57,373 Epoch: [305/484] Iter:[270/495], Time: 0.38, lr: [0.004073934362174874], Loss: 1.994825, Acc:0.799925, Semantic loss: 0.754416, BCE loss: 0.523219, SB loss: 0.717190
2023-10-30 16:56:01,031 Epoch: [305/484] Iter:[280/495], Time: 0.37, lr: [0.004073519287552081], Loss: 2.001714, Acc:0.800642, Semantic loss: 0.757335, BCE loss: 0.526647, SB loss: 0.717732
2023-10-30 16:56:04,670 Epoch: [305/484] Iter:[290/495], Time: 0.37, lr: [0.0040731042082298614], Loss: 1.999616, Acc:0.799229, Semantic loss: 0.756652, BCE loss: 0.524837, SB loss: 0.718127
2023-10-30 16:56:08,269 Epoch: [305/484] Iter:[300/495], Time: 0.37, lr: [0.0040726891242076286], Loss: 2.000368, Acc:0.798637, Semantic loss: 0.756846, BCE loss: 0.525152, SB loss: 0.718370
2023-10-30 16:56:11,950 Epoch: [305/484] Iter:[310/495], Time: 0.37, lr: [0.004072274035484797], Loss: 2.001946, Acc:0.798487, Semantic loss: 0.756717, BCE loss: 0.526044, SB loss: 0.719186
2023-10-30 16:56:15,611 Epoch: [305/484] Iter:[320/495], Time: 0.37, lr: [0.0040718589420607795], Loss: 2.001126, Acc:0.797926, Semantic loss: 0.756621, BCE loss: 0.525537, SB loss: 0.718968
2023-10-30 16:56:19,332 Epoch: [305/484] Iter:[330/495], Time: 0.37, lr: [0.004071443843934994], Loss: 1.996197, Acc:0.799321, Semantic loss: 0.753072, BCE loss: 0.525551, SB loss: 0.717575
2023-10-30 16:56:23,056 Epoch: [305/484] Iter:[340/495], Time: 0.37, lr: [0.004071028741106851], Loss: 1.996845, Acc:0.797943, Semantic loss: 0.754832, BCE loss: 0.524552, SB loss: 0.717460
2023-10-30 16:56:26,755 Epoch: [305/484] Iter:[350/495], Time: 0.37, lr: [0.004070613633575767], Loss: 1.993881, Acc:0.798967, Semantic loss: 0.752830, BCE loss: 0.524225, SB loss: 0.716826
2023-10-30 16:56:30,387 Epoch: [305/484] Iter:[360/495], Time: 0.37, lr: [0.004070198521341153], Loss: 1.992675, Acc:0.799812, Semantic loss: 0.752842, BCE loss: 0.523107, SB loss: 0.716726
2023-10-30 16:56:34,032 Epoch: [305/484] Iter:[370/495], Time: 0.37, lr: [0.004069783404402427], Loss: 1.988756, Acc:0.799200, Semantic loss: 0.750870, BCE loss: 0.521804, SB loss: 0.716082
2023-10-30 16:56:37,787 Epoch: [305/484] Iter:[380/495], Time: 0.37, lr: [0.004069368282758999], Loss: 1.993130, Acc:0.799572, Semantic loss: 0.752085, BCE loss: 0.524196, SB loss: 0.716849
2023-10-30 16:56:41,457 Epoch: [305/484] Iter:[390/495], Time: 0.37, lr: [0.004068953156410283], Loss: 1.997337, Acc:0.800050, Semantic loss: 0.754692, BCE loss: 0.525271, SB loss: 0.717374
2023-10-30 16:56:45,080 Epoch: [305/484] Iter:[400/495], Time: 0.37, lr: [0.0040685380253556915], Loss: 1.994521, Acc:0.801144, Semantic loss: 0.753470, BCE loss: 0.524227, SB loss: 0.716824
2023-10-30 16:56:48,826 Epoch: [305/484] Iter:[410/495], Time: 0.37, lr: [0.0040681228895946405], Loss: 1.993021, Acc:0.801227, Semantic loss: 0.752685, BCE loss: 0.523635, SB loss: 0.716701
2023-10-30 16:56:52,444 Epoch: [305/484] Iter:[420/495], Time: 0.37, lr: [0.0040677077491265414], Loss: 1.990323, Acc:0.801682, Semantic loss: 0.751820, BCE loss: 0.522121, SB loss: 0.716383
2023-10-30 16:56:56,068 Epoch: [305/484] Iter:[430/495], Time: 0.37, lr: [0.004067292603950807], Loss: 1.990165, Acc:0.801645, Semantic loss: 0.751141, BCE loss: 0.522705, SB loss: 0.716319
2023-10-30 16:56:59,768 Epoch: [305/484] Iter:[440/495], Time: 0.37, lr: [0.004066877454066848], Loss: 1.987940, Acc:0.801719, Semantic loss: 0.750066, BCE loss: 0.522148, SB loss: 0.715725
2023-10-30 16:57:03,497 Epoch: [305/484] Iter:[450/495], Time: 0.37, lr: [0.004066462299474082], Loss: 1.987756, Acc:0.802266, Semantic loss: 0.749355, BCE loss: 0.523035, SB loss: 0.715366
2023-10-30 16:57:07,166 Epoch: [305/484] Iter:[460/495], Time: 0.37, lr: [0.004066047140171916], Loss: 1.990945, Acc:0.802460, Semantic loss: 0.750783, BCE loss: 0.524218, SB loss: 0.715944
2023-10-30 16:57:10,897 Epoch: [305/484] Iter:[470/495], Time: 0.37, lr: [0.004065631976159766], Loss: 1.990096, Acc:0.801801, Semantic loss: 0.749430, BCE loss: 0.525257, SB loss: 0.715409
2023-10-30 16:57:14,533 Epoch: [305/484] Iter:[480/495], Time: 0.37, lr: [0.004065216807437042], Loss: 1.994300, Acc:0.801762, Semantic loss: 0.751361, BCE loss: 0.526666, SB loss: 0.716273
2023-10-30 16:57:18,050 Epoch: [305/484] Iter:[490/495], Time: 0.37, lr: [0.004064801634003157], Loss: 1.992836, Acc:0.802333, Semantic loss: 0.750161, BCE loss: 0.527005, SB loss: 0.715670
2023-10-30 17:00:14,636 0 [0.94403886 0.66870753 0.83621489 0.194484   0.27845536 0.43111786
 0.49518234 0.61431903 0.88920995 0.45607594 0.8726614  0.61867738
 0.04529812 0.82594056 0.00688249 0.15655733 0.07457369 0.07256
 0.62483846] 0.47925237702534745
2023-10-30 17:00:14,637 1 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068] 0.7145474593010155
2023-10-30 17:00:14,640 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:00:14,880 Loss: 1.992, MeanIU:  0.7145, Best_mIoU:  0.7309
2023-10-30 17:00:14,880 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068]
2023-10-30 17:00:16,834 Epoch: [306/484] Iter:[0/495], Time: 1.92, lr: [0.004064594045519346], Loss: 1.899279, Acc:0.808338, Semantic loss: 0.683018, BCE loss: 0.544756, SB loss: 0.671505
2023-10-30 17:00:20,695 Epoch: [306/484] Iter:[10/495], Time: 0.53, lr: [0.0040641788650176165], Loss: 1.974126, Acc:0.790367, Semantic loss: 0.748984, BCE loss: 0.498803, SB loss: 0.726338
2023-10-30 17:00:24,309 Epoch: [306/484] Iter:[20/495], Time: 0.45, lr: [0.004063763679803255], Loss: 1.993748, Acc:0.809323, Semantic loss: 0.748514, BCE loss: 0.509836, SB loss: 0.735398
2023-10-30 17:00:27,815 Epoch: [306/484] Iter:[30/495], Time: 0.42, lr: [0.004063348489875673], Loss: 1.981178, Acc:0.820225, Semantic loss: 0.743467, BCE loss: 0.512026, SB loss: 0.725685
2023-10-30 17:00:31,536 Epoch: [306/484] Iter:[40/495], Time: 0.41, lr: [0.004062933295234283], Loss: 2.023304, Acc:0.820202, Semantic loss: 0.776094, BCE loss: 0.528834, SB loss: 0.718376
2023-10-30 17:00:35,144 Epoch: [306/484] Iter:[50/495], Time: 0.40, lr: [0.0040625180958784955], Loss: 2.017589, Acc:0.817098, Semantic loss: 0.769009, BCE loss: 0.525753, SB loss: 0.722827
2023-10-30 17:00:38,752 Epoch: [306/484] Iter:[60/495], Time: 0.39, lr: [0.004062102891807721], Loss: 2.012186, Acc:0.811084, Semantic loss: 0.768342, BCE loss: 0.520442, SB loss: 0.723402
2023-10-30 17:00:42,281 Epoch: [306/484] Iter:[70/495], Time: 0.39, lr: [0.00406168768302137], Loss: 2.020746, Acc:0.813296, Semantic loss: 0.769555, BCE loss: 0.529036, SB loss: 0.722155
2023-10-30 17:00:45,766 Epoch: [306/484] Iter:[80/495], Time: 0.38, lr: [0.0040612724695188555], Loss: 2.025193, Acc:0.808930, Semantic loss: 0.767667, BCE loss: 0.534740, SB loss: 0.722787
2023-10-30 17:00:49,420 Epoch: [306/484] Iter:[90/495], Time: 0.38, lr: [0.004060857251299586], Loss: 2.004314, Acc:0.806531, Semantic loss: 0.755698, BCE loss: 0.528048, SB loss: 0.720568
2023-10-30 17:00:52,973 Epoch: [306/484] Iter:[100/495], Time: 0.38, lr: [0.0040604420283629735], Loss: 1.998869, Acc:0.803453, Semantic loss: 0.755746, BCE loss: 0.524377, SB loss: 0.718746
2023-10-30 17:00:56,519 Epoch: [306/484] Iter:[110/495], Time: 0.37, lr: [0.004060026800708428], Loss: 1.989251, Acc:0.805045, Semantic loss: 0.749416, BCE loss: 0.524590, SB loss: 0.715245
2023-10-30 17:01:00,233 Epoch: [306/484] Iter:[120/495], Time: 0.37, lr: [0.00405961156833536], Loss: 1.975006, Acc:0.802419, Semantic loss: 0.742758, BCE loss: 0.519586, SB loss: 0.712662
2023-10-30 17:01:03,864 Epoch: [306/484] Iter:[130/495], Time: 0.37, lr: [0.004059196331243178], Loss: 1.981457, Acc:0.803012, Semantic loss: 0.747768, BCE loss: 0.518134, SB loss: 0.715555
2023-10-30 17:01:07,365 Epoch: [306/484] Iter:[140/495], Time: 0.37, lr: [0.004058781089431293], Loss: 1.978163, Acc:0.802232, Semantic loss: 0.745993, BCE loss: 0.515917, SB loss: 0.716252
2023-10-30 17:01:11,002 Epoch: [306/484] Iter:[150/495], Time: 0.37, lr: [0.004058365842899116], Loss: 1.981933, Acc:0.801055, Semantic loss: 0.746010, BCE loss: 0.520383, SB loss: 0.715541
2023-10-30 17:01:14,712 Epoch: [306/484] Iter:[160/495], Time: 0.37, lr: [0.004057950591646056], Loss: 1.976423, Acc:0.800762, Semantic loss: 0.744741, BCE loss: 0.516271, SB loss: 0.715411
2023-10-30 17:01:18,308 Epoch: [306/484] Iter:[170/495], Time: 0.37, lr: [0.004057535335671523], Loss: 1.976278, Acc:0.799985, Semantic loss: 0.743812, BCE loss: 0.516807, SB loss: 0.715659
2023-10-30 17:01:22,063 Epoch: [306/484] Iter:[180/495], Time: 0.37, lr: [0.004057120074974923], Loss: 1.971982, Acc:0.799122, Semantic loss: 0.742682, BCE loss: 0.514455, SB loss: 0.714845
2023-10-30 17:01:25,786 Epoch: [306/484] Iter:[190/495], Time: 0.37, lr: [0.00405670480955567], Loss: 1.969789, Acc:0.800424, Semantic loss: 0.739984, BCE loss: 0.515790, SB loss: 0.714015
2023-10-30 17:01:29,514 Epoch: [306/484] Iter:[200/495], Time: 0.37, lr: [0.004056289539413171], Loss: 1.972769, Acc:0.800148, Semantic loss: 0.741124, BCE loss: 0.516366, SB loss: 0.715278
2023-10-30 17:01:33,029 Epoch: [306/484] Iter:[210/495], Time: 0.37, lr: [0.004055874264546835], Loss: 1.969614, Acc:0.798788, Semantic loss: 0.740944, BCE loss: 0.514633, SB loss: 0.714037
2023-10-30 17:01:36,712 Epoch: [306/484] Iter:[220/495], Time: 0.37, lr: [0.0040554589849560695], Loss: 1.964377, Acc:0.798640, Semantic loss: 0.739044, BCE loss: 0.511323, SB loss: 0.714010
2023-10-30 17:01:40,402 Epoch: [306/484] Iter:[230/495], Time: 0.37, lr: [0.004055043700640286], Loss: 1.969169, Acc:0.798407, Semantic loss: 0.742790, BCE loss: 0.510885, SB loss: 0.715494
2023-10-30 17:01:44,095 Epoch: [306/484] Iter:[240/495], Time: 0.37, lr: [0.0040546284115988915], Loss: 1.978261, Acc:0.798556, Semantic loss: 0.747952, BCE loss: 0.512186, SB loss: 0.718122
2023-10-30 17:01:47,709 Epoch: [306/484] Iter:[250/495], Time: 0.37, lr: [0.004054213117831294], Loss: 1.974429, Acc:0.796989, Semantic loss: 0.746278, BCE loss: 0.509978, SB loss: 0.718173
2023-10-30 17:01:51,466 Epoch: [306/484] Iter:[260/495], Time: 0.37, lr: [0.004053797819336903], Loss: 1.979479, Acc:0.797538, Semantic loss: 0.745172, BCE loss: 0.515800, SB loss: 0.718508
2023-10-30 17:01:55,196 Epoch: [306/484] Iter:[270/495], Time: 0.37, lr: [0.004053382516115126], Loss: 1.979994, Acc:0.798883, Semantic loss: 0.744270, BCE loss: 0.518020, SB loss: 0.717704
2023-10-30 17:01:58,893 Epoch: [306/484] Iter:[280/495], Time: 0.37, lr: [0.0040529672081653706], Loss: 1.987427, Acc:0.799344, Semantic loss: 0.749588, BCE loss: 0.518068, SB loss: 0.719771
2023-10-30 17:02:02,683 Epoch: [306/484] Iter:[290/495], Time: 0.37, lr: [0.004052551895487045], Loss: 1.985474, Acc:0.798929, Semantic loss: 0.748480, BCE loss: 0.517619, SB loss: 0.719375
2023-10-30 17:02:06,374 Epoch: [306/484] Iter:[300/495], Time: 0.37, lr: [0.004052136578079557], Loss: 1.983749, Acc:0.798827, Semantic loss: 0.748448, BCE loss: 0.517004, SB loss: 0.718297
2023-10-30 17:02:10,078 Epoch: [306/484] Iter:[310/495], Time: 0.37, lr: [0.004051721255942315], Loss: 1.987829, Acc:0.798964, Semantic loss: 0.749584, BCE loss: 0.519749, SB loss: 0.718496
2023-10-30 17:02:13,723 Epoch: [306/484] Iter:[320/495], Time: 0.37, lr: [0.004051305929074725], Loss: 1.992143, Acc:0.798940, Semantic loss: 0.751777, BCE loss: 0.520879, SB loss: 0.719486
2023-10-30 17:02:17,415 Epoch: [306/484] Iter:[330/495], Time: 0.37, lr: [0.004050890597476195], Loss: 1.991826, Acc:0.798855, Semantic loss: 0.751405, BCE loss: 0.521300, SB loss: 0.719121
2023-10-30 17:02:21,140 Epoch: [306/484] Iter:[340/495], Time: 0.37, lr: [0.004050475261146131], Loss: 1.994909, Acc:0.798587, Semantic loss: 0.753199, BCE loss: 0.522004, SB loss: 0.719706
2023-10-30 17:02:24,767 Epoch: [306/484] Iter:[350/495], Time: 0.37, lr: [0.004050059920083942], Loss: 1.994183, Acc:0.799925, Semantic loss: 0.752285, BCE loss: 0.522532, SB loss: 0.719365
2023-10-30 17:02:28,507 Epoch: [306/484] Iter:[360/495], Time: 0.37, lr: [0.0040496445742890345], Loss: 1.992483, Acc:0.800176, Semantic loss: 0.750730, BCE loss: 0.522869, SB loss: 0.718884
2023-10-30 17:02:32,445 Epoch: [306/484] Iter:[370/495], Time: 0.37, lr: [0.004049229223760814], Loss: 1.991206, Acc:0.800573, Semantic loss: 0.750386, BCE loss: 0.522297, SB loss: 0.718523
2023-10-30 17:02:36,036 Epoch: [306/484] Iter:[380/495], Time: 0.37, lr: [0.004048813868498687], Loss: 1.994799, Acc:0.801305, Semantic loss: 0.751270, BCE loss: 0.524537, SB loss: 0.718992
2023-10-30 17:02:39,673 Epoch: [306/484] Iter:[390/495], Time: 0.37, lr: [0.0040483985085020616], Loss: 1.992898, Acc:0.801542, Semantic loss: 0.749434, BCE loss: 0.524693, SB loss: 0.718770
2023-10-30 17:02:43,479 Epoch: [306/484] Iter:[400/495], Time: 0.37, lr: [0.004047983143770343], Loss: 1.994791, Acc:0.802733, Semantic loss: 0.750217, BCE loss: 0.524258, SB loss: 0.720316
2023-10-30 17:02:47,221 Epoch: [306/484] Iter:[410/495], Time: 0.37, lr: [0.004047567774302937], Loss: 1.996330, Acc:0.802595, Semantic loss: 0.749895, BCE loss: 0.525767, SB loss: 0.720669
2023-10-30 17:02:50,986 Epoch: [306/484] Iter:[420/495], Time: 0.37, lr: [0.004047152400099249], Loss: 1.995449, Acc:0.803333, Semantic loss: 0.750103, BCE loss: 0.525012, SB loss: 0.720334
2023-10-30 17:02:54,716 Epoch: [306/484] Iter:[430/495], Time: 0.37, lr: [0.0040467370211586876], Loss: 1.998078, Acc:0.803808, Semantic loss: 0.752031, BCE loss: 0.525061, SB loss: 0.720985
2023-10-30 17:02:58,399 Epoch: [306/484] Iter:[440/495], Time: 0.37, lr: [0.004046321637480657], Loss: 1.993647, Acc:0.803838, Semantic loss: 0.749858, BCE loss: 0.523942, SB loss: 0.719848
2023-10-30 17:03:02,041 Epoch: [306/484] Iter:[450/495], Time: 0.37, lr: [0.0040459062490645625], Loss: 1.993983, Acc:0.803461, Semantic loss: 0.750454, BCE loss: 0.523762, SB loss: 0.719766
2023-10-30 17:03:05,601 Epoch: [306/484] Iter:[460/495], Time: 0.37, lr: [0.004045490855909809], Loss: 1.992915, Acc:0.802982, Semantic loss: 0.750156, BCE loss: 0.522917, SB loss: 0.719842
2023-10-30 17:03:09,307 Epoch: [306/484] Iter:[470/495], Time: 0.37, lr: [0.004045075458015803], Loss: 1.991391, Acc:0.803470, Semantic loss: 0.749137, BCE loss: 0.522863, SB loss: 0.719390
2023-10-30 17:03:12,854 Epoch: [306/484] Iter:[480/495], Time: 0.37, lr: [0.004044660055381949], Loss: 1.993292, Acc:0.803637, Semantic loss: 0.750188, BCE loss: 0.523659, SB loss: 0.719445
2023-10-30 17:03:16,381 Epoch: [306/484] Iter:[490/495], Time: 0.37, lr: [0.0040442446480076525], Loss: 1.990165, Acc:0.802503, Semantic loss: 0.748725, BCE loss: 0.522199, SB loss: 0.719241
2023-10-30 17:03:17,788 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:03:18,030 Loss: 1.992, MeanIU:  0.7145, Best_mIoU:  0.7309
2023-10-30 17:03:18,030 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068]
2023-10-30 17:03:19,918 Epoch: [307/484] Iter:[0/495], Time: 1.85, lr: [0.004044036942542651], Loss: 2.140901, Acc:0.701601, Semantic loss: 0.799366, BCE loss: 0.547969, SB loss: 0.793567
2023-10-30 17:03:23,971 Epoch: [307/484] Iter:[10/495], Time: 0.54, lr: [0.004043621528056574], Loss: 2.073708, Acc:0.806063, Semantic loss: 0.775869, BCE loss: 0.556041, SB loss: 0.741797
2023-10-30 17:03:27,658 Epoch: [307/484] Iter:[20/495], Time: 0.46, lr: [0.0040432061088285665], Loss: 2.008657, Acc:0.790237, Semantic loss: 0.754393, BCE loss: 0.538513, SB loss: 0.715751
2023-10-30 17:03:31,333 Epoch: [307/484] Iter:[30/495], Time: 0.43, lr: [0.004042790684858032], Loss: 2.000510, Acc:0.793973, Semantic loss: 0.744746, BCE loss: 0.543977, SB loss: 0.711787
2023-10-30 17:03:35,074 Epoch: [307/484] Iter:[40/495], Time: 0.41, lr: [0.004042375256144376], Loss: 2.006058, Acc:0.796827, Semantic loss: 0.753624, BCE loss: 0.535088, SB loss: 0.717346
2023-10-30 17:03:38,863 Epoch: [307/484] Iter:[50/495], Time: 0.41, lr: [0.004041959822687001], Loss: 1.992475, Acc:0.795652, Semantic loss: 0.745668, BCE loss: 0.529329, SB loss: 0.717477
2023-10-30 17:03:42,536 Epoch: [307/484] Iter:[60/495], Time: 0.40, lr: [0.004041544384485314], Loss: 2.002997, Acc:0.796656, Semantic loss: 0.742979, BCE loss: 0.542178, SB loss: 0.717839
2023-10-30 17:03:46,234 Epoch: [307/484] Iter:[70/495], Time: 0.40, lr: [0.0040411289415387165], Loss: 2.011755, Acc:0.799231, Semantic loss: 0.750978, BCE loss: 0.539017, SB loss: 0.721759
2023-10-30 17:03:49,898 Epoch: [307/484] Iter:[80/495], Time: 0.39, lr: [0.0040407134938466125], Loss: 2.018382, Acc:0.800996, Semantic loss: 0.752219, BCE loss: 0.540285, SB loss: 0.725879
2023-10-30 17:03:53,533 Epoch: [307/484] Iter:[90/495], Time: 0.39, lr: [0.0040402980414084065], Loss: 2.018752, Acc:0.803806, Semantic loss: 0.748471, BCE loss: 0.544973, SB loss: 0.725308
2023-10-30 17:03:57,287 Epoch: [307/484] Iter:[100/495], Time: 0.39, lr: [0.004039882584223502], Loss: 2.008118, Acc:0.805449, Semantic loss: 0.744311, BCE loss: 0.542652, SB loss: 0.721154
2023-10-30 17:04:01,046 Epoch: [307/484] Iter:[110/495], Time: 0.39, lr: [0.004039467122291303], Loss: 2.003108, Acc:0.804967, Semantic loss: 0.742125, BCE loss: 0.541038, SB loss: 0.719946
2023-10-30 17:04:04,650 Epoch: [307/484] Iter:[120/495], Time: 0.38, lr: [0.0040390516556112095], Loss: 1.996364, Acc:0.805117, Semantic loss: 0.739427, BCE loss: 0.537765, SB loss: 0.719172
2023-10-30 17:04:08,291 Epoch: [307/484] Iter:[130/495], Time: 0.38, lr: [0.004038636184182628], Loss: 2.001296, Acc:0.806591, Semantic loss: 0.739285, BCE loss: 0.541158, SB loss: 0.720853
2023-10-30 17:04:12,132 Epoch: [307/484] Iter:[140/495], Time: 0.38, lr: [0.0040382207080049606], Loss: 1.986797, Acc:0.810641, Semantic loss: 0.733397, BCE loss: 0.536062, SB loss: 0.717338
2023-10-30 17:04:15,850 Epoch: [307/484] Iter:[150/495], Time: 0.38, lr: [0.00403780522707761], Loss: 1.991110, Acc:0.811320, Semantic loss: 0.737750, BCE loss: 0.536015, SB loss: 0.717344
2023-10-30 17:04:19,459 Epoch: [307/484] Iter:[160/495], Time: 0.38, lr: [0.004037389741399978], Loss: 1.993121, Acc:0.810086, Semantic loss: 0.740641, BCE loss: 0.535505, SB loss: 0.716975
2023-10-30 17:04:23,137 Epoch: [307/484] Iter:[170/495], Time: 0.38, lr: [0.004036974250971468], Loss: 1.989867, Acc:0.808956, Semantic loss: 0.741649, BCE loss: 0.531673, SB loss: 0.716545
2023-10-30 17:04:26,782 Epoch: [307/484] Iter:[180/495], Time: 0.38, lr: [0.004036558755791482], Loss: 1.990050, Acc:0.810206, Semantic loss: 0.741072, BCE loss: 0.533462, SB loss: 0.715516
2023-10-30 17:04:30,439 Epoch: [307/484] Iter:[190/495], Time: 0.38, lr: [0.004036143255859423], Loss: 1.998686, Acc:0.811821, Semantic loss: 0.744823, BCE loss: 0.536728, SB loss: 0.717135
2023-10-30 17:04:34,138 Epoch: [307/484] Iter:[200/495], Time: 0.38, lr: [0.004035727751174691], Loss: 1.996875, Acc:0.811659, Semantic loss: 0.744766, BCE loss: 0.534831, SB loss: 0.717278
2023-10-30 17:04:37,890 Epoch: [307/484] Iter:[210/495], Time: 0.38, lr: [0.004035312241736691], Loss: 1.996684, Acc:0.811087, Semantic loss: 0.744908, BCE loss: 0.534678, SB loss: 0.717098
2023-10-30 17:04:41,556 Epoch: [307/484] Iter:[220/495], Time: 0.38, lr: [0.004034896727544823], Loss: 2.002357, Acc:0.810888, Semantic loss: 0.746913, BCE loss: 0.538581, SB loss: 0.716863
2023-10-30 17:04:45,155 Epoch: [307/484] Iter:[230/495], Time: 0.38, lr: [0.004034481208598489], Loss: 1.995504, Acc:0.811656, Semantic loss: 0.744593, BCE loss: 0.535480, SB loss: 0.715431
2023-10-30 17:04:48,948 Epoch: [307/484] Iter:[240/495], Time: 0.38, lr: [0.004034065684897089], Loss: 1.995081, Acc:0.810478, Semantic loss: 0.744614, BCE loss: 0.534512, SB loss: 0.715954
2023-10-30 17:04:52,662 Epoch: [307/484] Iter:[250/495], Time: 0.38, lr: [0.0040336501564400265], Loss: 1.999962, Acc:0.810697, Semantic loss: 0.748355, BCE loss: 0.534554, SB loss: 0.717053
2023-10-30 17:04:56,354 Epoch: [307/484] Iter:[260/495], Time: 0.38, lr: [0.004033234623226702], Loss: 1.995437, Acc:0.810118, Semantic loss: 0.745965, BCE loss: 0.535021, SB loss: 0.714451
2023-10-30 17:05:00,054 Epoch: [307/484] Iter:[270/495], Time: 0.38, lr: [0.004032819085256517], Loss: 1.993550, Acc:0.810283, Semantic loss: 0.745028, BCE loss: 0.533795, SB loss: 0.714726
2023-10-30 17:05:03,765 Epoch: [307/484] Iter:[280/495], Time: 0.38, lr: [0.004032403542528871], Loss: 1.999695, Acc:0.810399, Semantic loss: 0.748650, BCE loss: 0.535926, SB loss: 0.715119
2023-10-30 17:05:07,426 Epoch: [307/484] Iter:[290/495], Time: 0.38, lr: [0.004031987995043166], Loss: 1.996652, Acc:0.809638, Semantic loss: 0.747713, BCE loss: 0.535268, SB loss: 0.713671
2023-10-30 17:05:11,108 Epoch: [307/484] Iter:[300/495], Time: 0.38, lr: [0.004031572442798803], Loss: 1.992913, Acc:0.808888, Semantic loss: 0.745544, BCE loss: 0.534595, SB loss: 0.712774
2023-10-30 17:05:14,790 Epoch: [307/484] Iter:[310/495], Time: 0.38, lr: [0.004031156885795181], Loss: 1.994821, Acc:0.808192, Semantic loss: 0.747612, BCE loss: 0.532287, SB loss: 0.714921
2023-10-30 17:05:18,509 Epoch: [307/484] Iter:[320/495], Time: 0.38, lr: [0.004030741324031701], Loss: 1.994130, Acc:0.807881, Semantic loss: 0.747360, BCE loss: 0.532227, SB loss: 0.714544
2023-10-30 17:05:22,139 Epoch: [307/484] Iter:[330/495], Time: 0.37, lr: [0.004030325757507764], Loss: 1.992214, Acc:0.807823, Semantic loss: 0.746406, BCE loss: 0.531240, SB loss: 0.714567
2023-10-30 17:05:25,797 Epoch: [307/484] Iter:[340/495], Time: 0.37, lr: [0.00402991018622277], Loss: 1.991594, Acc:0.807736, Semantic loss: 0.746526, BCE loss: 0.530170, SB loss: 0.714898
2023-10-30 17:05:29,550 Epoch: [307/484] Iter:[350/495], Time: 0.37, lr: [0.004029494610176118], Loss: 1.993490, Acc:0.807116, Semantic loss: 0.746716, BCE loss: 0.531318, SB loss: 0.715456
2023-10-30 17:05:33,255 Epoch: [307/484] Iter:[360/495], Time: 0.37, lr: [0.004029079029367207], Loss: 1.990203, Acc:0.807371, Semantic loss: 0.745075, BCE loss: 0.530012, SB loss: 0.715116
2023-10-30 17:05:37,069 Epoch: [307/484] Iter:[370/495], Time: 0.37, lr: [0.00402866344379544], Loss: 1.990295, Acc:0.807364, Semantic loss: 0.745752, BCE loss: 0.530035, SB loss: 0.714508
2023-10-30 17:05:40,935 Epoch: [307/484] Iter:[380/495], Time: 0.37, lr: [0.004028247853460213], Loss: 1.992938, Acc:0.807950, Semantic loss: 0.747721, BCE loss: 0.530177, SB loss: 0.715040
2023-10-30 17:05:44,581 Epoch: [307/484] Iter:[390/495], Time: 0.37, lr: [0.004027832258360927], Loss: 1.988565, Acc:0.806962, Semantic loss: 0.745729, BCE loss: 0.528662, SB loss: 0.714174
2023-10-30 17:05:48,283 Epoch: [307/484] Iter:[400/495], Time: 0.37, lr: [0.00402741665849698], Loss: 1.986922, Acc:0.807237, Semantic loss: 0.744768, BCE loss: 0.527583, SB loss: 0.714571
2023-10-30 17:05:51,966 Epoch: [307/484] Iter:[410/495], Time: 0.37, lr: [0.004027001053867773], Loss: 1.986480, Acc:0.807631, Semantic loss: 0.744151, BCE loss: 0.527221, SB loss: 0.715107
2023-10-30 17:05:55,768 Epoch: [307/484] Iter:[420/495], Time: 0.37, lr: [0.004026585444472703], Loss: 1.991359, Acc:0.807447, Semantic loss: 0.747433, BCE loss: 0.528396, SB loss: 0.715530
2023-10-30 17:05:59,364 Epoch: [307/484] Iter:[430/495], Time: 0.37, lr: [0.00402616983031117], Loss: 1.986315, Acc:0.807845, Semantic loss: 0.745317, BCE loss: 0.526505, SB loss: 0.714494
2023-10-30 17:06:03,085 Epoch: [307/484] Iter:[440/495], Time: 0.37, lr: [0.0040257542113825715], Loss: 1.989242, Acc:0.807885, Semantic loss: 0.746072, BCE loss: 0.527790, SB loss: 0.715381
2023-10-30 17:06:06,791 Epoch: [307/484] Iter:[450/495], Time: 0.37, lr: [0.0040253385876863074], Loss: 1.991154, Acc:0.807396, Semantic loss: 0.746961, BCE loss: 0.528338, SB loss: 0.715856
2023-10-30 17:06:10,466 Epoch: [307/484] Iter:[460/495], Time: 0.37, lr: [0.004024922959221775], Loss: 1.991802, Acc:0.807547, Semantic loss: 0.746516, BCE loss: 0.529620, SB loss: 0.715666
2023-10-30 17:06:14,135 Epoch: [307/484] Iter:[470/495], Time: 0.37, lr: [0.0040245073259883735], Loss: 1.992513, Acc:0.808127, Semantic loss: 0.746857, BCE loss: 0.529993, SB loss: 0.715663
2023-10-30 17:06:18,012 Epoch: [307/484] Iter:[480/495], Time: 0.37, lr: [0.004024091687985499], Loss: 1.990362, Acc:0.807965, Semantic loss: 0.745848, BCE loss: 0.529151, SB loss: 0.715362
2023-10-30 17:06:21,516 Epoch: [307/484] Iter:[490/495], Time: 0.37, lr: [0.004023676045212551], Loss: 1.989391, Acc:0.808816, Semantic loss: 0.744970, BCE loss: 0.529739, SB loss: 0.714683
2023-10-30 17:06:22,922 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:06:23,157 Loss: 1.992, MeanIU:  0.7145, Best_mIoU:  0.7309
2023-10-30 17:06:23,157 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068]
2023-10-30 17:06:24,872 Epoch: [308/484] Iter:[0/495], Time: 1.68, lr: [0.0040234682220371114], Loss: 1.805589, Acc:0.726290, Semantic loss: 0.707560, BCE loss: 0.406837, SB loss: 0.691191
2023-10-30 17:06:28,933 Epoch: [308/484] Iter:[10/495], Time: 0.52, lr: [0.004023052572107924], Loss: 1.958816, Acc:0.803981, Semantic loss: 0.733894, BCE loss: 0.507190, SB loss: 0.717732
2023-10-30 17:06:32,710 Epoch: [308/484] Iter:[20/495], Time: 0.45, lr: [0.004022636917407155], Loss: 1.989299, Acc:0.810712, Semantic loss: 0.764970, BCE loss: 0.518030, SB loss: 0.706299
2023-10-30 17:06:36,404 Epoch: [308/484] Iter:[30/495], Time: 0.43, lr: [0.0040222212579342055], Loss: 2.054182, Acc:0.804347, Semantic loss: 0.810230, BCE loss: 0.523230, SB loss: 0.720722
2023-10-30 17:06:40,014 Epoch: [308/484] Iter:[40/495], Time: 0.41, lr: [0.004021805593688471], Loss: 2.007841, Acc:0.799804, Semantic loss: 0.774053, BCE loss: 0.521355, SB loss: 0.712433
2023-10-30 17:06:43,791 Epoch: [308/484] Iter:[50/495], Time: 0.40, lr: [0.004021389924669347], Loss: 2.013588, Acc:0.800368, Semantic loss: 0.774994, BCE loss: 0.523816, SB loss: 0.714779
2023-10-30 17:06:47,486 Epoch: [308/484] Iter:[60/495], Time: 0.40, lr: [0.004020974250876232], Loss: 1.996511, Acc:0.802699, Semantic loss: 0.761625, BCE loss: 0.523940, SB loss: 0.710946
2023-10-30 17:06:51,245 Epoch: [308/484] Iter:[70/495], Time: 0.40, lr: [0.004020558572308524], Loss: 2.000711, Acc:0.807908, Semantic loss: 0.765009, BCE loss: 0.522246, SB loss: 0.713456
2023-10-30 17:06:54,894 Epoch: [308/484] Iter:[80/495], Time: 0.39, lr: [0.004020142888965617], Loss: 1.992886, Acc:0.808175, Semantic loss: 0.757033, BCE loss: 0.523681, SB loss: 0.712172
2023-10-30 17:06:58,625 Epoch: [308/484] Iter:[90/495], Time: 0.39, lr: [0.00401972720084691], Loss: 1.985078, Acc:0.802704, Semantic loss: 0.753003, BCE loss: 0.520186, SB loss: 0.711890
2023-10-30 17:07:02,340 Epoch: [308/484] Iter:[100/495], Time: 0.39, lr: [0.004019311507951796], Loss: 1.980272, Acc:0.800225, Semantic loss: 0.750376, BCE loss: 0.517556, SB loss: 0.712341
2023-10-30 17:07:06,032 Epoch: [308/484] Iter:[110/495], Time: 0.39, lr: [0.004018895810279676], Loss: 1.983189, Acc:0.802955, Semantic loss: 0.750257, BCE loss: 0.521124, SB loss: 0.711809
2023-10-30 17:07:09,740 Epoch: [308/484] Iter:[120/495], Time: 0.38, lr: [0.0040184801078299425], Loss: 1.973130, Acc:0.804554, Semantic loss: 0.744251, BCE loss: 0.519126, SB loss: 0.709753
2023-10-30 17:07:13,357 Epoch: [308/484] Iter:[130/495], Time: 0.38, lr: [0.0040180644006019926], Loss: 1.967901, Acc:0.802681, Semantic loss: 0.743521, BCE loss: 0.515858, SB loss: 0.708522
2023-10-30 17:07:17,037 Epoch: [308/484] Iter:[140/495], Time: 0.38, lr: [0.004017648688595221], Loss: 1.964804, Acc:0.802340, Semantic loss: 0.742484, BCE loss: 0.514478, SB loss: 0.707841
2023-10-30 17:07:20,773 Epoch: [308/484] Iter:[150/495], Time: 0.38, lr: [0.004017232971809026], Loss: 1.975484, Acc:0.802994, Semantic loss: 0.748986, BCE loss: 0.516971, SB loss: 0.709527
2023-10-30 17:07:24,477 Epoch: [308/484] Iter:[160/495], Time: 0.38, lr: [0.004016817250242801], Loss: 1.973049, Acc:0.803359, Semantic loss: 0.748408, BCE loss: 0.515925, SB loss: 0.708717
2023-10-30 17:07:28,261 Epoch: [308/484] Iter:[170/495], Time: 0.38, lr: [0.0040164015238959416], Loss: 1.973185, Acc:0.803853, Semantic loss: 0.745160, BCE loss: 0.518608, SB loss: 0.709417
2023-10-30 17:07:31,837 Epoch: [308/484] Iter:[180/495], Time: 0.38, lr: [0.0040159857927678415], Loss: 1.972076, Acc:0.804857, Semantic loss: 0.745632, BCE loss: 0.516360, SB loss: 0.710084
2023-10-30 17:07:35,483 Epoch: [308/484] Iter:[190/495], Time: 0.38, lr: [0.004015570056857899], Loss: 1.981166, Acc:0.802543, Semantic loss: 0.749382, BCE loss: 0.520403, SB loss: 0.711381
2023-10-30 17:07:39,302 Epoch: [308/484] Iter:[200/495], Time: 0.38, lr: [0.004015154316165507], Loss: 1.978834, Acc:0.800639, Semantic loss: 0.748519, BCE loss: 0.518416, SB loss: 0.711899
2023-10-30 17:07:43,091 Epoch: [308/484] Iter:[210/495], Time: 0.38, lr: [0.004014738570690061], Loss: 1.982101, Acc:0.801833, Semantic loss: 0.749540, BCE loss: 0.518772, SB loss: 0.713789
2023-10-30 17:07:46,816 Epoch: [308/484] Iter:[220/495], Time: 0.38, lr: [0.004014322820430954], Loss: 1.974192, Acc:0.802142, Semantic loss: 0.745823, BCE loss: 0.516247, SB loss: 0.712121
2023-10-30 17:07:50,486 Epoch: [308/484] Iter:[230/495], Time: 0.38, lr: [0.004013907065387582], Loss: 1.976134, Acc:0.803075, Semantic loss: 0.747692, BCE loss: 0.515751, SB loss: 0.712692
2023-10-30 17:07:54,144 Epoch: [308/484] Iter:[240/495], Time: 0.38, lr: [0.004013491305559341], Loss: 1.976242, Acc:0.804180, Semantic loss: 0.746975, BCE loss: 0.517516, SB loss: 0.711751
2023-10-30 17:07:57,725 Epoch: [308/484] Iter:[250/495], Time: 0.38, lr: [0.004013075540945622], Loss: 1.975799, Acc:0.803504, Semantic loss: 0.746932, BCE loss: 0.516527, SB loss: 0.712341
2023-10-30 17:08:01,439 Epoch: [308/484] Iter:[260/495], Time: 0.38, lr: [0.0040126597715458194], Loss: 1.977266, Acc:0.803595, Semantic loss: 0.747276, BCE loss: 0.517181, SB loss: 0.712809
2023-10-30 17:08:05,165 Epoch: [308/484] Iter:[270/495], Time: 0.38, lr: [0.004012243997359329], Loss: 1.974153, Acc:0.803597, Semantic loss: 0.746764, BCE loss: 0.514950, SB loss: 0.712439
2023-10-30 17:08:08,903 Epoch: [308/484] Iter:[280/495], Time: 0.38, lr: [0.004011828218385543], Loss: 1.978091, Acc:0.804352, Semantic loss: 0.750294, BCE loss: 0.514827, SB loss: 0.712971
2023-10-30 17:08:12,535 Epoch: [308/484] Iter:[290/495], Time: 0.38, lr: [0.004011412434623856], Loss: 1.975315, Acc:0.802982, Semantic loss: 0.749772, BCE loss: 0.513230, SB loss: 0.712313
2023-10-30 17:08:16,244 Epoch: [308/484] Iter:[300/495], Time: 0.38, lr: [0.00401099664607366], Loss: 1.980038, Acc:0.802787, Semantic loss: 0.751378, BCE loss: 0.514703, SB loss: 0.713957
2023-10-30 17:08:20,071 Epoch: [308/484] Iter:[310/495], Time: 0.38, lr: [0.00401058085273435], Loss: 1.985942, Acc:0.803016, Semantic loss: 0.755598, BCE loss: 0.514830, SB loss: 0.715513
2023-10-30 17:08:23,843 Epoch: [308/484] Iter:[320/495], Time: 0.38, lr: [0.004010165054605318], Loss: 1.992237, Acc:0.802328, Semantic loss: 0.757242, BCE loss: 0.518317, SB loss: 0.716678
2023-10-30 17:08:27,537 Epoch: [308/484] Iter:[330/495], Time: 0.38, lr: [0.004009749251685958], Loss: 1.991797, Acc:0.801871, Semantic loss: 0.756743, BCE loss: 0.518793, SB loss: 0.716261
2023-10-30 17:08:31,197 Epoch: [308/484] Iter:[340/495], Time: 0.38, lr: [0.00400933344397566], Loss: 1.996713, Acc:0.801516, Semantic loss: 0.758396, BCE loss: 0.522000, SB loss: 0.716317
2023-10-30 17:08:34,998 Epoch: [308/484] Iter:[350/495], Time: 0.38, lr: [0.004008917631473822], Loss: 1.994916, Acc:0.801260, Semantic loss: 0.756523, BCE loss: 0.521020, SB loss: 0.717373
2023-10-30 17:08:38,705 Epoch: [308/484] Iter:[360/495], Time: 0.38, lr: [0.004008501814179832], Loss: 1.998513, Acc:0.802536, Semantic loss: 0.756870, BCE loss: 0.523284, SB loss: 0.718359
2023-10-30 17:08:42,412 Epoch: [308/484] Iter:[370/495], Time: 0.38, lr: [0.0040080859920930845], Loss: 2.000169, Acc:0.803268, Semantic loss: 0.756614, BCE loss: 0.524776, SB loss: 0.718779
2023-10-30 17:08:46,067 Epoch: [308/484] Iter:[380/495], Time: 0.37, lr: [0.00400767016521297], Loss: 2.001240, Acc:0.802519, Semantic loss: 0.757895, BCE loss: 0.524195, SB loss: 0.719150
2023-10-30 17:08:49,801 Epoch: [308/484] Iter:[390/495], Time: 0.37, lr: [0.004007254333538883], Loss: 2.000225, Acc:0.802299, Semantic loss: 0.757313, BCE loss: 0.523917, SB loss: 0.718996
2023-10-30 17:08:53,562 Epoch: [308/484] Iter:[400/495], Time: 0.37, lr: [0.0040068384970702135], Loss: 1.998231, Acc:0.802737, Semantic loss: 0.756585, BCE loss: 0.522593, SB loss: 0.719053
2023-10-30 17:08:57,196 Epoch: [308/484] Iter:[410/495], Time: 0.37, lr: [0.0040064226558063545], Loss: 1.998263, Acc:0.802268, Semantic loss: 0.756671, BCE loss: 0.522781, SB loss: 0.718812
2023-10-30 17:09:00,871 Epoch: [308/484] Iter:[420/495], Time: 0.37, lr: [0.004006006809746697], Loss: 1.999095, Acc:0.801908, Semantic loss: 0.756276, BCE loss: 0.523731, SB loss: 0.719088
2023-10-30 17:09:04,538 Epoch: [308/484] Iter:[430/495], Time: 0.37, lr: [0.004005590958890633], Loss: 1.998611, Acc:0.802024, Semantic loss: 0.755632, BCE loss: 0.524056, SB loss: 0.718923
2023-10-30 17:09:08,220 Epoch: [308/484] Iter:[440/495], Time: 0.37, lr: [0.0040051751032375545], Loss: 1.997710, Acc:0.801669, Semantic loss: 0.755775, BCE loss: 0.523164, SB loss: 0.718770
2023-10-30 17:09:11,977 Epoch: [308/484] Iter:[450/495], Time: 0.37, lr: [0.00400475924278685], Loss: 2.000147, Acc:0.801389, Semantic loss: 0.757062, BCE loss: 0.523884, SB loss: 0.719201
2023-10-30 17:09:15,746 Epoch: [308/484] Iter:[460/495], Time: 0.37, lr: [0.004004343377537915], Loss: 2.001255, Acc:0.801845, Semantic loss: 0.756943, BCE loss: 0.524876, SB loss: 0.719436
2023-10-30 17:09:19,312 Epoch: [308/484] Iter:[470/495], Time: 0.37, lr: [0.004003927507490137], Loss: 1.999971, Acc:0.802454, Semantic loss: 0.755592, BCE loss: 0.525359, SB loss: 0.719020
2023-10-30 17:09:23,012 Epoch: [308/484] Iter:[480/495], Time: 0.37, lr: [0.004003511632642907], Loss: 1.996850, Acc:0.802301, Semantic loss: 0.754488, BCE loss: 0.524135, SB loss: 0.718228
2023-10-30 17:09:26,532 Epoch: [308/484] Iter:[490/495], Time: 0.37, lr: [0.004003095752995616], Loss: 1.997374, Acc:0.801897, Semantic loss: 0.754976, BCE loss: 0.524348, SB loss: 0.718050
2023-10-30 17:09:27,946 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:09:28,184 Loss: 1.992, MeanIU:  0.7145, Best_mIoU:  0.7309
2023-10-30 17:09:28,184 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068]
2023-10-30 17:09:30,390 Epoch: [309/484] Iter:[0/495], Time: 2.17, lr: [0.004002887811371758], Loss: 2.019248, Acc:0.837457, Semantic loss: 0.670895, BCE loss: 0.661100, SB loss: 0.687253
2023-10-30 17:09:34,321 Epoch: [309/484] Iter:[10/495], Time: 0.55, lr: [0.0040024719245232345], Loss: 1.886888, Acc:0.833043, Semantic loss: 0.708253, BCE loss: 0.491084, SB loss: 0.687551
2023-10-30 17:09:37,941 Epoch: [309/484] Iter:[20/495], Time: 0.46, lr: [0.0040020560328731265], Loss: 1.944617, Acc:0.807562, Semantic loss: 0.711416, BCE loss: 0.527118, SB loss: 0.706083
2023-10-30 17:09:41,635 Epoch: [309/484] Iter:[30/495], Time: 0.43, lr: [0.004001640136420824], Loss: 1.950593, Acc:0.801126, Semantic loss: 0.722940, BCE loss: 0.525313, SB loss: 0.702341
2023-10-30 17:09:45,338 Epoch: [309/484] Iter:[40/495], Time: 0.42, lr: [0.004001224235165716], Loss: 1.961383, Acc:0.805124, Semantic loss: 0.727192, BCE loss: 0.527351, SB loss: 0.706841
2023-10-30 17:09:49,148 Epoch: [309/484] Iter:[50/495], Time: 0.41, lr: [0.004000808329107194], Loss: 1.961501, Acc:0.797161, Semantic loss: 0.741857, BCE loss: 0.506828, SB loss: 0.712816
2023-10-30 17:09:52,817 Epoch: [309/484] Iter:[60/495], Time: 0.40, lr: [0.004000392418244647], Loss: 1.977318, Acc:0.794867, Semantic loss: 0.746389, BCE loss: 0.517280, SB loss: 0.713649
2023-10-30 17:09:56,515 Epoch: [309/484] Iter:[70/495], Time: 0.40, lr: [0.0039999765025774655], Loss: 2.004596, Acc:0.801702, Semantic loss: 0.754420, BCE loss: 0.532592, SB loss: 0.717584
2023-10-30 17:10:00,137 Epoch: [309/484] Iter:[80/495], Time: 0.39, lr: [0.003999560582105036], Loss: 1.991330, Acc:0.803140, Semantic loss: 0.749112, BCE loss: 0.527295, SB loss: 0.714924
2023-10-30 17:10:03,869 Epoch: [309/484] Iter:[90/495], Time: 0.39, lr: [0.0039991446568267515], Loss: 1.984635, Acc:0.803369, Semantic loss: 0.748657, BCE loss: 0.522816, SB loss: 0.713163
2023-10-30 17:10:07,562 Epoch: [309/484] Iter:[100/495], Time: 0.39, lr: [0.003998728726741998], Loss: 1.981770, Acc:0.797367, Semantic loss: 0.742236, BCE loss: 0.524844, SB loss: 0.714689
2023-10-30 17:10:11,364 Epoch: [309/484] Iter:[110/495], Time: 0.39, lr: [0.003998312791850167], Loss: 1.982582, Acc:0.800379, Semantic loss: 0.738138, BCE loss: 0.529421, SB loss: 0.715023
2023-10-30 17:10:15,076 Epoch: [309/484] Iter:[120/495], Time: 0.39, lr: [0.003997896852150645], Loss: 1.977180, Acc:0.803188, Semantic loss: 0.735707, BCE loss: 0.527536, SB loss: 0.713938
2023-10-30 17:10:18,748 Epoch: [309/484] Iter:[130/495], Time: 0.39, lr: [0.003997480907642822], Loss: 1.983635, Acc:0.804014, Semantic loss: 0.741653, BCE loss: 0.523589, SB loss: 0.718393
2023-10-30 17:10:22,528 Epoch: [309/484] Iter:[140/495], Time: 0.39, lr: [0.003997064958326087], Loss: 1.984372, Acc:0.804480, Semantic loss: 0.742104, BCE loss: 0.524856, SB loss: 0.717412
2023-10-30 17:10:26,193 Epoch: [309/484] Iter:[150/495], Time: 0.38, lr: [0.003996649004199827], Loss: 1.981274, Acc:0.805182, Semantic loss: 0.740380, BCE loss: 0.524856, SB loss: 0.716038
2023-10-30 17:10:29,846 Epoch: [309/484] Iter:[160/495], Time: 0.38, lr: [0.003996233045263429], Loss: 1.982277, Acc:0.805545, Semantic loss: 0.742289, BCE loss: 0.522871, SB loss: 0.717117
2023-10-30 17:10:33,708 Epoch: [309/484] Iter:[170/495], Time: 0.38, lr: [0.0039958170815162855], Loss: 1.988534, Acc:0.805076, Semantic loss: 0.744144, BCE loss: 0.525914, SB loss: 0.718476
2023-10-30 17:10:37,477 Epoch: [309/484] Iter:[180/495], Time: 0.38, lr: [0.00399540111295778], Loss: 1.987001, Acc:0.805823, Semantic loss: 0.743509, BCE loss: 0.527088, SB loss: 0.716404
2023-10-30 17:10:41,162 Epoch: [309/484] Iter:[190/495], Time: 0.38, lr: [0.003994985139587303], Loss: 1.985653, Acc:0.806216, Semantic loss: 0.743802, BCE loss: 0.524820, SB loss: 0.717031
2023-10-30 17:10:44,835 Epoch: [309/484] Iter:[200/495], Time: 0.38, lr: [0.00399456916140424], Loss: 1.983303, Acc:0.807948, Semantic loss: 0.742143, BCE loss: 0.526180, SB loss: 0.714979
2023-10-30 17:10:48,570 Epoch: [309/484] Iter:[210/495], Time: 0.38, lr: [0.0039941531784079805], Loss: 1.979012, Acc:0.808171, Semantic loss: 0.740161, BCE loss: 0.524333, SB loss: 0.714518
2023-10-30 17:10:52,354 Epoch: [309/484] Iter:[220/495], Time: 0.38, lr: [0.0039937371905979105], Loss: 1.978822, Acc:0.808064, Semantic loss: 0.741485, BCE loss: 0.522673, SB loss: 0.714664
2023-10-30 17:10:56,093 Epoch: [309/484] Iter:[230/495], Time: 0.38, lr: [0.003993321197973418], Loss: 1.984864, Acc:0.807723, Semantic loss: 0.744828, BCE loss: 0.525240, SB loss: 0.714796
2023-10-30 17:10:59,787 Epoch: [309/484] Iter:[240/495], Time: 0.38, lr: [0.003992905200533889], Loss: 1.982895, Acc:0.806578, Semantic loss: 0.746173, BCE loss: 0.522394, SB loss: 0.714328
2023-10-30 17:11:03,604 Epoch: [309/484] Iter:[250/495], Time: 0.38, lr: [0.00399248919827871], Loss: 1.980593, Acc:0.805080, Semantic loss: 0.745921, BCE loss: 0.519921, SB loss: 0.714752
2023-10-30 17:11:07,228 Epoch: [309/484] Iter:[260/495], Time: 0.38, lr: [0.00399207319120727], Loss: 1.979037, Acc:0.804663, Semantic loss: 0.744938, BCE loss: 0.519529, SB loss: 0.714570
2023-10-30 17:11:10,988 Epoch: [309/484] Iter:[270/495], Time: 0.38, lr: [0.003991657179318953], Loss: 1.977680, Acc:0.803857, Semantic loss: 0.744023, BCE loss: 0.518731, SB loss: 0.714927
2023-10-30 17:11:14,722 Epoch: [309/484] Iter:[280/495], Time: 0.38, lr: [0.003991241162613148], Loss: 1.980642, Acc:0.804183, Semantic loss: 0.743449, BCE loss: 0.521153, SB loss: 0.716040
2023-10-30 17:11:18,361 Epoch: [309/484] Iter:[290/495], Time: 0.38, lr: [0.003990825141089239], Loss: 1.982383, Acc:0.803472, Semantic loss: 0.744519, BCE loss: 0.521246, SB loss: 0.716617
2023-10-30 17:11:22,136 Epoch: [309/484] Iter:[300/495], Time: 0.38, lr: [0.003990409114746614], Loss: 1.984380, Acc:0.802951, Semantic loss: 0.744470, BCE loss: 0.522382, SB loss: 0.717529
2023-10-30 17:11:25,814 Epoch: [309/484] Iter:[310/495], Time: 0.38, lr: [0.0039899930835846555], Loss: 1.979684, Acc:0.803843, Semantic loss: 0.742513, BCE loss: 0.520583, SB loss: 0.716588
2023-10-30 17:11:29,499 Epoch: [309/484] Iter:[320/495], Time: 0.38, lr: [0.0039895770476027536], Loss: 1.977363, Acc:0.803208, Semantic loss: 0.742392, BCE loss: 0.518449, SB loss: 0.716522
2023-10-30 17:11:33,239 Epoch: [309/484] Iter:[330/495], Time: 0.38, lr: [0.003989161006800293], Loss: 1.975332, Acc:0.803980, Semantic loss: 0.740502, BCE loss: 0.519050, SB loss: 0.715780
2023-10-30 17:11:36,881 Epoch: [309/484] Iter:[340/495], Time: 0.38, lr: [0.003988744961176657], Loss: 1.971290, Acc:0.804170, Semantic loss: 0.738344, BCE loss: 0.518214, SB loss: 0.714732
2023-10-30 17:11:40,592 Epoch: [309/484] Iter:[350/495], Time: 0.38, lr: [0.003988328910731231], Loss: 1.972894, Acc:0.803889, Semantic loss: 0.737837, BCE loss: 0.519705, SB loss: 0.715353
2023-10-30 17:11:44,335 Epoch: [309/484] Iter:[360/495], Time: 0.38, lr: [0.003987912855463404], Loss: 1.977159, Acc:0.803521, Semantic loss: 0.740248, BCE loss: 0.520615, SB loss: 0.716296
2023-10-30 17:11:48,005 Epoch: [309/484] Iter:[370/495], Time: 0.38, lr: [0.003987496795372558], Loss: 1.976748, Acc:0.803608, Semantic loss: 0.739536, BCE loss: 0.520804, SB loss: 0.716408
2023-10-30 17:11:51,678 Epoch: [309/484] Iter:[380/495], Time: 0.38, lr: [0.003987080730458078], Loss: 1.977181, Acc:0.802756, Semantic loss: 0.740094, BCE loss: 0.520160, SB loss: 0.716926
2023-10-30 17:11:55,319 Epoch: [309/484] Iter:[390/495], Time: 0.38, lr: [0.00398666466071935], Loss: 1.975088, Acc:0.802518, Semantic loss: 0.739837, BCE loss: 0.518827, SB loss: 0.716425
2023-10-30 17:11:59,090 Epoch: [309/484] Iter:[400/495], Time: 0.38, lr: [0.003986248586155757], Loss: 1.973554, Acc:0.802729, Semantic loss: 0.739752, BCE loss: 0.518671, SB loss: 0.715131
2023-10-30 17:12:02,782 Epoch: [309/484] Iter:[410/495], Time: 0.38, lr: [0.003985832506766686], Loss: 1.973978, Acc:0.803144, Semantic loss: 0.741067, BCE loss: 0.517460, SB loss: 0.715451
2023-10-30 17:12:06,486 Epoch: [309/484] Iter:[420/495], Time: 0.38, lr: [0.003985416422551518], Loss: 1.975695, Acc:0.801503, Semantic loss: 0.742299, BCE loss: 0.517346, SB loss: 0.716051
2023-10-30 17:12:10,100 Epoch: [309/484] Iter:[430/495], Time: 0.38, lr: [0.003985000333509639], Loss: 1.978513, Acc:0.800859, Semantic loss: 0.743632, BCE loss: 0.517393, SB loss: 0.717487
2023-10-30 17:12:13,778 Epoch: [309/484] Iter:[440/495], Time: 0.38, lr: [0.0039845842396404344], Loss: 1.980391, Acc:0.800692, Semantic loss: 0.744012, BCE loss: 0.518269, SB loss: 0.718110
2023-10-30 17:12:17,397 Epoch: [309/484] Iter:[450/495], Time: 0.38, lr: [0.003984168140943285], Loss: 1.980830, Acc:0.801055, Semantic loss: 0.743041, BCE loss: 0.519572, SB loss: 0.718217
2023-10-30 17:12:21,029 Epoch: [309/484] Iter:[460/495], Time: 0.37, lr: [0.003983752037417578], Loss: 1.980000, Acc:0.801323, Semantic loss: 0.742492, BCE loss: 0.519535, SB loss: 0.717973
2023-10-30 17:12:24,755 Epoch: [309/484] Iter:[470/495], Time: 0.37, lr: [0.003983335929062693], Loss: 1.981515, Acc:0.801514, Semantic loss: 0.744050, BCE loss: 0.519698, SB loss: 0.717766
2023-10-30 17:12:28,500 Epoch: [309/484] Iter:[480/495], Time: 0.37, lr: [0.003982919815878017], Loss: 1.981279, Acc:0.801610, Semantic loss: 0.743477, BCE loss: 0.520192, SB loss: 0.717610
2023-10-30 17:12:32,042 Epoch: [309/484] Iter:[490/495], Time: 0.37, lr: [0.003982503697862932], Loss: 1.985080, Acc:0.802388, Semantic loss: 0.745317, BCE loss: 0.521517, SB loss: 0.718246
2023-10-30 17:12:33,455 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:12:33,690 Loss: 1.992, MeanIU:  0.7145, Best_mIoU:  0.7309
2023-10-30 17:12:33,690 [0.97756724 0.82558652 0.91535629 0.54154232 0.59965596 0.59947062
 0.69407335 0.75546814 0.91521564 0.59345872 0.9356846  0.78594648
 0.54575519 0.93749134 0.66358805 0.71114136 0.33515207 0.50305716
 0.74119068]
2023-10-30 17:12:35,667 Epoch: [310/484] Iter:[0/495], Time: 1.94, lr: [0.003982295637043792], Loss: 1.695654, Acc:0.819385, Semantic loss: 0.635565, BCE loss: 0.434443, SB loss: 0.625646
2023-10-30 17:12:39,926 Epoch: [310/484] Iter:[10/495], Time: 0.56, lr: [0.003981879511781937], Loss: 1.959974, Acc:0.791923, Semantic loss: 0.733782, BCE loss: 0.509068, SB loss: 0.717123
2023-10-30 17:12:43,558 Epoch: [310/484] Iter:[20/495], Time: 0.47, lr: [0.003981463381688128], Loss: 1.944166, Acc:0.808049, Semantic loss: 0.698193, BCE loss: 0.549720, SB loss: 0.696253
2023-10-30 17:12:47,264 Epoch: [310/484] Iter:[30/495], Time: 0.44, lr: [0.003981047246761751], Loss: 1.952736, Acc:0.796262, Semantic loss: 0.706373, BCE loss: 0.542171, SB loss: 0.704193
2023-10-30 17:12:50,961 Epoch: [310/484] Iter:[40/495], Time: 0.42, lr: [0.0039806311070021885], Loss: 1.956346, Acc:0.791121, Semantic loss: 0.712924, BCE loss: 0.539499, SB loss: 0.703923
2023-10-30 17:12:54,661 Epoch: [310/484] Iter:[50/495], Time: 0.41, lr: [0.003980214962408822], Loss: 1.969930, Acc:0.790898, Semantic loss: 0.719081, BCE loss: 0.542244, SB loss: 0.708606
2023-10-30 17:12:58,363 Epoch: [310/484] Iter:[60/495], Time: 0.40, lr: [0.003979798812981032], Loss: 1.976184, Acc:0.788782, Semantic loss: 0.728325, BCE loss: 0.537495, SB loss: 0.710364
2023-10-30 17:13:02,050 Epoch: [310/484] Iter:[70/495], Time: 0.40, lr: [0.003979382658718204], Loss: 1.977904, Acc:0.789324, Semantic loss: 0.735297, BCE loss: 0.532028, SB loss: 0.710579
2023-10-30 17:13:05,757 Epoch: [310/484] Iter:[80/495], Time: 0.40, lr: [0.003978966499619719], Loss: 1.974655, Acc:0.790182, Semantic loss: 0.738402, BCE loss: 0.526886, SB loss: 0.709367
2023-10-30 17:13:09,430 Epoch: [310/484] Iter:[90/495], Time: 0.39, lr: [0.003978550335684958], Loss: 1.979523, Acc:0.790471, Semantic loss: 0.741455, BCE loss: 0.528034, SB loss: 0.710033
2023-10-30 17:13:13,096 Epoch: [310/484] Iter:[100/495], Time: 0.39, lr: [0.003978134166913302], Loss: 1.965230, Acc:0.793226, Semantic loss: 0.733039, BCE loss: 0.525957, SB loss: 0.706234
2023-10-30 17:13:16,721 Epoch: [310/484] Iter:[110/495], Time: 0.39, lr: [0.003977717993304135], Loss: 1.965089, Acc:0.791711, Semantic loss: 0.732450, BCE loss: 0.526038, SB loss: 0.706601
2023-10-30 17:13:20,419 Epoch: [310/484] Iter:[120/495], Time: 0.39, lr: [0.0039773018148568364], Loss: 1.964254, Acc:0.790141, Semantic loss: 0.731888, BCE loss: 0.526990, SB loss: 0.705376
2023-10-30 17:13:24,218 Epoch: [310/484] Iter:[130/495], Time: 0.39, lr: [0.003976885631570787], Loss: 1.972145, Acc:0.788191, Semantic loss: 0.735562, BCE loss: 0.528523, SB loss: 0.708060
2023-10-30 17:13:27,871 Epoch: [310/484] Iter:[140/495], Time: 0.38, lr: [0.0039764694434453705], Loss: 1.977643, Acc:0.788120, Semantic loss: 0.738671, BCE loss: 0.530795, SB loss: 0.708178
2023-10-30 17:13:31,491 Epoch: [310/484] Iter:[150/495], Time: 0.38, lr: [0.003976053250479966], Loss: 1.971296, Acc:0.787763, Semantic loss: 0.734532, BCE loss: 0.527952, SB loss: 0.708812
2023-10-30 17:13:35,139 Epoch: [310/484] Iter:[160/495], Time: 0.38, lr: [0.003975637052673955], Loss: 1.967001, Acc:0.788515, Semantic loss: 0.730129, BCE loss: 0.527359, SB loss: 0.709514
2023-10-30 17:13:38,979 Epoch: [310/484] Iter:[170/495], Time: 0.38, lr: [0.0039752208500267155], Loss: 1.967913, Acc:0.790645, Semantic loss: 0.731662, BCE loss: 0.526277, SB loss: 0.709974
2023-10-30 17:13:42,643 Epoch: [310/484] Iter:[180/495], Time: 0.38, lr: [0.003974804642537632], Loss: 1.972479, Acc:0.791426, Semantic loss: 0.735792, BCE loss: 0.527076, SB loss: 0.709612
2023-10-30 17:13:46,367 Epoch: [310/484] Iter:[190/495], Time: 0.38, lr: [0.003974388430206083], Loss: 1.971675, Acc:0.791351, Semantic loss: 0.736009, BCE loss: 0.526498, SB loss: 0.709168
2023-10-30 17:13:50,053 Epoch: [310/484] Iter:[200/495], Time: 0.38, lr: [0.0039739722130314485], Loss: 1.968450, Acc:0.791314, Semantic loss: 0.736101, BCE loss: 0.523325, SB loss: 0.709024
2023-10-30 17:13:53,640 Epoch: [310/484] Iter:[210/495], Time: 0.38, lr: [0.003973555991013108], Loss: 1.963150, Acc:0.791093, Semantic loss: 0.733067, BCE loss: 0.521405, SB loss: 0.708679
2023-10-30 17:13:57,337 Epoch: [310/484] Iter:[220/495], Time: 0.38, lr: [0.003973139764150442], Loss: 1.961363, Acc:0.790456, Semantic loss: 0.733720, BCE loss: 0.519273, SB loss: 0.708370
2023-10-30 17:14:01,169 Epoch: [310/484] Iter:[230/495], Time: 0.38, lr: [0.003972723532442832], Loss: 1.968357, Acc:0.791090, Semantic loss: 0.734734, BCE loss: 0.523438, SB loss: 0.710186
2023-10-30 17:14:04,936 Epoch: [310/484] Iter:[240/495], Time: 0.38, lr: [0.003972307295889654], Loss: 1.965991, Acc:0.791054, Semantic loss: 0.734783, BCE loss: 0.521950, SB loss: 0.709258
2023-10-30 17:14:08,642 Epoch: [310/484] Iter:[250/495], Time: 0.38, lr: [0.00397189105449029], Loss: 1.968053, Acc:0.790788, Semantic loss: 0.735777, BCE loss: 0.521813, SB loss: 0.710464
2023-10-30 17:14:12,307 Epoch: [310/484] Iter:[260/495], Time: 0.38, lr: [0.003971474808244118], Loss: 1.968539, Acc:0.793193, Semantic loss: 0.734362, BCE loss: 0.523593, SB loss: 0.710584
2023-10-30 17:14:15,916 Epoch: [310/484] Iter:[270/495], Time: 0.38, lr: [0.003971058557150519], Loss: 1.969681, Acc:0.792473, Semantic loss: 0.733958, BCE loss: 0.524857, SB loss: 0.710866
2023-10-30 17:14:19,590 Epoch: [310/484] Iter:[280/495], Time: 0.38, lr: [0.00397064230120887], Loss: 1.971109, Acc:0.792888, Semantic loss: 0.735203, BCE loss: 0.524447, SB loss: 0.711459
2023-10-30 17:14:23,379 Epoch: [310/484] Iter:[290/495], Time: 0.38, lr: [0.003970226040418549], Loss: 1.972488, Acc:0.793998, Semantic loss: 0.736152, BCE loss: 0.524831, SB loss: 0.711506
2023-10-30 17:14:27,076 Epoch: [310/484] Iter:[300/495], Time: 0.38, lr: [0.003969809774778938], Loss: 1.973640, Acc:0.794138, Semantic loss: 0.737055, BCE loss: 0.525266, SB loss: 0.711319
2023-10-30 17:14:30,763 Epoch: [310/484] Iter:[310/495], Time: 0.38, lr: [0.003969393504289413], Loss: 1.976905, Acc:0.794053, Semantic loss: 0.739513, BCE loss: 0.525493, SB loss: 0.711899
2023-10-30 17:14:34,350 Epoch: [310/484] Iter:[320/495], Time: 0.38, lr: [0.003968977228949353], Loss: 1.973694, Acc:0.794378, Semantic loss: 0.738782, BCE loss: 0.523430, SB loss: 0.711482
2023-10-30 17:14:38,084 Epoch: [310/484] Iter:[330/495], Time: 0.38, lr: [0.003968560948758136], Loss: 1.974495, Acc:0.793220, Semantic loss: 0.739043, BCE loss: 0.523520, SB loss: 0.711932
2023-10-30 17:14:41,708 Epoch: [310/484] Iter:[340/495], Time: 0.38, lr: [0.00396814466371514], Loss: 1.973295, Acc:0.793536, Semantic loss: 0.738480, BCE loss: 0.523333, SB loss: 0.711481
2023-10-30 17:14:45,371 Epoch: [310/484] Iter:[350/495], Time: 0.38, lr: [0.003967728373819744], Loss: 1.972652, Acc:0.793529, Semantic loss: 0.738196, BCE loss: 0.522475, SB loss: 0.711980
2023-10-30 17:14:49,020 Epoch: [310/484] Iter:[360/495], Time: 0.37, lr: [0.003967312079071325], Loss: 1.970764, Acc:0.793960, Semantic loss: 0.737426, BCE loss: 0.521327, SB loss: 0.712011
2023-10-30 17:14:52,731 Epoch: [310/484] Iter:[370/495], Time: 0.37, lr: [0.003966895779469258], Loss: 1.969248, Acc:0.793980, Semantic loss: 0.737196, BCE loss: 0.520212, SB loss: 0.711840
2023-10-30 17:14:56,393 Epoch: [310/484] Iter:[380/495], Time: 0.37, lr: [0.003966479475012926], Loss: 1.971351, Acc:0.793866, Semantic loss: 0.738246, BCE loss: 0.520833, SB loss: 0.712272
2023-10-30 17:15:00,074 Epoch: [310/484] Iter:[390/495], Time: 0.37, lr: [0.003966063165701702], Loss: 1.972608, Acc:0.795230, Semantic loss: 0.738836, BCE loss: 0.521016, SB loss: 0.712757
2023-10-30 17:15:03,717 Epoch: [310/484] Iter:[400/495], Time: 0.37, lr: [0.003965646851534965], Loss: 1.973863, Acc:0.796328, Semantic loss: 0.738675, BCE loss: 0.521959, SB loss: 0.713230
2023-10-30 17:15:07,418 Epoch: [310/484] Iter:[410/495], Time: 0.37, lr: [0.003965230532512089], Loss: 1.974466, Acc:0.796951, Semantic loss: 0.739376, BCE loss: 0.521825, SB loss: 0.713265
2023-10-30 17:15:11,064 Epoch: [310/484] Iter:[420/495], Time: 0.37, lr: [0.003964814208632456], Loss: 1.975187, Acc:0.797594, Semantic loss: 0.739264, BCE loss: 0.522564, SB loss: 0.713359
2023-10-30 17:15:14,760 Epoch: [310/484] Iter:[430/495], Time: 0.37, lr: [0.003964397879895438], Loss: 1.975737, Acc:0.796991, Semantic loss: 0.739205, BCE loss: 0.522714, SB loss: 0.713817
2023-10-30 17:15:18,440 Epoch: [310/484] Iter:[440/495], Time: 0.37, lr: [0.003963981546300415], Loss: 1.979105, Acc:0.796958, Semantic loss: 0.740712, BCE loss: 0.524089, SB loss: 0.714304
2023-10-30 17:15:22,118 Epoch: [310/484] Iter:[450/495], Time: 0.37, lr: [0.00396356520784676], Loss: 1.977746, Acc:0.797836, Semantic loss: 0.740001, BCE loss: 0.523755, SB loss: 0.713990
2023-10-30 17:15:25,867 Epoch: [310/484] Iter:[460/495], Time: 0.37, lr: [0.003963148864533852], Loss: 1.975291, Acc:0.797661, Semantic loss: 0.738960, BCE loss: 0.522781, SB loss: 0.713550
2023-10-30 17:15:29,541 Epoch: [310/484] Iter:[470/495], Time: 0.37, lr: [0.003962732516361066], Loss: 1.975996, Acc:0.797945, Semantic loss: 0.739370, BCE loss: 0.522873, SB loss: 0.713753
2023-10-30 17:15:33,228 Epoch: [310/484] Iter:[480/495], Time: 0.37, lr: [0.003962316163327778], Loss: 1.976062, Acc:0.797914, Semantic loss: 0.739285, BCE loss: 0.523163, SB loss: 0.713614
2023-10-30 17:15:36,743 Epoch: [310/484] Iter:[490/495], Time: 0.37, lr: [0.003961899805433363], Loss: 1.977319, Acc:0.798714, Semantic loss: 0.739772, BCE loss: 0.523776, SB loss: 0.713771
2023-10-30 17:18:33,736 0 [0.94535479 0.67453394 0.83567617 0.13529043 0.27940825 0.43366168
 0.46378566 0.54792109 0.88881275 0.46435038 0.88066558 0.60556898
 0.03800401 0.78269221 0.00338547 0.05360351 0.0874937  0.0450276
 0.59421154] 0.4610235651168754
2023-10-30 17:18:33,736 1 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289] 0.6824298302621916
2023-10-30 17:18:33,740 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:18:33,976 Loss: 2.069, MeanIU:  0.6824, Best_mIoU:  0.7309
2023-10-30 17:18:33,976 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289]
2023-10-30 17:18:35,905 Epoch: [311/484] Iter:[0/495], Time: 1.90, lr: [0.003961691624663038], Loss: 1.692294, Acc:0.741542, Semantic loss: 0.586178, BCE loss: 0.477354, SB loss: 0.628763
2023-10-30 17:18:39,824 Epoch: [311/484] Iter:[10/495], Time: 0.53, lr: [0.003961275259475765], Loss: 1.886830, Acc:0.763018, Semantic loss: 0.662319, BCE loss: 0.531162, SB loss: 0.693349
2023-10-30 17:18:43,376 Epoch: [311/484] Iter:[20/495], Time: 0.45, lr: [0.003960858889425802], Loss: 1.986492, Acc:0.783649, Semantic loss: 0.714893, BCE loss: 0.572038, SB loss: 0.699562
2023-10-30 17:18:46,952 Epoch: [311/484] Iter:[30/495], Time: 0.42, lr: [0.003960442514512527], Loss: 2.009256, Acc:0.788805, Semantic loss: 0.734032, BCE loss: 0.562609, SB loss: 0.712615
2023-10-30 17:18:50,363 Epoch: [311/484] Iter:[40/495], Time: 0.40, lr: [0.003960026134735316], Loss: 1.955715, Acc:0.790872, Semantic loss: 0.715409, BCE loss: 0.537805, SB loss: 0.702502
2023-10-30 17:18:53,920 Epoch: [311/484] Iter:[50/495], Time: 0.39, lr: [0.003959609750093542], Loss: 1.969772, Acc:0.792914, Semantic loss: 0.727984, BCE loss: 0.536879, SB loss: 0.704909
2023-10-30 17:18:57,510 Epoch: [311/484] Iter:[60/495], Time: 0.39, lr: [0.003959193360586581], Loss: 1.967104, Acc:0.792988, Semantic loss: 0.725344, BCE loss: 0.532710, SB loss: 0.709049
2023-10-30 17:19:01,111 Epoch: [311/484] Iter:[70/495], Time: 0.38, lr: [0.003958776966213806], Loss: 1.973244, Acc:0.795017, Semantic loss: 0.728188, BCE loss: 0.536463, SB loss: 0.708593
2023-10-30 17:19:04,694 Epoch: [311/484] Iter:[80/495], Time: 0.38, lr: [0.003958360566974593], Loss: 1.961643, Acc:0.794708, Semantic loss: 0.724901, BCE loss: 0.528259, SB loss: 0.708484
2023-10-30 17:19:08,355 Epoch: [311/484] Iter:[90/495], Time: 0.38, lr: [0.003957944162868317], Loss: 1.958292, Acc:0.801405, Semantic loss: 0.724909, BCE loss: 0.524651, SB loss: 0.708731
2023-10-30 17:19:11,930 Epoch: [311/484] Iter:[100/495], Time: 0.38, lr: [0.0039575277538943495], Loss: 1.959525, Acc:0.803130, Semantic loss: 0.724595, BCE loss: 0.525455, SB loss: 0.709476
2023-10-30 17:19:15,533 Epoch: [311/484] Iter:[110/495], Time: 0.37, lr: [0.003957111340052066], Loss: 1.948879, Acc:0.801669, Semantic loss: 0.721273, BCE loss: 0.518855, SB loss: 0.708752
2023-10-30 17:19:19,044 Epoch: [311/484] Iter:[120/495], Time: 0.37, lr: [0.003956694921340841], Loss: 1.948249, Acc:0.802788, Semantic loss: 0.721234, BCE loss: 0.518374, SB loss: 0.708641
2023-10-30 17:19:22,656 Epoch: [311/484] Iter:[130/495], Time: 0.37, lr: [0.003956278497760047], Loss: 1.950947, Acc:0.804699, Semantic loss: 0.723304, BCE loss: 0.516540, SB loss: 0.711103
2023-10-30 17:19:26,365 Epoch: [311/484] Iter:[140/495], Time: 0.37, lr: [0.0039558620693090595], Loss: 1.944207, Acc:0.806085, Semantic loss: 0.721928, BCE loss: 0.513215, SB loss: 0.709064
2023-10-30 17:19:30,106 Epoch: [311/484] Iter:[150/495], Time: 0.37, lr: [0.003955445635987248], Loss: 1.945610, Acc:0.806082, Semantic loss: 0.724942, BCE loss: 0.511170, SB loss: 0.709498
2023-10-30 17:19:33,754 Epoch: [311/484] Iter:[160/495], Time: 0.37, lr: [0.00395502919779399], Loss: 1.941512, Acc:0.807715, Semantic loss: 0.726046, BCE loss: 0.508053, SB loss: 0.707412
2023-10-30 17:19:37,353 Epoch: [311/484] Iter:[170/495], Time: 0.37, lr: [0.003954612754728657], Loss: 1.939927, Acc:0.806740, Semantic loss: 0.726166, BCE loss: 0.507655, SB loss: 0.706105
2023-10-30 17:19:40,994 Epoch: [311/484] Iter:[180/495], Time: 0.37, lr: [0.003954196306790621], Loss: 1.943959, Acc:0.808851, Semantic loss: 0.726016, BCE loss: 0.511131, SB loss: 0.706813
2023-10-30 17:19:44,696 Epoch: [311/484] Iter:[190/495], Time: 0.37, lr: [0.003953779853979255], Loss: 1.954765, Acc:0.809402, Semantic loss: 0.729379, BCE loss: 0.517787, SB loss: 0.707599
2023-10-30 17:19:48,229 Epoch: [311/484] Iter:[200/495], Time: 0.37, lr: [0.003953363396293932], Loss: 1.961382, Acc:0.809801, Semantic loss: 0.733448, BCE loss: 0.517820, SB loss: 0.710114
2023-10-30 17:19:51,909 Epoch: [311/484] Iter:[210/495], Time: 0.37, lr: [0.0039529469337340264], Loss: 1.964044, Acc:0.810354, Semantic loss: 0.734313, BCE loss: 0.518907, SB loss: 0.710824
2023-10-30 17:19:55,618 Epoch: [311/484] Iter:[220/495], Time: 0.37, lr: [0.003952530466298908], Loss: 1.964041, Acc:0.809521, Semantic loss: 0.733853, BCE loss: 0.518111, SB loss: 0.712077
2023-10-30 17:19:59,262 Epoch: [311/484] Iter:[230/495], Time: 0.37, lr: [0.003952113993987948], Loss: 1.965192, Acc:0.809472, Semantic loss: 0.734401, BCE loss: 0.518310, SB loss: 0.712481
2023-10-30 17:20:03,113 Epoch: [311/484] Iter:[240/495], Time: 0.37, lr: [0.003951697516800521], Loss: 1.970504, Acc:0.808650, Semantic loss: 0.736433, BCE loss: 0.520143, SB loss: 0.713928
2023-10-30 17:20:06,710 Epoch: [311/484] Iter:[250/495], Time: 0.37, lr: [0.003951281034735998], Loss: 1.968021, Acc:0.808380, Semantic loss: 0.734371, BCE loss: 0.521137, SB loss: 0.712513
2023-10-30 17:20:10,599 Epoch: [311/484] Iter:[260/495], Time: 0.37, lr: [0.003950864547793751], Loss: 1.969723, Acc:0.809380, Semantic loss: 0.735859, BCE loss: 0.521131, SB loss: 0.712733
2023-10-30 17:20:14,318 Epoch: [311/484] Iter:[270/495], Time: 0.37, lr: [0.0039504480559731485], Loss: 1.976318, Acc:0.811113, Semantic loss: 0.737775, BCE loss: 0.524832, SB loss: 0.713712
2023-10-30 17:20:17,914 Epoch: [311/484] Iter:[280/495], Time: 0.37, lr: [0.003950031559273567], Loss: 1.974355, Acc:0.810285, Semantic loss: 0.737186, BCE loss: 0.524210, SB loss: 0.712959
2023-10-30 17:20:21,480 Epoch: [311/484] Iter:[290/495], Time: 0.37, lr: [0.0039496150576943745], Loss: 1.971441, Acc:0.810252, Semantic loss: 0.736184, BCE loss: 0.523715, SB loss: 0.711542
2023-10-30 17:20:25,117 Epoch: [311/484] Iter:[300/495], Time: 0.37, lr: [0.003949198551234943], Loss: 1.971075, Acc:0.808228, Semantic loss: 0.737273, BCE loss: 0.522584, SB loss: 0.711218
2023-10-30 17:20:28,834 Epoch: [311/484] Iter:[310/495], Time: 0.37, lr: [0.003948782039894642], Loss: 1.974167, Acc:0.808114, Semantic loss: 0.739820, BCE loss: 0.522281, SB loss: 0.712067
2023-10-30 17:20:32,561 Epoch: [311/484] Iter:[320/495], Time: 0.37, lr: [0.003948365523672845], Loss: 1.977617, Acc:0.808173, Semantic loss: 0.740211, BCE loss: 0.524548, SB loss: 0.712857
2023-10-30 17:20:36,325 Epoch: [311/484] Iter:[330/495], Time: 0.37, lr: [0.00394794900256892], Loss: 1.979861, Acc:0.808417, Semantic loss: 0.740157, BCE loss: 0.527127, SB loss: 0.712577
2023-10-30 17:20:39,984 Epoch: [311/484] Iter:[340/495], Time: 0.37, lr: [0.00394753247658224], Loss: 1.979350, Acc:0.808622, Semantic loss: 0.740291, BCE loss: 0.526220, SB loss: 0.712839
2023-10-30 17:20:43,789 Epoch: [311/484] Iter:[350/495], Time: 0.37, lr: [0.003947115945712171], Loss: 1.982809, Acc:0.807629, Semantic loss: 0.742781, BCE loss: 0.526165, SB loss: 0.713863
2023-10-30 17:20:47,479 Epoch: [311/484] Iter:[360/495], Time: 0.37, lr: [0.003946699409958088], Loss: 1.980273, Acc:0.807424, Semantic loss: 0.741420, BCE loss: 0.526176, SB loss: 0.712677
2023-10-30 17:20:51,145 Epoch: [311/484] Iter:[370/495], Time: 0.37, lr: [0.003946282869319358], Loss: 1.981210, Acc:0.806960, Semantic loss: 0.741192, BCE loss: 0.526558, SB loss: 0.713461
2023-10-30 17:20:54,823 Epoch: [311/484] Iter:[380/495], Time: 0.37, lr: [0.003945866323795353], Loss: 1.979621, Acc:0.807356, Semantic loss: 0.740525, BCE loss: 0.525683, SB loss: 0.713414
2023-10-30 17:20:58,621 Epoch: [311/484] Iter:[390/495], Time: 0.37, lr: [0.003945449773385439], Loss: 1.975987, Acc:0.807130, Semantic loss: 0.738810, BCE loss: 0.524574, SB loss: 0.712602
2023-10-30 17:21:02,393 Epoch: [311/484] Iter:[400/495], Time: 0.37, lr: [0.00394503321808899], Loss: 1.977037, Acc:0.806938, Semantic loss: 0.739649, BCE loss: 0.524495, SB loss: 0.712892
2023-10-30 17:21:06,129 Epoch: [311/484] Iter:[410/495], Time: 0.37, lr: [0.003944616657905372], Loss: 1.975686, Acc:0.807767, Semantic loss: 0.738974, BCE loss: 0.524082, SB loss: 0.712630
2023-10-30 17:21:09,770 Epoch: [311/484] Iter:[420/495], Time: 0.37, lr: [0.003944200092833957], Loss: 1.975332, Acc:0.808232, Semantic loss: 0.738049, BCE loss: 0.524167, SB loss: 0.713117
2023-10-30 17:21:13,401 Epoch: [311/484] Iter:[430/495], Time: 0.37, lr: [0.0039437835228741105], Loss: 1.973750, Acc:0.807739, Semantic loss: 0.737533, BCE loss: 0.523368, SB loss: 0.712848
2023-10-30 17:21:17,048 Epoch: [311/484] Iter:[440/495], Time: 0.37, lr: [0.003943366948025205], Loss: 1.977714, Acc:0.807509, Semantic loss: 0.739502, BCE loss: 0.524864, SB loss: 0.713348
2023-10-30 17:21:20,723 Epoch: [311/484] Iter:[450/495], Time: 0.37, lr: [0.0039429503682866076], Loss: 1.977555, Acc:0.806925, Semantic loss: 0.739793, BCE loss: 0.524289, SB loss: 0.713473
2023-10-30 17:21:24,380 Epoch: [311/484] Iter:[460/495], Time: 0.37, lr: [0.003942533783657687], Loss: 1.977878, Acc:0.807650, Semantic loss: 0.740414, BCE loss: 0.524299, SB loss: 0.713165
2023-10-30 17:21:28,093 Epoch: [311/484] Iter:[470/495], Time: 0.37, lr: [0.00394211719413781], Loss: 1.976192, Acc:0.806845, Semantic loss: 0.739923, BCE loss: 0.523496, SB loss: 0.712773
2023-10-30 17:21:31,819 Epoch: [311/484] Iter:[480/495], Time: 0.37, lr: [0.003941700599726348], Loss: 1.975226, Acc:0.806477, Semantic loss: 0.739676, BCE loss: 0.523284, SB loss: 0.712266
2023-10-30 17:21:35,391 Epoch: [311/484] Iter:[490/495], Time: 0.37, lr: [0.003941284000422668], Loss: 1.972973, Acc:0.807236, Semantic loss: 0.738361, BCE loss: 0.523058, SB loss: 0.711554
2023-10-30 17:21:36,799 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:21:37,035 Loss: 2.069, MeanIU:  0.6824, Best_mIoU:  0.7309
2023-10-30 17:21:37,035 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289]
2023-10-30 17:21:39,093 Epoch: [312/484] Iter:[0/495], Time: 2.02, lr: [0.003941075698936048], Loss: 2.158532, Acc:0.847731, Semantic loss: 0.815789, BCE loss: 0.513246, SB loss: 0.829497
2023-10-30 17:21:43,084 Epoch: [312/484] Iter:[10/495], Time: 0.55, lr: [0.003940659092292854], Loss: 2.147910, Acc:0.822132, Semantic loss: 0.815480, BCE loss: 0.588878, SB loss: 0.743552
2023-10-30 17:21:46,674 Epoch: [312/484] Iter:[20/495], Time: 0.46, lr: [0.003940242480755861], Loss: 2.054907, Acc:0.822025, Semantic loss: 0.773893, BCE loss: 0.547460, SB loss: 0.733554
2023-10-30 17:21:50,347 Epoch: [312/484] Iter:[30/495], Time: 0.43, lr: [0.0039398258643244385], Loss: 1.967107, Acc:0.805544, Semantic loss: 0.744920, BCE loss: 0.507810, SB loss: 0.714376
2023-10-30 17:21:54,003 Epoch: [312/484] Iter:[40/495], Time: 0.41, lr: [0.003939409242997951], Loss: 1.987209, Acc:0.796314, Semantic loss: 0.760133, BCE loss: 0.505629, SB loss: 0.721447
2023-10-30 17:21:57,817 Epoch: [312/484] Iter:[50/495], Time: 0.41, lr: [0.003938992616775766], Loss: 1.964909, Acc:0.796621, Semantic loss: 0.751125, BCE loss: 0.500585, SB loss: 0.713199
2023-10-30 17:22:01,510 Epoch: [312/484] Iter:[60/495], Time: 0.40, lr: [0.0039385759856572534], Loss: 1.971690, Acc:0.786550, Semantic loss: 0.753371, BCE loss: 0.501488, SB loss: 0.716832
2023-10-30 17:22:05,358 Epoch: [312/484] Iter:[70/495], Time: 0.40, lr: [0.003938159349641778], Loss: 1.993045, Acc:0.789573, Semantic loss: 0.758172, BCE loss: 0.517156, SB loss: 0.717716
2023-10-30 17:22:08,963 Epoch: [312/484] Iter:[80/495], Time: 0.39, lr: [0.003937742708728707], Loss: 2.000126, Acc:0.789093, Semantic loss: 0.762891, BCE loss: 0.517285, SB loss: 0.719950
2023-10-30 17:22:12,604 Epoch: [312/484] Iter:[90/495], Time: 0.39, lr: [0.003937326062917405], Loss: 2.009446, Acc:0.787582, Semantic loss: 0.767225, BCE loss: 0.520751, SB loss: 0.721470
2023-10-30 17:22:16,311 Epoch: [312/484] Iter:[100/495], Time: 0.39, lr: [0.003936909412207243], Loss: 2.008045, Acc:0.788036, Semantic loss: 0.762449, BCE loss: 0.522486, SB loss: 0.723111
2023-10-30 17:22:20,044 Epoch: [312/484] Iter:[110/495], Time: 0.39, lr: [0.003936492756597584], Loss: 2.002920, Acc:0.792406, Semantic loss: 0.762569, BCE loss: 0.518251, SB loss: 0.722100
2023-10-30 17:22:23,699 Epoch: [312/484] Iter:[120/495], Time: 0.39, lr: [0.003936076096087794], Loss: 2.001043, Acc:0.789789, Semantic loss: 0.760572, BCE loss: 0.519394, SB loss: 0.721077
2023-10-30 17:22:27,352 Epoch: [312/484] Iter:[130/495], Time: 0.38, lr: [0.003935659430677241], Loss: 2.005640, Acc:0.790336, Semantic loss: 0.763316, BCE loss: 0.520215, SB loss: 0.722109
2023-10-30 17:22:31,038 Epoch: [312/484] Iter:[140/495], Time: 0.38, lr: [0.003935242760365289], Loss: 2.001354, Acc:0.790916, Semantic loss: 0.758817, BCE loss: 0.521175, SB loss: 0.721362
2023-10-30 17:22:34,772 Epoch: [312/484] Iter:[150/495], Time: 0.38, lr: [0.003934826085151305], Loss: 2.000015, Acc:0.791485, Semantic loss: 0.757493, BCE loss: 0.522376, SB loss: 0.720147
2023-10-30 17:22:38,486 Epoch: [312/484] Iter:[160/495], Time: 0.38, lr: [0.003934409405034654], Loss: 1.999359, Acc:0.792708, Semantic loss: 0.755313, BCE loss: 0.522071, SB loss: 0.721975
2023-10-30 17:22:42,263 Epoch: [312/484] Iter:[170/495], Time: 0.38, lr: [0.0039339927200147005], Loss: 1.997146, Acc:0.794899, Semantic loss: 0.751408, BCE loss: 0.525200, SB loss: 0.720538
2023-10-30 17:22:45,965 Epoch: [312/484] Iter:[180/495], Time: 0.38, lr: [0.003933576030090812], Loss: 1.997328, Acc:0.795230, Semantic loss: 0.748556, BCE loss: 0.528852, SB loss: 0.719920
2023-10-30 17:22:49,611 Epoch: [312/484] Iter:[190/495], Time: 0.38, lr: [0.003933159335262352], Loss: 1.999620, Acc:0.795264, Semantic loss: 0.750526, BCE loss: 0.527430, SB loss: 0.721663
2023-10-30 17:22:53,416 Epoch: [312/484] Iter:[200/495], Time: 0.38, lr: [0.003932742635528685], Loss: 1.996170, Acc:0.795674, Semantic loss: 0.748209, BCE loss: 0.527597, SB loss: 0.720364
2023-10-30 17:22:57,224 Epoch: [312/484] Iter:[210/495], Time: 0.38, lr: [0.003932325930889176], Loss: 1.999897, Acc:0.796553, Semantic loss: 0.749920, BCE loss: 0.528587, SB loss: 0.721390
2023-10-30 17:23:00,921 Epoch: [312/484] Iter:[220/495], Time: 0.38, lr: [0.00393190922134319], Loss: 2.000533, Acc:0.796081, Semantic loss: 0.750704, BCE loss: 0.527971, SB loss: 0.721858
2023-10-30 17:23:04,677 Epoch: [312/484] Iter:[230/495], Time: 0.38, lr: [0.003931492506890093], Loss: 1.999145, Acc:0.795677, Semantic loss: 0.752415, BCE loss: 0.524778, SB loss: 0.721951
2023-10-30 17:23:08,489 Epoch: [312/484] Iter:[240/495], Time: 0.38, lr: [0.003931075787529247], Loss: 1.994655, Acc:0.795882, Semantic loss: 0.748993, BCE loss: 0.524701, SB loss: 0.720962
2023-10-30 17:23:12,183 Epoch: [312/484] Iter:[250/495], Time: 0.38, lr: [0.003930659063260016], Loss: 1.991952, Acc:0.796520, Semantic loss: 0.747374, BCE loss: 0.523966, SB loss: 0.720611
2023-10-30 17:23:15,866 Epoch: [312/484] Iter:[260/495], Time: 0.38, lr: [0.003930242334081765], Loss: 1.996778, Acc:0.796036, Semantic loss: 0.750637, BCE loss: 0.523942, SB loss: 0.722199
2023-10-30 17:23:19,617 Epoch: [312/484] Iter:[270/495], Time: 0.38, lr: [0.003929825599993858], Loss: 1.999588, Acc:0.795972, Semantic loss: 0.751342, BCE loss: 0.525364, SB loss: 0.722883
2023-10-30 17:23:23,270 Epoch: [312/484] Iter:[280/495], Time: 0.38, lr: [0.003929408860995659], Loss: 1.994427, Acc:0.795979, Semantic loss: 0.747711, BCE loss: 0.525740, SB loss: 0.720976
2023-10-30 17:23:26,967 Epoch: [312/484] Iter:[290/495], Time: 0.38, lr: [0.003928992117086529], Loss: 1.996478, Acc:0.795577, Semantic loss: 0.748101, BCE loss: 0.526761, SB loss: 0.721616
2023-10-30 17:23:30,596 Epoch: [312/484] Iter:[300/495], Time: 0.38, lr: [0.003928575368265835], Loss: 1.992117, Acc:0.794045, Semantic loss: 0.747862, BCE loss: 0.523846, SB loss: 0.720409
2023-10-30 17:23:34,361 Epoch: [312/484] Iter:[310/495], Time: 0.38, lr: [0.003928158614532937], Loss: 1.993985, Acc:0.795283, Semantic loss: 0.748608, BCE loss: 0.525474, SB loss: 0.719902
2023-10-30 17:23:38,033 Epoch: [312/484] Iter:[320/495], Time: 0.38, lr: [0.0039277418558872], Loss: 1.994317, Acc:0.795851, Semantic loss: 0.748853, BCE loss: 0.525856, SB loss: 0.719608
2023-10-30 17:23:41,780 Epoch: [312/484] Iter:[330/495], Time: 0.38, lr: [0.003927325092327984], Loss: 1.994285, Acc:0.795306, Semantic loss: 0.750089, BCE loss: 0.525367, SB loss: 0.718829
2023-10-30 17:23:45,469 Epoch: [312/484] Iter:[340/495], Time: 0.38, lr: [0.003926908323854657], Loss: 1.992971, Acc:0.795270, Semantic loss: 0.748022, BCE loss: 0.525753, SB loss: 0.719196
2023-10-30 17:23:49,159 Epoch: [312/484] Iter:[350/495], Time: 0.38, lr: [0.0039264915504665775], Loss: 1.989924, Acc:0.795796, Semantic loss: 0.747444, BCE loss: 0.524271, SB loss: 0.718208
2023-10-30 17:23:52,932 Epoch: [312/484] Iter:[360/495], Time: 0.38, lr: [0.0039260747721631085], Loss: 1.989004, Acc:0.796171, Semantic loss: 0.747020, BCE loss: 0.523794, SB loss: 0.718190
2023-10-30 17:23:56,630 Epoch: [312/484] Iter:[370/495], Time: 0.38, lr: [0.003925657988943612], Loss: 1.987527, Acc:0.795910, Semantic loss: 0.746638, BCE loss: 0.523309, SB loss: 0.717580
2023-10-30 17:24:00,324 Epoch: [312/484] Iter:[380/495], Time: 0.38, lr: [0.003925241200807452], Loss: 1.992223, Acc:0.794922, Semantic loss: 0.750244, BCE loss: 0.523718, SB loss: 0.718261
2023-10-30 17:24:04,079 Epoch: [312/484] Iter:[390/495], Time: 0.38, lr: [0.003924824407753988], Loss: 1.992365, Acc:0.794635, Semantic loss: 0.749230, BCE loss: 0.524869, SB loss: 0.718266
2023-10-30 17:24:07,790 Epoch: [312/484] Iter:[400/495], Time: 0.38, lr: [0.003924407609782583], Loss: 1.995186, Acc:0.795461, Semantic loss: 0.751072, BCE loss: 0.525062, SB loss: 0.719052
2023-10-30 17:24:11,477 Epoch: [312/484] Iter:[410/495], Time: 0.38, lr: [0.003923990806892598], Loss: 1.994015, Acc:0.795426, Semantic loss: 0.750431, BCE loss: 0.525122, SB loss: 0.718462
2023-10-30 17:24:15,425 Epoch: [312/484] Iter:[420/495], Time: 0.38, lr: [0.003923573999083396], Loss: 1.995970, Acc:0.795645, Semantic loss: 0.751629, BCE loss: 0.524734, SB loss: 0.719607
2023-10-30 17:24:19,130 Epoch: [312/484] Iter:[430/495], Time: 0.38, lr: [0.0039231571863543365], Loss: 1.999689, Acc:0.795544, Semantic loss: 0.753221, BCE loss: 0.525601, SB loss: 0.720867
2023-10-30 17:24:22,868 Epoch: [312/484] Iter:[440/495], Time: 0.38, lr: [0.003922740368704781], Loss: 1.999125, Acc:0.795887, Semantic loss: 0.753223, BCE loss: 0.525439, SB loss: 0.720463
2023-10-30 17:24:26,694 Epoch: [312/484] Iter:[450/495], Time: 0.38, lr: [0.003922323546134092], Loss: 1.998255, Acc:0.796299, Semantic loss: 0.753345, BCE loss: 0.524901, SB loss: 0.720009
2023-10-30 17:24:30,349 Epoch: [312/484] Iter:[460/495], Time: 0.38, lr: [0.003921906718641628], Loss: 1.999032, Acc:0.796672, Semantic loss: 0.753591, BCE loss: 0.525561, SB loss: 0.719881
2023-10-30 17:24:33,988 Epoch: [312/484] Iter:[470/495], Time: 0.38, lr: [0.003921489886226752], Loss: 2.001524, Acc:0.795588, Semantic loss: 0.754560, BCE loss: 0.526794, SB loss: 0.720170
2023-10-30 17:24:37,675 Epoch: [312/484] Iter:[480/495], Time: 0.38, lr: [0.0039210730488888216], Loss: 2.000611, Acc:0.796269, Semantic loss: 0.754434, BCE loss: 0.526838, SB loss: 0.719339
2023-10-30 17:24:41,165 Epoch: [312/484] Iter:[490/495], Time: 0.37, lr: [0.0039206562066271995], Loss: 1.998807, Acc:0.796548, Semantic loss: 0.753572, BCE loss: 0.526664, SB loss: 0.718571
2023-10-30 17:24:42,559 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:24:42,793 Loss: 2.069, MeanIU:  0.6824, Best_mIoU:  0.7309
2023-10-30 17:24:42,793 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289]
2023-10-30 17:24:44,853 Epoch: [313/484] Iter:[0/495], Time: 2.03, lr: [0.003920447783649804], Loss: 2.052571, Acc:0.913676, Semantic loss: 0.836350, BCE loss: 0.484861, SB loss: 0.731359
2023-10-30 17:24:48,792 Epoch: [313/484] Iter:[10/495], Time: 0.54, lr: [0.003920030934001444], Loss: 2.027822, Acc:0.780724, Semantic loss: 0.773402, BCE loss: 0.526718, SB loss: 0.727702
2023-10-30 17:24:52,498 Epoch: [313/484] Iter:[20/495], Time: 0.46, lr: [0.003919614079427791], Loss: 1.937696, Acc:0.792907, Semantic loss: 0.725887, BCE loss: 0.498378, SB loss: 0.713431
2023-10-30 17:24:56,098 Epoch: [313/484] Iter:[30/495], Time: 0.43, lr: [0.003919197219928205], Loss: 1.892188, Acc:0.795622, Semantic loss: 0.715749, BCE loss: 0.473354, SB loss: 0.703084
2023-10-30 17:24:59,737 Epoch: [313/484] Iter:[40/495], Time: 0.41, lr: [0.003918780355502047], Loss: 1.912437, Acc:0.798696, Semantic loss: 0.727154, BCE loss: 0.484599, SB loss: 0.700683
2023-10-30 17:25:03,493 Epoch: [313/484] Iter:[50/495], Time: 0.41, lr: [0.003918363486148676], Loss: 1.948537, Acc:0.794463, Semantic loss: 0.753690, BCE loss: 0.485392, SB loss: 0.709455
2023-10-30 17:25:07,283 Epoch: [313/484] Iter:[60/495], Time: 0.40, lr: [0.003917946611867451], Loss: 1.985520, Acc:0.792716, Semantic loss: 0.768789, BCE loss: 0.503244, SB loss: 0.713487
2023-10-30 17:25:11,091 Epoch: [313/484] Iter:[70/495], Time: 0.40, lr: [0.00391752973265773], Loss: 1.992333, Acc:0.796774, Semantic loss: 0.767471, BCE loss: 0.510281, SB loss: 0.714581
2023-10-30 17:25:14,746 Epoch: [313/484] Iter:[80/495], Time: 0.39, lr: [0.003917112848518874], Loss: 2.001230, Acc:0.798635, Semantic loss: 0.767247, BCE loss: 0.516957, SB loss: 0.717026
2023-10-30 17:25:18,383 Epoch: [313/484] Iter:[90/495], Time: 0.39, lr: [0.00391669595945024], Loss: 1.991801, Acc:0.795957, Semantic loss: 0.762580, BCE loss: 0.512931, SB loss: 0.716291
2023-10-30 17:25:22,069 Epoch: [313/484] Iter:[100/495], Time: 0.39, lr: [0.003916279065451188], Loss: 1.999212, Acc:0.795132, Semantic loss: 0.768821, BCE loss: 0.516395, SB loss: 0.713996
2023-10-30 17:25:25,687 Epoch: [313/484] Iter:[110/495], Time: 0.39, lr: [0.003915862166521075], Loss: 1.986927, Acc:0.792158, Semantic loss: 0.760872, BCE loss: 0.514657, SB loss: 0.711398
2023-10-30 17:25:29,421 Epoch: [313/484] Iter:[120/495], Time: 0.39, lr: [0.0039154452626592616], Loss: 1.982338, Acc:0.792085, Semantic loss: 0.755873, BCE loss: 0.514651, SB loss: 0.711814
2023-10-30 17:25:33,107 Epoch: [313/484] Iter:[130/495], Time: 0.38, lr: [0.003915028353865104], Loss: 1.973798, Acc:0.791751, Semantic loss: 0.750834, BCE loss: 0.512894, SB loss: 0.710070
2023-10-30 17:25:36,811 Epoch: [313/484] Iter:[140/495], Time: 0.38, lr: [0.003914611440137962], Loss: 1.974565, Acc:0.793011, Semantic loss: 0.751701, BCE loss: 0.512973, SB loss: 0.709891
2023-10-30 17:25:40,496 Epoch: [313/484] Iter:[150/495], Time: 0.38, lr: [0.0039141945214771915], Loss: 1.983969, Acc:0.795484, Semantic loss: 0.756840, BCE loss: 0.514856, SB loss: 0.712273
2023-10-30 17:25:44,189 Epoch: [313/484] Iter:[160/495], Time: 0.38, lr: [0.003913777597882151], Loss: 1.981769, Acc:0.793950, Semantic loss: 0.755066, BCE loss: 0.514604, SB loss: 0.712099
2023-10-30 17:25:47,840 Epoch: [313/484] Iter:[170/495], Time: 0.38, lr: [0.0039133606693522], Loss: 1.982345, Acc:0.794561, Semantic loss: 0.756302, BCE loss: 0.513471, SB loss: 0.712572
2023-10-30 17:25:51,560 Epoch: [313/484] Iter:[180/495], Time: 0.38, lr: [0.003912943735886692], Loss: 1.995778, Acc:0.793552, Semantic loss: 0.761258, BCE loss: 0.518000, SB loss: 0.716520
2023-10-30 17:25:55,397 Epoch: [313/484] Iter:[190/495], Time: 0.38, lr: [0.003912526797484986], Loss: 1.988884, Acc:0.795216, Semantic loss: 0.756235, BCE loss: 0.517541, SB loss: 0.715109
2023-10-30 17:25:59,045 Epoch: [313/484] Iter:[200/495], Time: 0.38, lr: [0.0039121098541464415], Loss: 1.994914, Acc:0.795348, Semantic loss: 0.759750, BCE loss: 0.519205, SB loss: 0.715960
2023-10-30 17:26:02,700 Epoch: [313/484] Iter:[210/495], Time: 0.38, lr: [0.003911692905870413], Loss: 1.995701, Acc:0.794473, Semantic loss: 0.759370, BCE loss: 0.520119, SB loss: 0.716211
2023-10-30 17:26:06,490 Epoch: [313/484] Iter:[220/495], Time: 0.38, lr: [0.0039112759526562565], Loss: 1.996850, Acc:0.795661, Semantic loss: 0.758662, BCE loss: 0.521456, SB loss: 0.716732
2023-10-30 17:26:10,080 Epoch: [313/484] Iter:[230/495], Time: 0.38, lr: [0.00391085899450333], Loss: 2.005063, Acc:0.795247, Semantic loss: 0.763383, BCE loss: 0.522937, SB loss: 0.718743
2023-10-30 17:26:13,795 Epoch: [313/484] Iter:[240/495], Time: 0.38, lr: [0.00391044203141099], Loss: 2.002322, Acc:0.794828, Semantic loss: 0.762574, BCE loss: 0.521252, SB loss: 0.718496
2023-10-30 17:26:17,491 Epoch: [313/484] Iter:[250/495], Time: 0.38, lr: [0.0039100250633785924], Loss: 2.004367, Acc:0.793781, Semantic loss: 0.762459, BCE loss: 0.522553, SB loss: 0.719355
2023-10-30 17:26:21,155 Epoch: [313/484] Iter:[260/495], Time: 0.38, lr: [0.003909608090405494], Loss: 2.004705, Acc:0.793134, Semantic loss: 0.761221, BCE loss: 0.524085, SB loss: 0.719399
2023-10-30 17:26:24,916 Epoch: [313/484] Iter:[270/495], Time: 0.38, lr: [0.003909191112491048], Loss: 2.000418, Acc:0.792532, Semantic loss: 0.759566, BCE loss: 0.522051, SB loss: 0.718801
2023-10-30 17:26:28,650 Epoch: [313/484] Iter:[280/495], Time: 0.38, lr: [0.003908774129634613], Loss: 2.004493, Acc:0.794152, Semantic loss: 0.760419, BCE loss: 0.524586, SB loss: 0.719488
2023-10-30 17:26:32,377 Epoch: [313/484] Iter:[290/495], Time: 0.38, lr: [0.003908357141835545], Loss: 2.005245, Acc:0.795143, Semantic loss: 0.759691, BCE loss: 0.525929, SB loss: 0.719625
2023-10-30 17:26:36,115 Epoch: [313/484] Iter:[300/495], Time: 0.38, lr: [0.0039079401490931965], Loss: 2.000203, Acc:0.795631, Semantic loss: 0.756745, BCE loss: 0.526121, SB loss: 0.717336
2023-10-30 17:26:39,858 Epoch: [313/484] Iter:[310/495], Time: 0.38, lr: [0.0039075231514069265], Loss: 2.004220, Acc:0.795447, Semantic loss: 0.759026, BCE loss: 0.526797, SB loss: 0.718396
2023-10-30 17:26:43,599 Epoch: [313/484] Iter:[320/495], Time: 0.38, lr: [0.003907106148776087], Loss: 2.007034, Acc:0.796361, Semantic loss: 0.759538, BCE loss: 0.528424, SB loss: 0.719073
2023-10-30 17:26:47,314 Epoch: [313/484] Iter:[330/495], Time: 0.38, lr: [0.003906689141200036], Loss: 2.005755, Acc:0.796996, Semantic loss: 0.759164, BCE loss: 0.528078, SB loss: 0.718513
2023-10-30 17:26:51,071 Epoch: [313/484] Iter:[340/495], Time: 0.38, lr: [0.003906272128678124], Loss: 2.003193, Acc:0.797195, Semantic loss: 0.757154, BCE loss: 0.526962, SB loss: 0.719078
2023-10-30 17:26:54,805 Epoch: [313/484] Iter:[350/495], Time: 0.38, lr: [0.00390585511120971], Loss: 2.003282, Acc:0.796718, Semantic loss: 0.756845, BCE loss: 0.527643, SB loss: 0.718793
2023-10-30 17:26:58,633 Epoch: [313/484] Iter:[360/495], Time: 0.38, lr: [0.003905438088794147], Loss: 2.000145, Acc:0.796288, Semantic loss: 0.755166, BCE loss: 0.526803, SB loss: 0.718176
2023-10-30 17:27:02,288 Epoch: [313/484] Iter:[370/495], Time: 0.38, lr: [0.0039050210614307887], Loss: 1.996415, Acc:0.796251, Semantic loss: 0.753343, BCE loss: 0.525802, SB loss: 0.717270
2023-10-30 17:27:05,964 Epoch: [313/484] Iter:[380/495], Time: 0.38, lr: [0.003904604029118989], Loss: 1.996862, Acc:0.796378, Semantic loss: 0.754461, BCE loss: 0.525221, SB loss: 0.717181
2023-10-30 17:27:09,725 Epoch: [313/484] Iter:[390/495], Time: 0.38, lr: [0.0039041869918581035], Loss: 1.999427, Acc:0.796735, Semantic loss: 0.756034, BCE loss: 0.525616, SB loss: 0.717777
2023-10-30 17:27:13,528 Epoch: [313/484] Iter:[400/495], Time: 0.38, lr: [0.003903769949647485], Loss: 2.002172, Acc:0.797299, Semantic loss: 0.757305, BCE loss: 0.525838, SB loss: 0.719028
2023-10-30 17:27:17,185 Epoch: [313/484] Iter:[410/495], Time: 0.38, lr: [0.0039033529024864876], Loss: 2.002263, Acc:0.797573, Semantic loss: 0.756472, BCE loss: 0.527107, SB loss: 0.718684
2023-10-30 17:27:20,881 Epoch: [313/484] Iter:[420/495], Time: 0.38, lr: [0.0039029358503744637], Loss: 2.000274, Acc:0.798880, Semantic loss: 0.754677, BCE loss: 0.527343, SB loss: 0.718255
2023-10-30 17:27:24,569 Epoch: [313/484] Iter:[430/495], Time: 0.38, lr: [0.003902518793310769], Loss: 1.997907, Acc:0.799119, Semantic loss: 0.753160, BCE loss: 0.526693, SB loss: 0.718054
2023-10-30 17:27:28,192 Epoch: [313/484] Iter:[440/495], Time: 0.37, lr: [0.003902101731294754], Loss: 1.997642, Acc:0.798119, Semantic loss: 0.754142, BCE loss: 0.524596, SB loss: 0.718904
2023-10-30 17:27:31,963 Epoch: [313/484] Iter:[450/495], Time: 0.38, lr: [0.003901684664325775], Loss: 1.997622, Acc:0.798122, Semantic loss: 0.754646, BCE loss: 0.523872, SB loss: 0.719104
2023-10-30 17:27:35,742 Epoch: [313/484] Iter:[460/495], Time: 0.38, lr: [0.0039012675924031803], Loss: 1.996285, Acc:0.798547, Semantic loss: 0.754362, BCE loss: 0.523337, SB loss: 0.718586
2023-10-30 17:27:39,407 Epoch: [313/484] Iter:[470/495], Time: 0.37, lr: [0.0039008505155263273], Loss: 1.995164, Acc:0.798997, Semantic loss: 0.753436, BCE loss: 0.523736, SB loss: 0.717991
2023-10-30 17:27:43,050 Epoch: [313/484] Iter:[480/495], Time: 0.37, lr: [0.0039004334336945664], Loss: 1.998172, Acc:0.799123, Semantic loss: 0.754920, BCE loss: 0.524764, SB loss: 0.718488
2023-10-30 17:27:46,592 Epoch: [313/484] Iter:[490/495], Time: 0.37, lr: [0.0039000163469072504], Loss: 1.998527, Acc:0.799404, Semantic loss: 0.754277, BCE loss: 0.525934, SB loss: 0.718317
2023-10-30 17:27:48,023 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:27:48,264 Loss: 2.069, MeanIU:  0.6824, Best_mIoU:  0.7309
2023-10-30 17:27:48,264 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289]
2023-10-30 17:27:50,081 Epoch: [314/484] Iter:[0/495], Time: 1.78, lr: [0.0038998078016550565], Loss: 1.460798, Acc:0.610198, Semantic loss: 0.580023, BCE loss: 0.225435, SB loss: 0.655339
2023-10-30 17:27:54,042 Epoch: [314/484] Iter:[10/495], Time: 0.52, lr: [0.0038993907074331914], Loss: 1.990808, Acc:0.788615, Semantic loss: 0.778836, BCE loss: 0.476962, SB loss: 0.735011
2023-10-30 17:27:57,837 Epoch: [314/484] Iter:[20/495], Time: 0.45, lr: [0.003898973608254153], Loss: 1.948565, Acc:0.799747, Semantic loss: 0.726321, BCE loss: 0.506660, SB loss: 0.715584
2023-10-30 17:28:01,525 Epoch: [314/484] Iter:[30/495], Time: 0.43, lr: [0.003898556504117291], Loss: 1.982333, Acc:0.800735, Semantic loss: 0.741085, BCE loss: 0.516116, SB loss: 0.725131
2023-10-30 17:28:05,073 Epoch: [314/484] Iter:[40/495], Time: 0.41, lr: [0.003898139395021958], Loss: 1.985832, Acc:0.800460, Semantic loss: 0.752074, BCE loss: 0.512886, SB loss: 0.720872
2023-10-30 17:28:08,758 Epoch: [314/484] Iter:[50/495], Time: 0.40, lr: [0.0038977222809675038], Loss: 1.955499, Acc:0.797057, Semantic loss: 0.729072, BCE loss: 0.513266, SB loss: 0.713161
2023-10-30 17:28:12,468 Epoch: [314/484] Iter:[60/495], Time: 0.40, lr: [0.0038973051619532817], Loss: 1.942613, Acc:0.801242, Semantic loss: 0.720835, BCE loss: 0.510961, SB loss: 0.710817
2023-10-30 17:28:16,060 Epoch: [314/484] Iter:[70/495], Time: 0.39, lr: [0.003896888037978643], Loss: 1.939134, Acc:0.798252, Semantic loss: 0.719314, BCE loss: 0.510391, SB loss: 0.709429
2023-10-30 17:28:19,798 Epoch: [314/484] Iter:[80/495], Time: 0.39, lr: [0.0038964709090429372], Loss: 1.946473, Acc:0.802769, Semantic loss: 0.727138, BCE loss: 0.509066, SB loss: 0.710269
2023-10-30 17:28:23,555 Epoch: [314/484] Iter:[90/495], Time: 0.39, lr: [0.0038960537751455155], Loss: 1.961675, Acc:0.802648, Semantic loss: 0.740404, BCE loss: 0.509067, SB loss: 0.712203
2023-10-30 17:28:27,247 Epoch: [314/484] Iter:[100/495], Time: 0.39, lr: [0.00389563663628573], Loss: 1.982732, Acc:0.801099, Semantic loss: 0.757043, BCE loss: 0.510528, SB loss: 0.715161
2023-10-30 17:28:30,897 Epoch: [314/484] Iter:[110/495], Time: 0.38, lr: [0.0038952194924629304], Loss: 2.007912, Acc:0.800531, Semantic loss: 0.769299, BCE loss: 0.514702, SB loss: 0.723911
2023-10-30 17:28:34,638 Epoch: [314/484] Iter:[120/495], Time: 0.38, lr: [0.0038948023436764655], Loss: 2.041449, Acc:0.801639, Semantic loss: 0.783025, BCE loss: 0.525815, SB loss: 0.732608
2023-10-30 17:28:38,312 Epoch: [314/484] Iter:[130/495], Time: 0.38, lr: [0.0038943851899256887], Loss: 2.043912, Acc:0.801133, Semantic loss: 0.779515, BCE loss: 0.529805, SB loss: 0.734592
2023-10-30 17:28:41,969 Epoch: [314/484] Iter:[140/495], Time: 0.38, lr: [0.003893968031209948], Loss: 2.069275, Acc:0.798058, Semantic loss: 0.798514, BCE loss: 0.533252, SB loss: 0.737510
2023-10-30 17:28:45,596 Epoch: [314/484] Iter:[150/495], Time: 0.38, lr: [0.0038935508675285936], Loss: 2.079229, Acc:0.797454, Semantic loss: 0.802456, BCE loss: 0.536343, SB loss: 0.740430
2023-10-30 17:28:49,162 Epoch: [314/484] Iter:[160/495], Time: 0.38, lr: [0.0038931336988809744], Loss: 2.098897, Acc:0.795200, Semantic loss: 0.817034, BCE loss: 0.535721, SB loss: 0.746142
2023-10-30 17:28:52,799 Epoch: [314/484] Iter:[170/495], Time: 0.38, lr: [0.003892716525266442], Loss: 2.107434, Acc:0.794097, Semantic loss: 0.820918, BCE loss: 0.538269, SB loss: 0.748247
2023-10-30 17:28:56,636 Epoch: [314/484] Iter:[180/495], Time: 0.38, lr: [0.003892299346684345], Loss: 2.113090, Acc:0.795245, Semantic loss: 0.824193, BCE loss: 0.538467, SB loss: 0.750429
2023-10-30 17:29:00,260 Epoch: [314/484] Iter:[190/495], Time: 0.38, lr: [0.0038918821631340316], Loss: 2.118314, Acc:0.796565, Semantic loss: 0.823785, BCE loss: 0.543236, SB loss: 0.751293
2023-10-30 17:29:04,005 Epoch: [314/484] Iter:[200/495], Time: 0.38, lr: [0.0038914649746148514], Loss: 2.116359, Acc:0.796986, Semantic loss: 0.821515, BCE loss: 0.542395, SB loss: 0.752448
2023-10-30 17:29:07,756 Epoch: [314/484] Iter:[210/495], Time: 0.38, lr: [0.003891047781126154], Loss: 2.115939, Acc:0.795323, Semantic loss: 0.820204, BCE loss: 0.544277, SB loss: 0.751458
2023-10-30 17:29:11,443 Epoch: [314/484] Iter:[220/495], Time: 0.38, lr: [0.0038906305826672885], Loss: 2.111263, Acc:0.796097, Semantic loss: 0.816444, BCE loss: 0.544611, SB loss: 0.750208
2023-10-30 17:29:15,215 Epoch: [314/484] Iter:[230/495], Time: 0.38, lr: [0.0038902133792376023], Loss: 2.103944, Acc:0.796627, Semantic loss: 0.810927, BCE loss: 0.542994, SB loss: 0.750024
2023-10-30 17:29:18,908 Epoch: [314/484] Iter:[240/495], Time: 0.38, lr: [0.0038897961708364427], Loss: 2.094039, Acc:0.796914, Semantic loss: 0.804422, BCE loss: 0.541673, SB loss: 0.747944
2023-10-30 17:29:22,651 Epoch: [314/484] Iter:[250/495], Time: 0.38, lr: [0.003889378957463161], Loss: 2.091005, Acc:0.796649, Semantic loss: 0.802471, BCE loss: 0.540990, SB loss: 0.747544
2023-10-30 17:29:26,335 Epoch: [314/484] Iter:[260/495], Time: 0.38, lr: [0.003888961739117104], Loss: 2.089099, Acc:0.797559, Semantic loss: 0.801123, BCE loss: 0.541547, SB loss: 0.746429
2023-10-30 17:29:30,009 Epoch: [314/484] Iter:[270/495], Time: 0.38, lr: [0.003888544515797619], Loss: 2.087755, Acc:0.796840, Semantic loss: 0.801130, BCE loss: 0.540652, SB loss: 0.745972
2023-10-30 17:29:33,710 Epoch: [314/484] Iter:[280/495], Time: 0.38, lr: [0.003888127287504054], Loss: 2.087503, Acc:0.796388, Semantic loss: 0.801008, BCE loss: 0.540620, SB loss: 0.745876
2023-10-30 17:29:37,389 Epoch: [314/484] Iter:[290/495], Time: 0.37, lr: [0.0038877100542357573], Loss: 2.083133, Acc:0.796460, Semantic loss: 0.798918, BCE loss: 0.540246, SB loss: 0.743969
2023-10-30 17:29:41,147 Epoch: [314/484] Iter:[300/495], Time: 0.37, lr: [0.003887292815992076], Loss: 2.080748, Acc:0.796681, Semantic loss: 0.798380, BCE loss: 0.539476, SB loss: 0.742893
2023-10-30 17:29:44,943 Epoch: [314/484] Iter:[310/495], Time: 0.38, lr: [0.0038868755727723575], Loss: 2.083216, Acc:0.798094, Semantic loss: 0.797393, BCE loss: 0.542490, SB loss: 0.743333
2023-10-30 17:29:48,660 Epoch: [314/484] Iter:[320/495], Time: 0.37, lr: [0.003886458324575948], Loss: 2.084249, Acc:0.798833, Semantic loss: 0.798428, BCE loss: 0.542582, SB loss: 0.743240
2023-10-30 17:29:52,403 Epoch: [314/484] Iter:[330/495], Time: 0.37, lr: [0.003886041071402196], Loss: 2.080913, Acc:0.799282, Semantic loss: 0.796963, BCE loss: 0.541460, SB loss: 0.742489
2023-10-30 17:29:56,176 Epoch: [314/484] Iter:[340/495], Time: 0.37, lr: [0.0038856238132504474], Loss: 2.079329, Acc:0.799484, Semantic loss: 0.796079, BCE loss: 0.542028, SB loss: 0.741222
2023-10-30 17:29:59,837 Epoch: [314/484] Iter:[350/495], Time: 0.37, lr: [0.0038852065501200493], Loss: 2.074273, Acc:0.799576, Semantic loss: 0.793181, BCE loss: 0.540237, SB loss: 0.740855
2023-10-30 17:30:03,518 Epoch: [314/484] Iter:[360/495], Time: 0.37, lr: [0.0038847892820103465], Loss: 2.071547, Acc:0.799774, Semantic loss: 0.791582, BCE loss: 0.540152, SB loss: 0.739813
2023-10-30 17:30:07,279 Epoch: [314/484] Iter:[370/495], Time: 0.37, lr: [0.003884372008920688], Loss: 2.068023, Acc:0.799462, Semantic loss: 0.789365, BCE loss: 0.538763, SB loss: 0.739895
2023-10-30 17:30:10,976 Epoch: [314/484] Iter:[380/495], Time: 0.37, lr: [0.003883954730850418], Loss: 2.068310, Acc:0.799909, Semantic loss: 0.789612, BCE loss: 0.538265, SB loss: 0.740433
2023-10-30 17:30:14,597 Epoch: [314/484] Iter:[390/495], Time: 0.37, lr: [0.0038835374477988838], Loss: 2.063533, Acc:0.800773, Semantic loss: 0.786504, BCE loss: 0.537646, SB loss: 0.739383
2023-10-30 17:30:18,394 Epoch: [314/484] Iter:[400/495], Time: 0.37, lr: [0.003883120159765429], Loss: 2.059911, Acc:0.800945, Semantic loss: 0.784564, BCE loss: 0.536582, SB loss: 0.738764
2023-10-30 17:30:22,266 Epoch: [314/484] Iter:[410/495], Time: 0.37, lr: [0.003882702866749402], Loss: 2.062596, Acc:0.801052, Semantic loss: 0.785793, BCE loss: 0.537050, SB loss: 0.739753
2023-10-30 17:30:25,865 Epoch: [314/484] Iter:[420/495], Time: 0.37, lr: [0.0038822855687501473], Loss: 2.061831, Acc:0.801380, Semantic loss: 0.785114, BCE loss: 0.537486, SB loss: 0.739231
2023-10-30 17:30:29,672 Epoch: [314/484] Iter:[430/495], Time: 0.37, lr: [0.0038818682657670097], Loss: 2.063044, Acc:0.801130, Semantic loss: 0.786613, BCE loss: 0.536861, SB loss: 0.739570
2023-10-30 17:30:33,289 Epoch: [314/484] Iter:[440/495], Time: 0.37, lr: [0.0038814509577993336], Loss: 2.062671, Acc:0.800972, Semantic loss: 0.785333, BCE loss: 0.537335, SB loss: 0.740002
2023-10-30 17:30:37,003 Epoch: [314/484] Iter:[450/495], Time: 0.37, lr: [0.0038810336448464656], Loss: 2.063774, Acc:0.800968, Semantic loss: 0.785171, BCE loss: 0.538274, SB loss: 0.740328
2023-10-30 17:30:40,720 Epoch: [314/484] Iter:[460/495], Time: 0.37, lr: [0.0038806163269077504], Loss: 2.064970, Acc:0.801264, Semantic loss: 0.785530, BCE loss: 0.538728, SB loss: 0.740713
2023-10-30 17:30:44,444 Epoch: [314/484] Iter:[470/495], Time: 0.37, lr: [0.0038801990039825326], Loss: 2.064149, Acc:0.801340, Semantic loss: 0.784882, BCE loss: 0.538669, SB loss: 0.740598
2023-10-30 17:30:48,231 Epoch: [314/484] Iter:[480/495], Time: 0.37, lr: [0.003879781676070155], Loss: 2.062311, Acc:0.800541, Semantic loss: 0.784676, BCE loss: 0.537216, SB loss: 0.740419
2023-10-30 17:30:51,734 Epoch: [314/484] Iter:[490/495], Time: 0.37, lr: [0.0038793643431699644], Loss: 2.059953, Acc:0.799996, Semantic loss: 0.783200, BCE loss: 0.536225, SB loss: 0.740528
2023-10-30 17:30:53,127 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:30:53,362 Loss: 2.069, MeanIU:  0.6824, Best_mIoU:  0.7309
2023-10-30 17:30:53,362 [0.97309349 0.80144957 0.91114817 0.38614805 0.51742452 0.59610151
 0.65409193 0.71852886 0.91390935 0.61416994 0.93820119 0.76077317
 0.56211511 0.87961469 0.24233137 0.56099586 0.74368879 0.48433831
 0.70804289]
2023-10-30 17:30:55,368 Epoch: [315/484] Iter:[0/495], Time: 1.97, lr: [0.0038791556748492334], Loss: 2.049820, Acc:0.868044, Semantic loss: 0.831002, BCE loss: 0.502519, SB loss: 0.716299
2023-10-30 17:30:59,426 Epoch: [315/484] Iter:[10/495], Time: 0.55, lr: [0.003878738334466092], Loss: 1.993964, Acc:0.800216, Semantic loss: 0.745871, BCE loss: 0.525509, SB loss: 0.722584
2023-10-30 17:31:03,297 Epoch: [315/484] Iter:[20/495], Time: 0.47, lr: [0.0038783209890934952], Loss: 2.065094, Acc:0.810773, Semantic loss: 0.774498, BCE loss: 0.556012, SB loss: 0.734585
2023-10-30 17:31:07,043 Epoch: [315/484] Iter:[30/495], Time: 0.44, lr: [0.0038779036387307894], Loss: 2.019742, Acc:0.807015, Semantic loss: 0.756217, BCE loss: 0.545495, SB loss: 0.718030
2023-10-30 17:31:10,901 Epoch: [315/484] Iter:[40/495], Time: 0.43, lr: [0.003877486283377317], Loss: 2.022970, Acc:0.807991, Semantic loss: 0.754694, BCE loss: 0.553909, SB loss: 0.714367
2023-10-30 17:31:14,704 Epoch: [315/484] Iter:[50/495], Time: 0.42, lr: [0.0038770689230324213], Loss: 2.020147, Acc:0.809733, Semantic loss: 0.754779, BCE loss: 0.553443, SB loss: 0.711924
2023-10-30 17:31:18,365 Epoch: [315/484] Iter:[60/495], Time: 0.41, lr: [0.0038766515576954446], Loss: 2.020568, Acc:0.813479, Semantic loss: 0.756403, BCE loss: 0.545015, SB loss: 0.719150
2023-10-30 17:31:22,021 Epoch: [315/484] Iter:[70/495], Time: 0.40, lr: [0.0038762341873657324], Loss: 2.011868, Acc:0.810511, Semantic loss: 0.753143, BCE loss: 0.537890, SB loss: 0.720836
2023-10-30 17:31:25,647 Epoch: [315/484] Iter:[80/495], Time: 0.40, lr: [0.003875816812042626], Loss: 1.991161, Acc:0.805746, Semantic loss: 0.747098, BCE loss: 0.528599, SB loss: 0.715464
2023-10-30 17:31:29,473 Epoch: [315/484] Iter:[90/495], Time: 0.40, lr: [0.0038753994317254686], Loss: 1.985886, Acc:0.805224, Semantic loss: 0.744773, BCE loss: 0.527823, SB loss: 0.713290
2023-10-30 17:31:33,121 Epoch: [315/484] Iter:[100/495], Time: 0.39, lr: [0.0038749820464136016], Loss: 1.993466, Acc:0.809685, Semantic loss: 0.749368, BCE loss: 0.527803, SB loss: 0.716295
2023-10-30 17:31:36,858 Epoch: [315/484] Iter:[110/495], Time: 0.39, lr: [0.00387456465610637], Loss: 1.971506, Acc:0.812011, Semantic loss: 0.738427, BCE loss: 0.519493, SB loss: 0.713586
2023-10-30 17:31:40,659 Epoch: [315/484] Iter:[120/495], Time: 0.39, lr: [0.003874147260803114], Loss: 1.987876, Acc:0.810325, Semantic loss: 0.747987, BCE loss: 0.519259, SB loss: 0.720631
2023-10-30 17:31:44,303 Epoch: [315/484] Iter:[130/495], Time: 0.39, lr: [0.0038737298605031768], Loss: 1.984206, Acc:0.810171, Semantic loss: 0.746453, BCE loss: 0.519955, SB loss: 0.717798
2023-10-30 17:31:47,920 Epoch: [315/484] Iter:[140/495], Time: 0.39, lr: [0.0038733124552058984], Loss: 1.978931, Acc:0.807758, Semantic loss: 0.743656, BCE loss: 0.519668, SB loss: 0.715607
2023-10-30 17:31:51,663 Epoch: [315/484] Iter:[150/495], Time: 0.39, lr: [0.0038728950449106237], Loss: 1.975683, Acc:0.807285, Semantic loss: 0.741516, BCE loss: 0.519611, SB loss: 0.714556
2023-10-30 17:31:55,278 Epoch: [315/484] Iter:[160/495], Time: 0.38, lr: [0.0038724776296166926], Loss: 1.978185, Acc:0.808064, Semantic loss: 0.743171, BCE loss: 0.521908, SB loss: 0.713105
2023-10-30 17:31:59,007 Epoch: [315/484] Iter:[170/495], Time: 0.38, lr: [0.0038720602093234462], Loss: 1.973707, Acc:0.809607, Semantic loss: 0.739906, BCE loss: 0.522199, SB loss: 0.711601
2023-10-30 17:32:02,634 Epoch: [315/484] Iter:[180/495], Time: 0.38, lr: [0.0038716427840302255], Loss: 1.979393, Acc:0.808273, Semantic loss: 0.742934, BCE loss: 0.523854, SB loss: 0.712605
2023-10-30 17:32:06,289 Epoch: [315/484] Iter:[190/495], Time: 0.38, lr: [0.003871225353736373], Loss: 1.973670, Acc:0.807467, Semantic loss: 0.739622, BCE loss: 0.523568, SB loss: 0.710480
2023-10-30 17:32:10,074 Epoch: [315/484] Iter:[200/495], Time: 0.38, lr: [0.0038708079184412293], Loss: 1.970609, Acc:0.807915, Semantic loss: 0.740111, BCE loss: 0.520636, SB loss: 0.709862
2023-10-30 17:32:13,787 Epoch: [315/484] Iter:[210/495], Time: 0.38, lr: [0.003870390478144135], Loss: 1.970379, Acc:0.806901, Semantic loss: 0.739450, BCE loss: 0.520197, SB loss: 0.710732
2023-10-30 17:32:17,424 Epoch: [315/484] Iter:[220/495], Time: 0.38, lr: [0.0038699730328444295], Loss: 1.968615, Acc:0.808694, Semantic loss: 0.736586, BCE loss: 0.522887, SB loss: 0.709142
2023-10-30 17:32:21,127 Epoch: [315/484] Iter:[230/495], Time: 0.38, lr: [0.0038695555825414554], Loss: 1.973085, Acc:0.806375, Semantic loss: 0.742985, BCE loss: 0.519745, SB loss: 0.710355
2023-10-30 17:32:24,842 Epoch: [315/484] Iter:[240/495], Time: 0.38, lr: [0.0038691381272345517], Loss: 1.976916, Acc:0.806256, Semantic loss: 0.743852, BCE loss: 0.521387, SB loss: 0.711677
2023-10-30 17:32:28,587 Epoch: [315/484] Iter:[250/495], Time: 0.38, lr: [0.003868720666923059], Loss: 1.977274, Acc:0.806454, Semantic loss: 0.745047, BCE loss: 0.520411, SB loss: 0.711816
2023-10-30 17:32:32,217 Epoch: [315/484] Iter:[260/495], Time: 0.38, lr: [0.003868303201606316], Loss: 1.977012, Acc:0.808149, Semantic loss: 0.742912, BCE loss: 0.522424, SB loss: 0.711677
2023-10-30 17:32:35,993 Epoch: [315/484] Iter:[270/495], Time: 0.38, lr: [0.003867885731283664], Loss: 1.975714, Acc:0.808200, Semantic loss: 0.742098, BCE loss: 0.521394, SB loss: 0.712221
2023-10-30 17:32:39,721 Epoch: [315/484] Iter:[280/495], Time: 0.38, lr: [0.0038674682559544427], Loss: 1.974547, Acc:0.808355, Semantic loss: 0.741446, BCE loss: 0.521937, SB loss: 0.711164
2023-10-30 17:32:43,353 Epoch: [315/484] Iter:[290/495], Time: 0.38, lr: [0.003867050775617991], Loss: 1.971594, Acc:0.809212, Semantic loss: 0.739225, BCE loss: 0.521274, SB loss: 0.711095
2023-10-30 17:32:46,978 Epoch: [315/484] Iter:[300/495], Time: 0.38, lr: [0.003866633290273647], Loss: 1.975830, Acc:0.808780, Semantic loss: 0.740950, BCE loss: 0.523015, SB loss: 0.711865
2023-10-30 17:32:50,622 Epoch: [315/484] Iter:[310/495], Time: 0.38, lr: [0.0038662157999207526], Loss: 1.972107, Acc:0.807654, Semantic loss: 0.738682, BCE loss: 0.521236, SB loss: 0.712189
2023-10-30 17:32:54,267 Epoch: [315/484] Iter:[320/495], Time: 0.38, lr: [0.003865798304558645], Loss: 1.974625, Acc:0.806135, Semantic loss: 0.739280, BCE loss: 0.522738, SB loss: 0.712607
2023-10-30 17:32:57,963 Epoch: [315/484] Iter:[330/495], Time: 0.38, lr: [0.003865380804186663], Loss: 1.973107, Acc:0.804974, Semantic loss: 0.739387, BCE loss: 0.522295, SB loss: 0.711425
2023-10-30 17:33:01,642 Epoch: [315/484] Iter:[340/495], Time: 0.38, lr: [0.003864963298804144], Loss: 1.970856, Acc:0.804910, Semantic loss: 0.738550, BCE loss: 0.521515, SB loss: 0.710791
2023-10-30 17:33:05,261 Epoch: [315/484] Iter:[350/495], Time: 0.38, lr: [0.003864545788410429], Loss: 1.969205, Acc:0.804396, Semantic loss: 0.737642, BCE loss: 0.520653, SB loss: 0.710911
2023-10-30 17:33:08,919 Epoch: [315/484] Iter:[360/495], Time: 0.38, lr: [0.0038641282730048554], Loss: 1.966080, Acc:0.802784, Semantic loss: 0.737107, BCE loss: 0.518075, SB loss: 0.710898
2023-10-30 17:33:12,635 Epoch: [315/484] Iter:[370/495], Time: 0.38, lr: [0.003863710752586761], Loss: 1.966458, Acc:0.802497, Semantic loss: 0.737640, BCE loss: 0.518001, SB loss: 0.710817
2023-10-30 17:33:16,345 Epoch: [315/484] Iter:[380/495], Time: 0.38, lr: [0.0038632932271554826], Loss: 1.966587, Acc:0.802529, Semantic loss: 0.736617, BCE loss: 0.518420, SB loss: 0.711550
2023-10-30 17:33:19,996 Epoch: [315/484] Iter:[390/495], Time: 0.37, lr: [0.003862875696710361], Loss: 1.967357, Acc:0.802148, Semantic loss: 0.737000, BCE loss: 0.518347, SB loss: 0.712009
2023-10-30 17:33:23,898 Epoch: [315/484] Iter:[400/495], Time: 0.38, lr: [0.0038624581612507316], Loss: 1.970169, Acc:0.802788, Semantic loss: 0.738227, BCE loss: 0.519198, SB loss: 0.712743
2023-10-30 17:33:27,689 Epoch: [315/484] Iter:[410/495], Time: 0.38, lr: [0.003862040620775932], Loss: 1.969012, Acc:0.803624, Semantic loss: 0.737177, BCE loss: 0.519350, SB loss: 0.712485
2023-10-30 17:33:31,453 Epoch: [315/484] Iter:[420/495], Time: 0.38, lr: [0.0038616230752852995], Loss: 1.968405, Acc:0.804035, Semantic loss: 0.736571, BCE loss: 0.519543, SB loss: 0.712291
2023-10-30 17:33:35,044 Epoch: [315/484] Iter:[430/495], Time: 0.38, lr: [0.003861205524778172], Loss: 1.969150, Acc:0.803993, Semantic loss: 0.736226, BCE loss: 0.520425, SB loss: 0.712499
2023-10-30 17:33:38,801 Epoch: [315/484] Iter:[440/495], Time: 0.38, lr: [0.003860787969253886], Loss: 1.967117, Acc:0.804103, Semantic loss: 0.735800, BCE loss: 0.519382, SB loss: 0.711935
2023-10-30 17:33:42,517 Epoch: [315/484] Iter:[450/495], Time: 0.37, lr: [0.0038603704087117785], Loss: 1.968885, Acc:0.804080, Semantic loss: 0.736378, BCE loss: 0.520224, SB loss: 0.712283
2023-10-30 17:33:46,241 Epoch: [315/484] Iter:[460/495], Time: 0.37, lr: [0.003859952843151185], Loss: 1.967663, Acc:0.803695, Semantic loss: 0.736151, BCE loss: 0.519365, SB loss: 0.712147
2023-10-30 17:33:49,938 Epoch: [315/484] Iter:[470/495], Time: 0.37, lr: [0.003859535272571444], Loss: 1.966922, Acc:0.803378, Semantic loss: 0.736037, BCE loss: 0.518911, SB loss: 0.711973
2023-10-30 17:33:53,653 Epoch: [315/484] Iter:[480/495], Time: 0.37, lr: [0.00385911769697189], Loss: 1.964795, Acc:0.803577, Semantic loss: 0.734900, BCE loss: 0.518541, SB loss: 0.711354
2023-10-30 17:33:57,169 Epoch: [315/484] Iter:[490/495], Time: 0.37, lr: [0.0038587001163518605], Loss: 1.966609, Acc:0.803703, Semantic loss: 0.735733, BCE loss: 0.518949, SB loss: 0.711927
2023-10-30 17:36:53,480 0 [0.94422595 0.68164074 0.826591   0.14073545 0.23898913 0.42369604
 0.46211408 0.59971517 0.87826834 0.47995455 0.88142609 0.59852297
 0.02088834 0.80114135 0.00205177 0.11436879 0.08636511 0.01472472
 0.53775707] 0.45964087626045225
2023-10-30 17:36:53,480 1 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924] 0.708355435444933
2023-10-30 17:36:53,484 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:36:53,727 Loss: 2.046, MeanIU:  0.7084, Best_mIoU:  0.7309
2023-10-30 17:36:53,727 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924]
2023-10-30 17:36:56,103 Epoch: [316/484] Iter:[0/495], Time: 2.34, lr: [0.0038584913241589583], Loss: 1.852495, Acc:0.890693, Semantic loss: 0.749166, BCE loss: 0.410471, SB loss: 0.692858
2023-10-30 17:36:59,880 Epoch: [316/484] Iter:[10/495], Time: 0.56, lr: [0.003858073736006969], Loss: 2.055691, Acc:0.801005, Semantic loss: 0.795439, BCE loss: 0.522840, SB loss: 0.737411
2023-10-30 17:37:03,381 Epoch: [316/484] Iter:[20/495], Time: 0.46, lr: [0.003857656142832843], Loss: 1.998681, Acc:0.797610, Semantic loss: 0.777413, BCE loss: 0.498310, SB loss: 0.722958
2023-10-30 17:37:06,851 Epoch: [316/484] Iter:[30/495], Time: 0.42, lr: [0.0038572385446359156], Loss: 2.035735, Acc:0.804292, Semantic loss: 0.784112, BCE loss: 0.518609, SB loss: 0.733013
2023-10-30 17:37:10,331 Epoch: [316/484] Iter:[40/495], Time: 0.40, lr: [0.0038568209414155214], Loss: 2.003692, Acc:0.807507, Semantic loss: 0.760427, BCE loss: 0.521078, SB loss: 0.722187
2023-10-30 17:37:13,886 Epoch: [316/484] Iter:[50/495], Time: 0.39, lr: [0.003856403333170998], Loss: 1.980970, Acc:0.799702, Semantic loss: 0.753636, BCE loss: 0.509628, SB loss: 0.717706
2023-10-30 17:37:17,469 Epoch: [316/484] Iter:[60/495], Time: 0.39, lr: [0.003855985719901679], Loss: 1.963661, Acc:0.800496, Semantic loss: 0.738437, BCE loss: 0.512359, SB loss: 0.712865
2023-10-30 17:37:20,950 Epoch: [316/484] Iter:[70/495], Time: 0.38, lr: [0.0038555681016068993], Loss: 1.967960, Acc:0.802633, Semantic loss: 0.736590, BCE loss: 0.516593, SB loss: 0.714777
2023-10-30 17:37:24,540 Epoch: [316/484] Iter:[80/495], Time: 0.38, lr: [0.0038551504782859927], Loss: 1.959951, Acc:0.801928, Semantic loss: 0.739925, BCE loss: 0.507393, SB loss: 0.712633
2023-10-30 17:37:28,156 Epoch: [316/484] Iter:[90/495], Time: 0.38, lr: [0.003854732849938295], Loss: 1.957599, Acc:0.802139, Semantic loss: 0.738386, BCE loss: 0.507333, SB loss: 0.711880
2023-10-30 17:37:31,692 Epoch: [316/484] Iter:[100/495], Time: 0.38, lr: [0.0038543152165631408], Loss: 1.967567, Acc:0.806592, Semantic loss: 0.741449, BCE loss: 0.511012, SB loss: 0.715106
2023-10-30 17:37:35,405 Epoch: [316/484] Iter:[110/495], Time: 0.38, lr: [0.0038538975781598635], Loss: 1.980419, Acc:0.807925, Semantic loss: 0.742993, BCE loss: 0.518754, SB loss: 0.718673
2023-10-30 17:37:39,092 Epoch: [316/484] Iter:[120/495], Time: 0.37, lr: [0.0038534799347277964], Loss: 1.998494, Acc:0.810920, Semantic loss: 0.746871, BCE loss: 0.529396, SB loss: 0.722227
2023-10-30 17:37:42,645 Epoch: [316/484] Iter:[130/495], Time: 0.37, lr: [0.003853062286266275], Loss: 1.997933, Acc:0.811779, Semantic loss: 0.744303, BCE loss: 0.530730, SB loss: 0.722900
2023-10-30 17:37:46,158 Epoch: [316/484] Iter:[140/495], Time: 0.37, lr: [0.0038526446327746323], Loss: 1.993673, Acc:0.811809, Semantic loss: 0.745121, BCE loss: 0.525214, SB loss: 0.723338
2023-10-30 17:37:49,747 Epoch: [316/484] Iter:[150/495], Time: 0.37, lr: [0.003852226974252202], Loss: 1.991173, Acc:0.809461, Semantic loss: 0.746091, BCE loss: 0.522698, SB loss: 0.722384
2023-10-30 17:37:53,356 Epoch: [316/484] Iter:[160/495], Time: 0.37, lr: [0.003851809310698316], Loss: 2.000791, Acc:0.808923, Semantic loss: 0.753064, BCE loss: 0.524376, SB loss: 0.723352
2023-10-30 17:37:56,952 Epoch: [316/484] Iter:[170/495], Time: 0.37, lr: [0.0038513916421123095], Loss: 1.991987, Acc:0.808894, Semantic loss: 0.748839, BCE loss: 0.520810, SB loss: 0.722339
2023-10-30 17:38:00,493 Epoch: [316/484] Iter:[180/495], Time: 0.37, lr: [0.003850973968493515], Loss: 1.993070, Acc:0.808553, Semantic loss: 0.750003, BCE loss: 0.520466, SB loss: 0.722601
2023-10-30 17:38:04,049 Epoch: [316/484] Iter:[190/495], Time: 0.37, lr: [0.003850556289841265], Loss: 1.994365, Acc:0.805940, Semantic loss: 0.749236, BCE loss: 0.523100, SB loss: 0.722029
2023-10-30 17:38:07,628 Epoch: [316/484] Iter:[200/495], Time: 0.37, lr: [0.003850138606154891], Loss: 1.992862, Acc:0.805608, Semantic loss: 0.747963, BCE loss: 0.523819, SB loss: 0.721080
2023-10-30 17:38:11,289 Epoch: [316/484] Iter:[210/495], Time: 0.37, lr: [0.0038497209174337276], Loss: 1.997621, Acc:0.804304, Semantic loss: 0.752437, BCE loss: 0.522512, SB loss: 0.722672
2023-10-30 17:38:14,938 Epoch: [316/484] Iter:[220/495], Time: 0.37, lr: [0.0038493032236771065], Loss: 1.994207, Acc:0.804693, Semantic loss: 0.750433, BCE loss: 0.522399, SB loss: 0.721374
2023-10-30 17:38:18,543 Epoch: [316/484] Iter:[230/495], Time: 0.37, lr: [0.0038488855248843597], Loss: 1.988875, Acc:0.804511, Semantic loss: 0.748303, BCE loss: 0.520635, SB loss: 0.719937
2023-10-30 17:38:22,198 Epoch: [316/484] Iter:[240/495], Time: 0.37, lr: [0.0038484678210548174], Loss: 1.992628, Acc:0.803600, Semantic loss: 0.749604, BCE loss: 0.522463, SB loss: 0.720562
2023-10-30 17:38:25,966 Epoch: [316/484] Iter:[250/495], Time: 0.37, lr: [0.003848050112187814], Loss: 1.991221, Acc:0.802883, Semantic loss: 0.748719, BCE loss: 0.522584, SB loss: 0.719918
2023-10-30 17:38:29,683 Epoch: [316/484] Iter:[260/495], Time: 0.37, lr: [0.0038476323982826813], Loss: 1.989360, Acc:0.804297, Semantic loss: 0.748201, BCE loss: 0.522571, SB loss: 0.718588
2023-10-30 17:38:33,231 Epoch: [316/484] Iter:[270/495], Time: 0.37, lr: [0.003847214679338749], Loss: 1.984793, Acc:0.802122, Semantic loss: 0.746282, BCE loss: 0.521449, SB loss: 0.717062
2023-10-30 17:38:36,844 Epoch: [316/484] Iter:[280/495], Time: 0.37, lr: [0.003846796955355348], Loss: 1.984812, Acc:0.800985, Semantic loss: 0.747895, BCE loss: 0.519559, SB loss: 0.717359
2023-10-30 17:38:40,466 Epoch: [316/484] Iter:[290/495], Time: 0.37, lr: [0.0038463792263318127], Loss: 1.990597, Acc:0.801170, Semantic loss: 0.750961, BCE loss: 0.521318, SB loss: 0.718319
2023-10-30 17:38:44,244 Epoch: [316/484] Iter:[300/495], Time: 0.37, lr: [0.003845961492267471], Loss: 1.989531, Acc:0.801419, Semantic loss: 0.751322, BCE loss: 0.519620, SB loss: 0.718589
2023-10-30 17:38:47,862 Epoch: [316/484] Iter:[310/495], Time: 0.37, lr: [0.003845543753161655], Loss: 1.988669, Acc:0.800394, Semantic loss: 0.752342, BCE loss: 0.517312, SB loss: 0.719015
2023-10-30 17:38:51,569 Epoch: [316/484] Iter:[320/495], Time: 0.37, lr: [0.003845126009013694], Loss: 1.987791, Acc:0.799526, Semantic loss: 0.752274, BCE loss: 0.517112, SB loss: 0.718405
2023-10-30 17:38:55,248 Epoch: [316/484] Iter:[330/495], Time: 0.37, lr: [0.0038447082598229198], Loss: 1.986228, Acc:0.799366, Semantic loss: 0.751822, BCE loss: 0.515716, SB loss: 0.718690
2023-10-30 17:38:58,898 Epoch: [316/484] Iter:[340/495], Time: 0.37, lr: [0.0038442905055886636], Loss: 1.985021, Acc:0.799260, Semantic loss: 0.750971, BCE loss: 0.515735, SB loss: 0.718316
2023-10-30 17:39:02,632 Epoch: [316/484] Iter:[350/495], Time: 0.37, lr: [0.0038438727463102535], Loss: 1.989502, Acc:0.799236, Semantic loss: 0.752518, BCE loss: 0.517833, SB loss: 0.719151
2023-10-30 17:39:06,262 Epoch: [316/484] Iter:[360/495], Time: 0.37, lr: [0.0038434549819870195], Loss: 1.988409, Acc:0.799167, Semantic loss: 0.752278, BCE loss: 0.516676, SB loss: 0.719455
2023-10-30 17:39:10,097 Epoch: [316/484] Iter:[370/495], Time: 0.37, lr: [0.0038430372126182933], Loss: 1.989001, Acc:0.799832, Semantic loss: 0.752315, BCE loss: 0.518174, SB loss: 0.718512
2023-10-30 17:39:13,746 Epoch: [316/484] Iter:[380/495], Time: 0.37, lr: [0.0038426194382034035], Loss: 1.985536, Acc:0.799662, Semantic loss: 0.750313, BCE loss: 0.516320, SB loss: 0.718904
2023-10-30 17:39:17,407 Epoch: [316/484] Iter:[390/495], Time: 0.37, lr: [0.003842201658741679], Loss: 1.985772, Acc:0.799847, Semantic loss: 0.750087, BCE loss: 0.517040, SB loss: 0.718645
2023-10-30 17:39:21,203 Epoch: [316/484] Iter:[400/495], Time: 0.37, lr: [0.003841783874232449], Loss: 1.984508, Acc:0.800239, Semantic loss: 0.750129, BCE loss: 0.516577, SB loss: 0.717802
2023-10-30 17:39:24,831 Epoch: [316/484] Iter:[410/495], Time: 0.37, lr: [0.0038413660846750436], Loss: 1.985246, Acc:0.799251, Semantic loss: 0.751131, BCE loss: 0.515516, SB loss: 0.718600
2023-10-30 17:39:28,530 Epoch: [316/484] Iter:[420/495], Time: 0.37, lr: [0.003840948290068792], Loss: 1.984589, Acc:0.798791, Semantic loss: 0.750504, BCE loss: 0.515334, SB loss: 0.718751
2023-10-30 17:39:32,213 Epoch: [316/484] Iter:[430/495], Time: 0.37, lr: [0.003840530490413022], Loss: 1.985893, Acc:0.798853, Semantic loss: 0.750747, BCE loss: 0.516139, SB loss: 0.719007
2023-10-30 17:39:35,926 Epoch: [316/484] Iter:[440/495], Time: 0.37, lr: [0.003840112685707061], Loss: 1.987325, Acc:0.798837, Semantic loss: 0.750968, BCE loss: 0.516779, SB loss: 0.719578
2023-10-30 17:39:39,606 Epoch: [316/484] Iter:[450/495], Time: 0.37, lr: [0.0038396948759502406], Loss: 1.988905, Acc:0.799095, Semantic loss: 0.751036, BCE loss: 0.518193, SB loss: 0.719676
2023-10-30 17:39:43,218 Epoch: [316/484] Iter:[460/495], Time: 0.37, lr: [0.0038392770611418866], Loss: 1.988198, Acc:0.798254, Semantic loss: 0.750457, BCE loss: 0.518175, SB loss: 0.719567
2023-10-30 17:39:46,897 Epoch: [316/484] Iter:[470/495], Time: 0.37, lr: [0.0038388592412813265], Loss: 1.986895, Acc:0.798896, Semantic loss: 0.750047, BCE loss: 0.517934, SB loss: 0.718915
2023-10-30 17:39:50,575 Epoch: [316/484] Iter:[480/495], Time: 0.37, lr: [0.0038384414163678917], Loss: 1.989151, Acc:0.798618, Semantic loss: 0.751013, BCE loss: 0.518923, SB loss: 0.719215
2023-10-30 17:39:54,116 Epoch: [316/484] Iter:[490/495], Time: 0.37, lr: [0.0038380235864009073], Loss: 1.987919, Acc:0.797542, Semantic loss: 0.750854, BCE loss: 0.518348, SB loss: 0.718717
2023-10-30 17:39:55,521 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:39:55,764 Loss: 2.046, MeanIU:  0.7084, Best_mIoU:  0.7309
2023-10-30 17:39:55,765 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924]
2023-10-30 17:39:57,983 Epoch: [317/484] Iter:[0/495], Time: 2.18, lr: [0.003837814669522124], Loss: 2.180671, Acc:0.871738, Semantic loss: 0.728433, BCE loss: 0.727125, SB loss: 0.725113
2023-10-30 17:40:02,056 Epoch: [317/484] Iter:[10/495], Time: 0.57, lr: [0.0038373968319735546], Loss: 2.057560, Acc:0.792431, Semantic loss: 0.735736, BCE loss: 0.601670, SB loss: 0.720155
2023-10-30 17:40:05,790 Epoch: [317/484] Iter:[20/495], Time: 0.48, lr: [0.0038369789893697545], Loss: 1.978438, Acc:0.795275, Semantic loss: 0.727957, BCE loss: 0.525414, SB loss: 0.725066
2023-10-30 17:40:09,509 Epoch: [317/484] Iter:[30/495], Time: 0.44, lr: [0.0038365611417100517], Loss: 2.000149, Acc:0.794394, Semantic loss: 0.745863, BCE loss: 0.524300, SB loss: 0.729986
2023-10-30 17:40:13,179 Epoch: [317/484] Iter:[40/495], Time: 0.42, lr: [0.0038361432889937727], Loss: 1.983296, Acc:0.789593, Semantic loss: 0.738472, BCE loss: 0.519799, SB loss: 0.725025
2023-10-30 17:40:16,773 Epoch: [317/484] Iter:[50/495], Time: 0.41, lr: [0.0038357254312202434], Loss: 1.975820, Acc:0.794302, Semantic loss: 0.736311, BCE loss: 0.514040, SB loss: 0.725469
2023-10-30 17:40:20,513 Epoch: [317/484] Iter:[60/495], Time: 0.41, lr: [0.0038353075683887905], Loss: 1.959170, Acc:0.788919, Semantic loss: 0.731484, BCE loss: 0.506344, SB loss: 0.721342
2023-10-30 17:40:24,151 Epoch: [317/484] Iter:[70/495], Time: 0.40, lr: [0.0038348897004987425], Loss: 1.962648, Acc:0.791723, Semantic loss: 0.735395, BCE loss: 0.507143, SB loss: 0.720110
2023-10-30 17:40:27,825 Epoch: [317/484] Iter:[80/495], Time: 0.40, lr: [0.003834471827549424], Loss: 1.962117, Acc:0.786349, Semantic loss: 0.738096, BCE loss: 0.500917, SB loss: 0.723104
2023-10-30 17:40:31,503 Epoch: [317/484] Iter:[90/495], Time: 0.39, lr: [0.003834053949540162], Loss: 1.969377, Acc:0.792446, Semantic loss: 0.740089, BCE loss: 0.510119, SB loss: 0.719169
2023-10-30 17:40:35,171 Epoch: [317/484] Iter:[100/495], Time: 0.39, lr: [0.0038336360664702803], Loss: 1.981483, Acc:0.789666, Semantic loss: 0.748376, BCE loss: 0.510976, SB loss: 0.722131
2023-10-30 17:40:39,006 Epoch: [317/484] Iter:[110/495], Time: 0.39, lr: [0.003833218178339107], Loss: 1.975464, Acc:0.787557, Semantic loss: 0.742571, BCE loss: 0.513230, SB loss: 0.719662
2023-10-30 17:40:42,697 Epoch: [317/484] Iter:[120/495], Time: 0.39, lr: [0.0038328002851459675], Loss: 1.981752, Acc:0.790110, Semantic loss: 0.744491, BCE loss: 0.517029, SB loss: 0.720232
2023-10-30 17:40:46,477 Epoch: [317/484] Iter:[130/495], Time: 0.39, lr: [0.003832382386890186], Loss: 1.976926, Acc:0.796596, Semantic loss: 0.739250, BCE loss: 0.518539, SB loss: 0.719137
2023-10-30 17:40:50,115 Epoch: [317/484] Iter:[140/495], Time: 0.39, lr: [0.0038319644835710888], Loss: 1.968747, Acc:0.796507, Semantic loss: 0.736111, BCE loss: 0.517303, SB loss: 0.715333
2023-10-30 17:40:53,845 Epoch: [317/484] Iter:[150/495], Time: 0.38, lr: [0.003831546575188001], Loss: 1.965647, Acc:0.797509, Semantic loss: 0.733433, BCE loss: 0.516548, SB loss: 0.715665
2023-10-30 17:40:57,481 Epoch: [317/484] Iter:[160/495], Time: 0.38, lr: [0.003831128661740247], Loss: 1.965087, Acc:0.799669, Semantic loss: 0.734189, BCE loss: 0.515991, SB loss: 0.714907
2023-10-30 17:41:01,106 Epoch: [317/484] Iter:[170/495], Time: 0.38, lr: [0.0038307107432271515], Loss: 1.972624, Acc:0.802063, Semantic loss: 0.740210, BCE loss: 0.516732, SB loss: 0.715682
2023-10-30 17:41:04,683 Epoch: [317/484] Iter:[180/495], Time: 0.38, lr: [0.0038302928196480386], Loss: 1.971613, Acc:0.802132, Semantic loss: 0.740441, BCE loss: 0.516785, SB loss: 0.714387
2023-10-30 17:41:08,428 Epoch: [317/484] Iter:[190/495], Time: 0.38, lr: [0.0038298748910022347], Loss: 1.971103, Acc:0.802297, Semantic loss: 0.740913, BCE loss: 0.515792, SB loss: 0.714398
2023-10-30 17:41:12,160 Epoch: [317/484] Iter:[200/495], Time: 0.38, lr: [0.0038294569572890624], Loss: 1.965323, Acc:0.804390, Semantic loss: 0.737787, BCE loss: 0.514775, SB loss: 0.712762
2023-10-30 17:41:15,838 Epoch: [317/484] Iter:[210/495], Time: 0.38, lr: [0.003829039018507846], Loss: 1.971376, Acc:0.803546, Semantic loss: 0.742097, BCE loss: 0.514478, SB loss: 0.714801
2023-10-30 17:41:19,479 Epoch: [317/484] Iter:[220/495], Time: 0.38, lr: [0.0038286210746579087], Loss: 1.972461, Acc:0.803666, Semantic loss: 0.740144, BCE loss: 0.517426, SB loss: 0.714891
2023-10-30 17:41:23,248 Epoch: [317/484] Iter:[230/495], Time: 0.38, lr: [0.003828203125738576], Loss: 1.970090, Acc:0.803596, Semantic loss: 0.736544, BCE loss: 0.519280, SB loss: 0.714266
2023-10-30 17:41:26,976 Epoch: [317/484] Iter:[240/495], Time: 0.38, lr: [0.0038277851717491707], Loss: 1.970698, Acc:0.802973, Semantic loss: 0.736839, BCE loss: 0.519568, SB loss: 0.714291
2023-10-30 17:41:30,672 Epoch: [317/484] Iter:[250/495], Time: 0.38, lr: [0.003827367212689015], Loss: 1.971153, Acc:0.803683, Semantic loss: 0.737754, BCE loss: 0.518585, SB loss: 0.714814
2023-10-30 17:41:34,428 Epoch: [317/484] Iter:[260/495], Time: 0.38, lr: [0.003826949248557433], Loss: 1.970207, Acc:0.806171, Semantic loss: 0.736670, BCE loss: 0.519524, SB loss: 0.714013
2023-10-30 17:41:38,110 Epoch: [317/484] Iter:[270/495], Time: 0.38, lr: [0.0038265312793537482], Loss: 1.967532, Acc:0.806478, Semantic loss: 0.735629, BCE loss: 0.518655, SB loss: 0.713248
2023-10-30 17:41:41,795 Epoch: [317/484] Iter:[280/495], Time: 0.38, lr: [0.0038261133050772832], Loss: 1.971924, Acc:0.804661, Semantic loss: 0.737963, BCE loss: 0.520100, SB loss: 0.713861
2023-10-30 17:41:45,474 Epoch: [317/484] Iter:[290/495], Time: 0.38, lr: [0.0038256953257273596], Loss: 1.973579, Acc:0.804420, Semantic loss: 0.738913, BCE loss: 0.521703, SB loss: 0.712963
2023-10-30 17:41:49,213 Epoch: [317/484] Iter:[300/495], Time: 0.38, lr: [0.0038252773413033014], Loss: 1.974793, Acc:0.803998, Semantic loss: 0.739131, BCE loss: 0.522295, SB loss: 0.713367
2023-10-30 17:41:52,885 Epoch: [317/484] Iter:[310/495], Time: 0.38, lr: [0.003824859351804431], Loss: 1.977608, Acc:0.803620, Semantic loss: 0.742565, BCE loss: 0.522176, SB loss: 0.712867
2023-10-30 17:41:56,563 Epoch: [317/484] Iter:[320/495], Time: 0.38, lr: [0.0038244413572300698], Loss: 1.975219, Acc:0.803785, Semantic loss: 0.741162, BCE loss: 0.521287, SB loss: 0.712769
2023-10-30 17:42:00,292 Epoch: [317/484] Iter:[330/495], Time: 0.38, lr: [0.003824023357579538], Loss: 1.970292, Acc:0.805103, Semantic loss: 0.738884, BCE loss: 0.520037, SB loss: 0.711371
2023-10-30 17:42:03,960 Epoch: [317/484] Iter:[340/495], Time: 0.38, lr: [0.003823605352852161], Loss: 1.968592, Acc:0.805210, Semantic loss: 0.738965, BCE loss: 0.519415, SB loss: 0.710211
2023-10-30 17:42:07,729 Epoch: [317/484] Iter:[350/495], Time: 0.38, lr: [0.0038231873430472586], Loss: 1.970309, Acc:0.806412, Semantic loss: 0.739467, BCE loss: 0.520598, SB loss: 0.710245
2023-10-30 17:42:11,485 Epoch: [317/484] Iter:[360/495], Time: 0.38, lr: [0.0038227693281641523], Loss: 1.972956, Acc:0.806050, Semantic loss: 0.741876, BCE loss: 0.520374, SB loss: 0.710705
2023-10-30 17:42:15,260 Epoch: [317/484] Iter:[370/495], Time: 0.38, lr: [0.003822351308202163], Loss: 1.973827, Acc:0.806161, Semantic loss: 0.743080, BCE loss: 0.519637, SB loss: 0.711110
2023-10-30 17:42:18,977 Epoch: [317/484] Iter:[380/495], Time: 0.38, lr: [0.003821933283160613], Loss: 1.976918, Acc:0.805570, Semantic loss: 0.745406, BCE loss: 0.520162, SB loss: 0.711349
2023-10-30 17:42:22,752 Epoch: [317/484] Iter:[390/495], Time: 0.38, lr: [0.003821515253038822], Loss: 1.974768, Acc:0.805772, Semantic loss: 0.743591, BCE loss: 0.520562, SB loss: 0.710615
2023-10-30 17:42:26,387 Epoch: [317/484] Iter:[400/495], Time: 0.38, lr: [0.003821097217836112], Loss: 1.976936, Acc:0.805800, Semantic loss: 0.744896, BCE loss: 0.520724, SB loss: 0.711316
2023-10-30 17:42:30,031 Epoch: [317/484] Iter:[410/495], Time: 0.38, lr: [0.003820679177551802], Loss: 1.972600, Acc:0.805232, Semantic loss: 0.741741, BCE loss: 0.520289, SB loss: 0.710570
2023-10-30 17:42:33,671 Epoch: [317/484] Iter:[420/495], Time: 0.37, lr: [0.0038202611321852143], Loss: 1.971746, Acc:0.804287, Semantic loss: 0.741532, BCE loss: 0.519388, SB loss: 0.710826
2023-10-30 17:42:37,371 Epoch: [317/484] Iter:[430/495], Time: 0.37, lr: [0.0038198430817356684], Loss: 1.974927, Acc:0.803604, Semantic loss: 0.743838, BCE loss: 0.519462, SB loss: 0.711626
2023-10-30 17:42:41,022 Epoch: [317/484] Iter:[440/495], Time: 0.37, lr: [0.0038194250262024837], Loss: 1.970742, Acc:0.803111, Semantic loss: 0.742654, BCE loss: 0.517828, SB loss: 0.710260
2023-10-30 17:42:44,707 Epoch: [317/484] Iter:[450/495], Time: 0.37, lr: [0.0038190069655849803], Loss: 1.969499, Acc:0.802499, Semantic loss: 0.741898, BCE loss: 0.518008, SB loss: 0.709593
2023-10-30 17:42:48,409 Epoch: [317/484] Iter:[460/495], Time: 0.37, lr: [0.003818588899882479], Loss: 1.971381, Acc:0.803312, Semantic loss: 0.742179, BCE loss: 0.518791, SB loss: 0.710410
2023-10-30 17:42:52,078 Epoch: [317/484] Iter:[470/495], Time: 0.37, lr: [0.0038181708290942985], Loss: 1.970958, Acc:0.803167, Semantic loss: 0.741757, BCE loss: 0.518147, SB loss: 0.711055
2023-10-30 17:42:55,798 Epoch: [317/484] Iter:[480/495], Time: 0.37, lr: [0.003817752753219758], Loss: 1.970246, Acc:0.803525, Semantic loss: 0.741852, BCE loss: 0.517624, SB loss: 0.710771
2023-10-30 17:42:59,326 Epoch: [317/484] Iter:[490/495], Time: 0.37, lr: [0.003817334672258177], Loss: 1.973022, Acc:0.804238, Semantic loss: 0.743839, BCE loss: 0.517779, SB loss: 0.711404
2023-10-30 17:43:00,741 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:43:00,978 Loss: 2.046, MeanIU:  0.7084, Best_mIoU:  0.7309
2023-10-30 17:43:00,979 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924]
2023-10-30 17:43:03,244 Epoch: [318/484] Iter:[0/495], Time: 2.23, lr: [0.0038171256298695335], Loss: 1.896978, Acc:0.831545, Semantic loss: 0.682161, BCE loss: 0.558551, SB loss: 0.656266
2023-10-30 17:43:07,184 Epoch: [318/484] Iter:[10/495], Time: 0.56, lr: [0.0038167075412761154], Loss: 1.931138, Acc:0.793680, Semantic loss: 0.710990, BCE loss: 0.514512, SB loss: 0.705635
2023-10-30 17:43:10,923 Epoch: [318/484] Iter:[20/495], Time: 0.47, lr: [0.003816289447593954], Loss: 1.957844, Acc:0.796127, Semantic loss: 0.736034, BCE loss: 0.513219, SB loss: 0.708591
2023-10-30 17:43:14,503 Epoch: [318/484] Iter:[30/495], Time: 0.44, lr: [0.0038158713488223683], Loss: 1.969462, Acc:0.800555, Semantic loss: 0.739479, BCE loss: 0.518467, SB loss: 0.711517
2023-10-30 17:43:18,178 Epoch: [318/484] Iter:[40/495], Time: 0.42, lr: [0.0038154532449606753], Loss: 1.941051, Acc:0.803062, Semantic loss: 0.727776, BCE loss: 0.514779, SB loss: 0.698497
2023-10-30 17:43:21,951 Epoch: [318/484] Iter:[50/495], Time: 0.41, lr: [0.003815035136008196], Loss: 1.958734, Acc:0.807830, Semantic loss: 0.734023, BCE loss: 0.524073, SB loss: 0.700638
2023-10-30 17:43:25,739 Epoch: [318/484] Iter:[60/495], Time: 0.41, lr: [0.003814617021964246], Loss: 1.979270, Acc:0.815633, Semantic loss: 0.738171, BCE loss: 0.535083, SB loss: 0.706016
2023-10-30 17:43:29,519 Epoch: [318/484] Iter:[70/495], Time: 0.40, lr: [0.0038141989028281447], Loss: 2.012624, Acc:0.816504, Semantic loss: 0.758255, BCE loss: 0.539244, SB loss: 0.715125
2023-10-30 17:43:33,250 Epoch: [318/484] Iter:[80/495], Time: 0.40, lr: [0.0038137807785992087], Loss: 1.997707, Acc:0.813339, Semantic loss: 0.739700, BCE loss: 0.544326, SB loss: 0.713682
2023-10-30 17:43:37,018 Epoch: [318/484] Iter:[90/495], Time: 0.40, lr: [0.0038133626492767563], Loss: 2.004525, Acc:0.816657, Semantic loss: 0.739755, BCE loss: 0.551106, SB loss: 0.713664
2023-10-30 17:43:40,697 Epoch: [318/484] Iter:[100/495], Time: 0.39, lr: [0.003812944514860105], Loss: 1.997457, Acc:0.813331, Semantic loss: 0.738083, BCE loss: 0.547043, SB loss: 0.712332
2023-10-30 17:43:44,477 Epoch: [318/484] Iter:[110/495], Time: 0.39, lr: [0.0038125263753485705], Loss: 2.002938, Acc:0.809788, Semantic loss: 0.742224, BCE loss: 0.544576, SB loss: 0.716137
2023-10-30 17:43:48,202 Epoch: [318/484] Iter:[120/495], Time: 0.39, lr: [0.003812108230741472], Loss: 1.998880, Acc:0.809593, Semantic loss: 0.739970, BCE loss: 0.541717, SB loss: 0.717194
2023-10-30 17:43:51,809 Epoch: [318/484] Iter:[130/495], Time: 0.39, lr: [0.0038116900810381254], Loss: 1.994411, Acc:0.810328, Semantic loss: 0.739604, BCE loss: 0.538662, SB loss: 0.716145
2023-10-30 17:43:55,656 Epoch: [318/484] Iter:[140/495], Time: 0.39, lr: [0.0038112719262378483], Loss: 1.990827, Acc:0.812206, Semantic loss: 0.739522, BCE loss: 0.535550, SB loss: 0.715755
2023-10-30 17:43:59,323 Epoch: [318/484] Iter:[150/495], Time: 0.39, lr: [0.003810853766339954], Loss: 1.995145, Acc:0.812531, Semantic loss: 0.742426, BCE loss: 0.536323, SB loss: 0.716396
2023-10-30 17:44:03,042 Epoch: [318/484] Iter:[160/495], Time: 0.39, lr: [0.003810435601343763], Loss: 1.996052, Acc:0.814317, Semantic loss: 0.741347, BCE loss: 0.539858, SB loss: 0.714846
2023-10-30 17:44:06,858 Epoch: [318/484] Iter:[170/495], Time: 0.39, lr: [0.003810017431248589], Loss: 1.996943, Acc:0.812237, Semantic loss: 0.743378, BCE loss: 0.540684, SB loss: 0.712881
2023-10-30 17:44:10,563 Epoch: [318/484] Iter:[180/495], Time: 0.38, lr: [0.003809599256053749], Loss: 1.999151, Acc:0.811747, Semantic loss: 0.744304, BCE loss: 0.540751, SB loss: 0.714096
2023-10-30 17:44:14,278 Epoch: [318/484] Iter:[190/495], Time: 0.38, lr: [0.003809181075758557], Loss: 2.002880, Acc:0.812656, Semantic loss: 0.745100, BCE loss: 0.543178, SB loss: 0.714602
2023-10-30 17:44:17,847 Epoch: [318/484] Iter:[200/495], Time: 0.38, lr: [0.003808762890362332], Loss: 2.003129, Acc:0.811304, Semantic loss: 0.745103, BCE loss: 0.543475, SB loss: 0.714551
2023-10-30 17:44:21,553 Epoch: [318/484] Iter:[210/495], Time: 0.38, lr: [0.003808344699864387], Loss: 2.003249, Acc:0.810581, Semantic loss: 0.746856, BCE loss: 0.540813, SB loss: 0.715580
2023-10-30 17:44:25,232 Epoch: [318/484] Iter:[220/495], Time: 0.38, lr: [0.003807926504264037], Loss: 2.003409, Acc:0.809409, Semantic loss: 0.746533, BCE loss: 0.541397, SB loss: 0.715479
2023-10-30 17:44:28,977 Epoch: [318/484] Iter:[230/495], Time: 0.38, lr: [0.0038075083035605975], Loss: 1.999195, Acc:0.808773, Semantic loss: 0.745364, BCE loss: 0.539092, SB loss: 0.714739
2023-10-30 17:44:32,841 Epoch: [318/484] Iter:[240/495], Time: 0.38, lr: [0.003807090097753385], Loss: 2.000458, Acc:0.809435, Semantic loss: 0.746413, BCE loss: 0.539520, SB loss: 0.714525
2023-10-30 17:44:36,540 Epoch: [318/484] Iter:[250/495], Time: 0.38, lr: [0.0038066718868417127], Loss: 2.007724, Acc:0.810292, Semantic loss: 0.751428, BCE loss: 0.541163, SB loss: 0.715133
2023-10-30 17:44:40,183 Epoch: [318/484] Iter:[260/495], Time: 0.38, lr: [0.0038062536708248955], Loss: 2.004657, Acc:0.808205, Semantic loss: 0.750285, BCE loss: 0.540666, SB loss: 0.713706
2023-10-30 17:44:43,950 Epoch: [318/484] Iter:[270/495], Time: 0.38, lr: [0.0038058354497022473], Loss: 1.997879, Acc:0.808390, Semantic loss: 0.746583, BCE loss: 0.538272, SB loss: 0.713024
2023-10-30 17:44:47,729 Epoch: [318/484] Iter:[280/495], Time: 0.38, lr: [0.003805417223473084], Loss: 2.000650, Acc:0.809008, Semantic loss: 0.747849, BCE loss: 0.540103, SB loss: 0.712697
2023-10-30 17:44:51,508 Epoch: [318/484] Iter:[290/495], Time: 0.38, lr: [0.003804998992136718], Loss: 2.000512, Acc:0.809629, Semantic loss: 0.746769, BCE loss: 0.540530, SB loss: 0.713212
2023-10-30 17:44:55,261 Epoch: [318/484] Iter:[300/495], Time: 0.38, lr: [0.003804580755692464], Loss: 2.002228, Acc:0.809247, Semantic loss: 0.747172, BCE loss: 0.541334, SB loss: 0.713722
2023-10-30 17:44:59,004 Epoch: [318/484] Iter:[310/495], Time: 0.38, lr: [0.003804162514139634], Loss: 2.000717, Acc:0.810803, Semantic loss: 0.746586, BCE loss: 0.540372, SB loss: 0.713759
2023-10-30 17:45:02,721 Epoch: [318/484] Iter:[320/495], Time: 0.38, lr: [0.003803744267477545], Loss: 1.998198, Acc:0.812128, Semantic loss: 0.745544, BCE loss: 0.539059, SB loss: 0.713595
2023-10-30 17:45:06,429 Epoch: [318/484] Iter:[330/495], Time: 0.38, lr: [0.0038033260157055073], Loss: 1.998369, Acc:0.811498, Semantic loss: 0.746581, BCE loss: 0.537815, SB loss: 0.713973
2023-10-30 17:45:10,104 Epoch: [318/484] Iter:[340/495], Time: 0.38, lr: [0.0038029077588228356], Loss: 1.999361, Acc:0.811347, Semantic loss: 0.748119, BCE loss: 0.537378, SB loss: 0.713865
2023-10-30 17:45:13,775 Epoch: [318/484] Iter:[350/495], Time: 0.38, lr: [0.003802489496828841], Loss: 1.999141, Acc:0.810642, Semantic loss: 0.748181, BCE loss: 0.536334, SB loss: 0.714625
2023-10-30 17:45:17,406 Epoch: [318/484] Iter:[360/495], Time: 0.38, lr: [0.0038020712297228395], Loss: 1.996701, Acc:0.808784, Semantic loss: 0.747936, BCE loss: 0.534102, SB loss: 0.714664
2023-10-30 17:45:21,183 Epoch: [318/484] Iter:[370/495], Time: 0.38, lr: [0.003801652957504141], Loss: 1.993796, Acc:0.809477, Semantic loss: 0.746119, BCE loss: 0.533959, SB loss: 0.713718
2023-10-30 17:45:24,931 Epoch: [318/484] Iter:[380/495], Time: 0.38, lr: [0.0038012346801720594], Loss: 1.996402, Acc:0.809152, Semantic loss: 0.746913, BCE loss: 0.536402, SB loss: 0.713088
2023-10-30 17:45:28,715 Epoch: [318/484] Iter:[390/495], Time: 0.38, lr: [0.0038008163977259054], Loss: 1.994982, Acc:0.809551, Semantic loss: 0.746618, BCE loss: 0.535765, SB loss: 0.712599
2023-10-30 17:45:32,345 Epoch: [318/484] Iter:[400/495], Time: 0.38, lr: [0.003800398110164993], Loss: 1.991849, Acc:0.809409, Semantic loss: 0.744966, BCE loss: 0.534678, SB loss: 0.712205
2023-10-30 17:45:36,056 Epoch: [318/484] Iter:[410/495], Time: 0.38, lr: [0.0037999798174886343], Loss: 1.990875, Acc:0.809016, Semantic loss: 0.744642, BCE loss: 0.534095, SB loss: 0.712138
2023-10-30 17:45:39,760 Epoch: [318/484] Iter:[420/495], Time: 0.38, lr: [0.0037995615196961393], Loss: 1.991945, Acc:0.809168, Semantic loss: 0.744764, BCE loss: 0.534550, SB loss: 0.712631
2023-10-30 17:45:43,604 Epoch: [318/484] Iter:[430/495], Time: 0.38, lr: [0.0037991432167868194], Loss: 1.993732, Acc:0.809349, Semantic loss: 0.744845, BCE loss: 0.535634, SB loss: 0.713253
2023-10-30 17:45:47,399 Epoch: [318/484] Iter:[440/495], Time: 0.38, lr: [0.0037987249087599886], Loss: 1.994271, Acc:0.809349, Semantic loss: 0.745308, BCE loss: 0.535945, SB loss: 0.713017
2023-10-30 17:45:51,048 Epoch: [318/484] Iter:[450/495], Time: 0.38, lr: [0.003798306595614956], Loss: 1.996497, Acc:0.809324, Semantic loss: 0.746302, BCE loss: 0.537102, SB loss: 0.713093
2023-10-30 17:45:54,948 Epoch: [318/484] Iter:[460/495], Time: 0.38, lr: [0.0037978882773510338], Loss: 1.996915, Acc:0.807354, Semantic loss: 0.747973, BCE loss: 0.534869, SB loss: 0.714074
2023-10-30 17:45:58,701 Epoch: [318/484] Iter:[470/495], Time: 0.38, lr: [0.0037974699539675308], Loss: 1.997344, Acc:0.807272, Semantic loss: 0.748582, BCE loss: 0.533925, SB loss: 0.714837
2023-10-30 17:46:02,432 Epoch: [318/484] Iter:[480/495], Time: 0.38, lr: [0.0037970516254637603], Loss: 2.004765, Acc:0.806891, Semantic loss: 0.752117, BCE loss: 0.534962, SB loss: 0.717686
2023-10-30 17:46:05,977 Epoch: [318/484] Iter:[490/495], Time: 0.38, lr: [0.003796633291839032], Loss: 2.004694, Acc:0.806861, Semantic loss: 0.751706, BCE loss: 0.535258, SB loss: 0.717730
2023-10-30 17:46:07,373 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:46:07,616 Loss: 2.046, MeanIU:  0.7084, Best_mIoU:  0.7309
2023-10-30 17:46:07,616 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924]
2023-10-30 17:46:09,869 Epoch: [319/484] Iter:[0/495], Time: 2.22, lr: [0.0037964241231060927], Loss: 2.154248, Acc:0.795302, Semantic loss: 0.803949, BCE loss: 0.482276, SB loss: 0.868024
2023-10-30 17:46:13,947 Epoch: [319/484] Iter:[10/495], Time: 0.57, lr: [0.0037960057817986326], Loss: 1.983412, Acc:0.789199, Semantic loss: 0.723624, BCE loss: 0.534707, SB loss: 0.725081
2023-10-30 17:46:17,799 Epoch: [319/484] Iter:[20/495], Time: 0.48, lr: [0.0037955874353684917], Loss: 2.015574, Acc:0.788712, Semantic loss: 0.748482, BCE loss: 0.541663, SB loss: 0.725428
2023-10-30 17:46:21,549 Epoch: [319/484] Iter:[30/495], Time: 0.45, lr: [0.0037951690838149777], Loss: 1.977892, Acc:0.787261, Semantic loss: 0.730773, BCE loss: 0.523103, SB loss: 0.724015
2023-10-30 17:46:25,171 Epoch: [319/484] Iter:[40/495], Time: 0.43, lr: [0.0037947507271374006], Loss: 1.967465, Acc:0.788735, Semantic loss: 0.736274, BCE loss: 0.506788, SB loss: 0.724402
2023-10-30 17:46:28,818 Epoch: [319/484] Iter:[50/495], Time: 0.41, lr: [0.003794332365335069], Loss: 1.925677, Acc:0.793258, Semantic loss: 0.710987, BCE loss: 0.501000, SB loss: 0.713690
2023-10-30 17:46:32,620 Epoch: [319/484] Iter:[60/495], Time: 0.41, lr: [0.003793913998407295], Loss: 1.976328, Acc:0.795757, Semantic loss: 0.739308, BCE loss: 0.514763, SB loss: 0.722258
2023-10-30 17:46:36,365 Epoch: [319/484] Iter:[70/495], Time: 0.40, lr: [0.003793495626353386], Loss: 2.007214, Acc:0.798591, Semantic loss: 0.752130, BCE loss: 0.527466, SB loss: 0.727617
2023-10-30 17:46:39,989 Epoch: [319/484] Iter:[80/495], Time: 0.40, lr: [0.003793077249172651], Loss: 1.991775, Acc:0.801369, Semantic loss: 0.742606, BCE loss: 0.526593, SB loss: 0.722576
2023-10-30 17:46:43,766 Epoch: [319/484] Iter:[90/495], Time: 0.40, lr: [0.003792658866864398], Loss: 1.979709, Acc:0.800264, Semantic loss: 0.737859, BCE loss: 0.521473, SB loss: 0.720377
2023-10-30 17:46:47,457 Epoch: [319/484] Iter:[100/495], Time: 0.39, lr: [0.003792240479427938], Loss: 1.962509, Acc:0.802972, Semantic loss: 0.731128, BCE loss: 0.514684, SB loss: 0.716697
2023-10-30 17:46:51,156 Epoch: [319/484] Iter:[110/495], Time: 0.39, lr: [0.0037918220868625786], Loss: 1.970203, Acc:0.803898, Semantic loss: 0.735818, BCE loss: 0.516634, SB loss: 0.717751
2023-10-30 17:46:54,929 Epoch: [319/484] Iter:[120/495], Time: 0.39, lr: [0.0037914036891676267], Loss: 1.961196, Acc:0.802988, Semantic loss: 0.735938, BCE loss: 0.510487, SB loss: 0.714772
2023-10-30 17:46:58,535 Epoch: [319/484] Iter:[130/495], Time: 0.39, lr: [0.003790985286342391], Loss: 1.970424, Acc:0.805937, Semantic loss: 0.739301, BCE loss: 0.515839, SB loss: 0.715284
2023-10-30 17:47:02,287 Epoch: [319/484] Iter:[140/495], Time: 0.39, lr: [0.0037905668783861806], Loss: 1.970449, Acc:0.805788, Semantic loss: 0.736210, BCE loss: 0.517833, SB loss: 0.716406
2023-10-30 17:47:06,018 Epoch: [319/484] Iter:[150/495], Time: 0.39, lr: [0.003790148465298303], Loss: 1.972240, Acc:0.808315, Semantic loss: 0.736000, BCE loss: 0.519877, SB loss: 0.716363
2023-10-30 17:47:09,764 Epoch: [319/484] Iter:[160/495], Time: 0.39, lr: [0.003789730047078065], Loss: 1.965881, Acc:0.808471, Semantic loss: 0.731769, BCE loss: 0.519419, SB loss: 0.714693
2023-10-30 17:47:13,399 Epoch: [319/484] Iter:[170/495], Time: 0.38, lr: [0.0037893116237247733], Loss: 1.963773, Acc:0.807162, Semantic loss: 0.732780, BCE loss: 0.516654, SB loss: 0.714339
2023-10-30 17:47:17,092 Epoch: [319/484] Iter:[180/495], Time: 0.38, lr: [0.003788893195237737], Loss: 1.964555, Acc:0.806643, Semantic loss: 0.734129, BCE loss: 0.515621, SB loss: 0.714805
2023-10-30 17:47:20,870 Epoch: [319/484] Iter:[190/495], Time: 0.38, lr: [0.003788474761616263], Loss: 1.963690, Acc:0.806558, Semantic loss: 0.734237, BCE loss: 0.514590, SB loss: 0.714863
2023-10-30 17:47:24,644 Epoch: [319/484] Iter:[200/495], Time: 0.38, lr: [0.003788056322859657], Loss: 1.968723, Acc:0.806357, Semantic loss: 0.737549, BCE loss: 0.515484, SB loss: 0.715690
2023-10-30 17:47:28,345 Epoch: [319/484] Iter:[210/495], Time: 0.38, lr: [0.003787637878967225], Loss: 1.980389, Acc:0.805928, Semantic loss: 0.745000, BCE loss: 0.516663, SB loss: 0.718725
2023-10-30 17:47:31,989 Epoch: [319/484] Iter:[220/495], Time: 0.38, lr: [0.003787219429938276], Loss: 1.980293, Acc:0.806414, Semantic loss: 0.744913, BCE loss: 0.516886, SB loss: 0.718494
2023-10-30 17:47:35,743 Epoch: [319/484] Iter:[230/495], Time: 0.38, lr: [0.003786800975772115], Loss: 1.978775, Acc:0.804673, Semantic loss: 0.742952, BCE loss: 0.516989, SB loss: 0.718834
2023-10-30 17:47:39,571 Epoch: [319/484] Iter:[240/495], Time: 0.38, lr: [0.003786382516468048], Loss: 1.980224, Acc:0.805071, Semantic loss: 0.742815, BCE loss: 0.518581, SB loss: 0.718828
2023-10-30 17:47:43,392 Epoch: [319/484] Iter:[250/495], Time: 0.38, lr: [0.0037859640520253807], Loss: 1.977656, Acc:0.806043, Semantic loss: 0.740441, BCE loss: 0.519544, SB loss: 0.717671
2023-10-30 17:47:47,088 Epoch: [319/484] Iter:[260/495], Time: 0.38, lr: [0.0037855455824434203], Loss: 1.976682, Acc:0.803915, Semantic loss: 0.740737, BCE loss: 0.518660, SB loss: 0.717285
2023-10-30 17:47:50,924 Epoch: [319/484] Iter:[270/495], Time: 0.38, lr: [0.0037851271077214716], Loss: 1.979370, Acc:0.804229, Semantic loss: 0.740001, BCE loss: 0.522095, SB loss: 0.717274
2023-10-30 17:47:54,624 Epoch: [319/484] Iter:[280/495], Time: 0.38, lr: [0.0037847086278588395], Loss: 1.981186, Acc:0.806134, Semantic loss: 0.739639, BCE loss: 0.524732, SB loss: 0.716815
2023-10-30 17:47:58,308 Epoch: [319/484] Iter:[290/495], Time: 0.38, lr: [0.003784290142854829], Loss: 1.977587, Acc:0.806442, Semantic loss: 0.738552, BCE loss: 0.523785, SB loss: 0.715251
2023-10-30 17:48:02,001 Epoch: [319/484] Iter:[300/495], Time: 0.38, lr: [0.0037838716527087467], Loss: 1.978041, Acc:0.806510, Semantic loss: 0.738813, BCE loss: 0.523915, SB loss: 0.715313
2023-10-30 17:48:05,784 Epoch: [319/484] Iter:[310/495], Time: 0.38, lr: [0.003783453157419897], Loss: 1.980646, Acc:0.805821, Semantic loss: 0.741633, BCE loss: 0.522252, SB loss: 0.716761
2023-10-30 17:48:09,489 Epoch: [319/484] Iter:[320/495], Time: 0.38, lr: [0.0037830346569875844], Loss: 1.982864, Acc:0.805826, Semantic loss: 0.742175, BCE loss: 0.523697, SB loss: 0.716992
2023-10-30 17:48:13,164 Epoch: [319/484] Iter:[330/495], Time: 0.38, lr: [0.0037826161514111123], Loss: 1.982478, Acc:0.805823, Semantic loss: 0.742432, BCE loss: 0.524263, SB loss: 0.715784
2023-10-30 17:48:16,974 Epoch: [319/484] Iter:[340/495], Time: 0.38, lr: [0.0037821976406897874], Loss: 1.981519, Acc:0.806287, Semantic loss: 0.741201, BCE loss: 0.524851, SB loss: 0.715468
2023-10-30 17:48:20,651 Epoch: [319/484] Iter:[350/495], Time: 0.38, lr: [0.0037817791248229127], Loss: 1.979241, Acc:0.806805, Semantic loss: 0.739482, BCE loss: 0.524724, SB loss: 0.715035
2023-10-30 17:48:24,285 Epoch: [319/484] Iter:[360/495], Time: 0.38, lr: [0.0037813606038097918], Loss: 1.978008, Acc:0.805721, Semantic loss: 0.739405, BCE loss: 0.523145, SB loss: 0.715457
2023-10-30 17:48:28,034 Epoch: [319/484] Iter:[370/495], Time: 0.38, lr: [0.0037809420776497285], Loss: 1.979034, Acc:0.805311, Semantic loss: 0.740755, BCE loss: 0.522219, SB loss: 0.716061
2023-10-30 17:48:31,704 Epoch: [319/484] Iter:[380/495], Time: 0.38, lr: [0.0037805235463420272], Loss: 1.983383, Acc:0.804799, Semantic loss: 0.743971, BCE loss: 0.521482, SB loss: 0.717930
2023-10-30 17:48:35,433 Epoch: [319/484] Iter:[390/495], Time: 0.38, lr: [0.003780105009885991], Loss: 1.984054, Acc:0.803768, Semantic loss: 0.743877, BCE loss: 0.522346, SB loss: 0.717830
2023-10-30 17:48:39,155 Epoch: [319/484] Iter:[400/495], Time: 0.38, lr: [0.003779686468280924], Loss: 1.981788, Acc:0.802868, Semantic loss: 0.743317, BCE loss: 0.521667, SB loss: 0.716804
2023-10-30 17:48:42,977 Epoch: [319/484] Iter:[410/495], Time: 0.38, lr: [0.0037792679215261273], Loss: 1.981675, Acc:0.803010, Semantic loss: 0.744028, BCE loss: 0.521202, SB loss: 0.716445
2023-10-30 17:48:46,740 Epoch: [319/484] Iter:[420/495], Time: 0.38, lr: [0.0037788493696209054], Loss: 1.981162, Acc:0.803706, Semantic loss: 0.742587, BCE loss: 0.522553, SB loss: 0.716023
2023-10-30 17:48:50,480 Epoch: [319/484] Iter:[430/495], Time: 0.38, lr: [0.003778430812564561], Loss: 1.979419, Acc:0.804408, Semantic loss: 0.741425, BCE loss: 0.522398, SB loss: 0.715596
2023-10-30 17:48:54,261 Epoch: [319/484] Iter:[440/495], Time: 0.38, lr: [0.003778012250356397], Loss: 1.980687, Acc:0.803268, Semantic loss: 0.742279, BCE loss: 0.522257, SB loss: 0.716150
2023-10-30 17:48:57,970 Epoch: [319/484] Iter:[450/495], Time: 0.38, lr: [0.0037775936829957135], Loss: 1.979717, Acc:0.803033, Semantic loss: 0.741958, BCE loss: 0.521391, SB loss: 0.716368
2023-10-30 17:49:01,664 Epoch: [319/484] Iter:[460/495], Time: 0.38, lr: [0.0037771751104818158], Loss: 1.984653, Acc:0.802788, Semantic loss: 0.745002, BCE loss: 0.522161, SB loss: 0.717490
2023-10-30 17:49:05,338 Epoch: [319/484] Iter:[470/495], Time: 0.38, lr: [0.0037767565328140043], Loss: 1.985885, Acc:0.803152, Semantic loss: 0.745452, BCE loss: 0.522636, SB loss: 0.717796
2023-10-30 17:49:09,081 Epoch: [319/484] Iter:[480/495], Time: 0.38, lr: [0.0037763379499915813], Loss: 1.983469, Acc:0.802804, Semantic loss: 0.743988, BCE loss: 0.522260, SB loss: 0.717221
2023-10-30 17:49:12,618 Epoch: [319/484] Iter:[490/495], Time: 0.38, lr: [0.0037759193620138464], Loss: 1.980713, Acc:0.802384, Semantic loss: 0.742381, BCE loss: 0.521788, SB loss: 0.716543
2023-10-30 17:49:14,035 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:49:14,271 Loss: 2.046, MeanIU:  0.7084, Best_mIoU:  0.7309
2023-10-30 17:49:14,271 [0.97626085 0.81895063 0.90469467 0.37578942 0.50986017 0.59611743
 0.6726035  0.76083275 0.90406232 0.51299186 0.9316707  0.78131879
 0.57907301 0.9284152  0.58311542 0.78771442 0.61182993 0.49270294
 0.73074924]
2023-10-30 17:49:16,407 Epoch: [320/484] Iter:[0/495], Time: 2.10, lr: [0.0037757100660915205], Loss: 1.960660, Acc:0.835337, Semantic loss: 0.753241, BCE loss: 0.464827, SB loss: 0.742591
2023-10-30 17:49:20,338 Epoch: [320/484] Iter:[10/495], Time: 0.55, lr: [0.0037752914703795123], Loss: 1.941923, Acc:0.812740, Semantic loss: 0.718391, BCE loss: 0.518772, SB loss: 0.704760
2023-10-30 17:49:23,955 Epoch: [320/484] Iter:[20/495], Time: 0.46, lr: [0.0037748728695104474], Loss: 1.951435, Acc:0.793052, Semantic loss: 0.721665, BCE loss: 0.512844, SB loss: 0.716926
2023-10-30 17:49:27,602 Epoch: [320/484] Iter:[30/495], Time: 0.43, lr: [0.003774454263483626], Loss: 1.938226, Acc:0.791996, Semantic loss: 0.714875, BCE loss: 0.509817, SB loss: 0.713534
2023-10-30 17:49:31,370 Epoch: [320/484] Iter:[40/495], Time: 0.42, lr: [0.0037740356522983506], Loss: 1.944876, Acc:0.801100, Semantic loss: 0.712647, BCE loss: 0.521607, SB loss: 0.710622
2023-10-30 17:49:35,084 Epoch: [320/484] Iter:[50/495], Time: 0.41, lr: [0.003773617035953921], Loss: 1.964525, Acc:0.800139, Semantic loss: 0.725996, BCE loss: 0.527186, SB loss: 0.711343
2023-10-30 17:49:38,725 Epoch: [320/484] Iter:[60/495], Time: 0.40, lr: [0.003773198414449638], Loss: 1.973379, Acc:0.803483, Semantic loss: 0.732418, BCE loss: 0.532237, SB loss: 0.708724
2023-10-30 17:49:42,519 Epoch: [320/484] Iter:[70/495], Time: 0.40, lr: [0.0037727797877848], Loss: 1.951876, Acc:0.808353, Semantic loss: 0.721659, BCE loss: 0.529432, SB loss: 0.700786
2023-10-30 17:49:46,203 Epoch: [320/484] Iter:[80/495], Time: 0.39, lr: [0.0037723611559587105], Loss: 1.955123, Acc:0.809697, Semantic loss: 0.723115, BCE loss: 0.529896, SB loss: 0.702112
2023-10-30 17:49:49,820 Epoch: [320/484] Iter:[90/495], Time: 0.39, lr: [0.003771942518970668], Loss: 1.954091, Acc:0.811855, Semantic loss: 0.720224, BCE loss: 0.533885, SB loss: 0.699982
2023-10-30 17:49:53,650 Epoch: [320/484] Iter:[100/495], Time: 0.39, lr: [0.003771523876819972], Loss: 1.962945, Acc:0.811800, Semantic loss: 0.730585, BCE loss: 0.532884, SB loss: 0.699476
2023-10-30 17:49:57,333 Epoch: [320/484] Iter:[110/495], Time: 0.39, lr: [0.0037711052295059206], Loss: 1.960019, Acc:0.811348, Semantic loss: 0.729236, BCE loss: 0.529873, SB loss: 0.700911
2023-10-30 17:50:01,025 Epoch: [320/484] Iter:[120/495], Time: 0.39, lr: [0.003770686577027816], Loss: 1.961109, Acc:0.812013, Semantic loss: 0.729497, BCE loss: 0.530265, SB loss: 0.701348
2023-10-30 17:50:04,772 Epoch: [320/484] Iter:[130/495], Time: 0.39, lr: [0.003770267919384956], Loss: 1.951829, Acc:0.813052, Semantic loss: 0.725858, BCE loss: 0.524426, SB loss: 0.701545
2023-10-30 17:50:08,440 Epoch: [320/484] Iter:[140/495], Time: 0.38, lr: [0.0037698492565766397], Loss: 1.952316, Acc:0.813611, Semantic loss: 0.728410, BCE loss: 0.523333, SB loss: 0.700573
2023-10-30 17:50:12,169 Epoch: [320/484] Iter:[150/495], Time: 0.38, lr: [0.003769430588602165], Loss: 1.964028, Acc:0.814109, Semantic loss: 0.735152, BCE loss: 0.525788, SB loss: 0.703089
2023-10-30 17:50:15,746 Epoch: [320/484] Iter:[160/495], Time: 0.38, lr: [0.0037690119154608326], Loss: 1.966703, Acc:0.810765, Semantic loss: 0.736573, BCE loss: 0.525186, SB loss: 0.704945
2023-10-30 17:50:19,614 Epoch: [320/484] Iter:[170/495], Time: 0.38, lr: [0.0037685932371519406], Loss: 1.958483, Acc:0.811646, Semantic loss: 0.734407, BCE loss: 0.520949, SB loss: 0.703127
2023-10-30 17:50:23,304 Epoch: [320/484] Iter:[180/495], Time: 0.38, lr: [0.003768174553674786], Loss: 1.961481, Acc:0.812781, Semantic loss: 0.734531, BCE loss: 0.523163, SB loss: 0.703787
2023-10-30 17:50:27,193 Epoch: [320/484] Iter:[190/495], Time: 0.38, lr: [0.003767755865028667], Loss: 1.964172, Acc:0.812480, Semantic loss: 0.736053, BCE loss: 0.523936, SB loss: 0.704183
2023-10-30 17:50:30,905 Epoch: [320/484] Iter:[200/495], Time: 0.38, lr: [0.0037673371712128837], Loss: 1.963076, Acc:0.812989, Semantic loss: 0.736389, BCE loss: 0.524431, SB loss: 0.702256
2023-10-30 17:50:34,597 Epoch: [320/484] Iter:[210/495], Time: 0.38, lr: [0.0037669184722267314], Loss: 1.961310, Acc:0.812721, Semantic loss: 0.736184, BCE loss: 0.523038, SB loss: 0.702088
2023-10-30 17:50:38,378 Epoch: [320/484] Iter:[220/495], Time: 0.38, lr: [0.003766499768069509], Loss: 1.962595, Acc:0.812765, Semantic loss: 0.736622, BCE loss: 0.523517, SB loss: 0.702456
2023-10-30 17:50:42,089 Epoch: [320/484] Iter:[230/495], Time: 0.38, lr: [0.003766081058740513], Loss: 1.957485, Acc:0.811911, Semantic loss: 0.734933, BCE loss: 0.520259, SB loss: 0.702293
2023-10-30 17:50:45,842 Epoch: [320/484] Iter:[240/495], Time: 0.38, lr: [0.003765662344239042], Loss: 1.958259, Acc:0.810736, Semantic loss: 0.734551, BCE loss: 0.519965, SB loss: 0.703742
2023-10-30 17:50:49,486 Epoch: [320/484] Iter:[250/495], Time: 0.38, lr: [0.0037652436245643917], Loss: 1.960220, Acc:0.811948, Semantic loss: 0.734301, BCE loss: 0.521982, SB loss: 0.703937
2023-10-30 17:50:53,264 Epoch: [320/484] Iter:[260/495], Time: 0.38, lr: [0.0037648248997158604], Loss: 1.959255, Acc:0.812816, Semantic loss: 0.732640, BCE loss: 0.523120, SB loss: 0.703495
2023-10-30 17:50:57,035 Epoch: [320/484] Iter:[270/495], Time: 0.38, lr: [0.003764406169692742], Loss: 1.963424, Acc:0.811506, Semantic loss: 0.735422, BCE loss: 0.524129, SB loss: 0.703873
2023-10-30 17:51:00,740 Epoch: [320/484] Iter:[280/495], Time: 0.38, lr: [0.0037639874344943367], Loss: 1.959240, Acc:0.810540, Semantic loss: 0.732310, BCE loss: 0.522044, SB loss: 0.704887
2023-10-30 17:51:04,440 Epoch: [320/484] Iter:[290/495], Time: 0.38, lr: [0.0037635686941199383], Loss: 1.957176, Acc:0.809656, Semantic loss: 0.731469, BCE loss: 0.520943, SB loss: 0.704765
2023-10-30 17:51:08,130 Epoch: [320/484] Iter:[300/495], Time: 0.38, lr: [0.0037631499485688436], Loss: 1.964103, Acc:0.811103, Semantic loss: 0.732795, BCE loss: 0.525573, SB loss: 0.705734
2023-10-30 17:51:11,842 Epoch: [320/484] Iter:[310/495], Time: 0.38, lr: [0.003762731197840348], Loss: 1.967030, Acc:0.812010, Semantic loss: 0.733871, BCE loss: 0.526262, SB loss: 0.706896
2023-10-30 17:51:15,422 Epoch: [320/484] Iter:[320/495], Time: 0.38, lr: [0.0037623124419337486], Loss: 1.961478, Acc:0.812154, Semantic loss: 0.731346, BCE loss: 0.523989, SB loss: 0.706143
2023-10-30 17:51:19,115 Epoch: [320/484] Iter:[330/495], Time: 0.38, lr: [0.00376189368084834], Loss: 1.963369, Acc:0.812111, Semantic loss: 0.731591, BCE loss: 0.525700, SB loss: 0.706078
2023-10-30 17:51:22,796 Epoch: [320/484] Iter:[340/495], Time: 0.38, lr: [0.003761474914583418], Loss: 1.960262, Acc:0.812836, Semantic loss: 0.730348, BCE loss: 0.524409, SB loss: 0.705505
2023-10-30 17:51:26,564 Epoch: [320/484] Iter:[350/495], Time: 0.38, lr: [0.003761056143138277], Loss: 1.960866, Acc:0.811886, Semantic loss: 0.731299, BCE loss: 0.524440, SB loss: 0.705127
2023-10-30 17:51:30,273 Epoch: [320/484] Iter:[360/495], Time: 0.38, lr: [0.0037606373665122128], Loss: 1.965801, Acc:0.810908, Semantic loss: 0.734820, BCE loss: 0.524201, SB loss: 0.706779
2023-10-30 17:51:33,998 Epoch: [320/484] Iter:[370/495], Time: 0.38, lr: [0.0037602185847045205], Loss: 1.963756, Acc:0.810784, Semantic loss: 0.733485, BCE loss: 0.523825, SB loss: 0.706447
2023-10-30 17:51:37,640 Epoch: [320/484] Iter:[380/495], Time: 0.38, lr: [0.003759799797714494], Loss: 1.960313, Acc:0.810265, Semantic loss: 0.732179, BCE loss: 0.522818, SB loss: 0.705316
2023-10-30 17:51:41,343 Epoch: [320/484] Iter:[390/495], Time: 0.38, lr: [0.0037593810055414276], Loss: 1.958269, Acc:0.810999, Semantic loss: 0.730501, BCE loss: 0.523426, SB loss: 0.704341
2023-10-30 17:51:44,951 Epoch: [320/484] Iter:[400/495], Time: 0.38, lr: [0.003758962208184617], Loss: 1.958433, Acc:0.810976, Semantic loss: 0.730960, BCE loss: 0.523830, SB loss: 0.703642
2023-10-30 17:51:48,683 Epoch: [320/484] Iter:[410/495], Time: 0.38, lr: [0.003758543405643355], Loss: 1.958433, Acc:0.810203, Semantic loss: 0.731115, BCE loss: 0.523716, SB loss: 0.703602
2023-10-30 17:51:52,331 Epoch: [320/484] Iter:[420/495], Time: 0.38, lr: [0.0037581245979169367], Loss: 1.956520, Acc:0.810149, Semantic loss: 0.729825, BCE loss: 0.523243, SB loss: 0.703452
2023-10-30 17:51:56,126 Epoch: [320/484] Iter:[430/495], Time: 0.38, lr: [0.003757705785004653], Loss: 1.958668, Acc:0.810049, Semantic loss: 0.731074, BCE loss: 0.523065, SB loss: 0.704529
2023-10-30 17:51:59,739 Epoch: [320/484] Iter:[440/495], Time: 0.38, lr: [0.0037572869669058014], Loss: 1.956511, Acc:0.809666, Semantic loss: 0.730114, BCE loss: 0.522417, SB loss: 0.703980
2023-10-30 17:52:03,409 Epoch: [320/484] Iter:[450/495], Time: 0.37, lr: [0.0037568681436196735], Loss: 1.954336, Acc:0.809627, Semantic loss: 0.729300, BCE loss: 0.520725, SB loss: 0.704311
2023-10-30 17:52:06,996 Epoch: [320/484] Iter:[460/495], Time: 0.37, lr: [0.003756449315145561], Loss: 1.953527, Acc:0.809394, Semantic loss: 0.729237, BCE loss: 0.520100, SB loss: 0.704191
2023-10-30 17:52:10,721 Epoch: [320/484] Iter:[470/495], Time: 0.37, lr: [0.0037560304814827595], Loss: 1.954025, Acc:0.809055, Semantic loss: 0.729365, BCE loss: 0.520286, SB loss: 0.704374
2023-10-30 17:52:14,476 Epoch: [320/484] Iter:[480/495], Time: 0.37, lr: [0.00375561164263056], Loss: 1.954851, Acc:0.808663, Semantic loss: 0.729962, BCE loss: 0.520311, SB loss: 0.704578
2023-10-30 17:52:17,946 Epoch: [320/484] Iter:[490/495], Time: 0.37, lr: [0.0037551927985882572], Loss: 1.952882, Acc:0.807602, Semantic loss: 0.729315, BCE loss: 0.519480, SB loss: 0.704088
2023-10-30 17:55:14,804 0 [0.94021334 0.66058792 0.83238305 0.12695661 0.25496303 0.43830112
 0.4751138  0.60890452 0.88267312 0.47158649 0.85307933 0.61637541
 0.0368874  0.83066869 0.00556831 0.14320273 0.09679369 0.05913463
 0.62716091] 0.47160811096885924
2023-10-30 17:55:14,804 1 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512] 0.7055635415062349
2023-10-30 17:55:14,808 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:55:15,048 Loss: 2.010, MeanIU:  0.7056, Best_mIoU:  0.7309
2023-10-30 17:55:15,049 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512]
2023-10-30 17:55:17,216 Epoch: [321/484] Iter:[0/495], Time: 2.13, lr: [0.0037549833746205953], Loss: 2.121924, Acc:0.807035, Semantic loss: 0.700505, BCE loss: 0.772731, SB loss: 0.648687
2023-10-30 17:55:21,007 Epoch: [321/484] Iter:[10/495], Time: 0.54, lr: [0.003754564522791807], Loss: 2.009445, Acc:0.784239, Semantic loss: 0.715491, BCE loss: 0.576588, SB loss: 0.717366
2023-10-30 17:55:24,602 Epoch: [321/484] Iter:[20/495], Time: 0.45, lr: [0.003754145665771145], Loss: 1.986463, Acc:0.793891, Semantic loss: 0.728499, BCE loss: 0.551945, SB loss: 0.706019
2023-10-30 17:55:28,067 Epoch: [321/484] Iter:[30/495], Time: 0.42, lr: [0.0037537268035579027], Loss: 1.996796, Acc:0.798884, Semantic loss: 0.729130, BCE loss: 0.551526, SB loss: 0.716140
2023-10-30 17:55:31,542 Epoch: [321/484] Iter:[40/495], Time: 0.40, lr: [0.0037533079361513695], Loss: 1.994173, Acc:0.797441, Semantic loss: 0.742812, BCE loss: 0.537100, SB loss: 0.714262
2023-10-30 17:55:35,017 Epoch: [321/484] Iter:[50/495], Time: 0.39, lr: [0.0037528890635508366], Loss: 1.983679, Acc:0.792835, Semantic loss: 0.741870, BCE loss: 0.527246, SB loss: 0.714562
2023-10-30 17:55:38,572 Epoch: [321/484] Iter:[60/495], Time: 0.39, lr: [0.0037524701857555983], Loss: 1.989700, Acc:0.789031, Semantic loss: 0.749427, BCE loss: 0.522678, SB loss: 0.717594
2023-10-30 17:55:42,082 Epoch: [321/484] Iter:[70/495], Time: 0.38, lr: [0.003752051302764944], Loss: 2.002461, Acc:0.789871, Semantic loss: 0.758805, BCE loss: 0.519746, SB loss: 0.723910
2023-10-30 17:55:45,626 Epoch: [321/484] Iter:[80/495], Time: 0.38, lr: [0.003751632414578165], Loss: 2.004519, Acc:0.791094, Semantic loss: 0.757494, BCE loss: 0.522375, SB loss: 0.724650
2023-10-30 17:55:49,176 Epoch: [321/484] Iter:[90/495], Time: 0.37, lr: [0.0037512135211945513], Loss: 1.976972, Acc:0.792121, Semantic loss: 0.741520, BCE loss: 0.517596, SB loss: 0.717855
2023-10-30 17:55:52,839 Epoch: [321/484] Iter:[100/495], Time: 0.37, lr: [0.0037507946226133953], Loss: 1.962322, Acc:0.791043, Semantic loss: 0.737278, BCE loss: 0.510218, SB loss: 0.714826
2023-10-30 17:55:56,470 Epoch: [321/484] Iter:[110/495], Time: 0.37, lr: [0.003750375718833987], Loss: 1.957615, Acc:0.795060, Semantic loss: 0.733783, BCE loss: 0.513178, SB loss: 0.710654
2023-10-30 17:56:00,049 Epoch: [321/484] Iter:[120/495], Time: 0.37, lr: [0.003749956809855617], Loss: 1.956542, Acc:0.796956, Semantic loss: 0.733009, BCE loss: 0.512741, SB loss: 0.710793
2023-10-30 17:56:03,625 Epoch: [321/484] Iter:[130/495], Time: 0.37, lr: [0.003749537895677573], Loss: 1.947425, Acc:0.795289, Semantic loss: 0.731059, BCE loss: 0.506425, SB loss: 0.709941
2023-10-30 17:56:07,288 Epoch: [321/484] Iter:[140/495], Time: 0.37, lr: [0.0037491189762991484], Loss: 1.935738, Acc:0.794092, Semantic loss: 0.723905, BCE loss: 0.505039, SB loss: 0.706795
2023-10-30 17:56:10,946 Epoch: [321/484] Iter:[150/495], Time: 0.37, lr: [0.0037487000517196314], Loss: 1.938025, Acc:0.795753, Semantic loss: 0.724755, BCE loss: 0.505931, SB loss: 0.707339
2023-10-30 17:56:14,666 Epoch: [321/484] Iter:[160/495], Time: 0.37, lr: [0.003748281121938312], Loss: 1.944173, Acc:0.798667, Semantic loss: 0.725518, BCE loss: 0.509105, SB loss: 0.709549
2023-10-30 17:56:18,452 Epoch: [321/484] Iter:[170/495], Time: 0.37, lr: [0.0037478621869544777], Loss: 1.957049, Acc:0.798814, Semantic loss: 0.735068, BCE loss: 0.508796, SB loss: 0.713186
2023-10-30 17:56:22,101 Epoch: [321/484] Iter:[180/495], Time: 0.37, lr: [0.0037474432467674208], Loss: 1.958325, Acc:0.798728, Semantic loss: 0.734908, BCE loss: 0.509490, SB loss: 0.713928
2023-10-30 17:56:25,733 Epoch: [321/484] Iter:[190/495], Time: 0.37, lr: [0.0037470243013764284], Loss: 1.964118, Acc:0.797870, Semantic loss: 0.739613, BCE loss: 0.509263, SB loss: 0.715242
2023-10-30 17:56:29,362 Epoch: [321/484] Iter:[200/495], Time: 0.37, lr: [0.00374660535078079], Loss: 1.959163, Acc:0.798014, Semantic loss: 0.737883, BCE loss: 0.506738, SB loss: 0.714542
2023-10-30 17:56:33,073 Epoch: [321/484] Iter:[210/495], Time: 0.37, lr: [0.003746186394979793], Loss: 1.962638, Acc:0.799921, Semantic loss: 0.738592, BCE loss: 0.509685, SB loss: 0.714361
2023-10-30 17:56:36,729 Epoch: [321/484] Iter:[220/495], Time: 0.37, lr: [0.003745767433972728], Loss: 1.963084, Acc:0.801332, Semantic loss: 0.737170, BCE loss: 0.512202, SB loss: 0.713712
2023-10-30 17:56:40,514 Epoch: [321/484] Iter:[230/495], Time: 0.37, lr: [0.0037453484677588827], Loss: 1.961295, Acc:0.801317, Semantic loss: 0.735438, BCE loss: 0.512461, SB loss: 0.713395
2023-10-30 17:56:44,139 Epoch: [321/484] Iter:[240/495], Time: 0.37, lr: [0.0037449294963375446], Loss: 1.962142, Acc:0.800858, Semantic loss: 0.737055, BCE loss: 0.510645, SB loss: 0.714442
2023-10-30 17:56:47,921 Epoch: [321/484] Iter:[250/495], Time: 0.37, lr: [0.0037445105197080005], Loss: 1.957959, Acc:0.801262, Semantic loss: 0.735763, BCE loss: 0.508783, SB loss: 0.713414
2023-10-30 17:56:51,561 Epoch: [321/484] Iter:[260/495], Time: 0.37, lr: [0.0037440915378695407], Loss: 1.959143, Acc:0.802779, Semantic loss: 0.736449, BCE loss: 0.509770, SB loss: 0.712924
2023-10-30 17:56:55,125 Epoch: [321/484] Iter:[270/495], Time: 0.37, lr: [0.0037436725508214514], Loss: 1.958272, Acc:0.802030, Semantic loss: 0.735756, BCE loss: 0.509920, SB loss: 0.712596
2023-10-30 17:56:58,788 Epoch: [321/484] Iter:[280/495], Time: 0.37, lr: [0.003743253558563019], Loss: 1.956667, Acc:0.803365, Semantic loss: 0.735090, BCE loss: 0.509812, SB loss: 0.711764
2023-10-30 17:57:02,577 Epoch: [321/484] Iter:[290/495], Time: 0.37, lr: [0.003742834561093533], Loss: 1.958773, Acc:0.804394, Semantic loss: 0.736850, BCE loss: 0.510156, SB loss: 0.711767
2023-10-30 17:57:06,306 Epoch: [321/484] Iter:[300/495], Time: 0.37, lr: [0.0037424155584122793], Loss: 1.960077, Acc:0.804886, Semantic loss: 0.738277, BCE loss: 0.510541, SB loss: 0.711259
2023-10-30 17:57:09,921 Epoch: [321/484] Iter:[310/495], Time: 0.37, lr: [0.0037419965505185444], Loss: 1.955206, Acc:0.804438, Semantic loss: 0.737055, BCE loss: 0.507937, SB loss: 0.710214
2023-10-30 17:57:13,609 Epoch: [321/484] Iter:[320/495], Time: 0.37, lr: [0.0037415775374116133], Loss: 1.957893, Acc:0.803586, Semantic loss: 0.737188, BCE loss: 0.509324, SB loss: 0.711381
2023-10-30 17:57:17,240 Epoch: [321/484] Iter:[330/495], Time: 0.37, lr: [0.003741158519090776], Loss: 1.960709, Acc:0.803520, Semantic loss: 0.739200, BCE loss: 0.508812, SB loss: 0.712697
2023-10-30 17:57:20,976 Epoch: [321/484] Iter:[340/495], Time: 0.37, lr: [0.003740739495555317], Loss: 1.959411, Acc:0.802603, Semantic loss: 0.737414, BCE loss: 0.509344, SB loss: 0.712653
2023-10-30 17:57:24,685 Epoch: [321/484] Iter:[350/495], Time: 0.37, lr: [0.0037403204668045222], Loss: 1.960569, Acc:0.803899, Semantic loss: 0.736743, BCE loss: 0.510964, SB loss: 0.712862
2023-10-30 17:57:28,303 Epoch: [321/484] Iter:[360/495], Time: 0.37, lr: [0.0037399014328376766], Loss: 1.961876, Acc:0.804123, Semantic loss: 0.737627, BCE loss: 0.510835, SB loss: 0.713414
2023-10-30 17:57:32,079 Epoch: [321/484] Iter:[370/495], Time: 0.37, lr: [0.003739482393654068], Loss: 1.958328, Acc:0.804429, Semantic loss: 0.735257, BCE loss: 0.510010, SB loss: 0.713060
2023-10-30 17:57:35,744 Epoch: [321/484] Iter:[380/495], Time: 0.37, lr: [0.0037390633492529806], Loss: 1.963914, Acc:0.803883, Semantic loss: 0.737518, BCE loss: 0.512702, SB loss: 0.713694
2023-10-30 17:57:39,528 Epoch: [321/484] Iter:[390/495], Time: 0.37, lr: [0.0037386442996337], Loss: 1.959054, Acc:0.803497, Semantic loss: 0.735693, BCE loss: 0.511123, SB loss: 0.712238
2023-10-30 17:57:43,258 Epoch: [321/484] Iter:[400/495], Time: 0.37, lr: [0.0037382252447955102], Loss: 1.960700, Acc:0.803915, Semantic loss: 0.737198, BCE loss: 0.511308, SB loss: 0.712194
2023-10-30 17:57:47,020 Epoch: [321/484] Iter:[410/495], Time: 0.37, lr: [0.003737806184737698], Loss: 1.959012, Acc:0.803336, Semantic loss: 0.735564, BCE loss: 0.511659, SB loss: 0.711789
2023-10-30 17:57:50,711 Epoch: [321/484] Iter:[420/495], Time: 0.37, lr: [0.0037373871194595477], Loss: 1.962450, Acc:0.803328, Semantic loss: 0.736470, BCE loss: 0.514116, SB loss: 0.711864
2023-10-30 17:57:54,417 Epoch: [321/484] Iter:[430/495], Time: 0.37, lr: [0.0037369680489603434], Loss: 1.958450, Acc:0.802770, Semantic loss: 0.734807, BCE loss: 0.512530, SB loss: 0.711114
2023-10-30 17:57:58,151 Epoch: [321/484] Iter:[440/495], Time: 0.37, lr: [0.0037365489732393686], Loss: 1.957341, Acc:0.802221, Semantic loss: 0.734327, BCE loss: 0.511619, SB loss: 0.711395
2023-10-30 17:58:01,828 Epoch: [321/484] Iter:[450/495], Time: 0.37, lr: [0.00373612989229591], Loss: 1.957637, Acc:0.802096, Semantic loss: 0.734659, BCE loss: 0.511927, SB loss: 0.711051
2023-10-30 17:58:05,478 Epoch: [321/484] Iter:[460/495], Time: 0.37, lr: [0.0037357108061292494], Loss: 1.956390, Acc:0.802077, Semantic loss: 0.734368, BCE loss: 0.511375, SB loss: 0.710646
2023-10-30 17:58:09,056 Epoch: [321/484] Iter:[470/495], Time: 0.37, lr: [0.003735291714738672], Loss: 1.955877, Acc:0.801178, Semantic loss: 0.735017, BCE loss: 0.510641, SB loss: 0.710219
2023-10-30 17:58:12,705 Epoch: [321/484] Iter:[480/495], Time: 0.37, lr: [0.003734872618123459], Loss: 1.954400, Acc:0.800548, Semantic loss: 0.734758, BCE loss: 0.509998, SB loss: 0.709644
2023-10-30 17:58:16,181 Epoch: [321/484] Iter:[490/495], Time: 0.37, lr: [0.003734453516282896], Loss: 1.953728, Acc:0.801020, Semantic loss: 0.734869, BCE loss: 0.509593, SB loss: 0.709266
2023-10-30 17:58:17,564 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 17:58:17,840 Loss: 2.010, MeanIU:  0.7056, Best_mIoU:  0.7309
2023-10-30 17:58:17,840 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512]
2023-10-30 17:58:19,967 Epoch: [322/484] Iter:[0/495], Time: 2.09, lr: [0.003734243963402885], Loss: 2.125727, Acc:0.917666, Semantic loss: 0.759854, BCE loss: 0.663653, SB loss: 0.702219
2023-10-30 17:58:23,989 Epoch: [322/484] Iter:[10/495], Time: 0.56, lr: [0.0037338248537229536], Loss: 1.971196, Acc:0.799387, Semantic loss: 0.750224, BCE loss: 0.508711, SB loss: 0.712262
2023-10-30 17:58:27,567 Epoch: [322/484] Iter:[20/495], Time: 0.46, lr: [0.003733405738815879], Loss: 1.967684, Acc:0.794385, Semantic loss: 0.742140, BCE loss: 0.521332, SB loss: 0.704211
2023-10-30 17:58:31,297 Epoch: [322/484] Iter:[30/495], Time: 0.43, lr: [0.003732986618680944], Loss: 1.961350, Acc:0.793728, Semantic loss: 0.745108, BCE loss: 0.509711, SB loss: 0.706531
2023-10-30 17:58:35,018 Epoch: [322/484] Iter:[40/495], Time: 0.42, lr: [0.0037325674933174325], Loss: 1.929371, Acc:0.802141, Semantic loss: 0.733276, BCE loss: 0.501911, SB loss: 0.694183
2023-10-30 17:58:38,694 Epoch: [322/484] Iter:[50/495], Time: 0.41, lr: [0.0037321483627246266], Loss: 1.933032, Acc:0.813164, Semantic loss: 0.729877, BCE loss: 0.507090, SB loss: 0.696065
2023-10-30 17:58:42,414 Epoch: [322/484] Iter:[60/495], Time: 0.40, lr: [0.0037317292269018077], Loss: 1.973797, Acc:0.808708, Semantic loss: 0.748866, BCE loss: 0.517216, SB loss: 0.707714
2023-10-30 17:58:46,138 Epoch: [322/484] Iter:[70/495], Time: 0.40, lr: [0.003731310085848257], Loss: 1.960332, Acc:0.809216, Semantic loss: 0.737863, BCE loss: 0.517465, SB loss: 0.705004
2023-10-30 17:58:49,784 Epoch: [322/484] Iter:[80/495], Time: 0.39, lr: [0.0037308909395632594], Loss: 1.998180, Acc:0.805839, Semantic loss: 0.763794, BCE loss: 0.525533, SB loss: 0.708853
2023-10-30 17:58:53,544 Epoch: [322/484] Iter:[90/495], Time: 0.39, lr: [0.003730471788046094], Loss: 1.978839, Acc:0.805094, Semantic loss: 0.754301, BCE loss: 0.519336, SB loss: 0.705203
2023-10-30 17:58:57,204 Epoch: [322/484] Iter:[100/495], Time: 0.39, lr: [0.003730052631296044], Loss: 1.993723, Acc:0.803912, Semantic loss: 0.759477, BCE loss: 0.523146, SB loss: 0.711101
2023-10-30 17:59:00,904 Epoch: [322/484] Iter:[110/495], Time: 0.39, lr: [0.003729633469312388], Loss: 2.005730, Acc:0.803345, Semantic loss: 0.761643, BCE loss: 0.530297, SB loss: 0.713791
2023-10-30 17:59:04,612 Epoch: [322/484] Iter:[120/495], Time: 0.39, lr: [0.0037292143020944096], Loss: 2.003164, Acc:0.803333, Semantic loss: 0.761805, BCE loss: 0.526507, SB loss: 0.714852
2023-10-30 17:59:08,354 Epoch: [322/484] Iter:[130/495], Time: 0.39, lr: [0.0037287951296413892], Loss: 1.996201, Acc:0.805037, Semantic loss: 0.759209, BCE loss: 0.523613, SB loss: 0.713378
2023-10-30 17:59:11,947 Epoch: [322/484] Iter:[140/495], Time: 0.38, lr: [0.003728375951952606], Loss: 1.989900, Acc:0.807861, Semantic loss: 0.759054, BCE loss: 0.517738, SB loss: 0.713108
2023-10-30 17:59:15,619 Epoch: [322/484] Iter:[150/495], Time: 0.38, lr: [0.003727956769027343], Loss: 1.976590, Acc:0.810490, Semantic loss: 0.753721, BCE loss: 0.512628, SB loss: 0.710241
2023-10-30 17:59:19,297 Epoch: [322/484] Iter:[160/495], Time: 0.38, lr: [0.003727537580864879], Loss: 1.976269, Acc:0.809962, Semantic loss: 0.752412, BCE loss: 0.513761, SB loss: 0.710097
2023-10-30 17:59:23,044 Epoch: [322/484] Iter:[170/495], Time: 0.38, lr: [0.0037271183874644956], Loss: 1.982898, Acc:0.807686, Semantic loss: 0.757578, BCE loss: 0.512953, SB loss: 0.712367
2023-10-30 17:59:26,776 Epoch: [322/484] Iter:[180/495], Time: 0.38, lr: [0.003726699188825469], Loss: 1.985934, Acc:0.808766, Semantic loss: 0.758126, BCE loss: 0.514626, SB loss: 0.713183
2023-10-30 17:59:30,478 Epoch: [322/484] Iter:[190/495], Time: 0.38, lr: [0.0037262799849470834], Loss: 1.981098, Acc:0.808466, Semantic loss: 0.753752, BCE loss: 0.515644, SB loss: 0.711702
2023-10-30 17:59:34,130 Epoch: [322/484] Iter:[200/495], Time: 0.38, lr: [0.0037258607758286167], Loss: 1.982471, Acc:0.806045, Semantic loss: 0.754734, BCE loss: 0.514844, SB loss: 0.712892
2023-10-30 17:59:37,750 Epoch: [322/484] Iter:[210/495], Time: 0.38, lr: [0.0037254415614693475], Loss: 1.980892, Acc:0.804950, Semantic loss: 0.754840, BCE loss: 0.512847, SB loss: 0.713205
2023-10-30 17:59:41,440 Epoch: [322/484] Iter:[220/495], Time: 0.38, lr: [0.0037250223418685553], Loss: 1.980753, Acc:0.804954, Semantic loss: 0.754821, BCE loss: 0.511118, SB loss: 0.714814
2023-10-30 17:59:45,223 Epoch: [322/484] Iter:[230/495], Time: 0.38, lr: [0.0037246031170255203], Loss: 1.981619, Acc:0.803867, Semantic loss: 0.754665, BCE loss: 0.511994, SB loss: 0.714960
2023-10-30 17:59:48,968 Epoch: [322/484] Iter:[240/495], Time: 0.38, lr: [0.00372418388693952], Loss: 1.984415, Acc:0.805572, Semantic loss: 0.756244, BCE loss: 0.512028, SB loss: 0.716142
2023-10-30 17:59:52,756 Epoch: [322/484] Iter:[250/495], Time: 0.38, lr: [0.003723764651609834], Loss: 1.985643, Acc:0.806315, Semantic loss: 0.755739, BCE loss: 0.513859, SB loss: 0.716045
2023-10-30 17:59:56,546 Epoch: [322/484] Iter:[260/495], Time: 0.38, lr: [0.003723345411035739], Loss: 1.982482, Acc:0.807232, Semantic loss: 0.753115, BCE loss: 0.514259, SB loss: 0.715108
2023-10-30 18:00:00,143 Epoch: [322/484] Iter:[270/495], Time: 0.38, lr: [0.003722926165216516], Loss: 1.983098, Acc:0.808444, Semantic loss: 0.752056, BCE loss: 0.516072, SB loss: 0.714970
2023-10-30 18:00:03,798 Epoch: [322/484] Iter:[280/495], Time: 0.38, lr: [0.003722506914151441], Loss: 1.976864, Acc:0.808119, Semantic loss: 0.749386, BCE loss: 0.513707, SB loss: 0.713771
2023-10-30 18:00:07,457 Epoch: [322/484] Iter:[290/495], Time: 0.38, lr: [0.0037220876578397933], Loss: 1.983819, Acc:0.807826, Semantic loss: 0.751546, BCE loss: 0.516806, SB loss: 0.715467
2023-10-30 18:00:11,302 Epoch: [322/484] Iter:[300/495], Time: 0.38, lr: [0.003721668396280848], Loss: 1.982711, Acc:0.807461, Semantic loss: 0.752387, BCE loss: 0.515691, SB loss: 0.714633
2023-10-30 18:00:15,029 Epoch: [322/484] Iter:[310/495], Time: 0.38, lr: [0.003721249129473886], Loss: 1.980539, Acc:0.807824, Semantic loss: 0.750829, BCE loss: 0.516079, SB loss: 0.713632
2023-10-30 18:00:18,733 Epoch: [322/484] Iter:[320/495], Time: 0.38, lr: [0.0037208298574181826], Loss: 1.982187, Acc:0.808208, Semantic loss: 0.751148, BCE loss: 0.516686, SB loss: 0.714353
2023-10-30 18:00:22,417 Epoch: [322/484] Iter:[330/495], Time: 0.38, lr: [0.003720410580113015], Loss: 1.990795, Acc:0.808590, Semantic loss: 0.756417, BCE loss: 0.519147, SB loss: 0.715231
2023-10-30 18:00:26,131 Epoch: [322/484] Iter:[340/495], Time: 0.38, lr: [0.00371999129755766], Loss: 1.991847, Acc:0.808403, Semantic loss: 0.755966, BCE loss: 0.519544, SB loss: 0.716338
2023-10-30 18:00:29,807 Epoch: [322/484] Iter:[350/495], Time: 0.38, lr: [0.003719572009751395], Loss: 1.986512, Acc:0.807028, Semantic loss: 0.751577, BCE loss: 0.519419, SB loss: 0.715515
2023-10-30 18:00:33,565 Epoch: [322/484] Iter:[360/495], Time: 0.38, lr: [0.0037191527166934974], Loss: 1.987944, Acc:0.806963, Semantic loss: 0.751896, BCE loss: 0.519340, SB loss: 0.716708
2023-10-30 18:00:37,283 Epoch: [322/484] Iter:[370/495], Time: 0.38, lr: [0.003718733418383242], Loss: 1.989291, Acc:0.807267, Semantic loss: 0.751574, BCE loss: 0.520332, SB loss: 0.717384
2023-10-30 18:00:41,012 Epoch: [322/484] Iter:[380/495], Time: 0.38, lr: [0.003718314114819904], Loss: 1.990724, Acc:0.807591, Semantic loss: 0.751653, BCE loss: 0.521831, SB loss: 0.717239
2023-10-30 18:00:44,744 Epoch: [322/484] Iter:[390/495], Time: 0.38, lr: [0.003717894806002762], Loss: 1.988188, Acc:0.808393, Semantic loss: 0.750826, BCE loss: 0.520006, SB loss: 0.717355
2023-10-30 18:00:48,386 Epoch: [322/484] Iter:[400/495], Time: 0.38, lr: [0.003717475491931091], Loss: 1.988441, Acc:0.808301, Semantic loss: 0.750975, BCE loss: 0.519769, SB loss: 0.717697
2023-10-30 18:00:52,094 Epoch: [322/484] Iter:[410/495], Time: 0.38, lr: [0.0037170561726041665], Loss: 1.989822, Acc:0.808556, Semantic loss: 0.750911, BCE loss: 0.521261, SB loss: 0.717650
2023-10-30 18:00:55,851 Epoch: [322/484] Iter:[420/495], Time: 0.38, lr: [0.003716636848021262], Loss: 1.988822, Acc:0.808146, Semantic loss: 0.750665, BCE loss: 0.520913, SB loss: 0.717243
2023-10-30 18:00:59,618 Epoch: [322/484] Iter:[430/495], Time: 0.38, lr: [0.0037162175181816555], Loss: 1.989752, Acc:0.808541, Semantic loss: 0.751236, BCE loss: 0.521118, SB loss: 0.717398
2023-10-30 18:01:03,277 Epoch: [322/484] Iter:[440/495], Time: 0.38, lr: [0.0037157981830846206], Loss: 1.988740, Acc:0.809399, Semantic loss: 0.750019, BCE loss: 0.521842, SB loss: 0.716879
2023-10-30 18:01:06,975 Epoch: [322/484] Iter:[450/495], Time: 0.37, lr: [0.0037153788427294328], Loss: 1.985361, Acc:0.808667, Semantic loss: 0.748083, BCE loss: 0.521146, SB loss: 0.716132
2023-10-30 18:01:10,662 Epoch: [322/484] Iter:[460/495], Time: 0.37, lr: [0.003714959497115365], Loss: 1.988143, Acc:0.808916, Semantic loss: 0.749957, BCE loss: 0.521553, SB loss: 0.716633
2023-10-30 18:01:14,371 Epoch: [322/484] Iter:[470/495], Time: 0.37, lr: [0.003714540146241694], Loss: 1.989488, Acc:0.808928, Semantic loss: 0.751478, BCE loss: 0.521046, SB loss: 0.716964
2023-10-30 18:01:18,182 Epoch: [322/484] Iter:[480/495], Time: 0.37, lr: [0.003714120790107693], Loss: 1.988823, Acc:0.809425, Semantic loss: 0.750381, BCE loss: 0.521891, SB loss: 0.716551
2023-10-30 18:01:21,707 Epoch: [322/484] Iter:[490/495], Time: 0.37, lr: [0.0037137014287126364], Loss: 1.988248, Acc:0.809145, Semantic loss: 0.750291, BCE loss: 0.521783, SB loss: 0.716174
2023-10-30 18:01:23,106 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:01:23,345 Loss: 2.010, MeanIU:  0.7056, Best_mIoU:  0.7309
2023-10-30 18:01:23,345 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512]
2023-10-30 18:01:25,367 Epoch: [323/484] Iter:[0/495], Time: 1.99, lr: [0.0037134917460419836], Loss: 2.248281, Acc:0.673988, Semantic loss: 0.880932, BCE loss: 0.518876, SB loss: 0.848472
2023-10-30 18:01:29,424 Epoch: [323/484] Iter:[10/495], Time: 0.55, lr: [0.003713072376753982], Loss: 2.045986, Acc:0.748008, Semantic loss: 0.806562, BCE loss: 0.520876, SB loss: 0.718547
2023-10-30 18:01:33,135 Epoch: [323/484] Iter:[20/495], Time: 0.46, lr: [0.003712653002203108], Loss: 1.994630, Acc:0.759093, Semantic loss: 0.766997, BCE loss: 0.513908, SB loss: 0.713725
2023-10-30 18:01:36,869 Epoch: [323/484] Iter:[30/495], Time: 0.44, lr: [0.003712233622388636], Loss: 1.978903, Acc:0.780450, Semantic loss: 0.743533, BCE loss: 0.516421, SB loss: 0.718949
2023-10-30 18:01:40,426 Epoch: [323/484] Iter:[40/495], Time: 0.42, lr: [0.0037118142373098384], Loss: 1.992763, Acc:0.789688, Semantic loss: 0.751475, BCE loss: 0.517308, SB loss: 0.723980
2023-10-30 18:01:44,085 Epoch: [323/484] Iter:[50/495], Time: 0.41, lr: [0.0037113948469659898], Loss: 1.967993, Acc:0.793921, Semantic loss: 0.738802, BCE loss: 0.510906, SB loss: 0.718285
2023-10-30 18:01:47,791 Epoch: [323/484] Iter:[60/495], Time: 0.40, lr: [0.0037109754513563616], Loss: 1.977903, Acc:0.790139, Semantic loss: 0.744940, BCE loss: 0.510941, SB loss: 0.722023
2023-10-30 18:01:51,487 Epoch: [323/484] Iter:[70/495], Time: 0.40, lr: [0.003710556050480227], Loss: 2.011813, Acc:0.793525, Semantic loss: 0.758339, BCE loss: 0.522273, SB loss: 0.731201
2023-10-30 18:01:55,284 Epoch: [323/484] Iter:[80/495], Time: 0.39, lr: [0.003710136644336858], Loss: 1.997422, Acc:0.793133, Semantic loss: 0.752027, BCE loss: 0.516770, SB loss: 0.728624
2023-10-30 18:01:59,031 Epoch: [323/484] Iter:[90/495], Time: 0.39, lr: [0.0037097172329255274], Loss: 1.987472, Acc:0.796206, Semantic loss: 0.743314, BCE loss: 0.521559, SB loss: 0.722599
2023-10-30 18:02:02,729 Epoch: [323/484] Iter:[100/495], Time: 0.39, lr: [0.0037092978162455077], Loss: 1.983802, Acc:0.796083, Semantic loss: 0.742023, BCE loss: 0.520308, SB loss: 0.721471
2023-10-30 18:02:06,439 Epoch: [323/484] Iter:[110/495], Time: 0.39, lr: [0.00370887839429607], Loss: 1.978817, Acc:0.799276, Semantic loss: 0.740944, BCE loss: 0.519133, SB loss: 0.718740
2023-10-30 18:02:10,138 Epoch: [323/484] Iter:[120/495], Time: 0.39, lr: [0.0037084589670764844], Loss: 1.979772, Acc:0.799106, Semantic loss: 0.740270, BCE loss: 0.522019, SB loss: 0.717482
2023-10-30 18:02:13,854 Epoch: [323/484] Iter:[130/495], Time: 0.39, lr: [0.003708039534586026], Loss: 1.989172, Acc:0.800735, Semantic loss: 0.747202, BCE loss: 0.526095, SB loss: 0.715874
2023-10-30 18:02:17,478 Epoch: [323/484] Iter:[140/495], Time: 0.38, lr: [0.0037076200968239634], Loss: 1.982002, Acc:0.802163, Semantic loss: 0.743428, BCE loss: 0.525325, SB loss: 0.713249
2023-10-30 18:02:21,228 Epoch: [323/484] Iter:[150/495], Time: 0.38, lr: [0.0037072006537895684], Loss: 1.978225, Acc:0.800283, Semantic loss: 0.744745, BCE loss: 0.522054, SB loss: 0.711426
2023-10-30 18:02:24,995 Epoch: [323/484] Iter:[160/495], Time: 0.38, lr: [0.0037067812054821115], Loss: 1.970949, Acc:0.801298, Semantic loss: 0.739287, BCE loss: 0.521266, SB loss: 0.710396
2023-10-30 18:02:28,677 Epoch: [323/484] Iter:[170/495], Time: 0.38, lr: [0.0037063617519008654], Loss: 1.977791, Acc:0.802744, Semantic loss: 0.741316, BCE loss: 0.523744, SB loss: 0.712732
2023-10-30 18:02:32,348 Epoch: [323/484] Iter:[180/495], Time: 0.38, lr: [0.003705942293045098], Loss: 1.981812, Acc:0.803198, Semantic loss: 0.743182, BCE loss: 0.524795, SB loss: 0.713836
2023-10-30 18:02:36,100 Epoch: [323/484] Iter:[190/495], Time: 0.38, lr: [0.003705522828914081], Loss: 1.982896, Acc:0.802530, Semantic loss: 0.741897, BCE loss: 0.527082, SB loss: 0.713917
2023-10-30 18:02:39,814 Epoch: [323/484] Iter:[200/495], Time: 0.38, lr: [0.0037051033595070838], Loss: 1.987459, Acc:0.804396, Semantic loss: 0.743626, BCE loss: 0.528974, SB loss: 0.714859
2023-10-30 18:02:43,503 Epoch: [323/484] Iter:[210/495], Time: 0.38, lr: [0.003704683884823377], Loss: 2.000815, Acc:0.803480, Semantic loss: 0.752159, BCE loss: 0.531151, SB loss: 0.717505
2023-10-30 18:02:47,178 Epoch: [323/484] Iter:[220/495], Time: 0.38, lr: [0.003704264404862231], Loss: 2.002467, Acc:0.804283, Semantic loss: 0.753504, BCE loss: 0.531345, SB loss: 0.717617
2023-10-30 18:02:50,832 Epoch: [323/484] Iter:[230/495], Time: 0.38, lr: [0.003703844919622914], Loss: 2.008499, Acc:0.801816, Semantic loss: 0.757553, BCE loss: 0.532375, SB loss: 0.718571
2023-10-30 18:02:54,721 Epoch: [323/484] Iter:[240/495], Time: 0.38, lr: [0.0037034254291046947], Loss: 2.002816, Acc:0.801324, Semantic loss: 0.755703, BCE loss: 0.530002, SB loss: 0.717111
2023-10-30 18:02:58,467 Epoch: [323/484] Iter:[250/495], Time: 0.38, lr: [0.0037030059333068442], Loss: 2.002848, Acc:0.801135, Semantic loss: 0.753974, BCE loss: 0.531743, SB loss: 0.717132
2023-10-30 18:03:02,306 Epoch: [323/484] Iter:[260/495], Time: 0.38, lr: [0.0037025864322286313], Loss: 2.001418, Acc:0.801417, Semantic loss: 0.754368, BCE loss: 0.529072, SB loss: 0.717978
2023-10-30 18:03:06,069 Epoch: [323/484] Iter:[270/495], Time: 0.38, lr: [0.003702166925869324], Loss: 2.002045, Acc:0.801660, Semantic loss: 0.756355, BCE loss: 0.527457, SB loss: 0.718234
2023-10-30 18:03:09,805 Epoch: [323/484] Iter:[280/495], Time: 0.38, lr: [0.00370174741422819], Loss: 2.003225, Acc:0.802748, Semantic loss: 0.755219, BCE loss: 0.528705, SB loss: 0.719302
2023-10-30 18:03:13,428 Epoch: [323/484] Iter:[290/495], Time: 0.38, lr: [0.0037013278973045], Loss: 1.998369, Acc:0.802755, Semantic loss: 0.753017, BCE loss: 0.527236, SB loss: 0.718116
2023-10-30 18:03:17,130 Epoch: [323/484] Iter:[300/495], Time: 0.38, lr: [0.0037009083750975205], Loss: 1.994944, Acc:0.802308, Semantic loss: 0.752267, BCE loss: 0.525016, SB loss: 0.717661
2023-10-30 18:03:20,897 Epoch: [323/484] Iter:[310/495], Time: 0.38, lr: [0.00370048884760652], Loss: 1.991743, Acc:0.802104, Semantic loss: 0.751325, BCE loss: 0.523449, SB loss: 0.716968
2023-10-30 18:03:24,550 Epoch: [323/484] Iter:[320/495], Time: 0.38, lr: [0.003700069314830766], Loss: 1.991712, Acc:0.801615, Semantic loss: 0.750454, BCE loss: 0.525005, SB loss: 0.716253
2023-10-30 18:03:28,256 Epoch: [323/484] Iter:[330/495], Time: 0.38, lr: [0.0036996497767695265], Loss: 1.996602, Acc:0.801445, Semantic loss: 0.754101, BCE loss: 0.525017, SB loss: 0.717484
2023-10-30 18:03:31,974 Epoch: [323/484] Iter:[340/495], Time: 0.38, lr: [0.0036992302334220694], Loss: 1.992567, Acc:0.802148, Semantic loss: 0.752794, BCE loss: 0.523152, SB loss: 0.716621
2023-10-30 18:03:35,693 Epoch: [323/484] Iter:[350/495], Time: 0.38, lr: [0.0036988106847876613], Loss: 1.993070, Acc:0.802276, Semantic loss: 0.752675, BCE loss: 0.523909, SB loss: 0.716486
2023-10-30 18:03:39,351 Epoch: [323/484] Iter:[360/495], Time: 0.38, lr: [0.0036983911308655676], Loss: 1.995923, Acc:0.802939, Semantic loss: 0.755766, BCE loss: 0.523331, SB loss: 0.716826
2023-10-30 18:03:43,070 Epoch: [323/484] Iter:[370/495], Time: 0.38, lr: [0.0036979715716550588], Loss: 1.996349, Acc:0.802476, Semantic loss: 0.755422, BCE loss: 0.524063, SB loss: 0.716863
2023-10-30 18:03:46,806 Epoch: [323/484] Iter:[380/495], Time: 0.38, lr: [0.0036975520071553993], Loss: 1.996411, Acc:0.802939, Semantic loss: 0.755145, BCE loss: 0.524446, SB loss: 0.716821
2023-10-30 18:03:50,551 Epoch: [323/484] Iter:[390/495], Time: 0.38, lr: [0.0036971324373658554], Loss: 1.994624, Acc:0.802436, Semantic loss: 0.754512, BCE loss: 0.523552, SB loss: 0.716560
2023-10-30 18:03:54,255 Epoch: [323/484] Iter:[400/495], Time: 0.38, lr: [0.0036967128622856934], Loss: 1.999079, Acc:0.801741, Semantic loss: 0.755530, BCE loss: 0.526026, SB loss: 0.717523
2023-10-30 18:03:58,025 Epoch: [323/484] Iter:[410/495], Time: 0.38, lr: [0.00369629328191418], Loss: 2.001448, Acc:0.801720, Semantic loss: 0.756112, BCE loss: 0.527427, SB loss: 0.717909
2023-10-30 18:04:01,691 Epoch: [323/484] Iter:[420/495], Time: 0.38, lr: [0.0036958736962505816], Loss: 2.004706, Acc:0.801729, Semantic loss: 0.757882, BCE loss: 0.528885, SB loss: 0.717939
2023-10-30 18:04:05,399 Epoch: [323/484] Iter:[430/495], Time: 0.38, lr: [0.003695454105294163], Loss: 2.006151, Acc:0.801890, Semantic loss: 0.758039, BCE loss: 0.530164, SB loss: 0.717948
2023-10-30 18:04:09,017 Epoch: [323/484] Iter:[440/495], Time: 0.38, lr: [0.0036950345090441886], Loss: 2.005748, Acc:0.801668, Semantic loss: 0.758284, BCE loss: 0.529569, SB loss: 0.717896
2023-10-30 18:04:12,718 Epoch: [323/484] Iter:[450/495], Time: 0.38, lr: [0.0036946149074999256], Loss: 2.008129, Acc:0.801153, Semantic loss: 0.759974, BCE loss: 0.529772, SB loss: 0.718383
2023-10-30 18:04:16,460 Epoch: [323/484] Iter:[460/495], Time: 0.38, lr: [0.0036941953006606396], Loss: 2.007091, Acc:0.800359, Semantic loss: 0.759576, BCE loss: 0.528232, SB loss: 0.719283
2023-10-30 18:04:20,209 Epoch: [323/484] Iter:[470/495], Time: 0.38, lr: [0.003693775688525593], Loss: 2.006057, Acc:0.800208, Semantic loss: 0.758717, BCE loss: 0.527697, SB loss: 0.719643
2023-10-30 18:04:23,830 Epoch: [323/484] Iter:[480/495], Time: 0.38, lr: [0.0036933560710940513], Loss: 2.007347, Acc:0.800495, Semantic loss: 0.759353, BCE loss: 0.527902, SB loss: 0.720092
2023-10-30 18:04:27,311 Epoch: [323/484] Iter:[490/495], Time: 0.37, lr: [0.0036929364483652806], Loss: 2.008706, Acc:0.800594, Semantic loss: 0.760152, BCE loss: 0.528193, SB loss: 0.720361
2023-10-30 18:04:28,723 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:04:28,962 Loss: 2.010, MeanIU:  0.7056, Best_mIoU:  0.7309
2023-10-30 18:04:28,962 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512]
2023-10-30 18:04:31,020 Epoch: [324/484] Iter:[0/495], Time: 2.02, lr: [0.0036927266350142043], Loss: 1.958819, Acc:0.798428, Semantic loss: 0.754566, BCE loss: 0.492950, SB loss: 0.711303
2023-10-30 18:04:34,939 Epoch: [324/484] Iter:[10/495], Time: 0.54, lr: [0.0036923070043382083], Loss: 2.037745, Acc:0.803488, Semantic loss: 0.783701, BCE loss: 0.535457, SB loss: 0.718587
2023-10-30 18:04:38,654 Epoch: [324/484] Iter:[20/495], Time: 0.46, lr: [0.0036918873683631425], Loss: 1.988934, Acc:0.796292, Semantic loss: 0.767070, BCE loss: 0.523923, SB loss: 0.697941
2023-10-30 18:04:42,456 Epoch: [324/484] Iter:[30/495], Time: 0.43, lr: [0.003691467727088272], Loss: 2.019783, Acc:0.809913, Semantic loss: 0.783400, BCE loss: 0.531280, SB loss: 0.705103
2023-10-30 18:04:46,062 Epoch: [324/484] Iter:[40/495], Time: 0.42, lr: [0.0036910480805128583], Loss: 2.023677, Acc:0.810868, Semantic loss: 0.779016, BCE loss: 0.540149, SB loss: 0.704512
2023-10-30 18:04:49,750 Epoch: [324/484] Iter:[50/495], Time: 0.41, lr: [0.003690628428636167], Loss: 1.999028, Acc:0.820557, Semantic loss: 0.762934, BCE loss: 0.532013, SB loss: 0.704081
2023-10-30 18:04:53,349 Epoch: [324/484] Iter:[60/495], Time: 0.40, lr: [0.003690208771457458], Loss: 1.986377, Acc:0.820774, Semantic loss: 0.757050, BCE loss: 0.529062, SB loss: 0.700264
2023-10-30 18:04:57,010 Epoch: [324/484] Iter:[70/495], Time: 0.39, lr: [0.003689789108975998], Loss: 1.981554, Acc:0.815379, Semantic loss: 0.751704, BCE loss: 0.527662, SB loss: 0.702188
2023-10-30 18:05:00,682 Epoch: [324/484] Iter:[80/495], Time: 0.39, lr: [0.003689369441191049], Loss: 1.988913, Acc:0.814389, Semantic loss: 0.749807, BCE loss: 0.534343, SB loss: 0.704763
2023-10-30 18:05:04,325 Epoch: [324/484] Iter:[90/495], Time: 0.39, lr: [0.0036889497681018724], Loss: 1.972221, Acc:0.813033, Semantic loss: 0.742427, BCE loss: 0.526411, SB loss: 0.703383
2023-10-30 18:05:07,966 Epoch: [324/484] Iter:[100/495], Time: 0.39, lr: [0.00368853008970773], Loss: 1.973571, Acc:0.812892, Semantic loss: 0.743085, BCE loss: 0.527688, SB loss: 0.702798
2023-10-30 18:05:11,648 Epoch: [324/484] Iter:[110/495], Time: 0.38, lr: [0.0036881104060078876], Loss: 1.976455, Acc:0.812969, Semantic loss: 0.747128, BCE loss: 0.524521, SB loss: 0.704806
2023-10-30 18:05:15,324 Epoch: [324/484] Iter:[120/495], Time: 0.38, lr: [0.003687690717001604], Loss: 1.979041, Acc:0.810479, Semantic loss: 0.748856, BCE loss: 0.522674, SB loss: 0.707512
2023-10-30 18:05:19,060 Epoch: [324/484] Iter:[130/495], Time: 0.38, lr: [0.003687271022688142], Loss: 1.975658, Acc:0.810902, Semantic loss: 0.745048, BCE loss: 0.525338, SB loss: 0.705272
2023-10-30 18:05:22,756 Epoch: [324/484] Iter:[140/495], Time: 0.38, lr: [0.0036868513230667627], Loss: 1.990676, Acc:0.813965, Semantic loss: 0.750937, BCE loss: 0.529311, SB loss: 0.710427
2023-10-30 18:05:26,428 Epoch: [324/484] Iter:[150/495], Time: 0.38, lr: [0.0036864316181367293], Loss: 1.985237, Acc:0.813122, Semantic loss: 0.748347, BCE loss: 0.526550, SB loss: 0.710340
2023-10-30 18:05:30,067 Epoch: [324/484] Iter:[160/495], Time: 0.38, lr: [0.0036860119078973015], Loss: 1.989395, Acc:0.812890, Semantic loss: 0.751793, BCE loss: 0.524729, SB loss: 0.712873
2023-10-30 18:05:33,888 Epoch: [324/484] Iter:[170/495], Time: 0.38, lr: [0.0036855921923477416], Loss: 1.993499, Acc:0.813022, Semantic loss: 0.752916, BCE loss: 0.525764, SB loss: 0.714820
2023-10-30 18:05:37,503 Epoch: [324/484] Iter:[180/495], Time: 0.38, lr: [0.003685172471487308], Loss: 1.996272, Acc:0.815333, Semantic loss: 0.752212, BCE loss: 0.529885, SB loss: 0.714175
2023-10-30 18:05:41,156 Epoch: [324/484] Iter:[190/495], Time: 0.38, lr: [0.003684752745315265], Loss: 2.000067, Acc:0.814093, Semantic loss: 0.753924, BCE loss: 0.532038, SB loss: 0.714105
2023-10-30 18:05:44,898 Epoch: [324/484] Iter:[200/495], Time: 0.38, lr: [0.003684333013830871], Loss: 1.995751, Acc:0.813909, Semantic loss: 0.751069, BCE loss: 0.531008, SB loss: 0.713675
2023-10-30 18:05:48,521 Epoch: [324/484] Iter:[210/495], Time: 0.38, lr: [0.0036839132770333867], Loss: 1.992782, Acc:0.813698, Semantic loss: 0.750284, BCE loss: 0.529294, SB loss: 0.713204
2023-10-30 18:05:52,167 Epoch: [324/484] Iter:[220/495], Time: 0.38, lr: [0.0036834935349220705], Loss: 1.990449, Acc:0.812576, Semantic loss: 0.749208, BCE loss: 0.528003, SB loss: 0.713239
2023-10-30 18:05:55,813 Epoch: [324/484] Iter:[230/495], Time: 0.38, lr: [0.0036830737874961857], Loss: 1.987946, Acc:0.812003, Semantic loss: 0.747125, BCE loss: 0.527713, SB loss: 0.713108
2023-10-30 18:05:59,474 Epoch: [324/484] Iter:[240/495], Time: 0.38, lr: [0.0036826540347549897], Loss: 1.984345, Acc:0.812162, Semantic loss: 0.744649, BCE loss: 0.527977, SB loss: 0.711719
2023-10-30 18:06:03,087 Epoch: [324/484] Iter:[250/495], Time: 0.37, lr: [0.003682234276697743], Loss: 1.985146, Acc:0.811303, Semantic loss: 0.745602, BCE loss: 0.528694, SB loss: 0.710850
2023-10-30 18:06:06,761 Epoch: [324/484] Iter:[260/495], Time: 0.37, lr: [0.003681814513323703], Loss: 1.985387, Acc:0.810692, Semantic loss: 0.747840, BCE loss: 0.526792, SB loss: 0.710754
2023-10-30 18:06:10,690 Epoch: [324/484] Iter:[270/495], Time: 0.38, lr: [0.0036813947446321317], Loss: 1.990799, Acc:0.810717, Semantic loss: 0.748656, BCE loss: 0.530570, SB loss: 0.711573
2023-10-30 18:06:14,314 Epoch: [324/484] Iter:[280/495], Time: 0.37, lr: [0.003680974970622286], Loss: 1.993871, Acc:0.811415, Semantic loss: 0.749816, BCE loss: 0.531487, SB loss: 0.712568
2023-10-30 18:06:18,035 Epoch: [324/484] Iter:[290/495], Time: 0.37, lr: [0.003680555191293426], Loss: 1.993710, Acc:0.810126, Semantic loss: 0.749452, BCE loss: 0.531417, SB loss: 0.712842
2023-10-30 18:06:21,666 Epoch: [324/484] Iter:[300/495], Time: 0.37, lr: [0.003680135406644808], Loss: 1.987227, Acc:0.808856, Semantic loss: 0.745944, BCE loss: 0.529462, SB loss: 0.711822
2023-10-30 18:06:25,278 Epoch: [324/484] Iter:[310/495], Time: 0.37, lr: [0.0036797156166756924], Loss: 1.991599, Acc:0.807864, Semantic loss: 0.747400, BCE loss: 0.530585, SB loss: 0.713614
2023-10-30 18:06:28,951 Epoch: [324/484] Iter:[320/495], Time: 0.37, lr: [0.0036792958213853373], Loss: 1.989704, Acc:0.808339, Semantic loss: 0.746110, BCE loss: 0.530367, SB loss: 0.713228
2023-10-30 18:06:32,604 Epoch: [324/484] Iter:[330/495], Time: 0.37, lr: [0.003678876020773], Loss: 1.994711, Acc:0.807903, Semantic loss: 0.750751, BCE loss: 0.529439, SB loss: 0.714522
2023-10-30 18:06:36,282 Epoch: [324/484] Iter:[340/495], Time: 0.37, lr: [0.003678456214837937], Loss: 1.994397, Acc:0.807181, Semantic loss: 0.750484, BCE loss: 0.528863, SB loss: 0.715051
2023-10-30 18:06:40,004 Epoch: [324/484] Iter:[350/495], Time: 0.37, lr: [0.0036780364035794077], Loss: 1.995592, Acc:0.807466, Semantic loss: 0.749358, BCE loss: 0.531195, SB loss: 0.715040
2023-10-30 18:06:43,634 Epoch: [324/484] Iter:[360/495], Time: 0.37, lr: [0.00367761658699667], Loss: 1.994111, Acc:0.806940, Semantic loss: 0.748359, BCE loss: 0.530518, SB loss: 0.715234
2023-10-30 18:06:47,268 Epoch: [324/484] Iter:[370/495], Time: 0.37, lr: [0.003677196765088979], Loss: 1.992594, Acc:0.807306, Semantic loss: 0.747746, BCE loss: 0.529473, SB loss: 0.715375
2023-10-30 18:06:50,911 Epoch: [324/484] Iter:[380/495], Time: 0.37, lr: [0.0036767769378555915], Loss: 1.996533, Acc:0.806747, Semantic loss: 0.749870, BCE loss: 0.530028, SB loss: 0.716636
2023-10-30 18:06:54,683 Epoch: [324/484] Iter:[390/495], Time: 0.37, lr: [0.003676357105295767], Loss: 1.994894, Acc:0.806629, Semantic loss: 0.748726, BCE loss: 0.529687, SB loss: 0.716482
2023-10-30 18:06:58,411 Epoch: [324/484] Iter:[400/495], Time: 0.37, lr: [0.00367593726740876], Loss: 1.991234, Acc:0.805725, Semantic loss: 0.748159, BCE loss: 0.527194, SB loss: 0.715880
2023-10-30 18:07:01,995 Epoch: [324/484] Iter:[410/495], Time: 0.37, lr: [0.0036755174241938273], Loss: 1.995644, Acc:0.806043, Semantic loss: 0.749557, BCE loss: 0.529064, SB loss: 0.717024
2023-10-30 18:07:05,752 Epoch: [324/484] Iter:[420/495], Time: 0.37, lr: [0.0036750975756502237], Loss: 1.994203, Acc:0.806175, Semantic loss: 0.748770, BCE loss: 0.528252, SB loss: 0.717181
2023-10-30 18:07:09,323 Epoch: [324/484] Iter:[430/495], Time: 0.37, lr: [0.0036746777217772078], Loss: 1.994267, Acc:0.805459, Semantic loss: 0.750001, BCE loss: 0.527284, SB loss: 0.716982
2023-10-30 18:07:13,142 Epoch: [324/484] Iter:[440/495], Time: 0.37, lr: [0.0036742578625740337], Loss: 1.992877, Acc:0.805819, Semantic loss: 0.748962, BCE loss: 0.527345, SB loss: 0.716570
2023-10-30 18:07:16,746 Epoch: [324/484] Iter:[450/495], Time: 0.37, lr: [0.003673837998039956], Loss: 1.993712, Acc:0.805179, Semantic loss: 0.749289, BCE loss: 0.527678, SB loss: 0.716745
2023-10-30 18:07:20,438 Epoch: [324/484] Iter:[460/495], Time: 0.37, lr: [0.003673418128174233], Loss: 1.994858, Acc:0.804258, Semantic loss: 0.751466, BCE loss: 0.526259, SB loss: 0.717133
2023-10-30 18:07:24,140 Epoch: [324/484] Iter:[470/495], Time: 0.37, lr: [0.0036729982529761173], Loss: 1.991761, Acc:0.804762, Semantic loss: 0.749766, BCE loss: 0.525776, SB loss: 0.716220
2023-10-30 18:07:27,838 Epoch: [324/484] Iter:[480/495], Time: 0.37, lr: [0.003672578372444866], Loss: 1.989783, Acc:0.804833, Semantic loss: 0.748487, BCE loss: 0.524326, SB loss: 0.716970
2023-10-30 18:07:31,301 Epoch: [324/484] Iter:[490/495], Time: 0.37, lr: [0.00367215848657973], Loss: 1.992699, Acc:0.805240, Semantic loss: 0.750357, BCE loss: 0.524753, SB loss: 0.717589
2023-10-30 18:07:32,703 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:07:32,946 Loss: 2.010, MeanIU:  0.7056, Best_mIoU:  0.7309
2023-10-30 18:07:32,946 [0.97499798 0.80895892 0.90622841 0.4322744  0.53930734 0.59451103
 0.66811293 0.74520255 0.90691812 0.60549891 0.93407912 0.7946639
 0.58023517 0.93169557 0.54015984 0.59413957 0.51623463 0.58557381
 0.74691512]
2023-10-30 18:07:34,889 Epoch: [325/484] Iter:[0/495], Time: 1.91, lr: [0.003671948541646725], Loss: 1.722481, Acc:0.721143, Semantic loss: 0.660376, BCE loss: 0.398920, SB loss: 0.663184
2023-10-30 18:07:38,984 Epoch: [325/484] Iter:[10/495], Time: 0.55, lr: [0.0036715286477793695], Loss: 2.032748, Acc:0.827888, Semantic loss: 0.767975, BCE loss: 0.536769, SB loss: 0.728004
2023-10-30 18:07:42,795 Epoch: [325/484] Iter:[20/495], Time: 0.47, lr: [0.0036711087485762684], Loss: 2.023792, Acc:0.815448, Semantic loss: 0.746490, BCE loss: 0.549664, SB loss: 0.727637
2023-10-30 18:07:46,463 Epoch: [325/484] Iter:[30/495], Time: 0.43, lr: [0.0036706888440366753], Loss: 1.992131, Acc:0.806263, Semantic loss: 0.739204, BCE loss: 0.530012, SB loss: 0.722915
2023-10-30 18:07:50,081 Epoch: [325/484] Iter:[40/495], Time: 0.42, lr: [0.0036702689341598428], Loss: 1.977179, Acc:0.802156, Semantic loss: 0.732947, BCE loss: 0.528497, SB loss: 0.715735
2023-10-30 18:07:53,696 Epoch: [325/484] Iter:[50/495], Time: 0.41, lr: [0.003669849018945027], Loss: 1.970691, Acc:0.799767, Semantic loss: 0.733906, BCE loss: 0.525047, SB loss: 0.711738
2023-10-30 18:07:57,612 Epoch: [325/484] Iter:[60/495], Time: 0.40, lr: [0.003669429098391481], Loss: 2.029331, Acc:0.800751, Semantic loss: 0.770622, BCE loss: 0.537689, SB loss: 0.721020
2023-10-30 18:08:01,250 Epoch: [325/484] Iter:[70/495], Time: 0.40, lr: [0.0036690091724984565], Loss: 2.075795, Acc:0.800344, Semantic loss: 0.800419, BCE loss: 0.537853, SB loss: 0.737522
2023-10-30 18:08:04,888 Epoch: [325/484] Iter:[80/495], Time: 0.39, lr: [0.003668589241265206], Loss: 2.072452, Acc:0.800154, Semantic loss: 0.797563, BCE loss: 0.536505, SB loss: 0.738384
2023-10-30 18:08:08,656 Epoch: [325/484] Iter:[90/495], Time: 0.39, lr: [0.0036681693046909853], Loss: 2.082092, Acc:0.801108, Semantic loss: 0.808357, BCE loss: 0.537726, SB loss: 0.736008
2023-10-30 18:08:12,303 Epoch: [325/484] Iter:[100/495], Time: 0.39, lr: [0.0036677493627750453], Loss: 2.075986, Acc:0.799348, Semantic loss: 0.800528, BCE loss: 0.540306, SB loss: 0.735152
2023-10-30 18:08:16,083 Epoch: [325/484] Iter:[110/495], Time: 0.39, lr: [0.0036673294155166393], Loss: 2.056119, Acc:0.798295, Semantic loss: 0.786804, BCE loss: 0.538501, SB loss: 0.730814
2023-10-30 18:08:19,798 Epoch: [325/484] Iter:[120/495], Time: 0.39, lr: [0.003666909462915017], Loss: 2.057420, Acc:0.798948, Semantic loss: 0.786231, BCE loss: 0.538475, SB loss: 0.732714
2023-10-30 18:08:23,662 Epoch: [325/484] Iter:[130/495], Time: 0.39, lr: [0.003666489504969434], Loss: 2.050240, Acc:0.800809, Semantic loss: 0.779186, BCE loss: 0.543268, SB loss: 0.727786
2023-10-30 18:08:27,357 Epoch: [325/484] Iter:[140/495], Time: 0.39, lr: [0.0036660695416791404], Loss: 2.043758, Acc:0.800256, Semantic loss: 0.777834, BCE loss: 0.538532, SB loss: 0.727392
2023-10-30 18:08:30,950 Epoch: [325/484] Iter:[150/495], Time: 0.38, lr: [0.003665649573043388], Loss: 2.051764, Acc:0.798400, Semantic loss: 0.778929, BCE loss: 0.544971, SB loss: 0.727864
2023-10-30 18:08:34,643 Epoch: [325/484] Iter:[160/495], Time: 0.38, lr: [0.0036652295990614275], Loss: 2.047578, Acc:0.798707, Semantic loss: 0.775829, BCE loss: 0.545792, SB loss: 0.725957
2023-10-30 18:08:38,259 Epoch: [325/484] Iter:[170/495], Time: 0.38, lr: [0.003664809619732512], Loss: 2.059663, Acc:0.796065, Semantic loss: 0.788751, BCE loss: 0.544522, SB loss: 0.726390
2023-10-30 18:08:41,876 Epoch: [325/484] Iter:[180/495], Time: 0.38, lr: [0.003664389635055892], Loss: 2.060122, Acc:0.793420, Semantic loss: 0.787899, BCE loss: 0.544662, SB loss: 0.727560
2023-10-30 18:08:45,457 Epoch: [325/484] Iter:[190/495], Time: 0.38, lr: [0.0036639696450308174], Loss: 2.059192, Acc:0.795010, Semantic loss: 0.785078, BCE loss: 0.545382, SB loss: 0.728733
2023-10-30 18:08:49,089 Epoch: [325/484] Iter:[200/495], Time: 0.38, lr: [0.003663549649656539], Loss: 2.049323, Acc:0.794157, Semantic loss: 0.780398, BCE loss: 0.541108, SB loss: 0.727817
2023-10-30 18:08:52,824 Epoch: [325/484] Iter:[210/495], Time: 0.38, lr: [0.0036631296489323083], Loss: 2.044967, Acc:0.793608, Semantic loss: 0.778060, BCE loss: 0.539054, SB loss: 0.727853
2023-10-30 18:08:56,549 Epoch: [325/484] Iter:[220/495], Time: 0.38, lr: [0.003662709642857375], Loss: 2.048851, Acc:0.794446, Semantic loss: 0.780104, BCE loss: 0.539869, SB loss: 0.728878
2023-10-30 18:09:00,187 Epoch: [325/484] Iter:[230/495], Time: 0.38, lr: [0.0036622896314309895], Loss: 2.048713, Acc:0.793590, Semantic loss: 0.778637, BCE loss: 0.541522, SB loss: 0.728555
2023-10-30 18:09:03,873 Epoch: [325/484] Iter:[240/495], Time: 0.38, lr: [0.0036618696146524], Loss: 2.062340, Acc:0.791076, Semantic loss: 0.785158, BCE loss: 0.546527, SB loss: 0.730656
2023-10-30 18:09:07,544 Epoch: [325/484] Iter:[250/495], Time: 0.38, lr: [0.0036614495925208585], Loss: 2.058709, Acc:0.792587, Semantic loss: 0.782636, BCE loss: 0.546684, SB loss: 0.729389
2023-10-30 18:09:11,066 Epoch: [325/484] Iter:[260/495], Time: 0.38, lr: [0.0036610295650356135], Loss: 2.061051, Acc:0.793242, Semantic loss: 0.783122, BCE loss: 0.547915, SB loss: 0.730014
2023-10-30 18:09:14,732 Epoch: [325/484] Iter:[270/495], Time: 0.38, lr: [0.003660609532195915], Loss: 2.057955, Acc:0.793915, Semantic loss: 0.781853, BCE loss: 0.546860, SB loss: 0.729242
2023-10-30 18:09:18,410 Epoch: [325/484] Iter:[280/495], Time: 0.38, lr: [0.0036601894940010093], Loss: 2.061392, Acc:0.795331, Semantic loss: 0.783213, BCE loss: 0.548326, SB loss: 0.729854
2023-10-30 18:09:22,154 Epoch: [325/484] Iter:[290/495], Time: 0.38, lr: [0.0036597694504501483], Loss: 2.055866, Acc:0.795538, Semantic loss: 0.779137, BCE loss: 0.548308, SB loss: 0.728422
2023-10-30 18:09:25,917 Epoch: [325/484] Iter:[300/495], Time: 0.38, lr: [0.0036593494015425805], Loss: 2.058098, Acc:0.796705, Semantic loss: 0.777267, BCE loss: 0.551676, SB loss: 0.729155
2023-10-30 18:09:29,656 Epoch: [325/484] Iter:[310/495], Time: 0.38, lr: [0.003658929347277552], Loss: 2.054928, Acc:0.798590, Semantic loss: 0.776176, BCE loss: 0.549552, SB loss: 0.729200
2023-10-30 18:09:33,303 Epoch: [325/484] Iter:[320/495], Time: 0.37, lr: [0.0036585092876543135], Loss: 2.053658, Acc:0.797466, Semantic loss: 0.775258, BCE loss: 0.549101, SB loss: 0.729299
2023-10-30 18:09:37,074 Epoch: [325/484] Iter:[330/495], Time: 0.37, lr: [0.0036580892226721123], Loss: 2.055781, Acc:0.797534, Semantic loss: 0.776121, BCE loss: 0.550716, SB loss: 0.728945
2023-10-30 18:09:40,669 Epoch: [325/484] Iter:[340/495], Time: 0.37, lr: [0.003657669152330196], Loss: 2.054237, Acc:0.798761, Semantic loss: 0.775360, BCE loss: 0.550384, SB loss: 0.728494
2023-10-30 18:09:44,448 Epoch: [325/484] Iter:[350/495], Time: 0.37, lr: [0.003657249076627811], Loss: 2.049811, Acc:0.797724, Semantic loss: 0.773420, BCE loss: 0.548651, SB loss: 0.727740
2023-10-30 18:09:48,123 Epoch: [325/484] Iter:[360/495], Time: 0.37, lr: [0.0036568289955642075], Loss: 2.057093, Acc:0.797518, Semantic loss: 0.779869, BCE loss: 0.548368, SB loss: 0.728855
2023-10-30 18:09:51,772 Epoch: [325/484] Iter:[370/495], Time: 0.37, lr: [0.0036564089091386314], Loss: 2.054273, Acc:0.796415, Semantic loss: 0.778221, BCE loss: 0.546944, SB loss: 0.729107
2023-10-30 18:09:55,469 Epoch: [325/484] Iter:[380/495], Time: 0.37, lr: [0.0036559888173503304], Loss: 2.049393, Acc:0.796182, Semantic loss: 0.776354, BCE loss: 0.545102, SB loss: 0.727937
2023-10-30 18:09:59,187 Epoch: [325/484] Iter:[390/495], Time: 0.37, lr: [0.003655568720198548], Loss: 2.048879, Acc:0.797300, Semantic loss: 0.775938, BCE loss: 0.545244, SB loss: 0.727697
2023-10-30 18:10:02,884 Epoch: [325/484] Iter:[400/495], Time: 0.37, lr: [0.003655148617682536], Loss: 2.046501, Acc:0.797438, Semantic loss: 0.774561, BCE loss: 0.544299, SB loss: 0.727641
2023-10-30 18:10:06,607 Epoch: [325/484] Iter:[410/495], Time: 0.37, lr: [0.003654728509801538], Loss: 2.046198, Acc:0.798256, Semantic loss: 0.774681, BCE loss: 0.544146, SB loss: 0.727371
2023-10-30 18:10:10,236 Epoch: [325/484] Iter:[420/495], Time: 0.37, lr: [0.0036543083965548], Loss: 2.047088, Acc:0.798526, Semantic loss: 0.775190, BCE loss: 0.544530, SB loss: 0.727367
2023-10-30 18:10:13,903 Epoch: [325/484] Iter:[430/495], Time: 0.37, lr: [0.0036538882779415683], Loss: 2.045849, Acc:0.797944, Semantic loss: 0.775439, BCE loss: 0.543525, SB loss: 0.726885
2023-10-30 18:10:17,633 Epoch: [325/484] Iter:[440/495], Time: 0.37, lr: [0.0036534681539610904], Loss: 2.042882, Acc:0.799035, Semantic loss: 0.773686, BCE loss: 0.542569, SB loss: 0.726627
2023-10-30 18:10:21,394 Epoch: [325/484] Iter:[450/495], Time: 0.37, lr: [0.00365304802461261], Loss: 2.041822, Acc:0.799153, Semantic loss: 0.773852, BCE loss: 0.540812, SB loss: 0.727158
2023-10-30 18:10:25,026 Epoch: [325/484] Iter:[460/495], Time: 0.37, lr: [0.0036526278898953734], Loss: 2.040779, Acc:0.799697, Semantic loss: 0.773653, BCE loss: 0.540608, SB loss: 0.726519
2023-10-30 18:10:28,761 Epoch: [325/484] Iter:[470/495], Time: 0.37, lr: [0.0036522077498086242], Loss: 2.039880, Acc:0.799335, Semantic loss: 0.773072, BCE loss: 0.539707, SB loss: 0.727101
2023-10-30 18:10:32,478 Epoch: [325/484] Iter:[480/495], Time: 0.37, lr: [0.0036517876043516105], Loss: 2.039416, Acc:0.799525, Semantic loss: 0.773222, BCE loss: 0.539268, SB loss: 0.726926
2023-10-30 18:10:36,022 Epoch: [325/484] Iter:[490/495], Time: 0.37, lr: [0.0036513674535235754], Loss: 2.038025, Acc:0.799244, Semantic loss: 0.772119, BCE loss: 0.539502, SB loss: 0.726403
2023-10-30 18:13:33,319 0 [0.94050814 0.65316602 0.82774291 0.16833027 0.26747337 0.44240389
 0.48917126 0.58174159 0.88587867 0.49354875 0.85655194 0.60408312
 0.04355317 0.81069381 0.005059   0.08055611 0.04330948 0.13297804
 0.60950034] 0.4703289400600562
2023-10-30 18:13:33,320 1 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ] 0.6960877430749871
2023-10-30 18:13:33,323 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:13:33,562 Loss: 2.056, MeanIU:  0.6961, Best_mIoU:  0.7309
2023-10-30 18:13:33,563 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ]
2023-10-30 18:13:35,770 Epoch: [326/484] Iter:[0/495], Time: 2.17, lr: [0.0036511573760951883], Loss: 1.955339, Acc:0.862191, Semantic loss: 0.646826, BCE loss: 0.571900, SB loss: 0.736613
2023-10-30 18:13:39,509 Epoch: [326/484] Iter:[10/495], Time: 0.54, lr: [0.0036507372172092044], Loss: 2.044508, Acc:0.792027, Semantic loss: 0.775249, BCE loss: 0.534907, SB loss: 0.734351
2023-10-30 18:13:43,045 Epoch: [326/484] Iter:[20/495], Time: 0.45, lr: [0.00365031705295031], Loss: 2.003380, Acc:0.788700, Semantic loss: 0.743071, BCE loss: 0.544269, SB loss: 0.716041
2023-10-30 18:13:46,572 Epoch: [326/484] Iter:[30/495], Time: 0.42, lr: [0.00364989688331775], Loss: 1.986037, Acc:0.793519, Semantic loss: 0.733575, BCE loss: 0.539913, SB loss: 0.712549
2023-10-30 18:13:50,080 Epoch: [326/484] Iter:[40/495], Time: 0.40, lr: [0.003649476708310768], Loss: 1.962945, Acc:0.789626, Semantic loss: 0.724903, BCE loss: 0.526611, SB loss: 0.711431
2023-10-30 18:13:53,549 Epoch: [326/484] Iter:[50/495], Time: 0.39, lr: [0.0036490565279286074], Loss: 1.983258, Acc:0.790065, Semantic loss: 0.738935, BCE loss: 0.530623, SB loss: 0.713700
2023-10-30 18:13:57,026 Epoch: [326/484] Iter:[60/495], Time: 0.38, lr: [0.003648636342170511], Loss: 1.972818, Acc:0.790271, Semantic loss: 0.732765, BCE loss: 0.527488, SB loss: 0.712565
2023-10-30 18:14:00,544 Epoch: [326/484] Iter:[70/495], Time: 0.38, lr: [0.0036482161510357244], Loss: 1.976606, Acc:0.795027, Semantic loss: 0.731989, BCE loss: 0.532103, SB loss: 0.712514
2023-10-30 18:14:04,077 Epoch: [326/484] Iter:[80/495], Time: 0.38, lr: [0.003647795954523489], Loss: 2.001805, Acc:0.798174, Semantic loss: 0.748787, BCE loss: 0.539074, SB loss: 0.713944
2023-10-30 18:14:07,692 Epoch: [326/484] Iter:[90/495], Time: 0.37, lr: [0.003647375752633048], Loss: 2.003415, Acc:0.799650, Semantic loss: 0.746698, BCE loss: 0.539529, SB loss: 0.717188
2023-10-30 18:14:11,207 Epoch: [326/484] Iter:[100/495], Time: 0.37, lr: [0.0036469555453636435], Loss: 2.007030, Acc:0.801455, Semantic loss: 0.744369, BCE loss: 0.545563, SB loss: 0.717097
2023-10-30 18:14:14,775 Epoch: [326/484] Iter:[110/495], Time: 0.37, lr: [0.003646535332714519], Loss: 2.003312, Acc:0.800868, Semantic loss: 0.743380, BCE loss: 0.543330, SB loss: 0.716602
2023-10-30 18:14:18,427 Epoch: [326/484] Iter:[120/495], Time: 0.37, lr: [0.003646115114684916], Loss: 1.995758, Acc:0.802482, Semantic loss: 0.740743, BCE loss: 0.541808, SB loss: 0.713207
2023-10-30 18:14:22,017 Epoch: [326/484] Iter:[130/495], Time: 0.37, lr: [0.003645694891274077], Loss: 1.990977, Acc:0.804007, Semantic loss: 0.738479, BCE loss: 0.540770, SB loss: 0.711728
2023-10-30 18:14:25,562 Epoch: [326/484] Iter:[140/495], Time: 0.37, lr: [0.0036452746624812443], Loss: 1.989891, Acc:0.803723, Semantic loss: 0.739004, BCE loss: 0.538434, SB loss: 0.712452
2023-10-30 18:14:29,122 Epoch: [326/484] Iter:[150/495], Time: 0.37, lr: [0.0036448544283056595], Loss: 1.995496, Acc:0.800096, Semantic loss: 0.742913, BCE loss: 0.537574, SB loss: 0.715009
2023-10-30 18:14:32,734 Epoch: [326/484] Iter:[160/495], Time: 0.37, lr: [0.0036444341887465637], Loss: 1.994737, Acc:0.803145, Semantic loss: 0.741640, BCE loss: 0.539450, SB loss: 0.713647
2023-10-30 18:14:36,337 Epoch: [326/484] Iter:[170/495], Time: 0.37, lr: [0.003644013943803197], Loss: 1.996252, Acc:0.803755, Semantic loss: 0.742188, BCE loss: 0.538564, SB loss: 0.715500
2023-10-30 18:14:40,007 Epoch: [326/484] Iter:[180/495], Time: 0.37, lr: [0.0036435936934748024], Loss: 2.001735, Acc:0.804304, Semantic loss: 0.744850, BCE loss: 0.540445, SB loss: 0.716440
2023-10-30 18:14:43,641 Epoch: [326/484] Iter:[190/495], Time: 0.37, lr: [0.0036431734377606203], Loss: 1.994500, Acc:0.802071, Semantic loss: 0.741941, BCE loss: 0.537462, SB loss: 0.715097
2023-10-30 18:14:47,306 Epoch: [326/484] Iter:[200/495], Time: 0.37, lr: [0.003642753176659891], Loss: 1.996683, Acc:0.803185, Semantic loss: 0.744637, BCE loss: 0.536150, SB loss: 0.715896
2023-10-30 18:14:50,935 Epoch: [326/484] Iter:[210/495], Time: 0.37, lr: [0.003642332910171854], Loss: 1.995110, Acc:0.803289, Semantic loss: 0.745128, BCE loss: 0.534641, SB loss: 0.715340
2023-10-30 18:14:54,536 Epoch: [326/484] Iter:[220/495], Time: 0.37, lr: [0.003641912638295751], Loss: 1.992555, Acc:0.803038, Semantic loss: 0.745136, BCE loss: 0.533472, SB loss: 0.713947
2023-10-30 18:14:58,196 Epoch: [326/484] Iter:[230/495], Time: 0.37, lr: [0.003641492361030822], Loss: 1.988344, Acc:0.803524, Semantic loss: 0.740542, BCE loss: 0.534540, SB loss: 0.713261
2023-10-30 18:15:01,843 Epoch: [326/484] Iter:[240/495], Time: 0.37, lr: [0.0036410720783763067], Loss: 1.994928, Acc:0.802472, Semantic loss: 0.742745, BCE loss: 0.536482, SB loss: 0.715701
2023-10-30 18:15:05,495 Epoch: [326/484] Iter:[250/495], Time: 0.37, lr: [0.0036406517903314435], Loss: 1.993871, Acc:0.801318, Semantic loss: 0.744329, BCE loss: 0.533148, SB loss: 0.716394
2023-10-30 18:15:09,098 Epoch: [326/484] Iter:[260/495], Time: 0.37, lr: [0.0036402314968954734], Loss: 1.994137, Acc:0.801256, Semantic loss: 0.745177, BCE loss: 0.532785, SB loss: 0.716175
2023-10-30 18:15:12,712 Epoch: [326/484] Iter:[270/495], Time: 0.37, lr: [0.003639811198067635], Loss: 1.992701, Acc:0.802271, Semantic loss: 0.743619, BCE loss: 0.533803, SB loss: 0.715279
2023-10-30 18:15:16,270 Epoch: [326/484] Iter:[280/495], Time: 0.37, lr: [0.0036393908938471674], Loss: 1.988694, Acc:0.802858, Semantic loss: 0.741852, BCE loss: 0.532923, SB loss: 0.713920
2023-10-30 18:15:19,819 Epoch: [326/484] Iter:[290/495], Time: 0.37, lr: [0.003638970584233309], Loss: 1.987761, Acc:0.802770, Semantic loss: 0.741871, BCE loss: 0.531923, SB loss: 0.713968
2023-10-30 18:15:23,386 Epoch: [326/484] Iter:[300/495], Time: 0.36, lr: [0.0036385502692252987], Loss: 1.982471, Acc:0.802410, Semantic loss: 0.740270, BCE loss: 0.529430, SB loss: 0.712771
2023-10-30 18:15:27,182 Epoch: [326/484] Iter:[310/495], Time: 0.37, lr: [0.0036381299488223756], Loss: 1.980314, Acc:0.802485, Semantic loss: 0.738467, BCE loss: 0.529817, SB loss: 0.712030
2023-10-30 18:15:30,856 Epoch: [326/484] Iter:[320/495], Time: 0.37, lr: [0.0036377096230237774], Loss: 1.984236, Acc:0.802927, Semantic loss: 0.740059, BCE loss: 0.531590, SB loss: 0.712586
2023-10-30 18:15:34,550 Epoch: [326/484] Iter:[330/495], Time: 0.37, lr: [0.00363728929182874], Loss: 1.984077, Acc:0.803506, Semantic loss: 0.740230, BCE loss: 0.531492, SB loss: 0.712355
2023-10-30 18:15:38,241 Epoch: [326/484] Iter:[340/495], Time: 0.37, lr: [0.0036368689552365046], Loss: 1.988474, Acc:0.803520, Semantic loss: 0.741876, BCE loss: 0.532233, SB loss: 0.714365
2023-10-30 18:15:41,953 Epoch: [326/484] Iter:[350/495], Time: 0.37, lr: [0.0036364486132463084], Loss: 1.986999, Acc:0.802345, Semantic loss: 0.742228, BCE loss: 0.530555, SB loss: 0.714216
2023-10-30 18:15:45,663 Epoch: [326/484] Iter:[360/495], Time: 0.37, lr: [0.0036360282658573864], Loss: 1.990223, Acc:0.803092, Semantic loss: 0.742398, BCE loss: 0.532776, SB loss: 0.715049
2023-10-30 18:15:49,306 Epoch: [326/484] Iter:[370/495], Time: 0.37, lr: [0.0036356079130689762], Loss: 1.986678, Acc:0.802882, Semantic loss: 0.741193, BCE loss: 0.531129, SB loss: 0.714356
2023-10-30 18:15:52,954 Epoch: [326/484] Iter:[380/495], Time: 0.37, lr: [0.003635187554880317], Loss: 1.992719, Acc:0.802173, Semantic loss: 0.744988, BCE loss: 0.531964, SB loss: 0.715767
2023-10-30 18:15:56,627 Epoch: [326/484] Iter:[390/495], Time: 0.37, lr: [0.0036347671912906436], Loss: 1.995703, Acc:0.802092, Semantic loss: 0.745884, BCE loss: 0.533592, SB loss: 0.716227
2023-10-30 18:16:00,228 Epoch: [326/484] Iter:[400/495], Time: 0.37, lr: [0.0036343468222991937], Loss: 1.995079, Acc:0.802198, Semantic loss: 0.746619, BCE loss: 0.532227, SB loss: 0.716233
2023-10-30 18:16:03,835 Epoch: [326/484] Iter:[410/495], Time: 0.37, lr: [0.003633926447905202], Loss: 1.993343, Acc:0.802350, Semantic loss: 0.745820, BCE loss: 0.531310, SB loss: 0.716212
2023-10-30 18:16:07,396 Epoch: [326/484] Iter:[420/495], Time: 0.37, lr: [0.0036335060681079064], Loss: 1.993023, Acc:0.801485, Semantic loss: 0.746062, BCE loss: 0.530658, SB loss: 0.716303
2023-10-30 18:16:11,002 Epoch: [326/484] Iter:[430/495], Time: 0.37, lr: [0.0036330856829065424], Loss: 1.992120, Acc:0.800823, Semantic loss: 0.745712, BCE loss: 0.529812, SB loss: 0.716596
2023-10-30 18:16:14,815 Epoch: [326/484] Iter:[440/495], Time: 0.37, lr: [0.0036326652923003456], Loss: 1.996122, Acc:0.800953, Semantic loss: 0.747908, BCE loss: 0.530968, SB loss: 0.717246
2023-10-30 18:16:18,511 Epoch: [326/484] Iter:[450/495], Time: 0.37, lr: [0.00363224489628855], Loss: 1.994778, Acc:0.800420, Semantic loss: 0.746395, BCE loss: 0.530788, SB loss: 0.717595
2023-10-30 18:16:22,193 Epoch: [326/484] Iter:[460/495], Time: 0.37, lr: [0.003631824494870394], Loss: 1.997860, Acc:0.800974, Semantic loss: 0.748062, BCE loss: 0.531426, SB loss: 0.718372
2023-10-30 18:16:26,031 Epoch: [326/484] Iter:[470/495], Time: 0.37, lr: [0.0036314040880451107], Loss: 1.995959, Acc:0.801975, Semantic loss: 0.747140, BCE loss: 0.530600, SB loss: 0.718219
2023-10-30 18:16:29,659 Epoch: [326/484] Iter:[480/495], Time: 0.37, lr: [0.0036309836758119346], Loss: 1.997255, Acc:0.801794, Semantic loss: 0.747538, BCE loss: 0.530981, SB loss: 0.718736
2023-10-30 18:16:33,187 Epoch: [326/484] Iter:[490/495], Time: 0.37, lr: [0.003630563258170101], Loss: 1.994012, Acc:0.802724, Semantic loss: 0.745776, BCE loss: 0.530317, SB loss: 0.717918
2023-10-30 18:16:34,593 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:16:34,835 Loss: 2.056, MeanIU:  0.6961, Best_mIoU:  0.7309
2023-10-30 18:16:34,835 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ]
2023-10-30 18:16:36,872 Epoch: [327/484] Iter:[0/495], Time: 2.00, lr: [0.003630353047320699], Loss: 1.627310, Acc:0.919254, Semantic loss: 0.621709, BCE loss: 0.353115, SB loss: 0.652486
2023-10-30 18:16:40,902 Epoch: [327/484] Iter:[10/495], Time: 0.55, lr: [0.0036299326215644442], Loss: 1.960253, Acc:0.821862, Semantic loss: 0.714311, BCE loss: 0.533552, SB loss: 0.712390
2023-10-30 18:16:44,694 Epoch: [327/484] Iter:[20/495], Time: 0.47, lr: [0.003629512190397618], Loss: 2.039353, Acc:0.813895, Semantic loss: 0.769500, BCE loss: 0.538183, SB loss: 0.731670
2023-10-30 18:16:48,360 Epoch: [327/484] Iter:[30/495], Time: 0.44, lr: [0.0036290917538194536], Loss: 2.045183, Acc:0.814263, Semantic loss: 0.757887, BCE loss: 0.550414, SB loss: 0.736883
2023-10-30 18:16:52,061 Epoch: [327/484] Iter:[40/495], Time: 0.42, lr: [0.0036286713118291866], Loss: 2.013580, Acc:0.809036, Semantic loss: 0.745731, BCE loss: 0.539037, SB loss: 0.728812
2023-10-30 18:16:55,824 Epoch: [327/484] Iter:[50/495], Time: 0.41, lr: [0.0036282508644260485], Loss: 2.020618, Acc:0.804536, Semantic loss: 0.742337, BCE loss: 0.549072, SB loss: 0.729210
2023-10-30 18:16:59,516 Epoch: [327/484] Iter:[60/495], Time: 0.40, lr: [0.0036278304116092743], Loss: 2.014390, Acc:0.808335, Semantic loss: 0.737862, BCE loss: 0.552057, SB loss: 0.724471
2023-10-30 18:17:03,268 Epoch: [327/484] Iter:[70/495], Time: 0.40, lr: [0.0036274099533780946], Loss: 1.990515, Acc:0.808314, Semantic loss: 0.730102, BCE loss: 0.542120, SB loss: 0.718293
2023-10-30 18:17:06,887 Epoch: [327/484] Iter:[80/495], Time: 0.40, lr: [0.0036269894897317458], Loss: 1.989375, Acc:0.807010, Semantic loss: 0.730427, BCE loss: 0.543867, SB loss: 0.715081
2023-10-30 18:17:10,584 Epoch: [327/484] Iter:[90/495], Time: 0.39, lr: [0.0036265690206694584], Loss: 1.988008, Acc:0.805094, Semantic loss: 0.733226, BCE loss: 0.539633, SB loss: 0.715149
2023-10-30 18:17:14,109 Epoch: [327/484] Iter:[100/495], Time: 0.39, lr: [0.0036261485461904653], Loss: 1.973425, Acc:0.804035, Semantic loss: 0.729498, BCE loss: 0.532706, SB loss: 0.711221
2023-10-30 18:17:17,820 Epoch: [327/484] Iter:[110/495], Time: 0.39, lr: [0.0036257280662939984], Loss: 1.973227, Acc:0.804612, Semantic loss: 0.732386, BCE loss: 0.531130, SB loss: 0.709711
2023-10-30 18:17:21,348 Epoch: [327/484] Iter:[120/495], Time: 0.38, lr: [0.0036253075809792906], Loss: 1.974399, Acc:0.805395, Semantic loss: 0.734385, BCE loss: 0.530690, SB loss: 0.709324
2023-10-30 18:17:25,030 Epoch: [327/484] Iter:[130/495], Time: 0.38, lr: [0.0036248870902455743], Loss: 1.966103, Acc:0.806433, Semantic loss: 0.731332, BCE loss: 0.526461, SB loss: 0.708310
2023-10-30 18:17:28,576 Epoch: [327/484] Iter:[140/495], Time: 0.38, lr: [0.00362446659409208], Loss: 1.960876, Acc:0.807958, Semantic loss: 0.727779, BCE loss: 0.526576, SB loss: 0.706520
2023-10-30 18:17:32,234 Epoch: [327/484] Iter:[150/495], Time: 0.38, lr: [0.0036240460925180385], Loss: 1.959906, Acc:0.806314, Semantic loss: 0.727362, BCE loss: 0.524799, SB loss: 0.707744
2023-10-30 18:17:35,932 Epoch: [327/484] Iter:[160/495], Time: 0.38, lr: [0.0036236255855226834], Loss: 1.957867, Acc:0.806792, Semantic loss: 0.727844, BCE loss: 0.522218, SB loss: 0.707805
2023-10-30 18:17:39,565 Epoch: [327/484] Iter:[170/495], Time: 0.38, lr: [0.0036232050731052445], Loss: 1.953842, Acc:0.807443, Semantic loss: 0.726626, BCE loss: 0.520023, SB loss: 0.707193
2023-10-30 18:17:43,269 Epoch: [327/484] Iter:[180/495], Time: 0.38, lr: [0.003622784555264953], Loss: 1.957228, Acc:0.808844, Semantic loss: 0.730612, BCE loss: 0.519026, SB loss: 0.707589
2023-10-30 18:17:46,950 Epoch: [327/484] Iter:[190/495], Time: 0.38, lr: [0.0036223640320010375], Loss: 1.961356, Acc:0.808016, Semantic loss: 0.734113, BCE loss: 0.517998, SB loss: 0.709244
2023-10-30 18:17:50,711 Epoch: [327/484] Iter:[200/495], Time: 0.38, lr: [0.0036219435033127316], Loss: 1.952862, Acc:0.807769, Semantic loss: 0.730364, BCE loss: 0.515204, SB loss: 0.707294
2023-10-30 18:17:54,352 Epoch: [327/484] Iter:[210/495], Time: 0.38, lr: [0.003621522969199264], Loss: 1.958942, Acc:0.807826, Semantic loss: 0.731698, BCE loss: 0.519609, SB loss: 0.707636
2023-10-30 18:17:57,933 Epoch: [327/484] Iter:[220/495], Time: 0.38, lr: [0.0036211024296598647], Loss: 1.957376, Acc:0.807023, Semantic loss: 0.730626, BCE loss: 0.519570, SB loss: 0.707180
2023-10-30 18:18:01,546 Epoch: [327/484] Iter:[230/495], Time: 0.38, lr: [0.003620681884693763], Loss: 1.960378, Acc:0.807444, Semantic loss: 0.733138, BCE loss: 0.518774, SB loss: 0.708466
2023-10-30 18:18:05,207 Epoch: [327/484] Iter:[240/495], Time: 0.37, lr: [0.0036202613343001896], Loss: 1.958811, Acc:0.807304, Semantic loss: 0.732439, BCE loss: 0.517921, SB loss: 0.708451
2023-10-30 18:18:08,846 Epoch: [327/484] Iter:[250/495], Time: 0.37, lr: [0.003619840778478374], Loss: 1.958827, Acc:0.807461, Semantic loss: 0.733084, BCE loss: 0.517355, SB loss: 0.708388
2023-10-30 18:18:12,571 Epoch: [327/484] Iter:[260/495], Time: 0.37, lr: [0.003619420217227544], Loss: 1.963506, Acc:0.807292, Semantic loss: 0.734608, BCE loss: 0.519805, SB loss: 0.709093
2023-10-30 18:18:16,264 Epoch: [327/484] Iter:[270/495], Time: 0.37, lr: [0.003618999650546929], Loss: 1.966711, Acc:0.806106, Semantic loss: 0.737255, BCE loss: 0.518403, SB loss: 0.711053
2023-10-30 18:18:19,918 Epoch: [327/484] Iter:[280/495], Time: 0.37, lr: [0.003618579078435759], Loss: 1.966616, Acc:0.805192, Semantic loss: 0.737089, BCE loss: 0.518992, SB loss: 0.710536
2023-10-30 18:18:23,661 Epoch: [327/484] Iter:[290/495], Time: 0.37, lr: [0.003618158500893262], Loss: 1.967505, Acc:0.805553, Semantic loss: 0.737649, BCE loss: 0.519158, SB loss: 0.710698
2023-10-30 18:18:27,219 Epoch: [327/484] Iter:[300/495], Time: 0.37, lr: [0.0036177379179186658], Loss: 1.970606, Acc:0.806009, Semantic loss: 0.737757, BCE loss: 0.520557, SB loss: 0.712293
2023-10-30 18:18:30,841 Epoch: [327/484] Iter:[310/495], Time: 0.37, lr: [0.003617317329511198], Loss: 1.966244, Acc:0.805477, Semantic loss: 0.736423, BCE loss: 0.518451, SB loss: 0.711369
2023-10-30 18:18:34,474 Epoch: [327/484] Iter:[320/495], Time: 0.37, lr: [0.003616896735670088], Loss: 1.967712, Acc:0.804823, Semantic loss: 0.737219, BCE loss: 0.518931, SB loss: 0.711561
2023-10-30 18:18:38,186 Epoch: [327/484] Iter:[330/495], Time: 0.37, lr: [0.003616476136394563], Loss: 1.971296, Acc:0.805389, Semantic loss: 0.738701, BCE loss: 0.520169, SB loss: 0.712426
2023-10-30 18:18:41,858 Epoch: [327/484] Iter:[340/495], Time: 0.37, lr: [0.0036160555316838506], Loss: 1.973194, Acc:0.803824, Semantic loss: 0.739187, BCE loss: 0.521798, SB loss: 0.712210
2023-10-30 18:18:45,628 Epoch: [327/484] Iter:[350/495], Time: 0.37, lr: [0.0036156349215371764], Loss: 1.972904, Acc:0.804986, Semantic loss: 0.738793, BCE loss: 0.522915, SB loss: 0.711196
2023-10-30 18:18:49,240 Epoch: [327/484] Iter:[360/495], Time: 0.37, lr: [0.003615214305953771], Loss: 1.972095, Acc:0.805113, Semantic loss: 0.738001, BCE loss: 0.522757, SB loss: 0.711337
2023-10-30 18:18:52,943 Epoch: [327/484] Iter:[370/495], Time: 0.37, lr: [0.0036147936849328577], Loss: 1.977398, Acc:0.805915, Semantic loss: 0.739602, BCE loss: 0.524593, SB loss: 0.713203
2023-10-30 18:18:56,534 Epoch: [327/484] Iter:[380/495], Time: 0.37, lr: [0.0036143730584736657], Loss: 1.977473, Acc:0.805282, Semantic loss: 0.739990, BCE loss: 0.524199, SB loss: 0.713284
2023-10-30 18:19:00,266 Epoch: [327/484] Iter:[390/495], Time: 0.37, lr: [0.0036139524265754192], Loss: 1.975831, Acc:0.803655, Semantic loss: 0.739774, BCE loss: 0.522728, SB loss: 0.713329
2023-10-30 18:19:03,938 Epoch: [327/484] Iter:[400/495], Time: 0.37, lr: [0.003613531789237347], Loss: 1.974332, Acc:0.804792, Semantic loss: 0.738305, BCE loss: 0.522968, SB loss: 0.713059
2023-10-30 18:19:07,528 Epoch: [327/484] Iter:[410/495], Time: 0.37, lr: [0.003613111146458674], Loss: 1.975713, Acc:0.804721, Semantic loss: 0.738427, BCE loss: 0.523602, SB loss: 0.713684
2023-10-30 18:19:11,106 Epoch: [327/484] Iter:[420/495], Time: 0.37, lr: [0.0036126904982386257], Loss: 1.973985, Acc:0.803907, Semantic loss: 0.737948, BCE loss: 0.522817, SB loss: 0.713220
2023-10-30 18:19:14,771 Epoch: [327/484] Iter:[430/495], Time: 0.37, lr: [0.003612269844576427], Loss: 1.975263, Acc:0.804327, Semantic loss: 0.738695, BCE loss: 0.523012, SB loss: 0.713555
2023-10-30 18:19:18,345 Epoch: [327/484] Iter:[440/495], Time: 0.37, lr: [0.003611849185471305], Loss: 1.975793, Acc:0.803850, Semantic loss: 0.738746, BCE loss: 0.523709, SB loss: 0.713338
2023-10-30 18:19:21,967 Epoch: [327/484] Iter:[450/495], Time: 0.37, lr: [0.0036114285209224847], Loss: 1.973110, Acc:0.803602, Semantic loss: 0.737856, BCE loss: 0.522903, SB loss: 0.712350
2023-10-30 18:19:25,639 Epoch: [327/484] Iter:[460/495], Time: 0.37, lr: [0.00361100785092919], Loss: 1.974427, Acc:0.804137, Semantic loss: 0.738470, BCE loss: 0.523591, SB loss: 0.712365
2023-10-30 18:19:29,295 Epoch: [327/484] Iter:[470/495], Time: 0.37, lr: [0.0036105871754906448], Loss: 1.975290, Acc:0.804415, Semantic loss: 0.738963, BCE loss: 0.524286, SB loss: 0.712041
2023-10-30 18:19:32,946 Epoch: [327/484] Iter:[480/495], Time: 0.37, lr: [0.0036101664946060767], Loss: 1.980128, Acc:0.804406, Semantic loss: 0.740971, BCE loss: 0.525698, SB loss: 0.713459
2023-10-30 18:19:36,429 Epoch: [327/484] Iter:[490/495], Time: 0.37, lr: [0.0036097458082747086], Loss: 1.978317, Acc:0.804668, Semantic loss: 0.739750, BCE loss: 0.525844, SB loss: 0.712722
2023-10-30 18:19:37,820 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:19:38,056 Loss: 2.056, MeanIU:  0.6961, Best_mIoU:  0.7309
2023-10-30 18:19:38,056 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ]
2023-10-30 18:19:39,995 Epoch: [328/484] Iter:[0/495], Time: 1.90, lr: [0.0036095354630662326], Loss: 1.380211, Acc:0.809491, Semantic loss: 0.490500, BCE loss: 0.234831, SB loss: 0.654880
2023-10-30 18:19:43,870 Epoch: [328/484] Iter:[10/495], Time: 0.53, lr: [0.003609114768563208], Loss: 1.838412, Acc:0.799802, Semantic loss: 0.669760, BCE loss: 0.484481, SB loss: 0.684171
2023-10-30 18:19:47,558 Epoch: [328/484] Iter:[20/495], Time: 0.45, lr: [0.0036086940686114446], Loss: 1.839396, Acc:0.800678, Semantic loss: 0.679041, BCE loss: 0.473142, SB loss: 0.687213
2023-10-30 18:19:51,128 Epoch: [328/484] Iter:[30/495], Time: 0.42, lr: [0.0036082733632101646], Loss: 1.908241, Acc:0.785140, Semantic loss: 0.715669, BCE loss: 0.490119, SB loss: 0.702453
2023-10-30 18:19:54,717 Epoch: [328/484] Iter:[40/495], Time: 0.41, lr: [0.0036078526523585916], Loss: 1.944372, Acc:0.794688, Semantic loss: 0.740901, BCE loss: 0.496008, SB loss: 0.707462
2023-10-30 18:19:58,466 Epoch: [328/484] Iter:[50/495], Time: 0.40, lr: [0.0036074319360559475], Loss: 1.960614, Acc:0.797720, Semantic loss: 0.745325, BCE loss: 0.507915, SB loss: 0.707374
2023-10-30 18:20:02,027 Epoch: [328/484] Iter:[60/495], Time: 0.39, lr: [0.003607011214301458], Loss: 1.959539, Acc:0.800834, Semantic loss: 0.740120, BCE loss: 0.514518, SB loss: 0.704902
2023-10-30 18:20:05,699 Epoch: [328/484] Iter:[70/495], Time: 0.39, lr: [0.0036065904870943434], Loss: 1.962955, Acc:0.802046, Semantic loss: 0.738767, BCE loss: 0.522040, SB loss: 0.702148
2023-10-30 18:20:09,296 Epoch: [328/484] Iter:[80/495], Time: 0.39, lr: [0.0036061697544338273], Loss: 1.960987, Acc:0.800282, Semantic loss: 0.737188, BCE loss: 0.519295, SB loss: 0.704504
2023-10-30 18:20:13,051 Epoch: [328/484] Iter:[90/495], Time: 0.38, lr: [0.0036057490163191315], Loss: 1.975958, Acc:0.798255, Semantic loss: 0.748075, BCE loss: 0.518871, SB loss: 0.709011
2023-10-30 18:20:16,630 Epoch: [328/484] Iter:[100/495], Time: 0.38, lr: [0.003605328272749479], Loss: 1.975940, Acc:0.799952, Semantic loss: 0.749970, BCE loss: 0.517265, SB loss: 0.708706
2023-10-30 18:20:20,343 Epoch: [328/484] Iter:[110/495], Time: 0.38, lr: [0.003604907523724092], Loss: 1.974268, Acc:0.801267, Semantic loss: 0.747511, BCE loss: 0.520640, SB loss: 0.706117
2023-10-30 18:20:23,917 Epoch: [328/484] Iter:[120/495], Time: 0.38, lr: [0.0036044867692421913], Loss: 1.967849, Acc:0.801231, Semantic loss: 0.744258, BCE loss: 0.517430, SB loss: 0.706161
2023-10-30 18:20:27,647 Epoch: [328/484] Iter:[130/495], Time: 0.38, lr: [0.003604066009302997], Loss: 1.972191, Acc:0.799699, Semantic loss: 0.746580, BCE loss: 0.517664, SB loss: 0.707947
2023-10-30 18:20:31,449 Epoch: [328/484] Iter:[140/495], Time: 0.38, lr: [0.0036036452439057332], Loss: 1.972483, Acc:0.797669, Semantic loss: 0.747066, BCE loss: 0.514821, SB loss: 0.710596
2023-10-30 18:20:35,046 Epoch: [328/484] Iter:[150/495], Time: 0.38, lr: [0.0036032244730496207], Loss: 1.983849, Acc:0.796580, Semantic loss: 0.749923, BCE loss: 0.520227, SB loss: 0.713699
2023-10-30 18:20:38,651 Epoch: [328/484] Iter:[160/495], Time: 0.38, lr: [0.0036028036967338784], Loss: 1.979851, Acc:0.798574, Semantic loss: 0.745093, BCE loss: 0.520050, SB loss: 0.714708
2023-10-30 18:20:42,363 Epoch: [328/484] Iter:[170/495], Time: 0.38, lr: [0.0036023829149577275], Loss: 1.981593, Acc:0.797682, Semantic loss: 0.747027, BCE loss: 0.518931, SB loss: 0.715636
2023-10-30 18:20:46,040 Epoch: [328/484] Iter:[180/495], Time: 0.38, lr: [0.0036019621277203896], Loss: 1.984391, Acc:0.797050, Semantic loss: 0.749500, BCE loss: 0.519553, SB loss: 0.715338
2023-10-30 18:20:49,732 Epoch: [328/484] Iter:[190/495], Time: 0.38, lr: [0.0036015413350210844], Loss: 1.981211, Acc:0.798607, Semantic loss: 0.748700, BCE loss: 0.519918, SB loss: 0.712592
2023-10-30 18:20:53,328 Epoch: [328/484] Iter:[200/495], Time: 0.37, lr: [0.0036011205368590322], Loss: 1.986048, Acc:0.796364, Semantic loss: 0.752094, BCE loss: 0.519064, SB loss: 0.714890
2023-10-30 18:20:57,050 Epoch: [328/484] Iter:[210/495], Time: 0.37, lr: [0.003600699733233451], Loss: 1.987420, Acc:0.797022, Semantic loss: 0.751005, BCE loss: 0.521508, SB loss: 0.714907
2023-10-30 18:21:00,715 Epoch: [328/484] Iter:[220/495], Time: 0.37, lr: [0.003600278924143563], Loss: 1.989312, Acc:0.797154, Semantic loss: 0.750523, BCE loss: 0.524498, SB loss: 0.714292
2023-10-30 18:21:04,401 Epoch: [328/484] Iter:[230/495], Time: 0.37, lr: [0.003599858109588586], Loss: 1.992789, Acc:0.797507, Semantic loss: 0.751756, BCE loss: 0.525539, SB loss: 0.715494
2023-10-30 18:21:08,035 Epoch: [328/484] Iter:[240/495], Time: 0.37, lr: [0.00359943728956774], Loss: 1.993448, Acc:0.797217, Semantic loss: 0.751874, BCE loss: 0.526185, SB loss: 0.715389
2023-10-30 18:21:11,792 Epoch: [328/484] Iter:[250/495], Time: 0.37, lr: [0.0035990164640802426], Loss: 1.987307, Acc:0.797719, Semantic loss: 0.748278, BCE loss: 0.525335, SB loss: 0.713693
2023-10-30 18:21:15,461 Epoch: [328/484] Iter:[260/495], Time: 0.37, lr: [0.0035985956331253143], Loss: 1.988677, Acc:0.798676, Semantic loss: 0.748114, BCE loss: 0.527018, SB loss: 0.713545
2023-10-30 18:21:19,159 Epoch: [328/484] Iter:[270/495], Time: 0.37, lr: [0.0035981747967021725], Loss: 1.987141, Acc:0.798069, Semantic loss: 0.748500, BCE loss: 0.524562, SB loss: 0.714079
2023-10-30 18:21:22,792 Epoch: [328/484] Iter:[280/495], Time: 0.37, lr: [0.003597753954810036], Loss: 1.984492, Acc:0.798486, Semantic loss: 0.746590, BCE loss: 0.524330, SB loss: 0.713572
2023-10-30 18:21:26,599 Epoch: [328/484] Iter:[290/495], Time: 0.37, lr: [0.003597333107448122], Loss: 1.981910, Acc:0.798796, Semantic loss: 0.746329, BCE loss: 0.522377, SB loss: 0.713204
2023-10-30 18:21:30,253 Epoch: [328/484] Iter:[300/495], Time: 0.37, lr: [0.0035969122546156496], Loss: 1.981021, Acc:0.799219, Semantic loss: 0.746297, BCE loss: 0.521701, SB loss: 0.713024
2023-10-30 18:21:34,043 Epoch: [328/484] Iter:[310/495], Time: 0.37, lr: [0.003596491396311836], Loss: 1.982703, Acc:0.799392, Semantic loss: 0.747878, BCE loss: 0.522108, SB loss: 0.712718
2023-10-30 18:21:37,790 Epoch: [328/484] Iter:[320/495], Time: 0.37, lr: [0.003596070532535899], Loss: 1.986646, Acc:0.799330, Semantic loss: 0.749029, BCE loss: 0.524565, SB loss: 0.713052
2023-10-30 18:21:41,526 Epoch: [328/484] Iter:[330/495], Time: 0.37, lr: [0.003595649663287054], Loss: 1.982362, Acc:0.801518, Semantic loss: 0.746050, BCE loss: 0.524505, SB loss: 0.711807
2023-10-30 18:21:45,155 Epoch: [328/484] Iter:[340/495], Time: 0.37, lr: [0.0035952287885645203], Loss: 1.981391, Acc:0.802603, Semantic loss: 0.745102, BCE loss: 0.524254, SB loss: 0.712035
2023-10-30 18:21:48,898 Epoch: [328/484] Iter:[350/495], Time: 0.37, lr: [0.0035948079083675147], Loss: 1.979149, Acc:0.802578, Semantic loss: 0.744141, BCE loss: 0.522730, SB loss: 0.712278
2023-10-30 18:21:52,531 Epoch: [328/484] Iter:[360/495], Time: 0.37, lr: [0.0035943870226952525], Loss: 1.981204, Acc:0.801823, Semantic loss: 0.746006, BCE loss: 0.522371, SB loss: 0.712827
2023-10-30 18:21:56,117 Epoch: [328/484] Iter:[370/495], Time: 0.37, lr: [0.003593966131546949], Loss: 1.983842, Acc:0.802226, Semantic loss: 0.746758, BCE loss: 0.523892, SB loss: 0.713193
2023-10-30 18:21:59,786 Epoch: [328/484] Iter:[380/495], Time: 0.37, lr: [0.003593545234921824], Loss: 1.980097, Acc:0.802384, Semantic loss: 0.745345, BCE loss: 0.522839, SB loss: 0.711914
2023-10-30 18:22:03,505 Epoch: [328/484] Iter:[390/495], Time: 0.37, lr: [0.003593124332819091], Loss: 1.983811, Acc:0.802617, Semantic loss: 0.746146, BCE loss: 0.524893, SB loss: 0.712772
2023-10-30 18:22:07,291 Epoch: [328/484] Iter:[400/495], Time: 0.37, lr: [0.003592703425237966], Loss: 1.984686, Acc:0.802273, Semantic loss: 0.746676, BCE loss: 0.524776, SB loss: 0.713234
2023-10-30 18:22:11,004 Epoch: [328/484] Iter:[410/495], Time: 0.37, lr: [0.0035922825121776636], Loss: 1.988976, Acc:0.802340, Semantic loss: 0.748978, BCE loss: 0.525883, SB loss: 0.714115
2023-10-30 18:22:14,631 Epoch: [328/484] Iter:[420/495], Time: 0.37, lr: [0.0035918615936374023], Loss: 1.986440, Acc:0.802564, Semantic loss: 0.747535, BCE loss: 0.525662, SB loss: 0.713243
2023-10-30 18:22:18,393 Epoch: [328/484] Iter:[430/495], Time: 0.37, lr: [0.0035914406696163944], Loss: 1.988477, Acc:0.803129, Semantic loss: 0.747529, BCE loss: 0.527282, SB loss: 0.713666
2023-10-30 18:22:22,079 Epoch: [328/484] Iter:[440/495], Time: 0.37, lr: [0.003591019740113855], Loss: 1.990068, Acc:0.803365, Semantic loss: 0.749108, BCE loss: 0.527308, SB loss: 0.713652
2023-10-30 18:22:25,769 Epoch: [328/484] Iter:[450/495], Time: 0.37, lr: [0.003590598805128999], Loss: 1.991825, Acc:0.802895, Semantic loss: 0.750100, BCE loss: 0.527588, SB loss: 0.714137
2023-10-30 18:22:29,612 Epoch: [328/484] Iter:[460/495], Time: 0.37, lr: [0.0035901778646610424], Loss: 1.989465, Acc:0.803481, Semantic loss: 0.748504, BCE loss: 0.527501, SB loss: 0.713460
2023-10-30 18:22:33,358 Epoch: [328/484] Iter:[470/495], Time: 0.37, lr: [0.0035897569187091976], Loss: 1.989734, Acc:0.804254, Semantic loss: 0.748151, BCE loss: 0.527564, SB loss: 0.714019
2023-10-30 18:22:37,110 Epoch: [328/484] Iter:[480/495], Time: 0.37, lr: [0.003589335967272678], Loss: 1.989076, Acc:0.804790, Semantic loss: 0.747956, BCE loss: 0.527497, SB loss: 0.713623
2023-10-30 18:22:40,594 Epoch: [328/484] Iter:[490/495], Time: 0.37, lr: [0.0035889150103507006], Loss: 1.991525, Acc:0.805060, Semantic loss: 0.748969, BCE loss: 0.528310, SB loss: 0.714246
2023-10-30 18:22:41,996 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:22:42,232 Loss: 2.056, MeanIU:  0.6961, Best_mIoU:  0.7309
2023-10-30 18:22:42,232 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ]
2023-10-30 18:22:44,377 Epoch: [329/484] Iter:[0/495], Time: 2.11, lr: [0.0035887045298324182], Loss: 2.009010, Acc:0.772445, Semantic loss: 0.745478, BCE loss: 0.499621, SB loss: 0.763912
2023-10-30 18:22:48,333 Epoch: [329/484] Iter:[10/495], Time: 0.55, lr: [0.0035882835646807764], Loss: 2.001814, Acc:0.796885, Semantic loss: 0.760404, BCE loss: 0.506198, SB loss: 0.735212
2023-10-30 18:22:52,094 Epoch: [329/484] Iter:[20/495], Time: 0.47, lr: [0.003587862594041708], Loss: 1.976177, Acc:0.805410, Semantic loss: 0.761972, BCE loss: 0.508486, SB loss: 0.705719
2023-10-30 18:22:55,708 Epoch: [329/484] Iter:[30/495], Time: 0.43, lr: [0.003587441617914426], Loss: 1.980492, Acc:0.798073, Semantic loss: 0.765628, BCE loss: 0.507986, SB loss: 0.706878
2023-10-30 18:22:59,446 Epoch: [329/484] Iter:[40/495], Time: 0.42, lr: [0.0035870206362981446], Loss: 1.950911, Acc:0.804047, Semantic loss: 0.747519, BCE loss: 0.503888, SB loss: 0.699503
2023-10-30 18:23:03,061 Epoch: [329/484] Iter:[50/495], Time: 0.41, lr: [0.0035865996491920753], Loss: 1.975544, Acc:0.809270, Semantic loss: 0.750143, BCE loss: 0.522402, SB loss: 0.702998
2023-10-30 18:23:06,666 Epoch: [329/484] Iter:[60/495], Time: 0.40, lr: [0.0035861786565954314], Loss: 1.944986, Acc:0.802079, Semantic loss: 0.737648, BCE loss: 0.511023, SB loss: 0.696315
2023-10-30 18:23:10,408 Epoch: [329/484] Iter:[70/495], Time: 0.40, lr: [0.0035857576585074224], Loss: 1.958526, Acc:0.806210, Semantic loss: 0.738437, BCE loss: 0.524001, SB loss: 0.696088
2023-10-30 18:23:14,081 Epoch: [329/484] Iter:[80/495], Time: 0.39, lr: [0.003585336654927264], Loss: 1.973124, Acc:0.802787, Semantic loss: 0.744955, BCE loss: 0.523840, SB loss: 0.704329
2023-10-30 18:23:17,879 Epoch: [329/484] Iter:[90/495], Time: 0.39, lr: [0.003584915645854167], Loss: 1.981319, Acc:0.807821, Semantic loss: 0.752222, BCE loss: 0.523336, SB loss: 0.705761
2023-10-30 18:23:21,626 Epoch: [329/484] Iter:[100/495], Time: 0.39, lr: [0.0035844946312873415], Loss: 1.985349, Acc:0.803468, Semantic loss: 0.755015, BCE loss: 0.523500, SB loss: 0.706835
2023-10-30 18:23:25,306 Epoch: [329/484] Iter:[110/495], Time: 0.39, lr: [0.003584073611225999], Loss: 1.984858, Acc:0.802993, Semantic loss: 0.755624, BCE loss: 0.522171, SB loss: 0.707062
2023-10-30 18:23:28,941 Epoch: [329/484] Iter:[120/495], Time: 0.39, lr: [0.0035836525856693525], Loss: 1.976118, Acc:0.799778, Semantic loss: 0.751448, BCE loss: 0.517667, SB loss: 0.707003
2023-10-30 18:23:32,582 Epoch: [329/484] Iter:[130/495], Time: 0.38, lr: [0.003583231554616611], Loss: 1.978418, Acc:0.800951, Semantic loss: 0.750152, BCE loss: 0.520426, SB loss: 0.707840
2023-10-30 18:23:36,245 Epoch: [329/484] Iter:[140/495], Time: 0.38, lr: [0.003582810518066986], Loss: 1.984700, Acc:0.801240, Semantic loss: 0.753009, BCE loss: 0.523071, SB loss: 0.708620
2023-10-30 18:23:39,908 Epoch: [329/484] Iter:[150/495], Time: 0.38, lr: [0.0035823894760196873], Loss: 1.977087, Acc:0.801388, Semantic loss: 0.747891, BCE loss: 0.520798, SB loss: 0.708398
2023-10-30 18:23:43,524 Epoch: [329/484] Iter:[160/495], Time: 0.38, lr: [0.003581968428473927], Loss: 1.970086, Acc:0.802299, Semantic loss: 0.745610, BCE loss: 0.517042, SB loss: 0.707434
2023-10-30 18:23:47,127 Epoch: [329/484] Iter:[170/495], Time: 0.38, lr: [0.003581547375428913], Loss: 1.978474, Acc:0.803510, Semantic loss: 0.748157, BCE loss: 0.523687, SB loss: 0.706629
2023-10-30 18:23:50,776 Epoch: [329/484] Iter:[180/495], Time: 0.38, lr: [0.003581126316883856], Loss: 1.983049, Acc:0.803791, Semantic loss: 0.751633, BCE loss: 0.521957, SB loss: 0.709458
2023-10-30 18:23:54,456 Epoch: [329/484] Iter:[190/495], Time: 0.38, lr: [0.0035807052528379645], Loss: 1.986735, Acc:0.801437, Semantic loss: 0.753166, BCE loss: 0.521403, SB loss: 0.712166
2023-10-30 18:23:58,151 Epoch: [329/484] Iter:[200/495], Time: 0.38, lr: [0.0035802841832904505], Loss: 1.994095, Acc:0.802740, Semantic loss: 0.755870, BCE loss: 0.523560, SB loss: 0.714665
2023-10-30 18:24:01,824 Epoch: [329/484] Iter:[210/495], Time: 0.38, lr: [0.0035798631082405215], Loss: 1.993813, Acc:0.801517, Semantic loss: 0.756333, BCE loss: 0.523221, SB loss: 0.714260
2023-10-30 18:24:05,520 Epoch: [329/484] Iter:[220/495], Time: 0.38, lr: [0.003579442027687386], Loss: 2.003576, Acc:0.800355, Semantic loss: 0.762423, BCE loss: 0.525003, SB loss: 0.716149
2023-10-30 18:24:09,179 Epoch: [329/484] Iter:[230/495], Time: 0.38, lr: [0.0035790209416302525], Loss: 2.003102, Acc:0.800309, Semantic loss: 0.761092, BCE loss: 0.525393, SB loss: 0.716617
2023-10-30 18:24:12,711 Epoch: [329/484] Iter:[240/495], Time: 0.38, lr: [0.003578599850068332], Loss: 2.005507, Acc:0.799909, Semantic loss: 0.764143, BCE loss: 0.525342, SB loss: 0.716022
2023-10-30 18:24:16,384 Epoch: [329/484] Iter:[250/495], Time: 0.37, lr: [0.00357817875300083], Loss: 1.999370, Acc:0.798218, Semantic loss: 0.760555, BCE loss: 0.524321, SB loss: 0.714494
2023-10-30 18:24:19,957 Epoch: [329/484] Iter:[260/495], Time: 0.37, lr: [0.0035777576504269566], Loss: 1.993416, Acc:0.798084, Semantic loss: 0.756928, BCE loss: 0.522699, SB loss: 0.713788
2023-10-30 18:24:23,554 Epoch: [329/484] Iter:[270/495], Time: 0.37, lr: [0.0035773365423459177], Loss: 1.994374, Acc:0.797189, Semantic loss: 0.757429, BCE loss: 0.521351, SB loss: 0.715594
2023-10-30 18:24:27,347 Epoch: [329/484] Iter:[280/495], Time: 0.37, lr: [0.0035769154287569223], Loss: 1.993481, Acc:0.798540, Semantic loss: 0.756687, BCE loss: 0.521880, SB loss: 0.714914
2023-10-30 18:24:30,943 Epoch: [329/484] Iter:[290/495], Time: 0.37, lr: [0.0035764943096591784], Loss: 1.995138, Acc:0.798401, Semantic loss: 0.757401, BCE loss: 0.522053, SB loss: 0.715684
2023-10-30 18:24:34,663 Epoch: [329/484] Iter:[300/495], Time: 0.37, lr: [0.003576073185051891], Loss: 2.000293, Acc:0.796981, Semantic loss: 0.759551, BCE loss: 0.522655, SB loss: 0.718087
2023-10-30 18:24:38,394 Epoch: [329/484] Iter:[310/495], Time: 0.37, lr: [0.0035756520549342693], Loss: 1.997934, Acc:0.797875, Semantic loss: 0.756893, BCE loss: 0.524126, SB loss: 0.716915
2023-10-30 18:24:42,142 Epoch: [329/484] Iter:[320/495], Time: 0.37, lr: [0.0035752309193055193], Loss: 2.000603, Acc:0.797855, Semantic loss: 0.757346, BCE loss: 0.526104, SB loss: 0.717152
2023-10-30 18:24:45,815 Epoch: [329/484] Iter:[330/495], Time: 0.37, lr: [0.0035748097781648476], Loss: 1.999052, Acc:0.798487, Semantic loss: 0.757401, BCE loss: 0.525143, SB loss: 0.716508
2023-10-30 18:24:49,526 Epoch: [329/484] Iter:[340/495], Time: 0.37, lr: [0.003574388631511459], Loss: 1.998822, Acc:0.797884, Semantic loss: 0.756206, BCE loss: 0.525846, SB loss: 0.716770
2023-10-30 18:24:53,238 Epoch: [329/484] Iter:[350/495], Time: 0.37, lr: [0.0035739674793445627], Loss: 1.996545, Acc:0.797832, Semantic loss: 0.755671, BCE loss: 0.524186, SB loss: 0.716689
2023-10-30 18:24:56,933 Epoch: [329/484] Iter:[360/495], Time: 0.37, lr: [0.0035735463216633625], Loss: 1.995764, Acc:0.798669, Semantic loss: 0.755279, BCE loss: 0.524279, SB loss: 0.716207
2023-10-30 18:25:00,621 Epoch: [329/484] Iter:[370/495], Time: 0.37, lr: [0.003573125158467065], Loss: 1.997482, Acc:0.799037, Semantic loss: 0.755667, BCE loss: 0.525967, SB loss: 0.715849
2023-10-30 18:25:04,298 Epoch: [329/484] Iter:[380/495], Time: 0.37, lr: [0.0035727039897548735], Loss: 1.994890, Acc:0.799964, Semantic loss: 0.754535, BCE loss: 0.525435, SB loss: 0.714920
2023-10-30 18:25:07,968 Epoch: [329/484] Iter:[390/495], Time: 0.37, lr: [0.003572282815525996], Loss: 1.993241, Acc:0.800141, Semantic loss: 0.753528, BCE loss: 0.525258, SB loss: 0.714456
2023-10-30 18:25:11,652 Epoch: [329/484] Iter:[400/495], Time: 0.37, lr: [0.0035718616357796372], Loss: 1.990457, Acc:0.800683, Semantic loss: 0.752201, BCE loss: 0.524705, SB loss: 0.713552
2023-10-30 18:25:15,328 Epoch: [329/484] Iter:[410/495], Time: 0.37, lr: [0.003571440450515001], Loss: 1.995655, Acc:0.800489, Semantic loss: 0.755750, BCE loss: 0.525681, SB loss: 0.714223
2023-10-30 18:25:19,104 Epoch: [329/484] Iter:[420/495], Time: 0.37, lr: [0.0035710192597312907], Loss: 1.995295, Acc:0.800664, Semantic loss: 0.755410, BCE loss: 0.525494, SB loss: 0.714391
2023-10-30 18:25:22,962 Epoch: [329/484] Iter:[430/495], Time: 0.37, lr: [0.0035705980634277135], Loss: 1.993692, Acc:0.801532, Semantic loss: 0.753580, BCE loss: 0.526015, SB loss: 0.714097
2023-10-30 18:25:26,645 Epoch: [329/484] Iter:[440/495], Time: 0.37, lr: [0.0035701768616034726], Loss: 1.994125, Acc:0.801455, Semantic loss: 0.754178, BCE loss: 0.525612, SB loss: 0.714335
2023-10-30 18:25:30,298 Epoch: [329/484] Iter:[450/495], Time: 0.37, lr: [0.003569755654257771], Loss: 1.992932, Acc:0.801287, Semantic loss: 0.753492, BCE loss: 0.525094, SB loss: 0.714346
2023-10-30 18:25:34,092 Epoch: [329/484] Iter:[460/495], Time: 0.37, lr: [0.0035693344413898127], Loss: 1.991205, Acc:0.801104, Semantic loss: 0.752793, BCE loss: 0.524356, SB loss: 0.714055
2023-10-30 18:25:37,696 Epoch: [329/484] Iter:[470/495], Time: 0.37, lr: [0.003568913222998802], Loss: 1.991704, Acc:0.801171, Semantic loss: 0.752553, BCE loss: 0.524871, SB loss: 0.714280
2023-10-30 18:25:41,309 Epoch: [329/484] Iter:[480/495], Time: 0.37, lr: [0.0035684919990839415], Loss: 1.989623, Acc:0.801310, Semantic loss: 0.751999, BCE loss: 0.523717, SB loss: 0.713907
2023-10-30 18:25:44,800 Epoch: [329/484] Iter:[490/495], Time: 0.37, lr: [0.0035680707696444346], Loss: 1.988066, Acc:0.801010, Semantic loss: 0.751901, BCE loss: 0.522555, SB loss: 0.713609
2023-10-30 18:25:46,194 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:25:46,422 Loss: 2.056, MeanIU:  0.6961, Best_mIoU:  0.7309
2023-10-30 18:25:46,422 [0.97706202 0.82416668 0.90886047 0.48839144 0.56913168 0.60349218
 0.66891929 0.73748085 0.91400231 0.6205787  0.93379618 0.75971329
 0.56241336 0.93027158 0.6593744  0.65610928 0.21262714 0.46921987
 0.7300564 ]
2023-10-30 18:25:48,284 Epoch: [330/484] Iter:[0/495], Time: 1.83, lr: [0.0035678601528526892], Loss: 1.944549, Acc:0.840248, Semantic loss: 0.731337, BCE loss: 0.523791, SB loss: 0.689422
2023-10-30 18:25:52,399 Epoch: [330/484] Iter:[10/495], Time: 0.54, lr: [0.0035674389151247174], Loss: 1.846856, Acc:0.776758, Semantic loss: 0.707253, BCE loss: 0.470155, SB loss: 0.669448
2023-10-30 18:25:56,007 Epoch: [330/484] Iter:[20/495], Time: 0.45, lr: [0.003567017671870106], Loss: 1.904697, Acc:0.808892, Semantic loss: 0.725874, BCE loss: 0.487203, SB loss: 0.691621
2023-10-30 18:25:59,664 Epoch: [330/484] Iter:[30/495], Time: 0.43, lr: [0.0035665964230880563], Loss: 1.978744, Acc:0.790836, Semantic loss: 0.750053, BCE loss: 0.522583, SB loss: 0.706107
2023-10-30 18:26:03,230 Epoch: [330/484] Iter:[40/495], Time: 0.41, lr: [0.003566175168777772], Loss: 2.012707, Acc:0.791597, Semantic loss: 0.774872, BCE loss: 0.525219, SB loss: 0.712615
2023-10-30 18:26:06,900 Epoch: [330/484] Iter:[50/495], Time: 0.40, lr: [0.0035657539089384528], Loss: 1.978186, Acc:0.797409, Semantic loss: 0.758166, BCE loss: 0.515081, SB loss: 0.704939
2023-10-30 18:26:10,525 Epoch: [330/484] Iter:[60/495], Time: 0.39, lr: [0.0035653326435693025], Loss: 1.976708, Acc:0.795413, Semantic loss: 0.760718, BCE loss: 0.508683, SB loss: 0.707307
2023-10-30 18:26:14,234 Epoch: [330/484] Iter:[70/495], Time: 0.39, lr: [0.0035649113726695216], Loss: 1.975564, Acc:0.800011, Semantic loss: 0.751047, BCE loss: 0.512911, SB loss: 0.711606
2023-10-30 18:26:17,921 Epoch: [330/484] Iter:[80/495], Time: 0.39, lr: [0.0035644900962383116], Loss: 1.955771, Acc:0.798772, Semantic loss: 0.738743, BCE loss: 0.508276, SB loss: 0.708752
2023-10-30 18:26:21,535 Epoch: [330/484] Iter:[90/495], Time: 0.39, lr: [0.0035640688142748716], Loss: 1.954340, Acc:0.796212, Semantic loss: 0.735985, BCE loss: 0.509335, SB loss: 0.709019
2023-10-30 18:26:25,196 Epoch: [330/484] Iter:[100/495], Time: 0.38, lr: [0.003563647526778405], Loss: 1.953977, Acc:0.795743, Semantic loss: 0.734869, BCE loss: 0.509379, SB loss: 0.709729
2023-10-30 18:26:28,829 Epoch: [330/484] Iter:[110/495], Time: 0.38, lr: [0.003563226233748111], Loss: 1.944323, Acc:0.795072, Semantic loss: 0.729033, BCE loss: 0.509170, SB loss: 0.706119
2023-10-30 18:26:32,451 Epoch: [330/484] Iter:[120/495], Time: 0.38, lr: [0.0035628049351831906], Loss: 1.943986, Acc:0.796324, Semantic loss: 0.729003, BCE loss: 0.509832, SB loss: 0.705151
2023-10-30 18:26:36,080 Epoch: [330/484] Iter:[130/495], Time: 0.38, lr: [0.0035623836310828424], Loss: 1.944000, Acc:0.795740, Semantic loss: 0.728673, BCE loss: 0.508604, SB loss: 0.706723
2023-10-30 18:26:39,699 Epoch: [330/484] Iter:[140/495], Time: 0.38, lr: [0.0035619623214462677], Loss: 1.941962, Acc:0.794470, Semantic loss: 0.728685, BCE loss: 0.506523, SB loss: 0.706754
2023-10-30 18:26:43,390 Epoch: [330/484] Iter:[150/495], Time: 0.38, lr: [0.003561541006272666], Loss: 1.942494, Acc:0.795312, Semantic loss: 0.728385, BCE loss: 0.506854, SB loss: 0.707255
2023-10-30 18:26:47,018 Epoch: [330/484] Iter:[160/495], Time: 0.38, lr: [0.0035611196855612356], Loss: 1.949421, Acc:0.794393, Semantic loss: 0.732883, BCE loss: 0.508076, SB loss: 0.708462
2023-10-30 18:26:50,576 Epoch: [330/484] Iter:[170/495], Time: 0.37, lr: [0.0035606983593111773], Loss: 1.957454, Acc:0.795778, Semantic loss: 0.733803, BCE loss: 0.515284, SB loss: 0.708367
2023-10-30 18:26:54,205 Epoch: [330/484] Iter:[180/495], Time: 0.37, lr: [0.0035602770275216895], Loss: 1.959976, Acc:0.795201, Semantic loss: 0.734117, BCE loss: 0.515413, SB loss: 0.710446
2023-10-30 18:26:57,852 Epoch: [330/484] Iter:[190/495], Time: 0.37, lr: [0.00355985569019197], Loss: 1.956271, Acc:0.795999, Semantic loss: 0.733018, BCE loss: 0.512674, SB loss: 0.710579
2023-10-30 18:27:01,453 Epoch: [330/484] Iter:[200/495], Time: 0.37, lr: [0.003559434347321218], Loss: 1.956688, Acc:0.797115, Semantic loss: 0.733773, BCE loss: 0.512375, SB loss: 0.710540
2023-10-30 18:27:05,109 Epoch: [330/484] Iter:[210/495], Time: 0.37, lr: [0.003559012998908633], Loss: 1.960820, Acc:0.798831, Semantic loss: 0.734431, BCE loss: 0.514481, SB loss: 0.711908
2023-10-30 18:27:08,765 Epoch: [330/484] Iter:[220/495], Time: 0.37, lr: [0.003558591644953412], Loss: 1.959028, Acc:0.798510, Semantic loss: 0.734653, BCE loss: 0.513172, SB loss: 0.711202
2023-10-30 18:27:12,426 Epoch: [330/484] Iter:[230/495], Time: 0.37, lr: [0.0035581702854547525], Loss: 1.957725, Acc:0.800444, Semantic loss: 0.734562, BCE loss: 0.512842, SB loss: 0.710322
2023-10-30 18:27:16,029 Epoch: [330/484] Iter:[240/495], Time: 0.37, lr: [0.0035577489204118525], Loss: 1.960099, Acc:0.802626, Semantic loss: 0.735061, BCE loss: 0.514070, SB loss: 0.710967
2023-10-30 18:27:19,637 Epoch: [330/484] Iter:[250/495], Time: 0.37, lr: [0.0035573275498239094], Loss: 1.957314, Acc:0.801613, Semantic loss: 0.735504, BCE loss: 0.512052, SB loss: 0.709758
2023-10-30 18:27:23,400 Epoch: [330/484] Iter:[260/495], Time: 0.37, lr: [0.0035569061736901207], Loss: 1.953560, Acc:0.802381, Semantic loss: 0.733594, BCE loss: 0.511795, SB loss: 0.708171
2023-10-30 18:27:27,001 Epoch: [330/484] Iter:[270/495], Time: 0.37, lr: [0.003556484792009684], Loss: 1.957669, Acc:0.803498, Semantic loss: 0.735073, BCE loss: 0.514050, SB loss: 0.708546
2023-10-30 18:27:30,554 Epoch: [330/484] Iter:[280/495], Time: 0.37, lr: [0.0035560634047817935], Loss: 1.958020, Acc:0.803846, Semantic loss: 0.734258, BCE loss: 0.515183, SB loss: 0.708579
2023-10-30 18:27:34,166 Epoch: [330/484] Iter:[290/495], Time: 0.37, lr: [0.0035556420120056486], Loss: 1.960924, Acc:0.803666, Semantic loss: 0.735935, BCE loss: 0.516030, SB loss: 0.708959
2023-10-30 18:27:37,797 Epoch: [330/484] Iter:[300/495], Time: 0.37, lr: [0.003555220613680445], Loss: 1.957797, Acc:0.803273, Semantic loss: 0.735009, BCE loss: 0.513877, SB loss: 0.708911
2023-10-30 18:27:41,574 Epoch: [330/484] Iter:[310/495], Time: 0.37, lr: [0.0035547992098053783], Loss: 1.957551, Acc:0.804556, Semantic loss: 0.732810, BCE loss: 0.516062, SB loss: 0.708679
2023-10-30 18:27:45,131 Epoch: [330/484] Iter:[320/495], Time: 0.37, lr: [0.003554377800379643], Loss: 1.956079, Acc:0.804676, Semantic loss: 0.732964, BCE loss: 0.513166, SB loss: 0.709948
2023-10-30 18:27:48,768 Epoch: [330/484] Iter:[330/495], Time: 0.37, lr: [0.0035539563854024374], Loss: 1.954359, Acc:0.804054, Semantic loss: 0.732685, BCE loss: 0.511803, SB loss: 0.709872
2023-10-30 18:27:52,505 Epoch: [330/484] Iter:[340/495], Time: 0.37, lr: [0.003553534964872956], Loss: 1.955626, Acc:0.804301, Semantic loss: 0.732920, BCE loss: 0.512574, SB loss: 0.710132
2023-10-30 18:27:56,209 Epoch: [330/484] Iter:[350/495], Time: 0.37, lr: [0.0035531135387903935], Loss: 1.958864, Acc:0.804302, Semantic loss: 0.734758, BCE loss: 0.513365, SB loss: 0.710741
2023-10-30 18:27:59,819 Epoch: [330/484] Iter:[360/495], Time: 0.37, lr: [0.003552692107153944], Loss: 1.960936, Acc:0.804462, Semantic loss: 0.735588, BCE loss: 0.514455, SB loss: 0.710893
2023-10-30 18:28:03,487 Epoch: [330/484] Iter:[370/495], Time: 0.37, lr: [0.003552270669962804], Loss: 1.960928, Acc:0.803523, Semantic loss: 0.736128, BCE loss: 0.514371, SB loss: 0.710428
2023-10-30 18:28:07,076 Epoch: [330/484] Iter:[380/495], Time: 0.37, lr: [0.0035518492272161683], Loss: 1.956708, Acc:0.803746, Semantic loss: 0.733674, BCE loss: 0.513328, SB loss: 0.709707
2023-10-30 18:28:10,816 Epoch: [330/484] Iter:[390/495], Time: 0.37, lr: [0.0035514277789132297], Loss: 1.954994, Acc:0.802857, Semantic loss: 0.732987, BCE loss: 0.512455, SB loss: 0.709552
2023-10-30 18:28:14,512 Epoch: [330/484] Iter:[400/495], Time: 0.37, lr: [0.003551006325053182], Loss: 1.955669, Acc:0.803579, Semantic loss: 0.733375, BCE loss: 0.512769, SB loss: 0.709525
2023-10-30 18:28:18,287 Epoch: [330/484] Iter:[410/495], Time: 0.37, lr: [0.0035505848656352213], Loss: 1.958066, Acc:0.802738, Semantic loss: 0.734302, BCE loss: 0.513622, SB loss: 0.710142
2023-10-30 18:28:21,980 Epoch: [330/484] Iter:[420/495], Time: 0.37, lr: [0.0035501634006585396], Loss: 1.962177, Acc:0.802753, Semantic loss: 0.736253, BCE loss: 0.515302, SB loss: 0.710622
2023-10-30 18:28:25,663 Epoch: [330/484] Iter:[430/495], Time: 0.37, lr: [0.0035497419301223315], Loss: 1.960354, Acc:0.801666, Semantic loss: 0.736692, BCE loss: 0.513593, SB loss: 0.710068
2023-10-30 18:28:29,363 Epoch: [330/484] Iter:[440/495], Time: 0.37, lr: [0.003549320454025788], Loss: 1.956626, Acc:0.801283, Semantic loss: 0.734504, BCE loss: 0.512372, SB loss: 0.709750
2023-10-30 18:28:33,014 Epoch: [330/484] Iter:[450/495], Time: 0.37, lr: [0.0035488989723681044], Loss: 1.956166, Acc:0.801517, Semantic loss: 0.733954, BCE loss: 0.512463, SB loss: 0.709749
2023-10-30 18:28:36,647 Epoch: [330/484] Iter:[460/495], Time: 0.37, lr: [0.0035484774851484717], Loss: 1.956437, Acc:0.801480, Semantic loss: 0.734650, BCE loss: 0.511995, SB loss: 0.709792
2023-10-30 18:28:40,440 Epoch: [330/484] Iter:[470/495], Time: 0.37, lr: [0.0035480559923660843], Loss: 1.955176, Acc:0.801610, Semantic loss: 0.733519, BCE loss: 0.511978, SB loss: 0.709678
2023-10-30 18:28:44,076 Epoch: [330/484] Iter:[480/495], Time: 0.37, lr: [0.003547634494020132], Loss: 1.958920, Acc:0.802531, Semantic loss: 0.734650, BCE loss: 0.514340, SB loss: 0.709930
2023-10-30 18:28:47,596 Epoch: [330/484] Iter:[490/495], Time: 0.37, lr: [0.00354721299010981], Loss: 1.960033, Acc:0.802573, Semantic loss: 0.735771, BCE loss: 0.513922, SB loss: 0.710340
2023-10-30 18:31:44,278 0 [0.94436815 0.67475766 0.83029545 0.18630426 0.3030395  0.43001036
 0.46526352 0.60341731 0.88805103 0.47500618 0.81228569 0.62526618
 0.03705699 0.82860058 0.00222763 0.17348706 0.08681358 0.04793197
 0.60888271] 0.4748981999686123
2023-10-30 18:31:44,278 1 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576] 0.7192851727098679
2023-10-30 18:31:44,282 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:31:44,521 Loss: 2.034, MeanIU:  0.7193, Best_mIoU:  0.7309
2023-10-30 18:31:44,521 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576]
2023-10-30 18:31:46,791 Epoch: [331/484] Iter:[0/495], Time: 2.24, lr: [0.0035470022360677565], Loss: 1.874321, Acc:0.834977, Semantic loss: 0.646646, BCE loss: 0.568795, SB loss: 0.658880
2023-10-30 18:31:50,615 Epoch: [331/484] Iter:[10/495], Time: 0.55, lr: [0.0035465807238093615], Loss: 1.945309, Acc:0.818185, Semantic loss: 0.691910, BCE loss: 0.552700, SB loss: 0.700700
2023-10-30 18:31:54,216 Epoch: [331/484] Iter:[20/495], Time: 0.46, lr: [0.0035461592059845737], Loss: 1.947266, Acc:0.824212, Semantic loss: 0.734246, BCE loss: 0.517098, SB loss: 0.695922
2023-10-30 18:31:57,652 Epoch: [331/484] Iter:[30/495], Time: 0.42, lr: [0.0035457376825925864], Loss: 1.944851, Acc:0.809495, Semantic loss: 0.747114, BCE loss: 0.502503, SB loss: 0.695234
2023-10-30 18:32:01,106 Epoch: [331/484] Iter:[40/495], Time: 0.40, lr: [0.0035453161536325886], Loss: 1.976409, Acc:0.815121, Semantic loss: 0.753853, BCE loss: 0.518099, SB loss: 0.704457
2023-10-30 18:32:04,702 Epoch: [331/484] Iter:[50/495], Time: 0.40, lr: [0.0035448946191037724], Loss: 1.981135, Acc:0.808509, Semantic loss: 0.755785, BCE loss: 0.516705, SB loss: 0.708646
2023-10-30 18:32:08,085 Epoch: [331/484] Iter:[60/495], Time: 0.39, lr: [0.0035444730790053264], Loss: 1.979130, Acc:0.806373, Semantic loss: 0.757911, BCE loss: 0.512758, SB loss: 0.708461
2023-10-30 18:32:11,558 Epoch: [331/484] Iter:[70/495], Time: 0.38, lr: [0.0035440515333364443], Loss: 1.996076, Acc:0.802835, Semantic loss: 0.760607, BCE loss: 0.521991, SB loss: 0.713478
2023-10-30 18:32:14,996 Epoch: [331/484] Iter:[80/495], Time: 0.38, lr: [0.003543629982096314], Loss: 1.990041, Acc:0.801335, Semantic loss: 0.752840, BCE loss: 0.525051, SB loss: 0.712150
2023-10-30 18:32:18,576 Epoch: [331/484] Iter:[90/495], Time: 0.37, lr: [0.0035432084252841264], Loss: 1.993621, Acc:0.803518, Semantic loss: 0.760016, BCE loss: 0.520155, SB loss: 0.713450
2023-10-30 18:32:22,127 Epoch: [331/484] Iter:[100/495], Time: 0.37, lr: [0.003542786862899069], Loss: 1.985461, Acc:0.802495, Semantic loss: 0.753684, BCE loss: 0.521047, SB loss: 0.710730
2023-10-30 18:32:25,688 Epoch: [331/484] Iter:[110/495], Time: 0.37, lr: [0.0035423652949403348], Loss: 1.995898, Acc:0.801059, Semantic loss: 0.758891, BCE loss: 0.523261, SB loss: 0.713746
2023-10-30 18:32:29,275 Epoch: [331/484] Iter:[120/495], Time: 0.37, lr: [0.003541943721407111], Loss: 1.996100, Acc:0.797253, Semantic loss: 0.758179, BCE loss: 0.522145, SB loss: 0.715775
2023-10-30 18:32:32,888 Epoch: [331/484] Iter:[130/495], Time: 0.37, lr: [0.003541522142298587], Loss: 1.987988, Acc:0.799258, Semantic loss: 0.755113, BCE loss: 0.518553, SB loss: 0.714322
2023-10-30 18:32:36,463 Epoch: [331/484] Iter:[140/495], Time: 0.37, lr: [0.003541100557613951], Loss: 1.986872, Acc:0.798463, Semantic loss: 0.752521, BCE loss: 0.519431, SB loss: 0.714920
2023-10-30 18:32:40,155 Epoch: [331/484] Iter:[150/495], Time: 0.37, lr: [0.0035406789673523933], Loss: 1.992382, Acc:0.799037, Semantic loss: 0.751790, BCE loss: 0.527274, SB loss: 0.713317
2023-10-30 18:32:43,895 Epoch: [331/484] Iter:[160/495], Time: 0.37, lr: [0.003540257371513101], Loss: 2.002562, Acc:0.798470, Semantic loss: 0.759537, BCE loss: 0.526996, SB loss: 0.716029
2023-10-30 18:32:47,578 Epoch: [331/484] Iter:[170/495], Time: 0.37, lr: [0.0035398357700952626], Loss: 1.998991, Acc:0.798754, Semantic loss: 0.755615, BCE loss: 0.526998, SB loss: 0.716378
2023-10-30 18:32:51,315 Epoch: [331/484] Iter:[180/495], Time: 0.37, lr: [0.003539414163098065], Loss: 1.993294, Acc:0.798269, Semantic loss: 0.752294, BCE loss: 0.526033, SB loss: 0.714967
2023-10-30 18:32:55,005 Epoch: [331/484] Iter:[190/495], Time: 0.37, lr: [0.0035389925505206975], Loss: 1.992976, Acc:0.799421, Semantic loss: 0.751110, BCE loss: 0.527530, SB loss: 0.714337
2023-10-30 18:32:58,566 Epoch: [331/484] Iter:[200/495], Time: 0.37, lr: [0.003538570932362347], Loss: 1.990809, Acc:0.800334, Semantic loss: 0.751111, BCE loss: 0.526030, SB loss: 0.713668
2023-10-30 18:33:02,293 Epoch: [331/484] Iter:[210/495], Time: 0.37, lr: [0.0035381493086222007], Loss: 1.986140, Acc:0.799792, Semantic loss: 0.748790, BCE loss: 0.524331, SB loss: 0.713020
2023-10-30 18:33:06,103 Epoch: [331/484] Iter:[220/495], Time: 0.37, lr: [0.0035377276792994444], Loss: 1.979535, Acc:0.800035, Semantic loss: 0.745625, BCE loss: 0.523114, SB loss: 0.710796
2023-10-30 18:33:09,667 Epoch: [331/484] Iter:[230/495], Time: 0.37, lr: [0.0035373060443932673], Loss: 1.979768, Acc:0.801125, Semantic loss: 0.743341, BCE loss: 0.526517, SB loss: 0.709910
2023-10-30 18:33:13,377 Epoch: [331/484] Iter:[240/495], Time: 0.37, lr: [0.003536884403902855], Loss: 1.976346, Acc:0.802702, Semantic loss: 0.740201, BCE loss: 0.527287, SB loss: 0.708859
2023-10-30 18:33:16,984 Epoch: [331/484] Iter:[250/495], Time: 0.37, lr: [0.0035364627578273926], Loss: 1.976568, Acc:0.802768, Semantic loss: 0.741717, BCE loss: 0.525199, SB loss: 0.709652
2023-10-30 18:33:20,742 Epoch: [331/484] Iter:[260/495], Time: 0.37, lr: [0.003536041106166067], Loss: 1.976763, Acc:0.801677, Semantic loss: 0.741318, BCE loss: 0.525518, SB loss: 0.709927
2023-10-30 18:33:24,320 Epoch: [331/484] Iter:[270/495], Time: 0.37, lr: [0.0035356194489180653], Loss: 1.980912, Acc:0.800599, Semantic loss: 0.744051, BCE loss: 0.526441, SB loss: 0.710421
2023-10-30 18:33:28,044 Epoch: [331/484] Iter:[280/495], Time: 0.37, lr: [0.0035351977860825718], Loss: 1.982566, Acc:0.800900, Semantic loss: 0.744758, BCE loss: 0.526952, SB loss: 0.710855
2023-10-30 18:33:31,768 Epoch: [331/484] Iter:[290/495], Time: 0.37, lr: [0.0035347761176587724], Loss: 1.986058, Acc:0.801654, Semantic loss: 0.744253, BCE loss: 0.530359, SB loss: 0.711446
2023-10-30 18:33:35,307 Epoch: [331/484] Iter:[300/495], Time: 0.37, lr: [0.0035343544436458514], Loss: 1.983897, Acc:0.802197, Semantic loss: 0.743267, BCE loss: 0.529707, SB loss: 0.710923
2023-10-30 18:33:39,102 Epoch: [331/484] Iter:[310/495], Time: 0.37, lr: [0.003533932764042995], Loss: 1.978937, Acc:0.802736, Semantic loss: 0.741433, BCE loss: 0.527236, SB loss: 0.710269
2023-10-30 18:33:42,931 Epoch: [331/484] Iter:[320/495], Time: 0.37, lr: [0.003533511078849388], Loss: 1.980932, Acc:0.802795, Semantic loss: 0.741761, BCE loss: 0.528120, SB loss: 0.711052
2023-10-30 18:33:46,628 Epoch: [331/484] Iter:[330/495], Time: 0.37, lr: [0.0035330893880642146], Loss: 1.976944, Acc:0.803754, Semantic loss: 0.740357, BCE loss: 0.526923, SB loss: 0.709664
2023-10-30 18:33:50,254 Epoch: [331/484] Iter:[340/495], Time: 0.37, lr: [0.0035326676916866574], Loss: 1.976037, Acc:0.803166, Semantic loss: 0.740723, BCE loss: 0.525531, SB loss: 0.709783
2023-10-30 18:33:54,002 Epoch: [331/484] Iter:[350/495], Time: 0.37, lr: [0.0035322459897159032], Loss: 1.976394, Acc:0.802449, Semantic loss: 0.742399, BCE loss: 0.523777, SB loss: 0.710218
2023-10-30 18:33:57,613 Epoch: [331/484] Iter:[360/495], Time: 0.37, lr: [0.0035318242821511347], Loss: 1.977899, Acc:0.801733, Semantic loss: 0.743288, BCE loss: 0.524412, SB loss: 0.710199
2023-10-30 18:34:01,217 Epoch: [331/484] Iter:[370/495], Time: 0.37, lr: [0.0035314025689915356], Loss: 1.974180, Acc:0.801163, Semantic loss: 0.741681, BCE loss: 0.522823, SB loss: 0.709675
2023-10-30 18:34:04,940 Epoch: [331/484] Iter:[380/495], Time: 0.37, lr: [0.0035309808502362885], Loss: 1.974607, Acc:0.801335, Semantic loss: 0.742708, BCE loss: 0.522623, SB loss: 0.709276
2023-10-30 18:34:08,594 Epoch: [331/484] Iter:[390/495], Time: 0.37, lr: [0.0035305591258845783], Loss: 1.975348, Acc:0.800666, Semantic loss: 0.742555, BCE loss: 0.523004, SB loss: 0.709790
2023-10-30 18:34:12,210 Epoch: [331/484] Iter:[400/495], Time: 0.37, lr: [0.0035301373959355864], Loss: 1.974027, Acc:0.799985, Semantic loss: 0.742263, BCE loss: 0.522357, SB loss: 0.709407
2023-10-30 18:34:15,826 Epoch: [331/484] Iter:[410/495], Time: 0.37, lr: [0.003529715660388496], Loss: 1.973577, Acc:0.799951, Semantic loss: 0.743032, BCE loss: 0.520363, SB loss: 0.710183
2023-10-30 18:34:19,646 Epoch: [331/484] Iter:[420/495], Time: 0.37, lr: [0.0035292939192424887], Loss: 1.972123, Acc:0.800602, Semantic loss: 0.741068, BCE loss: 0.521543, SB loss: 0.709511
2023-10-30 18:34:23,314 Epoch: [331/484] Iter:[430/495], Time: 0.37, lr: [0.0035288721724967493], Loss: 1.969903, Acc:0.801185, Semantic loss: 0.739616, BCE loss: 0.521222, SB loss: 0.709065
2023-10-30 18:34:27,066 Epoch: [331/484] Iter:[440/495], Time: 0.37, lr: [0.0035284504201504576], Loss: 1.972655, Acc:0.800827, Semantic loss: 0.740576, BCE loss: 0.522126, SB loss: 0.709953
2023-10-30 18:34:30,722 Epoch: [331/484] Iter:[450/495], Time: 0.37, lr: [0.0035280286622027955], Loss: 1.974418, Acc:0.801173, Semantic loss: 0.741432, BCE loss: 0.523412, SB loss: 0.709574
2023-10-30 18:34:34,411 Epoch: [331/484] Iter:[460/495], Time: 0.37, lr: [0.0035276068986529446], Loss: 1.975539, Acc:0.801710, Semantic loss: 0.741547, BCE loss: 0.524007, SB loss: 0.709985
2023-10-30 18:34:38,099 Epoch: [331/484] Iter:[470/495], Time: 0.37, lr: [0.0035271851295000877], Loss: 1.973402, Acc:0.802295, Semantic loss: 0.740270, BCE loss: 0.523867, SB loss: 0.709265
2023-10-30 18:34:41,795 Epoch: [331/484] Iter:[480/495], Time: 0.37, lr: [0.0035267633547434053], Loss: 1.971133, Acc:0.802344, Semantic loss: 0.739210, BCE loss: 0.522927, SB loss: 0.708995
2023-10-30 18:34:45,310 Epoch: [331/484] Iter:[490/495], Time: 0.37, lr: [0.0035263415743820776], Loss: 1.971405, Acc:0.802780, Semantic loss: 0.738987, BCE loss: 0.523463, SB loss: 0.708955
2023-10-30 18:34:46,710 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:34:46,945 Loss: 2.034, MeanIU:  0.7193, Best_mIoU:  0.7309
2023-10-30 18:34:46,945 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576]
2023-10-30 18:34:49,123 Epoch: [332/484] Iter:[0/495], Time: 2.15, lr: [0.0035261306820994144], Loss: 2.026422, Acc:0.746902, Semantic loss: 0.759447, BCE loss: 0.570605, SB loss: 0.696370
2023-10-30 18:34:53,090 Epoch: [332/484] Iter:[10/495], Time: 0.56, lr: [0.003525708893329583], Loss: 2.001595, Acc:0.822511, Semantic loss: 0.757440, BCE loss: 0.554232, SB loss: 0.689923
2023-10-30 18:34:56,844 Epoch: [332/484] Iter:[20/495], Time: 0.47, lr: [0.0035252870989530573], Loss: 1.895583, Acc:0.796697, Semantic loss: 0.705805, BCE loss: 0.514547, SB loss: 0.675231
2023-10-30 18:35:00,603 Epoch: [332/484] Iter:[30/495], Time: 0.44, lr: [0.0035248652989690182], Loss: 1.908044, Acc:0.809136, Semantic loss: 0.709695, BCE loss: 0.513998, SB loss: 0.684350
2023-10-30 18:35:04,227 Epoch: [332/484] Iter:[40/495], Time: 0.42, lr: [0.0035244434933766437], Loss: 1.917887, Acc:0.810738, Semantic loss: 0.714960, BCE loss: 0.520269, SB loss: 0.682658
2023-10-30 18:35:08,029 Epoch: [332/484] Iter:[50/495], Time: 0.41, lr: [0.0035240216821751163], Loss: 1.926303, Acc:0.811408, Semantic loss: 0.719439, BCE loss: 0.516659, SB loss: 0.690205
2023-10-30 18:35:11,667 Epoch: [332/484] Iter:[60/495], Time: 0.40, lr: [0.0035235998653636146], Loss: 1.930114, Acc:0.811033, Semantic loss: 0.717157, BCE loss: 0.522513, SB loss: 0.690444
2023-10-30 18:35:15,437 Epoch: [332/484] Iter:[70/495], Time: 0.40, lr: [0.003523178042941317], Loss: 1.947319, Acc:0.812237, Semantic loss: 0.725678, BCE loss: 0.524805, SB loss: 0.696836
2023-10-30 18:35:19,091 Epoch: [332/484] Iter:[80/495], Time: 0.40, lr: [0.003522756214907401], Loss: 1.945587, Acc:0.814538, Semantic loss: 0.725694, BCE loss: 0.524098, SB loss: 0.695795
2023-10-30 18:35:22,655 Epoch: [332/484] Iter:[90/495], Time: 0.39, lr: [0.0035223343812610486], Loss: 1.929734, Acc:0.810782, Semantic loss: 0.721572, BCE loss: 0.516354, SB loss: 0.691808
2023-10-30 18:35:26,250 Epoch: [332/484] Iter:[100/495], Time: 0.39, lr: [0.0035219125420014362], Loss: 1.952969, Acc:0.809651, Semantic loss: 0.733852, BCE loss: 0.519843, SB loss: 0.699273
2023-10-30 18:35:30,057 Epoch: [332/484] Iter:[110/495], Time: 0.39, lr: [0.003521490697127743], Loss: 1.946283, Acc:0.809965, Semantic loss: 0.728360, BCE loss: 0.519730, SB loss: 0.698194
2023-10-30 18:35:33,877 Epoch: [332/484] Iter:[120/495], Time: 0.39, lr: [0.0035210688466391455], Loss: 1.938754, Acc:0.808449, Semantic loss: 0.724864, BCE loss: 0.517796, SB loss: 0.696094
2023-10-30 18:35:37,664 Epoch: [332/484] Iter:[130/495], Time: 0.39, lr: [0.003520646990534823], Loss: 1.942223, Acc:0.809237, Semantic loss: 0.728763, BCE loss: 0.517584, SB loss: 0.695877
2023-10-30 18:35:41,434 Epoch: [332/484] Iter:[140/495], Time: 0.39, lr: [0.0035202251288139535], Loss: 1.937475, Acc:0.811791, Semantic loss: 0.725337, BCE loss: 0.517883, SB loss: 0.694255
2023-10-30 18:35:45,243 Epoch: [332/484] Iter:[150/495], Time: 0.39, lr: [0.003519803261475713], Loss: 1.936312, Acc:0.812499, Semantic loss: 0.724770, BCE loss: 0.515260, SB loss: 0.696281
2023-10-30 18:35:48,926 Epoch: [332/484] Iter:[160/495], Time: 0.38, lr: [0.0035193813885192778], Loss: 1.943629, Acc:0.813735, Semantic loss: 0.726229, BCE loss: 0.519580, SB loss: 0.697819
2023-10-30 18:35:52,691 Epoch: [332/484] Iter:[170/495], Time: 0.38, lr: [0.003518959509943827], Loss: 1.939738, Acc:0.812250, Semantic loss: 0.724092, BCE loss: 0.516664, SB loss: 0.698982
2023-10-30 18:35:56,306 Epoch: [332/484] Iter:[180/495], Time: 0.38, lr: [0.0035185376257485363], Loss: 1.941929, Acc:0.812494, Semantic loss: 0.723820, BCE loss: 0.517114, SB loss: 0.700995
2023-10-30 18:35:59,943 Epoch: [332/484] Iter:[190/495], Time: 0.38, lr: [0.0035181157359325823], Loss: 1.946818, Acc:0.810405, Semantic loss: 0.727065, BCE loss: 0.517927, SB loss: 0.701826
2023-10-30 18:36:03,614 Epoch: [332/484] Iter:[200/495], Time: 0.38, lr: [0.0035176938404951393], Loss: 1.946135, Acc:0.809146, Semantic loss: 0.728178, BCE loss: 0.514984, SB loss: 0.702973
2023-10-30 18:36:07,262 Epoch: [332/484] Iter:[210/495], Time: 0.38, lr: [0.0035172719394353865], Loss: 1.944110, Acc:0.809221, Semantic loss: 0.726867, BCE loss: 0.514561, SB loss: 0.702682
2023-10-30 18:36:10,950 Epoch: [332/484] Iter:[220/495], Time: 0.38, lr: [0.0035168500327524975], Loss: 1.947504, Acc:0.808538, Semantic loss: 0.726727, BCE loss: 0.517485, SB loss: 0.703292
2023-10-30 18:36:14,614 Epoch: [332/484] Iter:[230/495], Time: 0.38, lr: [0.003516428120445649], Loss: 1.946052, Acc:0.808175, Semantic loss: 0.725754, BCE loss: 0.517040, SB loss: 0.703257
2023-10-30 18:36:18,415 Epoch: [332/484] Iter:[240/495], Time: 0.38, lr: [0.0035160062025140133], Loss: 1.949988, Acc:0.807333, Semantic loss: 0.727239, BCE loss: 0.518202, SB loss: 0.704547
2023-10-30 18:36:22,046 Epoch: [332/484] Iter:[250/495], Time: 0.38, lr: [0.00351558427895677], Loss: 1.951771, Acc:0.807463, Semantic loss: 0.728229, BCE loss: 0.519405, SB loss: 0.704137
2023-10-30 18:36:25,824 Epoch: [332/484] Iter:[260/495], Time: 0.38, lr: [0.0035151623497730908], Loss: 1.955265, Acc:0.807547, Semantic loss: 0.730122, BCE loss: 0.520292, SB loss: 0.704851
2023-10-30 18:36:29,595 Epoch: [332/484] Iter:[270/495], Time: 0.38, lr: [0.0035147404149621507], Loss: 1.953950, Acc:0.807860, Semantic loss: 0.730209, BCE loss: 0.519342, SB loss: 0.704398
2023-10-30 18:36:33,229 Epoch: [332/484] Iter:[280/495], Time: 0.38, lr: [0.0035143184745231237], Loss: 1.953181, Acc:0.809113, Semantic loss: 0.729521, BCE loss: 0.520084, SB loss: 0.703576
2023-10-30 18:36:36,884 Epoch: [332/484] Iter:[290/495], Time: 0.38, lr: [0.003513896528455186], Loss: 1.956613, Acc:0.808166, Semantic loss: 0.731138, BCE loss: 0.520399, SB loss: 0.705077
2023-10-30 18:36:40,648 Epoch: [332/484] Iter:[300/495], Time: 0.38, lr: [0.0035134745767575097], Loss: 1.955036, Acc:0.805950, Semantic loss: 0.730862, BCE loss: 0.518606, SB loss: 0.705568
2023-10-30 18:36:44,392 Epoch: [332/484] Iter:[310/495], Time: 0.38, lr: [0.0035130526194292687], Loss: 1.960461, Acc:0.805857, Semantic loss: 0.732913, BCE loss: 0.520473, SB loss: 0.707074
2023-10-30 18:36:47,990 Epoch: [332/484] Iter:[320/495], Time: 0.38, lr: [0.0035126306564696353], Loss: 1.959427, Acc:0.806903, Semantic loss: 0.731846, BCE loss: 0.521471, SB loss: 0.706110
2023-10-30 18:36:51,710 Epoch: [332/484] Iter:[330/495], Time: 0.38, lr: [0.0035122086878777853], Loss: 1.961665, Acc:0.806339, Semantic loss: 0.732869, BCE loss: 0.522679, SB loss: 0.706117
2023-10-30 18:36:55,336 Epoch: [332/484] Iter:[340/495], Time: 0.38, lr: [0.0035117867136528896], Loss: 1.962879, Acc:0.806488, Semantic loss: 0.733946, BCE loss: 0.522727, SB loss: 0.706206
2023-10-30 18:36:59,031 Epoch: [332/484] Iter:[350/495], Time: 0.38, lr: [0.003511364733794122], Loss: 1.966071, Acc:0.806447, Semantic loss: 0.735252, BCE loss: 0.523885, SB loss: 0.706934
2023-10-30 18:37:02,637 Epoch: [332/484] Iter:[360/495], Time: 0.38, lr: [0.0035109427483006536], Loss: 1.971518, Acc:0.806716, Semantic loss: 0.738605, BCE loss: 0.524473, SB loss: 0.708440
2023-10-30 18:37:06,402 Epoch: [332/484] Iter:[370/495], Time: 0.38, lr: [0.003510520757171658], Loss: 1.969889, Acc:0.805323, Semantic loss: 0.737624, BCE loss: 0.523710, SB loss: 0.708555
2023-10-30 18:37:10,246 Epoch: [332/484] Iter:[380/495], Time: 0.38, lr: [0.0035100987604063066], Loss: 1.970001, Acc:0.805487, Semantic loss: 0.738061, BCE loss: 0.522555, SB loss: 0.709386
2023-10-30 18:37:13,960 Epoch: [332/484] Iter:[390/495], Time: 0.38, lr: [0.003509676758003772], Loss: 1.969435, Acc:0.805720, Semantic loss: 0.736807, BCE loss: 0.523321, SB loss: 0.709307
2023-10-30 18:37:17,662 Epoch: [332/484] Iter:[400/495], Time: 0.38, lr: [0.0035092547499632237], Loss: 1.971123, Acc:0.804885, Semantic loss: 0.737446, BCE loss: 0.523540, SB loss: 0.710138
2023-10-30 18:37:21,454 Epoch: [332/484] Iter:[410/495], Time: 0.38, lr: [0.003508832736283835], Loss: 1.968667, Acc:0.805751, Semantic loss: 0.735677, BCE loss: 0.522860, SB loss: 0.710130
2023-10-30 18:37:25,170 Epoch: [332/484] Iter:[420/495], Time: 0.38, lr: [0.003508410716964777], Loss: 1.967869, Acc:0.805941, Semantic loss: 0.735407, BCE loss: 0.522354, SB loss: 0.710109
2023-10-30 18:37:28,940 Epoch: [332/484] Iter:[430/495], Time: 0.38, lr: [0.00350798869200522], Loss: 1.967492, Acc:0.806600, Semantic loss: 0.735578, BCE loss: 0.521622, SB loss: 0.710292
2023-10-30 18:37:32,567 Epoch: [332/484] Iter:[440/495], Time: 0.38, lr: [0.0035075666614043334], Loss: 1.964484, Acc:0.806635, Semantic loss: 0.734464, BCE loss: 0.519973, SB loss: 0.710047
2023-10-30 18:37:36,319 Epoch: [332/484] Iter:[450/495], Time: 0.38, lr: [0.0035071446251612893], Loss: 1.967322, Acc:0.805815, Semantic loss: 0.735316, BCE loss: 0.521489, SB loss: 0.710518
2023-10-30 18:37:40,071 Epoch: [332/484] Iter:[460/495], Time: 0.38, lr: [0.0035067225832752574], Loss: 1.966119, Acc:0.806708, Semantic loss: 0.734720, BCE loss: 0.521919, SB loss: 0.709481
2023-10-30 18:37:43,703 Epoch: [332/484] Iter:[470/495], Time: 0.38, lr: [0.0035063005357454068], Loss: 1.967558, Acc:0.806421, Semantic loss: 0.735072, BCE loss: 0.522803, SB loss: 0.709684
2023-10-30 18:37:47,371 Epoch: [332/484] Iter:[480/495], Time: 0.38, lr: [0.003505878482570909], Loss: 1.967143, Acc:0.806290, Semantic loss: 0.734828, BCE loss: 0.522785, SB loss: 0.709530
2023-10-30 18:37:50,805 Epoch: [332/484] Iter:[490/495], Time: 0.37, lr: [0.0035054564237509325], Loss: 1.969310, Acc:0.805803, Semantic loss: 0.735826, BCE loss: 0.523038, SB loss: 0.710446
2023-10-30 18:37:52,202 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:37:52,442 Loss: 2.034, MeanIU:  0.7193, Best_mIoU:  0.7309
2023-10-30 18:37:52,442 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576]
2023-10-30 18:37:54,443 Epoch: [333/484] Iter:[0/495], Time: 1.97, lr: [0.003505245392223629], Loss: 1.945771, Acc:0.730171, Semantic loss: 0.796660, BCE loss: 0.404651, SB loss: 0.744460
2023-10-30 18:37:58,462 Epoch: [333/484] Iter:[10/495], Time: 0.54, lr: [0.003504823324933877], Loss: 1.941027, Acc:0.807471, Semantic loss: 0.727726, BCE loss: 0.494976, SB loss: 0.718326
2023-10-30 18:38:02,121 Epoch: [333/484] Iter:[20/495], Time: 0.46, lr: [0.0035044012519965667], Loss: 1.909399, Acc:0.789918, Semantic loss: 0.709094, BCE loss: 0.491630, SB loss: 0.708675
2023-10-30 18:38:05,837 Epoch: [333/484] Iter:[30/495], Time: 0.43, lr: [0.00350397917341087], Loss: 1.945256, Acc:0.783355, Semantic loss: 0.733134, BCE loss: 0.495385, SB loss: 0.716737
2023-10-30 18:38:09,487 Epoch: [333/484] Iter:[40/495], Time: 0.41, lr: [0.003503557089175954], Loss: 1.917066, Acc:0.780450, Semantic loss: 0.719644, BCE loss: 0.483191, SB loss: 0.714231
2023-10-30 18:38:13,191 Epoch: [333/484] Iter:[50/495], Time: 0.41, lr: [0.0035031349992909874], Loss: 1.936304, Acc:0.782659, Semantic loss: 0.735776, BCE loss: 0.490952, SB loss: 0.709576
2023-10-30 18:38:16,872 Epoch: [333/484] Iter:[60/495], Time: 0.40, lr: [0.0035027129037551357], Loss: 1.923239, Acc:0.788316, Semantic loss: 0.724523, BCE loss: 0.491223, SB loss: 0.707493
2023-10-30 18:38:20,577 Epoch: [333/484] Iter:[70/495], Time: 0.40, lr: [0.003502290802567571], Loss: 1.940428, Acc:0.791367, Semantic loss: 0.734226, BCE loss: 0.497706, SB loss: 0.708496
2023-10-30 18:38:24,206 Epoch: [333/484] Iter:[80/495], Time: 0.39, lr: [0.0035018686957274574], Loss: 1.954714, Acc:0.793684, Semantic loss: 0.740348, BCE loss: 0.501475, SB loss: 0.712892
2023-10-30 18:38:27,854 Epoch: [333/484] Iter:[90/495], Time: 0.39, lr: [0.003501446583233964], Loss: 1.951324, Acc:0.795055, Semantic loss: 0.737544, BCE loss: 0.503081, SB loss: 0.710699
2023-10-30 18:38:31,480 Epoch: [333/484] Iter:[100/495], Time: 0.39, lr: [0.003501024465086255], Loss: 1.963448, Acc:0.794793, Semantic loss: 0.743421, BCE loss: 0.507358, SB loss: 0.712669
2023-10-30 18:38:35,137 Epoch: [333/484] Iter:[110/495], Time: 0.38, lr: [0.0035006023412835004], Loss: 1.949512, Acc:0.797155, Semantic loss: 0.740144, BCE loss: 0.500133, SB loss: 0.709235
2023-10-30 18:38:38,795 Epoch: [333/484] Iter:[120/495], Time: 0.38, lr: [0.0035001802118248652], Loss: 1.952067, Acc:0.798030, Semantic loss: 0.736915, BCE loss: 0.506417, SB loss: 0.708734
2023-10-30 18:38:42,335 Epoch: [333/484] Iter:[130/495], Time: 0.38, lr: [0.0034997580767095167], Loss: 1.951833, Acc:0.797897, Semantic loss: 0.739205, BCE loss: 0.503977, SB loss: 0.708650
2023-10-30 18:38:45,942 Epoch: [333/484] Iter:[140/495], Time: 0.38, lr: [0.0034993359359366183], Loss: 1.953709, Acc:0.799739, Semantic loss: 0.741387, BCE loss: 0.502818, SB loss: 0.709504
2023-10-30 18:38:49,659 Epoch: [333/484] Iter:[150/495], Time: 0.38, lr: [0.003498913789505339], Loss: 1.945518, Acc:0.798444, Semantic loss: 0.739118, BCE loss: 0.498647, SB loss: 0.707753
2023-10-30 18:38:53,295 Epoch: [333/484] Iter:[160/495], Time: 0.38, lr: [0.0034984916374148434], Loss: 1.942696, Acc:0.799596, Semantic loss: 0.737409, BCE loss: 0.498558, SB loss: 0.706729
2023-10-30 18:38:57,005 Epoch: [333/484] Iter:[170/495], Time: 0.38, lr: [0.0034980694796642965], Loss: 1.940401, Acc:0.802375, Semantic loss: 0.736681, BCE loss: 0.499436, SB loss: 0.704284
2023-10-30 18:39:00,617 Epoch: [333/484] Iter:[180/495], Time: 0.38, lr: [0.003497647316252862], Loss: 1.937520, Acc:0.802448, Semantic loss: 0.732742, BCE loss: 0.499971, SB loss: 0.704806
2023-10-30 18:39:04,263 Epoch: [333/484] Iter:[190/495], Time: 0.38, lr: [0.0034972251471797077], Loss: 1.935644, Acc:0.801847, Semantic loss: 0.730781, BCE loss: 0.500369, SB loss: 0.704494
2023-10-30 18:39:07,822 Epoch: [333/484] Iter:[200/495], Time: 0.37, lr: [0.0034968029724439967], Loss: 1.941015, Acc:0.800614, Semantic loss: 0.733943, BCE loss: 0.501145, SB loss: 0.705927
2023-10-30 18:39:11,379 Epoch: [333/484] Iter:[210/495], Time: 0.37, lr: [0.0034963807920448935], Loss: 1.944292, Acc:0.801527, Semantic loss: 0.735281, BCE loss: 0.502717, SB loss: 0.706294
2023-10-30 18:39:15,096 Epoch: [333/484] Iter:[220/495], Time: 0.37, lr: [0.0034959586059815613], Loss: 1.948435, Acc:0.799914, Semantic loss: 0.738765, BCE loss: 0.501650, SB loss: 0.708021
2023-10-30 18:39:18,744 Epoch: [333/484] Iter:[230/495], Time: 0.37, lr: [0.003495536414253166], Loss: 1.946509, Acc:0.799965, Semantic loss: 0.736738, BCE loss: 0.501473, SB loss: 0.708298
2023-10-30 18:39:22,549 Epoch: [333/484] Iter:[240/495], Time: 0.37, lr: [0.003495114216858871], Loss: 1.943149, Acc:0.797819, Semantic loss: 0.735077, BCE loss: 0.499287, SB loss: 0.708784
2023-10-30 18:39:26,204 Epoch: [333/484] Iter:[250/495], Time: 0.37, lr: [0.0034946920137978385], Loss: 1.941156, Acc:0.797599, Semantic loss: 0.733429, BCE loss: 0.499552, SB loss: 0.708176
2023-10-30 18:39:29,928 Epoch: [333/484] Iter:[260/495], Time: 0.37, lr: [0.0034942698050692313], Loss: 1.945398, Acc:0.797028, Semantic loss: 0.736174, BCE loss: 0.500320, SB loss: 0.708904
2023-10-30 18:39:33,629 Epoch: [333/484] Iter:[270/495], Time: 0.37, lr: [0.003493847590672215], Loss: 1.945577, Acc:0.796671, Semantic loss: 0.735696, BCE loss: 0.501692, SB loss: 0.708189
2023-10-30 18:39:37,283 Epoch: [333/484] Iter:[280/495], Time: 0.37, lr: [0.0034934253706059505], Loss: 1.945697, Acc:0.797620, Semantic loss: 0.735259, BCE loss: 0.502311, SB loss: 0.708127
2023-10-30 18:39:41,021 Epoch: [333/484] Iter:[290/495], Time: 0.37, lr: [0.0034930031448696], Loss: 1.944556, Acc:0.798431, Semantic loss: 0.733974, BCE loss: 0.503833, SB loss: 0.706749
2023-10-30 18:39:44,635 Epoch: [333/484] Iter:[300/495], Time: 0.37, lr: [0.003492580913462327], Loss: 1.940880, Acc:0.798831, Semantic loss: 0.732457, BCE loss: 0.502391, SB loss: 0.706031
2023-10-30 18:39:48,354 Epoch: [333/484] Iter:[310/495], Time: 0.37, lr: [0.0034921586763832935], Loss: 1.942841, Acc:0.797802, Semantic loss: 0.733234, BCE loss: 0.503346, SB loss: 0.706261
2023-10-30 18:39:52,104 Epoch: [333/484] Iter:[320/495], Time: 0.37, lr: [0.0034917364336316606], Loss: 1.946627, Acc:0.799272, Semantic loss: 0.735128, BCE loss: 0.503787, SB loss: 0.707712
2023-10-30 18:39:55,756 Epoch: [333/484] Iter:[330/495], Time: 0.37, lr: [0.003491314185206589], Loss: 1.949205, Acc:0.798892, Semantic loss: 0.737537, BCE loss: 0.503736, SB loss: 0.707932
2023-10-30 18:39:59,464 Epoch: [333/484] Iter:[340/495], Time: 0.37, lr: [0.0034908919311072424], Loss: 1.950415, Acc:0.799221, Semantic loss: 0.737423, BCE loss: 0.505288, SB loss: 0.707704
2023-10-30 18:40:03,088 Epoch: [333/484] Iter:[350/495], Time: 0.37, lr: [0.003490469671332781], Loss: 1.946898, Acc:0.799644, Semantic loss: 0.734797, BCE loss: 0.505488, SB loss: 0.706612
2023-10-30 18:40:06,822 Epoch: [333/484] Iter:[360/495], Time: 0.37, lr: [0.003490047405882365], Loss: 1.947339, Acc:0.800350, Semantic loss: 0.735312, BCE loss: 0.505612, SB loss: 0.706416
2023-10-30 18:40:10,524 Epoch: [333/484] Iter:[370/495], Time: 0.37, lr: [0.0034896251347551546], Loss: 1.950470, Acc:0.800004, Semantic loss: 0.738307, BCE loss: 0.504988, SB loss: 0.707176
2023-10-30 18:40:14,267 Epoch: [333/484] Iter:[380/495], Time: 0.37, lr: [0.003489202857950312], Loss: 1.953426, Acc:0.800719, Semantic loss: 0.739837, BCE loss: 0.505783, SB loss: 0.707805
2023-10-30 18:40:17,889 Epoch: [333/484] Iter:[390/495], Time: 0.37, lr: [0.0034887805754669965], Loss: 1.952649, Acc:0.800863, Semantic loss: 0.739067, BCE loss: 0.505291, SB loss: 0.708291
2023-10-30 18:40:21,601 Epoch: [333/484] Iter:[400/495], Time: 0.37, lr: [0.003488358287304368], Loss: 1.949289, Acc:0.800343, Semantic loss: 0.737596, BCE loss: 0.504403, SB loss: 0.707291
2023-10-30 18:40:25,252 Epoch: [333/484] Iter:[410/495], Time: 0.37, lr: [0.0034879359934615844], Loss: 1.950332, Acc:0.799843, Semantic loss: 0.738306, BCE loss: 0.504839, SB loss: 0.707187
2023-10-30 18:40:28,995 Epoch: [333/484] Iter:[420/495], Time: 0.37, lr: [0.003487513693937808], Loss: 1.950845, Acc:0.800516, Semantic loss: 0.737666, BCE loss: 0.506590, SB loss: 0.706588
2023-10-30 18:40:32,666 Epoch: [333/484] Iter:[430/495], Time: 0.37, lr: [0.0034870913887321974], Loss: 1.950618, Acc:0.800052, Semantic loss: 0.736850, BCE loss: 0.507493, SB loss: 0.706276
2023-10-30 18:40:36,362 Epoch: [333/484] Iter:[440/495], Time: 0.37, lr: [0.0034866690778439114], Loss: 1.958437, Acc:0.800166, Semantic loss: 0.741881, BCE loss: 0.508932, SB loss: 0.707625
2023-10-30 18:40:40,023 Epoch: [333/484] Iter:[450/495], Time: 0.37, lr: [0.0034862467612721067], Loss: 1.955357, Acc:0.800148, Semantic loss: 0.740628, BCE loss: 0.507996, SB loss: 0.706734
2023-10-30 18:40:43,681 Epoch: [333/484] Iter:[460/495], Time: 0.37, lr: [0.0034858244390159445], Loss: 1.955158, Acc:0.798958, Semantic loss: 0.740855, BCE loss: 0.507925, SB loss: 0.706379
2023-10-30 18:40:47,384 Epoch: [333/484] Iter:[470/495], Time: 0.37, lr: [0.003485402111074582], Loss: 1.953476, Acc:0.798627, Semantic loss: 0.739959, BCE loss: 0.507572, SB loss: 0.705945
2023-10-30 18:40:51,104 Epoch: [333/484] Iter:[480/495], Time: 0.37, lr: [0.0034849797774471774], Loss: 1.956038, Acc:0.798586, Semantic loss: 0.741367, BCE loss: 0.508126, SB loss: 0.706546
2023-10-30 18:40:54,572 Epoch: [333/484] Iter:[490/495], Time: 0.37, lr: [0.0034845574381328877], Loss: 1.954420, Acc:0.798230, Semantic loss: 0.740433, BCE loss: 0.507569, SB loss: 0.706418
2023-10-30 18:40:55,975 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:40:56,217 Loss: 2.034, MeanIU:  0.7193, Best_mIoU:  0.7309
2023-10-30 18:40:56,217 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576]
2023-10-30 18:40:58,438 Epoch: [334/484] Iter:[0/495], Time: 2.19, lr: [0.0034843462663428984], Loss: 1.926739, Acc:0.852325, Semantic loss: 0.677747, BCE loss: 0.564524, SB loss: 0.684468
2023-10-30 18:41:02,482 Epoch: [334/484] Iter:[10/495], Time: 0.57, lr: [0.003483923918496703], Loss: 1.904853, Acc:0.782504, Semantic loss: 0.703329, BCE loss: 0.488155, SB loss: 0.713369
2023-10-30 18:41:06,117 Epoch: [334/484] Iter:[20/495], Time: 0.47, lr: [0.003483501564961517], Loss: 1.926466, Acc:0.794062, Semantic loss: 0.708100, BCE loss: 0.514269, SB loss: 0.704097
2023-10-30 18:41:09,833 Epoch: [334/484] Iter:[30/495], Time: 0.44, lr: [0.003483079205736497], Loss: 1.921727, Acc:0.811820, Semantic loss: 0.702019, BCE loss: 0.519584, SB loss: 0.700124
2023-10-30 18:41:13,506 Epoch: [334/484] Iter:[40/495], Time: 0.42, lr: [0.003482656840820798], Loss: 1.946178, Acc:0.814174, Semantic loss: 0.711275, BCE loss: 0.530472, SB loss: 0.704432
2023-10-30 18:41:17,166 Epoch: [334/484] Iter:[50/495], Time: 0.41, lr: [0.0034822344702135793], Loss: 1.948755, Acc:0.809778, Semantic loss: 0.716803, BCE loss: 0.527641, SB loss: 0.704312
2023-10-30 18:41:20,735 Epoch: [334/484] Iter:[60/495], Time: 0.40, lr: [0.0034818120939139963], Loss: 1.948784, Acc:0.807628, Semantic loss: 0.718853, BCE loss: 0.525902, SB loss: 0.704029
2023-10-30 18:41:24,323 Epoch: [334/484] Iter:[70/495], Time: 0.40, lr: [0.0034813897119212044], Loss: 1.939781, Acc:0.805407, Semantic loss: 0.716386, BCE loss: 0.520280, SB loss: 0.703115
2023-10-30 18:41:27,924 Epoch: [334/484] Iter:[80/495], Time: 0.39, lr: [0.003480967324234359], Loss: 1.940608, Acc:0.800498, Semantic loss: 0.717416, BCE loss: 0.518525, SB loss: 0.704668
2023-10-30 18:41:31,580 Epoch: [334/484] Iter:[90/495], Time: 0.39, lr: [0.003480544930852617], Loss: 1.943528, Acc:0.800974, Semantic loss: 0.721856, BCE loss: 0.518065, SB loss: 0.703606
2023-10-30 18:41:35,295 Epoch: [334/484] Iter:[100/495], Time: 0.39, lr: [0.0034801225317751335], Loss: 1.934093, Acc:0.803210, Semantic loss: 0.719831, BCE loss: 0.513345, SB loss: 0.700917
2023-10-30 18:41:38,960 Epoch: [334/484] Iter:[110/495], Time: 0.38, lr: [0.003479700127001062], Loss: 1.940885, Acc:0.800473, Semantic loss: 0.726437, BCE loss: 0.512145, SB loss: 0.702303
2023-10-30 18:41:42,745 Epoch: [334/484] Iter:[120/495], Time: 0.38, lr: [0.003479277716529558], Loss: 1.960412, Acc:0.798613, Semantic loss: 0.740145, BCE loss: 0.513625, SB loss: 0.706641
2023-10-30 18:41:46,511 Epoch: [334/484] Iter:[130/495], Time: 0.38, lr: [0.0034788553003597773], Loss: 1.962236, Acc:0.799194, Semantic loss: 0.741186, BCE loss: 0.514565, SB loss: 0.706486
2023-10-30 18:41:50,159 Epoch: [334/484] Iter:[140/495], Time: 0.38, lr: [0.003478432878490873], Loss: 1.958121, Acc:0.799645, Semantic loss: 0.739931, BCE loss: 0.513370, SB loss: 0.704819
2023-10-30 18:41:53,824 Epoch: [334/484] Iter:[150/495], Time: 0.38, lr: [0.0034780104509219982], Loss: 1.953680, Acc:0.801277, Semantic loss: 0.736160, BCE loss: 0.513764, SB loss: 0.703755
2023-10-30 18:41:57,444 Epoch: [334/484] Iter:[160/495], Time: 0.38, lr: [0.0034775880176523095], Loss: 1.955295, Acc:0.799897, Semantic loss: 0.736801, BCE loss: 0.514956, SB loss: 0.703538
2023-10-30 18:42:01,329 Epoch: [334/484] Iter:[170/495], Time: 0.38, lr: [0.003477165578680959], Loss: 1.956671, Acc:0.797505, Semantic loss: 0.737459, BCE loss: 0.515101, SB loss: 0.704111
2023-10-30 18:42:05,101 Epoch: [334/484] Iter:[180/495], Time: 0.38, lr: [0.0034767431340070997], Loss: 1.959033, Acc:0.799691, Semantic loss: 0.738906, BCE loss: 0.516438, SB loss: 0.703688
2023-10-30 18:42:08,677 Epoch: [334/484] Iter:[190/495], Time: 0.38, lr: [0.0034763206836298842], Loss: 1.963164, Acc:0.801419, Semantic loss: 0.739668, BCE loss: 0.518856, SB loss: 0.704641
2023-10-30 18:42:12,290 Epoch: [334/484] Iter:[200/495], Time: 0.38, lr: [0.0034758982275484678], Loss: 1.960475, Acc:0.799558, Semantic loss: 0.737835, BCE loss: 0.518083, SB loss: 0.704558
2023-10-30 18:42:15,963 Epoch: [334/484] Iter:[210/495], Time: 0.38, lr: [0.0034754757657620016], Loss: 1.959188, Acc:0.799613, Semantic loss: 0.736680, BCE loss: 0.516948, SB loss: 0.705560
2023-10-30 18:42:19,730 Epoch: [334/484] Iter:[220/495], Time: 0.38, lr: [0.0034750532982696374], Loss: 1.957915, Acc:0.799664, Semantic loss: 0.736701, BCE loss: 0.514880, SB loss: 0.706334
2023-10-30 18:42:23,420 Epoch: [334/484] Iter:[230/495], Time: 0.38, lr: [0.0034746308250705278], Loss: 1.953993, Acc:0.799335, Semantic loss: 0.735004, BCE loss: 0.512934, SB loss: 0.706055
2023-10-30 18:42:27,103 Epoch: [334/484] Iter:[240/495], Time: 0.38, lr: [0.0034742083461638254], Loss: 1.954427, Acc:0.799815, Semantic loss: 0.737099, BCE loss: 0.511706, SB loss: 0.705622
2023-10-30 18:42:30,686 Epoch: [334/484] Iter:[250/495], Time: 0.38, lr: [0.003473785861548681], Loss: 1.955203, Acc:0.799788, Semantic loss: 0.738120, BCE loss: 0.511233, SB loss: 0.705850
2023-10-30 18:42:34,400 Epoch: [334/484] Iter:[260/495], Time: 0.38, lr: [0.0034733633712242472], Loss: 1.948545, Acc:0.799593, Semantic loss: 0.735656, BCE loss: 0.508719, SB loss: 0.704170
2023-10-30 18:42:38,168 Epoch: [334/484] Iter:[270/495], Time: 0.38, lr: [0.003472940875189673], Loss: 1.950402, Acc:0.801525, Semantic loss: 0.736381, BCE loss: 0.509986, SB loss: 0.704036
2023-10-30 18:42:41,860 Epoch: [334/484] Iter:[280/495], Time: 0.38, lr: [0.0034725183734441124], Loss: 1.950375, Acc:0.802600, Semantic loss: 0.736398, BCE loss: 0.509655, SB loss: 0.704322
2023-10-30 18:42:45,591 Epoch: [334/484] Iter:[290/495], Time: 0.38, lr: [0.0034720958659867143], Loss: 1.952917, Acc:0.801704, Semantic loss: 0.739097, BCE loss: 0.508033, SB loss: 0.705787
2023-10-30 18:42:49,320 Epoch: [334/484] Iter:[300/495], Time: 0.38, lr: [0.003471673352816629], Loss: 1.956256, Acc:0.801242, Semantic loss: 0.741793, BCE loss: 0.507524, SB loss: 0.706939
2023-10-30 18:42:53,044 Epoch: [334/484] Iter:[310/495], Time: 0.38, lr: [0.0034712508339330064], Loss: 1.958225, Acc:0.800206, Semantic loss: 0.741540, BCE loss: 0.508496, SB loss: 0.708190
2023-10-30 18:42:56,685 Epoch: [334/484] Iter:[320/495], Time: 0.38, lr: [0.0034708283093349977], Loss: 1.957509, Acc:0.799847, Semantic loss: 0.740916, BCE loss: 0.509196, SB loss: 0.707398
2023-10-30 18:43:00,445 Epoch: [334/484] Iter:[330/495], Time: 0.38, lr: [0.003470405779021753], Loss: 1.960579, Acc:0.799978, Semantic loss: 0.742202, BCE loss: 0.510844, SB loss: 0.707534
2023-10-30 18:43:04,176 Epoch: [334/484] Iter:[340/495], Time: 0.38, lr: [0.0034699832429924207], Loss: 1.962480, Acc:0.800204, Semantic loss: 0.741700, BCE loss: 0.512475, SB loss: 0.708305
2023-10-30 18:43:07,894 Epoch: [334/484] Iter:[350/495], Time: 0.38, lr: [0.0034695607012461493], Loss: 1.965059, Acc:0.801108, Semantic loss: 0.742325, BCE loss: 0.513857, SB loss: 0.708878
2023-10-30 18:43:11,592 Epoch: [334/484] Iter:[360/495], Time: 0.37, lr: [0.00346913815378209], Loss: 1.966790, Acc:0.802013, Semantic loss: 0.743643, BCE loss: 0.514109, SB loss: 0.709038
2023-10-30 18:43:15,391 Epoch: [334/484] Iter:[370/495], Time: 0.38, lr: [0.003468715600599391], Loss: 1.969523, Acc:0.802338, Semantic loss: 0.745061, BCE loss: 0.514255, SB loss: 0.710207
2023-10-30 18:43:19,086 Epoch: [334/484] Iter:[380/495], Time: 0.37, lr: [0.003468293041697199], Loss: 1.975053, Acc:0.802508, Semantic loss: 0.747500, BCE loss: 0.516247, SB loss: 0.711305
2023-10-30 18:43:22,797 Epoch: [334/484] Iter:[390/495], Time: 0.37, lr: [0.0034678704770746637], Loss: 1.980402, Acc:0.802269, Semantic loss: 0.751265, BCE loss: 0.516591, SB loss: 0.712546
2023-10-30 18:43:26,500 Epoch: [334/484] Iter:[400/495], Time: 0.37, lr: [0.003467447906730934], Loss: 1.986141, Acc:0.800795, Semantic loss: 0.753326, BCE loss: 0.517686, SB loss: 0.715129
2023-10-30 18:43:30,199 Epoch: [334/484] Iter:[410/495], Time: 0.37, lr: [0.0034670253306651566], Loss: 1.997995, Acc:0.800519, Semantic loss: 0.759251, BCE loss: 0.520683, SB loss: 0.718062
2023-10-30 18:43:33,800 Epoch: [334/484] Iter:[420/495], Time: 0.37, lr: [0.0034666027488764795], Loss: 1.998843, Acc:0.800629, Semantic loss: 0.758708, BCE loss: 0.520936, SB loss: 0.719200
2023-10-30 18:43:37,553 Epoch: [334/484] Iter:[430/495], Time: 0.37, lr: [0.0034661801613640486], Loss: 2.002758, Acc:0.799925, Semantic loss: 0.762035, BCE loss: 0.520338, SB loss: 0.720385
2023-10-30 18:43:41,158 Epoch: [334/484] Iter:[440/495], Time: 0.37, lr: [0.0034657575681270136], Loss: 2.003233, Acc:0.799057, Semantic loss: 0.761762, BCE loss: 0.519996, SB loss: 0.721474
2023-10-30 18:43:44,936 Epoch: [334/484] Iter:[450/495], Time: 0.37, lr: [0.00346533496916452], Loss: 2.005597, Acc:0.797581, Semantic loss: 0.762668, BCE loss: 0.519826, SB loss: 0.723102
2023-10-30 18:43:48,656 Epoch: [334/484] Iter:[460/495], Time: 0.37, lr: [0.003464912364475714], Loss: 2.005657, Acc:0.797908, Semantic loss: 0.761477, BCE loss: 0.521224, SB loss: 0.722956
2023-10-30 18:43:52,253 Epoch: [334/484] Iter:[470/495], Time: 0.37, lr: [0.0034644897540597416], Loss: 2.004902, Acc:0.798035, Semantic loss: 0.760824, BCE loss: 0.520987, SB loss: 0.723091
2023-10-30 18:43:55,889 Epoch: [334/484] Iter:[480/495], Time: 0.37, lr: [0.00346406713791575], Loss: 2.008501, Acc:0.797628, Semantic loss: 0.762817, BCE loss: 0.521042, SB loss: 0.724641
2023-10-30 18:43:59,438 Epoch: [334/484] Iter:[490/495], Time: 0.37, lr: [0.003463644516042885], Loss: 2.009462, Acc:0.798168, Semantic loss: 0.763207, BCE loss: 0.521641, SB loss: 0.724614
2023-10-30 18:44:00,844 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:44:01,081 Loss: 2.034, MeanIU:  0.7193, Best_mIoU:  0.7309
2023-10-30 18:44:01,081 [0.97676407 0.82739323 0.90668265 0.445246   0.54604222 0.58788284
 0.63875857 0.74999588 0.91154175 0.60925021 0.92832882 0.78797198
 0.59262685 0.93590237 0.66326654 0.78493107 0.55987287 0.48156459
 0.73239576]
2023-10-30 18:44:03,009 Epoch: [335/484] Iter:[0/495], Time: 1.90, lr: [0.0034634332029578586], Loss: 1.873901, Acc:0.815090, Semantic loss: 0.653054, BCE loss: 0.536092, SB loss: 0.684755
2023-10-30 18:44:06,988 Epoch: [335/484] Iter:[10/495], Time: 0.53, lr: [0.00346301057249008], Loss: 2.055184, Acc:0.806251, Semantic loss: 0.758581, BCE loss: 0.567155, SB loss: 0.729447
2023-10-30 18:44:10,788 Epoch: [335/484] Iter:[20/495], Time: 0.46, lr: [0.0034625879362912932], Loss: 2.031025, Acc:0.804873, Semantic loss: 0.732825, BCE loss: 0.566305, SB loss: 0.731894
2023-10-30 18:44:14,477 Epoch: [335/484] Iter:[30/495], Time: 0.43, lr: [0.0034621652943606406], Loss: 2.020175, Acc:0.812484, Semantic loss: 0.745932, BCE loss: 0.550015, SB loss: 0.724228
2023-10-30 18:44:18,250 Epoch: [335/484] Iter:[40/495], Time: 0.42, lr: [0.0034617426466972685], Loss: 2.024041, Acc:0.812664, Semantic loss: 0.745956, BCE loss: 0.547410, SB loss: 0.730674
2023-10-30 18:44:21,932 Epoch: [335/484] Iter:[50/495], Time: 0.41, lr: [0.003461319993300319], Loss: 2.028056, Acc:0.807540, Semantic loss: 0.757327, BCE loss: 0.537140, SB loss: 0.733589
2023-10-30 18:44:25,603 Epoch: [335/484] Iter:[60/495], Time: 0.40, lr: [0.00346089733416894], Loss: 2.031538, Acc:0.806652, Semantic loss: 0.761687, BCE loss: 0.535318, SB loss: 0.734533
2023-10-30 18:44:29,232 Epoch: [335/484] Iter:[70/495], Time: 0.40, lr: [0.0034604746693022727], Loss: 2.006763, Acc:0.806391, Semantic loss: 0.745971, BCE loss: 0.533747, SB loss: 0.727045
2023-10-30 18:44:32,922 Epoch: [335/484] Iter:[80/495], Time: 0.39, lr: [0.003460051998699462], Loss: 2.015994, Acc:0.805681, Semantic loss: 0.750276, BCE loss: 0.537005, SB loss: 0.728713
2023-10-30 18:44:36,598 Epoch: [335/484] Iter:[90/495], Time: 0.39, lr: [0.0034596293223596508], Loss: 2.056587, Acc:0.803093, Semantic loss: 0.781497, BCE loss: 0.537806, SB loss: 0.737284
2023-10-30 18:44:40,434 Epoch: [335/484] Iter:[100/495], Time: 0.39, lr: [0.003459206640281984], Loss: 2.066890, Acc:0.801927, Semantic loss: 0.782009, BCE loss: 0.543950, SB loss: 0.740931
2023-10-30 18:44:44,160 Epoch: [335/484] Iter:[110/495], Time: 0.39, lr: [0.0034587839524656033], Loss: 2.075578, Acc:0.800710, Semantic loss: 0.783369, BCE loss: 0.548923, SB loss: 0.743286
2023-10-30 18:44:47,847 Epoch: [335/484] Iter:[120/495], Time: 0.39, lr: [0.003458361258909652], Loss: 2.073206, Acc:0.799495, Semantic loss: 0.783229, BCE loss: 0.547992, SB loss: 0.741985
2023-10-30 18:44:51,513 Epoch: [335/484] Iter:[130/495], Time: 0.38, lr: [0.0034579385596132713], Loss: 2.075849, Acc:0.798452, Semantic loss: 0.786368, BCE loss: 0.546280, SB loss: 0.743201
2023-10-30 18:44:55,174 Epoch: [335/484] Iter:[140/495], Time: 0.38, lr: [0.003457515854575606], Loss: 2.080542, Acc:0.797656, Semantic loss: 0.789718, BCE loss: 0.546594, SB loss: 0.744230
2023-10-30 18:44:58,832 Epoch: [335/484] Iter:[150/495], Time: 0.38, lr: [0.003457093143795797], Loss: 2.069668, Acc:0.798156, Semantic loss: 0.784288, BCE loss: 0.544762, SB loss: 0.740619
2023-10-30 18:45:02,481 Epoch: [335/484] Iter:[160/495], Time: 0.38, lr: [0.003456670427272986], Loss: 2.063795, Acc:0.795434, Semantic loss: 0.780025, BCE loss: 0.544179, SB loss: 0.739590
2023-10-30 18:45:06,193 Epoch: [335/484] Iter:[170/495], Time: 0.38, lr: [0.003456247705006314], Loss: 2.061063, Acc:0.793791, Semantic loss: 0.780429, BCE loss: 0.539651, SB loss: 0.740983
2023-10-30 18:45:09,897 Epoch: [335/484] Iter:[180/495], Time: 0.38, lr: [0.0034558249769949235], Loss: 2.050937, Acc:0.796867, Semantic loss: 0.775064, BCE loss: 0.536776, SB loss: 0.739097
2023-10-30 18:45:13,615 Epoch: [335/484] Iter:[190/495], Time: 0.38, lr: [0.0034554022432379556], Loss: 2.050970, Acc:0.797325, Semantic loss: 0.776011, BCE loss: 0.535810, SB loss: 0.739149
2023-10-30 18:45:17,278 Epoch: [335/484] Iter:[200/495], Time: 0.38, lr: [0.003454979503734551], Loss: 2.048112, Acc:0.795980, Semantic loss: 0.775128, BCE loss: 0.535339, SB loss: 0.737645
2023-10-30 18:45:21,009 Epoch: [335/484] Iter:[210/495], Time: 0.38, lr: [0.0034545567584838488], Loss: 2.045531, Acc:0.796418, Semantic loss: 0.774562, BCE loss: 0.533605, SB loss: 0.737365
2023-10-30 18:45:24,715 Epoch: [335/484] Iter:[220/495], Time: 0.38, lr: [0.003454134007484992], Loss: 2.049657, Acc:0.795994, Semantic loss: 0.776620, BCE loss: 0.534168, SB loss: 0.738869
2023-10-30 18:45:28,412 Epoch: [335/484] Iter:[230/495], Time: 0.38, lr: [0.0034537112507371194], Loss: 2.048918, Acc:0.797313, Semantic loss: 0.776259, BCE loss: 0.533726, SB loss: 0.738933
2023-10-30 18:45:32,053 Epoch: [335/484] Iter:[240/495], Time: 0.38, lr: [0.0034532884882393705], Loss: 2.051153, Acc:0.797006, Semantic loss: 0.777416, BCE loss: 0.533966, SB loss: 0.739772
2023-10-30 18:45:35,806 Epoch: [335/484] Iter:[250/495], Time: 0.38, lr: [0.003452865719990885], Loss: 2.054741, Acc:0.796685, Semantic loss: 0.781814, BCE loss: 0.532756, SB loss: 0.740171
2023-10-30 18:45:39,462 Epoch: [335/484] Iter:[260/495], Time: 0.38, lr: [0.003452442945990803], Loss: 2.049293, Acc:0.795903, Semantic loss: 0.778664, BCE loss: 0.531437, SB loss: 0.739192
2023-10-30 18:45:43,231 Epoch: [335/484] Iter:[270/495], Time: 0.38, lr: [0.0034520201662382633], Loss: 2.044889, Acc:0.795078, Semantic loss: 0.775944, BCE loss: 0.530671, SB loss: 0.738274
2023-10-30 18:45:47,029 Epoch: [335/484] Iter:[280/495], Time: 0.38, lr: [0.003451597380732405], Loss: 2.052941, Acc:0.794954, Semantic loss: 0.783323, BCE loss: 0.530226, SB loss: 0.739391
2023-10-30 18:45:50,729 Epoch: [335/484] Iter:[290/495], Time: 0.38, lr: [0.0034511745894723663], Loss: 2.055327, Acc:0.795904, Semantic loss: 0.785641, BCE loss: 0.530154, SB loss: 0.739532
2023-10-30 18:45:54,483 Epoch: [335/484] Iter:[300/495], Time: 0.38, lr: [0.003450751792457286], Loss: 2.054598, Acc:0.797028, Semantic loss: 0.784163, BCE loss: 0.531199, SB loss: 0.739236
2023-10-30 18:45:58,137 Epoch: [335/484] Iter:[310/495], Time: 0.38, lr: [0.003450328989686303], Loss: 2.048940, Acc:0.796888, Semantic loss: 0.781159, BCE loss: 0.529910, SB loss: 0.737871
2023-10-30 18:46:01,858 Epoch: [335/484] Iter:[320/495], Time: 0.38, lr: [0.0034499061811585534], Loss: 2.051623, Acc:0.797219, Semantic loss: 0.783380, BCE loss: 0.529163, SB loss: 0.739081
2023-10-30 18:46:05,540 Epoch: [335/484] Iter:[330/495], Time: 0.38, lr: [0.0034494833668731752], Loss: 2.050378, Acc:0.798180, Semantic loss: 0.782443, BCE loss: 0.528901, SB loss: 0.739034
2023-10-30 18:46:09,295 Epoch: [335/484] Iter:[340/495], Time: 0.38, lr: [0.0034490605468293074], Loss: 2.045984, Acc:0.795832, Semantic loss: 0.781908, BCE loss: 0.524738, SB loss: 0.739338
2023-10-30 18:46:12,870 Epoch: [335/484] Iter:[350/495], Time: 0.38, lr: [0.0034486377210260865], Loss: 2.044442, Acc:0.796745, Semantic loss: 0.781781, BCE loss: 0.523887, SB loss: 0.738774
2023-10-30 18:46:16,652 Epoch: [335/484] Iter:[360/495], Time: 0.38, lr: [0.003448214889462649], Loss: 2.044322, Acc:0.797092, Semantic loss: 0.780647, BCE loss: 0.525479, SB loss: 0.738197
2023-10-30 18:46:20,356 Epoch: [335/484] Iter:[370/495], Time: 0.38, lr: [0.0034477920521381314], Loss: 2.042351, Acc:0.797504, Semantic loss: 0.779926, BCE loss: 0.524818, SB loss: 0.737607
2023-10-30 18:46:24,038 Epoch: [335/484] Iter:[380/495], Time: 0.38, lr: [0.003447369209051671], Loss: 2.041320, Acc:0.796459, Semantic loss: 0.778850, BCE loss: 0.524480, SB loss: 0.737990
2023-10-30 18:46:27,596 Epoch: [335/484] Iter:[390/495], Time: 0.37, lr: [0.0034469463602024037], Loss: 2.040857, Acc:0.795730, Semantic loss: 0.779276, BCE loss: 0.523300, SB loss: 0.738281
2023-10-30 18:46:31,252 Epoch: [335/484] Iter:[400/495], Time: 0.37, lr: [0.003446523505589465], Loss: 2.035087, Acc:0.795823, Semantic loss: 0.776469, BCE loss: 0.522297, SB loss: 0.736321
2023-10-30 18:46:34,906 Epoch: [335/484] Iter:[410/495], Time: 0.37, lr: [0.00344610064521199], Loss: 2.034769, Acc:0.795788, Semantic loss: 0.776294, BCE loss: 0.522640, SB loss: 0.735835
2023-10-30 18:46:38,544 Epoch: [335/484] Iter:[420/495], Time: 0.37, lr: [0.0034456777790691164], Loss: 2.031462, Acc:0.795341, Semantic loss: 0.774401, BCE loss: 0.522241, SB loss: 0.734819
2023-10-30 18:46:42,224 Epoch: [335/484] Iter:[430/495], Time: 0.37, lr: [0.0034452549071599774], Loss: 2.027940, Acc:0.795305, Semantic loss: 0.773739, BCE loss: 0.520287, SB loss: 0.733914
2023-10-30 18:46:45,818 Epoch: [335/484] Iter:[440/495], Time: 0.37, lr: [0.003444832029483709], Loss: 2.026107, Acc:0.795117, Semantic loss: 0.773574, BCE loss: 0.518957, SB loss: 0.733575
2023-10-30 18:46:49,500 Epoch: [335/484] Iter:[450/495], Time: 0.37, lr: [0.003444409146039444], Loss: 2.022459, Acc:0.795207, Semantic loss: 0.771915, BCE loss: 0.517764, SB loss: 0.732780
2023-10-30 18:46:53,203 Epoch: [335/484] Iter:[460/495], Time: 0.37, lr: [0.0034439862568263198], Loss: 2.028421, Acc:0.795518, Semantic loss: 0.773664, BCE loss: 0.521001, SB loss: 0.733757
2023-10-30 18:46:56,870 Epoch: [335/484] Iter:[470/495], Time: 0.37, lr: [0.003443563361843469], Loss: 2.026001, Acc:0.795896, Semantic loss: 0.772471, BCE loss: 0.520868, SB loss: 0.732662
2023-10-30 18:47:00,692 Epoch: [335/484] Iter:[480/495], Time: 0.37, lr: [0.003443140461090026], Loss: 2.023389, Acc:0.796663, Semantic loss: 0.770603, BCE loss: 0.520876, SB loss: 0.731909
2023-10-30 18:47:04,164 Epoch: [335/484] Iter:[490/495], Time: 0.37, lr: [0.003442717554565123], Loss: 2.022897, Acc:0.797425, Semantic loss: 0.769788, BCE loss: 0.521771, SB loss: 0.731338
2023-10-30 18:50:00,043 0 [0.94013862 0.64396287 0.8336343  0.16185899 0.26393569 0.43584676
 0.48601199 0.5866416  0.88672334 0.38921193 0.85442797 0.62961399
 0.03443456 0.82474456 0.00245085 0.09695816 0.04761859 0.08528824
 0.61735036] 0.4642554407719206
2023-10-30 18:50:00,044 1 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559] 0.7117415034150896
2023-10-30 18:50:00,047 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:50:00,282 Loss: 2.020, MeanIU:  0.7117, Best_mIoU:  0.7309
2023-10-30 18:50:00,282 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559]
2023-10-30 18:50:02,228 Epoch: [336/484] Iter:[0/495], Time: 1.91, lr: [0.003442506099138104], Loss: 1.730444, Acc:0.729030, Semantic loss: 0.694152, BCE loss: 0.411905, SB loss: 0.624386
2023-10-30 18:50:06,220 Epoch: [336/484] Iter:[10/495], Time: 0.54, lr: [0.0034420831839543893], Loss: 1.954102, Acc:0.780516, Semantic loss: 0.718313, BCE loss: 0.521551, SB loss: 0.714238
2023-10-30 18:50:09,885 Epoch: [336/484] Iter:[20/495], Time: 0.46, lr: [0.003441660262997048], Loss: 2.011556, Acc:0.792459, Semantic loss: 0.742916, BCE loss: 0.552686, SB loss: 0.715954
2023-10-30 18:50:13,306 Epoch: [336/484] Iter:[30/495], Time: 0.42, lr: [0.0034412373362652142], Loss: 2.016367, Acc:0.791069, Semantic loss: 0.741364, BCE loss: 0.567512, SB loss: 0.707491
2023-10-30 18:50:16,771 Epoch: [336/484] Iter:[40/495], Time: 0.40, lr: [0.003440814403758021], Loss: 1.968355, Acc:0.784604, Semantic loss: 0.727835, BCE loss: 0.542115, SB loss: 0.698405
2023-10-30 18:50:20,195 Epoch: [336/484] Iter:[50/495], Time: 0.39, lr: [0.0034403914654746], Loss: 1.956966, Acc:0.788057, Semantic loss: 0.723148, BCE loss: 0.537872, SB loss: 0.695946
2023-10-30 18:50:23,647 Epoch: [336/484] Iter:[60/495], Time: 0.38, lr: [0.003439968521414083], Loss: 1.957716, Acc:0.794479, Semantic loss: 0.726059, BCE loss: 0.533046, SB loss: 0.698611
2023-10-30 18:50:27,207 Epoch: [336/484] Iter:[70/495], Time: 0.38, lr: [0.003439545571575602], Loss: 1.975693, Acc:0.798535, Semantic loss: 0.738158, BCE loss: 0.537597, SB loss: 0.699938
2023-10-30 18:50:30,803 Epoch: [336/484] Iter:[80/495], Time: 0.38, lr: [0.003439122615958289], Loss: 1.967819, Acc:0.799170, Semantic loss: 0.734450, BCE loss: 0.532140, SB loss: 0.701230
2023-10-30 18:50:34,401 Epoch: [336/484] Iter:[90/495], Time: 0.37, lr: [0.0034386996545612753], Loss: 1.974898, Acc:0.802572, Semantic loss: 0.734299, BCE loss: 0.536774, SB loss: 0.703825
2023-10-30 18:50:38,038 Epoch: [336/484] Iter:[100/495], Time: 0.37, lr: [0.0034382766873836917], Loss: 1.972462, Acc:0.802886, Semantic loss: 0.732494, BCE loss: 0.534789, SB loss: 0.705179
2023-10-30 18:50:41,583 Epoch: [336/484] Iter:[110/495], Time: 0.37, lr: [0.0034378537144246686], Loss: 1.972987, Acc:0.803945, Semantic loss: 0.734437, BCE loss: 0.534610, SB loss: 0.703940
2023-10-30 18:50:45,305 Epoch: [336/484] Iter:[120/495], Time: 0.37, lr: [0.003437430735683338], Loss: 1.967759, Acc:0.804780, Semantic loss: 0.731031, BCE loss: 0.532805, SB loss: 0.703924
2023-10-30 18:50:48,905 Epoch: [336/484] Iter:[130/495], Time: 0.37, lr: [0.0034370077511588293], Loss: 1.975489, Acc:0.806779, Semantic loss: 0.732478, BCE loss: 0.537959, SB loss: 0.705052
2023-10-30 18:50:52,479 Epoch: [336/484] Iter:[140/495], Time: 0.37, lr: [0.0034365847608502733], Loss: 1.965034, Acc:0.806069, Semantic loss: 0.728064, BCE loss: 0.534442, SB loss: 0.702528
2023-10-30 18:50:56,078 Epoch: [336/484] Iter:[150/495], Time: 0.37, lr: [0.003436161764756798], Loss: 1.976182, Acc:0.803519, Semantic loss: 0.735554, BCE loss: 0.533848, SB loss: 0.706780
2023-10-30 18:50:59,684 Epoch: [336/484] Iter:[160/495], Time: 0.37, lr: [0.0034357387628775357], Loss: 1.975762, Acc:0.803122, Semantic loss: 0.735484, BCE loss: 0.533645, SB loss: 0.706633
2023-10-30 18:51:03,411 Epoch: [336/484] Iter:[170/495], Time: 0.37, lr: [0.0034353157552116137], Loss: 1.974466, Acc:0.804545, Semantic loss: 0.735682, BCE loss: 0.534000, SB loss: 0.704784
2023-10-30 18:51:07,073 Epoch: [336/484] Iter:[180/495], Time: 0.37, lr: [0.003434892741758162], Loss: 1.976537, Acc:0.805531, Semantic loss: 0.737240, BCE loss: 0.533945, SB loss: 0.705352
2023-10-30 18:51:10,656 Epoch: [336/484] Iter:[190/495], Time: 0.37, lr: [0.0034344697225163084], Loss: 1.974839, Acc:0.803135, Semantic loss: 0.737002, BCE loss: 0.531762, SB loss: 0.706075
2023-10-30 18:51:14,214 Epoch: [336/484] Iter:[200/495], Time: 0.37, lr: [0.003434046697485183], Loss: 1.974030, Acc:0.802611, Semantic loss: 0.736857, BCE loss: 0.531929, SB loss: 0.705243
2023-10-30 18:51:17,773 Epoch: [336/484] Iter:[210/495], Time: 0.37, lr: [0.0034336236666639144], Loss: 1.977925, Acc:0.803501, Semantic loss: 0.740446, BCE loss: 0.531530, SB loss: 0.705949
2023-10-30 18:51:21,342 Epoch: [336/484] Iter:[220/495], Time: 0.37, lr: [0.003433200630051629], Loss: 1.972746, Acc:0.803828, Semantic loss: 0.736872, BCE loss: 0.531120, SB loss: 0.704754
2023-10-30 18:51:25,066 Epoch: [336/484] Iter:[230/495], Time: 0.37, lr: [0.0034327775876474543], Loss: 1.972727, Acc:0.804228, Semantic loss: 0.736884, BCE loss: 0.529704, SB loss: 0.706139
2023-10-30 18:51:28,616 Epoch: [336/484] Iter:[240/495], Time: 0.37, lr: [0.0034323545394505206], Loss: 1.985499, Acc:0.804254, Semantic loss: 0.744777, BCE loss: 0.531489, SB loss: 0.709232
2023-10-30 18:51:32,184 Epoch: [336/484] Iter:[250/495], Time: 0.37, lr: [0.0034319314854599535], Loss: 1.979934, Acc:0.803043, Semantic loss: 0.741265, BCE loss: 0.530379, SB loss: 0.708290
2023-10-30 18:51:35,782 Epoch: [336/484] Iter:[260/495], Time: 0.37, lr: [0.0034315084256748805], Loss: 1.979548, Acc:0.802873, Semantic loss: 0.741459, BCE loss: 0.530574, SB loss: 0.707514
2023-10-30 18:51:39,374 Epoch: [336/484] Iter:[270/495], Time: 0.37, lr: [0.003431085360094427], Loss: 1.980226, Acc:0.802302, Semantic loss: 0.742734, BCE loss: 0.528684, SB loss: 0.708808
2023-10-30 18:51:43,044 Epoch: [336/484] Iter:[280/495], Time: 0.37, lr: [0.0034306622887177226], Loss: 1.982687, Acc:0.801732, Semantic loss: 0.743478, BCE loss: 0.529602, SB loss: 0.709608
2023-10-30 18:51:46,789 Epoch: [336/484] Iter:[290/495], Time: 0.37, lr: [0.0034302392115438908], Loss: 1.984304, Acc:0.801295, Semantic loss: 0.745381, BCE loss: 0.528708, SB loss: 0.710215
2023-10-30 18:51:50,338 Epoch: [336/484] Iter:[300/495], Time: 0.37, lr: [0.0034298161285720597], Loss: 1.983981, Acc:0.800346, Semantic loss: 0.745504, BCE loss: 0.527779, SB loss: 0.710699
2023-10-30 18:51:53,987 Epoch: [336/484] Iter:[310/495], Time: 0.37, lr: [0.0034293930398013525], Loss: 1.985556, Acc:0.800400, Semantic loss: 0.745895, BCE loss: 0.528313, SB loss: 0.711349
2023-10-30 18:51:57,689 Epoch: [336/484] Iter:[320/495], Time: 0.37, lr: [0.003428969945230898], Loss: 1.983274, Acc:0.801114, Semantic loss: 0.745532, BCE loss: 0.526383, SB loss: 0.711358
2023-10-30 18:52:01,388 Epoch: [336/484] Iter:[330/495], Time: 0.37, lr: [0.00342854684485982], Loss: 1.987757, Acc:0.799908, Semantic loss: 0.748446, BCE loss: 0.526071, SB loss: 0.713239
2023-10-30 18:52:05,023 Epoch: [336/484] Iter:[340/495], Time: 0.37, lr: [0.0034281237386872437], Loss: 1.988566, Acc:0.800190, Semantic loss: 0.747701, BCE loss: 0.528032, SB loss: 0.712833
2023-10-30 18:52:08,657 Epoch: [336/484] Iter:[350/495], Time: 0.37, lr: [0.003427700626712293], Loss: 1.988612, Acc:0.799869, Semantic loss: 0.748377, BCE loss: 0.527403, SB loss: 0.712831
2023-10-30 18:52:12,337 Epoch: [336/484] Iter:[360/495], Time: 0.37, lr: [0.003427277508934094], Loss: 1.991913, Acc:0.799926, Semantic loss: 0.751043, BCE loss: 0.527850, SB loss: 0.713020
2023-10-30 18:52:15,914 Epoch: [336/484] Iter:[370/495], Time: 0.37, lr: [0.003426854385351771], Loss: 1.991496, Acc:0.801107, Semantic loss: 0.750089, BCE loss: 0.528800, SB loss: 0.712607
2023-10-30 18:52:19,590 Epoch: [336/484] Iter:[380/495], Time: 0.37, lr: [0.0034264312559644473], Loss: 1.996044, Acc:0.800792, Semantic loss: 0.752294, BCE loss: 0.530492, SB loss: 0.713258
2023-10-30 18:52:23,306 Epoch: [336/484] Iter:[390/495], Time: 0.37, lr: [0.003426008120771246], Loss: 1.997887, Acc:0.801875, Semantic loss: 0.751627, BCE loss: 0.532549, SB loss: 0.713710
2023-10-30 18:52:26,962 Epoch: [336/484] Iter:[400/495], Time: 0.37, lr: [0.0034255849797712916], Loss: 1.998041, Acc:0.801152, Semantic loss: 0.752265, BCE loss: 0.531867, SB loss: 0.713909
2023-10-30 18:52:30,780 Epoch: [336/484] Iter:[410/495], Time: 0.37, lr: [0.0034251618329637083], Loss: 1.997508, Acc:0.801497, Semantic loss: 0.751693, BCE loss: 0.531410, SB loss: 0.714404
2023-10-30 18:52:34,364 Epoch: [336/484] Iter:[420/495], Time: 0.37, lr: [0.0034247386803476186], Loss: 2.000799, Acc:0.801485, Semantic loss: 0.754249, BCE loss: 0.532300, SB loss: 0.714250
2023-10-30 18:52:37,967 Epoch: [336/484] Iter:[430/495], Time: 0.37, lr: [0.0034243155219221433], Loss: 2.001138, Acc:0.801019, Semantic loss: 0.754250, BCE loss: 0.532428, SB loss: 0.714459
2023-10-30 18:52:41,577 Epoch: [336/484] Iter:[440/495], Time: 0.37, lr: [0.0034238923576864083], Loss: 1.997703, Acc:0.801946, Semantic loss: 0.751989, BCE loss: 0.532087, SB loss: 0.713627
2023-10-30 18:52:45,179 Epoch: [336/484] Iter:[450/495], Time: 0.37, lr: [0.0034234691876395343], Loss: 1.995731, Acc:0.801561, Semantic loss: 0.750917, BCE loss: 0.532036, SB loss: 0.712777
2023-10-30 18:52:48,758 Epoch: [336/484] Iter:[460/495], Time: 0.37, lr: [0.0034230460117806415], Loss: 1.997386, Acc:0.802608, Semantic loss: 0.751595, BCE loss: 0.532363, SB loss: 0.713428
2023-10-30 18:52:52,469 Epoch: [336/484] Iter:[470/495], Time: 0.37, lr: [0.003422622830108855], Loss: 1.996123, Acc:0.802787, Semantic loss: 0.751276, BCE loss: 0.531321, SB loss: 0.713526
2023-10-30 18:52:56,065 Epoch: [336/484] Iter:[480/495], Time: 0.37, lr: [0.0034221996426232956], Loss: 1.999884, Acc:0.801766, Semantic loss: 0.753637, BCE loss: 0.531600, SB loss: 0.714648
2023-10-30 18:52:59,462 Epoch: [336/484] Iter:[490/495], Time: 0.36, lr: [0.003421776449323083], Loss: 1.999966, Acc:0.801988, Semantic loss: 0.754194, BCE loss: 0.530406, SB loss: 0.715366
2023-10-30 18:53:00,844 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:53:01,084 Loss: 2.020, MeanIU:  0.7117, Best_mIoU:  0.7309
2023-10-30 18:53:01,084 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559]
2023-10-30 18:53:03,189 Epoch: [337/484] Iter:[0/495], Time: 2.07, lr: [0.003421564850492208], Loss: 2.117374, Acc:0.881472, Semantic loss: 0.870482, BCE loss: 0.457747, SB loss: 0.789145
2023-10-30 18:53:07,203 Epoch: [337/484] Iter:[10/495], Time: 0.55, lr: [0.003421141648468368], Loss: 2.053692, Acc:0.790003, Semantic loss: 0.801442, BCE loss: 0.527803, SB loss: 0.724447
2023-10-30 18:53:10,939 Epoch: [337/484] Iter:[20/495], Time: 0.47, lr: [0.0034207184406276786], Loss: 1.964766, Acc:0.786391, Semantic loss: 0.734154, BCE loss: 0.511157, SB loss: 0.719455
2023-10-30 18:53:14,451 Epoch: [337/484] Iter:[30/495], Time: 0.43, lr: [0.00342029522696926], Loss: 1.973869, Acc:0.801674, Semantic loss: 0.727217, BCE loss: 0.533681, SB loss: 0.712971
2023-10-30 18:53:18,158 Epoch: [337/484] Iter:[40/495], Time: 0.42, lr: [0.0034198720074922317], Loss: 1.951379, Acc:0.796757, Semantic loss: 0.720033, BCE loss: 0.526926, SB loss: 0.704420
2023-10-30 18:53:21,849 Epoch: [337/484] Iter:[50/495], Time: 0.41, lr: [0.0034194487821957126], Loss: 1.957410, Acc:0.800271, Semantic loss: 0.732029, BCE loss: 0.515616, SB loss: 0.709766
2023-10-30 18:53:25,490 Epoch: [337/484] Iter:[60/495], Time: 0.40, lr: [0.003419025551078825], Loss: 1.954140, Acc:0.801537, Semantic loss: 0.731693, BCE loss: 0.511507, SB loss: 0.710940
2023-10-30 18:53:29,101 Epoch: [337/484] Iter:[70/495], Time: 0.39, lr: [0.003418602314140686], Loss: 1.955865, Acc:0.800591, Semantic loss: 0.734802, BCE loss: 0.509598, SB loss: 0.711465
2023-10-30 18:53:32,811 Epoch: [337/484] Iter:[80/495], Time: 0.39, lr: [0.003418179071380416], Loss: 1.964355, Acc:0.801712, Semantic loss: 0.729363, BCE loss: 0.523628, SB loss: 0.711364
2023-10-30 18:53:36,513 Epoch: [337/484] Iter:[90/495], Time: 0.39, lr: [0.003417755822797132], Loss: 1.967366, Acc:0.799418, Semantic loss: 0.733756, BCE loss: 0.518567, SB loss: 0.715043
2023-10-30 18:53:40,219 Epoch: [337/484] Iter:[100/495], Time: 0.39, lr: [0.003417332568389955], Loss: 1.973608, Acc:0.798790, Semantic loss: 0.738275, BCE loss: 0.518428, SB loss: 0.716905
2023-10-30 18:53:43,827 Epoch: [337/484] Iter:[110/495], Time: 0.38, lr: [0.0034169093081580022], Loss: 1.978168, Acc:0.802513, Semantic loss: 0.737857, BCE loss: 0.522352, SB loss: 0.717959
2023-10-30 18:53:47,391 Epoch: [337/484] Iter:[120/495], Time: 0.38, lr: [0.0034164860421003924], Loss: 1.982921, Acc:0.803994, Semantic loss: 0.740753, BCE loss: 0.523846, SB loss: 0.718323
2023-10-30 18:53:51,015 Epoch: [337/484] Iter:[130/495], Time: 0.38, lr: [0.0034160627702162416], Loss: 1.988694, Acc:0.804115, Semantic loss: 0.744022, BCE loss: 0.525994, SB loss: 0.718678
2023-10-30 18:53:54,616 Epoch: [337/484] Iter:[140/495], Time: 0.38, lr: [0.00341563949250467], Loss: 1.984223, Acc:0.806591, Semantic loss: 0.741922, BCE loss: 0.524643, SB loss: 0.717658
2023-10-30 18:53:58,256 Epoch: [337/484] Iter:[150/495], Time: 0.38, lr: [0.003415216208964794], Loss: 1.990783, Acc:0.805974, Semantic loss: 0.744411, BCE loss: 0.528715, SB loss: 0.717657
2023-10-30 18:54:01,966 Epoch: [337/484] Iter:[160/495], Time: 0.38, lr: [0.0034147929195957293], Loss: 1.991942, Acc:0.807115, Semantic loss: 0.745393, BCE loss: 0.528474, SB loss: 0.718075
2023-10-30 18:54:05,645 Epoch: [337/484] Iter:[170/495], Time: 0.38, lr: [0.003414369624396594], Loss: 1.990524, Acc:0.808105, Semantic loss: 0.746656, BCE loss: 0.526110, SB loss: 0.717758
2023-10-30 18:54:09,192 Epoch: [337/484] Iter:[180/495], Time: 0.38, lr: [0.003413946323366505], Loss: 1.990020, Acc:0.806836, Semantic loss: 0.744313, BCE loss: 0.528877, SB loss: 0.716830
2023-10-30 18:54:12,874 Epoch: [337/484] Iter:[190/495], Time: 0.38, lr: [0.0034135230165045784], Loss: 1.984997, Acc:0.806806, Semantic loss: 0.741019, BCE loss: 0.528724, SB loss: 0.715255
2023-10-30 18:54:16,441 Epoch: [337/484] Iter:[200/495], Time: 0.37, lr: [0.00341309970380993], Loss: 1.982457, Acc:0.807569, Semantic loss: 0.739822, BCE loss: 0.528010, SB loss: 0.714625
2023-10-30 18:54:20,064 Epoch: [337/484] Iter:[210/495], Time: 0.37, lr: [0.003412676385281675], Loss: 1.979376, Acc:0.808359, Semantic loss: 0.738645, BCE loss: 0.527441, SB loss: 0.713290
2023-10-30 18:54:23,637 Epoch: [337/484] Iter:[220/495], Time: 0.37, lr: [0.00341225306091893], Loss: 1.976658, Acc:0.807123, Semantic loss: 0.737629, BCE loss: 0.526382, SB loss: 0.712647
2023-10-30 18:54:27,387 Epoch: [337/484] Iter:[230/495], Time: 0.37, lr: [0.0034118297307208106], Loss: 1.979517, Acc:0.806711, Semantic loss: 0.739838, BCE loss: 0.526376, SB loss: 0.713303
2023-10-30 18:54:31,007 Epoch: [337/484] Iter:[240/495], Time: 0.37, lr: [0.003411406394686431], Loss: 1.987619, Acc:0.806679, Semantic loss: 0.747993, BCE loss: 0.525272, SB loss: 0.714354
2023-10-30 18:54:34,712 Epoch: [337/484] Iter:[250/495], Time: 0.37, lr: [0.003410983052814905], Loss: 1.989520, Acc:0.806335, Semantic loss: 0.747402, BCE loss: 0.526990, SB loss: 0.715129
2023-10-30 18:54:38,359 Epoch: [337/484] Iter:[260/495], Time: 0.37, lr: [0.0034105597051053496], Loss: 1.986804, Acc:0.807463, Semantic loss: 0.743606, BCE loss: 0.528351, SB loss: 0.714847
2023-10-30 18:54:42,070 Epoch: [337/484] Iter:[270/495], Time: 0.37, lr: [0.003410136351556878], Loss: 1.986464, Acc:0.807980, Semantic loss: 0.743124, BCE loss: 0.527989, SB loss: 0.715351
2023-10-30 18:54:45,710 Epoch: [337/484] Iter:[280/495], Time: 0.37, lr: [0.003409712992168604], Loss: 1.989425, Acc:0.808156, Semantic loss: 0.743421, BCE loss: 0.529871, SB loss: 0.716133
2023-10-30 18:54:49,436 Epoch: [337/484] Iter:[290/495], Time: 0.37, lr: [0.00340928962693964], Loss: 1.987118, Acc:0.808581, Semantic loss: 0.741683, BCE loss: 0.529240, SB loss: 0.716195
2023-10-30 18:54:52,970 Epoch: [337/484] Iter:[300/495], Time: 0.37, lr: [0.003408866255869102], Loss: 1.990377, Acc:0.809065, Semantic loss: 0.741211, BCE loss: 0.533283, SB loss: 0.715883
2023-10-30 18:54:56,600 Epoch: [337/484] Iter:[310/495], Time: 0.37, lr: [0.003408442878956103], Loss: 1.990098, Acc:0.809791, Semantic loss: 0.740993, BCE loss: 0.533855, SB loss: 0.715250
2023-10-30 18:55:00,317 Epoch: [337/484] Iter:[320/495], Time: 0.37, lr: [0.003408019496199753], Loss: 1.992787, Acc:0.809577, Semantic loss: 0.743996, BCE loss: 0.533171, SB loss: 0.715620
2023-10-30 18:55:03,960 Epoch: [337/484] Iter:[330/495], Time: 0.37, lr: [0.003407596107599169], Loss: 1.992426, Acc:0.810063, Semantic loss: 0.743722, BCE loss: 0.533248, SB loss: 0.715456
2023-10-30 18:55:07,581 Epoch: [337/484] Iter:[340/495], Time: 0.37, lr: [0.0034071727131534607], Loss: 1.993444, Acc:0.809829, Semantic loss: 0.744733, BCE loss: 0.533027, SB loss: 0.715684
2023-10-30 18:55:11,112 Epoch: [337/484] Iter:[350/495], Time: 0.37, lr: [0.0034067493128617414], Loss: 1.992288, Acc:0.809117, Semantic loss: 0.744828, BCE loss: 0.531978, SB loss: 0.715482
2023-10-30 18:55:14,822 Epoch: [337/484] Iter:[360/495], Time: 0.37, lr: [0.0034063259067231223], Loss: 1.990001, Acc:0.808882, Semantic loss: 0.744007, BCE loss: 0.530602, SB loss: 0.715392
2023-10-30 18:55:18,570 Epoch: [337/484] Iter:[370/495], Time: 0.37, lr: [0.0034059024947367157], Loss: 1.988438, Acc:0.808771, Semantic loss: 0.742869, BCE loss: 0.530874, SB loss: 0.714696
2023-10-30 18:55:22,244 Epoch: [337/484] Iter:[380/495], Time: 0.37, lr: [0.003405479076901634], Loss: 1.987734, Acc:0.809527, Semantic loss: 0.741506, BCE loss: 0.531384, SB loss: 0.714844
2023-10-30 18:55:25,877 Epoch: [337/484] Iter:[390/495], Time: 0.37, lr: [0.0034050556532169863], Loss: 1.988050, Acc:0.809587, Semantic loss: 0.742478, BCE loss: 0.531377, SB loss: 0.714194
2023-10-30 18:55:29,581 Epoch: [337/484] Iter:[400/495], Time: 0.37, lr: [0.0034046322236818837], Loss: 1.985429, Acc:0.809664, Semantic loss: 0.741676, BCE loss: 0.529774, SB loss: 0.713979
2023-10-30 18:55:33,255 Epoch: [337/484] Iter:[410/495], Time: 0.37, lr: [0.0034042087882954386], Loss: 1.985979, Acc:0.808219, Semantic loss: 0.742263, BCE loss: 0.529494, SB loss: 0.714222
2023-10-30 18:55:36,904 Epoch: [337/484] Iter:[420/495], Time: 0.37, lr: [0.0034037853470567613], Loss: 1.988337, Acc:0.808374, Semantic loss: 0.742540, BCE loss: 0.531293, SB loss: 0.714504
2023-10-30 18:55:40,498 Epoch: [337/484] Iter:[430/495], Time: 0.37, lr: [0.0034033618999649608], Loss: 1.986349, Acc:0.807633, Semantic loss: 0.742199, BCE loss: 0.529865, SB loss: 0.714285
2023-10-30 18:55:44,187 Epoch: [337/484] Iter:[440/495], Time: 0.37, lr: [0.0034029384470191464], Loss: 1.986561, Acc:0.807189, Semantic loss: 0.741752, BCE loss: 0.530786, SB loss: 0.714023
2023-10-30 18:55:47,782 Epoch: [337/484] Iter:[450/495], Time: 0.37, lr: [0.0034025149882184295], Loss: 1.988053, Acc:0.808259, Semantic loss: 0.743040, BCE loss: 0.531053, SB loss: 0.713960
2023-10-30 18:55:51,398 Epoch: [337/484] Iter:[460/495], Time: 0.37, lr: [0.0034020915235619194], Loss: 1.985446, Acc:0.808494, Semantic loss: 0.741869, BCE loss: 0.530336, SB loss: 0.713241
2023-10-30 18:55:54,980 Epoch: [337/484] Iter:[470/495], Time: 0.37, lr: [0.0034016680530487243], Loss: 1.985255, Acc:0.808446, Semantic loss: 0.742637, BCE loss: 0.529394, SB loss: 0.713224
2023-10-30 18:55:58,655 Epoch: [337/484] Iter:[480/495], Time: 0.37, lr: [0.0034012445766779527], Loss: 1.982860, Acc:0.807667, Semantic loss: 0.741921, BCE loss: 0.528089, SB loss: 0.712850
2023-10-30 18:56:02,088 Epoch: [337/484] Iter:[490/495], Time: 0.37, lr: [0.0034008210944487145], Loss: 1.985483, Acc:0.807188, Semantic loss: 0.742555, BCE loss: 0.529454, SB loss: 0.713475
2023-10-30 18:56:03,485 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:56:03,724 Loss: 2.020, MeanIU:  0.7117, Best_mIoU:  0.7309
2023-10-30 18:56:03,724 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559]
2023-10-30 18:56:05,854 Epoch: [338/484] Iter:[0/495], Time: 2.10, lr: [0.0034006093511368914], Loss: 1.826047, Acc:0.745118, Semantic loss: 0.677352, BCE loss: 0.445323, SB loss: 0.703371
2023-10-30 18:56:09,937 Epoch: [338/484] Iter:[10/495], Time: 0.56, lr: [0.0034001858601182804], Loss: 1.865316, Acc:0.825718, Semantic loss: 0.695303, BCE loss: 0.453968, SB loss: 0.716045
2023-10-30 18:56:13,608 Epoch: [338/484] Iter:[20/495], Time: 0.47, lr: [0.0033997623632389734], Loss: 1.832901, Acc:0.817339, Semantic loss: 0.669305, BCE loss: 0.471848, SB loss: 0.691749
2023-10-30 18:56:17,340 Epoch: [338/484] Iter:[30/495], Time: 0.44, lr: [0.0033993388604980756], Loss: 1.853957, Acc:0.815784, Semantic loss: 0.676141, BCE loss: 0.481111, SB loss: 0.696705
2023-10-30 18:56:21,008 Epoch: [338/484] Iter:[40/495], Time: 0.42, lr: [0.0033989153518946967], Loss: 1.871319, Acc:0.813842, Semantic loss: 0.681974, BCE loss: 0.487932, SB loss: 0.701413
2023-10-30 18:56:24,788 Epoch: [338/484] Iter:[50/495], Time: 0.41, lr: [0.0033984918374279443], Loss: 1.896647, Acc:0.812389, Semantic loss: 0.691654, BCE loss: 0.503433, SB loss: 0.701560
2023-10-30 18:56:28,447 Epoch: [338/484] Iter:[60/495], Time: 0.40, lr: [0.003398068317096924], Loss: 1.910388, Acc:0.818137, Semantic loss: 0.693364, BCE loss: 0.520667, SB loss: 0.696357
2023-10-30 18:56:32,155 Epoch: [338/484] Iter:[70/495], Time: 0.40, lr: [0.003397644790900742], Loss: 1.923249, Acc:0.813968, Semantic loss: 0.702932, BCE loss: 0.519400, SB loss: 0.700917
2023-10-30 18:56:35,832 Epoch: [338/484] Iter:[80/495], Time: 0.40, lr: [0.0033972212588385064], Loss: 1.938365, Acc:0.814894, Semantic loss: 0.710589, BCE loss: 0.524150, SB loss: 0.703626
2023-10-30 18:56:39,490 Epoch: [338/484] Iter:[90/495], Time: 0.39, lr: [0.0033967977209093227], Loss: 1.943101, Acc:0.815289, Semantic loss: 0.710812, BCE loss: 0.528307, SB loss: 0.703981
2023-10-30 18:56:43,043 Epoch: [338/484] Iter:[100/495], Time: 0.39, lr: [0.0033963741771122964], Loss: 1.937343, Acc:0.809970, Semantic loss: 0.709722, BCE loss: 0.525014, SB loss: 0.702608
2023-10-30 18:56:46,823 Epoch: [338/484] Iter:[110/495], Time: 0.39, lr: [0.0033959506274465322], Loss: 1.938116, Acc:0.807185, Semantic loss: 0.713690, BCE loss: 0.520573, SB loss: 0.703854
2023-10-30 18:56:50,356 Epoch: [338/484] Iter:[120/495], Time: 0.39, lr: [0.0033955270719111382], Loss: 1.937985, Acc:0.805290, Semantic loss: 0.713234, BCE loss: 0.521735, SB loss: 0.703015
2023-10-30 18:56:54,047 Epoch: [338/484] Iter:[130/495], Time: 0.38, lr: [0.003395103510505217], Loss: 1.943853, Acc:0.802788, Semantic loss: 0.720094, BCE loss: 0.521184, SB loss: 0.702575
2023-10-30 18:56:57,802 Epoch: [338/484] Iter:[140/495], Time: 0.38, lr: [0.003394679943227874], Loss: 1.943477, Acc:0.801396, Semantic loss: 0.721619, BCE loss: 0.520611, SB loss: 0.701248
2023-10-30 18:57:01,438 Epoch: [338/484] Iter:[150/495], Time: 0.38, lr: [0.0033942563700782146], Loss: 1.946895, Acc:0.803312, Semantic loss: 0.722349, BCE loss: 0.524207, SB loss: 0.700339
2023-10-30 18:57:05,188 Epoch: [338/484] Iter:[160/495], Time: 0.38, lr: [0.0033938327910553435], Loss: 1.935308, Acc:0.804308, Semantic loss: 0.717414, BCE loss: 0.520109, SB loss: 0.697785
2023-10-30 18:57:08,889 Epoch: [338/484] Iter:[170/495], Time: 0.38, lr: [0.0033934092061583634], Loss: 1.933652, Acc:0.804946, Semantic loss: 0.717231, BCE loss: 0.518582, SB loss: 0.697839
2023-10-30 18:57:12,584 Epoch: [338/484] Iter:[180/495], Time: 0.38, lr: [0.0033929856153863775], Loss: 1.932689, Acc:0.805207, Semantic loss: 0.717428, BCE loss: 0.516586, SB loss: 0.698675
2023-10-30 18:57:16,350 Epoch: [338/484] Iter:[190/495], Time: 0.38, lr: [0.003392562018738492], Loss: 1.935748, Acc:0.805223, Semantic loss: 0.718510, BCE loss: 0.517277, SB loss: 0.699961
2023-10-30 18:57:20,098 Epoch: [338/484] Iter:[200/495], Time: 0.38, lr: [0.003392138416213808], Loss: 1.933099, Acc:0.805736, Semantic loss: 0.716826, BCE loss: 0.516427, SB loss: 0.699846
2023-10-30 18:57:23,747 Epoch: [338/484] Iter:[210/495], Time: 0.38, lr: [0.0033917148078114294], Loss: 1.936964, Acc:0.806086, Semantic loss: 0.718836, BCE loss: 0.518788, SB loss: 0.699341
2023-10-30 18:57:27,543 Epoch: [338/484] Iter:[220/495], Time: 0.38, lr: [0.003391291193530458], Loss: 1.932162, Acc:0.806733, Semantic loss: 0.717944, BCE loss: 0.517112, SB loss: 0.697107
2023-10-30 18:57:31,135 Epoch: [338/484] Iter:[230/495], Time: 0.38, lr: [0.0033908675733699983], Loss: 1.934236, Acc:0.808027, Semantic loss: 0.717957, BCE loss: 0.518270, SB loss: 0.698009
2023-10-30 18:57:34,709 Epoch: [338/484] Iter:[240/495], Time: 0.38, lr: [0.003390443947329151], Loss: 1.933874, Acc:0.808077, Semantic loss: 0.718901, BCE loss: 0.517403, SB loss: 0.697570
2023-10-30 18:57:38,379 Epoch: [338/484] Iter:[250/495], Time: 0.38, lr: [0.003390020315407018], Loss: 1.933030, Acc:0.806863, Semantic loss: 0.718871, BCE loss: 0.516463, SB loss: 0.697696
2023-10-30 18:57:42,000 Epoch: [338/484] Iter:[260/495], Time: 0.38, lr: [0.003389596677602701], Loss: 1.934169, Acc:0.806526, Semantic loss: 0.719684, BCE loss: 0.516845, SB loss: 0.697640
2023-10-30 18:57:45,690 Epoch: [338/484] Iter:[270/495], Time: 0.38, lr: [0.0033891730339153025], Loss: 1.933544, Acc:0.805405, Semantic loss: 0.719089, BCE loss: 0.516703, SB loss: 0.697752
2023-10-30 18:57:49,485 Epoch: [338/484] Iter:[280/495], Time: 0.38, lr: [0.0033887493843439225], Loss: 1.937135, Acc:0.806380, Semantic loss: 0.720251, BCE loss: 0.517527, SB loss: 0.699356
2023-10-30 18:57:53,183 Epoch: [338/484] Iter:[290/495], Time: 0.38, lr: [0.0033883257288876635], Loss: 1.940949, Acc:0.807648, Semantic loss: 0.722133, BCE loss: 0.518420, SB loss: 0.700396
2023-10-30 18:57:56,719 Epoch: [338/484] Iter:[300/495], Time: 0.38, lr: [0.0033879020675456235], Loss: 1.940759, Acc:0.807196, Semantic loss: 0.721311, BCE loss: 0.519206, SB loss: 0.700242
2023-10-30 18:58:00,537 Epoch: [338/484] Iter:[310/495], Time: 0.38, lr: [0.0033874784003169057], Loss: 1.940055, Acc:0.807724, Semantic loss: 0.720240, BCE loss: 0.519816, SB loss: 0.700000
2023-10-30 18:58:04,144 Epoch: [338/484] Iter:[320/495], Time: 0.38, lr: [0.0033870547272006088], Loss: 1.940061, Acc:0.806727, Semantic loss: 0.721277, BCE loss: 0.518654, SB loss: 0.700131
2023-10-30 18:58:07,836 Epoch: [338/484] Iter:[330/495], Time: 0.37, lr: [0.003386631048195833], Loss: 1.941077, Acc:0.807170, Semantic loss: 0.722407, BCE loss: 0.518117, SB loss: 0.700553
2023-10-30 18:58:11,500 Epoch: [338/484] Iter:[340/495], Time: 0.37, lr: [0.003386207363301677], Loss: 1.941947, Acc:0.806954, Semantic loss: 0.723483, BCE loss: 0.517972, SB loss: 0.700492
2023-10-30 18:58:15,204 Epoch: [338/484] Iter:[350/495], Time: 0.37, lr: [0.003385783672517242], Loss: 1.942485, Acc:0.808070, Semantic loss: 0.723364, BCE loss: 0.518510, SB loss: 0.700611
2023-10-30 18:58:18,837 Epoch: [338/484] Iter:[360/495], Time: 0.37, lr: [0.003385359975841626], Loss: 1.943713, Acc:0.808029, Semantic loss: 0.723726, BCE loss: 0.518973, SB loss: 0.701014
2023-10-30 18:58:22,510 Epoch: [338/484] Iter:[370/495], Time: 0.37, lr: [0.003384936273273928], Loss: 1.947768, Acc:0.807654, Semantic loss: 0.725956, BCE loss: 0.520518, SB loss: 0.701294
2023-10-30 18:58:26,272 Epoch: [338/484] Iter:[380/495], Time: 0.37, lr: [0.0033845125648132453], Loss: 1.948144, Acc:0.807233, Semantic loss: 0.726676, BCE loss: 0.520379, SB loss: 0.701089
2023-10-30 18:58:29,987 Epoch: [338/484] Iter:[390/495], Time: 0.37, lr: [0.0033840888504586782], Loss: 1.950097, Acc:0.807647, Semantic loss: 0.727185, BCE loss: 0.521065, SB loss: 0.701847
2023-10-30 18:58:33,646 Epoch: [338/484] Iter:[400/495], Time: 0.37, lr: [0.003383665130209324], Loss: 1.949138, Acc:0.807373, Semantic loss: 0.726275, BCE loss: 0.521480, SB loss: 0.701382
2023-10-30 18:58:37,370 Epoch: [338/484] Iter:[410/495], Time: 0.37, lr: [0.0033832414040642807], Loss: 1.949462, Acc:0.806935, Semantic loss: 0.725268, BCE loss: 0.522970, SB loss: 0.701223
2023-10-30 18:58:40,985 Epoch: [338/484] Iter:[420/495], Time: 0.37, lr: [0.0033828176720226443], Loss: 1.949218, Acc:0.808035, Semantic loss: 0.725116, BCE loss: 0.523196, SB loss: 0.700906
2023-10-30 18:58:44,662 Epoch: [338/484] Iter:[430/495], Time: 0.37, lr: [0.003382393934083514], Loss: 1.951576, Acc:0.808404, Semantic loss: 0.726249, BCE loss: 0.524277, SB loss: 0.701050
2023-10-30 18:58:48,244 Epoch: [338/484] Iter:[440/495], Time: 0.37, lr: [0.0033819701902459867], Loss: 1.950758, Acc:0.808346, Semantic loss: 0.725668, BCE loss: 0.524537, SB loss: 0.700553
2023-10-30 18:58:52,007 Epoch: [338/484] Iter:[450/495], Time: 0.37, lr: [0.003381546440509158], Loss: 1.952367, Acc:0.808106, Semantic loss: 0.726609, BCE loss: 0.524783, SB loss: 0.700976
2023-10-30 18:58:55,638 Epoch: [338/484] Iter:[460/495], Time: 0.37, lr: [0.0033811226848721237], Loss: 1.952198, Acc:0.808100, Semantic loss: 0.726415, BCE loss: 0.524912, SB loss: 0.700870
2023-10-30 18:58:59,207 Epoch: [338/484] Iter:[470/495], Time: 0.37, lr: [0.0033806989233339823], Loss: 1.952248, Acc:0.808207, Semantic loss: 0.726325, BCE loss: 0.524793, SB loss: 0.701129
2023-10-30 18:59:02,851 Epoch: [338/484] Iter:[480/495], Time: 0.37, lr: [0.003380275155893828], Loss: 1.951185, Acc:0.808131, Semantic loss: 0.726164, BCE loss: 0.523150, SB loss: 0.701872
2023-10-30 18:59:06,347 Epoch: [338/484] Iter:[490/495], Time: 0.37, lr: [0.0033798513825507577], Loss: 1.953681, Acc:0.808786, Semantic loss: 0.727026, BCE loss: 0.523774, SB loss: 0.702881
2023-10-30 18:59:07,738 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 18:59:07,978 Loss: 2.020, MeanIU:  0.7117, Best_mIoU:  0.7309
2023-10-30 18:59:07,978 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559]
2023-10-30 18:59:10,117 Epoch: [339/484] Iter:[0/495], Time: 2.11, lr: [0.0033796394936653445], Loss: 1.483401, Acc:0.775263, Semantic loss: 0.566713, BCE loss: 0.325324, SB loss: 0.591364
2023-10-30 18:59:13,973 Epoch: [339/484] Iter:[10/495], Time: 0.54, lr: [0.0033792157114662024], Loss: 1.975377, Acc:0.802623, Semantic loss: 0.731418, BCE loss: 0.544229, SB loss: 0.699729
2023-10-30 18:59:17,622 Epoch: [339/484] Iter:[20/495], Time: 0.46, lr: [0.003378791923361882], Loss: 1.917578, Acc:0.796146, Semantic loss: 0.720791, BCE loss: 0.499488, SB loss: 0.697298
2023-10-30 18:59:21,351 Epoch: [339/484] Iter:[30/495], Time: 0.43, lr: [0.003378368129351477], Loss: 1.957745, Acc:0.809778, Semantic loss: 0.744114, BCE loss: 0.514006, SB loss: 0.699625
2023-10-30 18:59:24,977 Epoch: [339/484] Iter:[40/495], Time: 0.41, lr: [0.0033779443294340815], Loss: 1.971444, Acc:0.805977, Semantic loss: 0.741796, BCE loss: 0.528225, SB loss: 0.701423
2023-10-30 18:59:28,639 Epoch: [339/484] Iter:[50/495], Time: 0.40, lr: [0.003377520523608792], Loss: 1.962934, Acc:0.811171, Semantic loss: 0.738334, BCE loss: 0.521837, SB loss: 0.702763
2023-10-30 18:59:32,243 Epoch: [339/484] Iter:[60/495], Time: 0.40, lr: [0.003377096711874701], Loss: 1.968288, Acc:0.814627, Semantic loss: 0.746188, BCE loss: 0.519591, SB loss: 0.702509
2023-10-30 18:59:36,013 Epoch: [339/484] Iter:[70/495], Time: 0.39, lr: [0.0033766728942309023], Loss: 1.982049, Acc:0.818217, Semantic loss: 0.741889, BCE loss: 0.534155, SB loss: 0.706005
2023-10-30 18:59:39,640 Epoch: [339/484] Iter:[80/495], Time: 0.39, lr: [0.003376249070676488], Loss: 2.009036, Acc:0.812451, Semantic loss: 0.754740, BCE loss: 0.530954, SB loss: 0.723342
2023-10-30 18:59:43,363 Epoch: [339/484] Iter:[90/495], Time: 0.39, lr: [0.003375825241210554], Loss: 2.019086, Acc:0.806208, Semantic loss: 0.767395, BCE loss: 0.528326, SB loss: 0.723365
2023-10-30 18:59:46,975 Epoch: [339/484] Iter:[100/495], Time: 0.39, lr: [0.003375401405832191], Loss: 2.014883, Acc:0.806585, Semantic loss: 0.761780, BCE loss: 0.533142, SB loss: 0.719960
2023-10-30 18:59:50,581 Epoch: [339/484] Iter:[110/495], Time: 0.38, lr: [0.003374977564540493], Loss: 2.014246, Acc:0.803989, Semantic loss: 0.761720, BCE loss: 0.531967, SB loss: 0.720559
2023-10-30 18:59:54,181 Epoch: [339/484] Iter:[120/495], Time: 0.38, lr: [0.0033745537173345496], Loss: 2.011567, Acc:0.803860, Semantic loss: 0.759954, BCE loss: 0.529635, SB loss: 0.721979
2023-10-30 18:59:57,762 Epoch: [339/484] Iter:[130/495], Time: 0.38, lr: [0.0033741298642134573], Loss: 2.008541, Acc:0.805163, Semantic loss: 0.757091, BCE loss: 0.530486, SB loss: 0.720964
2023-10-30 19:00:01,427 Epoch: [339/484] Iter:[140/495], Time: 0.38, lr: [0.0033737060051763045], Loss: 1.999926, Acc:0.807100, Semantic loss: 0.752347, BCE loss: 0.528723, SB loss: 0.718856
2023-10-30 19:00:04,933 Epoch: [339/484] Iter:[150/495], Time: 0.38, lr: [0.003373282140222184], Loss: 1.991206, Acc:0.806056, Semantic loss: 0.749405, BCE loss: 0.525342, SB loss: 0.716459
2023-10-30 19:00:08,585 Epoch: [339/484] Iter:[160/495], Time: 0.38, lr: [0.0033728582693501857], Loss: 1.991117, Acc:0.804593, Semantic loss: 0.750739, BCE loss: 0.523096, SB loss: 0.717281
2023-10-30 19:00:12,247 Epoch: [339/484] Iter:[170/495], Time: 0.38, lr: [0.003372434392559403], Loss: 1.990832, Acc:0.803660, Semantic loss: 0.752060, BCE loss: 0.522482, SB loss: 0.716291
2023-10-30 19:00:15,928 Epoch: [339/484] Iter:[180/495], Time: 0.38, lr: [0.0033720105098489256], Loss: 1.987935, Acc:0.802715, Semantic loss: 0.750620, BCE loss: 0.521599, SB loss: 0.715715
2023-10-30 19:00:19,578 Epoch: [339/484] Iter:[190/495], Time: 0.37, lr: [0.003371586621217844], Loss: 1.990837, Acc:0.803419, Semantic loss: 0.752367, BCE loss: 0.522878, SB loss: 0.715593
2023-10-30 19:00:23,258 Epoch: [339/484] Iter:[200/495], Time: 0.37, lr: [0.0033711627266652467], Loss: 1.990192, Acc:0.802399, Semantic loss: 0.750758, BCE loss: 0.524050, SB loss: 0.715384
2023-10-30 19:00:26,840 Epoch: [339/484] Iter:[210/495], Time: 0.37, lr: [0.003370738826190226], Loss: 1.990212, Acc:0.802855, Semantic loss: 0.751704, BCE loss: 0.522485, SB loss: 0.716023
2023-10-30 19:00:30,439 Epoch: [339/484] Iter:[220/495], Time: 0.37, lr: [0.0033703149197918713], Loss: 1.991706, Acc:0.801492, Semantic loss: 0.753026, BCE loss: 0.522048, SB loss: 0.716632
2023-10-30 19:00:34,083 Epoch: [339/484] Iter:[230/495], Time: 0.37, lr: [0.003369891007469271], Loss: 1.987513, Acc:0.801623, Semantic loss: 0.750390, BCE loss: 0.521177, SB loss: 0.715946
2023-10-30 19:00:37,710 Epoch: [339/484] Iter:[240/495], Time: 0.37, lr: [0.003369467089221514], Loss: 1.988870, Acc:0.800216, Semantic loss: 0.751748, BCE loss: 0.520595, SB loss: 0.716527
2023-10-30 19:00:41,391 Epoch: [339/484] Iter:[250/495], Time: 0.37, lr: [0.003369043165047691], Loss: 1.991140, Acc:0.799750, Semantic loss: 0.751643, BCE loss: 0.522675, SB loss: 0.716823
2023-10-30 19:00:45,000 Epoch: [339/484] Iter:[260/495], Time: 0.37, lr: [0.003368619234946889], Loss: 1.987029, Acc:0.799743, Semantic loss: 0.749055, BCE loss: 0.522474, SB loss: 0.715500
2023-10-30 19:00:48,585 Epoch: [339/484] Iter:[270/495], Time: 0.37, lr: [0.0033681952989181975], Loss: 1.989630, Acc:0.800659, Semantic loss: 0.749798, BCE loss: 0.524727, SB loss: 0.715105
2023-10-30 19:00:52,316 Epoch: [339/484] Iter:[280/495], Time: 0.37, lr: [0.003367771356960702], Loss: 1.987112, Acc:0.801268, Semantic loss: 0.749515, BCE loss: 0.523275, SB loss: 0.714322
2023-10-30 19:00:56,010 Epoch: [339/484] Iter:[290/495], Time: 0.37, lr: [0.0033673474090734935], Loss: 1.988391, Acc:0.800164, Semantic loss: 0.750033, BCE loss: 0.523779, SB loss: 0.714579
2023-10-30 19:00:59,544 Epoch: [339/484] Iter:[300/495], Time: 0.37, lr: [0.0033669234552556587], Loss: 1.985364, Acc:0.797978, Semantic loss: 0.748684, BCE loss: 0.522509, SB loss: 0.714170
2023-10-30 19:01:03,122 Epoch: [339/484] Iter:[310/495], Time: 0.37, lr: [0.003366499495506284], Loss: 1.985900, Acc:0.798193, Semantic loss: 0.749356, BCE loss: 0.521717, SB loss: 0.714827
2023-10-30 19:01:06,840 Epoch: [339/484] Iter:[320/495], Time: 0.37, lr: [0.003366075529824456], Loss: 1.984288, Acc:0.797815, Semantic loss: 0.748919, BCE loss: 0.521180, SB loss: 0.714190
2023-10-30 19:01:10,476 Epoch: [339/484] Iter:[330/495], Time: 0.37, lr: [0.003365651558209263], Loss: 1.981675, Acc:0.797875, Semantic loss: 0.748891, BCE loss: 0.519381, SB loss: 0.713404
2023-10-30 19:01:14,348 Epoch: [339/484] Iter:[340/495], Time: 0.37, lr: [0.003365227580659791], Loss: 1.979096, Acc:0.798683, Semantic loss: 0.746956, BCE loss: 0.519924, SB loss: 0.712216
2023-10-30 19:01:17,926 Epoch: [339/484] Iter:[350/495], Time: 0.37, lr: [0.0033648035971751257], Loss: 1.978281, Acc:0.798850, Semantic loss: 0.746257, BCE loss: 0.520378, SB loss: 0.711645
2023-10-30 19:01:21,508 Epoch: [339/484] Iter:[360/495], Time: 0.37, lr: [0.003364379607754352], Loss: 1.976111, Acc:0.798689, Semantic loss: 0.745426, BCE loss: 0.519911, SB loss: 0.710774
2023-10-30 19:01:25,108 Epoch: [339/484] Iter:[370/495], Time: 0.37, lr: [0.003363955612396558], Loss: 1.974153, Acc:0.800079, Semantic loss: 0.743943, BCE loss: 0.520478, SB loss: 0.709732
2023-10-30 19:01:28,757 Epoch: [339/484] Iter:[380/495], Time: 0.37, lr: [0.0033635316111008287], Loss: 1.970614, Acc:0.800283, Semantic loss: 0.743035, BCE loss: 0.519008, SB loss: 0.708570
2023-10-30 19:01:32,375 Epoch: [339/484] Iter:[390/495], Time: 0.37, lr: [0.003363107603866247], Loss: 1.966026, Acc:0.801045, Semantic loss: 0.741165, BCE loss: 0.517054, SB loss: 0.707807
2023-10-30 19:01:36,069 Epoch: [339/484] Iter:[400/495], Time: 0.37, lr: [0.003362683590691899], Loss: 1.964782, Acc:0.801379, Semantic loss: 0.741002, BCE loss: 0.516196, SB loss: 0.707584
2023-10-30 19:01:39,665 Epoch: [339/484] Iter:[410/495], Time: 0.37, lr: [0.0033622595715768707], Loss: 1.963100, Acc:0.801785, Semantic loss: 0.740457, BCE loss: 0.515429, SB loss: 0.707214
2023-10-30 19:01:43,359 Epoch: [339/484] Iter:[420/495], Time: 0.37, lr: [0.0033618355465202445], Loss: 1.959899, Acc:0.801155, Semantic loss: 0.739382, BCE loss: 0.513942, SB loss: 0.706575
2023-10-30 19:01:46,993 Epoch: [339/484] Iter:[430/495], Time: 0.37, lr: [0.0033614115155211058], Loss: 1.963443, Acc:0.800545, Semantic loss: 0.741754, BCE loss: 0.514634, SB loss: 0.707055
2023-10-30 19:01:50,624 Epoch: [339/484] Iter:[440/495], Time: 0.37, lr: [0.003360987478578536], Loss: 1.962154, Acc:0.801216, Semantic loss: 0.740835, BCE loss: 0.514700, SB loss: 0.706619
2023-10-30 19:01:54,362 Epoch: [339/484] Iter:[450/495], Time: 0.37, lr: [0.0033605634356916217], Loss: 1.963798, Acc:0.801065, Semantic loss: 0.741110, BCE loss: 0.514895, SB loss: 0.707792
2023-10-30 19:01:57,950 Epoch: [339/484] Iter:[460/495], Time: 0.37, lr: [0.0033601393868594445], Loss: 1.961791, Acc:0.801007, Semantic loss: 0.740234, BCE loss: 0.514405, SB loss: 0.707152
2023-10-30 19:02:01,649 Epoch: [339/484] Iter:[470/495], Time: 0.37, lr: [0.0033597153320810876], Loss: 1.961493, Acc:0.800862, Semantic loss: 0.739958, BCE loss: 0.514568, SB loss: 0.706967
2023-10-30 19:02:05,300 Epoch: [339/484] Iter:[480/495], Time: 0.37, lr: [0.0033592912713556323], Loss: 1.962976, Acc:0.800421, Semantic loss: 0.741380, BCE loss: 0.514460, SB loss: 0.707135
2023-10-30 19:02:08,817 Epoch: [339/484] Iter:[490/495], Time: 0.37, lr: [0.0033588672046821638], Loss: 1.963048, Acc:0.800320, Semantic loss: 0.741124, BCE loss: 0.514972, SB loss: 0.706952
2023-10-30 19:02:10,212 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:02:10,451 Loss: 2.020, MeanIU:  0.7117, Best_mIoU:  0.7309
2023-10-30 19:02:10,451 [0.97338385 0.80739536 0.91051479 0.47235422 0.55145154 0.58901852
 0.66630362 0.74773025 0.91333195 0.55988365 0.91978429 0.78254048
 0.55721026 0.93016458 0.60605252 0.70340683 0.5509255  0.54065075
 0.74098559]
2023-10-30 19:02:12,613 Epoch: [340/484] Iter:[0/495], Time: 2.13, lr: [0.003358655169114637], Loss: 1.706460, Acc:0.877823, Semantic loss: 0.554946, BCE loss: 0.541414, SB loss: 0.610100
2023-10-30 19:02:16,613 Epoch: [340/484] Iter:[10/495], Time: 0.56, lr: [0.003358231093517426], Loss: 1.971167, Acc:0.764746, Semantic loss: 0.735982, BCE loss: 0.498949, SB loss: 0.736236
2023-10-30 19:02:20,248 Epoch: [340/484] Iter:[20/495], Time: 0.46, lr: [0.0033578070119699038], Loss: 2.006214, Acc:0.775796, Semantic loss: 0.774260, BCE loss: 0.501665, SB loss: 0.730289
2023-10-30 19:02:23,922 Epoch: [340/484] Iter:[30/495], Time: 0.43, lr: [0.0033573829244711545], Loss: 2.029749, Acc:0.771242, Semantic loss: 0.783227, BCE loss: 0.510572, SB loss: 0.735950
2023-10-30 19:02:27,574 Epoch: [340/484] Iter:[40/495], Time: 0.42, lr: [0.003356958831020258], Loss: 2.010333, Acc:0.766488, Semantic loss: 0.777325, BCE loss: 0.503651, SB loss: 0.729358
2023-10-30 19:02:31,263 Epoch: [340/484] Iter:[50/495], Time: 0.41, lr: [0.0033565347316162953], Loss: 2.011988, Acc:0.772204, Semantic loss: 0.779715, BCE loss: 0.499513, SB loss: 0.732760
2023-10-30 19:02:34,962 Epoch: [340/484] Iter:[60/495], Time: 0.40, lr: [0.0033561106262583462], Loss: 2.011642, Acc:0.777593, Semantic loss: 0.774220, BCE loss: 0.505107, SB loss: 0.732315
2023-10-30 19:02:38,707 Epoch: [340/484] Iter:[70/495], Time: 0.40, lr: [0.0033556865149454934], Loss: 2.011181, Acc:0.781122, Semantic loss: 0.768155, BCE loss: 0.511577, SB loss: 0.731449
2023-10-30 19:02:42,355 Epoch: [340/484] Iter:[80/495], Time: 0.39, lr: [0.0033552623976768154], Loss: 2.007189, Acc:0.786755, Semantic loss: 0.772919, BCE loss: 0.507820, SB loss: 0.726450
2023-10-30 19:02:45,970 Epoch: [340/484] Iter:[90/495], Time: 0.39, lr: [0.0033548382744513923], Loss: 2.015200, Acc:0.788288, Semantic loss: 0.768677, BCE loss: 0.518787, SB loss: 0.727736
2023-10-30 19:02:49,666 Epoch: [340/484] Iter:[100/495], Time: 0.39, lr: [0.003354414145268303], Loss: 2.015044, Acc:0.790913, Semantic loss: 0.762957, BCE loss: 0.526311, SB loss: 0.725776
2023-10-30 19:02:53,342 Epoch: [340/484] Iter:[110/495], Time: 0.39, lr: [0.003353990010126628], Loss: 2.030631, Acc:0.796293, Semantic loss: 0.772415, BCE loss: 0.528158, SB loss: 0.730058
2023-10-30 19:02:57,026 Epoch: [340/484] Iter:[120/495], Time: 0.38, lr: [0.003353565869025446], Loss: 2.021161, Acc:0.796109, Semantic loss: 0.767268, BCE loss: 0.526175, SB loss: 0.727719
2023-10-30 19:03:00,728 Epoch: [340/484] Iter:[130/495], Time: 0.38, lr: [0.003353141721963836], Loss: 2.014372, Acc:0.795779, Semantic loss: 0.763574, BCE loss: 0.524832, SB loss: 0.725966
2023-10-30 19:03:04,402 Epoch: [340/484] Iter:[140/495], Time: 0.38, lr: [0.003352717568940875], Loss: 2.020486, Acc:0.795983, Semantic loss: 0.764905, BCE loss: 0.527268, SB loss: 0.728313
2023-10-30 19:03:08,127 Epoch: [340/484] Iter:[150/495], Time: 0.38, lr: [0.0033522934099556433], Loss: 2.007211, Acc:0.798822, Semantic loss: 0.755919, BCE loss: 0.527699, SB loss: 0.723592
2023-10-30 19:03:11,837 Epoch: [340/484] Iter:[160/495], Time: 0.38, lr: [0.003351869245007218], Loss: 2.004206, Acc:0.798820, Semantic loss: 0.754492, BCE loss: 0.526967, SB loss: 0.722747
2023-10-30 19:03:15,410 Epoch: [340/484] Iter:[170/495], Time: 0.38, lr: [0.0033514450740946768], Loss: 2.003987, Acc:0.800116, Semantic loss: 0.754822, BCE loss: 0.526228, SB loss: 0.722937
2023-10-30 19:03:19,119 Epoch: [340/484] Iter:[180/495], Time: 0.38, lr: [0.0033510208972170955], Loss: 2.008048, Acc:0.799522, Semantic loss: 0.756015, BCE loss: 0.529578, SB loss: 0.722455
2023-10-30 19:03:22,804 Epoch: [340/484] Iter:[190/495], Time: 0.38, lr: [0.0033505967143735538], Loss: 2.009508, Acc:0.800824, Semantic loss: 0.755632, BCE loss: 0.531442, SB loss: 0.722434
2023-10-30 19:03:26,631 Epoch: [340/484] Iter:[200/495], Time: 0.38, lr: [0.0033501725255631275], Loss: 2.014803, Acc:0.800194, Semantic loss: 0.757974, BCE loss: 0.533129, SB loss: 0.723700
2023-10-30 19:03:30,262 Epoch: [340/484] Iter:[210/495], Time: 0.38, lr: [0.0033497483307848934], Loss: 2.019951, Acc:0.799833, Semantic loss: 0.760810, BCE loss: 0.533781, SB loss: 0.725361
2023-10-30 19:03:33,903 Epoch: [340/484] Iter:[220/495], Time: 0.38, lr: [0.003349324130037927], Loss: 2.016527, Acc:0.800871, Semantic loss: 0.758622, BCE loss: 0.533256, SB loss: 0.724650
2023-10-30 19:03:37,597 Epoch: [340/484] Iter:[230/495], Time: 0.38, lr: [0.003348899923321305], Loss: 2.012522, Acc:0.800971, Semantic loss: 0.756953, BCE loss: 0.531314, SB loss: 0.724255
2023-10-30 19:03:41,175 Epoch: [340/484] Iter:[240/495], Time: 0.38, lr: [0.0033484757106341037], Loss: 2.005539, Acc:0.799327, Semantic loss: 0.754712, BCE loss: 0.528141, SB loss: 0.722686
2023-10-30 19:03:44,755 Epoch: [340/484] Iter:[250/495], Time: 0.38, lr: [0.0033480514919753974], Loss: 2.000372, Acc:0.800094, Semantic loss: 0.753030, BCE loss: 0.525586, SB loss: 0.721756
2023-10-30 19:03:48,482 Epoch: [340/484] Iter:[260/495], Time: 0.38, lr: [0.003347627267344261], Loss: 1.999688, Acc:0.800824, Semantic loss: 0.752288, BCE loss: 0.526527, SB loss: 0.720872
2023-10-30 19:03:52,125 Epoch: [340/484] Iter:[270/495], Time: 0.38, lr: [0.0033472030367397714], Loss: 1.998243, Acc:0.800430, Semantic loss: 0.751295, BCE loss: 0.525804, SB loss: 0.721145
2023-10-30 19:03:55,723 Epoch: [340/484] Iter:[280/495], Time: 0.37, lr: [0.003346778800161003], Loss: 2.001398, Acc:0.800147, Semantic loss: 0.754323, BCE loss: 0.524856, SB loss: 0.722218
2023-10-30 19:03:59,316 Epoch: [340/484] Iter:[290/495], Time: 0.37, lr: [0.003346354557607029], Loss: 1.995017, Acc:0.799660, Semantic loss: 0.751705, BCE loss: 0.522533, SB loss: 0.720779
2023-10-30 19:04:02,838 Epoch: [340/484] Iter:[300/495], Time: 0.37, lr: [0.003345930309076922], Loss: 1.996667, Acc:0.799569, Semantic loss: 0.753893, BCE loss: 0.521819, SB loss: 0.720955
2023-10-30 19:04:06,447 Epoch: [340/484] Iter:[310/495], Time: 0.37, lr: [0.0033455060545697596], Loss: 1.992428, Acc:0.799765, Semantic loss: 0.751585, BCE loss: 0.520679, SB loss: 0.720164
2023-10-30 19:04:10,196 Epoch: [340/484] Iter:[320/495], Time: 0.37, lr: [0.0033450817940846134], Loss: 1.990479, Acc:0.800102, Semantic loss: 0.750848, BCE loss: 0.519780, SB loss: 0.719850
2023-10-30 19:04:13,824 Epoch: [340/484] Iter:[330/495], Time: 0.37, lr: [0.003344657527620557], Loss: 1.992100, Acc:0.799973, Semantic loss: 0.750618, BCE loss: 0.521695, SB loss: 0.719787
2023-10-30 19:04:17,471 Epoch: [340/484] Iter:[340/495], Time: 0.37, lr: [0.0033442332551766626], Loss: 1.995886, Acc:0.800104, Semantic loss: 0.752809, BCE loss: 0.522303, SB loss: 0.720775
2023-10-30 19:04:21,068 Epoch: [340/484] Iter:[350/495], Time: 0.37, lr: [0.003343808976752004], Loss: 2.001283, Acc:0.799622, Semantic loss: 0.754915, BCE loss: 0.524245, SB loss: 0.722123
2023-10-30 19:04:24,742 Epoch: [340/484] Iter:[360/495], Time: 0.37, lr: [0.003343384692345654], Loss: 1.997970, Acc:0.800115, Semantic loss: 0.753936, BCE loss: 0.522936, SB loss: 0.721098
2023-10-30 19:04:28,414 Epoch: [340/484] Iter:[370/495], Time: 0.37, lr: [0.003342960401956684], Loss: 2.000813, Acc:0.801310, Semantic loss: 0.755382, BCE loss: 0.523678, SB loss: 0.721752
2023-10-30 19:04:32,082 Epoch: [340/484] Iter:[380/495], Time: 0.37, lr: [0.003342536105584165], Loss: 2.002090, Acc:0.801810, Semantic loss: 0.755358, BCE loss: 0.524460, SB loss: 0.722273
2023-10-30 19:04:35,848 Epoch: [340/484] Iter:[390/495], Time: 0.37, lr: [0.0033421118032271706], Loss: 2.000686, Acc:0.801594, Semantic loss: 0.753569, BCE loss: 0.525446, SB loss: 0.721671
2023-10-30 19:04:39,438 Epoch: [340/484] Iter:[400/495], Time: 0.37, lr: [0.0033416874948847715], Loss: 2.000932, Acc:0.802152, Semantic loss: 0.754711, BCE loss: 0.525011, SB loss: 0.721210
2023-10-30 19:04:43,105 Epoch: [340/484] Iter:[410/495], Time: 0.37, lr: [0.0033412631805560386], Loss: 1.998773, Acc:0.803124, Semantic loss: 0.753044, BCE loss: 0.524678, SB loss: 0.721051
2023-10-30 19:04:46,763 Epoch: [340/484] Iter:[420/495], Time: 0.37, lr: [0.003340838860240042], Loss: 2.000140, Acc:0.802926, Semantic loss: 0.755037, BCE loss: 0.523561, SB loss: 0.721542
2023-10-30 19:04:50,485 Epoch: [340/484] Iter:[430/495], Time: 0.37, lr: [0.0033404145339358533], Loss: 2.001375, Acc:0.803207, Semantic loss: 0.756626, BCE loss: 0.522976, SB loss: 0.721772
2023-10-30 19:04:54,244 Epoch: [340/484] Iter:[440/495], Time: 0.37, lr: [0.003339990201642543], Loss: 2.000850, Acc:0.803345, Semantic loss: 0.756762, BCE loss: 0.522853, SB loss: 0.721235
2023-10-30 19:04:57,922 Epoch: [340/484] Iter:[450/495], Time: 0.37, lr: [0.0033395658633591807], Loss: 2.003087, Acc:0.802689, Semantic loss: 0.758707, BCE loss: 0.522938, SB loss: 0.721441
2023-10-30 19:05:01,561 Epoch: [340/484] Iter:[460/495], Time: 0.37, lr: [0.003339141519084835], Loss: 2.001261, Acc:0.803049, Semantic loss: 0.756967, BCE loss: 0.523032, SB loss: 0.721263
2023-10-30 19:05:05,274 Epoch: [340/484] Iter:[470/495], Time: 0.37, lr: [0.0033387171688185773], Loss: 2.004082, Acc:0.803507, Semantic loss: 0.758078, BCE loss: 0.524464, SB loss: 0.721540
2023-10-30 19:05:08,899 Epoch: [340/484] Iter:[480/495], Time: 0.37, lr: [0.0033382928125594764], Loss: 2.005106, Acc:0.803240, Semantic loss: 0.759362, BCE loss: 0.524284, SB loss: 0.721460
2023-10-30 19:05:12,322 Epoch: [340/484] Iter:[490/495], Time: 0.37, lr: [0.0033378684503065988], Loss: 2.007021, Acc:0.803055, Semantic loss: 0.759731, BCE loss: 0.524652, SB loss: 0.722638
2023-10-30 19:08:09,507 0 [0.93145289 0.60507203 0.82300902 0.14172293 0.25213018 0.4316471
 0.4626125  0.57201717 0.88156313 0.44517427 0.87408076 0.51309352
 0.03666483 0.79307126 0.00569151 0.15047614 0.0589771  0.04786694
 0.57749997] 0.45283280274400756
2023-10-30 19:08:09,508 1 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745] 0.7107737693940561
2023-10-30 19:08:09,511 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:08:09,752 Loss: 2.019, MeanIU:  0.7108, Best_mIoU:  0.7309
2023-10-30 19:08:09,752 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745]
2023-10-30 19:08:11,898 Epoch: [341/484] Iter:[0/495], Time: 2.11, lr: [0.0033376562669322042], Loss: 1.803920, Acc:0.771062, Semantic loss: 0.638080, BCE loss: 0.488108, SB loss: 0.677732
2023-10-30 19:08:15,703 Epoch: [341/484] Iter:[10/495], Time: 0.54, lr: [0.003337231895686919], Loss: 1.866494, Acc:0.791677, Semantic loss: 0.678981, BCE loss: 0.492042, SB loss: 0.695471
2023-10-30 19:08:19,143 Epoch: [341/484] Iter:[20/495], Time: 0.45, lr: [0.003336807518445531], Loss: 1.979331, Acc:0.816002, Semantic loss: 0.723857, BCE loss: 0.558084, SB loss: 0.697391
2023-10-30 19:08:22,658 Epoch: [341/484] Iter:[30/495], Time: 0.42, lr: [0.003336383135207106], Loss: 1.976952, Acc:0.809946, Semantic loss: 0.727643, BCE loss: 0.537487, SB loss: 0.711822
2023-10-30 19:08:26,123 Epoch: [341/484] Iter:[40/495], Time: 0.40, lr: [0.0033359587459707123], Loss: 1.986611, Acc:0.808189, Semantic loss: 0.738676, BCE loss: 0.531752, SB loss: 0.716183
2023-10-30 19:08:29,608 Epoch: [341/484] Iter:[50/495], Time: 0.39, lr: [0.0033355343507354192], Loss: 1.973405, Acc:0.809128, Semantic loss: 0.735987, BCE loss: 0.530095, SB loss: 0.707323
2023-10-30 19:08:33,018 Epoch: [341/484] Iter:[60/495], Time: 0.38, lr: [0.003335109949500292], Loss: 1.972510, Acc:0.806629, Semantic loss: 0.735371, BCE loss: 0.528226, SB loss: 0.708913
2023-10-30 19:08:36,622 Epoch: [341/484] Iter:[70/495], Time: 0.38, lr: [0.003334685542264398], Loss: 1.963622, Acc:0.802312, Semantic loss: 0.735235, BCE loss: 0.520290, SB loss: 0.708098
2023-10-30 19:08:40,172 Epoch: [341/484] Iter:[80/495], Time: 0.38, lr: [0.0033342611290268025], Loss: 1.956675, Acc:0.803169, Semantic loss: 0.732638, BCE loss: 0.516708, SB loss: 0.707329
2023-10-30 19:08:43,729 Epoch: [341/484] Iter:[90/495], Time: 0.37, lr: [0.003333836709786574], Loss: 1.961127, Acc:0.803381, Semantic loss: 0.735077, BCE loss: 0.518355, SB loss: 0.707695
2023-10-30 19:08:47,268 Epoch: [341/484] Iter:[100/495], Time: 0.37, lr: [0.003333412284542778], Loss: 1.956513, Acc:0.806634, Semantic loss: 0.738423, BCE loss: 0.513280, SB loss: 0.704809
2023-10-30 19:08:50,791 Epoch: [341/484] Iter:[110/495], Time: 0.37, lr: [0.0033329878532944793], Loss: 1.961372, Acc:0.805086, Semantic loss: 0.738761, BCE loss: 0.516087, SB loss: 0.706525
2023-10-30 19:08:54,454 Epoch: [341/484] Iter:[120/495], Time: 0.37, lr: [0.0033325634160407424], Loss: 1.979141, Acc:0.803756, Semantic loss: 0.749814, BCE loss: 0.517394, SB loss: 0.711933
2023-10-30 19:08:58,124 Epoch: [341/484] Iter:[130/495], Time: 0.37, lr: [0.0033321389727806352], Loss: 1.988878, Acc:0.805347, Semantic loss: 0.752059, BCE loss: 0.520960, SB loss: 0.715859
2023-10-30 19:09:01,786 Epoch: [341/484] Iter:[140/495], Time: 0.37, lr: [0.0033317145235132206], Loss: 1.986735, Acc:0.807997, Semantic loss: 0.751552, BCE loss: 0.520722, SB loss: 0.714461
2023-10-30 19:09:05,491 Epoch: [341/484] Iter:[150/495], Time: 0.37, lr: [0.0033312900682375642], Loss: 1.982143, Acc:0.805806, Semantic loss: 0.750145, BCE loss: 0.518133, SB loss: 0.713865
2023-10-30 19:09:09,066 Epoch: [341/484] Iter:[160/495], Time: 0.37, lr: [0.0033308656069527287], Loss: 1.988820, Acc:0.803074, Semantic loss: 0.752576, BCE loss: 0.521611, SB loss: 0.714633
2023-10-30 19:09:12,617 Epoch: [341/484] Iter:[170/495], Time: 0.37, lr: [0.0033304411396577805], Loss: 1.986432, Acc:0.802991, Semantic loss: 0.752140, BCE loss: 0.520101, SB loss: 0.714192
2023-10-30 19:09:16,201 Epoch: [341/484] Iter:[180/495], Time: 0.37, lr: [0.0033300166663517822], Loss: 1.988161, Acc:0.803091, Semantic loss: 0.754512, BCE loss: 0.519820, SB loss: 0.713829
2023-10-30 19:09:19,739 Epoch: [341/484] Iter:[190/495], Time: 0.37, lr: [0.0033295921870337974], Loss: 1.983735, Acc:0.802014, Semantic loss: 0.751815, BCE loss: 0.517742, SB loss: 0.714177
2023-10-30 19:09:23,240 Epoch: [341/484] Iter:[200/495], Time: 0.37, lr: [0.003329167701702888], Loss: 1.984729, Acc:0.801635, Semantic loss: 0.753899, BCE loss: 0.515043, SB loss: 0.715787
2023-10-30 19:09:26,866 Epoch: [341/484] Iter:[210/495], Time: 0.37, lr: [0.0033287432103581193], Loss: 1.978943, Acc:0.803226, Semantic loss: 0.750672, BCE loss: 0.512541, SB loss: 0.715729
2023-10-30 19:09:30,443 Epoch: [341/484] Iter:[220/495], Time: 0.36, lr: [0.003328318712998553], Loss: 1.981563, Acc:0.803620, Semantic loss: 0.751321, BCE loss: 0.513695, SB loss: 0.716547
2023-10-30 19:09:34,095 Epoch: [341/484] Iter:[230/495], Time: 0.36, lr: [0.0033278942096232507], Loss: 1.984582, Acc:0.804383, Semantic loss: 0.752190, BCE loss: 0.514452, SB loss: 0.717941
2023-10-30 19:09:37,702 Epoch: [341/484] Iter:[240/495], Time: 0.36, lr: [0.0033274697002312744], Loss: 1.981179, Acc:0.802588, Semantic loss: 0.749977, BCE loss: 0.514267, SB loss: 0.716935
2023-10-30 19:09:41,393 Epoch: [341/484] Iter:[250/495], Time: 0.36, lr: [0.0033270451848216877], Loss: 1.978443, Acc:0.802805, Semantic loss: 0.748116, BCE loss: 0.514383, SB loss: 0.715944
2023-10-30 19:09:45,097 Epoch: [341/484] Iter:[260/495], Time: 0.37, lr: [0.0033266206633935508], Loss: 1.977023, Acc:0.804292, Semantic loss: 0.747846, BCE loss: 0.513578, SB loss: 0.715599
2023-10-30 19:09:48,827 Epoch: [341/484] Iter:[270/495], Time: 0.37, lr: [0.003326196135945926], Loss: 1.981232, Acc:0.805629, Semantic loss: 0.747749, BCE loss: 0.517887, SB loss: 0.715595
2023-10-30 19:09:52,411 Epoch: [341/484] Iter:[280/495], Time: 0.37, lr: [0.0033257716024778718], Loss: 1.981452, Acc:0.806331, Semantic loss: 0.747101, BCE loss: 0.518852, SB loss: 0.715499
2023-10-30 19:09:55,987 Epoch: [341/484] Iter:[290/495], Time: 0.36, lr: [0.0033253470629884515], Loss: 1.979849, Acc:0.806818, Semantic loss: 0.745743, BCE loss: 0.520132, SB loss: 0.713974
2023-10-30 19:09:59,631 Epoch: [341/484] Iter:[300/495], Time: 0.36, lr: [0.0033249225174767252], Loss: 1.975396, Acc:0.806586, Semantic loss: 0.743843, BCE loss: 0.518047, SB loss: 0.713507
2023-10-30 19:10:03,225 Epoch: [341/484] Iter:[310/495], Time: 0.36, lr: [0.0033244979659417507], Loss: 1.977542, Acc:0.806365, Semantic loss: 0.743444, BCE loss: 0.520328, SB loss: 0.713770
2023-10-30 19:10:06,839 Epoch: [341/484] Iter:[320/495], Time: 0.36, lr: [0.0033240734083825915], Loss: 1.978671, Acc:0.806970, Semantic loss: 0.744292, BCE loss: 0.519674, SB loss: 0.714706
2023-10-30 19:10:10,514 Epoch: [341/484] Iter:[330/495], Time: 0.36, lr: [0.0033236488447983045], Loss: 1.975570, Acc:0.805946, Semantic loss: 0.743400, BCE loss: 0.518131, SB loss: 0.714039
2023-10-30 19:10:14,170 Epoch: [341/484] Iter:[340/495], Time: 0.36, lr: [0.0033232242751879497], Loss: 1.977271, Acc:0.806653, Semantic loss: 0.744470, BCE loss: 0.518686, SB loss: 0.714114
2023-10-30 19:10:17,749 Epoch: [341/484] Iter:[350/495], Time: 0.36, lr: [0.003322799699550586], Loss: 1.976326, Acc:0.806880, Semantic loss: 0.743876, BCE loss: 0.518610, SB loss: 0.713840
2023-10-30 19:10:21,332 Epoch: [341/484] Iter:[360/495], Time: 0.36, lr: [0.003322375117885273], Loss: 1.975700, Acc:0.806614, Semantic loss: 0.744580, BCE loss: 0.517822, SB loss: 0.713298
2023-10-30 19:10:25,018 Epoch: [341/484] Iter:[370/495], Time: 0.36, lr: [0.003321950530191069], Loss: 1.972069, Acc:0.806074, Semantic loss: 0.743702, BCE loss: 0.515697, SB loss: 0.712669
2023-10-30 19:10:28,673 Epoch: [341/484] Iter:[380/495], Time: 0.36, lr: [0.003321525936467031], Loss: 1.975781, Acc:0.805477, Semantic loss: 0.745427, BCE loss: 0.517735, SB loss: 0.712619
2023-10-30 19:10:32,286 Epoch: [341/484] Iter:[390/495], Time: 0.36, lr: [0.003321101336712217], Loss: 1.973054, Acc:0.804650, Semantic loss: 0.743824, BCE loss: 0.517170, SB loss: 0.712060
2023-10-30 19:10:35,913 Epoch: [341/484] Iter:[400/495], Time: 0.36, lr: [0.003320676730925686], Loss: 1.973837, Acc:0.804356, Semantic loss: 0.744578, BCE loss: 0.517085, SB loss: 0.712174
2023-10-30 19:10:39,590 Epoch: [341/484] Iter:[410/495], Time: 0.36, lr: [0.0033202521191064947], Loss: 1.972191, Acc:0.803673, Semantic loss: 0.743374, BCE loss: 0.516983, SB loss: 0.711834
2023-10-30 19:10:43,264 Epoch: [341/484] Iter:[420/495], Time: 0.36, lr: [0.0033198275012537005], Loss: 1.975321, Acc:0.803848, Semantic loss: 0.743419, BCE loss: 0.519915, SB loss: 0.711988
2023-10-30 19:10:46,903 Epoch: [341/484] Iter:[430/495], Time: 0.36, lr: [0.0033194028773663583], Loss: 1.970848, Acc:0.804183, Semantic loss: 0.741258, BCE loss: 0.518718, SB loss: 0.710872
2023-10-30 19:10:50,622 Epoch: [341/484] Iter:[440/495], Time: 0.36, lr: [0.0033189782474435272], Loss: 1.967295, Acc:0.804080, Semantic loss: 0.739753, BCE loss: 0.517551, SB loss: 0.709991
2023-10-30 19:10:54,308 Epoch: [341/484] Iter:[450/495], Time: 0.36, lr: [0.003318553611484262], Loss: 1.968111, Acc:0.805050, Semantic loss: 0.739841, BCE loss: 0.518229, SB loss: 0.710042
2023-10-30 19:10:57,923 Epoch: [341/484] Iter:[460/495], Time: 0.36, lr: [0.0033181289694876187], Loss: 1.971533, Acc:0.805357, Semantic loss: 0.739950, BCE loss: 0.520784, SB loss: 0.710799
2023-10-30 19:11:01,556 Epoch: [341/484] Iter:[470/495], Time: 0.36, lr: [0.003317704321452652], Loss: 1.970624, Acc:0.805633, Semantic loss: 0.739144, BCE loss: 0.520580, SB loss: 0.710899
2023-10-30 19:11:05,325 Epoch: [341/484] Iter:[480/495], Time: 0.36, lr: [0.0033172796673784193], Loss: 1.968211, Acc:0.804976, Semantic loss: 0.738183, BCE loss: 0.519681, SB loss: 0.710347
2023-10-30 19:11:08,792 Epoch: [341/484] Iter:[490/495], Time: 0.36, lr: [0.003316855007263975], Loss: 1.969257, Acc:0.805302, Semantic loss: 0.738643, BCE loss: 0.520230, SB loss: 0.710383
2023-10-30 19:11:10,182 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:11:10,423 Loss: 2.019, MeanIU:  0.7108, Best_mIoU:  0.7309
2023-10-30 19:11:10,423 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745]
2023-10-30 19:11:12,568 Epoch: [342/484] Iter:[0/495], Time: 2.11, lr: [0.0033166426749413782], Loss: 2.014472, Acc:0.856001, Semantic loss: 0.970757, BCE loss: 0.342497, SB loss: 0.701218
2023-10-30 19:11:16,571 Epoch: [342/484] Iter:[10/495], Time: 0.56, lr: [0.003316218005764844], Loss: 1.985077, Acc:0.775718, Semantic loss: 0.753108, BCE loss: 0.540160, SB loss: 0.691809
2023-10-30 19:11:20,281 Epoch: [342/484] Iter:[20/495], Time: 0.47, lr: [0.0033157933305457328], Loss: 2.025924, Acc:0.787134, Semantic loss: 0.769140, BCE loss: 0.544008, SB loss: 0.712777
2023-10-30 19:11:23,993 Epoch: [342/484] Iter:[30/495], Time: 0.44, lr: [0.0033153686492831016], Loss: 2.051357, Acc:0.794967, Semantic loss: 0.785457, BCE loss: 0.549854, SB loss: 0.716045
2023-10-30 19:11:27,635 Epoch: [342/484] Iter:[40/495], Time: 0.42, lr: [0.003314943961976003], Loss: 2.032610, Acc:0.797440, Semantic loss: 0.761232, BCE loss: 0.556477, SB loss: 0.714900
2023-10-30 19:11:31,205 Epoch: [342/484] Iter:[50/495], Time: 0.41, lr: [0.0033145192686234904], Loss: 2.029849, Acc:0.807444, Semantic loss: 0.756391, BCE loss: 0.562369, SB loss: 0.711089
2023-10-30 19:11:34,781 Epoch: [342/484] Iter:[60/495], Time: 0.40, lr: [0.003314094569224616], Loss: 2.010620, Acc:0.807950, Semantic loss: 0.747596, BCE loss: 0.553826, SB loss: 0.709198
2023-10-30 19:11:38,544 Epoch: [342/484] Iter:[70/495], Time: 0.40, lr: [0.0033136698637784346], Loss: 2.004074, Acc:0.802822, Semantic loss: 0.749004, BCE loss: 0.542817, SB loss: 0.712254
2023-10-30 19:11:42,104 Epoch: [342/484] Iter:[80/495], Time: 0.39, lr: [0.0033132451522839986], Loss: 1.996074, Acc:0.801800, Semantic loss: 0.744184, BCE loss: 0.543472, SB loss: 0.708418
2023-10-30 19:11:45,713 Epoch: [342/484] Iter:[90/495], Time: 0.39, lr: [0.0033128204347403593], Loss: 1.988924, Acc:0.797331, Semantic loss: 0.745965, BCE loss: 0.536332, SB loss: 0.706627
2023-10-30 19:11:49,326 Epoch: [342/484] Iter:[100/495], Time: 0.38, lr: [0.0033123957111465692], Loss: 1.991257, Acc:0.795181, Semantic loss: 0.749133, BCE loss: 0.532445, SB loss: 0.709679
2023-10-30 19:11:52,933 Epoch: [342/484] Iter:[110/495], Time: 0.38, lr: [0.0033119709815016807], Loss: 1.992350, Acc:0.795410, Semantic loss: 0.749661, BCE loss: 0.532494, SB loss: 0.710194
2023-10-30 19:11:56,514 Epoch: [342/484] Iter:[120/495], Time: 0.38, lr: [0.0033115462458047453], Loss: 1.989433, Acc:0.791764, Semantic loss: 0.748568, BCE loss: 0.532501, SB loss: 0.708364
2023-10-30 19:12:00,109 Epoch: [342/484] Iter:[130/495], Time: 0.38, lr: [0.003311121504054814], Loss: 1.981035, Acc:0.793078, Semantic loss: 0.742237, BCE loss: 0.530808, SB loss: 0.707990
2023-10-30 19:12:03,729 Epoch: [342/484] Iter:[140/495], Time: 0.38, lr: [0.0033106967562509366], Loss: 1.970405, Acc:0.793712, Semantic loss: 0.735067, BCE loss: 0.528655, SB loss: 0.706683
2023-10-30 19:12:07,380 Epoch: [342/484] Iter:[150/495], Time: 0.38, lr: [0.0033102720023921663], Loss: 1.999021, Acc:0.793044, Semantic loss: 0.759229, BCE loss: 0.529346, SB loss: 0.710446
2023-10-30 19:12:11,005 Epoch: [342/484] Iter:[160/495], Time: 0.38, lr: [0.003309847242477552], Loss: 2.015227, Acc:0.793578, Semantic loss: 0.768077, BCE loss: 0.533307, SB loss: 0.713843
2023-10-30 19:12:14,675 Epoch: [342/484] Iter:[170/495], Time: 0.38, lr: [0.0033094224765061425], Loss: 2.022460, Acc:0.795269, Semantic loss: 0.770635, BCE loss: 0.535031, SB loss: 0.716794
2023-10-30 19:12:18,333 Epoch: [342/484] Iter:[180/495], Time: 0.37, lr: [0.0033089977044769904], Loss: 2.019018, Acc:0.796184, Semantic loss: 0.769557, BCE loss: 0.533835, SB loss: 0.715627
2023-10-30 19:12:22,074 Epoch: [342/484] Iter:[190/495], Time: 0.37, lr: [0.003308572926389144], Loss: 2.026618, Acc:0.796059, Semantic loss: 0.772951, BCE loss: 0.534238, SB loss: 0.719429
2023-10-30 19:12:25,740 Epoch: [342/484] Iter:[200/495], Time: 0.37, lr: [0.003308148142241653], Loss: 2.029054, Acc:0.796375, Semantic loss: 0.772034, BCE loss: 0.537627, SB loss: 0.719393
2023-10-30 19:12:29,318 Epoch: [342/484] Iter:[210/495], Time: 0.37, lr: [0.0033077233520335636], Loss: 2.034040, Acc:0.796413, Semantic loss: 0.774997, BCE loss: 0.536664, SB loss: 0.722379
2023-10-30 19:12:32,945 Epoch: [342/484] Iter:[220/495], Time: 0.37, lr: [0.003307298555763929], Loss: 2.034685, Acc:0.798260, Semantic loss: 0.773161, BCE loss: 0.538319, SB loss: 0.723205
2023-10-30 19:12:36,616 Epoch: [342/484] Iter:[230/495], Time: 0.37, lr: [0.003306873753431795], Loss: 2.029390, Acc:0.798731, Semantic loss: 0.768860, BCE loss: 0.538100, SB loss: 0.722431
2023-10-30 19:12:40,250 Epoch: [342/484] Iter:[240/495], Time: 0.37, lr: [0.00330644894503621], Loss: 2.030834, Acc:0.799400, Semantic loss: 0.768989, BCE loss: 0.539439, SB loss: 0.722406
2023-10-30 19:12:43,903 Epoch: [342/484] Iter:[250/495], Time: 0.37, lr: [0.003306024130576221], Loss: 2.031823, Acc:0.800288, Semantic loss: 0.769697, BCE loss: 0.539677, SB loss: 0.722449
2023-10-30 19:12:47,536 Epoch: [342/484] Iter:[260/495], Time: 0.37, lr: [0.0033055993100508784], Loss: 2.029520, Acc:0.800067, Semantic loss: 0.767901, BCE loss: 0.539339, SB loss: 0.722280
2023-10-30 19:12:51,143 Epoch: [342/484] Iter:[270/495], Time: 0.37, lr: [0.0033051744834592268], Loss: 2.031105, Acc:0.799978, Semantic loss: 0.769126, BCE loss: 0.538770, SB loss: 0.723209
2023-10-30 19:12:54,835 Epoch: [342/484] Iter:[280/495], Time: 0.37, lr: [0.0033047496508003143], Loss: 2.028437, Acc:0.798458, Semantic loss: 0.767506, BCE loss: 0.537991, SB loss: 0.722941
2023-10-30 19:12:58,555 Epoch: [342/484] Iter:[290/495], Time: 0.37, lr: [0.003304324812073187], Loss: 2.028319, Acc:0.799290, Semantic loss: 0.765734, BCE loss: 0.539584, SB loss: 0.723000
2023-10-30 19:13:02,131 Epoch: [342/484] Iter:[300/495], Time: 0.37, lr: [0.0033038999672768917], Loss: 2.026301, Acc:0.800750, Semantic loss: 0.764717, BCE loss: 0.539388, SB loss: 0.722196
2023-10-30 19:13:05,721 Epoch: [342/484] Iter:[310/495], Time: 0.37, lr: [0.0033034751164104747], Loss: 2.024432, Acc:0.800474, Semantic loss: 0.764159, BCE loss: 0.538232, SB loss: 0.722040
2023-10-30 19:13:09,430 Epoch: [342/484] Iter:[320/495], Time: 0.37, lr: [0.003303050259472982], Loss: 2.021297, Acc:0.801244, Semantic loss: 0.763231, BCE loss: 0.536752, SB loss: 0.721314
2023-10-30 19:13:13,066 Epoch: [342/484] Iter:[330/495], Time: 0.37, lr: [0.003302625396463457], Loss: 2.018893, Acc:0.801649, Semantic loss: 0.761248, BCE loss: 0.537171, SB loss: 0.720475
2023-10-30 19:13:16,818 Epoch: [342/484] Iter:[340/495], Time: 0.37, lr: [0.0033022005273809487], Loss: 2.021705, Acc:0.802108, Semantic loss: 0.762274, BCE loss: 0.538571, SB loss: 0.720859
2023-10-30 19:13:20,353 Epoch: [342/484] Iter:[350/495], Time: 0.37, lr: [0.0033017756522244995], Loss: 2.019422, Acc:0.802586, Semantic loss: 0.760094, BCE loss: 0.539754, SB loss: 0.719574
2023-10-30 19:13:24,036 Epoch: [342/484] Iter:[360/495], Time: 0.37, lr: [0.003301350770993155], Loss: 2.017039, Acc:0.802268, Semantic loss: 0.759438, BCE loss: 0.537954, SB loss: 0.719647
2023-10-30 19:13:27,681 Epoch: [342/484] Iter:[370/495], Time: 0.37, lr: [0.0033009258836859583], Loss: 2.017474, Acc:0.802873, Semantic loss: 0.759945, BCE loss: 0.537491, SB loss: 0.720037
2023-10-30 19:13:31,229 Epoch: [342/484] Iter:[380/495], Time: 0.37, lr: [0.0033005009903019555], Loss: 2.015974, Acc:0.803369, Semantic loss: 0.758176, BCE loss: 0.538219, SB loss: 0.719579
2023-10-30 19:13:34,868 Epoch: [342/484] Iter:[390/495], Time: 0.37, lr: [0.0033000760908401894], Loss: 2.016909, Acc:0.803272, Semantic loss: 0.757840, BCE loss: 0.539659, SB loss: 0.719411
2023-10-30 19:13:38,563 Epoch: [342/484] Iter:[400/495], Time: 0.37, lr: [0.003299651185299704], Loss: 2.015951, Acc:0.803533, Semantic loss: 0.757467, BCE loss: 0.539597, SB loss: 0.718887
2023-10-30 19:13:42,201 Epoch: [342/484] Iter:[410/495], Time: 0.37, lr: [0.003299226273679541], Loss: 2.013502, Acc:0.803661, Semantic loss: 0.756476, BCE loss: 0.538259, SB loss: 0.718766
2023-10-30 19:13:45,864 Epoch: [342/484] Iter:[420/495], Time: 0.37, lr: [0.003298801355978746], Loss: 2.011210, Acc:0.803852, Semantic loss: 0.755182, BCE loss: 0.537669, SB loss: 0.718359
2023-10-30 19:13:49,573 Epoch: [342/484] Iter:[430/495], Time: 0.37, lr: [0.00329837643219636], Loss: 2.011488, Acc:0.804234, Semantic loss: 0.755074, BCE loss: 0.538004, SB loss: 0.718411
2023-10-30 19:13:53,166 Epoch: [342/484] Iter:[440/495], Time: 0.37, lr: [0.0032979515023314255], Loss: 2.012974, Acc:0.804931, Semantic loss: 0.756624, BCE loss: 0.538094, SB loss: 0.718256
2023-10-30 19:13:56,764 Epoch: [342/484] Iter:[450/495], Time: 0.37, lr: [0.003297526566382984], Loss: 2.009498, Acc:0.803033, Semantic loss: 0.754908, BCE loss: 0.536775, SB loss: 0.717816
2023-10-30 19:14:00,437 Epoch: [342/484] Iter:[460/495], Time: 0.37, lr: [0.0032971016243500788], Loss: 2.003723, Acc:0.802038, Semantic loss: 0.752505, BCE loss: 0.534864, SB loss: 0.716355
2023-10-30 19:14:04,252 Epoch: [342/484] Iter:[470/495], Time: 0.37, lr: [0.0032966766762317513], Loss: 2.003178, Acc:0.802076, Semantic loss: 0.752913, BCE loss: 0.534163, SB loss: 0.716102
2023-10-30 19:14:07,956 Epoch: [342/484] Iter:[480/495], Time: 0.37, lr: [0.0032962517220270424], Loss: 2.001862, Acc:0.801999, Semantic loss: 0.752163, BCE loss: 0.534162, SB loss: 0.715536
2023-10-30 19:14:11,354 Epoch: [342/484] Iter:[490/495], Time: 0.37, lr: [0.0032958267617349906], Loss: 1.999816, Acc:0.802640, Semantic loss: 0.751348, BCE loss: 0.532901, SB loss: 0.715567
2023-10-30 19:14:12,731 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:14:12,988 Loss: 2.019, MeanIU:  0.7108, Best_mIoU:  0.7309
2023-10-30 19:14:12,988 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745]
2023-10-30 19:14:14,896 Epoch: [343/484] Iter:[0/495], Time: 1.87, lr: [0.0032956142793059136], Loss: 1.923238, Acc:0.719044, Semantic loss: 0.658084, BCE loss: 0.541721, SB loss: 0.723433
2023-10-30 19:14:18,855 Epoch: [343/484] Iter:[10/495], Time: 0.53, lr: [0.0032951893098810536], Loss: 1.808470, Acc:0.735236, Semantic loss: 0.699902, BCE loss: 0.408031, SB loss: 0.700537
2023-10-30 19:14:22,641 Epoch: [343/484] Iter:[20/495], Time: 0.46, lr: [0.003294764334366454], Loss: 1.862776, Acc:0.774406, Semantic loss: 0.708224, BCE loss: 0.449546, SB loss: 0.705006
2023-10-30 19:14:26,477 Epoch: [343/484] Iter:[30/495], Time: 0.43, lr: [0.0032943393527611543], Loss: 1.904867, Acc:0.782716, Semantic loss: 0.732228, BCE loss: 0.464948, SB loss: 0.707692
2023-10-30 19:14:30,182 Epoch: [343/484] Iter:[40/495], Time: 0.42, lr: [0.0032939143650641957], Loss: 1.913974, Acc:0.791601, Semantic loss: 0.725080, BCE loss: 0.484268, SB loss: 0.704626
2023-10-30 19:14:33,812 Epoch: [343/484] Iter:[50/495], Time: 0.41, lr: [0.0032934893712746162], Loss: 1.893735, Acc:0.795205, Semantic loss: 0.715622, BCE loss: 0.480404, SB loss: 0.697708
2023-10-30 19:14:37,544 Epoch: [343/484] Iter:[60/495], Time: 0.40, lr: [0.0032930643713914554], Loss: 1.912434, Acc:0.800575, Semantic loss: 0.723954, BCE loss: 0.487258, SB loss: 0.701221
2023-10-30 19:14:41,131 Epoch: [343/484] Iter:[70/495], Time: 0.40, lr: [0.003292639365413751], Loss: 1.914331, Acc:0.808241, Semantic loss: 0.716765, BCE loss: 0.500407, SB loss: 0.697159
2023-10-30 19:14:44,740 Epoch: [343/484] Iter:[80/495], Time: 0.39, lr: [0.0032922143533405434], Loss: 1.937537, Acc:0.806020, Semantic loss: 0.746315, BCE loss: 0.495239, SB loss: 0.695984
2023-10-30 19:14:48,486 Epoch: [343/484] Iter:[90/495], Time: 0.39, lr: [0.0032917893351708705], Loss: 1.947904, Acc:0.806689, Semantic loss: 0.746839, BCE loss: 0.501689, SB loss: 0.699376
2023-10-30 19:14:52,120 Epoch: [343/484] Iter:[100/495], Time: 0.39, lr: [0.003291364310903769], Loss: 1.979408, Acc:0.806700, Semantic loss: 0.760899, BCE loss: 0.509917, SB loss: 0.708592
2023-10-30 19:14:55,753 Epoch: [343/484] Iter:[110/495], Time: 0.38, lr: [0.003290939280538276], Loss: 1.986656, Acc:0.807202, Semantic loss: 0.760384, BCE loss: 0.514942, SB loss: 0.711330
2023-10-30 19:14:59,416 Epoch: [343/484] Iter:[120/495], Time: 0.38, lr: [0.0032905142440734308], Loss: 1.976010, Acc:0.807779, Semantic loss: 0.753314, BCE loss: 0.512302, SB loss: 0.710395
2023-10-30 19:15:03,107 Epoch: [343/484] Iter:[130/495], Time: 0.38, lr: [0.00329008920150827], Loss: 1.981487, Acc:0.807414, Semantic loss: 0.753236, BCE loss: 0.515180, SB loss: 0.713071
2023-10-30 19:15:06,723 Epoch: [343/484] Iter:[140/495], Time: 0.38, lr: [0.00328966415284183], Loss: 1.983100, Acc:0.808172, Semantic loss: 0.752111, BCE loss: 0.517940, SB loss: 0.713050
2023-10-30 19:15:10,435 Epoch: [343/484] Iter:[150/495], Time: 0.38, lr: [0.003289239098073146], Loss: 1.985671, Acc:0.806177, Semantic loss: 0.753603, BCE loss: 0.518293, SB loss: 0.713775
2023-10-30 19:15:14,088 Epoch: [343/484] Iter:[160/495], Time: 0.38, lr: [0.0032888140372012565], Loss: 1.990918, Acc:0.804856, Semantic loss: 0.752216, BCE loss: 0.521643, SB loss: 0.717059
2023-10-30 19:15:17,815 Epoch: [343/484] Iter:[170/495], Time: 0.38, lr: [0.003288388970225197], Loss: 1.990172, Acc:0.806168, Semantic loss: 0.752586, BCE loss: 0.520861, SB loss: 0.716725
2023-10-30 19:15:21,504 Epoch: [343/484] Iter:[180/495], Time: 0.38, lr: [0.003287963897144001], Loss: 1.997209, Acc:0.805959, Semantic loss: 0.756222, BCE loss: 0.522964, SB loss: 0.718023
2023-10-30 19:15:25,141 Epoch: [343/484] Iter:[190/495], Time: 0.38, lr: [0.003287538817956705], Loss: 1.989274, Acc:0.806868, Semantic loss: 0.751313, BCE loss: 0.521033, SB loss: 0.716929
2023-10-30 19:15:28,823 Epoch: [343/484] Iter:[200/495], Time: 0.38, lr: [0.0032871137326623457], Loss: 1.988016, Acc:0.805850, Semantic loss: 0.750869, BCE loss: 0.521356, SB loss: 0.715791
2023-10-30 19:15:32,484 Epoch: [343/484] Iter:[210/495], Time: 0.38, lr: [0.0032866886412599556], Loss: 1.983363, Acc:0.805481, Semantic loss: 0.746762, BCE loss: 0.521744, SB loss: 0.714858
2023-10-30 19:15:36,152 Epoch: [343/484] Iter:[220/495], Time: 0.38, lr: [0.0032862635437485707], Loss: 1.985273, Acc:0.805553, Semantic loss: 0.746236, BCE loss: 0.523753, SB loss: 0.715284
2023-10-30 19:15:39,943 Epoch: [343/484] Iter:[230/495], Time: 0.38, lr: [0.003285838440127222], Loss: 1.988398, Acc:0.805511, Semantic loss: 0.747466, BCE loss: 0.525127, SB loss: 0.715805
2023-10-30 19:15:43,575 Epoch: [343/484] Iter:[240/495], Time: 0.38, lr: [0.003285413330394948], Loss: 1.992116, Acc:0.807161, Semantic loss: 0.747217, BCE loss: 0.529011, SB loss: 0.715888
2023-10-30 19:15:47,189 Epoch: [343/484] Iter:[250/495], Time: 0.38, lr: [0.00328498821455078], Loss: 1.988756, Acc:0.806375, Semantic loss: 0.745371, BCE loss: 0.527382, SB loss: 0.716003
2023-10-30 19:15:50,810 Epoch: [343/484] Iter:[260/495], Time: 0.37, lr: [0.0032845630925937507], Loss: 1.992754, Acc:0.805142, Semantic loss: 0.748098, BCE loss: 0.528842, SB loss: 0.715814
2023-10-30 19:15:54,454 Epoch: [343/484] Iter:[270/495], Time: 0.37, lr: [0.0032841379645228925], Loss: 1.991512, Acc:0.805036, Semantic loss: 0.746488, BCE loss: 0.529402, SB loss: 0.715622
2023-10-30 19:15:58,049 Epoch: [343/484] Iter:[280/495], Time: 0.37, lr: [0.0032837128303372406], Loss: 1.991094, Acc:0.805725, Semantic loss: 0.745610, BCE loss: 0.530616, SB loss: 0.714868
2023-10-30 19:16:01,663 Epoch: [343/484] Iter:[290/495], Time: 0.37, lr: [0.0032832876900358255], Loss: 1.987159, Acc:0.806260, Semantic loss: 0.744521, BCE loss: 0.529500, SB loss: 0.713137
2023-10-30 19:16:05,304 Epoch: [343/484] Iter:[300/495], Time: 0.37, lr: [0.00328286254361768], Loss: 1.986049, Acc:0.806852, Semantic loss: 0.743682, BCE loss: 0.528873, SB loss: 0.713494
2023-10-30 19:16:08,979 Epoch: [343/484] Iter:[310/495], Time: 0.37, lr: [0.003282437391081835], Loss: 1.988990, Acc:0.806660, Semantic loss: 0.745608, BCE loss: 0.529222, SB loss: 0.714160
2023-10-30 19:16:12,658 Epoch: [343/484] Iter:[320/495], Time: 0.37, lr: [0.0032820122324273234], Loss: 1.993658, Acc:0.806299, Semantic loss: 0.749803, BCE loss: 0.528677, SB loss: 0.715178
2023-10-30 19:16:16,245 Epoch: [343/484] Iter:[330/495], Time: 0.37, lr: [0.0032815870676531755], Loss: 1.987258, Acc:0.805945, Semantic loss: 0.747346, BCE loss: 0.526424, SB loss: 0.713488
2023-10-30 19:16:19,918 Epoch: [343/484] Iter:[340/495], Time: 0.37, lr: [0.0032811618967584226], Loss: 1.988332, Acc:0.805937, Semantic loss: 0.749148, BCE loss: 0.525974, SB loss: 0.713210
2023-10-30 19:16:23,536 Epoch: [343/484] Iter:[350/495], Time: 0.37, lr: [0.0032807367197420947], Loss: 1.985060, Acc:0.805222, Semantic loss: 0.746708, BCE loss: 0.525140, SB loss: 0.713212
2023-10-30 19:16:27,201 Epoch: [343/484] Iter:[360/495], Time: 0.37, lr: [0.0032803115366032234], Loss: 1.985111, Acc:0.804645, Semantic loss: 0.747104, BCE loss: 0.524202, SB loss: 0.713805
2023-10-30 19:16:30,834 Epoch: [343/484] Iter:[370/495], Time: 0.37, lr: [0.003279886347340838], Loss: 1.982550, Acc:0.804632, Semantic loss: 0.745876, BCE loss: 0.523587, SB loss: 0.713087
2023-10-30 19:16:34,597 Epoch: [343/484] Iter:[380/495], Time: 0.37, lr: [0.003279461151953968], Loss: 1.983127, Acc:0.804628, Semantic loss: 0.747236, BCE loss: 0.521809, SB loss: 0.714082
2023-10-30 19:16:38,293 Epoch: [343/484] Iter:[390/495], Time: 0.37, lr: [0.003279035950441642], Loss: 1.983089, Acc:0.803650, Semantic loss: 0.747190, BCE loss: 0.521199, SB loss: 0.714700
2023-10-30 19:16:42,162 Epoch: [343/484] Iter:[400/495], Time: 0.37, lr: [0.0032786107428028916], Loss: 1.986653, Acc:0.802434, Semantic loss: 0.749038, BCE loss: 0.522583, SB loss: 0.715032
2023-10-30 19:16:45,751 Epoch: [343/484] Iter:[410/495], Time: 0.37, lr: [0.003278185529036744], Loss: 1.987194, Acc:0.802790, Semantic loss: 0.749342, BCE loss: 0.522728, SB loss: 0.715124
2023-10-30 19:16:49,344 Epoch: [343/484] Iter:[420/495], Time: 0.37, lr: [0.0032777603091422285], Loss: 1.985639, Acc:0.802821, Semantic loss: 0.748717, BCE loss: 0.521631, SB loss: 0.715292
2023-10-30 19:16:53,036 Epoch: [343/484] Iter:[430/495], Time: 0.37, lr: [0.0032773350831183726], Loss: 1.984967, Acc:0.802782, Semantic loss: 0.748463, BCE loss: 0.521035, SB loss: 0.715469
2023-10-30 19:16:56,676 Epoch: [343/484] Iter:[440/495], Time: 0.37, lr: [0.0032769098509642046], Loss: 1.986125, Acc:0.802774, Semantic loss: 0.748208, BCE loss: 0.521800, SB loss: 0.716117
2023-10-30 19:17:00,232 Epoch: [343/484] Iter:[450/495], Time: 0.37, lr: [0.003276484612678753], Loss: 1.984813, Acc:0.802054, Semantic loss: 0.747901, BCE loss: 0.520692, SB loss: 0.716219
2023-10-30 19:17:03,978 Epoch: [343/484] Iter:[460/495], Time: 0.37, lr: [0.003276059368261044], Loss: 1.986075, Acc:0.801951, Semantic loss: 0.748192, BCE loss: 0.521551, SB loss: 0.716332
2023-10-30 19:17:07,628 Epoch: [343/484] Iter:[470/495], Time: 0.37, lr: [0.0032756341177101046], Loss: 1.986960, Acc:0.800874, Semantic loss: 0.748777, BCE loss: 0.521450, SB loss: 0.716733
2023-10-30 19:17:11,409 Epoch: [343/484] Iter:[480/495], Time: 0.37, lr: [0.003275208861024963], Loss: 1.986747, Acc:0.801173, Semantic loss: 0.748560, BCE loss: 0.521742, SB loss: 0.716446
2023-10-30 19:17:14,882 Epoch: [343/484] Iter:[490/495], Time: 0.37, lr: [0.0032747835982046454], Loss: 1.987086, Acc:0.801018, Semantic loss: 0.748331, BCE loss: 0.522576, SB loss: 0.716179
2023-10-30 19:17:16,261 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:17:16,499 Loss: 2.019, MeanIU:  0.7108, Best_mIoU:  0.7309
2023-10-30 19:17:16,499 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745]
2023-10-30 19:17:18,854 Epoch: [344/484] Iter:[0/495], Time: 2.33, lr: [0.0032745709644934912], Loss: 1.630687, Acc:0.894813, Semantic loss: 0.526303, BCE loss: 0.529533, SB loss: 0.574852
2023-10-30 19:17:22,864 Epoch: [344/484] Iter:[10/495], Time: 0.58, lr: [0.0032741456924685816], Loss: 1.908120, Acc:0.857603, Semantic loss: 0.667800, BCE loss: 0.547529, SB loss: 0.692790
2023-10-30 19:17:26,686 Epoch: [344/484] Iter:[20/495], Time: 0.48, lr: [0.0032737204143060616], Loss: 1.935030, Acc:0.812397, Semantic loss: 0.706613, BCE loss: 0.517546, SB loss: 0.710871
2023-10-30 19:17:30,343 Epoch: [344/484] Iter:[30/495], Time: 0.45, lr: [0.003273295130004956], Loss: 1.999618, Acc:0.818136, Semantic loss: 0.727037, BCE loss: 0.548522, SB loss: 0.724059
2023-10-30 19:17:33,971 Epoch: [344/484] Iter:[40/495], Time: 0.43, lr: [0.003272869839564289], Loss: 1.996843, Acc:0.819220, Semantic loss: 0.728996, BCE loss: 0.551208, SB loss: 0.716639
2023-10-30 19:17:37,640 Epoch: [344/484] Iter:[50/495], Time: 0.41, lr: [0.0032724445429830862], Loss: 1.962776, Acc:0.817579, Semantic loss: 0.715385, BCE loss: 0.542712, SB loss: 0.704679
2023-10-30 19:17:41,232 Epoch: [344/484] Iter:[60/495], Time: 0.40, lr: [0.0032720192402603725], Loss: 1.990609, Acc:0.824012, Semantic loss: 0.730539, BCE loss: 0.551819, SB loss: 0.708251
2023-10-30 19:17:44,957 Epoch: [344/484] Iter:[70/495], Time: 0.40, lr: [0.003271593931395172], Loss: 1.970741, Acc:0.821959, Semantic loss: 0.726737, BCE loss: 0.540087, SB loss: 0.703917
2023-10-30 19:17:48,587 Epoch: [344/484] Iter:[80/495], Time: 0.40, lr: [0.0032711686163865083], Loss: 1.961259, Acc:0.816460, Semantic loss: 0.722443, BCE loss: 0.537163, SB loss: 0.701653
2023-10-30 19:17:52,117 Epoch: [344/484] Iter:[90/495], Time: 0.39, lr: [0.003270743295233405], Loss: 1.952809, Acc:0.814985, Semantic loss: 0.721871, BCE loss: 0.529488, SB loss: 0.701449
2023-10-30 19:17:55,802 Epoch: [344/484] Iter:[100/495], Time: 0.39, lr: [0.0032703179679348868], Loss: 1.962575, Acc:0.810334, Semantic loss: 0.731043, BCE loss: 0.529085, SB loss: 0.702447
2023-10-30 19:17:59,604 Epoch: [344/484] Iter:[110/495], Time: 0.39, lr: [0.0032698926344899753], Loss: 1.965259, Acc:0.810664, Semantic loss: 0.731300, BCE loss: 0.531440, SB loss: 0.702520
2023-10-30 19:18:03,165 Epoch: [344/484] Iter:[120/495], Time: 0.39, lr: [0.0032694672948976947], Loss: 1.975309, Acc:0.812266, Semantic loss: 0.735291, BCE loss: 0.536153, SB loss: 0.703865
2023-10-30 19:18:06,748 Epoch: [344/484] Iter:[130/495], Time: 0.38, lr: [0.003269041949157065], Loss: 1.974525, Acc:0.810372, Semantic loss: 0.734027, BCE loss: 0.535921, SB loss: 0.704576
2023-10-30 19:18:10,359 Epoch: [344/484] Iter:[140/495], Time: 0.38, lr: [0.003268616597267111], Loss: 1.966363, Acc:0.813348, Semantic loss: 0.730063, BCE loss: 0.533586, SB loss: 0.702715
2023-10-30 19:18:14,006 Epoch: [344/484] Iter:[150/495], Time: 0.38, lr: [0.0032681912392268546], Loss: 1.958159, Acc:0.811942, Semantic loss: 0.726963, BCE loss: 0.527655, SB loss: 0.703541
2023-10-30 19:18:17,697 Epoch: [344/484] Iter:[160/495], Time: 0.38, lr: [0.003267765875035317], Loss: 1.968897, Acc:0.809865, Semantic loss: 0.732204, BCE loss: 0.531348, SB loss: 0.705345
2023-10-30 19:18:21,353 Epoch: [344/484] Iter:[170/495], Time: 0.38, lr: [0.0032673405046915174], Loss: 1.972593, Acc:0.810228, Semantic loss: 0.733891, BCE loss: 0.530448, SB loss: 0.708254
2023-10-30 19:18:25,024 Epoch: [344/484] Iter:[180/495], Time: 0.38, lr: [0.0032669151281944798], Loss: 1.972735, Acc:0.810158, Semantic loss: 0.734727, BCE loss: 0.531205, SB loss: 0.706803
2023-10-30 19:18:28,724 Epoch: [344/484] Iter:[190/495], Time: 0.38, lr: [0.003266489745543224], Loss: 1.969901, Acc:0.807987, Semantic loss: 0.733783, BCE loss: 0.528827, SB loss: 0.707291
2023-10-30 19:18:32,401 Epoch: [344/484] Iter:[200/495], Time: 0.38, lr: [0.0032660643567367703], Loss: 1.968882, Acc:0.808147, Semantic loss: 0.732841, BCE loss: 0.530034, SB loss: 0.706008
2023-10-30 19:18:36,036 Epoch: [344/484] Iter:[210/495], Time: 0.38, lr: [0.0032656389617741377], Loss: 1.967995, Acc:0.809582, Semantic loss: 0.733596, BCE loss: 0.529392, SB loss: 0.705007
2023-10-30 19:18:39,740 Epoch: [344/484] Iter:[220/495], Time: 0.38, lr: [0.0032652135606543484], Loss: 1.964794, Acc:0.810856, Semantic loss: 0.732838, BCE loss: 0.527623, SB loss: 0.704333
2023-10-30 19:18:43,417 Epoch: [344/484] Iter:[230/495], Time: 0.38, lr: [0.0032647881533764203], Loss: 1.972431, Acc:0.812212, Semantic loss: 0.734715, BCE loss: 0.531394, SB loss: 0.706321
2023-10-30 19:18:47,133 Epoch: [344/484] Iter:[240/495], Time: 0.38, lr: [0.0032643627399393735], Loss: 1.979441, Acc:0.811547, Semantic loss: 0.738460, BCE loss: 0.532622, SB loss: 0.708359
2023-10-30 19:18:50,862 Epoch: [344/484] Iter:[250/495], Time: 0.38, lr: [0.003263937320342225], Loss: 1.975134, Acc:0.811947, Semantic loss: 0.735836, BCE loss: 0.531407, SB loss: 0.707891
2023-10-30 19:18:54,478 Epoch: [344/484] Iter:[260/495], Time: 0.38, lr: [0.0032635118945839965], Loss: 1.975543, Acc:0.813185, Semantic loss: 0.736205, BCE loss: 0.531367, SB loss: 0.707970
2023-10-30 19:18:58,054 Epoch: [344/484] Iter:[270/495], Time: 0.37, lr: [0.0032630864626637043], Loss: 1.973263, Acc:0.813575, Semantic loss: 0.735497, BCE loss: 0.531175, SB loss: 0.706591
2023-10-30 19:19:01,735 Epoch: [344/484] Iter:[280/495], Time: 0.37, lr: [0.0032626610245803673], Loss: 1.973056, Acc:0.813722, Semantic loss: 0.735703, BCE loss: 0.530252, SB loss: 0.707101
2023-10-30 19:19:05,257 Epoch: [344/484] Iter:[290/495], Time: 0.37, lr: [0.0032622355803330018], Loss: 1.967813, Acc:0.812895, Semantic loss: 0.733233, BCE loss: 0.529046, SB loss: 0.705535
2023-10-30 19:19:08,923 Epoch: [344/484] Iter:[300/495], Time: 0.37, lr: [0.0032618101299206276], Loss: 1.969543, Acc:0.812795, Semantic loss: 0.734449, BCE loss: 0.529130, SB loss: 0.705964
2023-10-30 19:19:12,515 Epoch: [344/484] Iter:[310/495], Time: 0.37, lr: [0.003261384673342261], Loss: 1.968149, Acc:0.813042, Semantic loss: 0.733501, BCE loss: 0.529397, SB loss: 0.705252
2023-10-30 19:19:16,326 Epoch: [344/484] Iter:[320/495], Time: 0.37, lr: [0.003260959210596918], Loss: 1.978227, Acc:0.810902, Semantic loss: 0.742715, BCE loss: 0.529155, SB loss: 0.706357
2023-10-30 19:19:20,012 Epoch: [344/484] Iter:[330/495], Time: 0.37, lr: [0.0032605337416836146], Loss: 1.983442, Acc:0.812105, Semantic loss: 0.743967, BCE loss: 0.531709, SB loss: 0.707767
2023-10-30 19:19:23,619 Epoch: [344/484] Iter:[340/495], Time: 0.37, lr: [0.0032601082666013697], Loss: 1.984528, Acc:0.810225, Semantic loss: 0.744688, BCE loss: 0.531954, SB loss: 0.707886
2023-10-30 19:19:27,293 Epoch: [344/484] Iter:[350/495], Time: 0.37, lr: [0.0032596827853491974], Loss: 1.983930, Acc:0.810221, Semantic loss: 0.744064, BCE loss: 0.531308, SB loss: 0.708558
2023-10-30 19:19:30,941 Epoch: [344/484] Iter:[360/495], Time: 0.37, lr: [0.003259257297926114], Loss: 1.979408, Acc:0.809557, Semantic loss: 0.742445, BCE loss: 0.529105, SB loss: 0.707858
2023-10-30 19:19:34,672 Epoch: [344/484] Iter:[370/495], Time: 0.37, lr: [0.003258831804331133], Loss: 1.978342, Acc:0.808197, Semantic loss: 0.742749, BCE loss: 0.527223, SB loss: 0.708370
2023-10-30 19:19:38,365 Epoch: [344/484] Iter:[380/495], Time: 0.37, lr: [0.0032584063045632728], Loss: 1.975236, Acc:0.808249, Semantic loss: 0.740605, BCE loss: 0.527187, SB loss: 0.707444
2023-10-30 19:19:42,067 Epoch: [344/484] Iter:[390/495], Time: 0.37, lr: [0.0032579807986215467], Loss: 1.974220, Acc:0.806677, Semantic loss: 0.740981, BCE loss: 0.525442, SB loss: 0.707797
2023-10-30 19:19:45,608 Epoch: [344/484] Iter:[400/495], Time: 0.37, lr: [0.003257555286504968], Loss: 1.971518, Acc:0.805713, Semantic loss: 0.740675, BCE loss: 0.523647, SB loss: 0.707196
2023-10-30 19:19:49,427 Epoch: [344/484] Iter:[410/495], Time: 0.37, lr: [0.003257129768212551], Loss: 1.972882, Acc:0.805145, Semantic loss: 0.741469, BCE loss: 0.524080, SB loss: 0.707333
2023-10-30 19:19:53,133 Epoch: [344/484] Iter:[420/495], Time: 0.37, lr: [0.0032567042437433116], Loss: 1.974047, Acc:0.805550, Semantic loss: 0.743335, BCE loss: 0.523238, SB loss: 0.707475
2023-10-30 19:19:56,785 Epoch: [344/484] Iter:[430/495], Time: 0.37, lr: [0.0032562787130962618], Loss: 1.976065, Acc:0.805315, Semantic loss: 0.744930, BCE loss: 0.522650, SB loss: 0.708485
2023-10-30 19:20:00,447 Epoch: [344/484] Iter:[440/495], Time: 0.37, lr: [0.0032558531762704158], Loss: 1.975441, Acc:0.806034, Semantic loss: 0.744029, BCE loss: 0.523166, SB loss: 0.708246
2023-10-30 19:20:04,065 Epoch: [344/484] Iter:[450/495], Time: 0.37, lr: [0.0032554276332647843], Loss: 1.975465, Acc:0.805829, Semantic loss: 0.744386, BCE loss: 0.522503, SB loss: 0.708576
2023-10-30 19:20:07,836 Epoch: [344/484] Iter:[460/495], Time: 0.37, lr: [0.003255002084078383], Loss: 1.973088, Acc:0.806229, Semantic loss: 0.742926, BCE loss: 0.522111, SB loss: 0.708050
2023-10-30 19:20:11,509 Epoch: [344/484] Iter:[470/495], Time: 0.37, lr: [0.0032545765287102226], Loss: 1.974304, Acc:0.806117, Semantic loss: 0.743838, BCE loss: 0.521614, SB loss: 0.708852
2023-10-30 19:20:15,162 Epoch: [344/484] Iter:[480/495], Time: 0.37, lr: [0.003254150967159314], Loss: 1.974715, Acc:0.806716, Semantic loss: 0.743699, BCE loss: 0.521915, SB loss: 0.709101
2023-10-30 19:20:18,639 Epoch: [344/484] Iter:[490/495], Time: 0.37, lr: [0.003253725399424672], Loss: 1.976194, Acc:0.807062, Semantic loss: 0.744094, BCE loss: 0.522665, SB loss: 0.709434
2023-10-30 19:20:20,008 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:20:20,248 Loss: 2.019, MeanIU:  0.7108, Best_mIoU:  0.7309
2023-10-30 19:20:20,248 [0.9707242  0.79143305 0.90375813 0.43885255 0.52615963 0.58335379
 0.66215625 0.67717944 0.91087218 0.59342597 0.92901705 0.74442603
 0.52579572 0.93035403 0.59719319 0.7963669  0.76079411 0.43882195
 0.72401745]
2023-10-30 19:20:22,422 Epoch: [345/484] Iter:[0/495], Time: 2.14, lr: [0.0032535126132381413], Loss: 2.269058, Acc:0.867224, Semantic loss: 0.729077, BCE loss: 0.808479, SB loss: 0.731502
2023-10-30 19:20:26,490 Epoch: [345/484] Iter:[10/495], Time: 0.56, lr: [0.003253087036226043], Loss: 2.012873, Acc:0.809623, Semantic loss: 0.742866, BCE loss: 0.529264, SB loss: 0.740743
2023-10-30 19:20:30,204 Epoch: [345/484] Iter:[20/495], Time: 0.47, lr: [0.0032526614530277377], Loss: 1.955503, Acc:0.802313, Semantic loss: 0.728531, BCE loss: 0.500194, SB loss: 0.726778
2023-10-30 19:20:33,755 Epoch: [345/484] Iter:[30/495], Time: 0.43, lr: [0.003252235863642235], Loss: 2.043883, Acc:0.799107, Semantic loss: 0.777136, BCE loss: 0.531009, SB loss: 0.735738
2023-10-30 19:20:37,367 Epoch: [345/484] Iter:[40/495], Time: 0.42, lr: [0.0032518102680685478], Loss: 1.982903, Acc:0.795199, Semantic loss: 0.742824, BCE loss: 0.523583, SB loss: 0.716497
2023-10-30 19:20:41,039 Epoch: [345/484] Iter:[50/495], Time: 0.41, lr: [0.0032513846663056846], Loss: 1.972185, Acc:0.797406, Semantic loss: 0.737548, BCE loss: 0.518075, SB loss: 0.716562
2023-10-30 19:20:44,605 Epoch: [345/484] Iter:[60/495], Time: 0.40, lr: [0.0032509590583526555], Loss: 1.983043, Acc:0.793258, Semantic loss: 0.743842, BCE loss: 0.521637, SB loss: 0.717564
2023-10-30 19:20:48,395 Epoch: [345/484] Iter:[70/495], Time: 0.40, lr: [0.003250533444208469], Loss: 1.977621, Acc:0.795863, Semantic loss: 0.735442, BCE loss: 0.526859, SB loss: 0.715319
2023-10-30 19:20:52,115 Epoch: [345/484] Iter:[80/495], Time: 0.39, lr: [0.0032501078238721367], Loss: 1.992859, Acc:0.803588, Semantic loss: 0.744285, BCE loss: 0.531312, SB loss: 0.717263
2023-10-30 19:20:55,737 Epoch: [345/484] Iter:[90/495], Time: 0.39, lr: [0.0032496821973426655], Loss: 1.980723, Acc:0.803516, Semantic loss: 0.738978, BCE loss: 0.528836, SB loss: 0.712910
2023-10-30 19:20:59,314 Epoch: [345/484] Iter:[100/495], Time: 0.39, lr: [0.003249256564619064], Loss: 1.989920, Acc:0.801937, Semantic loss: 0.746204, BCE loss: 0.529936, SB loss: 0.713780
2023-10-30 19:21:02,910 Epoch: [345/484] Iter:[110/495], Time: 0.38, lr: [0.0032488309257003405], Loss: 1.984309, Acc:0.803828, Semantic loss: 0.742695, BCE loss: 0.531408, SB loss: 0.710206
2023-10-30 19:21:06,588 Epoch: [345/484] Iter:[120/495], Time: 0.38, lr: [0.003248405280585505], Loss: 1.974502, Acc:0.805251, Semantic loss: 0.739421, BCE loss: 0.526348, SB loss: 0.708733
2023-10-30 19:21:10,341 Epoch: [345/484] Iter:[130/495], Time: 0.38, lr: [0.003247979629273563], Loss: 1.971921, Acc:0.805303, Semantic loss: 0.738318, BCE loss: 0.523965, SB loss: 0.709639
2023-10-30 19:21:14,003 Epoch: [345/484] Iter:[140/495], Time: 0.38, lr: [0.003247553971763523], Loss: 1.976718, Acc:0.806760, Semantic loss: 0.739131, BCE loss: 0.525985, SB loss: 0.711602
2023-10-30 19:21:17,606 Epoch: [345/484] Iter:[150/495], Time: 0.38, lr: [0.00324712830805439], Loss: 1.977408, Acc:0.806408, Semantic loss: 0.741790, BCE loss: 0.522963, SB loss: 0.712656
2023-10-30 19:21:21,229 Epoch: [345/484] Iter:[160/495], Time: 0.38, lr: [0.003246702638145174], Loss: 1.984349, Acc:0.806382, Semantic loss: 0.744466, BCE loss: 0.526276, SB loss: 0.713607
2023-10-30 19:21:24,821 Epoch: [345/484] Iter:[170/495], Time: 0.38, lr: [0.00324627696203488], Loss: 1.978344, Acc:0.805313, Semantic loss: 0.741452, BCE loss: 0.525161, SB loss: 0.711731
2023-10-30 19:21:28,418 Epoch: [345/484] Iter:[180/495], Time: 0.38, lr: [0.003245851279722513], Loss: 1.971001, Acc:0.805350, Semantic loss: 0.738254, BCE loss: 0.522770, SB loss: 0.709977
2023-10-30 19:21:32,046 Epoch: [345/484] Iter:[190/495], Time: 0.38, lr: [0.0032454255912070795], Loss: 1.972328, Acc:0.804877, Semantic loss: 0.740681, BCE loss: 0.521651, SB loss: 0.709996
2023-10-30 19:21:35,733 Epoch: [345/484] Iter:[200/495], Time: 0.38, lr: [0.003244999896487586], Loss: 1.973072, Acc:0.806152, Semantic loss: 0.741086, BCE loss: 0.522321, SB loss: 0.709665
2023-10-30 19:21:39,294 Epoch: [345/484] Iter:[210/495], Time: 0.37, lr: [0.0032445741955630376], Loss: 1.970820, Acc:0.804636, Semantic loss: 0.742530, BCE loss: 0.519812, SB loss: 0.708478
2023-10-30 19:21:43,069 Epoch: [345/484] Iter:[220/495], Time: 0.37, lr: [0.0032441484884324387], Loss: 1.972957, Acc:0.804295, Semantic loss: 0.742601, BCE loss: 0.521597, SB loss: 0.708759
2023-10-30 19:21:46,686 Epoch: [345/484] Iter:[230/495], Time: 0.37, lr: [0.0032437227750947927], Loss: 1.973394, Acc:0.803691, Semantic loss: 0.742583, BCE loss: 0.521793, SB loss: 0.709018
2023-10-30 19:21:50,364 Epoch: [345/484] Iter:[240/495], Time: 0.37, lr: [0.0032432970555491066], Loss: 1.979455, Acc:0.803449, Semantic loss: 0.745452, BCE loss: 0.523198, SB loss: 0.710805
2023-10-30 19:21:54,130 Epoch: [345/484] Iter:[250/495], Time: 0.37, lr: [0.0032428713297943824], Loss: 1.976813, Acc:0.805549, Semantic loss: 0.741737, BCE loss: 0.525467, SB loss: 0.709609
2023-10-30 19:21:57,870 Epoch: [345/484] Iter:[260/495], Time: 0.37, lr: [0.0032424455978296253], Loss: 1.975178, Acc:0.806246, Semantic loss: 0.740364, BCE loss: 0.524673, SB loss: 0.710142
2023-10-30 19:22:01,572 Epoch: [345/484] Iter:[270/495], Time: 0.37, lr: [0.0032420198596538365], Loss: 1.974004, Acc:0.807365, Semantic loss: 0.738439, BCE loss: 0.526273, SB loss: 0.709292
2023-10-30 19:22:05,138 Epoch: [345/484] Iter:[280/495], Time: 0.37, lr: [0.0032415941152660215], Loss: 1.971304, Acc:0.806912, Semantic loss: 0.736714, BCE loss: 0.524605, SB loss: 0.709985
2023-10-30 19:22:08,772 Epoch: [345/484] Iter:[290/495], Time: 0.37, lr: [0.0032411683646651826], Loss: 1.966094, Acc:0.806797, Semantic loss: 0.733720, BCE loss: 0.523932, SB loss: 0.708442
2023-10-30 19:22:12,503 Epoch: [345/484] Iter:[300/495], Time: 0.37, lr: [0.003240742607850321], Loss: 1.971155, Acc:0.806734, Semantic loss: 0.736473, BCE loss: 0.524718, SB loss: 0.709965
2023-10-30 19:22:16,084 Epoch: [345/484] Iter:[310/495], Time: 0.37, lr: [0.003240316844820439], Loss: 1.972551, Acc:0.806203, Semantic loss: 0.737075, BCE loss: 0.524639, SB loss: 0.710836
2023-10-30 19:22:19,667 Epoch: [345/484] Iter:[320/495], Time: 0.37, lr: [0.0032398910755745405], Loss: 1.973968, Acc:0.805227, Semantic loss: 0.737780, BCE loss: 0.525476, SB loss: 0.710712
2023-10-30 19:22:23,475 Epoch: [345/484] Iter:[330/495], Time: 0.37, lr: [0.003239465300111625], Loss: 1.972448, Acc:0.804472, Semantic loss: 0.736036, BCE loss: 0.525998, SB loss: 0.710414
2023-10-30 19:22:27,046 Epoch: [345/484] Iter:[340/495], Time: 0.37, lr: [0.003239039518430694], Loss: 1.971600, Acc:0.805826, Semantic loss: 0.735640, BCE loss: 0.525976, SB loss: 0.709984
2023-10-30 19:22:30,774 Epoch: [345/484] Iter:[350/495], Time: 0.37, lr: [0.0032386137305307505], Loss: 1.971054, Acc:0.804870, Semantic loss: 0.737284, BCE loss: 0.524201, SB loss: 0.709569
2023-10-30 19:22:34,363 Epoch: [345/484] Iter:[360/495], Time: 0.37, lr: [0.0032381879364107935], Loss: 1.972686, Acc:0.804311, Semantic loss: 0.738985, BCE loss: 0.523637, SB loss: 0.710064
2023-10-30 19:22:38,118 Epoch: [345/484] Iter:[370/495], Time: 0.37, lr: [0.0032377621360698233], Loss: 1.968897, Acc:0.803743, Semantic loss: 0.737093, BCE loss: 0.521875, SB loss: 0.709929
2023-10-30 19:22:41,650 Epoch: [345/484] Iter:[380/495], Time: 0.37, lr: [0.0032373363295068393], Loss: 1.973490, Acc:0.803726, Semantic loss: 0.739128, BCE loss: 0.522413, SB loss: 0.711948
2023-10-30 19:22:45,281 Epoch: [345/484] Iter:[390/495], Time: 0.37, lr: [0.0032369105167208427], Loss: 1.973726, Acc:0.802699, Semantic loss: 0.741364, BCE loss: 0.520821, SB loss: 0.711541
2023-10-30 19:22:48,844 Epoch: [345/484] Iter:[400/495], Time: 0.37, lr: [0.003236484697710833], Loss: 1.970792, Acc:0.802130, Semantic loss: 0.740263, BCE loss: 0.518895, SB loss: 0.711634
2023-10-30 19:22:52,512 Epoch: [345/484] Iter:[410/495], Time: 0.37, lr: [0.003236058872475808], Loss: 1.971400, Acc:0.801829, Semantic loss: 0.741151, BCE loss: 0.518998, SB loss: 0.711251
2023-10-30 19:22:56,148 Epoch: [345/484] Iter:[420/495], Time: 0.37, lr: [0.003235633041014767], Loss: 1.974203, Acc:0.801137, Semantic loss: 0.744017, BCE loss: 0.518340, SB loss: 0.711846
2023-10-30 19:22:59,901 Epoch: [345/484] Iter:[430/495], Time: 0.37, lr: [0.0032352072033267096], Loss: 1.972602, Acc:0.801866, Semantic loss: 0.742951, BCE loss: 0.518343, SB loss: 0.711308
2023-10-30 19:23:03,532 Epoch: [345/484] Iter:[440/495], Time: 0.37, lr: [0.0032347813594106327], Loss: 1.972213, Acc:0.802582, Semantic loss: 0.741956, BCE loss: 0.519312, SB loss: 0.710946
2023-10-30 19:23:07,269 Epoch: [345/484] Iter:[450/495], Time: 0.37, lr: [0.003234355509265535], Loss: 1.972504, Acc:0.802964, Semantic loss: 0.741882, BCE loss: 0.519652, SB loss: 0.710969
2023-10-30 19:23:10,891 Epoch: [345/484] Iter:[460/495], Time: 0.37, lr: [0.0032339296528904127], Loss: 1.971632, Acc:0.803348, Semantic loss: 0.741699, BCE loss: 0.518787, SB loss: 0.711146
2023-10-30 19:23:14,532 Epoch: [345/484] Iter:[470/495], Time: 0.37, lr: [0.003233503790284265], Loss: 1.973605, Acc:0.801931, Semantic loss: 0.742733, BCE loss: 0.518873, SB loss: 0.711999
2023-10-30 19:23:18,289 Epoch: [345/484] Iter:[480/495], Time: 0.37, lr: [0.0032330779214460874], Loss: 1.974983, Acc:0.801246, Semantic loss: 0.744891, BCE loss: 0.517953, SB loss: 0.712139
2023-10-30 19:23:21,760 Epoch: [345/484] Iter:[490/495], Time: 0.37, lr: [0.0032326520463748783], Loss: 1.974140, Acc:0.800947, Semantic loss: 0.744067, BCE loss: 0.517504, SB loss: 0.712569
2023-10-30 19:26:18,746 0 [0.87741344 0.60036383 0.79767124 0.13165491 0.29365799 0.37349665
 0.40349944 0.59932912 0.86175461 0.44323742 0.86297309 0.60695367
 0.02841952 0.63636833 0.00661682 0.06378292 0.09118933 0.05646943
 0.59851721] 0.43859836635197047
2023-10-30 19:26:18,747 1 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463] 0.6805481459728832
2023-10-30 19:26:18,750 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:26:18,991 Loss: 2.136, MeanIU:  0.6805, Best_mIoU:  0.7309
2023-10-30 19:26:18,991 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463]
2023-10-30 19:26:21,270 Epoch: [346/484] Iter:[0/495], Time: 2.25, lr: [0.0032324391065015725], Loss: 1.855877, Acc:0.815955, Semantic loss: 0.677515, BCE loss: 0.496074, SB loss: 0.682287
2023-10-30 19:26:25,083 Epoch: [346/484] Iter:[10/495], Time: 0.55, lr: [0.0032320132220789305], Loss: 2.046146, Acc:0.806332, Semantic loss: 0.748478, BCE loss: 0.562575, SB loss: 0.735092
2023-10-30 19:26:28,516 Epoch: [346/484] Iter:[20/495], Time: 0.45, lr: [0.003231587331420748], Loss: 2.023244, Acc:0.798669, Semantic loss: 0.755251, BCE loss: 0.552379, SB loss: 0.715614
2023-10-30 19:26:32,004 Epoch: [346/484] Iter:[30/495], Time: 0.42, lr: [0.0032311614345260182], Loss: 2.019788, Acc:0.801636, Semantic loss: 0.758378, BCE loss: 0.541987, SB loss: 0.719423
2023-10-30 19:26:35,398 Epoch: [346/484] Iter:[40/495], Time: 0.40, lr: [0.003230735531393737], Loss: 2.018752, Acc:0.806267, Semantic loss: 0.761870, BCE loss: 0.531746, SB loss: 0.725136
2023-10-30 19:26:38,757 Epoch: [346/484] Iter:[50/495], Time: 0.39, lr: [0.0032303096220228983], Loss: 2.012995, Acc:0.803979, Semantic loss: 0.763348, BCE loss: 0.525851, SB loss: 0.723796
2023-10-30 19:26:42,412 Epoch: [346/484] Iter:[60/495], Time: 0.38, lr: [0.0032298837064124986], Loss: 1.989326, Acc:0.807086, Semantic loss: 0.750316, BCE loss: 0.519305, SB loss: 0.719704
2023-10-30 19:26:45,877 Epoch: [346/484] Iter:[70/495], Time: 0.38, lr: [0.0032294577845615314], Loss: 1.977336, Acc:0.805152, Semantic loss: 0.738489, BCE loss: 0.525233, SB loss: 0.713614
2023-10-30 19:26:49,489 Epoch: [346/484] Iter:[80/495], Time: 0.38, lr: [0.0032290318564689915], Loss: 1.984267, Acc:0.801836, Semantic loss: 0.746044, BCE loss: 0.524886, SB loss: 0.713338
2023-10-30 19:26:53,012 Epoch: [346/484] Iter:[90/495], Time: 0.37, lr: [0.00322860592213387], Loss: 1.974503, Acc:0.806073, Semantic loss: 0.744649, BCE loss: 0.517247, SB loss: 0.712607
2023-10-30 19:26:56,626 Epoch: [346/484] Iter:[100/495], Time: 0.37, lr: [0.0032281799815551634], Loss: 1.993190, Acc:0.803275, Semantic loss: 0.755614, BCE loss: 0.520965, SB loss: 0.716611
2023-10-30 19:27:00,063 Epoch: [346/484] Iter:[110/495], Time: 0.37, lr: [0.0032277540347318634], Loss: 1.990985, Acc:0.800934, Semantic loss: 0.754819, BCE loss: 0.521065, SB loss: 0.715102
2023-10-30 19:27:03,699 Epoch: [346/484] Iter:[120/495], Time: 0.37, lr: [0.0032273280816629635], Loss: 1.990589, Acc:0.799392, Semantic loss: 0.757755, BCE loss: 0.516636, SB loss: 0.716199
2023-10-30 19:27:07,215 Epoch: [346/484] Iter:[130/495], Time: 0.37, lr: [0.0032269021223474545], Loss: 2.000483, Acc:0.800128, Semantic loss: 0.760834, BCE loss: 0.521558, SB loss: 0.718091
2023-10-30 19:27:10,753 Epoch: [346/484] Iter:[140/495], Time: 0.37, lr: [0.0032264761567843306], Loss: 2.002854, Acc:0.802983, Semantic loss: 0.762466, BCE loss: 0.520880, SB loss: 0.719508
2023-10-30 19:27:14,311 Epoch: [346/484] Iter:[150/495], Time: 0.37, lr: [0.0032260501849725827], Loss: 2.015942, Acc:0.803783, Semantic loss: 0.771067, BCE loss: 0.521404, SB loss: 0.723471
2023-10-30 19:27:17,963 Epoch: [346/484] Iter:[160/495], Time: 0.37, lr: [0.003225624206911201], Loss: 2.011108, Acc:0.804588, Semantic loss: 0.767689, BCE loss: 0.523083, SB loss: 0.720336
2023-10-30 19:27:21,563 Epoch: [346/484] Iter:[170/495], Time: 0.37, lr: [0.0032251982225991807], Loss: 2.014264, Acc:0.804817, Semantic loss: 0.768490, BCE loss: 0.524772, SB loss: 0.721002
2023-10-30 19:27:25,180 Epoch: [346/484] Iter:[180/495], Time: 0.37, lr: [0.0032247722320355096], Loss: 2.014411, Acc:0.805008, Semantic loss: 0.768589, BCE loss: 0.525929, SB loss: 0.719893
2023-10-30 19:27:28,810 Epoch: [346/484] Iter:[190/495], Time: 0.37, lr: [0.0032243462352191787], Loss: 2.011040, Acc:0.805939, Semantic loss: 0.765643, BCE loss: 0.525720, SB loss: 0.719677
2023-10-30 19:27:32,367 Epoch: [346/484] Iter:[200/495], Time: 0.36, lr: [0.0032239202321491774], Loss: 2.014577, Acc:0.806127, Semantic loss: 0.768800, BCE loss: 0.524934, SB loss: 0.720843
2023-10-30 19:27:36,088 Epoch: [346/484] Iter:[210/495], Time: 0.37, lr: [0.0032234942228244984], Loss: 2.005599, Acc:0.803597, Semantic loss: 0.765088, BCE loss: 0.520674, SB loss: 0.719836
2023-10-30 19:27:39,795 Epoch: [346/484] Iter:[220/495], Time: 0.37, lr: [0.00322306820724413], Loss: 2.010476, Acc:0.803062, Semantic loss: 0.768577, BCE loss: 0.520306, SB loss: 0.721592
2023-10-30 19:27:43,387 Epoch: [346/484] Iter:[230/495], Time: 0.37, lr: [0.0032226421854070616], Loss: 2.011087, Acc:0.803063, Semantic loss: 0.768950, BCE loss: 0.520115, SB loss: 0.722021
2023-10-30 19:27:47,083 Epoch: [346/484] Iter:[240/495], Time: 0.37, lr: [0.0032222161573122804], Loss: 2.010635, Acc:0.801987, Semantic loss: 0.768259, BCE loss: 0.520630, SB loss: 0.721747
2023-10-30 19:27:50,715 Epoch: [346/484] Iter:[250/495], Time: 0.37, lr: [0.0032217901229587786], Loss: 2.007901, Acc:0.800687, Semantic loss: 0.767351, BCE loss: 0.518887, SB loss: 0.721663
2023-10-30 19:27:54,280 Epoch: [346/484] Iter:[260/495], Time: 0.36, lr: [0.0032213640823455427], Loss: 2.012752, Acc:0.800410, Semantic loss: 0.769767, BCE loss: 0.520804, SB loss: 0.722181
2023-10-30 19:27:57,898 Epoch: [346/484] Iter:[270/495], Time: 0.36, lr: [0.003220938035471561], Loss: 2.010845, Acc:0.800901, Semantic loss: 0.769525, BCE loss: 0.519874, SB loss: 0.721445
2023-10-30 19:28:01,505 Epoch: [346/484] Iter:[280/495], Time: 0.36, lr: [0.003220511982335821], Loss: 2.003355, Acc:0.800708, Semantic loss: 0.764155, BCE loss: 0.518515, SB loss: 0.720685
2023-10-30 19:28:05,062 Epoch: [346/484] Iter:[290/495], Time: 0.36, lr: [0.003220085922937311], Loss: 1.998494, Acc:0.800918, Semantic loss: 0.761945, BCE loss: 0.516684, SB loss: 0.719865
2023-10-30 19:28:08,813 Epoch: [346/484] Iter:[300/495], Time: 0.36, lr: [0.003219659857275018], Loss: 1.997652, Acc:0.800705, Semantic loss: 0.761995, BCE loss: 0.516557, SB loss: 0.719100
2023-10-30 19:28:12,394 Epoch: [346/484] Iter:[310/495], Time: 0.36, lr: [0.0032192337853479288], Loss: 1.998250, Acc:0.801212, Semantic loss: 0.761851, BCE loss: 0.517528, SB loss: 0.718870
2023-10-30 19:28:15,931 Epoch: [346/484] Iter:[320/495], Time: 0.36, lr: [0.0032188077071550287], Loss: 1.996822, Acc:0.799598, Semantic loss: 0.760879, BCE loss: 0.517340, SB loss: 0.718603
2023-10-30 19:28:19,625 Epoch: [346/484] Iter:[330/495], Time: 0.36, lr: [0.003218381622695306], Loss: 1.996488, Acc:0.799904, Semantic loss: 0.760375, BCE loss: 0.518007, SB loss: 0.718105
2023-10-30 19:28:23,221 Epoch: [346/484] Iter:[340/495], Time: 0.36, lr: [0.003217955531967746], Loss: 1.990612, Acc:0.800030, Semantic loss: 0.757735, BCE loss: 0.516266, SB loss: 0.716611
2023-10-30 19:28:26,893 Epoch: [346/484] Iter:[350/495], Time: 0.36, lr: [0.0032175294349713348], Loss: 1.989889, Acc:0.799288, Semantic loss: 0.757052, BCE loss: 0.516241, SB loss: 0.716596
2023-10-30 19:28:30,540 Epoch: [346/484] Iter:[360/495], Time: 0.36, lr: [0.0032171033317050547], Loss: 1.989302, Acc:0.799778, Semantic loss: 0.757551, BCE loss: 0.515491, SB loss: 0.716260
2023-10-30 19:28:34,045 Epoch: [346/484] Iter:[370/495], Time: 0.36, lr: [0.0032166772221678946], Loss: 1.995415, Acc:0.799675, Semantic loss: 0.761551, BCE loss: 0.516255, SB loss: 0.717608
2023-10-30 19:28:37,639 Epoch: [346/484] Iter:[380/495], Time: 0.36, lr: [0.003216251106358838], Loss: 1.988080, Acc:0.799662, Semantic loss: 0.756941, BCE loss: 0.513991, SB loss: 0.717148
2023-10-30 19:28:41,237 Epoch: [346/484] Iter:[390/495], Time: 0.36, lr: [0.0032158249842768683], Loss: 1.986075, Acc:0.799643, Semantic loss: 0.754680, BCE loss: 0.514449, SB loss: 0.716946
2023-10-30 19:28:44,979 Epoch: [346/484] Iter:[400/495], Time: 0.36, lr: [0.0032153988559209695], Loss: 1.986986, Acc:0.799734, Semantic loss: 0.755648, BCE loss: 0.514032, SB loss: 0.717305
2023-10-30 19:28:48,577 Epoch: [346/484] Iter:[410/495], Time: 0.36, lr: [0.003214972721290127], Loss: 1.985800, Acc:0.801104, Semantic loss: 0.753463, BCE loss: 0.515776, SB loss: 0.716561
2023-10-30 19:28:52,298 Epoch: [346/484] Iter:[420/495], Time: 0.36, lr: [0.003214546580383323], Loss: 1.985152, Acc:0.801578, Semantic loss: 0.752344, BCE loss: 0.516631, SB loss: 0.716178
2023-10-30 19:28:55,931 Epoch: [346/484] Iter:[430/495], Time: 0.36, lr: [0.003214120433199541], Loss: 1.985472, Acc:0.801194, Semantic loss: 0.752870, BCE loss: 0.515598, SB loss: 0.717005
2023-10-30 19:28:59,573 Epoch: [346/484] Iter:[440/495], Time: 0.36, lr: [0.003213694279737762], Loss: 1.985424, Acc:0.800847, Semantic loss: 0.752414, BCE loss: 0.516343, SB loss: 0.716666
2023-10-30 19:29:03,146 Epoch: [346/484] Iter:[450/495], Time: 0.36, lr: [0.003213268119996972], Loss: 1.984410, Acc:0.801457, Semantic loss: 0.751471, BCE loss: 0.516501, SB loss: 0.716439
2023-10-30 19:29:06,749 Epoch: [346/484] Iter:[460/495], Time: 0.36, lr: [0.0032128419539761512], Loss: 1.982465, Acc:0.801767, Semantic loss: 0.751004, BCE loss: 0.515445, SB loss: 0.716016
2023-10-30 19:29:10,304 Epoch: [346/484] Iter:[470/495], Time: 0.36, lr: [0.0032124157816742814], Loss: 1.981624, Acc:0.802237, Semantic loss: 0.751001, BCE loss: 0.515281, SB loss: 0.715342
2023-10-30 19:29:13,968 Epoch: [346/484] Iter:[480/495], Time: 0.36, lr: [0.0032119896030903435], Loss: 1.981610, Acc:0.802472, Semantic loss: 0.750997, BCE loss: 0.515131, SB loss: 0.715483
2023-10-30 19:29:17,344 Epoch: [346/484] Iter:[490/495], Time: 0.36, lr: [0.0032115634182233207], Loss: 1.978967, Acc:0.802175, Semantic loss: 0.749866, BCE loss: 0.513926, SB loss: 0.715175
2023-10-30 19:29:18,723 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:29:18,966 Loss: 2.136, MeanIU:  0.6805, Best_mIoU:  0.7309
2023-10-30 19:29:18,966 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463]
2023-10-30 19:29:20,962 Epoch: [347/484] Iter:[0/495], Time: 1.96, lr: [0.003211350323433333], Loss: 1.634362, Acc:0.688059, Semantic loss: 0.610332, BCE loss: 0.397074, SB loss: 0.626957
2023-10-30 19:29:24,862 Epoch: [347/484] Iter:[10/495], Time: 0.53, lr: [0.00321092412913977], Loss: 1.911016, Acc:0.820086, Semantic loss: 0.711890, BCE loss: 0.504094, SB loss: 0.695032
2023-10-30 19:29:28,479 Epoch: [347/484] Iter:[20/495], Time: 0.45, lr: [0.0032104979285605714], Loss: 1.881341, Acc:0.809858, Semantic loss: 0.705088, BCE loss: 0.499663, SB loss: 0.676589
2023-10-30 19:29:32,153 Epoch: [347/484] Iter:[30/495], Time: 0.42, lr: [0.0032100717216947197], Loss: 1.888926, Acc:0.810398, Semantic loss: 0.710565, BCE loss: 0.497529, SB loss: 0.680833
2023-10-30 19:29:35,866 Epoch: [347/484] Iter:[40/495], Time: 0.41, lr: [0.0032096455085411937], Loss: 1.949097, Acc:0.813638, Semantic loss: 0.733429, BCE loss: 0.521540, SB loss: 0.694128
2023-10-30 19:29:39,666 Epoch: [347/484] Iter:[50/495], Time: 0.41, lr: [0.0032092192890989723], Loss: 1.942217, Acc:0.815254, Semantic loss: 0.726686, BCE loss: 0.519218, SB loss: 0.696314
2023-10-30 19:29:43,364 Epoch: [347/484] Iter:[60/495], Time: 0.40, lr: [0.003208793063367035], Loss: 1.972801, Acc:0.819676, Semantic loss: 0.735265, BCE loss: 0.533849, SB loss: 0.703688
2023-10-30 19:29:47,117 Epoch: [347/484] Iter:[70/495], Time: 0.40, lr: [0.003208366831344361], Loss: 1.974976, Acc:0.820955, Semantic loss: 0.733211, BCE loss: 0.539413, SB loss: 0.702353
2023-10-30 19:29:50,763 Epoch: [347/484] Iter:[80/495], Time: 0.39, lr: [0.003207940593029929], Loss: 1.969556, Acc:0.820619, Semantic loss: 0.732388, BCE loss: 0.535546, SB loss: 0.701622
2023-10-30 19:29:54,390 Epoch: [347/484] Iter:[90/495], Time: 0.39, lr: [0.0032075143484227163], Loss: 1.965486, Acc:0.816344, Semantic loss: 0.729483, BCE loss: 0.533791, SB loss: 0.702212
2023-10-30 19:29:58,007 Epoch: [347/484] Iter:[100/495], Time: 0.39, lr: [0.003207088097521701], Loss: 1.964429, Acc:0.811429, Semantic loss: 0.731508, BCE loss: 0.529633, SB loss: 0.703288
2023-10-30 19:30:01,674 Epoch: [347/484] Iter:[110/495], Time: 0.38, lr: [0.0032066618403258623], Loss: 1.965933, Acc:0.807655, Semantic loss: 0.732449, BCE loss: 0.531020, SB loss: 0.702464
2023-10-30 19:30:05,279 Epoch: [347/484] Iter:[120/495], Time: 0.38, lr: [0.0032062355768341755], Loss: 1.966301, Acc:0.808590, Semantic loss: 0.731296, BCE loss: 0.532200, SB loss: 0.702805
2023-10-30 19:30:08,912 Epoch: [347/484] Iter:[130/495], Time: 0.38, lr: [0.003205809307045619], Loss: 1.972572, Acc:0.807677, Semantic loss: 0.736279, BCE loss: 0.531140, SB loss: 0.705153
2023-10-30 19:30:12,588 Epoch: [347/484] Iter:[140/495], Time: 0.38, lr: [0.003205383030959167], Loss: 1.975518, Acc:0.806671, Semantic loss: 0.737672, BCE loss: 0.531058, SB loss: 0.706789
2023-10-30 19:30:16,267 Epoch: [347/484] Iter:[150/495], Time: 0.38, lr: [0.003204956748573799], Loss: 1.979842, Acc:0.808190, Semantic loss: 0.739479, BCE loss: 0.533339, SB loss: 0.707024
2023-10-30 19:30:19,903 Epoch: [347/484] Iter:[160/495], Time: 0.38, lr: [0.00320453045988849], Loss: 1.969028, Acc:0.806698, Semantic loss: 0.736496, BCE loss: 0.529229, SB loss: 0.703304
2023-10-30 19:30:23,496 Epoch: [347/484] Iter:[170/495], Time: 0.38, lr: [0.0032041041649022144], Loss: 1.961016, Acc:0.809594, Semantic loss: 0.733520, BCE loss: 0.524518, SB loss: 0.702978
2023-10-30 19:30:27,176 Epoch: [347/484] Iter:[180/495], Time: 0.38, lr: [0.003203677863613948], Loss: 1.966680, Acc:0.809989, Semantic loss: 0.735380, BCE loss: 0.528067, SB loss: 0.703232
2023-10-30 19:30:30,862 Epoch: [347/484] Iter:[190/495], Time: 0.38, lr: [0.003203251556022667], Loss: 1.966985, Acc:0.811560, Semantic loss: 0.735393, BCE loss: 0.527723, SB loss: 0.703868
2023-10-30 19:30:34,648 Epoch: [347/484] Iter:[200/495], Time: 0.38, lr: [0.003202825242127346], Loss: 1.973011, Acc:0.809896, Semantic loss: 0.737269, BCE loss: 0.529625, SB loss: 0.706116
2023-10-30 19:30:38,241 Epoch: [347/484] Iter:[210/495], Time: 0.38, lr: [0.003202398921926958], Loss: 1.974255, Acc:0.808677, Semantic loss: 0.737541, BCE loss: 0.529776, SB loss: 0.706937
2023-10-30 19:30:41,834 Epoch: [347/484] Iter:[220/495], Time: 0.37, lr: [0.0032019725954204772], Loss: 1.967877, Acc:0.806848, Semantic loss: 0.735856, BCE loss: 0.526155, SB loss: 0.705866
2023-10-30 19:30:45,486 Epoch: [347/484] Iter:[230/495], Time: 0.37, lr: [0.0032015462626068794], Loss: 1.968934, Acc:0.806607, Semantic loss: 0.734963, BCE loss: 0.528593, SB loss: 0.705378
2023-10-30 19:30:49,119 Epoch: [347/484] Iter:[240/495], Time: 0.37, lr: [0.003201119923485136], Loss: 1.973181, Acc:0.806379, Semantic loss: 0.738196, BCE loss: 0.528293, SB loss: 0.706693
2023-10-30 19:30:52,718 Epoch: [347/484] Iter:[250/495], Time: 0.37, lr: [0.003200693578054222], Loss: 1.972267, Acc:0.804650, Semantic loss: 0.737290, BCE loss: 0.528133, SB loss: 0.706843
2023-10-30 19:30:56,441 Epoch: [347/484] Iter:[260/495], Time: 0.37, lr: [0.0032002672263131073], Loss: 1.979724, Acc:0.803080, Semantic loss: 0.745640, BCE loss: 0.526512, SB loss: 0.707573
2023-10-30 19:31:00,116 Epoch: [347/484] Iter:[270/495], Time: 0.37, lr: [0.0031998408682607673], Loss: 1.979348, Acc:0.801775, Semantic loss: 0.745674, BCE loss: 0.526882, SB loss: 0.706792
2023-10-30 19:31:03,759 Epoch: [347/484] Iter:[280/495], Time: 0.37, lr: [0.003199414503896173], Loss: 1.980908, Acc:0.800619, Semantic loss: 0.748454, BCE loss: 0.525832, SB loss: 0.706623
2023-10-30 19:31:07,426 Epoch: [347/484] Iter:[290/495], Time: 0.37, lr: [0.003198988133218297], Loss: 1.989699, Acc:0.800254, Semantic loss: 0.755596, BCE loss: 0.525624, SB loss: 0.708479
2023-10-30 19:31:11,125 Epoch: [347/484] Iter:[300/495], Time: 0.37, lr: [0.003198561756226108], Loss: 1.991658, Acc:0.798904, Semantic loss: 0.758544, BCE loss: 0.524548, SB loss: 0.708566
2023-10-30 19:31:14,700 Epoch: [347/484] Iter:[310/495], Time: 0.37, lr: [0.0031981353729185814], Loss: 1.994675, Acc:0.799352, Semantic loss: 0.758618, BCE loss: 0.526871, SB loss: 0.709187
2023-10-30 19:31:18,327 Epoch: [347/484] Iter:[320/495], Time: 0.37, lr: [0.0031977089832946858], Loss: 1.997421, Acc:0.799304, Semantic loss: 0.759712, BCE loss: 0.527625, SB loss: 0.710084
2023-10-30 19:31:21,936 Epoch: [347/484] Iter:[330/495], Time: 0.37, lr: [0.003197282587353393], Loss: 2.001855, Acc:0.798923, Semantic loss: 0.761784, BCE loss: 0.528546, SB loss: 0.711525
2023-10-30 19:31:25,601 Epoch: [347/484] Iter:[340/495], Time: 0.37, lr: [0.00319685618509367], Loss: 2.000052, Acc:0.799199, Semantic loss: 0.761177, BCE loss: 0.527348, SB loss: 0.711527
2023-10-30 19:31:29,226 Epoch: [347/484] Iter:[350/495], Time: 0.37, lr: [0.0031964297765144905], Loss: 2.002639, Acc:0.799047, Semantic loss: 0.760663, BCE loss: 0.529681, SB loss: 0.712294
2023-10-30 19:31:32,920 Epoch: [347/484] Iter:[360/495], Time: 0.37, lr: [0.0031960033616148234], Loss: 2.000249, Acc:0.798353, Semantic loss: 0.759663, BCE loss: 0.528886, SB loss: 0.711700
2023-10-30 19:31:36,613 Epoch: [347/484] Iter:[370/495], Time: 0.37, lr: [0.003195576940393637], Loss: 2.006841, Acc:0.799279, Semantic loss: 0.761622, BCE loss: 0.532641, SB loss: 0.712578
2023-10-30 19:31:40,264 Epoch: [347/484] Iter:[380/495], Time: 0.37, lr: [0.003195150512849899], Loss: 2.003357, Acc:0.800160, Semantic loss: 0.759074, BCE loss: 0.532790, SB loss: 0.711493
2023-10-30 19:31:43,906 Epoch: [347/484] Iter:[390/495], Time: 0.37, lr: [0.0031947240789825817], Loss: 2.002487, Acc:0.799926, Semantic loss: 0.759004, BCE loss: 0.532111, SB loss: 0.711372
2023-10-30 19:31:47,549 Epoch: [347/484] Iter:[400/495], Time: 0.37, lr: [0.003194297638790651], Loss: 2.000258, Acc:0.800634, Semantic loss: 0.757957, BCE loss: 0.531140, SB loss: 0.711162
2023-10-30 19:31:51,110 Epoch: [347/484] Iter:[410/495], Time: 0.37, lr: [0.003193871192273075], Loss: 1.998999, Acc:0.800925, Semantic loss: 0.757955, BCE loss: 0.529497, SB loss: 0.711547
2023-10-30 19:31:54,759 Epoch: [347/484] Iter:[420/495], Time: 0.37, lr: [0.003193444739428821], Loss: 1.996689, Acc:0.800839, Semantic loss: 0.757624, BCE loss: 0.527935, SB loss: 0.711130
2023-10-30 19:31:58,346 Epoch: [347/484] Iter:[430/495], Time: 0.37, lr: [0.0031930182802568574], Loss: 1.994939, Acc:0.800559, Semantic loss: 0.756486, BCE loss: 0.527033, SB loss: 0.711420
2023-10-30 19:32:02,015 Epoch: [347/484] Iter:[440/495], Time: 0.37, lr: [0.0031925918147561517], Loss: 1.995240, Acc:0.800894, Semantic loss: 0.756404, BCE loss: 0.526798, SB loss: 0.712037
2023-10-30 19:32:05,603 Epoch: [347/484] Iter:[450/495], Time: 0.37, lr: [0.00319216534292567], Loss: 1.995492, Acc:0.801224, Semantic loss: 0.756602, BCE loss: 0.527103, SB loss: 0.711786
2023-10-30 19:32:09,240 Epoch: [347/484] Iter:[460/495], Time: 0.37, lr: [0.003191738864764377], Loss: 1.993880, Acc:0.801904, Semantic loss: 0.755071, BCE loss: 0.527336, SB loss: 0.711474
2023-10-30 19:32:12,841 Epoch: [347/484] Iter:[470/495], Time: 0.37, lr: [0.003191312380271242], Loss: 1.992384, Acc:0.801920, Semantic loss: 0.754730, BCE loss: 0.526840, SB loss: 0.710813
2023-10-30 19:32:16,477 Epoch: [347/484] Iter:[480/495], Time: 0.37, lr: [0.0031908858894452285], Loss: 1.991914, Acc:0.801808, Semantic loss: 0.753667, BCE loss: 0.527057, SB loss: 0.711189
2023-10-30 19:32:19,942 Epoch: [347/484] Iter:[490/495], Time: 0.37, lr: [0.0031904593922853024], Loss: 1.990208, Acc:0.802217, Semantic loss: 0.752440, BCE loss: 0.526959, SB loss: 0.710810
2023-10-30 19:32:21,317 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:32:21,563 Loss: 2.136, MeanIU:  0.6805, Best_mIoU:  0.7309
2023-10-30 19:32:21,563 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463]
2023-10-30 19:32:23,796 Epoch: [348/484] Iter:[0/495], Time: 2.20, lr: [0.003190246141329798], Loss: 2.357996, Acc:0.739211, Semantic loss: 0.895382, BCE loss: 0.726538, SB loss: 0.736076
2023-10-30 19:32:27,663 Epoch: [348/484] Iter:[10/495], Time: 0.55, lr: [0.0031898196346670632], Loss: 1.999184, Acc:0.785853, Semantic loss: 0.726297, BCE loss: 0.574089, SB loss: 0.698799
2023-10-30 19:32:31,405 Epoch: [348/484] Iter:[20/495], Time: 0.47, lr: [0.0031893931216678277], Loss: 1.948322, Acc:0.800726, Semantic loss: 0.715863, BCE loss: 0.539650, SB loss: 0.692809
2023-10-30 19:32:34,974 Epoch: [348/484] Iter:[30/495], Time: 0.43, lr: [0.003188966602331057], Loss: 2.008892, Acc:0.790469, Semantic loss: 0.766638, BCE loss: 0.530518, SB loss: 0.711736
2023-10-30 19:32:38,687 Epoch: [348/484] Iter:[40/495], Time: 0.42, lr: [0.0031885400766557127], Loss: 1.985272, Acc:0.792130, Semantic loss: 0.747937, BCE loss: 0.532183, SB loss: 0.705153
2023-10-30 19:32:42,301 Epoch: [348/484] Iter:[50/495], Time: 0.41, lr: [0.0031881135446407615], Loss: 1.985835, Acc:0.793936, Semantic loss: 0.742249, BCE loss: 0.537495, SB loss: 0.706091
2023-10-30 19:32:45,955 Epoch: [348/484] Iter:[60/495], Time: 0.40, lr: [0.003187687006285165], Loss: 1.984304, Acc:0.795878, Semantic loss: 0.740723, BCE loss: 0.537100, SB loss: 0.706481
2023-10-30 19:32:49,621 Epoch: [348/484] Iter:[70/495], Time: 0.39, lr: [0.0031872604615878868], Loss: 2.018032, Acc:0.793950, Semantic loss: 0.768404, BCE loss: 0.539260, SB loss: 0.710368
2023-10-30 19:32:53,313 Epoch: [348/484] Iter:[80/495], Time: 0.39, lr: [0.0031868339105478884], Loss: 2.019787, Acc:0.793120, Semantic loss: 0.765886, BCE loss: 0.542816, SB loss: 0.711086
2023-10-30 19:32:56,953 Epoch: [348/484] Iter:[90/495], Time: 0.39, lr: [0.0031864073531641334], Loss: 2.029497, Acc:0.791067, Semantic loss: 0.772690, BCE loss: 0.541956, SB loss: 0.714851
2023-10-30 19:33:00,536 Epoch: [348/484] Iter:[100/495], Time: 0.39, lr: [0.0031859807894355843], Loss: 2.028762, Acc:0.790469, Semantic loss: 0.768993, BCE loss: 0.541200, SB loss: 0.718568
2023-10-30 19:33:04,123 Epoch: [348/484] Iter:[110/495], Time: 0.38, lr: [0.003185554219361202], Loss: 2.017034, Acc:0.785223, Semantic loss: 0.766460, BCE loss: 0.533023, SB loss: 0.717550
2023-10-30 19:33:07,685 Epoch: [348/484] Iter:[120/495], Time: 0.38, lr: [0.0031851276429399468], Loss: 2.020441, Acc:0.786850, Semantic loss: 0.764901, BCE loss: 0.537556, SB loss: 0.717984
2023-10-30 19:33:11,460 Epoch: [348/484] Iter:[130/495], Time: 0.38, lr: [0.0031847010601707823], Loss: 2.033692, Acc:0.789677, Semantic loss: 0.770655, BCE loss: 0.541280, SB loss: 0.721757
2023-10-30 19:33:15,090 Epoch: [348/484] Iter:[140/495], Time: 0.38, lr: [0.0031842744710526673], Loss: 2.029707, Acc:0.791689, Semantic loss: 0.767655, BCE loss: 0.540287, SB loss: 0.721764
2023-10-30 19:33:18,723 Epoch: [348/484] Iter:[150/495], Time: 0.38, lr: [0.003183847875584563], Loss: 2.016708, Acc:0.794171, Semantic loss: 0.757657, BCE loss: 0.540497, SB loss: 0.718553
2023-10-30 19:33:22,464 Epoch: [348/484] Iter:[160/495], Time: 0.38, lr: [0.003183421273765428], Loss: 2.015956, Acc:0.792369, Semantic loss: 0.758500, BCE loss: 0.538586, SB loss: 0.718870
2023-10-30 19:33:26,236 Epoch: [348/484] Iter:[170/495], Time: 0.38, lr: [0.003182994665594225], Loss: 2.020386, Acc:0.793009, Semantic loss: 0.765163, BCE loss: 0.537705, SB loss: 0.717518
2023-10-30 19:33:29,852 Epoch: [348/484] Iter:[180/495], Time: 0.38, lr: [0.003182568051069911], Loss: 2.012599, Acc:0.794627, Semantic loss: 0.758426, BCE loss: 0.536111, SB loss: 0.718063
2023-10-30 19:33:33,540 Epoch: [348/484] Iter:[190/495], Time: 0.38, lr: [0.003182141430191447], Loss: 2.007211, Acc:0.792217, Semantic loss: 0.755798, BCE loss: 0.533199, SB loss: 0.718214
2023-10-30 19:33:37,202 Epoch: [348/484] Iter:[200/495], Time: 0.38, lr: [0.003181714802957789], Loss: 2.001922, Acc:0.791400, Semantic loss: 0.752862, BCE loss: 0.531463, SB loss: 0.717597
2023-10-30 19:33:40,785 Epoch: [348/484] Iter:[210/495], Time: 0.38, lr: [0.003181288169367898], Loss: 2.008249, Acc:0.792569, Semantic loss: 0.758233, BCE loss: 0.529924, SB loss: 0.720093
2023-10-30 19:33:44,440 Epoch: [348/484] Iter:[220/495], Time: 0.37, lr: [0.0031808615294207318], Loss: 2.004294, Acc:0.793986, Semantic loss: 0.755206, BCE loss: 0.529641, SB loss: 0.719447
2023-10-30 19:33:48,166 Epoch: [348/484] Iter:[230/495], Time: 0.37, lr: [0.0031804348831152474], Loss: 2.002298, Acc:0.793465, Semantic loss: 0.755004, BCE loss: 0.529153, SB loss: 0.718140
2023-10-30 19:33:51,858 Epoch: [348/484] Iter:[240/495], Time: 0.37, lr: [0.003180008230450402], Loss: 1.999710, Acc:0.792931, Semantic loss: 0.755270, BCE loss: 0.526635, SB loss: 0.717805
2023-10-30 19:33:55,481 Epoch: [348/484] Iter:[250/495], Time: 0.37, lr: [0.003179581571425154], Loss: 2.000260, Acc:0.793645, Semantic loss: 0.757182, BCE loss: 0.526038, SB loss: 0.717040
2023-10-30 19:33:59,176 Epoch: [348/484] Iter:[260/495], Time: 0.37, lr: [0.00317915490603846], Loss: 2.000278, Acc:0.794603, Semantic loss: 0.757160, BCE loss: 0.526723, SB loss: 0.716395
2023-10-30 19:34:02,844 Epoch: [348/484] Iter:[270/495], Time: 0.37, lr: [0.003178728234289276], Loss: 1.994079, Acc:0.795210, Semantic loss: 0.753035, BCE loss: 0.526386, SB loss: 0.714657
2023-10-30 19:34:06,483 Epoch: [348/484] Iter:[280/495], Time: 0.37, lr: [0.003178301556176557], Loss: 1.990424, Acc:0.794888, Semantic loss: 0.751443, BCE loss: 0.524561, SB loss: 0.714419
2023-10-30 19:34:10,069 Epoch: [348/484] Iter:[290/495], Time: 0.37, lr: [0.0031778748716992616], Loss: 1.993291, Acc:0.796053, Semantic loss: 0.752633, BCE loss: 0.525945, SB loss: 0.714712
2023-10-30 19:34:13,691 Epoch: [348/484] Iter:[300/495], Time: 0.37, lr: [0.0031774481808563445], Loss: 1.996894, Acc:0.796332, Semantic loss: 0.754423, BCE loss: 0.526638, SB loss: 0.715832
2023-10-30 19:34:17,276 Epoch: [348/484] Iter:[310/495], Time: 0.37, lr: [0.0031770214836467593], Loss: 1.991758, Acc:0.797374, Semantic loss: 0.752036, BCE loss: 0.525771, SB loss: 0.713951
2023-10-30 19:34:20,922 Epoch: [348/484] Iter:[320/495], Time: 0.37, lr: [0.0031765947800694613], Loss: 1.991117, Acc:0.796987, Semantic loss: 0.752317, BCE loss: 0.524637, SB loss: 0.714163
2023-10-30 19:34:24,577 Epoch: [348/484] Iter:[330/495], Time: 0.37, lr: [0.0031761680701234063], Loss: 1.991520, Acc:0.798039, Semantic loss: 0.751965, BCE loss: 0.524848, SB loss: 0.714708
2023-10-30 19:34:28,239 Epoch: [348/484] Iter:[340/495], Time: 0.37, lr: [0.0031757413538075485], Loss: 1.991007, Acc:0.796900, Semantic loss: 0.752467, BCE loss: 0.523367, SB loss: 0.715173
2023-10-30 19:34:31,945 Epoch: [348/484] Iter:[350/495], Time: 0.37, lr: [0.0031753146311208407], Loss: 1.989794, Acc:0.796933, Semantic loss: 0.753303, BCE loss: 0.520970, SB loss: 0.715521
2023-10-30 19:34:35,551 Epoch: [348/484] Iter:[360/495], Time: 0.37, lr: [0.0031748879020622356], Loss: 1.989811, Acc:0.797705, Semantic loss: 0.752355, BCE loss: 0.522472, SB loss: 0.714983
2023-10-30 19:34:39,170 Epoch: [348/484] Iter:[370/495], Time: 0.37, lr: [0.0031744611666306892], Loss: 1.989678, Acc:0.797402, Semantic loss: 0.752497, BCE loss: 0.522990, SB loss: 0.714191
2023-10-30 19:34:42,790 Epoch: [348/484] Iter:[380/495], Time: 0.37, lr: [0.0031740344248251534], Loss: 1.989483, Acc:0.798307, Semantic loss: 0.752263, BCE loss: 0.522802, SB loss: 0.714418
2023-10-30 19:34:46,344 Epoch: [348/484] Iter:[390/495], Time: 0.37, lr: [0.00317360767664458], Loss: 1.986735, Acc:0.797649, Semantic loss: 0.751172, BCE loss: 0.521419, SB loss: 0.714144
2023-10-30 19:34:49,966 Epoch: [348/484] Iter:[400/495], Time: 0.37, lr: [0.0031731809220879197], Loss: 1.988615, Acc:0.797918, Semantic loss: 0.752030, BCE loss: 0.521547, SB loss: 0.715038
2023-10-30 19:34:53,558 Epoch: [348/484] Iter:[410/495], Time: 0.37, lr: [0.003172754161154128], Loss: 1.985762, Acc:0.797663, Semantic loss: 0.750746, BCE loss: 0.520855, SB loss: 0.714160
2023-10-30 19:34:57,337 Epoch: [348/484] Iter:[420/495], Time: 0.37, lr: [0.0031723273938421555], Loss: 1.982448, Acc:0.797736, Semantic loss: 0.748610, BCE loss: 0.520344, SB loss: 0.713494
2023-10-30 19:35:01,105 Epoch: [348/484] Iter:[430/495], Time: 0.37, lr: [0.003171900620150952], Loss: 1.982308, Acc:0.798405, Semantic loss: 0.748377, BCE loss: 0.520628, SB loss: 0.713304
2023-10-30 19:35:04,777 Epoch: [348/484] Iter:[440/495], Time: 0.37, lr: [0.003171473840079468], Loss: 1.980866, Acc:0.799314, Semantic loss: 0.748044, BCE loss: 0.519949, SB loss: 0.712872
2023-10-30 19:35:08,428 Epoch: [348/484] Iter:[450/495], Time: 0.37, lr: [0.0031710470536266567], Loss: 1.979872, Acc:0.799141, Semantic loss: 0.748011, BCE loss: 0.519219, SB loss: 0.712643
2023-10-30 19:35:12,001 Epoch: [348/484] Iter:[460/495], Time: 0.37, lr: [0.003170620260791467], Loss: 1.978483, Acc:0.799737, Semantic loss: 0.747356, BCE loss: 0.518597, SB loss: 0.712531
2023-10-30 19:35:15,604 Epoch: [348/484] Iter:[470/495], Time: 0.37, lr: [0.0031701934615728485], Loss: 1.977158, Acc:0.799412, Semantic loss: 0.746717, BCE loss: 0.518002, SB loss: 0.712438
2023-10-30 19:35:19,243 Epoch: [348/484] Iter:[480/495], Time: 0.37, lr: [0.0031697666559697504], Loss: 1.975389, Acc:0.799679, Semantic loss: 0.745515, BCE loss: 0.517864, SB loss: 0.712011
2023-10-30 19:35:22,694 Epoch: [348/484] Iter:[490/495], Time: 0.37, lr: [0.0031693398439811235], Loss: 1.977129, Acc:0.799594, Semantic loss: 0.746837, BCE loss: 0.517706, SB loss: 0.712586
2023-10-30 19:35:24,077 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:35:24,318 Loss: 2.136, MeanIU:  0.6805, Best_mIoU:  0.7309
2023-10-30 19:35:24,318 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463]
2023-10-30 19:35:26,385 Epoch: [349/484] Iter:[0/495], Time: 2.03, lr: [0.003169126435591908], Loss: 2.111065, Acc:0.798879, Semantic loss: 0.859079, BCE loss: 0.489944, SB loss: 0.762043
2023-10-30 19:35:30,444 Epoch: [349/484] Iter:[10/495], Time: 0.55, lr: [0.003168699614023016], Loss: 1.903417, Acc:0.794914, Semantic loss: 0.675702, BCE loss: 0.542504, SB loss: 0.685211
2023-10-30 19:35:34,087 Epoch: [349/484] Iter:[20/495], Time: 0.46, lr: [0.003168272786065965], Loss: 1.897151, Acc:0.798636, Semantic loss: 0.693102, BCE loss: 0.517202, SB loss: 0.686847
2023-10-30 19:35:37,720 Epoch: [349/484] Iter:[30/495], Time: 0.43, lr: [0.0031678459517197055], Loss: 1.913210, Acc:0.794688, Semantic loss: 0.708017, BCE loss: 0.513773, SB loss: 0.691420
2023-10-30 19:35:41,304 Epoch: [349/484] Iter:[40/495], Time: 0.41, lr: [0.003167419110983184], Loss: 1.922508, Acc:0.803905, Semantic loss: 0.708842, BCE loss: 0.515753, SB loss: 0.697913
2023-10-30 19:35:45,039 Epoch: [349/484] Iter:[50/495], Time: 0.41, lr: [0.003166992263855348], Loss: 1.901079, Acc:0.800007, Semantic loss: 0.706196, BCE loss: 0.501633, SB loss: 0.693251
2023-10-30 19:35:48,741 Epoch: [349/484] Iter:[60/495], Time: 0.40, lr: [0.0031665654103351444], Loss: 1.906945, Acc:0.805597, Semantic loss: 0.699773, BCE loss: 0.507833, SB loss: 0.699338
2023-10-30 19:35:52,486 Epoch: [349/484] Iter:[70/495], Time: 0.40, lr: [0.0031661385504215206], Loss: 1.929447, Acc:0.803758, Semantic loss: 0.713158, BCE loss: 0.513630, SB loss: 0.702659
2023-10-30 19:35:56,042 Epoch: [349/484] Iter:[80/495], Time: 0.39, lr: [0.0031657116841134233], Loss: 1.922573, Acc:0.803989, Semantic loss: 0.707237, BCE loss: 0.513236, SB loss: 0.702100
2023-10-30 19:35:59,654 Epoch: [349/484] Iter:[90/495], Time: 0.39, lr: [0.003165284811409798], Loss: 1.934503, Acc:0.800045, Semantic loss: 0.715136, BCE loss: 0.513074, SB loss: 0.706293
2023-10-30 19:36:03,399 Epoch: [349/484] Iter:[100/495], Time: 0.39, lr: [0.003164857932309589], Loss: 1.933421, Acc:0.799219, Semantic loss: 0.716265, BCE loss: 0.513574, SB loss: 0.703583
2023-10-30 19:36:07,003 Epoch: [349/484] Iter:[110/495], Time: 0.38, lr: [0.0031644310468117447], Loss: 1.934961, Acc:0.801685, Semantic loss: 0.714881, BCE loss: 0.516890, SB loss: 0.703190
2023-10-30 19:36:10,611 Epoch: [349/484] Iter:[120/495], Time: 0.38, lr: [0.0031640041549152093], Loss: 1.930283, Acc:0.799861, Semantic loss: 0.712523, BCE loss: 0.515077, SB loss: 0.702683
2023-10-30 19:36:14,277 Epoch: [349/484] Iter:[130/495], Time: 0.38, lr: [0.003163577256618927], Loss: 1.929207, Acc:0.798664, Semantic loss: 0.713840, BCE loss: 0.512470, SB loss: 0.702898
2023-10-30 19:36:17,943 Epoch: [349/484] Iter:[140/495], Time: 0.38, lr: [0.003163150351921842], Loss: 1.934758, Acc:0.800055, Semantic loss: 0.713895, BCE loss: 0.517260, SB loss: 0.703603
2023-10-30 19:36:21,568 Epoch: [349/484] Iter:[150/495], Time: 0.38, lr: [0.0031627234408228995], Loss: 1.932244, Acc:0.801299, Semantic loss: 0.716504, BCE loss: 0.513542, SB loss: 0.702198
2023-10-30 19:36:25,228 Epoch: [349/484] Iter:[160/495], Time: 0.38, lr: [0.0031622965233210434], Loss: 1.936176, Acc:0.802694, Semantic loss: 0.719320, BCE loss: 0.514135, SB loss: 0.702721
2023-10-30 19:36:28,792 Epoch: [349/484] Iter:[170/495], Time: 0.38, lr: [0.0031618695994152157], Loss: 1.938553, Acc:0.801423, Semantic loss: 0.721072, BCE loss: 0.515149, SB loss: 0.702332
2023-10-30 19:36:32,409 Epoch: [349/484] Iter:[180/495], Time: 0.38, lr: [0.00316144266910436], Loss: 1.940641, Acc:0.802678, Semantic loss: 0.720279, BCE loss: 0.519077, SB loss: 0.701285
2023-10-30 19:36:36,053 Epoch: [349/484] Iter:[190/495], Time: 0.38, lr: [0.003161015732387421], Loss: 1.938867, Acc:0.801141, Semantic loss: 0.719707, BCE loss: 0.518340, SB loss: 0.700820
2023-10-30 19:36:39,728 Epoch: [349/484] Iter:[200/495], Time: 0.37, lr: [0.0031605887892633393], Loss: 1.941547, Acc:0.801817, Semantic loss: 0.721316, BCE loss: 0.519360, SB loss: 0.700871
2023-10-30 19:36:43,389 Epoch: [349/484] Iter:[210/495], Time: 0.37, lr: [0.0031601618397310576], Loss: 1.937515, Acc:0.802167, Semantic loss: 0.720126, BCE loss: 0.516466, SB loss: 0.700923
2023-10-30 19:36:47,092 Epoch: [349/484] Iter:[220/495], Time: 0.37, lr: [0.003159734883789517], Loss: 1.935167, Acc:0.801157, Semantic loss: 0.717828, BCE loss: 0.517393, SB loss: 0.699946
2023-10-30 19:36:50,792 Epoch: [349/484] Iter:[230/495], Time: 0.37, lr: [0.00315930792143766], Loss: 1.936099, Acc:0.802399, Semantic loss: 0.721304, BCE loss: 0.514974, SB loss: 0.699820
2023-10-30 19:36:54,425 Epoch: [349/484] Iter:[240/495], Time: 0.37, lr: [0.003158880952674428], Loss: 1.945911, Acc:0.803908, Semantic loss: 0.726746, BCE loss: 0.516994, SB loss: 0.702172
2023-10-30 19:36:58,045 Epoch: [349/484] Iter:[250/495], Time: 0.37, lr: [0.003158453977498761], Loss: 1.945264, Acc:0.804376, Semantic loss: 0.726422, BCE loss: 0.515858, SB loss: 0.702984
2023-10-30 19:37:01,662 Epoch: [349/484] Iter:[260/495], Time: 0.37, lr: [0.0031580269959095983], Loss: 1.944963, Acc:0.805624, Semantic loss: 0.725897, BCE loss: 0.516364, SB loss: 0.702702
2023-10-30 19:37:05,305 Epoch: [349/484] Iter:[270/495], Time: 0.37, lr: [0.0031576000079058825], Loss: 1.946417, Acc:0.805583, Semantic loss: 0.725485, BCE loss: 0.518864, SB loss: 0.702067
2023-10-30 19:37:08,890 Epoch: [349/484] Iter:[280/495], Time: 0.37, lr: [0.0031571730134865527], Loss: 1.945207, Acc:0.805173, Semantic loss: 0.724817, BCE loss: 0.518598, SB loss: 0.701792
2023-10-30 19:37:12,505 Epoch: [349/484] Iter:[290/495], Time: 0.37, lr: [0.0031567460126505475], Loss: 1.944452, Acc:0.804071, Semantic loss: 0.724781, BCE loss: 0.517312, SB loss: 0.702359
2023-10-30 19:37:16,259 Epoch: [349/484] Iter:[300/495], Time: 0.37, lr: [0.003156319005396806], Loss: 1.939337, Acc:0.803505, Semantic loss: 0.723269, BCE loss: 0.515260, SB loss: 0.700808
2023-10-30 19:37:19,861 Epoch: [349/484] Iter:[310/495], Time: 0.37, lr: [0.003155891991724269], Loss: 1.942123, Acc:0.803223, Semantic loss: 0.724058, BCE loss: 0.516358, SB loss: 0.701708
2023-10-30 19:37:23,532 Epoch: [349/484] Iter:[320/495], Time: 0.37, lr: [0.003155464971631873], Loss: 1.938253, Acc:0.803029, Semantic loss: 0.721893, BCE loss: 0.515806, SB loss: 0.700554
2023-10-30 19:37:27,204 Epoch: [349/484] Iter:[330/495], Time: 0.37, lr: [0.0031550379451185558], Loss: 1.939194, Acc:0.803945, Semantic loss: 0.722607, BCE loss: 0.515312, SB loss: 0.701275
2023-10-30 19:37:30,741 Epoch: [349/484] Iter:[340/495], Time: 0.37, lr: [0.003154610912183257], Loss: 1.942484, Acc:0.802968, Semantic loss: 0.724055, BCE loss: 0.515585, SB loss: 0.702844
2023-10-30 19:37:34,339 Epoch: [349/484] Iter:[350/495], Time: 0.37, lr: [0.0031541838728249135], Loss: 1.945869, Acc:0.802374, Semantic loss: 0.725876, BCE loss: 0.517405, SB loss: 0.702588
2023-10-30 19:37:37,993 Epoch: [349/484] Iter:[360/495], Time: 0.37, lr: [0.0031537568270424616], Loss: 1.947718, Acc:0.802217, Semantic loss: 0.726613, BCE loss: 0.518192, SB loss: 0.702913
2023-10-30 19:37:41,563 Epoch: [349/484] Iter:[370/495], Time: 0.37, lr: [0.0031533297748348376], Loss: 1.948955, Acc:0.802364, Semantic loss: 0.726929, BCE loss: 0.518915, SB loss: 0.703112
2023-10-30 19:37:45,184 Epoch: [349/484] Iter:[380/495], Time: 0.37, lr: [0.0031529027162009804], Loss: 1.949490, Acc:0.802339, Semantic loss: 0.726842, BCE loss: 0.519042, SB loss: 0.703606
2023-10-30 19:37:48,819 Epoch: [349/484] Iter:[390/495], Time: 0.37, lr: [0.003152475651139825], Loss: 1.955906, Acc:0.803124, Semantic loss: 0.731368, BCE loss: 0.519724, SB loss: 0.704814
2023-10-30 19:37:52,383 Epoch: [349/484] Iter:[400/495], Time: 0.37, lr: [0.0031520485796503062], Loss: 1.952525, Acc:0.803695, Semantic loss: 0.729345, BCE loss: 0.519305, SB loss: 0.703875
2023-10-30 19:37:56,161 Epoch: [349/484] Iter:[410/495], Time: 0.37, lr: [0.0031516215017313594], Loss: 1.953280, Acc:0.803064, Semantic loss: 0.730158, BCE loss: 0.519217, SB loss: 0.703905
2023-10-30 19:37:59,791 Epoch: [349/484] Iter:[420/495], Time: 0.37, lr: [0.003151194417381921], Loss: 1.957890, Acc:0.803850, Semantic loss: 0.732504, BCE loss: 0.520121, SB loss: 0.705265
2023-10-30 19:38:03,359 Epoch: [349/484] Iter:[430/495], Time: 0.37, lr: [0.003150767326600926], Loss: 1.956143, Acc:0.803230, Semantic loss: 0.731302, BCE loss: 0.520004, SB loss: 0.704837
2023-10-30 19:38:07,047 Epoch: [349/484] Iter:[440/495], Time: 0.37, lr: [0.003150340229387308], Loss: 1.959275, Acc:0.802665, Semantic loss: 0.734237, BCE loss: 0.519102, SB loss: 0.705936
2023-10-30 19:38:10,772 Epoch: [349/484] Iter:[450/495], Time: 0.37, lr: [0.00314991312574], Loss: 1.958089, Acc:0.802535, Semantic loss: 0.733269, BCE loss: 0.519112, SB loss: 0.705708
2023-10-30 19:38:14,443 Epoch: [349/484] Iter:[460/495], Time: 0.37, lr: [0.0031494860156579376], Loss: 1.956010, Acc:0.803289, Semantic loss: 0.732096, BCE loss: 0.519106, SB loss: 0.704808
2023-10-30 19:38:18,108 Epoch: [349/484] Iter:[470/495], Time: 0.37, lr: [0.003149058899140054], Loss: 1.955643, Acc:0.802885, Semantic loss: 0.731593, BCE loss: 0.518930, SB loss: 0.705120
2023-10-30 19:38:21,748 Epoch: [349/484] Iter:[480/495], Time: 0.37, lr: [0.0031486317761852817], Loss: 1.953385, Acc:0.802610, Semantic loss: 0.730872, BCE loss: 0.517682, SB loss: 0.704831
2023-10-30 19:38:25,207 Epoch: [349/484] Iter:[490/495], Time: 0.37, lr: [0.003148204646792552], Loss: 1.953094, Acc:0.801399, Semantic loss: 0.730901, BCE loss: 0.517516, SB loss: 0.704676
2023-10-30 19:38:26,587 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:38:26,824 Loss: 2.136, MeanIU:  0.6805, Best_mIoU:  0.7309
2023-10-30 19:38:26,824 [0.95949458 0.76737464 0.89985373 0.3497135  0.56077646 0.53868015
 0.60252122 0.74582047 0.90937761 0.59469319 0.93946424 0.75862607
 0.57550364 0.89274953 0.60730479 0.68224026 0.3997466  0.43875943
 0.70771463]
2023-10-30 19:38:29,081 Epoch: [350/484] Iter:[0/495], Time: 2.22, lr: [0.0031479910796816213], Loss: 1.772771, Acc:0.843572, Semantic loss: 0.617616, BCE loss: 0.507528, SB loss: 0.647628
2023-10-30 19:38:33,059 Epoch: [350/484] Iter:[10/495], Time: 0.56, lr: [0.0031475639406299584], Loss: 1.875766, Acc:0.782420, Semantic loss: 0.676231, BCE loss: 0.506865, SB loss: 0.692671
2023-10-30 19:38:36,679 Epoch: [350/484] Iter:[20/495], Time: 0.47, lr: [0.0031471367951376693], Loss: 2.006926, Acc:0.802832, Semantic loss: 0.734364, BCE loss: 0.546029, SB loss: 0.726533
2023-10-30 19:38:40,212 Epoch: [350/484] Iter:[30/495], Time: 0.43, lr: [0.0031467096432036866], Loss: 1.927363, Acc:0.790909, Semantic loss: 0.714029, BCE loss: 0.502917, SB loss: 0.710417
2023-10-30 19:38:43,869 Epoch: [350/484] Iter:[40/495], Time: 0.41, lr: [0.0031462824848269406], Loss: 1.922124, Acc:0.794367, Semantic loss: 0.711863, BCE loss: 0.503250, SB loss: 0.707012
2023-10-30 19:38:47,445 Epoch: [350/484] Iter:[50/495], Time: 0.40, lr: [0.0031458553200063633], Loss: 1.942161, Acc:0.808778, Semantic loss: 0.721564, BCE loss: 0.513946, SB loss: 0.706652
2023-10-30 19:38:51,168 Epoch: [350/484] Iter:[60/495], Time: 0.40, lr: [0.0031454281487408855], Loss: 1.939850, Acc:0.806476, Semantic loss: 0.718729, BCE loss: 0.517409, SB loss: 0.703712
2023-10-30 19:38:54,969 Epoch: [350/484] Iter:[70/495], Time: 0.40, lr: [0.0031450009710294368], Loss: 1.944590, Acc:0.813296, Semantic loss: 0.718042, BCE loss: 0.522918, SB loss: 0.703631
2023-10-30 19:38:58,594 Epoch: [350/484] Iter:[80/495], Time: 0.39, lr: [0.0031445737868709455], Loss: 1.947389, Acc:0.818843, Semantic loss: 0.720767, BCE loss: 0.524074, SB loss: 0.702548
2023-10-30 19:39:02,311 Epoch: [350/484] Iter:[90/495], Time: 0.39, lr: [0.0031441465962643443], Loss: 1.962045, Acc:0.820395, Semantic loss: 0.727659, BCE loss: 0.528202, SB loss: 0.706184
2023-10-30 19:39:05,940 Epoch: [350/484] Iter:[100/495], Time: 0.39, lr: [0.0031437193992085613], Loss: 1.958856, Acc:0.821027, Semantic loss: 0.727457, BCE loss: 0.527237, SB loss: 0.704163
2023-10-30 19:39:09,574 Epoch: [350/484] Iter:[110/495], Time: 0.38, lr: [0.003143292195702524], Loss: 1.962346, Acc:0.820126, Semantic loss: 0.731921, BCE loss: 0.525589, SB loss: 0.704836
2023-10-30 19:39:13,205 Epoch: [350/484] Iter:[120/495], Time: 0.38, lr: [0.0031428649857451613], Loss: 1.962539, Acc:0.816639, Semantic loss: 0.734693, BCE loss: 0.521428, SB loss: 0.706419
2023-10-30 19:39:16,809 Epoch: [350/484] Iter:[130/495], Time: 0.38, lr: [0.0031424377693354028], Loss: 1.969997, Acc:0.815382, Semantic loss: 0.738652, BCE loss: 0.521809, SB loss: 0.709536
2023-10-30 19:39:20,490 Epoch: [350/484] Iter:[140/495], Time: 0.38, lr: [0.0031420105464721754], Loss: 1.973211, Acc:0.814839, Semantic loss: 0.738623, BCE loss: 0.524051, SB loss: 0.710536
2023-10-30 19:39:24,231 Epoch: [350/484] Iter:[150/495], Time: 0.38, lr: [0.0031415833171544055], Loss: 1.972642, Acc:0.815483, Semantic loss: 0.737804, BCE loss: 0.525040, SB loss: 0.709799
2023-10-30 19:39:27,854 Epoch: [350/484] Iter:[160/495], Time: 0.38, lr: [0.0031411560813810226], Loss: 1.965929, Acc:0.815870, Semantic loss: 0.734557, BCE loss: 0.523543, SB loss: 0.707830
2023-10-30 19:39:31,486 Epoch: [350/484] Iter:[170/495], Time: 0.38, lr: [0.0031407288391509525], Loss: 1.968895, Acc:0.814199, Semantic loss: 0.735456, BCE loss: 0.524843, SB loss: 0.708597
2023-10-30 19:39:35,147 Epoch: [350/484] Iter:[180/495], Time: 0.38, lr: [0.003140301590463121], Loss: 1.966875, Acc:0.814274, Semantic loss: 0.735155, BCE loss: 0.523810, SB loss: 0.707909
2023-10-30 19:39:38,796 Epoch: [350/484] Iter:[190/495], Time: 0.38, lr: [0.0031398743353164543], Loss: 1.967682, Acc:0.814127, Semantic loss: 0.738890, BCE loss: 0.521601, SB loss: 0.707191
2023-10-30 19:39:42,456 Epoch: [350/484] Iter:[200/495], Time: 0.38, lr: [0.0031394470737098794], Loss: 1.966507, Acc:0.814605, Semantic loss: 0.736613, BCE loss: 0.522257, SB loss: 0.707638
2023-10-30 19:39:46,211 Epoch: [350/484] Iter:[210/495], Time: 0.38, lr: [0.003139019805642321], Loss: 1.961563, Acc:0.813324, Semantic loss: 0.734215, BCE loss: 0.520065, SB loss: 0.707283
2023-10-30 19:39:49,855 Epoch: [350/484] Iter:[220/495], Time: 0.38, lr: [0.0031385925311127045], Loss: 1.963911, Acc:0.813084, Semantic loss: 0.735499, BCE loss: 0.520848, SB loss: 0.707564
2023-10-30 19:39:53,614 Epoch: [350/484] Iter:[230/495], Time: 0.38, lr: [0.0031381652501199526], Loss: 1.962991, Acc:0.812697, Semantic loss: 0.734403, BCE loss: 0.520622, SB loss: 0.707966
2023-10-30 19:39:57,225 Epoch: [350/484] Iter:[240/495], Time: 0.37, lr: [0.003137737962662993], Loss: 1.964185, Acc:0.812944, Semantic loss: 0.733329, BCE loss: 0.522424, SB loss: 0.708432
2023-10-30 19:40:00,850 Epoch: [350/484] Iter:[250/495], Time: 0.37, lr: [0.003137310668740749], Loss: 1.960157, Acc:0.812626, Semantic loss: 0.731469, BCE loss: 0.520651, SB loss: 0.708036
2023-10-30 19:40:04,586 Epoch: [350/484] Iter:[260/495], Time: 0.37, lr: [0.0031368833683521427], Loss: 1.955600, Acc:0.812038, Semantic loss: 0.730053, BCE loss: 0.518652, SB loss: 0.706895
2023-10-30 19:40:08,208 Epoch: [350/484] Iter:[270/495], Time: 0.37, lr: [0.0031364560614960974], Loss: 1.952850, Acc:0.813042, Semantic loss: 0.728520, BCE loss: 0.518097, SB loss: 0.706233
2023-10-30 19:40:11,869 Epoch: [350/484] Iter:[280/495], Time: 0.37, lr: [0.003136028748171539], Loss: 1.954538, Acc:0.812583, Semantic loss: 0.728405, BCE loss: 0.520084, SB loss: 0.706049
2023-10-30 19:40:15,526 Epoch: [350/484] Iter:[290/495], Time: 0.37, lr: [0.0031356014283773883], Loss: 1.958351, Acc:0.811762, Semantic loss: 0.730881, BCE loss: 0.521250, SB loss: 0.706220
2023-10-30 19:40:19,149 Epoch: [350/484] Iter:[300/495], Time: 0.37, lr: [0.0031351741021125672], Loss: 1.964123, Acc:0.812428, Semantic loss: 0.733441, BCE loss: 0.523394, SB loss: 0.707288
2023-10-30 19:40:22,723 Epoch: [350/484] Iter:[310/495], Time: 0.37, lr: [0.0031347467693759977], Loss: 1.960677, Acc:0.811425, Semantic loss: 0.731505, BCE loss: 0.521928, SB loss: 0.707245
2023-10-30 19:40:26,353 Epoch: [350/484] Iter:[320/495], Time: 0.37, lr: [0.0031343194301666033], Loss: 1.960790, Acc:0.810892, Semantic loss: 0.731301, BCE loss: 0.522657, SB loss: 0.706832
2023-10-30 19:40:29,989 Epoch: [350/484] Iter:[330/495], Time: 0.37, lr: [0.0031338920844833046], Loss: 1.959429, Acc:0.811626, Semantic loss: 0.730123, BCE loss: 0.522590, SB loss: 0.706716
2023-10-30 19:40:33,608 Epoch: [350/484] Iter:[340/495], Time: 0.37, lr: [0.0031334647323250217], Loss: 1.960088, Acc:0.812944, Semantic loss: 0.730217, BCE loss: 0.523490, SB loss: 0.706381
2023-10-30 19:40:37,357 Epoch: [350/484] Iter:[350/495], Time: 0.37, lr: [0.0031330373736906747], Loss: 1.958122, Acc:0.812569, Semantic loss: 0.729524, BCE loss: 0.522672, SB loss: 0.705927
2023-10-30 19:40:41,169 Epoch: [350/484] Iter:[360/495], Time: 0.37, lr: [0.0031326100085791865], Loss: 1.959458, Acc:0.812683, Semantic loss: 0.729606, BCE loss: 0.523831, SB loss: 0.706021
2023-10-30 19:40:44,836 Epoch: [350/484] Iter:[370/495], Time: 0.37, lr: [0.0031321826369894753], Loss: 1.957743, Acc:0.812411, Semantic loss: 0.728990, BCE loss: 0.522946, SB loss: 0.705806
2023-10-30 19:40:48,439 Epoch: [350/484] Iter:[380/495], Time: 0.37, lr: [0.0031317552589204605], Loss: 1.952866, Acc:0.812719, Semantic loss: 0.726323, BCE loss: 0.521894, SB loss: 0.704650
2023-10-30 19:40:52,176 Epoch: [350/484] Iter:[390/495], Time: 0.37, lr: [0.0031313278743710614], Loss: 1.956968, Acc:0.811953, Semantic loss: 0.731776, BCE loss: 0.520225, SB loss: 0.704966
2023-10-30 19:40:55,803 Epoch: [350/484] Iter:[400/495], Time: 0.37, lr: [0.003130900483340199], Loss: 1.951856, Acc:0.812097, Semantic loss: 0.730652, BCE loss: 0.517378, SB loss: 0.703826
2023-10-30 19:40:59,411 Epoch: [350/484] Iter:[410/495], Time: 0.37, lr: [0.003130473085826789], Loss: 1.950559, Acc:0.812340, Semantic loss: 0.729841, BCE loss: 0.516927, SB loss: 0.703791
2023-10-30 19:41:03,077 Epoch: [350/484] Iter:[420/495], Time: 0.37, lr: [0.0031300456818297525], Loss: 1.949611, Acc:0.811420, Semantic loss: 0.731320, BCE loss: 0.514736, SB loss: 0.703555
2023-10-30 19:41:06,691 Epoch: [350/484] Iter:[430/495], Time: 0.37, lr: [0.003129618271348004], Loss: 1.949397, Acc:0.812402, Semantic loss: 0.731529, BCE loss: 0.514533, SB loss: 0.703335
2023-10-30 19:41:10,351 Epoch: [350/484] Iter:[440/495], Time: 0.37, lr: [0.0031291908543804644], Loss: 1.948885, Acc:0.812247, Semantic loss: 0.731837, BCE loss: 0.513933, SB loss: 0.703115
2023-10-30 19:41:14,070 Epoch: [350/484] Iter:[450/495], Time: 0.37, lr: [0.0031287634309260493], Loss: 1.946881, Acc:0.812868, Semantic loss: 0.730456, BCE loss: 0.513625, SB loss: 0.702799
2023-10-30 19:41:17,878 Epoch: [350/484] Iter:[460/495], Time: 0.37, lr: [0.003128336000983676], Loss: 1.946550, Acc:0.813009, Semantic loss: 0.730305, BCE loss: 0.513374, SB loss: 0.702871
2023-10-30 19:41:21,520 Epoch: [350/484] Iter:[470/495], Time: 0.37, lr: [0.00312790856455226], Loss: 1.948249, Acc:0.812203, Semantic loss: 0.730555, BCE loss: 0.514432, SB loss: 0.703262
2023-10-30 19:41:25,006 Epoch: [350/484] Iter:[480/495], Time: 0.37, lr: [0.0031274811216307186], Loss: 1.947329, Acc:0.811218, Semantic loss: 0.730039, BCE loss: 0.514474, SB loss: 0.702815
2023-10-30 19:41:28,411 Epoch: [350/484] Iter:[490/495], Time: 0.37, lr: [0.003127053672217968], Loss: 1.945831, Acc:0.810166, Semantic loss: 0.729794, BCE loss: 0.513276, SB loss: 0.702760
2023-10-30 19:44:25,349 0 [0.94545722 0.67652961 0.83124052 0.1838163  0.29666432 0.43136829
 0.48626827 0.6141906  0.88309803 0.40731459 0.86389036 0.584003
 0.04893049 0.80511648 0.00335605 0.16587877 0.10183629 0.07433324
 0.61811727] 0.4748110372015734
2023-10-30 19:44:25,349 1 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886] 0.7201474739227472
2023-10-30 19:44:25,353 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:44:25,591 Loss: 2.049, MeanIU:  0.7201, Best_mIoU:  0.7309
2023-10-30 19:44:25,591 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886]
2023-10-30 19:44:27,624 Epoch: [351/484] Iter:[0/495], Time: 2.00, lr: [0.00312683994507705], Loss: 1.740766, Acc:0.691115, Semantic loss: 0.678437, BCE loss: 0.347874, SB loss: 0.714455
2023-10-30 19:44:31,483 Epoch: [351/484] Iter:[10/495], Time: 0.53, lr: [0.0031264124859254495], Loss: 1.863543, Acc:0.803990, Semantic loss: 0.713018, BCE loss: 0.464143, SB loss: 0.686382
2023-10-30 19:44:35,090 Epoch: [351/484] Iter:[20/495], Time: 0.45, lr: [0.0031259850202799283], Loss: 1.846268, Acc:0.799430, Semantic loss: 0.706696, BCE loss: 0.466274, SB loss: 0.673298
2023-10-30 19:44:38,685 Epoch: [351/484] Iter:[30/495], Time: 0.42, lr: [0.0031255575481394004], Loss: 1.890198, Acc:0.804446, Semantic loss: 0.719458, BCE loss: 0.482485, SB loss: 0.688255
2023-10-30 19:44:42,199 Epoch: [351/484] Iter:[40/495], Time: 0.40, lr: [0.0031251300695027797], Loss: 1.903166, Acc:0.808078, Semantic loss: 0.732633, BCE loss: 0.487114, SB loss: 0.683418
2023-10-30 19:44:45,653 Epoch: [351/484] Iter:[50/495], Time: 0.39, lr: [0.0031247025843689786], Loss: 1.934155, Acc:0.809830, Semantic loss: 0.737261, BCE loss: 0.501666, SB loss: 0.695228
2023-10-30 19:44:49,239 Epoch: [351/484] Iter:[60/495], Time: 0.39, lr: [0.0031242750927369133], Loss: 1.931088, Acc:0.813268, Semantic loss: 0.731997, BCE loss: 0.504123, SB loss: 0.694967
2023-10-30 19:44:52,810 Epoch: [351/484] Iter:[70/495], Time: 0.38, lr: [0.0031238475946054963], Loss: 1.935234, Acc:0.814506, Semantic loss: 0.727229, BCE loss: 0.513531, SB loss: 0.694474
2023-10-30 19:44:56,387 Epoch: [351/484] Iter:[80/495], Time: 0.38, lr: [0.0031234200899736397], Loss: 1.948219, Acc:0.816308, Semantic loss: 0.734249, BCE loss: 0.514445, SB loss: 0.699525
2023-10-30 19:44:59,964 Epoch: [351/484] Iter:[90/495], Time: 0.38, lr: [0.003122992578840255], Loss: 1.949626, Acc:0.817295, Semantic loss: 0.733722, BCE loss: 0.517220, SB loss: 0.698684
2023-10-30 19:45:03,631 Epoch: [351/484] Iter:[100/495], Time: 0.38, lr: [0.0031225650612042577], Loss: 1.937951, Acc:0.815652, Semantic loss: 0.729128, BCE loss: 0.510473, SB loss: 0.698350
2023-10-30 19:45:07,194 Epoch: [351/484] Iter:[110/495], Time: 0.37, lr: [0.003122137537064558], Loss: 1.939544, Acc:0.816074, Semantic loss: 0.726635, BCE loss: 0.512966, SB loss: 0.699942
2023-10-30 19:45:10,714 Epoch: [351/484] Iter:[120/495], Time: 0.37, lr: [0.0031217100064200665], Loss: 1.944325, Acc:0.812838, Semantic loss: 0.732276, BCE loss: 0.512539, SB loss: 0.699511
2023-10-30 19:45:14,277 Epoch: [351/484] Iter:[130/495], Time: 0.37, lr: [0.0031212824692696947], Loss: 1.942967, Acc:0.812280, Semantic loss: 0.732569, BCE loss: 0.510026, SB loss: 0.700372
2023-10-30 19:45:17,900 Epoch: [351/484] Iter:[140/495], Time: 0.37, lr: [0.0031208549256123543], Loss: 1.940600, Acc:0.811393, Semantic loss: 0.734974, BCE loss: 0.507134, SB loss: 0.698493
2023-10-30 19:45:21,531 Epoch: [351/484] Iter:[150/495], Time: 0.37, lr: [0.0031204273754469555], Loss: 1.943150, Acc:0.811349, Semantic loss: 0.733617, BCE loss: 0.509090, SB loss: 0.700443
2023-10-30 19:45:25,132 Epoch: [351/484] Iter:[160/495], Time: 0.37, lr: [0.0031199998187724075], Loss: 1.943865, Acc:0.810346, Semantic loss: 0.733542, BCE loss: 0.510156, SB loss: 0.700166
2023-10-30 19:45:28,685 Epoch: [351/484] Iter:[170/495], Time: 0.37, lr: [0.0031195722555876207], Loss: 1.943768, Acc:0.808903, Semantic loss: 0.731990, BCE loss: 0.509237, SB loss: 0.702541
2023-10-30 19:45:32,248 Epoch: [351/484] Iter:[180/495], Time: 0.37, lr: [0.0031191446858915045], Loss: 1.942336, Acc:0.807931, Semantic loss: 0.734433, BCE loss: 0.506807, SB loss: 0.701095
2023-10-30 19:45:35,809 Epoch: [351/484] Iter:[190/495], Time: 0.37, lr: [0.0031187171096829693], Loss: 1.940726, Acc:0.809473, Semantic loss: 0.733495, BCE loss: 0.506683, SB loss: 0.700547
2023-10-30 19:45:39,453 Epoch: [351/484] Iter:[200/495], Time: 0.37, lr: [0.0031182895269609213], Loss: 1.940202, Acc:0.808934, Semantic loss: 0.731413, BCE loss: 0.507315, SB loss: 0.701475
2023-10-30 19:45:42,976 Epoch: [351/484] Iter:[210/495], Time: 0.37, lr: [0.0031178619377242693], Loss: 1.946032, Acc:0.807902, Semantic loss: 0.734727, BCE loss: 0.509244, SB loss: 0.702061
2023-10-30 19:45:46,453 Epoch: [351/484] Iter:[220/495], Time: 0.37, lr: [0.0031174343419719244], Loss: 1.943709, Acc:0.806123, Semantic loss: 0.733960, BCE loss: 0.507142, SB loss: 0.702608
2023-10-30 19:45:50,031 Epoch: [351/484] Iter:[230/495], Time: 0.37, lr: [0.0031170067397027906], Loss: 1.942906, Acc:0.805317, Semantic loss: 0.733904, BCE loss: 0.507103, SB loss: 0.701900
2023-10-30 19:45:53,691 Epoch: [351/484] Iter:[240/495], Time: 0.37, lr: [0.003116579130915777], Loss: 1.943466, Acc:0.805822, Semantic loss: 0.732161, BCE loss: 0.510267, SB loss: 0.701037
2023-10-30 19:45:57,302 Epoch: [351/484] Iter:[250/495], Time: 0.37, lr: [0.003116151515609789], Loss: 1.951192, Acc:0.806843, Semantic loss: 0.734773, BCE loss: 0.513827, SB loss: 0.702592
2023-10-30 19:46:00,939 Epoch: [351/484] Iter:[260/495], Time: 0.37, lr: [0.003115723893783736], Loss: 1.954533, Acc:0.806255, Semantic loss: 0.736123, BCE loss: 0.514518, SB loss: 0.703892
2023-10-30 19:46:04,671 Epoch: [351/484] Iter:[270/495], Time: 0.37, lr: [0.0031152962654365226], Loss: 1.956236, Acc:0.807079, Semantic loss: 0.736830, BCE loss: 0.514610, SB loss: 0.704796
2023-10-30 19:46:08,284 Epoch: [351/484] Iter:[280/495], Time: 0.37, lr: [0.003114868630567054], Loss: 1.961671, Acc:0.808346, Semantic loss: 0.739343, BCE loss: 0.518468, SB loss: 0.703860
2023-10-30 19:46:11,919 Epoch: [351/484] Iter:[290/495], Time: 0.37, lr: [0.0031144409891742364], Loss: 1.962677, Acc:0.808299, Semantic loss: 0.740673, BCE loss: 0.517940, SB loss: 0.704065
2023-10-30 19:46:15,736 Epoch: [351/484] Iter:[300/495], Time: 0.37, lr: [0.003114013341256976], Loss: 1.958599, Acc:0.807826, Semantic loss: 0.738769, BCE loss: 0.517570, SB loss: 0.702260
2023-10-30 19:46:19,384 Epoch: [351/484] Iter:[310/495], Time: 0.37, lr: [0.0031135856868141766], Loss: 1.957273, Acc:0.808852, Semantic loss: 0.736961, BCE loss: 0.518525, SB loss: 0.701787
2023-10-30 19:46:22,930 Epoch: [351/484] Iter:[320/495], Time: 0.37, lr: [0.003113158025844743], Loss: 1.963694, Acc:0.810369, Semantic loss: 0.739067, BCE loss: 0.522076, SB loss: 0.702552
2023-10-30 19:46:26,545 Epoch: [351/484] Iter:[330/495], Time: 0.37, lr: [0.0031127303583475784], Loss: 1.959500, Acc:0.809428, Semantic loss: 0.736838, BCE loss: 0.521026, SB loss: 0.701636
2023-10-30 19:46:30,073 Epoch: [351/484] Iter:[340/495], Time: 0.36, lr: [0.0031123026843215885], Loss: 1.957154, Acc:0.809367, Semantic loss: 0.736213, BCE loss: 0.519557, SB loss: 0.701383
2023-10-30 19:46:33,572 Epoch: [351/484] Iter:[350/495], Time: 0.36, lr: [0.003111875003765676], Loss: 1.958815, Acc:0.808624, Semantic loss: 0.736960, BCE loss: 0.519695, SB loss: 0.702160
2023-10-30 19:46:37,164 Epoch: [351/484] Iter:[360/495], Time: 0.36, lr: [0.003111447316678744], Loss: 1.954550, Acc:0.808421, Semantic loss: 0.734681, BCE loss: 0.518563, SB loss: 0.701306
2023-10-30 19:46:40,917 Epoch: [351/484] Iter:[370/495], Time: 0.36, lr: [0.0031110196230596937], Loss: 1.953662, Acc:0.808250, Semantic loss: 0.733851, BCE loss: 0.518787, SB loss: 0.701025
2023-10-30 19:46:44,558 Epoch: [351/484] Iter:[380/495], Time: 0.36, lr: [0.00311059192290743], Loss: 1.957751, Acc:0.808633, Semantic loss: 0.735441, BCE loss: 0.520828, SB loss: 0.701482
2023-10-30 19:46:48,283 Epoch: [351/484] Iter:[390/495], Time: 0.36, lr: [0.0031101642162208536], Loss: 1.961520, Acc:0.808333, Semantic loss: 0.737983, BCE loss: 0.521139, SB loss: 0.702397
2023-10-30 19:46:51,954 Epoch: [351/484] Iter:[400/495], Time: 0.36, lr: [0.003109736502998867], Loss: 1.957377, Acc:0.808119, Semantic loss: 0.736065, BCE loss: 0.519763, SB loss: 0.701549
2023-10-30 19:46:55,736 Epoch: [351/484] Iter:[410/495], Time: 0.37, lr: [0.00310930878324037], Loss: 1.961369, Acc:0.808406, Semantic loss: 0.738725, BCE loss: 0.521000, SB loss: 0.701644
2023-10-30 19:46:59,330 Epoch: [351/484] Iter:[420/495], Time: 0.37, lr: [0.003108881056944265], Loss: 1.963035, Acc:0.808789, Semantic loss: 0.738985, BCE loss: 0.522279, SB loss: 0.701771
2023-10-30 19:47:02,981 Epoch: [351/484] Iter:[430/495], Time: 0.37, lr: [0.0031084533241094526], Loss: 1.961092, Acc:0.808815, Semantic loss: 0.738188, BCE loss: 0.520903, SB loss: 0.702001
2023-10-30 19:47:06,729 Epoch: [351/484] Iter:[440/495], Time: 0.37, lr: [0.0031080255847348325], Loss: 1.958818, Acc:0.808478, Semantic loss: 0.736562, BCE loss: 0.520183, SB loss: 0.702073
2023-10-30 19:47:10,488 Epoch: [351/484] Iter:[450/495], Time: 0.37, lr: [0.0031075978388193045], Loss: 1.961269, Acc:0.808240, Semantic loss: 0.737593, BCE loss: 0.519997, SB loss: 0.703678
2023-10-30 19:47:14,123 Epoch: [351/484] Iter:[460/495], Time: 0.37, lr: [0.003107170086361769], Loss: 1.960208, Acc:0.808383, Semantic loss: 0.737073, BCE loss: 0.519873, SB loss: 0.703262
2023-10-30 19:47:17,654 Epoch: [351/484] Iter:[470/495], Time: 0.37, lr: [0.003106742327361125], Loss: 1.958227, Acc:0.807690, Semantic loss: 0.736183, BCE loss: 0.519184, SB loss: 0.702859
2023-10-30 19:47:21,270 Epoch: [351/484] Iter:[480/495], Time: 0.37, lr: [0.0031063145618162712], Loss: 1.955873, Acc:0.807529, Semantic loss: 0.735059, BCE loss: 0.518351, SB loss: 0.702463
2023-10-30 19:47:24,750 Epoch: [351/484] Iter:[490/495], Time: 0.36, lr: [0.0031058867897261052], Loss: 1.958440, Acc:0.807802, Semantic loss: 0.736713, BCE loss: 0.519045, SB loss: 0.702681
2023-10-30 19:47:26,134 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:47:26,376 Loss: 2.049, MeanIU:  0.7201, Best_mIoU:  0.7309
2023-10-30 19:47:26,376 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886]
2023-10-30 19:47:28,591 Epoch: [352/484] Iter:[0/495], Time: 2.18, lr: [0.0031056729012261864], Loss: 2.071206, Acc:0.923112, Semantic loss: 0.809754, BCE loss: 0.565735, SB loss: 0.695718
2023-10-30 19:47:32,505 Epoch: [352/484] Iter:[10/495], Time: 0.55, lr: [0.0031052451193159885], Loss: 2.044225, Acc:0.829365, Semantic loss: 0.750627, BCE loss: 0.571109, SB loss: 0.722489
2023-10-30 19:47:36,289 Epoch: [352/484] Iter:[20/495], Time: 0.47, lr: [0.003104817330857724], Loss: 1.990824, Acc:0.815057, Semantic loss: 0.727563, BCE loss: 0.537206, SB loss: 0.726056
2023-10-30 19:47:39,942 Epoch: [352/484] Iter:[30/495], Time: 0.44, lr: [0.0031043895358502894], Loss: 1.980093, Acc:0.815812, Semantic loss: 0.726730, BCE loss: 0.542042, SB loss: 0.711320
2023-10-30 19:47:43,524 Epoch: [352/484] Iter:[40/495], Time: 0.42, lr: [0.003103961734292583], Loss: 1.967189, Acc:0.811915, Semantic loss: 0.720642, BCE loss: 0.542869, SB loss: 0.703678
2023-10-30 19:47:47,128 Epoch: [352/484] Iter:[50/495], Time: 0.41, lr: [0.003103533926183501], Loss: 1.955779, Acc:0.806436, Semantic loss: 0.720015, BCE loss: 0.533359, SB loss: 0.702406
2023-10-30 19:47:50,797 Epoch: [352/484] Iter:[60/495], Time: 0.40, lr: [0.00310310611152194], Loss: 1.929666, Acc:0.810525, Semantic loss: 0.713364, BCE loss: 0.519053, SB loss: 0.697249
2023-10-30 19:47:54,537 Epoch: [352/484] Iter:[70/495], Time: 0.40, lr: [0.003102678290306794], Loss: 1.932438, Acc:0.809642, Semantic loss: 0.714726, BCE loss: 0.518740, SB loss: 0.698972
2023-10-30 19:47:58,145 Epoch: [352/484] Iter:[80/495], Time: 0.39, lr: [0.003102250462536961], Loss: 1.947203, Acc:0.812611, Semantic loss: 0.725194, BCE loss: 0.519934, SB loss: 0.702075
2023-10-30 19:48:01,725 Epoch: [352/484] Iter:[90/495], Time: 0.39, lr: [0.0031018226282113347], Loss: 1.951040, Acc:0.811483, Semantic loss: 0.726325, BCE loss: 0.522817, SB loss: 0.701898
2023-10-30 19:48:05,337 Epoch: [352/484] Iter:[100/495], Time: 0.39, lr: [0.0031013947873288106], Loss: 1.947718, Acc:0.809019, Semantic loss: 0.733355, BCE loss: 0.514158, SB loss: 0.700205
2023-10-30 19:48:09,049 Epoch: [352/484] Iter:[110/495], Time: 0.38, lr: [0.003100966939888281], Loss: 1.944834, Acc:0.810770, Semantic loss: 0.731264, BCE loss: 0.516138, SB loss: 0.697432
2023-10-30 19:48:12,734 Epoch: [352/484] Iter:[120/495], Time: 0.38, lr: [0.0031005390858886432], Loss: 1.951777, Acc:0.813485, Semantic loss: 0.735408, BCE loss: 0.515161, SB loss: 0.701207
2023-10-30 19:48:16,335 Epoch: [352/484] Iter:[130/495], Time: 0.38, lr: [0.00310011122532879], Loss: 1.944594, Acc:0.812075, Semantic loss: 0.732073, BCE loss: 0.510730, SB loss: 0.701791
2023-10-30 19:48:20,033 Epoch: [352/484] Iter:[140/495], Time: 0.38, lr: [0.003099683358207614], Loss: 1.940843, Acc:0.810890, Semantic loss: 0.725490, BCE loss: 0.514256, SB loss: 0.701097
2023-10-30 19:48:23,746 Epoch: [352/484] Iter:[150/495], Time: 0.38, lr: [0.0030992554845240073], Loss: 1.940437, Acc:0.810734, Semantic loss: 0.724254, BCE loss: 0.515037, SB loss: 0.701146
2023-10-30 19:48:27,422 Epoch: [352/484] Iter:[160/495], Time: 0.38, lr: [0.003098827604276865], Loss: 1.935806, Acc:0.808870, Semantic loss: 0.722567, BCE loss: 0.512166, SB loss: 0.701073
2023-10-30 19:48:31,192 Epoch: [352/484] Iter:[170/495], Time: 0.38, lr: [0.003098399717465078], Loss: 1.935733, Acc:0.810892, Semantic loss: 0.722222, BCE loss: 0.513725, SB loss: 0.699787
2023-10-30 19:48:34,999 Epoch: [352/484] Iter:[180/495], Time: 0.38, lr: [0.003097971824087539], Loss: 1.932648, Acc:0.810209, Semantic loss: 0.722423, BCE loss: 0.511582, SB loss: 0.698643
2023-10-30 19:48:38,692 Epoch: [352/484] Iter:[190/495], Time: 0.38, lr: [0.003097543924143137], Loss: 1.936420, Acc:0.810173, Semantic loss: 0.724245, BCE loss: 0.511273, SB loss: 0.700902
2023-10-30 19:48:42,422 Epoch: [352/484] Iter:[200/495], Time: 0.38, lr: [0.0030971160176307667], Loss: 1.933035, Acc:0.809596, Semantic loss: 0.723773, BCE loss: 0.508843, SB loss: 0.700418
2023-10-30 19:48:46,076 Epoch: [352/484] Iter:[210/495], Time: 0.38, lr: [0.0030966881045493173], Loss: 1.931336, Acc:0.807424, Semantic loss: 0.722978, BCE loss: 0.508726, SB loss: 0.699632
2023-10-30 19:48:49,749 Epoch: [352/484] Iter:[220/495], Time: 0.38, lr: [0.0030962601848976796], Loss: 1.928985, Acc:0.807934, Semantic loss: 0.722524, BCE loss: 0.508229, SB loss: 0.698232
2023-10-30 19:48:53,445 Epoch: [352/484] Iter:[230/495], Time: 0.38, lr: [0.003095832258674743], Loss: 1.928112, Acc:0.808467, Semantic loss: 0.723098, BCE loss: 0.507728, SB loss: 0.697286
2023-10-30 19:48:57,114 Epoch: [352/484] Iter:[240/495], Time: 0.38, lr: [0.0030954043258793985], Loss: 1.932650, Acc:0.807451, Semantic loss: 0.725240, BCE loss: 0.507833, SB loss: 0.699577
2023-10-30 19:49:00,932 Epoch: [352/484] Iter:[250/495], Time: 0.38, lr: [0.0030949763865105355], Loss: 1.933860, Acc:0.807349, Semantic loss: 0.726697, BCE loss: 0.508127, SB loss: 0.699036
2023-10-30 19:49:04,740 Epoch: [352/484] Iter:[260/495], Time: 0.38, lr: [0.003094548440567043], Loss: 1.929912, Acc:0.807246, Semantic loss: 0.724076, BCE loss: 0.506632, SB loss: 0.699204
2023-10-30 19:49:08,389 Epoch: [352/484] Iter:[270/495], Time: 0.38, lr: [0.0030941204880478076], Loss: 1.925728, Acc:0.806965, Semantic loss: 0.721396, BCE loss: 0.506067, SB loss: 0.698264
2023-10-30 19:49:11,973 Epoch: [352/484] Iter:[280/495], Time: 0.38, lr: [0.0030936925289517204], Loss: 1.924232, Acc:0.808277, Semantic loss: 0.721991, BCE loss: 0.504514, SB loss: 0.697727
2023-10-30 19:49:15,717 Epoch: [352/484] Iter:[290/495], Time: 0.38, lr: [0.003093264563277669], Loss: 1.923421, Acc:0.808131, Semantic loss: 0.720470, BCE loss: 0.505370, SB loss: 0.697581
2023-10-30 19:49:19,327 Epoch: [352/484] Iter:[300/495], Time: 0.38, lr: [0.00309283659102454], Loss: 1.924423, Acc:0.807902, Semantic loss: 0.721255, BCE loss: 0.505982, SB loss: 0.697186
2023-10-30 19:49:22,889 Epoch: [352/484] Iter:[310/495], Time: 0.37, lr: [0.0030924086121912205], Loss: 1.925583, Acc:0.809228, Semantic loss: 0.721977, BCE loss: 0.505946, SB loss: 0.697661
2023-10-30 19:49:26,489 Epoch: [352/484] Iter:[320/495], Time: 0.37, lr: [0.0030919806267765988], Loss: 1.925092, Acc:0.807617, Semantic loss: 0.723178, BCE loss: 0.503921, SB loss: 0.697993
2023-10-30 19:49:30,179 Epoch: [352/484] Iter:[330/495], Time: 0.37, lr: [0.0030915526347795614], Loss: 1.929950, Acc:0.807531, Semantic loss: 0.725919, BCE loss: 0.505002, SB loss: 0.699030
2023-10-30 19:49:33,796 Epoch: [352/484] Iter:[340/495], Time: 0.37, lr: [0.0030911246361989934], Loss: 1.931193, Acc:0.807986, Semantic loss: 0.726182, BCE loss: 0.505955, SB loss: 0.699057
2023-10-30 19:49:37,487 Epoch: [352/484] Iter:[350/495], Time: 0.37, lr: [0.0030906966310337803], Loss: 1.930674, Acc:0.807781, Semantic loss: 0.726800, BCE loss: 0.504797, SB loss: 0.699076
2023-10-30 19:49:41,167 Epoch: [352/484] Iter:[360/495], Time: 0.37, lr: [0.0030902686192828092], Loss: 1.931147, Acc:0.807472, Semantic loss: 0.726107, BCE loss: 0.505821, SB loss: 0.699220
2023-10-30 19:49:44,740 Epoch: [352/484] Iter:[370/495], Time: 0.37, lr: [0.003089840600944965], Loss: 1.931617, Acc:0.807928, Semantic loss: 0.725145, BCE loss: 0.507208, SB loss: 0.699264
2023-10-30 19:49:48,543 Epoch: [352/484] Iter:[380/495], Time: 0.37, lr: [0.0030894125760191323], Loss: 1.933369, Acc:0.807065, Semantic loss: 0.725335, BCE loss: 0.508023, SB loss: 0.700011
2023-10-30 19:49:52,097 Epoch: [352/484] Iter:[390/495], Time: 0.37, lr: [0.003088984544504193], Loss: 1.930244, Acc:0.807034, Semantic loss: 0.723553, BCE loss: 0.507672, SB loss: 0.699019
2023-10-30 19:49:55,830 Epoch: [352/484] Iter:[400/495], Time: 0.37, lr: [0.0030885565063990357], Loss: 1.930641, Acc:0.807588, Semantic loss: 0.723637, BCE loss: 0.508029, SB loss: 0.698975
2023-10-30 19:49:59,499 Epoch: [352/484] Iter:[410/495], Time: 0.37, lr: [0.0030881284617025407], Loss: 1.934715, Acc:0.806932, Semantic loss: 0.726012, BCE loss: 0.508256, SB loss: 0.700448
2023-10-30 19:50:03,107 Epoch: [352/484] Iter:[420/495], Time: 0.37, lr: [0.003087700410413593], Loss: 1.936614, Acc:0.806700, Semantic loss: 0.725893, BCE loss: 0.509679, SB loss: 0.701042
2023-10-30 19:50:06,689 Epoch: [352/484] Iter:[430/495], Time: 0.37, lr: [0.0030872723525310736], Loss: 1.936199, Acc:0.806300, Semantic loss: 0.725999, BCE loss: 0.509154, SB loss: 0.701046
2023-10-30 19:50:10,308 Epoch: [352/484] Iter:[440/495], Time: 0.37, lr: [0.0030868442880538673], Loss: 1.935898, Acc:0.805130, Semantic loss: 0.726477, BCE loss: 0.508076, SB loss: 0.701345
2023-10-30 19:50:14,058 Epoch: [352/484] Iter:[450/495], Time: 0.37, lr: [0.003086416216980856], Loss: 1.934300, Acc:0.805079, Semantic loss: 0.725206, BCE loss: 0.507589, SB loss: 0.701505
2023-10-30 19:50:17,640 Epoch: [352/484] Iter:[460/495], Time: 0.37, lr: [0.003085988139310921], Loss: 1.935306, Acc:0.805153, Semantic loss: 0.725756, BCE loss: 0.508569, SB loss: 0.700981
2023-10-30 19:50:21,173 Epoch: [352/484] Iter:[470/495], Time: 0.37, lr: [0.0030855600550429426], Loss: 1.937345, Acc:0.805311, Semantic loss: 0.725894, BCE loss: 0.509667, SB loss: 0.701783
2023-10-30 19:50:24,698 Epoch: [352/484] Iter:[480/495], Time: 0.37, lr: [0.003085131964175804], Loss: 1.936366, Acc:0.804913, Semantic loss: 0.725797, BCE loss: 0.508984, SB loss: 0.701585
2023-10-30 19:50:28,165 Epoch: [352/484] Iter:[490/495], Time: 0.37, lr: [0.003084703866708386], Loss: 1.937821, Acc:0.805633, Semantic loss: 0.726037, BCE loss: 0.509981, SB loss: 0.701803
2023-10-30 19:50:29,528 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:50:29,762 Loss: 2.049, MeanIU:  0.7201, Best_mIoU:  0.7309
2023-10-30 19:50:29,763 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886]
2023-10-30 19:50:31,583 Epoch: [353/484] Iter:[0/495], Time: 1.79, lr: [0.0030844898154992217], Loss: 1.626396, Acc:0.873944, Semantic loss: 0.546341, BCE loss: 0.458737, SB loss: 0.621317
2023-10-30 19:50:35,662 Epoch: [353/484] Iter:[10/495], Time: 0.53, lr: [0.0030840617081292834], Loss: 1.888649, Acc:0.823739, Semantic loss: 0.720237, BCE loss: 0.475474, SB loss: 0.692938
2023-10-30 19:50:39,312 Epoch: [353/484] Iter:[20/495], Time: 0.45, lr: [0.003083633594156266], Loss: 1.908790, Acc:0.808539, Semantic loss: 0.723201, BCE loss: 0.480512, SB loss: 0.705077
2023-10-30 19:50:42,976 Epoch: [353/484] Iter:[30/495], Time: 0.43, lr: [0.0030832054735790483], Loss: 1.926647, Acc:0.796453, Semantic loss: 0.726316, BCE loss: 0.492975, SB loss: 0.707356
2023-10-30 19:50:46,605 Epoch: [353/484] Iter:[40/495], Time: 0.41, lr: [0.0030827773463965092], Loss: 1.947025, Acc:0.793734, Semantic loss: 0.733848, BCE loss: 0.512496, SB loss: 0.700682
2023-10-30 19:50:50,237 Epoch: [353/484] Iter:[50/495], Time: 0.40, lr: [0.0030823492126075274], Loss: 1.941418, Acc:0.795321, Semantic loss: 0.733475, BCE loss: 0.506192, SB loss: 0.701752
2023-10-30 19:50:53,911 Epoch: [353/484] Iter:[60/495], Time: 0.40, lr: [0.0030819210722109825], Loss: 1.979487, Acc:0.798431, Semantic loss: 0.764076, BCE loss: 0.507407, SB loss: 0.708005
2023-10-30 19:50:57,551 Epoch: [353/484] Iter:[70/495], Time: 0.39, lr: [0.003081492925205752], Loss: 1.974281, Acc:0.797806, Semantic loss: 0.754712, BCE loss: 0.510044, SB loss: 0.709526
2023-10-30 19:51:01,085 Epoch: [353/484] Iter:[80/495], Time: 0.39, lr: [0.003081064771590714], Loss: 1.971248, Acc:0.797563, Semantic loss: 0.755134, BCE loss: 0.505976, SB loss: 0.710138
2023-10-30 19:51:04,745 Epoch: [353/484] Iter:[90/495], Time: 0.38, lr: [0.003080636611364744], Loss: 1.973212, Acc:0.799118, Semantic loss: 0.757693, BCE loss: 0.505958, SB loss: 0.709562
2023-10-30 19:51:08,412 Epoch: [353/484] Iter:[100/495], Time: 0.38, lr: [0.0030802084445267215], Loss: 1.973627, Acc:0.798540, Semantic loss: 0.754629, BCE loss: 0.508778, SB loss: 0.710220
2023-10-30 19:51:12,054 Epoch: [353/484] Iter:[110/495], Time: 0.38, lr: [0.0030797802710755217], Loss: 1.974986, Acc:0.798166, Semantic loss: 0.754055, BCE loss: 0.511315, SB loss: 0.709616
2023-10-30 19:51:15,644 Epoch: [353/484] Iter:[120/495], Time: 0.38, lr: [0.0030793520910100216], Loss: 1.979450, Acc:0.797147, Semantic loss: 0.754807, BCE loss: 0.512124, SB loss: 0.712519
2023-10-30 19:51:19,360 Epoch: [353/484] Iter:[130/495], Time: 0.38, lr: [0.003078923904329095], Loss: 1.977891, Acc:0.800700, Semantic loss: 0.754396, BCE loss: 0.509545, SB loss: 0.713950
2023-10-30 19:51:23,012 Epoch: [353/484] Iter:[140/495], Time: 0.38, lr: [0.0030784957110316204], Loss: 1.970213, Acc:0.801627, Semantic loss: 0.750738, BCE loss: 0.507732, SB loss: 0.711742
2023-10-30 19:51:26,718 Epoch: [353/484] Iter:[150/495], Time: 0.38, lr: [0.003078067511116472], Loss: 1.972032, Acc:0.802960, Semantic loss: 0.749838, BCE loss: 0.510669, SB loss: 0.711525
2023-10-30 19:51:30,351 Epoch: [353/484] Iter:[160/495], Time: 0.38, lr: [0.0030776393045825233], Loss: 1.970588, Acc:0.803051, Semantic loss: 0.748382, BCE loss: 0.510287, SB loss: 0.711919
2023-10-30 19:51:34,073 Epoch: [353/484] Iter:[170/495], Time: 0.38, lr: [0.003077211091428649], Loss: 1.965875, Acc:0.802737, Semantic loss: 0.747204, BCE loss: 0.507245, SB loss: 0.711426
2023-10-30 19:51:37,699 Epoch: [353/484] Iter:[180/495], Time: 0.38, lr: [0.003076782871653725], Loss: 1.963949, Acc:0.804565, Semantic loss: 0.745720, BCE loss: 0.508412, SB loss: 0.709818
2023-10-30 19:51:41,325 Epoch: [353/484] Iter:[190/495], Time: 0.37, lr: [0.0030763546452566236], Loss: 1.961005, Acc:0.805117, Semantic loss: 0.744534, BCE loss: 0.506491, SB loss: 0.709981
2023-10-30 19:51:44,952 Epoch: [353/484] Iter:[200/495], Time: 0.37, lr: [0.003075926412236219], Loss: 1.968551, Acc:0.804236, Semantic loss: 0.752992, BCE loss: 0.505059, SB loss: 0.710500
2023-10-30 19:51:48,592 Epoch: [353/484] Iter:[210/495], Time: 0.37, lr: [0.0030754981725913816], Loss: 1.971398, Acc:0.805003, Semantic loss: 0.754354, BCE loss: 0.504839, SB loss: 0.712206
2023-10-30 19:51:52,097 Epoch: [353/484] Iter:[220/495], Time: 0.37, lr: [0.0030750699263209875], Loss: 1.972337, Acc:0.805026, Semantic loss: 0.751906, BCE loss: 0.507757, SB loss: 0.712674
2023-10-30 19:51:55,726 Epoch: [353/484] Iter:[230/495], Time: 0.37, lr: [0.0030746416734239073], Loss: 1.975529, Acc:0.803726, Semantic loss: 0.752228, BCE loss: 0.509592, SB loss: 0.713709
2023-10-30 19:51:59,320 Epoch: [353/484] Iter:[240/495], Time: 0.37, lr: [0.003074213413899013], Loss: 1.979862, Acc:0.803725, Semantic loss: 0.753215, BCE loss: 0.511678, SB loss: 0.714970
2023-10-30 19:52:02,981 Epoch: [353/484] Iter:[250/495], Time: 0.37, lr: [0.0030737851477451745], Loss: 1.976432, Acc:0.803668, Semantic loss: 0.751135, BCE loss: 0.510051, SB loss: 0.715246
2023-10-30 19:52:06,688 Epoch: [353/484] Iter:[260/495], Time: 0.37, lr: [0.003073356874961266], Loss: 1.971977, Acc:0.802060, Semantic loss: 0.749160, BCE loss: 0.508873, SB loss: 0.713945
2023-10-30 19:52:10,353 Epoch: [353/484] Iter:[270/495], Time: 0.37, lr: [0.0030729285955461566], Loss: 1.971480, Acc:0.802883, Semantic loss: 0.749012, BCE loss: 0.508444, SB loss: 0.714024
2023-10-30 19:52:14,046 Epoch: [353/484] Iter:[280/495], Time: 0.37, lr: [0.003072500309498717], Loss: 1.981660, Acc:0.803651, Semantic loss: 0.755422, BCE loss: 0.509927, SB loss: 0.716312
2023-10-30 19:52:17,644 Epoch: [353/484] Iter:[290/495], Time: 0.37, lr: [0.0030720720168178157], Loss: 1.980595, Acc:0.802322, Semantic loss: 0.755930, BCE loss: 0.508488, SB loss: 0.716177
2023-10-30 19:52:21,341 Epoch: [353/484] Iter:[300/495], Time: 0.37, lr: [0.0030716437175023247], Loss: 1.980310, Acc:0.802524, Semantic loss: 0.755366, BCE loss: 0.509066, SB loss: 0.715879
2023-10-30 19:52:24,965 Epoch: [353/484] Iter:[310/495], Time: 0.37, lr: [0.0030712154115511126], Loss: 1.989392, Acc:0.801317, Semantic loss: 0.761149, BCE loss: 0.510163, SB loss: 0.718079
2023-10-30 19:52:28,718 Epoch: [353/484] Iter:[320/495], Time: 0.37, lr: [0.003070787098963047], Loss: 1.983958, Acc:0.801495, Semantic loss: 0.757016, BCE loss: 0.510409, SB loss: 0.716533
2023-10-30 19:52:32,323 Epoch: [353/484] Iter:[330/495], Time: 0.37, lr: [0.0030703587797369985], Loss: 1.986634, Acc:0.800404, Semantic loss: 0.758156, BCE loss: 0.511606, SB loss: 0.716872
2023-10-30 19:52:35,976 Epoch: [353/484] Iter:[340/495], Time: 0.37, lr: [0.003069930453871835], Loss: 1.983837, Acc:0.800932, Semantic loss: 0.756959, BCE loss: 0.510577, SB loss: 0.716301
2023-10-30 19:52:39,632 Epoch: [353/484] Iter:[350/495], Time: 0.37, lr: [0.0030695021213664225], Loss: 1.985352, Acc:0.800060, Semantic loss: 0.758009, BCE loss: 0.511165, SB loss: 0.716178
2023-10-30 19:52:43,219 Epoch: [353/484] Iter:[360/495], Time: 0.37, lr: [0.003069073782219629], Loss: 1.982792, Acc:0.800674, Semantic loss: 0.755074, BCE loss: 0.512060, SB loss: 0.715658
2023-10-30 19:52:46,856 Epoch: [353/484] Iter:[370/495], Time: 0.37, lr: [0.0030686454364303242], Loss: 1.985250, Acc:0.800108, Semantic loss: 0.756715, BCE loss: 0.512508, SB loss: 0.716026
2023-10-30 19:52:50,529 Epoch: [353/484] Iter:[380/495], Time: 0.37, lr: [0.003068217083997372], Loss: 1.984402, Acc:0.800464, Semantic loss: 0.756280, BCE loss: 0.512498, SB loss: 0.715624
2023-10-30 19:52:54,174 Epoch: [353/484] Iter:[390/495], Time: 0.37, lr: [0.003067788724919639], Loss: 1.983172, Acc:0.800228, Semantic loss: 0.755100, BCE loss: 0.512551, SB loss: 0.715521
2023-10-30 19:52:57,735 Epoch: [353/484] Iter:[400/495], Time: 0.37, lr: [0.0030673603591959914], Loss: 1.981202, Acc:0.800357, Semantic loss: 0.753977, BCE loss: 0.512317, SB loss: 0.714908
2023-10-30 19:53:01,351 Epoch: [353/484] Iter:[410/495], Time: 0.37, lr: [0.003066931986825296], Loss: 1.980043, Acc:0.800039, Semantic loss: 0.753321, BCE loss: 0.511567, SB loss: 0.715155
2023-10-30 19:53:04,979 Epoch: [353/484] Iter:[420/495], Time: 0.37, lr: [0.0030665036078064175], Loss: 1.977964, Acc:0.799998, Semantic loss: 0.752081, BCE loss: 0.510928, SB loss: 0.714955
2023-10-30 19:53:08,646 Epoch: [353/484] Iter:[430/495], Time: 0.37, lr: [0.0030660752221382203], Loss: 1.976593, Acc:0.800292, Semantic loss: 0.751468, BCE loss: 0.510552, SB loss: 0.714573
2023-10-30 19:53:12,283 Epoch: [353/484] Iter:[440/495], Time: 0.37, lr: [0.0030656468298195677], Loss: 1.974412, Acc:0.800636, Semantic loss: 0.750432, BCE loss: 0.510259, SB loss: 0.713721
2023-10-30 19:53:15,888 Epoch: [353/484] Iter:[450/495], Time: 0.37, lr: [0.003065218430849327], Loss: 1.974026, Acc:0.800403, Semantic loss: 0.751235, BCE loss: 0.509076, SB loss: 0.713715
2023-10-30 19:53:19,547 Epoch: [353/484] Iter:[460/495], Time: 0.37, lr: [0.00306479002522636], Loss: 1.973720, Acc:0.800354, Semantic loss: 0.749985, BCE loss: 0.510091, SB loss: 0.713643
2023-10-30 19:53:23,297 Epoch: [353/484] Iter:[470/495], Time: 0.37, lr: [0.00306436161294953], Loss: 1.974496, Acc:0.799924, Semantic loss: 0.750283, BCE loss: 0.510653, SB loss: 0.713559
2023-10-30 19:53:26,936 Epoch: [353/484] Iter:[480/495], Time: 0.37, lr: [0.003063933194017699], Loss: 1.972841, Acc:0.800031, Semantic loss: 0.749141, BCE loss: 0.510685, SB loss: 0.713014
2023-10-30 19:53:30,330 Epoch: [353/484] Iter:[490/495], Time: 0.37, lr: [0.0030635047684297325], Loss: 1.974293, Acc:0.799394, Semantic loss: 0.749843, BCE loss: 0.511232, SB loss: 0.713218
2023-10-30 19:53:31,703 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:53:31,940 Loss: 2.049, MeanIU:  0.7201, Best_mIoU:  0.7309
2023-10-30 19:53:31,940 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886]
2023-10-30 19:53:33,803 Epoch: [354/484] Iter:[0/495], Time: 1.83, lr: [0.0030632905531393423], Loss: 1.386739, Acc:0.939815, Semantic loss: 0.492621, BCE loss: 0.372842, SB loss: 0.521276
2023-10-30 19:53:37,761 Epoch: [354/484] Iter:[10/495], Time: 0.53, lr: [0.0030628621175650367], Loss: 1.881904, Acc:0.822622, Semantic loss: 0.703273, BCE loss: 0.497752, SB loss: 0.680879
2023-10-30 19:53:41,386 Epoch: [354/484] Iter:[20/495], Time: 0.45, lr: [0.0030624336753317487], Loss: 1.876193, Acc:0.829593, Semantic loss: 0.703161, BCE loss: 0.492025, SB loss: 0.681007
2023-10-30 19:53:45,047 Epoch: [354/484] Iter:[30/495], Time: 0.42, lr: [0.00306200522643834], Loss: 1.831288, Acc:0.836427, Semantic loss: 0.685728, BCE loss: 0.474759, SB loss: 0.670801
2023-10-30 19:53:48,613 Epoch: [354/484] Iter:[40/495], Time: 0.41, lr: [0.003061576770883671], Loss: 1.862566, Acc:0.819353, Semantic loss: 0.698383, BCE loss: 0.477719, SB loss: 0.686464
2023-10-30 19:53:52,321 Epoch: [354/484] Iter:[50/495], Time: 0.40, lr: [0.003061148308666604], Loss: 1.883575, Acc:0.812962, Semantic loss: 0.709267, BCE loss: 0.479551, SB loss: 0.694757
2023-10-30 19:53:55,885 Epoch: [354/484] Iter:[60/495], Time: 0.39, lr: [0.003060719839785998], Loss: 1.917581, Acc:0.813900, Semantic loss: 0.730188, BCE loss: 0.485325, SB loss: 0.702068
2023-10-30 19:53:59,630 Epoch: [354/484] Iter:[70/495], Time: 0.39, lr: [0.0030602913642407115], Loss: 1.927860, Acc:0.817350, Semantic loss: 0.727025, BCE loss: 0.500117, SB loss: 0.700718
2023-10-30 19:54:03,337 Epoch: [354/484] Iter:[80/495], Time: 0.39, lr: [0.003059862882029607], Loss: 1.930544, Acc:0.817875, Semantic loss: 0.724017, BCE loss: 0.510039, SB loss: 0.696488
2023-10-30 19:54:06,933 Epoch: [354/484] Iter:[90/495], Time: 0.38, lr: [0.0030594343931515423], Loss: 1.937962, Acc:0.819974, Semantic loss: 0.725166, BCE loss: 0.513983, SB loss: 0.698813
2023-10-30 19:54:10,574 Epoch: [354/484] Iter:[100/495], Time: 0.38, lr: [0.0030590058976053755], Loss: 1.939807, Acc:0.817648, Semantic loss: 0.728915, BCE loss: 0.509268, SB loss: 0.701623
2023-10-30 19:54:14,254 Epoch: [354/484] Iter:[110/495], Time: 0.38, lr: [0.003058577395389964], Loss: 1.937388, Acc:0.813653, Semantic loss: 0.731534, BCE loss: 0.504279, SB loss: 0.701575
2023-10-30 19:54:17,941 Epoch: [354/484] Iter:[120/495], Time: 0.38, lr: [0.0030581488865041684], Loss: 1.933726, Acc:0.814735, Semantic loss: 0.730971, BCE loss: 0.499370, SB loss: 0.703386
2023-10-30 19:54:21,630 Epoch: [354/484] Iter:[130/495], Time: 0.38, lr: [0.0030577203709468456], Loss: 1.953366, Acc:0.814600, Semantic loss: 0.738763, BCE loss: 0.508140, SB loss: 0.706464
2023-10-30 19:54:25,316 Epoch: [354/484] Iter:[140/495], Time: 0.38, lr: [0.003057291848716852], Loss: 1.950181, Acc:0.814512, Semantic loss: 0.732990, BCE loss: 0.511861, SB loss: 0.705330
2023-10-30 19:54:28,901 Epoch: [354/484] Iter:[150/495], Time: 0.38, lr: [0.0030568633198130436], Loss: 1.955457, Acc:0.814309, Semantic loss: 0.735488, BCE loss: 0.513740, SB loss: 0.706229
2023-10-30 19:54:32,474 Epoch: [354/484] Iter:[160/495], Time: 0.38, lr: [0.0030564347842342797], Loss: 1.962551, Acc:0.814277, Semantic loss: 0.738361, BCE loss: 0.515857, SB loss: 0.708334
2023-10-30 19:54:36,014 Epoch: [354/484] Iter:[170/495], Time: 0.37, lr: [0.0030560062419794144], Loss: 1.949007, Acc:0.813485, Semantic loss: 0.731501, BCE loss: 0.510997, SB loss: 0.706510
2023-10-30 19:54:39,608 Epoch: [354/484] Iter:[180/495], Time: 0.37, lr: [0.0030555776930473034], Loss: 1.964238, Acc:0.813301, Semantic loss: 0.739972, BCE loss: 0.514273, SB loss: 0.709994
2023-10-30 19:54:43,237 Epoch: [354/484] Iter:[190/495], Time: 0.37, lr: [0.003055149137436803], Loss: 1.964983, Acc:0.812312, Semantic loss: 0.738771, BCE loss: 0.515942, SB loss: 0.710270
2023-10-30 19:54:46,899 Epoch: [354/484] Iter:[200/495], Time: 0.37, lr: [0.0030547205751467682], Loss: 1.968686, Acc:0.810665, Semantic loss: 0.742144, BCE loss: 0.514436, SB loss: 0.712106
2023-10-30 19:54:50,528 Epoch: [354/484] Iter:[210/495], Time: 0.37, lr: [0.0030542920061760533], Loss: 1.966050, Acc:0.809947, Semantic loss: 0.741308, BCE loss: 0.513433, SB loss: 0.711310
2023-10-30 19:54:54,145 Epoch: [354/484] Iter:[220/495], Time: 0.37, lr: [0.0030538634305235113], Loss: 1.961268, Acc:0.809647, Semantic loss: 0.739597, BCE loss: 0.511943, SB loss: 0.709728
2023-10-30 19:54:57,752 Epoch: [354/484] Iter:[230/495], Time: 0.37, lr: [0.003053434848187999], Loss: 1.966930, Acc:0.810766, Semantic loss: 0.740841, BCE loss: 0.515732, SB loss: 0.710357
2023-10-30 19:55:01,401 Epoch: [354/484] Iter:[240/495], Time: 0.37, lr: [0.0030530062591683674], Loss: 1.971823, Acc:0.810334, Semantic loss: 0.742513, BCE loss: 0.516675, SB loss: 0.712634
2023-10-30 19:55:04,991 Epoch: [354/484] Iter:[250/495], Time: 0.37, lr: [0.00305257766346347], Loss: 1.968686, Acc:0.809581, Semantic loss: 0.740278, BCE loss: 0.516006, SB loss: 0.712403
2023-10-30 19:55:08,675 Epoch: [354/484] Iter:[260/495], Time: 0.37, lr: [0.0030521490610721596], Loss: 1.972080, Acc:0.809509, Semantic loss: 0.743645, BCE loss: 0.515229, SB loss: 0.713207
2023-10-30 19:55:12,381 Epoch: [354/484] Iter:[270/495], Time: 0.37, lr: [0.00305172045199329], Loss: 1.970839, Acc:0.809941, Semantic loss: 0.742014, BCE loss: 0.515856, SB loss: 0.712969
2023-10-30 19:55:16,092 Epoch: [354/484] Iter:[280/495], Time: 0.37, lr: [0.0030512918362257118], Loss: 1.965472, Acc:0.809610, Semantic loss: 0.739036, BCE loss: 0.514297, SB loss: 0.712139
2023-10-30 19:55:19,732 Epoch: [354/484] Iter:[290/495], Time: 0.37, lr: [0.0030508632137682774], Loss: 1.964699, Acc:0.810209, Semantic loss: 0.738242, BCE loss: 0.515089, SB loss: 0.711368
2023-10-30 19:55:23,371 Epoch: [354/484] Iter:[300/495], Time: 0.37, lr: [0.0030504345846198364], Loss: 1.964072, Acc:0.809471, Semantic loss: 0.737344, BCE loss: 0.515579, SB loss: 0.711149
2023-10-30 19:55:26,949 Epoch: [354/484] Iter:[310/495], Time: 0.37, lr: [0.0030500059487792415], Loss: 1.964587, Acc:0.809918, Semantic loss: 0.737880, BCE loss: 0.515227, SB loss: 0.711480
2023-10-30 19:55:30,679 Epoch: [354/484] Iter:[320/495], Time: 0.37, lr: [0.003049577306245343], Loss: 1.967246, Acc:0.809468, Semantic loss: 0.739931, BCE loss: 0.515483, SB loss: 0.711832
2023-10-30 19:55:34,316 Epoch: [354/484] Iter:[330/495], Time: 0.37, lr: [0.003049148657016991], Loss: 1.963511, Acc:0.809907, Semantic loss: 0.737263, BCE loss: 0.515528, SB loss: 0.710720
2023-10-30 19:55:37,958 Epoch: [354/484] Iter:[340/495], Time: 0.37, lr: [0.003048720001093033], Loss: 1.964833, Acc:0.810137, Semantic loss: 0.738198, BCE loss: 0.516237, SB loss: 0.710398
2023-10-30 19:55:41,547 Epoch: [354/484] Iter:[350/495], Time: 0.37, lr: [0.0030482913384723216], Loss: 1.964657, Acc:0.809857, Semantic loss: 0.738285, BCE loss: 0.516057, SB loss: 0.710315
2023-10-30 19:55:45,079 Epoch: [354/484] Iter:[360/495], Time: 0.37, lr: [0.003047862669153705], Loss: 1.965242, Acc:0.809957, Semantic loss: 0.738835, BCE loss: 0.515927, SB loss: 0.710479
2023-10-30 19:55:48,704 Epoch: [354/484] Iter:[370/495], Time: 0.37, lr: [0.00304743399313603], Loss: 1.967243, Acc:0.809613, Semantic loss: 0.740304, BCE loss: 0.515685, SB loss: 0.711255
2023-10-30 19:55:52,418 Epoch: [354/484] Iter:[380/495], Time: 0.37, lr: [0.0030470053104181454], Loss: 1.970117, Acc:0.808422, Semantic loss: 0.742170, BCE loss: 0.516517, SB loss: 0.711430
2023-10-30 19:55:56,037 Epoch: [354/484] Iter:[390/495], Time: 0.37, lr: [0.0030465766209989017], Loss: 1.971907, Acc:0.809075, Semantic loss: 0.741531, BCE loss: 0.519086, SB loss: 0.711289
2023-10-30 19:55:59,711 Epoch: [354/484] Iter:[400/495], Time: 0.37, lr: [0.0030461479248771435], Loss: 1.973546, Acc:0.808303, Semantic loss: 0.742652, BCE loss: 0.519360, SB loss: 0.711535
2023-10-30 19:56:03,350 Epoch: [354/484] Iter:[410/495], Time: 0.37, lr: [0.0030457192220517187], Loss: 1.974441, Acc:0.808072, Semantic loss: 0.743754, BCE loss: 0.519327, SB loss: 0.711359
2023-10-30 19:56:06,965 Epoch: [354/484] Iter:[420/495], Time: 0.37, lr: [0.003045290512521473], Loss: 1.970955, Acc:0.808125, Semantic loss: 0.741794, BCE loss: 0.518439, SB loss: 0.710721
2023-10-30 19:56:10,515 Epoch: [354/484] Iter:[430/495], Time: 0.37, lr: [0.0030448617962852555], Loss: 1.966348, Acc:0.807623, Semantic loss: 0.739433, BCE loss: 0.517066, SB loss: 0.709849
2023-10-30 19:56:14,294 Epoch: [354/484] Iter:[440/495], Time: 0.37, lr: [0.0030444330733419094], Loss: 1.966387, Acc:0.808262, Semantic loss: 0.739526, BCE loss: 0.516862, SB loss: 0.709999
2023-10-30 19:56:17,976 Epoch: [354/484] Iter:[450/495], Time: 0.37, lr: [0.0030440043436902827], Loss: 1.966897, Acc:0.808538, Semantic loss: 0.739210, BCE loss: 0.517821, SB loss: 0.709866
2023-10-30 19:56:21,625 Epoch: [354/484] Iter:[460/495], Time: 0.37, lr: [0.003043575607329217], Loss: 1.968064, Acc:0.808178, Semantic loss: 0.740523, BCE loss: 0.517790, SB loss: 0.709751
2023-10-30 19:56:25,263 Epoch: [354/484] Iter:[470/495], Time: 0.37, lr: [0.003043146864257561], Loss: 1.968809, Acc:0.807870, Semantic loss: 0.741807, BCE loss: 0.517400, SB loss: 0.709602
2023-10-30 19:56:28,924 Epoch: [354/484] Iter:[480/495], Time: 0.37, lr: [0.0030427181144741574], Loss: 1.971783, Acc:0.807091, Semantic loss: 0.743320, BCE loss: 0.517887, SB loss: 0.710576
2023-10-30 19:56:32,353 Epoch: [354/484] Iter:[490/495], Time: 0.37, lr: [0.0030422893579778506], Loss: 1.972368, Acc:0.807129, Semantic loss: 0.743585, BCE loss: 0.517993, SB loss: 0.710790
2023-10-30 19:56:33,734 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 19:56:33,975 Loss: 2.049, MeanIU:  0.7201, Best_mIoU:  0.7309
2023-10-30 19:56:33,975 [0.97847134 0.83055402 0.90455114 0.40238812 0.49836557 0.58634286
 0.66695931 0.7492887  0.9101919  0.51592613 0.93503383 0.7813317
 0.5660478  0.93777169 0.73261321 0.8415921  0.72552725 0.37979649
 0.74004886]
2023-10-30 19:56:36,120 Epoch: [355/484] Iter:[0/495], Time: 2.11, lr: [0.0030420749772119954], Loss: 1.446907, Acc:0.726436, Semantic loss: 0.596197, BCE loss: 0.249294, SB loss: 0.601416
2023-10-30 19:56:39,983 Epoch: [355/484] Iter:[10/495], Time: 0.54, lr: [0.0030416462106441656], Loss: 1.996523, Acc:0.811652, Semantic loss: 0.761683, BCE loss: 0.525243, SB loss: 0.709597
2023-10-30 19:56:43,758 Epoch: [355/484] Iter:[20/495], Time: 0.46, lr: [0.00304121743736054], Loss: 1.967443, Acc:0.797470, Semantic loss: 0.751522, BCE loss: 0.515167, SB loss: 0.700754
2023-10-30 19:56:47,428 Epoch: [355/484] Iter:[30/495], Time: 0.43, lr: [0.0030407886573599625], Loss: 1.984994, Acc:0.797120, Semantic loss: 0.765542, BCE loss: 0.510741, SB loss: 0.708712
2023-10-30 19:56:51,053 Epoch: [355/484] Iter:[40/495], Time: 0.42, lr: [0.003040359870641274], Loss: 1.978075, Acc:0.794725, Semantic loss: 0.763306, BCE loss: 0.502546, SB loss: 0.712223
2023-10-30 19:56:54,715 Epoch: [355/484] Iter:[50/495], Time: 0.41, lr: [0.003039931077203319], Loss: 1.969548, Acc:0.785568, Semantic loss: 0.757422, BCE loss: 0.501033, SB loss: 0.711093
2023-10-30 19:56:58,350 Epoch: [355/484] Iter:[60/495], Time: 0.40, lr: [0.0030395022770449377], Loss: 1.976980, Acc:0.788789, Semantic loss: 0.761098, BCE loss: 0.509927, SB loss: 0.705955
2023-10-30 19:57:02,012 Epoch: [355/484] Iter:[70/495], Time: 0.39, lr: [0.003039073470164971], Loss: 1.985563, Acc:0.789420, Semantic loss: 0.758848, BCE loss: 0.516755, SB loss: 0.709960
2023-10-30 19:57:05,719 Epoch: [355/484] Iter:[80/495], Time: 0.39, lr: [0.003038644656562259], Loss: 1.993233, Acc:0.789747, Semantic loss: 0.757174, BCE loss: 0.527048, SB loss: 0.709011
2023-10-30 19:57:09,372 Epoch: [355/484] Iter:[90/495], Time: 0.39, lr: [0.0030382158362356445], Loss: 1.989283, Acc:0.791087, Semantic loss: 0.752965, BCE loss: 0.528772, SB loss: 0.707546
2023-10-30 19:57:12,994 Epoch: [355/484] Iter:[100/495], Time: 0.39, lr: [0.0030377870091839653], Loss: 1.988994, Acc:0.788164, Semantic loss: 0.754604, BCE loss: 0.525356, SB loss: 0.709033
2023-10-30 19:57:16,623 Epoch: [355/484] Iter:[110/495], Time: 0.38, lr: [0.003037358175406063], Loss: 1.983482, Acc:0.791017, Semantic loss: 0.751355, BCE loss: 0.523091, SB loss: 0.709037
2023-10-30 19:57:20,299 Epoch: [355/484] Iter:[120/495], Time: 0.38, lr: [0.003036929334900775], Loss: 1.965492, Acc:0.794373, Semantic loss: 0.739934, BCE loss: 0.520364, SB loss: 0.705193
2023-10-30 19:57:23,934 Epoch: [355/484] Iter:[130/495], Time: 0.38, lr: [0.0030365004876669417], Loss: 1.962650, Acc:0.793899, Semantic loss: 0.735832, BCE loss: 0.523576, SB loss: 0.703243
2023-10-30 19:57:27,501 Epoch: [355/484] Iter:[140/495], Time: 0.38, lr: [0.003036071633703401], Loss: 1.963053, Acc:0.795070, Semantic loss: 0.736323, BCE loss: 0.522301, SB loss: 0.704428
2023-10-30 19:57:31,241 Epoch: [355/484] Iter:[150/495], Time: 0.38, lr: [0.0030356427730089913], Loss: 1.969089, Acc:0.796181, Semantic loss: 0.740471, BCE loss: 0.522518, SB loss: 0.706100
2023-10-30 19:57:34,881 Epoch: [355/484] Iter:[160/495], Time: 0.38, lr: [0.0030352139055825488], Loss: 1.965564, Acc:0.795271, Semantic loss: 0.739201, BCE loss: 0.520790, SB loss: 0.705574
2023-10-30 19:57:38,478 Epoch: [355/484] Iter:[170/495], Time: 0.38, lr: [0.0030347850314229137], Loss: 1.963683, Acc:0.794768, Semantic loss: 0.739617, BCE loss: 0.519100, SB loss: 0.704965
2023-10-30 19:57:42,109 Epoch: [355/484] Iter:[180/495], Time: 0.38, lr: [0.003034356150528921], Loss: 1.960874, Acc:0.795842, Semantic loss: 0.738199, BCE loss: 0.518070, SB loss: 0.704605
2023-10-30 19:57:45,752 Epoch: [355/484] Iter:[190/495], Time: 0.38, lr: [0.0030339272628994085], Loss: 1.962776, Acc:0.795708, Semantic loss: 0.737043, BCE loss: 0.521304, SB loss: 0.704429
2023-10-30 19:57:49,381 Epoch: [355/484] Iter:[200/495], Time: 0.37, lr: [0.003033498368533211], Loss: 1.955384, Acc:0.796831, Semantic loss: 0.734387, BCE loss: 0.517583, SB loss: 0.703414
2023-10-30 19:57:52,945 Epoch: [355/484] Iter:[210/495], Time: 0.37, lr: [0.0030330694674291655], Loss: 1.954260, Acc:0.795589, Semantic loss: 0.735375, BCE loss: 0.514791, SB loss: 0.704093
2023-10-30 19:57:56,601 Epoch: [355/484] Iter:[220/495], Time: 0.37, lr: [0.003032640559586107], Loss: 1.953563, Acc:0.795719, Semantic loss: 0.734466, BCE loss: 0.514960, SB loss: 0.704137
2023-10-30 19:58:00,288 Epoch: [355/484] Iter:[230/495], Time: 0.37, lr: [0.0030322116450028714], Loss: 1.950697, Acc:0.797595, Semantic loss: 0.731629, BCE loss: 0.516199, SB loss: 0.702869
2023-10-30 19:58:03,953 Epoch: [355/484] Iter:[240/495], Time: 0.37, lr: [0.0030317827236782907], Loss: 1.947866, Acc:0.796768, Semantic loss: 0.731271, BCE loss: 0.513594, SB loss: 0.703001
2023-10-30 19:58:07,546 Epoch: [355/484] Iter:[250/495], Time: 0.37, lr: [0.003031353795611203], Loss: 1.939375, Acc:0.796555, Semantic loss: 0.728404, BCE loss: 0.509779, SB loss: 0.701192
2023-10-30 19:58:11,189 Epoch: [355/484] Iter:[260/495], Time: 0.37, lr: [0.0030309248608004404], Loss: 1.938433, Acc:0.797830, Semantic loss: 0.725239, BCE loss: 0.513177, SB loss: 0.700018
2023-10-30 19:58:14,882 Epoch: [355/484] Iter:[270/495], Time: 0.37, lr: [0.0030304959192448363], Loss: 1.942076, Acc:0.798022, Semantic loss: 0.728532, BCE loss: 0.512188, SB loss: 0.701356
2023-10-30 19:58:18,504 Epoch: [355/484] Iter:[280/495], Time: 0.37, lr: [0.0030300669709432226], Loss: 1.941033, Acc:0.796960, Semantic loss: 0.728124, BCE loss: 0.511477, SB loss: 0.701432
2023-10-30 19:58:22,245 Epoch: [355/484] Iter:[290/495], Time: 0.37, lr: [0.003029638015894435], Loss: 1.943273, Acc:0.796678, Semantic loss: 0.728642, BCE loss: 0.512204, SB loss: 0.702427
2023-10-30 19:58:25,876 Epoch: [355/484] Iter:[300/495], Time: 0.37, lr: [0.0030292090540973045], Loss: 1.945003, Acc:0.796650, Semantic loss: 0.729548, BCE loss: 0.512527, SB loss: 0.702928
2023-10-30 19:58:29,665 Epoch: [355/484] Iter:[310/495], Time: 0.37, lr: [0.0030287800855506625], Loss: 1.945045, Acc:0.795866, Semantic loss: 0.730090, BCE loss: 0.511808, SB loss: 0.703147
2023-10-30 19:58:33,416 Epoch: [355/484] Iter:[320/495], Time: 0.37, lr: [0.00302835111025334], Loss: 1.945198, Acc:0.796074, Semantic loss: 0.728266, BCE loss: 0.514170, SB loss: 0.702762
2023-10-30 19:58:37,201 Epoch: [355/484] Iter:[330/495], Time: 0.37, lr: [0.003027922128204171], Loss: 1.948655, Acc:0.796457, Semantic loss: 0.730388, BCE loss: 0.514529, SB loss: 0.703738
2023-10-30 19:58:40,778 Epoch: [355/484] Iter:[340/495], Time: 0.37, lr: [0.003027493139401984], Loss: 1.949745, Acc:0.796587, Semantic loss: 0.730954, BCE loss: 0.514272, SB loss: 0.704519
2023-10-30 19:58:44,372 Epoch: [355/484] Iter:[350/495], Time: 0.37, lr: [0.0030270641438456102], Loss: 1.948358, Acc:0.796924, Semantic loss: 0.730872, BCE loss: 0.513094, SB loss: 0.704392
2023-10-30 19:58:48,038 Epoch: [355/484] Iter:[360/495], Time: 0.37, lr: [0.003026635141533879], Loss: 1.945307, Acc:0.796878, Semantic loss: 0.730151, BCE loss: 0.511657, SB loss: 0.703499
2023-10-30 19:58:51,740 Epoch: [355/484] Iter:[370/495], Time: 0.37, lr: [0.003026206132465621], Loss: 1.947612, Acc:0.797783, Semantic loss: 0.731910, BCE loss: 0.511666, SB loss: 0.704036
2023-10-30 19:58:55,590 Epoch: [355/484] Iter:[380/495], Time: 0.37, lr: [0.0030257771166396653], Loss: 1.947340, Acc:0.797774, Semantic loss: 0.732006, BCE loss: 0.511652, SB loss: 0.703682
2023-10-30 19:58:59,280 Epoch: [355/484] Iter:[390/495], Time: 0.37, lr: [0.003025348094054841], Loss: 1.949351, Acc:0.798512, Semantic loss: 0.732561, BCE loss: 0.512510, SB loss: 0.704279
2023-10-30 19:59:03,017 Epoch: [355/484] Iter:[400/495], Time: 0.37, lr: [0.003024919064709975], Loss: 1.948156, Acc:0.798461, Semantic loss: 0.732607, BCE loss: 0.511285, SB loss: 0.704265
2023-10-30 19:59:06,673 Epoch: [355/484] Iter:[410/495], Time: 0.37, lr: [0.003024490028603898], Loss: 1.949890, Acc:0.798404, Semantic loss: 0.733477, BCE loss: 0.512013, SB loss: 0.704400
2023-10-30 19:59:10,375 Epoch: [355/484] Iter:[420/495], Time: 0.37, lr: [0.0030240609857354363], Loss: 1.951303, Acc:0.799060, Semantic loss: 0.734215, BCE loss: 0.512902, SB loss: 0.704186
2023-10-30 19:59:14,100 Epoch: [355/484] Iter:[430/495], Time: 0.37, lr: [0.003023631936103417], Loss: 1.958252, Acc:0.798556, Semantic loss: 0.738298, BCE loss: 0.514556, SB loss: 0.705398
2023-10-30 19:59:17,665 Epoch: [355/484] Iter:[440/495], Time: 0.37, lr: [0.0030232028797066665], Loss: 1.956269, Acc:0.798590, Semantic loss: 0.736996, BCE loss: 0.513683, SB loss: 0.705590
2023-10-30 19:59:21,293 Epoch: [355/484] Iter:[450/495], Time: 0.37, lr: [0.0030227738165440133], Loss: 1.956828, Acc:0.798357, Semantic loss: 0.736992, BCE loss: 0.514352, SB loss: 0.705484
2023-10-30 19:59:25,098 Epoch: [355/484] Iter:[460/495], Time: 0.37, lr: [0.0030223447466142836], Loss: 1.953677, Acc:0.798565, Semantic loss: 0.735224, BCE loss: 0.513714, SB loss: 0.704738
2023-10-30 19:59:28,702 Epoch: [355/484] Iter:[470/495], Time: 0.37, lr: [0.003021915669916301], Loss: 1.957229, Acc:0.799430, Semantic loss: 0.736302, BCE loss: 0.516040, SB loss: 0.704887
2023-10-30 19:59:32,292 Epoch: [355/484] Iter:[480/495], Time: 0.37, lr: [0.0030214865864488915], Loss: 1.956516, Acc:0.799193, Semantic loss: 0.735809, BCE loss: 0.515602, SB loss: 0.705105
2023-10-30 19:59:35,779 Epoch: [355/484] Iter:[490/495], Time: 0.37, lr: [0.0030210574962108816], Loss: 1.956491, Acc:0.799703, Semantic loss: 0.735165, BCE loss: 0.516329, SB loss: 0.704997
2023-10-30 20:02:32,798 0 [0.93813792 0.62192782 0.83563789 0.14305104 0.28897959 0.42717773
 0.47795892 0.6059206  0.88560152 0.44602808 0.86059467 0.61797323
 0.04779697 0.81430214 0.00627351 0.17984598 0.06378336 0.04632402
 0.61571656] 0.4696332379930577
2023-10-30 20:02:32,798 1 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238] 0.7053535329473332
2023-10-30 20:02:32,802 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:02:33,038 Loss: 2.023, MeanIU:  0.7054, Best_mIoU:  0.7309
2023-10-30 20:02:33,038 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238]
2023-10-30 20:02:34,956 Epoch: [356/484] Iter:[0/495], Time: 1.88, lr: [0.003020842948552534], Loss: 1.608103, Acc:0.738072, Semantic loss: 0.593301, BCE loss: 0.397584, SB loss: 0.617219
2023-10-30 20:02:39,043 Epoch: [356/484] Iter:[10/495], Time: 0.54, lr: [0.003020413848156419], Loss: 1.857604, Acc:0.807994, Semantic loss: 0.676518, BCE loss: 0.496837, SB loss: 0.684249
2023-10-30 20:02:42,747 Epoch: [356/484] Iter:[20/495], Time: 0.46, lr: [0.0030199847409867614], Loss: 1.920927, Acc:0.823031, Semantic loss: 0.698586, BCE loss: 0.525262, SB loss: 0.697079
2023-10-30 20:02:46,168 Epoch: [356/484] Iter:[30/495], Time: 0.42, lr: [0.003019555627042389], Loss: 1.900828, Acc:0.828676, Semantic loss: 0.699155, BCE loss: 0.504806, SB loss: 0.696867
2023-10-30 20:02:49,668 Epoch: [356/484] Iter:[40/495], Time: 0.40, lr: [0.003019126506322123], Loss: 1.874537, Acc:0.828814, Semantic loss: 0.685223, BCE loss: 0.501328, SB loss: 0.687986
2023-10-30 20:02:53,168 Epoch: [356/484] Iter:[50/495], Time: 0.39, lr: [0.003018697378824786], Loss: 1.870713, Acc:0.823514, Semantic loss: 0.683801, BCE loss: 0.503852, SB loss: 0.683060
2023-10-30 20:02:56,649 Epoch: [356/484] Iter:[60/495], Time: 0.39, lr: [0.0030182682445492005], Loss: 1.912734, Acc:0.819818, Semantic loss: 0.700504, BCE loss: 0.521531, SB loss: 0.690699
2023-10-30 20:03:00,221 Epoch: [356/484] Iter:[70/495], Time: 0.38, lr: [0.0030178391034941894], Loss: 1.930739, Acc:0.821560, Semantic loss: 0.713236, BCE loss: 0.524771, SB loss: 0.692732
2023-10-30 20:03:03,710 Epoch: [356/484] Iter:[80/495], Time: 0.38, lr: [0.0030174099556585744], Loss: 1.946843, Acc:0.816944, Semantic loss: 0.721092, BCE loss: 0.528150, SB loss: 0.697601
2023-10-30 20:03:07,409 Epoch: [356/484] Iter:[90/495], Time: 0.38, lr: [0.003016980801041176], Loss: 1.939318, Acc:0.816349, Semantic loss: 0.719844, BCE loss: 0.524062, SB loss: 0.695412
2023-10-30 20:03:10,980 Epoch: [356/484] Iter:[100/495], Time: 0.38, lr: [0.003016551639640815], Loss: 1.940485, Acc:0.817512, Semantic loss: 0.716960, BCE loss: 0.527304, SB loss: 0.696221
2023-10-30 20:03:14,628 Epoch: [356/484] Iter:[110/495], Time: 0.37, lr: [0.0030161224714563128], Loss: 1.942012, Acc:0.815161, Semantic loss: 0.718176, BCE loss: 0.525305, SB loss: 0.698531
2023-10-30 20:03:18,126 Epoch: [356/484] Iter:[120/495], Time: 0.37, lr: [0.0030156932964864897], Loss: 1.947988, Acc:0.815556, Semantic loss: 0.721569, BCE loss: 0.525907, SB loss: 0.700512
2023-10-30 20:03:21,665 Epoch: [356/484] Iter:[130/495], Time: 0.37, lr: [0.0030152641147301647], Loss: 1.945971, Acc:0.809515, Semantic loss: 0.723372, BCE loss: 0.522002, SB loss: 0.700597
2023-10-30 20:03:25,141 Epoch: [356/484] Iter:[140/495], Time: 0.37, lr: [0.0030148349261861565], Loss: 1.935886, Acc:0.807030, Semantic loss: 0.720965, BCE loss: 0.516462, SB loss: 0.698458
2023-10-30 20:03:28,694 Epoch: [356/484] Iter:[150/495], Time: 0.37, lr: [0.0030144057308532863], Loss: 1.929383, Acc:0.804188, Semantic loss: 0.718920, BCE loss: 0.512298, SB loss: 0.698164
2023-10-30 20:03:32,178 Epoch: [356/484] Iter:[160/495], Time: 0.37, lr: [0.0030139765287303705], Loss: 1.930803, Acc:0.804356, Semantic loss: 0.720080, BCE loss: 0.512560, SB loss: 0.698163
2023-10-30 20:03:35,738 Epoch: [356/484] Iter:[170/495], Time: 0.37, lr: [0.0030135473198162287], Loss: 1.937297, Acc:0.803626, Semantic loss: 0.723895, BCE loss: 0.513857, SB loss: 0.699545
2023-10-30 20:03:39,289 Epoch: [356/484] Iter:[180/495], Time: 0.37, lr: [0.0030131181041096774], Loss: 1.933831, Acc:0.804962, Semantic loss: 0.719483, BCE loss: 0.516599, SB loss: 0.697749
2023-10-30 20:03:42,934 Epoch: [356/484] Iter:[190/495], Time: 0.37, lr: [0.003012688881609535], Loss: 1.936738, Acc:0.806768, Semantic loss: 0.720876, BCE loss: 0.517483, SB loss: 0.698379
2023-10-30 20:03:46,544 Epoch: [356/484] Iter:[200/495], Time: 0.37, lr: [0.0030122596523146183], Loss: 1.942822, Acc:0.807018, Semantic loss: 0.723997, BCE loss: 0.519169, SB loss: 0.699656
2023-10-30 20:03:50,083 Epoch: [356/484] Iter:[210/495], Time: 0.36, lr: [0.0030118304162237443], Loss: 1.950888, Acc:0.807935, Semantic loss: 0.729370, BCE loss: 0.520089, SB loss: 0.701429
2023-10-30 20:03:53,681 Epoch: [356/484] Iter:[220/495], Time: 0.36, lr: [0.003011401173335727], Loss: 1.953302, Acc:0.807048, Semantic loss: 0.731748, BCE loss: 0.519113, SB loss: 0.702441
2023-10-30 20:03:57,283 Epoch: [356/484] Iter:[230/495], Time: 0.36, lr: [0.0030109719236493856], Loss: 1.950560, Acc:0.806584, Semantic loss: 0.728626, BCE loss: 0.519835, SB loss: 0.702099
2023-10-30 20:04:00,978 Epoch: [356/484] Iter:[240/495], Time: 0.36, lr: [0.0030105426671635334], Loss: 1.946644, Acc:0.806549, Semantic loss: 0.727037, BCE loss: 0.517743, SB loss: 0.701865
2023-10-30 20:04:04,604 Epoch: [356/484] Iter:[250/495], Time: 0.36, lr: [0.003010113403876986], Loss: 1.945444, Acc:0.806416, Semantic loss: 0.727487, BCE loss: 0.516384, SB loss: 0.701573
2023-10-30 20:04:08,229 Epoch: [356/484] Iter:[260/495], Time: 0.36, lr: [0.0030096841337885574], Loss: 1.944857, Acc:0.806115, Semantic loss: 0.726041, BCE loss: 0.516702, SB loss: 0.702114
2023-10-30 20:04:11,770 Epoch: [356/484] Iter:[270/495], Time: 0.36, lr: [0.003009254856897063], Loss: 1.945643, Acc:0.806249, Semantic loss: 0.726690, BCE loss: 0.516223, SB loss: 0.702731
2023-10-30 20:04:15,464 Epoch: [356/484] Iter:[280/495], Time: 0.36, lr: [0.003008825573201316], Loss: 1.944886, Acc:0.806219, Semantic loss: 0.727617, BCE loss: 0.514950, SB loss: 0.702319
2023-10-30 20:04:19,018 Epoch: [356/484] Iter:[290/495], Time: 0.36, lr: [0.00300839628270013], Loss: 1.941942, Acc:0.806425, Semantic loss: 0.725940, BCE loss: 0.514251, SB loss: 0.701751
2023-10-30 20:04:22,691 Epoch: [356/484] Iter:[300/495], Time: 0.36, lr: [0.0030079669853923163], Loss: 1.942173, Acc:0.806402, Semantic loss: 0.726324, BCE loss: 0.513847, SB loss: 0.702002
2023-10-30 20:04:26,331 Epoch: [356/484] Iter:[310/495], Time: 0.36, lr: [0.0030075376812766907], Loss: 1.939511, Acc:0.807112, Semantic loss: 0.724785, BCE loss: 0.513615, SB loss: 0.701111
2023-10-30 20:04:30,018 Epoch: [356/484] Iter:[320/495], Time: 0.36, lr: [0.003007108370352064], Loss: 1.942111, Acc:0.807873, Semantic loss: 0.725808, BCE loss: 0.515331, SB loss: 0.700971
2023-10-30 20:04:33,659 Epoch: [356/484] Iter:[330/495], Time: 0.36, lr: [0.0030066790526172477], Loss: 1.946212, Acc:0.807777, Semantic loss: 0.727708, BCE loss: 0.516674, SB loss: 0.701829
2023-10-30 20:04:37,258 Epoch: [356/484] Iter:[340/495], Time: 0.36, lr: [0.0030062497280710534], Loss: 1.945715, Acc:0.808314, Semantic loss: 0.727963, BCE loss: 0.515736, SB loss: 0.702016
2023-10-30 20:04:40,873 Epoch: [356/484] Iter:[350/495], Time: 0.36, lr: [0.0030058203967122925], Loss: 1.944545, Acc:0.807745, Semantic loss: 0.726893, BCE loss: 0.515772, SB loss: 0.701881
2023-10-30 20:04:44,614 Epoch: [356/484] Iter:[360/495], Time: 0.36, lr: [0.003005391058539776], Loss: 1.941856, Acc:0.807644, Semantic loss: 0.726005, BCE loss: 0.513711, SB loss: 0.702139
2023-10-30 20:04:48,278 Epoch: [356/484] Iter:[370/495], Time: 0.36, lr: [0.003004961713552314], Loss: 1.941174, Acc:0.808318, Semantic loss: 0.725512, BCE loss: 0.514157, SB loss: 0.701505
2023-10-30 20:04:51,959 Epoch: [356/484] Iter:[380/495], Time: 0.36, lr: [0.003004532361748714], Loss: 1.941791, Acc:0.808745, Semantic loss: 0.725720, BCE loss: 0.514495, SB loss: 0.701577
2023-10-30 20:04:55,622 Epoch: [356/484] Iter:[390/495], Time: 0.36, lr: [0.00300410300312779], Loss: 1.945019, Acc:0.807777, Semantic loss: 0.726747, BCE loss: 0.516235, SB loss: 0.702036
2023-10-30 20:04:59,373 Epoch: [356/484] Iter:[400/495], Time: 0.36, lr: [0.0030036736376883484], Loss: 1.941769, Acc:0.807080, Semantic loss: 0.726001, BCE loss: 0.514649, SB loss: 0.701119
2023-10-30 20:05:03,029 Epoch: [356/484] Iter:[410/495], Time: 0.36, lr: [0.0030032442654291977], Loss: 1.942918, Acc:0.805423, Semantic loss: 0.728167, BCE loss: 0.512555, SB loss: 0.702196
2023-10-30 20:05:06,714 Epoch: [356/484] Iter:[420/495], Time: 0.36, lr: [0.0030028148863491463], Loss: 1.941398, Acc:0.804431, Semantic loss: 0.727181, BCE loss: 0.512116, SB loss: 0.702101
2023-10-30 20:05:10,392 Epoch: [356/484] Iter:[430/495], Time: 0.36, lr: [0.003002385500447003], Loss: 1.943454, Acc:0.803853, Semantic loss: 0.727794, BCE loss: 0.513054, SB loss: 0.702606
2023-10-30 20:05:13,996 Epoch: [356/484] Iter:[440/495], Time: 0.36, lr: [0.0030019561077215752], Loss: 1.942310, Acc:0.804038, Semantic loss: 0.726793, BCE loss: 0.513352, SB loss: 0.702166
2023-10-30 20:05:17,610 Epoch: [356/484] Iter:[450/495], Time: 0.36, lr: [0.0030015267081716698], Loss: 1.944371, Acc:0.804049, Semantic loss: 0.726768, BCE loss: 0.515019, SB loss: 0.702585
2023-10-30 20:05:21,195 Epoch: [356/484] Iter:[460/495], Time: 0.36, lr: [0.003001097301796092], Loss: 1.945478, Acc:0.803961, Semantic loss: 0.728305, BCE loss: 0.513990, SB loss: 0.703182
2023-10-30 20:05:24,787 Epoch: [356/484] Iter:[470/495], Time: 0.36, lr: [0.0030006678885936507], Loss: 1.948169, Acc:0.804410, Semantic loss: 0.730248, BCE loss: 0.514285, SB loss: 0.703636
2023-10-30 20:05:28,395 Epoch: [356/484] Iter:[480/495], Time: 0.36, lr: [0.0030002384685631506], Loss: 1.949605, Acc:0.804121, Semantic loss: 0.732002, BCE loss: 0.513578, SB loss: 0.704026
2023-10-30 20:05:31,824 Epoch: [356/484] Iter:[490/495], Time: 0.36, lr: [0.002999809041703396], Loss: 1.948355, Acc:0.804062, Semantic loss: 0.730875, BCE loss: 0.513884, SB loss: 0.703596
2023-10-30 20:05:33,195 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:05:33,437 Loss: 2.023, MeanIU:  0.7054, Best_mIoU:  0.7309
2023-10-30 20:05:33,437 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238]
2023-10-30 20:05:35,663 Epoch: [357/484] Iter:[0/495], Time: 2.19, lr: [0.002999594325712176], Loss: 1.772302, Acc:0.803615, Semantic loss: 0.667724, BCE loss: 0.481595, SB loss: 0.622983
2023-10-30 20:05:39,760 Epoch: [357/484] Iter:[10/495], Time: 0.57, lr: [0.002999164888606302], Loss: 1.870792, Acc:0.797166, Semantic loss: 0.716144, BCE loss: 0.466036, SB loss: 0.688612
2023-10-30 20:05:43,504 Epoch: [357/484] Iter:[20/495], Time: 0.48, lr: [0.002998735444668187], Loss: 1.908043, Acc:0.819951, Semantic loss: 0.709501, BCE loss: 0.524162, SB loss: 0.674381
2023-10-30 20:05:47,213 Epoch: [357/484] Iter:[30/495], Time: 0.44, lr: [0.0029983059938966344], Loss: 1.884513, Acc:0.810891, Semantic loss: 0.707650, BCE loss: 0.494045, SB loss: 0.682818
2023-10-30 20:05:50,905 Epoch: [357/484] Iter:[40/495], Time: 0.43, lr: [0.0029978765362904483], Loss: 1.920934, Acc:0.810899, Semantic loss: 0.716314, BCE loss: 0.519263, SB loss: 0.685357
2023-10-30 20:05:54,463 Epoch: [357/484] Iter:[50/495], Time: 0.41, lr: [0.002997447071848432], Loss: 1.926878, Acc:0.808823, Semantic loss: 0.720077, BCE loss: 0.520557, SB loss: 0.686244
2023-10-30 20:05:58,073 Epoch: [357/484] Iter:[60/495], Time: 0.40, lr: [0.0029970176005693887], Loss: 1.952516, Acc:0.803119, Semantic loss: 0.742257, BCE loss: 0.517297, SB loss: 0.692962
2023-10-30 20:06:01,848 Epoch: [357/484] Iter:[70/495], Time: 0.40, lr: [0.0029965881224521215], Loss: 1.942008, Acc:0.804727, Semantic loss: 0.731921, BCE loss: 0.519094, SB loss: 0.690994
2023-10-30 20:06:05,637 Epoch: [357/484] Iter:[80/495], Time: 0.40, lr: [0.00299615863749543], Loss: 1.937942, Acc:0.804998, Semantic loss: 0.727680, BCE loss: 0.520093, SB loss: 0.690169
2023-10-30 20:06:09,380 Epoch: [357/484] Iter:[90/495], Time: 0.39, lr: [0.002995729145698119], Loss: 1.934207, Acc:0.805361, Semantic loss: 0.725070, BCE loss: 0.518793, SB loss: 0.690344
2023-10-30 20:06:13,052 Epoch: [357/484] Iter:[100/495], Time: 0.39, lr: [0.0029952996470589887], Loss: 1.933279, Acc:0.807147, Semantic loss: 0.722652, BCE loss: 0.521100, SB loss: 0.689526
2023-10-30 20:06:16,781 Epoch: [357/484] Iter:[110/495], Time: 0.39, lr: [0.00299487014157684], Loss: 1.921887, Acc:0.807814, Semantic loss: 0.719593, BCE loss: 0.516721, SB loss: 0.685574
2023-10-30 20:06:20,483 Epoch: [357/484] Iter:[120/495], Time: 0.39, lr: [0.0029944406292504713], Loss: 1.924538, Acc:0.809711, Semantic loss: 0.721963, BCE loss: 0.513762, SB loss: 0.688813
2023-10-30 20:06:24,155 Epoch: [357/484] Iter:[130/495], Time: 0.39, lr: [0.002994011110078686], Loss: 1.940465, Acc:0.809249, Semantic loss: 0.730997, BCE loss: 0.516606, SB loss: 0.692862
2023-10-30 20:06:27,768 Epoch: [357/484] Iter:[140/495], Time: 0.39, lr: [0.0029935815840602827], Loss: 1.940762, Acc:0.809814, Semantic loss: 0.728947, BCE loss: 0.518452, SB loss: 0.693363
2023-10-30 20:06:31,563 Epoch: [357/484] Iter:[150/495], Time: 0.38, lr: [0.00299315205119406], Loss: 1.944509, Acc:0.808598, Semantic loss: 0.727908, BCE loss: 0.522600, SB loss: 0.694001
2023-10-30 20:06:35,201 Epoch: [357/484] Iter:[160/495], Time: 0.38, lr: [0.0029927225114788165], Loss: 1.948323, Acc:0.807807, Semantic loss: 0.727659, BCE loss: 0.526422, SB loss: 0.694242
2023-10-30 20:06:38,807 Epoch: [357/484] Iter:[170/495], Time: 0.38, lr: [0.0029922929649133525], Loss: 1.944759, Acc:0.807368, Semantic loss: 0.727474, BCE loss: 0.523402, SB loss: 0.693883
2023-10-30 20:06:42,435 Epoch: [357/484] Iter:[180/495], Time: 0.38, lr: [0.002991863411496465], Loss: 1.943299, Acc:0.808149, Semantic loss: 0.728746, BCE loss: 0.521269, SB loss: 0.693284
2023-10-30 20:06:46,150 Epoch: [357/484] Iter:[190/495], Time: 0.38, lr: [0.0029914338512269517], Loss: 1.947543, Acc:0.807818, Semantic loss: 0.731403, BCE loss: 0.521475, SB loss: 0.694665
2023-10-30 20:06:49,821 Epoch: [357/484] Iter:[200/495], Time: 0.38, lr: [0.002991004284103609], Loss: 1.943016, Acc:0.808925, Semantic loss: 0.728659, BCE loss: 0.519693, SB loss: 0.694665
2023-10-30 20:06:53,510 Epoch: [357/484] Iter:[210/495], Time: 0.38, lr: [0.0029905747101252357], Loss: 1.938328, Acc:0.809038, Semantic loss: 0.726955, BCE loss: 0.518298, SB loss: 0.693075
2023-10-30 20:06:57,140 Epoch: [357/484] Iter:[220/495], Time: 0.38, lr: [0.0029901451292906273], Loss: 1.940917, Acc:0.809052, Semantic loss: 0.727989, BCE loss: 0.520279, SB loss: 0.692650
2023-10-30 20:07:00,716 Epoch: [357/484] Iter:[230/495], Time: 0.38, lr: [0.0029897155415985798], Loss: 1.947493, Acc:0.810405, Semantic loss: 0.731347, BCE loss: 0.521983, SB loss: 0.694163
2023-10-30 20:07:04,364 Epoch: [357/484] Iter:[240/495], Time: 0.38, lr: [0.0029892859470478884], Loss: 1.953780, Acc:0.809129, Semantic loss: 0.734863, BCE loss: 0.523609, SB loss: 0.695308
2023-10-30 20:07:07,990 Epoch: [357/484] Iter:[250/495], Time: 0.38, lr: [0.0029888563456373497], Loss: 1.966173, Acc:0.809686, Semantic loss: 0.740765, BCE loss: 0.527480, SB loss: 0.697929
2023-10-30 20:07:11,750 Epoch: [357/484] Iter:[260/495], Time: 0.38, lr: [0.002988426737365758], Loss: 1.969734, Acc:0.810047, Semantic loss: 0.742341, BCE loss: 0.528260, SB loss: 0.699132
2023-10-30 20:07:15,429 Epoch: [357/484] Iter:[270/495], Time: 0.38, lr: [0.0029879971222319074], Loss: 1.972121, Acc:0.809598, Semantic loss: 0.743395, BCE loss: 0.528423, SB loss: 0.700303
2023-10-30 20:07:19,103 Epoch: [357/484] Iter:[280/495], Time: 0.38, lr: [0.0029875675002345916], Loss: 1.974260, Acc:0.810848, Semantic loss: 0.744496, BCE loss: 0.527483, SB loss: 0.702281
2023-10-30 20:07:22,788 Epoch: [357/484] Iter:[290/495], Time: 0.38, lr: [0.0029871378713726055], Loss: 1.970787, Acc:0.810004, Semantic loss: 0.742853, BCE loss: 0.525989, SB loss: 0.701945
2023-10-30 20:07:26,356 Epoch: [357/484] Iter:[300/495], Time: 0.38, lr: [0.002986708235644742], Loss: 1.969340, Acc:0.810637, Semantic loss: 0.741720, BCE loss: 0.526115, SB loss: 0.701506
2023-10-30 20:07:30,018 Epoch: [357/484] Iter:[310/495], Time: 0.37, lr: [0.002986278593049793], Loss: 1.968710, Acc:0.810417, Semantic loss: 0.740924, BCE loss: 0.526862, SB loss: 0.700924
2023-10-30 20:07:33,685 Epoch: [357/484] Iter:[320/495], Time: 0.37, lr: [0.002985848943586551], Loss: 1.963579, Acc:0.809506, Semantic loss: 0.738420, BCE loss: 0.525872, SB loss: 0.699287
2023-10-30 20:07:37,288 Epoch: [357/484] Iter:[330/495], Time: 0.37, lr: [0.00298541928725381], Loss: 1.961508, Acc:0.809502, Semantic loss: 0.737233, BCE loss: 0.525533, SB loss: 0.698742
2023-10-30 20:07:40,958 Epoch: [357/484] Iter:[340/495], Time: 0.37, lr: [0.00298498962405036], Loss: 1.961420, Acc:0.809832, Semantic loss: 0.737532, BCE loss: 0.524396, SB loss: 0.699493
2023-10-30 20:07:44,580 Epoch: [357/484] Iter:[350/495], Time: 0.37, lr: [0.0029845599539749914], Loss: 1.957412, Acc:0.810386, Semantic loss: 0.734879, BCE loss: 0.524367, SB loss: 0.698166
2023-10-30 20:07:48,274 Epoch: [357/484] Iter:[360/495], Time: 0.37, lr: [0.002984130277026497], Loss: 1.956702, Acc:0.810257, Semantic loss: 0.734709, BCE loss: 0.524196, SB loss: 0.697797
2023-10-30 20:07:51,960 Epoch: [357/484] Iter:[370/495], Time: 0.37, lr: [0.0029837005932036665], Loss: 1.952511, Acc:0.810431, Semantic loss: 0.733349, BCE loss: 0.522431, SB loss: 0.696732
2023-10-30 20:07:55,707 Epoch: [357/484] Iter:[380/495], Time: 0.37, lr: [0.0029832709025052894], Loss: 1.952178, Acc:0.810667, Semantic loss: 0.733558, BCE loss: 0.522330, SB loss: 0.696290
2023-10-30 20:07:59,578 Epoch: [357/484] Iter:[390/495], Time: 0.37, lr: [0.0029828412049301553], Loss: 1.953545, Acc:0.810961, Semantic loss: 0.734305, BCE loss: 0.522535, SB loss: 0.696705
2023-10-30 20:08:03,274 Epoch: [357/484] Iter:[400/495], Time: 0.37, lr: [0.0029824115004770547], Loss: 1.955335, Acc:0.811040, Semantic loss: 0.734697, BCE loss: 0.522666, SB loss: 0.697973
2023-10-30 20:08:06,969 Epoch: [357/484] Iter:[410/495], Time: 0.37, lr: [0.0029819817891447754], Loss: 1.955104, Acc:0.811293, Semantic loss: 0.734684, BCE loss: 0.521942, SB loss: 0.698478
2023-10-30 20:08:10,641 Epoch: [357/484] Iter:[420/495], Time: 0.37, lr: [0.0029815520709321054], Loss: 1.956301, Acc:0.810103, Semantic loss: 0.735399, BCE loss: 0.522154, SB loss: 0.698747
2023-10-30 20:08:14,365 Epoch: [357/484] Iter:[430/495], Time: 0.37, lr: [0.0029811223458378324], Loss: 1.954649, Acc:0.809494, Semantic loss: 0.734974, BCE loss: 0.521148, SB loss: 0.698527
2023-10-30 20:08:18,139 Epoch: [357/484] Iter:[440/495], Time: 0.37, lr: [0.0029806926138607453], Loss: 1.956130, Acc:0.809627, Semantic loss: 0.735649, BCE loss: 0.521897, SB loss: 0.698585
2023-10-30 20:08:21,785 Epoch: [357/484] Iter:[450/495], Time: 0.37, lr: [0.0029802628749996314], Loss: 1.956679, Acc:0.810476, Semantic loss: 0.735689, BCE loss: 0.522010, SB loss: 0.698980
2023-10-30 20:08:25,487 Epoch: [357/484] Iter:[460/495], Time: 0.37, lr: [0.002979833129253276], Loss: 1.955896, Acc:0.810569, Semantic loss: 0.736020, BCE loss: 0.520709, SB loss: 0.699166
2023-10-30 20:08:29,228 Epoch: [357/484] Iter:[470/495], Time: 0.37, lr: [0.0029794033766204655], Loss: 1.956134, Acc:0.809690, Semantic loss: 0.735929, BCE loss: 0.520495, SB loss: 0.699710
2023-10-30 20:08:32,844 Epoch: [357/484] Iter:[480/495], Time: 0.37, lr: [0.002978973617099987], Loss: 1.963344, Acc:0.809481, Semantic loss: 0.739116, BCE loss: 0.522829, SB loss: 0.701400
2023-10-30 20:08:36,347 Epoch: [357/484] Iter:[490/495], Time: 0.37, lr: [0.0029785438506906257], Loss: 1.961880, Acc:0.809769, Semantic loss: 0.738138, BCE loss: 0.522402, SB loss: 0.701340
2023-10-30 20:08:37,723 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:08:37,962 Loss: 2.023, MeanIU:  0.7054, Best_mIoU:  0.7309
2023-10-30 20:08:37,962 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238]
2023-10-30 20:08:39,879 Epoch: [358/484] Iter:[0/495], Time: 1.89, lr: [0.002978328964902235], Loss: 1.740781, Acc:0.733282, Semantic loss: 0.657285, BCE loss: 0.405431, SB loss: 0.678064
2023-10-30 20:08:44,039 Epoch: [358/484] Iter:[10/495], Time: 0.55, lr: [0.002977899188157271], Loss: 1.887648, Acc:0.788931, Semantic loss: 0.688295, BCE loss: 0.512568, SB loss: 0.686785
2023-10-30 20:08:47,716 Epoch: [358/484] Iter:[20/495], Time: 0.46, lr: [0.0029774694045203855], Loss: 1.906301, Acc:0.812694, Semantic loss: 0.695032, BCE loss: 0.508052, SB loss: 0.703218
2023-10-30 20:08:51,398 Epoch: [358/484] Iter:[30/495], Time: 0.43, lr: [0.0029770396139903637], Loss: 1.951601, Acc:0.812429, Semantic loss: 0.713285, BCE loss: 0.539981, SB loss: 0.698335
2023-10-30 20:08:55,003 Epoch: [358/484] Iter:[40/495], Time: 0.41, lr: [0.0029766098165659887], Loss: 1.931786, Acc:0.814087, Semantic loss: 0.703581, BCE loss: 0.537114, SB loss: 0.691091
2023-10-30 20:08:58,562 Epoch: [358/484] Iter:[50/495], Time: 0.40, lr: [0.002976180012246044], Loss: 1.945369, Acc:0.810086, Semantic loss: 0.708532, BCE loss: 0.541963, SB loss: 0.694873
2023-10-30 20:09:02,238 Epoch: [358/484] Iter:[60/495], Time: 0.40, lr: [0.0029757502010293113], Loss: 1.930167, Acc:0.813441, Semantic loss: 0.702681, BCE loss: 0.533509, SB loss: 0.693977
2023-10-30 20:09:05,844 Epoch: [358/484] Iter:[70/495], Time: 0.39, lr: [0.0029753203829145747], Loss: 1.928096, Acc:0.814431, Semantic loss: 0.701428, BCE loss: 0.533005, SB loss: 0.693662
2023-10-30 20:09:09,443 Epoch: [358/484] Iter:[80/495], Time: 0.39, lr: [0.002974890557900616], Loss: 1.936380, Acc:0.814092, Semantic loss: 0.711572, BCE loss: 0.529854, SB loss: 0.694954
2023-10-30 20:09:13,157 Epoch: [358/484] Iter:[90/495], Time: 0.39, lr: [0.002974460725986216], Loss: 1.951226, Acc:0.812757, Semantic loss: 0.718493, BCE loss: 0.532776, SB loss: 0.699957
2023-10-30 20:09:16,904 Epoch: [358/484] Iter:[100/495], Time: 0.39, lr: [0.002974030887170155], Loss: 1.969231, Acc:0.813702, Semantic loss: 0.731653, BCE loss: 0.534387, SB loss: 0.703190
2023-10-30 20:09:20,541 Epoch: [358/484] Iter:[110/495], Time: 0.38, lr: [0.002973601041451217], Loss: 1.973594, Acc:0.811037, Semantic loss: 0.737190, BCE loss: 0.531710, SB loss: 0.704694
2023-10-30 20:09:24,176 Epoch: [358/484] Iter:[120/495], Time: 0.38, lr: [0.00297317118882818], Loss: 1.967976, Acc:0.811733, Semantic loss: 0.736806, BCE loss: 0.529584, SB loss: 0.701586
2023-10-30 20:09:27,778 Epoch: [358/484] Iter:[130/495], Time: 0.38, lr: [0.002972741329299824], Loss: 1.973544, Acc:0.811284, Semantic loss: 0.742180, BCE loss: 0.527063, SB loss: 0.704301
2023-10-30 20:09:31,418 Epoch: [358/484] Iter:[140/495], Time: 0.38, lr: [0.0029723114628649283], Loss: 1.968160, Acc:0.810147, Semantic loss: 0.739092, BCE loss: 0.525724, SB loss: 0.703343
2023-10-30 20:09:35,114 Epoch: [358/484] Iter:[150/495], Time: 0.38, lr: [0.002971881589522274], Loss: 1.962561, Acc:0.811215, Semantic loss: 0.734841, BCE loss: 0.524825, SB loss: 0.702895
2023-10-30 20:09:38,729 Epoch: [358/484] Iter:[160/495], Time: 0.38, lr: [0.0029714517092706387], Loss: 1.965229, Acc:0.810990, Semantic loss: 0.737129, BCE loss: 0.525535, SB loss: 0.702565
2023-10-30 20:09:42,349 Epoch: [358/484] Iter:[170/495], Time: 0.38, lr: [0.0029710218221087998], Loss: 1.962643, Acc:0.810778, Semantic loss: 0.735597, BCE loss: 0.524948, SB loss: 0.702099
2023-10-30 20:09:46,025 Epoch: [358/484] Iter:[180/495], Time: 0.38, lr: [0.002970591928035537], Loss: 1.957972, Acc:0.809580, Semantic loss: 0.733059, BCE loss: 0.523383, SB loss: 0.701530
2023-10-30 20:09:49,582 Epoch: [358/484] Iter:[190/495], Time: 0.37, lr: [0.002970162027049627], Loss: 1.955197, Acc:0.809768, Semantic loss: 0.732360, BCE loss: 0.522346, SB loss: 0.700491
2023-10-30 20:09:53,349 Epoch: [358/484] Iter:[200/495], Time: 0.37, lr: [0.0029697321191498468], Loss: 1.956360, Acc:0.809544, Semantic loss: 0.731536, BCE loss: 0.525442, SB loss: 0.699383
2023-10-30 20:09:56,912 Epoch: [358/484] Iter:[210/495], Time: 0.37, lr: [0.002969302204334972], Loss: 1.962155, Acc:0.808836, Semantic loss: 0.734140, BCE loss: 0.527308, SB loss: 0.700708
2023-10-30 20:10:00,509 Epoch: [358/484] Iter:[220/495], Time: 0.37, lr: [0.0029688722826037815], Loss: 1.958942, Acc:0.807735, Semantic loss: 0.733706, BCE loss: 0.524921, SB loss: 0.700315
2023-10-30 20:10:04,084 Epoch: [358/484] Iter:[230/495], Time: 0.37, lr: [0.0029684423539550493], Loss: 1.958015, Acc:0.806002, Semantic loss: 0.733635, BCE loss: 0.524264, SB loss: 0.700116
2023-10-30 20:10:07,598 Epoch: [358/484] Iter:[240/495], Time: 0.37, lr: [0.002968012418387552], Loss: 1.955464, Acc:0.806235, Semantic loss: 0.731682, BCE loss: 0.522471, SB loss: 0.701311
2023-10-30 20:10:11,188 Epoch: [358/484] Iter:[250/495], Time: 0.37, lr: [0.002967582475900062], Loss: 1.956885, Acc:0.806070, Semantic loss: 0.732640, BCE loss: 0.522423, SB loss: 0.701821
2023-10-30 20:10:14,829 Epoch: [358/484] Iter:[260/495], Time: 0.37, lr: [0.002967152526491357], Loss: 1.952925, Acc:0.806532, Semantic loss: 0.731360, BCE loss: 0.520085, SB loss: 0.701481
2023-10-30 20:10:18,509 Epoch: [358/484] Iter:[270/495], Time: 0.37, lr: [0.00296672257016021], Loss: 1.948494, Acc:0.807139, Semantic loss: 0.728349, BCE loss: 0.520495, SB loss: 0.699651
2023-10-30 20:10:22,159 Epoch: [358/484] Iter:[280/495], Time: 0.37, lr: [0.0029662926069053954], Loss: 1.950161, Acc:0.806871, Semantic loss: 0.729652, BCE loss: 0.520558, SB loss: 0.699950
2023-10-30 20:10:25,830 Epoch: [358/484] Iter:[290/495], Time: 0.37, lr: [0.002965862636725684], Loss: 1.955145, Acc:0.808496, Semantic loss: 0.730913, BCE loss: 0.523433, SB loss: 0.700800
2023-10-30 20:10:29,467 Epoch: [358/484] Iter:[300/495], Time: 0.37, lr: [0.0029654326596198523], Loss: 1.960396, Acc:0.807939, Semantic loss: 0.733822, BCE loss: 0.524959, SB loss: 0.701614
2023-10-30 20:10:33,049 Epoch: [358/484] Iter:[310/495], Time: 0.37, lr: [0.0029650026755866712], Loss: 1.958514, Acc:0.807550, Semantic loss: 0.732494, BCE loss: 0.524647, SB loss: 0.701373
2023-10-30 20:10:36,744 Epoch: [358/484] Iter:[320/495], Time: 0.37, lr: [0.002964572684624913], Loss: 1.955467, Acc:0.807711, Semantic loss: 0.730520, BCE loss: 0.523185, SB loss: 0.701763
2023-10-30 20:10:40,385 Epoch: [358/484] Iter:[330/495], Time: 0.37, lr: [0.002964142686733348], Loss: 1.953124, Acc:0.808201, Semantic loss: 0.729744, BCE loss: 0.521566, SB loss: 0.701814
2023-10-30 20:10:43,917 Epoch: [358/484] Iter:[340/495], Time: 0.37, lr: [0.0029637126819107504], Loss: 1.955593, Acc:0.808483, Semantic loss: 0.730727, BCE loss: 0.523170, SB loss: 0.701696
2023-10-30 20:10:47,590 Epoch: [358/484] Iter:[350/495], Time: 0.37, lr: [0.00296328267015589], Loss: 1.955410, Acc:0.808973, Semantic loss: 0.729880, BCE loss: 0.524440, SB loss: 0.701090
2023-10-30 20:10:51,157 Epoch: [358/484] Iter:[360/495], Time: 0.37, lr: [0.002962852651467535], Loss: 1.954392, Acc:0.809246, Semantic loss: 0.728179, BCE loss: 0.525163, SB loss: 0.701049
2023-10-30 20:10:54,897 Epoch: [358/484] Iter:[370/495], Time: 0.37, lr: [0.0029624226258444576], Loss: 1.953352, Acc:0.810741, Semantic loss: 0.727519, BCE loss: 0.525540, SB loss: 0.700292
2023-10-30 20:10:58,496 Epoch: [358/484] Iter:[380/495], Time: 0.37, lr: [0.002961992593285428], Loss: 1.952536, Acc:0.811575, Semantic loss: 0.727711, BCE loss: 0.524739, SB loss: 0.700086
2023-10-30 20:11:02,160 Epoch: [358/484] Iter:[390/495], Time: 0.37, lr: [0.002961562553789214], Loss: 1.950286, Acc:0.811698, Semantic loss: 0.727197, BCE loss: 0.523773, SB loss: 0.699316
2023-10-30 20:11:05,728 Epoch: [358/484] Iter:[400/495], Time: 0.37, lr: [0.0029611325073545854], Loss: 1.951772, Acc:0.810820, Semantic loss: 0.728499, BCE loss: 0.523132, SB loss: 0.700140
2023-10-30 20:11:09,354 Epoch: [358/484] Iter:[410/495], Time: 0.37, lr: [0.002960702453980309], Loss: 1.951084, Acc:0.810772, Semantic loss: 0.728528, BCE loss: 0.522489, SB loss: 0.700068
2023-10-30 20:11:12,933 Epoch: [358/484] Iter:[420/495], Time: 0.37, lr: [0.002960272393665155], Loss: 1.953254, Acc:0.810988, Semantic loss: 0.728462, BCE loss: 0.524641, SB loss: 0.700151
2023-10-30 20:11:16,590 Epoch: [358/484] Iter:[430/495], Time: 0.37, lr: [0.0029598423264078893], Loss: 1.956797, Acc:0.810906, Semantic loss: 0.730634, BCE loss: 0.524754, SB loss: 0.701409
2023-10-30 20:11:20,246 Epoch: [358/484] Iter:[440/495], Time: 0.37, lr: [0.0029594122522072796], Loss: 1.958534, Acc:0.810262, Semantic loss: 0.731837, BCE loss: 0.524523, SB loss: 0.702174
2023-10-30 20:11:23,893 Epoch: [358/484] Iter:[450/495], Time: 0.37, lr: [0.0029589821710620918], Loss: 1.958011, Acc:0.809412, Semantic loss: 0.731480, BCE loss: 0.523924, SB loss: 0.702607
2023-10-30 20:11:27,742 Epoch: [358/484] Iter:[460/495], Time: 0.37, lr: [0.0029585520829710945], Loss: 1.958578, Acc:0.810109, Semantic loss: 0.731604, BCE loss: 0.524090, SB loss: 0.702884
2023-10-30 20:11:31,357 Epoch: [358/484] Iter:[470/495], Time: 0.37, lr: [0.002958121987933051], Loss: 1.960736, Acc:0.809981, Semantic loss: 0.732453, BCE loss: 0.524736, SB loss: 0.703547
2023-10-30 20:11:34,994 Epoch: [358/484] Iter:[480/495], Time: 0.37, lr: [0.0029576918859467284], Loss: 1.962162, Acc:0.810257, Semantic loss: 0.732817, BCE loss: 0.525970, SB loss: 0.703376
2023-10-30 20:11:38,483 Epoch: [358/484] Iter:[490/495], Time: 0.37, lr: [0.00295726177701089], Loss: 1.961620, Acc:0.809358, Semantic loss: 0.732886, BCE loss: 0.525324, SB loss: 0.703409
2023-10-30 20:11:39,869 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:11:40,108 Loss: 2.023, MeanIU:  0.7054, Best_mIoU:  0.7309
2023-10-30 20:11:40,108 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238]
2023-10-30 20:11:42,385 Epoch: [359/484] Iter:[0/495], Time: 2.24, lr: [0.0029570467199365176], Loss: 1.698960, Acc:0.816506, Semantic loss: 0.652505, BCE loss: 0.385501, SB loss: 0.660954
2023-10-30 20:11:46,397 Epoch: [359/484] Iter:[10/495], Time: 0.57, lr: [0.0029566166005740913], Loss: 2.065471, Acc:0.829539, Semantic loss: 0.792046, BCE loss: 0.548186, SB loss: 0.725238
2023-10-30 20:11:50,045 Epoch: [359/484] Iter:[20/495], Time: 0.47, lr: [0.0029561864742590617], Loss: 2.013964, Acc:0.834529, Semantic loss: 0.780690, BCE loss: 0.529440, SB loss: 0.703834
2023-10-30 20:11:53,561 Epoch: [359/484] Iter:[30/495], Time: 0.43, lr: [0.0029557563409901904], Loss: 1.966775, Acc:0.827571, Semantic loss: 0.749741, BCE loss: 0.515444, SB loss: 0.701591
2023-10-30 20:11:57,201 Epoch: [359/484] Iter:[40/495], Time: 0.42, lr: [0.002955326200766243], Loss: 1.961705, Acc:0.815891, Semantic loss: 0.740402, BCE loss: 0.509218, SB loss: 0.712085
2023-10-30 20:12:00,750 Epoch: [359/484] Iter:[50/495], Time: 0.40, lr: [0.0029548960535859814], Loss: 1.969629, Acc:0.809756, Semantic loss: 0.742838, BCE loss: 0.509909, SB loss: 0.716882
2023-10-30 20:12:04,290 Epoch: [359/484] Iter:[60/495], Time: 0.40, lr: [0.0029544658994481677], Loss: 1.967038, Acc:0.810272, Semantic loss: 0.741585, BCE loss: 0.511644, SB loss: 0.713809
2023-10-30 20:12:07,960 Epoch: [359/484] Iter:[70/495], Time: 0.39, lr: [0.0029540357383515624], Loss: 1.956808, Acc:0.808549, Semantic loss: 0.733730, BCE loss: 0.512818, SB loss: 0.710260
2023-10-30 20:12:11,574 Epoch: [359/484] Iter:[80/495], Time: 0.39, lr: [0.0029536055702949295], Loss: 1.959824, Acc:0.809502, Semantic loss: 0.732137, BCE loss: 0.518897, SB loss: 0.708791
2023-10-30 20:12:15,308 Epoch: [359/484] Iter:[90/495], Time: 0.39, lr: [0.002953175395277029], Loss: 1.950215, Acc:0.805560, Semantic loss: 0.728796, BCE loss: 0.513880, SB loss: 0.707539
2023-10-30 20:12:18,879 Epoch: [359/484] Iter:[100/495], Time: 0.38, lr: [0.002952745213296621], Loss: 1.958324, Acc:0.803032, Semantic loss: 0.732570, BCE loss: 0.515789, SB loss: 0.709965
2023-10-30 20:12:22,588 Epoch: [359/484] Iter:[110/495], Time: 0.38, lr: [0.0029523150243524654], Loss: 1.957886, Acc:0.803466, Semantic loss: 0.734481, BCE loss: 0.514439, SB loss: 0.708966
2023-10-30 20:12:26,304 Epoch: [359/484] Iter:[120/495], Time: 0.38, lr: [0.0029518848284433236], Loss: 1.966327, Acc:0.806079, Semantic loss: 0.737765, BCE loss: 0.520481, SB loss: 0.708081
2023-10-30 20:12:29,855 Epoch: [359/484] Iter:[130/495], Time: 0.38, lr: [0.0029514546255679543], Loss: 1.975482, Acc:0.808652, Semantic loss: 0.744925, BCE loss: 0.519515, SB loss: 0.711042
2023-10-30 20:12:33,467 Epoch: [359/484] Iter:[140/495], Time: 0.38, lr: [0.002951024415725116], Loss: 1.977289, Acc:0.804596, Semantic loss: 0.739884, BCE loss: 0.521499, SB loss: 0.715907
2023-10-30 20:12:37,063 Epoch: [359/484] Iter:[150/495], Time: 0.38, lr: [0.0029505941989135666], Loss: 1.973064, Acc:0.802132, Semantic loss: 0.739204, BCE loss: 0.518687, SB loss: 0.715173
2023-10-30 20:12:40,753 Epoch: [359/484] Iter:[160/495], Time: 0.38, lr: [0.002950163975132066], Loss: 1.965680, Acc:0.803458, Semantic loss: 0.734283, BCE loss: 0.518232, SB loss: 0.713165
2023-10-30 20:12:44,334 Epoch: [359/484] Iter:[170/495], Time: 0.38, lr: [0.00294973374437937], Loss: 1.972842, Acc:0.801597, Semantic loss: 0.738018, BCE loss: 0.520322, SB loss: 0.714503
2023-10-30 20:12:47,892 Epoch: [359/484] Iter:[180/495], Time: 0.37, lr: [0.002949303506654238], Loss: 1.984026, Acc:0.801518, Semantic loss: 0.741698, BCE loss: 0.525435, SB loss: 0.716893
2023-10-30 20:12:51,548 Epoch: [359/484] Iter:[190/495], Time: 0.37, lr: [0.002948873261955424], Loss: 1.986300, Acc:0.800852, Semantic loss: 0.744493, BCE loss: 0.523097, SB loss: 0.718711
2023-10-30 20:12:55,225 Epoch: [359/484] Iter:[200/495], Time: 0.37, lr: [0.0029484430102816868], Loss: 1.986278, Acc:0.801105, Semantic loss: 0.743868, BCE loss: 0.523981, SB loss: 0.718429
2023-10-30 20:12:58,850 Epoch: [359/484] Iter:[210/495], Time: 0.37, lr: [0.002948012751631782], Loss: 1.980834, Acc:0.801302, Semantic loss: 0.738890, BCE loss: 0.524549, SB loss: 0.717395
2023-10-30 20:13:02,524 Epoch: [359/484] Iter:[220/495], Time: 0.37, lr: [0.0029475824860044648], Loss: 1.983163, Acc:0.799580, Semantic loss: 0.740148, BCE loss: 0.526042, SB loss: 0.716974
2023-10-30 20:13:06,176 Epoch: [359/484] Iter:[230/495], Time: 0.37, lr: [0.0029471522133984883], Loss: 1.975828, Acc:0.799049, Semantic loss: 0.737085, BCE loss: 0.523483, SB loss: 0.715260
2023-10-30 20:13:09,840 Epoch: [359/484] Iter:[240/495], Time: 0.37, lr: [0.0029467219338126112], Loss: 1.977409, Acc:0.799017, Semantic loss: 0.736659, BCE loss: 0.525785, SB loss: 0.714965
2023-10-30 20:13:13,502 Epoch: [359/484] Iter:[250/495], Time: 0.37, lr: [0.0029462916472455854], Loss: 1.973526, Acc:0.799187, Semantic loss: 0.734874, BCE loss: 0.525088, SB loss: 0.713564
2023-10-30 20:13:17,120 Epoch: [359/484] Iter:[260/495], Time: 0.37, lr: [0.0029458613536961654], Loss: 1.971721, Acc:0.800631, Semantic loss: 0.734999, BCE loss: 0.524069, SB loss: 0.712654
2023-10-30 20:13:20,829 Epoch: [359/484] Iter:[270/495], Time: 0.37, lr: [0.002945431053163103], Loss: 1.967378, Acc:0.800793, Semantic loss: 0.732468, BCE loss: 0.523633, SB loss: 0.711277
2023-10-30 20:13:24,486 Epoch: [359/484] Iter:[280/495], Time: 0.37, lr: [0.0029450007456451534], Loss: 1.973722, Acc:0.802162, Semantic loss: 0.735738, BCE loss: 0.525414, SB loss: 0.712570
2023-10-30 20:13:28,114 Epoch: [359/484] Iter:[290/495], Time: 0.37, lr: [0.0029445704311410687], Loss: 1.972865, Acc:0.802821, Semantic loss: 0.735824, BCE loss: 0.524884, SB loss: 0.712157
2023-10-30 20:13:31,711 Epoch: [359/484] Iter:[300/495], Time: 0.37, lr: [0.0029441401096496006], Loss: 1.971615, Acc:0.803790, Semantic loss: 0.735474, BCE loss: 0.524826, SB loss: 0.711316
2023-10-30 20:13:35,440 Epoch: [359/484] Iter:[310/495], Time: 0.37, lr: [0.0029437097811695], Loss: 1.967849, Acc:0.802671, Semantic loss: 0.734113, BCE loss: 0.523067, SB loss: 0.710670
2023-10-30 20:13:39,070 Epoch: [359/484] Iter:[320/495], Time: 0.37, lr: [0.00294327944569952], Loss: 1.969134, Acc:0.803353, Semantic loss: 0.735067, BCE loss: 0.524106, SB loss: 0.709961
2023-10-30 20:13:42,726 Epoch: [359/484] Iter:[330/495], Time: 0.37, lr: [0.002942849103238411], Loss: 1.967548, Acc:0.803466, Semantic loss: 0.734796, BCE loss: 0.523526, SB loss: 0.709226
2023-10-30 20:13:46,333 Epoch: [359/484] Iter:[340/495], Time: 0.37, lr: [0.002942418753784922], Loss: 1.971024, Acc:0.803911, Semantic loss: 0.735522, BCE loss: 0.525289, SB loss: 0.710213
2023-10-30 20:13:49,932 Epoch: [359/484] Iter:[350/495], Time: 0.37, lr: [0.002941988397337804], Loss: 1.970832, Acc:0.803778, Semantic loss: 0.734454, BCE loss: 0.526119, SB loss: 0.710259
2023-10-30 20:13:53,636 Epoch: [359/484] Iter:[360/495], Time: 0.37, lr: [0.002941558033895808], Loss: 1.966281, Acc:0.803293, Semantic loss: 0.732593, BCE loss: 0.525092, SB loss: 0.708595
2023-10-30 20:13:57,354 Epoch: [359/484] Iter:[370/495], Time: 0.37, lr: [0.0029411276634576816], Loss: 1.964941, Acc:0.804035, Semantic loss: 0.731725, BCE loss: 0.525119, SB loss: 0.708097
2023-10-30 20:14:01,018 Epoch: [359/484] Iter:[380/495], Time: 0.37, lr: [0.002940697286022174], Loss: 1.960912, Acc:0.803869, Semantic loss: 0.730536, BCE loss: 0.523536, SB loss: 0.706840
2023-10-30 20:14:04,678 Epoch: [359/484] Iter:[390/495], Time: 0.37, lr: [0.0029402669015880325], Loss: 1.961792, Acc:0.803259, Semantic loss: 0.731168, BCE loss: 0.524081, SB loss: 0.706543
2023-10-30 20:14:08,341 Epoch: [359/484] Iter:[400/495], Time: 0.37, lr: [0.0029398365101540066], Loss: 1.958522, Acc:0.803094, Semantic loss: 0.729594, BCE loss: 0.523725, SB loss: 0.705203
2023-10-30 20:14:11,949 Epoch: [359/484] Iter:[410/495], Time: 0.37, lr: [0.0029394061117188433], Loss: 1.958090, Acc:0.802111, Semantic loss: 0.731148, BCE loss: 0.521884, SB loss: 0.705058
2023-10-30 20:14:15,611 Epoch: [359/484] Iter:[420/495], Time: 0.37, lr: [0.002938975706281289], Loss: 1.956947, Acc:0.802086, Semantic loss: 0.730995, BCE loss: 0.520826, SB loss: 0.705126
2023-10-30 20:14:19,299 Epoch: [359/484] Iter:[430/495], Time: 0.37, lr: [0.0029385452938400897], Loss: 1.958004, Acc:0.802102, Semantic loss: 0.732730, BCE loss: 0.519399, SB loss: 0.705875
2023-10-30 20:14:22,932 Epoch: [359/484] Iter:[440/495], Time: 0.37, lr: [0.0029381148743939938], Loss: 1.960958, Acc:0.801894, Semantic loss: 0.732873, BCE loss: 0.521179, SB loss: 0.706907
2023-10-30 20:14:26,594 Epoch: [359/484] Iter:[450/495], Time: 0.37, lr: [0.0029376844479417456], Loss: 1.961035, Acc:0.801611, Semantic loss: 0.732455, BCE loss: 0.522167, SB loss: 0.706413
2023-10-30 20:14:30,228 Epoch: [359/484] Iter:[460/495], Time: 0.37, lr: [0.0029372540144820916], Loss: 1.961090, Acc:0.801840, Semantic loss: 0.732001, BCE loss: 0.522730, SB loss: 0.706359
2023-10-30 20:14:33,855 Epoch: [359/484] Iter:[470/495], Time: 0.37, lr: [0.002936823574013774], Loss: 1.961348, Acc:0.801881, Semantic loss: 0.731562, BCE loss: 0.523145, SB loss: 0.706641
2023-10-30 20:14:37,401 Epoch: [359/484] Iter:[480/495], Time: 0.37, lr: [0.0029363931265355405], Loss: 1.965413, Acc:0.801929, Semantic loss: 0.733622, BCE loss: 0.524178, SB loss: 0.707613
2023-10-30 20:14:40,809 Epoch: [359/484] Iter:[490/495], Time: 0.37, lr: [0.002935962672046133], Loss: 1.962894, Acc:0.802378, Semantic loss: 0.732457, BCE loss: 0.523854, SB loss: 0.706583
2023-10-30 20:14:42,185 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:14:42,425 Loss: 2.023, MeanIU:  0.7054, Best_mIoU:  0.7309
2023-10-30 20:14:42,425 [0.97341319 0.79833179 0.91512943 0.36188798 0.54134392 0.6006969
 0.69020866 0.75167353 0.91423889 0.61283274 0.94297027 0.79555573
 0.59297295 0.93214955 0.52805379 0.6484008  0.50446591 0.5522787
 0.74511238]
2023-10-30 20:14:44,864 Epoch: [360/484] Iter:[0/495], Time: 2.41, lr: [0.0029357474421718467], Loss: 1.640121, Acc:0.766784, Semantic loss: 0.636961, BCE loss: 0.302740, SB loss: 0.700420
2023-10-30 20:14:48,769 Epoch: [360/484] Iter:[10/495], Time: 0.57, lr: [0.002935316977163323], Loss: 1.853432, Acc:0.834923, Semantic loss: 0.692672, BCE loss: 0.464153, SB loss: 0.696607
2023-10-30 20:14:52,564 Epoch: [360/484] Iter:[20/495], Time: 0.48, lr: [0.002934886505140485], Loss: 1.920581, Acc:0.845766, Semantic loss: 0.729609, BCE loss: 0.493925, SB loss: 0.697047
2023-10-30 20:14:56,149 Epoch: [360/484] Iter:[30/495], Time: 0.44, lr: [0.0029344560261020743], Loss: 1.936770, Acc:0.834087, Semantic loss: 0.718546, BCE loss: 0.515126, SB loss: 0.703098
2023-10-30 20:14:59,754 Epoch: [360/484] Iter:[40/495], Time: 0.42, lr: [0.002934025540046833], Loss: 1.941555, Acc:0.832362, Semantic loss: 0.728100, BCE loss: 0.510201, SB loss: 0.703255
2023-10-30 20:15:03,333 Epoch: [360/484] Iter:[50/495], Time: 0.41, lr: [0.002933595046973502], Loss: 1.943421, Acc:0.826354, Semantic loss: 0.727212, BCE loss: 0.513615, SB loss: 0.702594
2023-10-30 20:15:07,013 Epoch: [360/484] Iter:[60/495], Time: 0.40, lr: [0.0029331645468808247], Loss: 1.945735, Acc:0.830377, Semantic loss: 0.726273, BCE loss: 0.520882, SB loss: 0.698580
2023-10-30 20:15:10,687 Epoch: [360/484] Iter:[70/495], Time: 0.40, lr: [0.0029327340397675406], Loss: 1.942029, Acc:0.828900, Semantic loss: 0.725961, BCE loss: 0.517678, SB loss: 0.698390
2023-10-30 20:15:14,302 Epoch: [360/484] Iter:[80/495], Time: 0.39, lr: [0.00293230352563239], Loss: 1.946282, Acc:0.824383, Semantic loss: 0.728908, BCE loss: 0.517236, SB loss: 0.700138
2023-10-30 20:15:17,980 Epoch: [360/484] Iter:[90/495], Time: 0.39, lr: [0.0029318730044741123], Loss: 1.943296, Acc:0.824604, Semantic loss: 0.725106, BCE loss: 0.517756, SB loss: 0.700434
2023-10-30 20:15:21,652 Epoch: [360/484] Iter:[100/495], Time: 0.39, lr: [0.0029314424762914484], Loss: 1.956352, Acc:0.820984, Semantic loss: 0.731368, BCE loss: 0.521911, SB loss: 0.703073
2023-10-30 20:15:25,287 Epoch: [360/484] Iter:[110/495], Time: 0.39, lr: [0.0029310119410831366], Loss: 1.953651, Acc:0.824030, Semantic loss: 0.729316, BCE loss: 0.520928, SB loss: 0.703408
2023-10-30 20:15:28,940 Epoch: [360/484] Iter:[120/495], Time: 0.38, lr: [0.002930581398847916], Loss: 1.961878, Acc:0.821045, Semantic loss: 0.737906, BCE loss: 0.517702, SB loss: 0.706270
2023-10-30 20:15:32,558 Epoch: [360/484] Iter:[130/495], Time: 0.38, lr: [0.0029301508495845232], Loss: 1.961440, Acc:0.818254, Semantic loss: 0.739240, BCE loss: 0.515449, SB loss: 0.706751
2023-10-30 20:15:36,167 Epoch: [360/484] Iter:[140/495], Time: 0.38, lr: [0.0029297202932916985], Loss: 1.969619, Acc:0.815530, Semantic loss: 0.745365, BCE loss: 0.515127, SB loss: 0.709127
2023-10-30 20:15:39,788 Epoch: [360/484] Iter:[150/495], Time: 0.38, lr: [0.0029292897299681778], Loss: 1.970960, Acc:0.814171, Semantic loss: 0.745794, BCE loss: 0.514072, SB loss: 0.711094
2023-10-30 20:15:43,365 Epoch: [360/484] Iter:[160/495], Time: 0.38, lr: [0.0029288591596126983], Loss: 1.974198, Acc:0.811754, Semantic loss: 0.748448, BCE loss: 0.514195, SB loss: 0.711556
2023-10-30 20:15:47,152 Epoch: [360/484] Iter:[170/495], Time: 0.38, lr: [0.0029284285822239954], Loss: 1.978355, Acc:0.811157, Semantic loss: 0.751783, BCE loss: 0.514519, SB loss: 0.712052
2023-10-30 20:15:50,842 Epoch: [360/484] Iter:[180/495], Time: 0.38, lr: [0.002927997997800807], Loss: 1.973887, Acc:0.809274, Semantic loss: 0.750963, BCE loss: 0.512596, SB loss: 0.710327
2023-10-30 20:15:54,467 Epoch: [360/484] Iter:[190/495], Time: 0.38, lr: [0.0029275674063418684], Loss: 1.968163, Acc:0.808049, Semantic loss: 0.747110, BCE loss: 0.511769, SB loss: 0.709284
2023-10-30 20:15:58,172 Epoch: [360/484] Iter:[200/495], Time: 0.38, lr: [0.0029271368078459137], Loss: 1.974120, Acc:0.806447, Semantic loss: 0.750706, BCE loss: 0.512775, SB loss: 0.710639
2023-10-30 20:16:01,828 Epoch: [360/484] Iter:[210/495], Time: 0.38, lr: [0.0029267062023116777], Loss: 1.969823, Acc:0.806220, Semantic loss: 0.746707, BCE loss: 0.512977, SB loss: 0.710138
2023-10-30 20:16:05,484 Epoch: [360/484] Iter:[220/495], Time: 0.38, lr: [0.0029262755897378956], Loss: 1.973276, Acc:0.805806, Semantic loss: 0.745361, BCE loss: 0.517460, SB loss: 0.710455
2023-10-30 20:16:09,139 Epoch: [360/484] Iter:[230/495], Time: 0.38, lr: [0.0029258449701233015], Loss: 1.967082, Acc:0.806690, Semantic loss: 0.741277, BCE loss: 0.516603, SB loss: 0.709202
2023-10-30 20:16:12,829 Epoch: [360/484] Iter:[240/495], Time: 0.37, lr: [0.002925414343466628], Loss: 1.969143, Acc:0.807105, Semantic loss: 0.742475, BCE loss: 0.517478, SB loss: 0.709190
2023-10-30 20:16:16,384 Epoch: [360/484] Iter:[250/495], Time: 0.37, lr: [0.002924983709766608], Loss: 1.976255, Acc:0.806334, Semantic loss: 0.747763, BCE loss: 0.518294, SB loss: 0.710198
2023-10-30 20:16:19,997 Epoch: [360/484] Iter:[260/495], Time: 0.37, lr: [0.002924553069021975], Loss: 1.974914, Acc:0.806069, Semantic loss: 0.746453, BCE loss: 0.518763, SB loss: 0.709699
2023-10-30 20:16:23,603 Epoch: [360/484] Iter:[270/495], Time: 0.37, lr: [0.0029241224212314607], Loss: 1.971702, Acc:0.806508, Semantic loss: 0.743745, BCE loss: 0.518956, SB loss: 0.709001
2023-10-30 20:16:27,151 Epoch: [360/484] Iter:[280/495], Time: 0.37, lr: [0.002923691766393797], Loss: 1.968279, Acc:0.805958, Semantic loss: 0.741240, BCE loss: 0.517572, SB loss: 0.709467
2023-10-30 20:16:30,840 Epoch: [360/484] Iter:[290/495], Time: 0.37, lr: [0.0029232611045077136], Loss: 1.967875, Acc:0.806197, Semantic loss: 0.741364, BCE loss: 0.516706, SB loss: 0.709806
2023-10-30 20:16:34,537 Epoch: [360/484] Iter:[300/495], Time: 0.37, lr: [0.002922830435571943], Loss: 1.963712, Acc:0.806407, Semantic loss: 0.739379, BCE loss: 0.515213, SB loss: 0.709119
2023-10-30 20:16:38,224 Epoch: [360/484] Iter:[310/495], Time: 0.37, lr: [0.0029223997595852163], Loss: 1.965170, Acc:0.805321, Semantic loss: 0.739950, BCE loss: 0.515463, SB loss: 0.709757
2023-10-30 20:16:41,877 Epoch: [360/484] Iter:[320/495], Time: 0.37, lr: [0.002921969076546262], Loss: 1.964405, Acc:0.804975, Semantic loss: 0.739380, BCE loss: 0.515549, SB loss: 0.709476
2023-10-30 20:16:45,611 Epoch: [360/484] Iter:[330/495], Time: 0.37, lr: [0.002921538386453809], Loss: 1.964832, Acc:0.806278, Semantic loss: 0.739655, BCE loss: 0.516627, SB loss: 0.708550
2023-10-30 20:16:49,370 Epoch: [360/484] Iter:[340/495], Time: 0.37, lr: [0.0029211076893065884], Loss: 1.961558, Acc:0.806387, Semantic loss: 0.737749, BCE loss: 0.515919, SB loss: 0.707890
2023-10-30 20:16:53,011 Epoch: [360/484] Iter:[350/495], Time: 0.37, lr: [0.0029206769851033284], Loss: 1.964539, Acc:0.806432, Semantic loss: 0.740782, BCE loss: 0.515924, SB loss: 0.707834
2023-10-30 20:16:56,717 Epoch: [360/484] Iter:[360/495], Time: 0.37, lr: [0.002920246273842756], Loss: 1.963116, Acc:0.805274, Semantic loss: 0.740584, BCE loss: 0.514264, SB loss: 0.708268
2023-10-30 20:17:00,324 Epoch: [360/484] Iter:[370/495], Time: 0.37, lr: [0.002919815555523599], Loss: 1.963537, Acc:0.804581, Semantic loss: 0.739724, BCE loss: 0.515343, SB loss: 0.708471
2023-10-30 20:17:03,942 Epoch: [360/484] Iter:[380/495], Time: 0.37, lr: [0.0029193848301445856], Loss: 1.966047, Acc:0.804902, Semantic loss: 0.739374, BCE loss: 0.517952, SB loss: 0.708720
2023-10-30 20:17:07,606 Epoch: [360/484] Iter:[390/495], Time: 0.37, lr: [0.0029189540977044436], Loss: 1.966365, Acc:0.805214, Semantic loss: 0.740037, BCE loss: 0.516693, SB loss: 0.709636
2023-10-30 20:17:11,317 Epoch: [360/484] Iter:[400/495], Time: 0.37, lr: [0.0029185233582018984], Loss: 1.968295, Acc:0.804975, Semantic loss: 0.740833, BCE loss: 0.517554, SB loss: 0.709907
2023-10-30 20:17:14,954 Epoch: [360/484] Iter:[410/495], Time: 0.37, lr: [0.002918092611635674], Loss: 1.969144, Acc:0.804250, Semantic loss: 0.740583, BCE loss: 0.518156, SB loss: 0.710405
2023-10-30 20:17:18,549 Epoch: [360/484] Iter:[420/495], Time: 0.37, lr: [0.0029176618580044993], Loss: 1.966078, Acc:0.804048, Semantic loss: 0.739112, BCE loss: 0.517202, SB loss: 0.709765
2023-10-30 20:17:22,261 Epoch: [360/484] Iter:[430/495], Time: 0.37, lr: [0.0029172310973070987], Loss: 1.964062, Acc:0.803824, Semantic loss: 0.738077, BCE loss: 0.516668, SB loss: 0.709317
2023-10-30 20:17:25,864 Epoch: [360/484] Iter:[440/495], Time: 0.37, lr: [0.002916800329542196], Loss: 1.966477, Acc:0.804781, Semantic loss: 0.738733, BCE loss: 0.518334, SB loss: 0.709410
2023-10-30 20:17:29,481 Epoch: [360/484] Iter:[450/495], Time: 0.37, lr: [0.0029163695547085146], Loss: 1.966675, Acc:0.804894, Semantic loss: 0.738729, BCE loss: 0.518504, SB loss: 0.709442
2023-10-30 20:17:33,067 Epoch: [360/484] Iter:[460/495], Time: 0.37, lr: [0.002915938772804781], Loss: 1.967486, Acc:0.804508, Semantic loss: 0.739588, BCE loss: 0.518428, SB loss: 0.709470
2023-10-30 20:17:36,660 Epoch: [360/484] Iter:[470/495], Time: 0.37, lr: [0.0029155079838297164], Loss: 1.965844, Acc:0.804739, Semantic loss: 0.738994, BCE loss: 0.518115, SB loss: 0.708735
2023-10-30 20:17:40,307 Epoch: [360/484] Iter:[480/495], Time: 0.37, lr: [0.002915077187782045], Loss: 1.965673, Acc:0.804350, Semantic loss: 0.739357, BCE loss: 0.517413, SB loss: 0.708902
2023-10-30 20:17:43,755 Epoch: [360/484] Iter:[490/495], Time: 0.37, lr: [0.0029146463846604874], Loss: 1.965149, Acc:0.804356, Semantic loss: 0.738743, BCE loss: 0.517856, SB loss: 0.708551
2023-10-30 20:20:40,899 0 [9.49033548e-01 6.76347611e-01 8.46980223e-01 1.59298633e-01
 2.94075835e-01 4.37340669e-01 4.94262747e-01 6.13566176e-01
 8.91749351e-01 4.71754561e-01 8.89494340e-01 6.25592604e-01
 4.35642650e-02 8.39374724e-01 7.07512619e-04 1.81905111e-01
 1.07304345e-01 7.67574000e-02 6.34768418e-01] 0.4859935828026764
2023-10-30 20:20:40,899 1 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697] 0.7289033817843629
2023-10-30 20:20:40,903 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:20:41,143 Loss: 1.993, MeanIU:  0.7289, Best_mIoU:  0.7309
2023-10-30 20:20:41,143 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697]
2023-10-30 20:20:43,243 Epoch: [361/484] Iter:[0/495], Time: 2.07, lr: [0.002914430980446603], Loss: 2.073196, Acc:0.870148, Semantic loss: 0.785388, BCE loss: 0.523141, SB loss: 0.764667
2023-10-30 20:20:47,140 Epoch: [361/484] Iter:[10/495], Time: 0.54, lr: [0.002914000166711823], Loss: 2.063741, Acc:0.822383, Semantic loss: 0.817955, BCE loss: 0.536356, SB loss: 0.709429
2023-10-30 20:20:50,646 Epoch: [361/484] Iter:[20/495], Time: 0.45, lr: [0.0029135693458999627], Loss: 1.936134, Acc:0.809149, Semantic loss: 0.748381, BCE loss: 0.493742, SB loss: 0.694012
2023-10-30 20:20:54,161 Epoch: [361/484] Iter:[30/495], Time: 0.42, lr: [0.002913138518009742], Loss: 1.922237, Acc:0.806939, Semantic loss: 0.730520, BCE loss: 0.500170, SB loss: 0.691547
2023-10-30 20:20:57,700 Epoch: [361/484] Iter:[40/495], Time: 0.40, lr: [0.002912707683039883], Loss: 1.940342, Acc:0.806310, Semantic loss: 0.731646, BCE loss: 0.509972, SB loss: 0.698724
2023-10-30 20:21:01,281 Epoch: [361/484] Iter:[50/495], Time: 0.39, lr: [0.002912276840989105], Loss: 1.919968, Acc:0.808258, Semantic loss: 0.722523, BCE loss: 0.503589, SB loss: 0.693856
2023-10-30 20:21:04,864 Epoch: [361/484] Iter:[60/495], Time: 0.39, lr: [0.0029118459918561278], Loss: 1.974289, Acc:0.810836, Semantic loss: 0.743642, BCE loss: 0.529044, SB loss: 0.701603
2023-10-30 20:21:08,456 Epoch: [361/484] Iter:[70/495], Time: 0.38, lr: [0.0029114151356396697], Loss: 1.975264, Acc:0.809172, Semantic loss: 0.739018, BCE loss: 0.531411, SB loss: 0.704835
2023-10-30 20:21:11,993 Epoch: [361/484] Iter:[80/495], Time: 0.38, lr: [0.002910984272338451], Loss: 1.986334, Acc:0.809318, Semantic loss: 0.741490, BCE loss: 0.536556, SB loss: 0.708289
2023-10-30 20:21:15,516 Epoch: [361/484] Iter:[90/495], Time: 0.38, lr: [0.002910553401951189], Loss: 1.994170, Acc:0.810035, Semantic loss: 0.745792, BCE loss: 0.537493, SB loss: 0.710884
2023-10-30 20:21:18,993 Epoch: [361/484] Iter:[100/495], Time: 0.37, lr: [0.0029101225244766026], Loss: 1.996553, Acc:0.812161, Semantic loss: 0.746829, BCE loss: 0.539262, SB loss: 0.710462
2023-10-30 20:21:22,573 Epoch: [361/484] Iter:[110/495], Time: 0.37, lr: [0.0029096916399134064], Loss: 1.991129, Acc:0.807713, Semantic loss: 0.744769, BCE loss: 0.534180, SB loss: 0.712180
2023-10-30 20:21:26,239 Epoch: [361/484] Iter:[120/495], Time: 0.37, lr: [0.0029092607482603216], Loss: 1.983510, Acc:0.807204, Semantic loss: 0.741201, BCE loss: 0.531876, SB loss: 0.710433
2023-10-30 20:21:29,691 Epoch: [361/484] Iter:[130/495], Time: 0.37, lr: [0.002908829849516062], Loss: 1.984018, Acc:0.807472, Semantic loss: 0.741457, BCE loss: 0.531676, SB loss: 0.710885
2023-10-30 20:21:33,256 Epoch: [361/484] Iter:[140/495], Time: 0.37, lr: [0.0029083989436793447], Loss: 1.978333, Acc:0.805802, Semantic loss: 0.739232, BCE loss: 0.529259, SB loss: 0.709842
2023-10-30 20:21:36,856 Epoch: [361/484] Iter:[150/495], Time: 0.37, lr: [0.002907968030748883], Loss: 1.976976, Acc:0.805429, Semantic loss: 0.738658, BCE loss: 0.529469, SB loss: 0.708849
2023-10-30 20:21:40,441 Epoch: [361/484] Iter:[160/495], Time: 0.37, lr: [0.002907537110723396], Loss: 1.975000, Acc:0.803825, Semantic loss: 0.736543, BCE loss: 0.530976, SB loss: 0.707482
2023-10-30 20:21:44,082 Epoch: [361/484] Iter:[170/495], Time: 0.37, lr: [0.0029071061836015966], Loss: 1.974558, Acc:0.804320, Semantic loss: 0.736455, BCE loss: 0.530876, SB loss: 0.707227
2023-10-30 20:21:47,762 Epoch: [361/484] Iter:[180/495], Time: 0.37, lr: [0.0029066752493821985], Loss: 1.967969, Acc:0.805914, Semantic loss: 0.733007, BCE loss: 0.530281, SB loss: 0.704681
2023-10-30 20:21:51,361 Epoch: [361/484] Iter:[190/495], Time: 0.37, lr: [0.002906244308063915], Loss: 1.971961, Acc:0.803313, Semantic loss: 0.736280, BCE loss: 0.528791, SB loss: 0.706891
2023-10-30 20:21:54,903 Epoch: [361/484] Iter:[200/495], Time: 0.37, lr: [0.0029058133596454624], Loss: 1.976972, Acc:0.802573, Semantic loss: 0.738005, BCE loss: 0.531600, SB loss: 0.707367
2023-10-30 20:21:58,598 Epoch: [361/484] Iter:[210/495], Time: 0.37, lr: [0.002905382404125551], Loss: 1.977104, Acc:0.803111, Semantic loss: 0.739375, BCE loss: 0.531426, SB loss: 0.706303
2023-10-30 20:22:02,196 Epoch: [361/484] Iter:[220/495], Time: 0.37, lr: [0.002904951441502895], Loss: 1.977541, Acc:0.804829, Semantic loss: 0.739357, BCE loss: 0.531134, SB loss: 0.707049
2023-10-30 20:22:05,799 Epoch: [361/484] Iter:[230/495], Time: 0.37, lr: [0.0029045204717762043], Loss: 1.976103, Acc:0.805822, Semantic loss: 0.737324, BCE loss: 0.532669, SB loss: 0.706109
2023-10-30 20:22:09,469 Epoch: [361/484] Iter:[240/495], Time: 0.37, lr: [0.002904089494944193], Loss: 1.974076, Acc:0.806095, Semantic loss: 0.736399, BCE loss: 0.532063, SB loss: 0.705614
2023-10-30 20:22:12,977 Epoch: [361/484] Iter:[250/495], Time: 0.37, lr: [0.002903658511005571], Loss: 1.971075, Acc:0.806784, Semantic loss: 0.735042, BCE loss: 0.531460, SB loss: 0.704573
2023-10-30 20:22:16,596 Epoch: [361/484] Iter:[260/495], Time: 0.37, lr: [0.00290322751995905], Loss: 1.968515, Acc:0.806621, Semantic loss: 0.734441, BCE loss: 0.530254, SB loss: 0.703820
2023-10-30 20:22:20,270 Epoch: [361/484] Iter:[270/495], Time: 0.37, lr: [0.002902796521803339], Loss: 1.966258, Acc:0.806639, Semantic loss: 0.733118, BCE loss: 0.530119, SB loss: 0.703020
2023-10-30 20:22:23,911 Epoch: [361/484] Iter:[280/495], Time: 0.37, lr: [0.0029023655165371486], Loss: 1.965294, Acc:0.806077, Semantic loss: 0.732422, BCE loss: 0.529859, SB loss: 0.703014
2023-10-30 20:22:27,449 Epoch: [361/484] Iter:[290/495], Time: 0.37, lr: [0.002901934504159189], Loss: 1.963881, Acc:0.806474, Semantic loss: 0.733068, BCE loss: 0.528089, SB loss: 0.702724
2023-10-30 20:22:31,024 Epoch: [361/484] Iter:[300/495], Time: 0.36, lr: [0.0029015034846681677], Loss: 1.960989, Acc:0.806897, Semantic loss: 0.731873, BCE loss: 0.526995, SB loss: 0.702121
2023-10-30 20:22:34,595 Epoch: [361/484] Iter:[310/495], Time: 0.36, lr: [0.0029010724580627928], Loss: 1.961736, Acc:0.807621, Semantic loss: 0.732723, BCE loss: 0.527009, SB loss: 0.702004
2023-10-30 20:22:38,234 Epoch: [361/484] Iter:[320/495], Time: 0.36, lr: [0.0029006414243417746], Loss: 1.961950, Acc:0.807841, Semantic loss: 0.734148, BCE loss: 0.525671, SB loss: 0.702131
2023-10-30 20:22:41,894 Epoch: [361/484] Iter:[330/495], Time: 0.36, lr: [0.0029002103835038197], Loss: 1.961427, Acc:0.807399, Semantic loss: 0.733286, BCE loss: 0.525857, SB loss: 0.702284
2023-10-30 20:22:45,565 Epoch: [361/484] Iter:[340/495], Time: 0.36, lr: [0.002899779335547634], Loss: 1.957118, Acc:0.807655, Semantic loss: 0.731555, BCE loss: 0.524747, SB loss: 0.700816
2023-10-30 20:22:49,198 Epoch: [361/484] Iter:[350/495], Time: 0.36, lr: [0.0028993482804719256], Loss: 1.959245, Acc:0.808055, Semantic loss: 0.732257, BCE loss: 0.526580, SB loss: 0.700408
2023-10-30 20:22:52,865 Epoch: [361/484] Iter:[360/495], Time: 0.36, lr: [0.0028989172182754016], Loss: 1.957228, Acc:0.807734, Semantic loss: 0.732041, BCE loss: 0.524359, SB loss: 0.700828
2023-10-30 20:22:56,499 Epoch: [361/484] Iter:[370/495], Time: 0.36, lr: [0.002898486148956766], Loss: 1.959581, Acc:0.807442, Semantic loss: 0.732930, BCE loss: 0.525869, SB loss: 0.700782
2023-10-30 20:23:00,257 Epoch: [361/484] Iter:[380/495], Time: 0.37, lr: [0.0028980550725147243], Loss: 1.959957, Acc:0.807854, Semantic loss: 0.732531, BCE loss: 0.526725, SB loss: 0.700701
2023-10-30 20:23:03,847 Epoch: [361/484] Iter:[390/495], Time: 0.36, lr: [0.002897623988947983], Loss: 1.957455, Acc:0.807946, Semantic loss: 0.731437, BCE loss: 0.525902, SB loss: 0.700116
2023-10-30 20:23:07,374 Epoch: [361/484] Iter:[400/495], Time: 0.36, lr: [0.002897192898255246], Loss: 1.955844, Acc:0.808357, Semantic loss: 0.730959, BCE loss: 0.525422, SB loss: 0.699464
2023-10-30 20:23:11,174 Epoch: [361/484] Iter:[410/495], Time: 0.36, lr: [0.0028967618004352162], Loss: 1.959014, Acc:0.808083, Semantic loss: 0.732439, BCE loss: 0.526540, SB loss: 0.700035
2023-10-30 20:23:14,739 Epoch: [361/484] Iter:[420/495], Time: 0.36, lr: [0.0028963306954865975], Loss: 1.962843, Acc:0.808302, Semantic loss: 0.734755, BCE loss: 0.527504, SB loss: 0.700584
2023-10-30 20:23:18,424 Epoch: [361/484] Iter:[430/495], Time: 0.36, lr: [0.0028958995834080944], Loss: 1.962409, Acc:0.808206, Semantic loss: 0.735030, BCE loss: 0.527047, SB loss: 0.700332
2023-10-30 20:23:22,017 Epoch: [361/484] Iter:[440/495], Time: 0.36, lr: [0.0028954684641984084], Loss: 1.962801, Acc:0.808364, Semantic loss: 0.734186, BCE loss: 0.528534, SB loss: 0.700082
2023-10-30 20:23:25,690 Epoch: [361/484] Iter:[450/495], Time: 0.36, lr: [0.002895037337856242], Loss: 1.961036, Acc:0.808217, Semantic loss: 0.733756, BCE loss: 0.527435, SB loss: 0.699846
2023-10-30 20:23:29,376 Epoch: [361/484] Iter:[460/495], Time: 0.36, lr: [0.0028946062043802966], Loss: 1.959811, Acc:0.808108, Semantic loss: 0.733193, BCE loss: 0.527125, SB loss: 0.699494
2023-10-30 20:23:33,054 Epoch: [361/484] Iter:[470/495], Time: 0.36, lr: [0.0028941750637692743], Loss: 1.960151, Acc:0.808202, Semantic loss: 0.733344, BCE loss: 0.526841, SB loss: 0.699966
2023-10-30 20:23:36,864 Epoch: [361/484] Iter:[480/495], Time: 0.37, lr: [0.002893743916021876], Loss: 1.960565, Acc:0.808505, Semantic loss: 0.733628, BCE loss: 0.526501, SB loss: 0.700435
2023-10-30 20:23:40,289 Epoch: [361/484] Iter:[490/495], Time: 0.36, lr: [0.0028933127611368015], Loss: 1.961748, Acc:0.808733, Semantic loss: 0.734530, BCE loss: 0.526427, SB loss: 0.700791
2023-10-30 20:23:41,671 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:23:41,916 Loss: 1.993, MeanIU:  0.7289, Best_mIoU:  0.7309
2023-10-30 20:23:41,916 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697]
2023-10-30 20:23:43,885 Epoch: [362/484] Iter:[0/495], Time: 1.94, lr: [0.0028930971810172297], Loss: 2.257381, Acc:0.761038, Semantic loss: 0.835790, BCE loss: 0.605727, SB loss: 0.815864
2023-10-30 20:23:47,977 Epoch: [362/484] Iter:[10/495], Time: 0.55, lr: [0.002892666015423202], Loss: 1.868248, Acc:0.798687, Semantic loss: 0.687905, BCE loss: 0.507311, SB loss: 0.673032
2023-10-30 20:23:51,781 Epoch: [362/484] Iter:[20/495], Time: 0.47, lr: [0.002892234842688249], Loss: 1.919266, Acc:0.812889, Semantic loss: 0.722382, BCE loss: 0.524453, SB loss: 0.672431
2023-10-30 20:23:55,493 Epoch: [362/484] Iter:[30/495], Time: 0.44, lr: [0.002891803662811068], Loss: 1.913871, Acc:0.818876, Semantic loss: 0.705880, BCE loss: 0.533883, SB loss: 0.674108
2023-10-30 20:23:59,077 Epoch: [362/484] Iter:[40/495], Time: 0.42, lr: [0.002891372475790357], Loss: 1.956281, Acc:0.811326, Semantic loss: 0.729124, BCE loss: 0.538481, SB loss: 0.688676
2023-10-30 20:24:02,638 Epoch: [362/484] Iter:[50/495], Time: 0.41, lr: [0.002890941281624814], Loss: 1.959234, Acc:0.807377, Semantic loss: 0.734154, BCE loss: 0.528709, SB loss: 0.696371
2023-10-30 20:24:06,432 Epoch: [362/484] Iter:[60/495], Time: 0.40, lr: [0.0028905100803131366], Loss: 1.930593, Acc:0.807148, Semantic loss: 0.717151, BCE loss: 0.521095, SB loss: 0.692347
2023-10-30 20:24:10,040 Epoch: [362/484] Iter:[70/495], Time: 0.40, lr: [0.002890078871854023], Loss: 1.931591, Acc:0.809221, Semantic loss: 0.721629, BCE loss: 0.518917, SB loss: 0.691044
2023-10-30 20:24:13,595 Epoch: [362/484] Iter:[80/495], Time: 0.39, lr: [0.002889647656246168], Loss: 1.913011, Acc:0.803715, Semantic loss: 0.715341, BCE loss: 0.508662, SB loss: 0.689008
2023-10-30 20:24:17,167 Epoch: [362/484] Iter:[90/495], Time: 0.39, lr: [0.0028892164334882674], Loss: 1.914987, Acc:0.801555, Semantic loss: 0.715390, BCE loss: 0.509225, SB loss: 0.690373
2023-10-30 20:24:20,874 Epoch: [362/484] Iter:[100/495], Time: 0.39, lr: [0.0028887852035790196], Loss: 1.916940, Acc:0.801114, Semantic loss: 0.714545, BCE loss: 0.509485, SB loss: 0.692910
2023-10-30 20:24:24,596 Epoch: [362/484] Iter:[110/495], Time: 0.38, lr: [0.0028883539665171183], Loss: 1.920407, Acc:0.803903, Semantic loss: 0.714537, BCE loss: 0.512014, SB loss: 0.693855
2023-10-30 20:24:28,200 Epoch: [362/484] Iter:[120/495], Time: 0.38, lr: [0.0028879227223012577], Loss: 1.920673, Acc:0.804572, Semantic loss: 0.715678, BCE loss: 0.513754, SB loss: 0.691241
2023-10-30 20:24:31,781 Epoch: [362/484] Iter:[130/495], Time: 0.38, lr: [0.0028874914709301315], Loss: 1.920169, Acc:0.803466, Semantic loss: 0.717369, BCE loss: 0.511404, SB loss: 0.691395
2023-10-30 20:24:35,414 Epoch: [362/484] Iter:[140/495], Time: 0.38, lr: [0.0028870602124024354], Loss: 1.919764, Acc:0.802144, Semantic loss: 0.719532, BCE loss: 0.508430, SB loss: 0.691802
2023-10-30 20:24:39,181 Epoch: [362/484] Iter:[150/495], Time: 0.38, lr: [0.002886628946716862], Loss: 1.919520, Acc:0.802997, Semantic loss: 0.723993, BCE loss: 0.503691, SB loss: 0.691835
2023-10-30 20:24:42,704 Epoch: [362/484] Iter:[160/495], Time: 0.38, lr: [0.0028861976738721045], Loss: 1.924023, Acc:0.804765, Semantic loss: 0.724648, BCE loss: 0.506952, SB loss: 0.692423
2023-10-30 20:24:46,418 Epoch: [362/484] Iter:[170/495], Time: 0.38, lr: [0.002885766393866854], Loss: 1.922624, Acc:0.802380, Semantic loss: 0.722845, BCE loss: 0.508196, SB loss: 0.691583
2023-10-30 20:24:50,021 Epoch: [362/484] Iter:[180/495], Time: 0.38, lr: [0.002885335106699805], Loss: 1.924324, Acc:0.804044, Semantic loss: 0.720358, BCE loss: 0.513019, SB loss: 0.690946
2023-10-30 20:24:53,682 Epoch: [362/484] Iter:[190/495], Time: 0.38, lr: [0.0028849038123696475], Loss: 1.925621, Acc:0.804376, Semantic loss: 0.720768, BCE loss: 0.513380, SB loss: 0.691473
2023-10-30 20:24:57,287 Epoch: [362/484] Iter:[200/495], Time: 0.37, lr: [0.0028844725108750713], Loss: 1.923602, Acc:0.804861, Semantic loss: 0.720046, BCE loss: 0.512509, SB loss: 0.691047
2023-10-30 20:25:00,835 Epoch: [362/484] Iter:[210/495], Time: 0.37, lr: [0.00288404120221477], Loss: 1.925480, Acc:0.803614, Semantic loss: 0.720906, BCE loss: 0.512026, SB loss: 0.692549
2023-10-30 20:25:04,606 Epoch: [362/484] Iter:[220/495], Time: 0.37, lr: [0.0028836098863874327], Loss: 1.924613, Acc:0.803935, Semantic loss: 0.720467, BCE loss: 0.511473, SB loss: 0.692673
2023-10-30 20:25:08,267 Epoch: [362/484] Iter:[230/495], Time: 0.37, lr: [0.0028831785633917483], Loss: 1.927290, Acc:0.804405, Semantic loss: 0.722587, BCE loss: 0.511489, SB loss: 0.693215
2023-10-30 20:25:11,807 Epoch: [362/484] Iter:[240/495], Time: 0.37, lr: [0.002882747233226406], Loss: 1.925360, Acc:0.804477, Semantic loss: 0.722321, BCE loss: 0.510627, SB loss: 0.692412
2023-10-30 20:25:15,423 Epoch: [362/484] Iter:[250/495], Time: 0.37, lr: [0.002882315895890096], Loss: 1.925799, Acc:0.803416, Semantic loss: 0.722500, BCE loss: 0.510471, SB loss: 0.692829
2023-10-30 20:25:19,014 Epoch: [362/484] Iter:[260/495], Time: 0.37, lr: [0.0028818845513815055], Loss: 1.923984, Acc:0.803181, Semantic loss: 0.721673, BCE loss: 0.509803, SB loss: 0.692509
2023-10-30 20:25:22,672 Epoch: [362/484] Iter:[270/495], Time: 0.37, lr: [0.002881453199699324], Loss: 1.924951, Acc:0.801866, Semantic loss: 0.722781, BCE loss: 0.509085, SB loss: 0.693085
2023-10-30 20:25:26,327 Epoch: [362/484] Iter:[280/495], Time: 0.37, lr: [0.002881021840842236], Loss: 1.929859, Acc:0.802010, Semantic loss: 0.723799, BCE loss: 0.511304, SB loss: 0.694755
2023-10-30 20:25:29,976 Epoch: [362/484] Iter:[290/495], Time: 0.37, lr: [0.0028805904748089306], Loss: 1.931732, Acc:0.802718, Semantic loss: 0.724502, BCE loss: 0.512516, SB loss: 0.694714
2023-10-30 20:25:33,645 Epoch: [362/484] Iter:[300/495], Time: 0.37, lr: [0.0028801591015980947], Loss: 1.931861, Acc:0.803990, Semantic loss: 0.724108, BCE loss: 0.514215, SB loss: 0.693538
2023-10-30 20:25:37,232 Epoch: [362/484] Iter:[310/495], Time: 0.37, lr: [0.002879727721208414], Loss: 1.933283, Acc:0.803356, Semantic loss: 0.723677, BCE loss: 0.516019, SB loss: 0.693587
2023-10-30 20:25:40,793 Epoch: [362/484] Iter:[320/495], Time: 0.37, lr: [0.0028792963336385724], Loss: 1.935657, Acc:0.803077, Semantic loss: 0.723968, BCE loss: 0.517017, SB loss: 0.694672
2023-10-30 20:25:44,505 Epoch: [362/484] Iter:[330/495], Time: 0.37, lr: [0.002878864938887258], Loss: 1.933276, Acc:0.801057, Semantic loss: 0.723552, BCE loss: 0.515222, SB loss: 0.694501
2023-10-30 20:25:48,127 Epoch: [362/484] Iter:[340/495], Time: 0.37, lr: [0.0028784335369531535], Loss: 1.933990, Acc:0.800609, Semantic loss: 0.723779, BCE loss: 0.515183, SB loss: 0.695027
2023-10-30 20:25:51,730 Epoch: [362/484] Iter:[350/495], Time: 0.37, lr: [0.0028780021278349433], Loss: 1.932089, Acc:0.801512, Semantic loss: 0.722613, BCE loss: 0.514785, SB loss: 0.694691
2023-10-30 20:25:55,378 Epoch: [362/484] Iter:[360/495], Time: 0.37, lr: [0.002877570711531311], Loss: 1.929326, Acc:0.801060, Semantic loss: 0.721221, BCE loss: 0.514020, SB loss: 0.694085
2023-10-30 20:25:59,093 Epoch: [362/484] Iter:[370/495], Time: 0.37, lr: [0.0028771392880409413], Loss: 1.929685, Acc:0.801203, Semantic loss: 0.721031, BCE loss: 0.514625, SB loss: 0.694029
2023-10-30 20:26:02,866 Epoch: [362/484] Iter:[380/495], Time: 0.37, lr: [0.0028767078573625165], Loss: 1.932377, Acc:0.802191, Semantic loss: 0.721260, BCE loss: 0.517121, SB loss: 0.693996
2023-10-30 20:26:06,448 Epoch: [362/484] Iter:[390/495], Time: 0.37, lr: [0.002876276419494718], Loss: 1.938071, Acc:0.801995, Semantic loss: 0.724723, BCE loss: 0.517262, SB loss: 0.696086
2023-10-30 20:26:10,021 Epoch: [362/484] Iter:[400/495], Time: 0.37, lr: [0.002875844974436228], Loss: 1.935588, Acc:0.802405, Semantic loss: 0.723285, BCE loss: 0.516952, SB loss: 0.695350
2023-10-30 20:26:13,751 Epoch: [362/484] Iter:[410/495], Time: 0.37, lr: [0.002875413522185729], Loss: 1.935582, Acc:0.803026, Semantic loss: 0.723446, BCE loss: 0.516393, SB loss: 0.695743
2023-10-30 20:26:17,494 Epoch: [362/484] Iter:[420/495], Time: 0.37, lr: [0.0028749820627419014], Loss: 1.938133, Acc:0.803223, Semantic loss: 0.725073, BCE loss: 0.516989, SB loss: 0.696071
2023-10-30 20:26:21,177 Epoch: [362/484] Iter:[430/495], Time: 0.37, lr: [0.002874550596103426], Loss: 1.935701, Acc:0.803599, Semantic loss: 0.723714, BCE loss: 0.516569, SB loss: 0.695418
2023-10-30 20:26:24,856 Epoch: [362/484] Iter:[440/495], Time: 0.37, lr: [0.0028741191222689815], Loss: 1.937043, Acc:0.802872, Semantic loss: 0.724686, BCE loss: 0.516344, SB loss: 0.696014
2023-10-30 20:26:28,484 Epoch: [362/484] Iter:[450/495], Time: 0.37, lr: [0.00287368764123725], Loss: 1.938431, Acc:0.803083, Semantic loss: 0.724920, BCE loss: 0.517603, SB loss: 0.695909
2023-10-30 20:26:32,203 Epoch: [362/484] Iter:[460/495], Time: 0.37, lr: [0.002873256153006909], Loss: 1.939925, Acc:0.802790, Semantic loss: 0.725522, BCE loss: 0.517712, SB loss: 0.696691
2023-10-30 20:26:35,832 Epoch: [362/484] Iter:[470/495], Time: 0.37, lr: [0.002872824657576638], Loss: 1.937996, Acc:0.803076, Semantic loss: 0.724833, BCE loss: 0.516927, SB loss: 0.696236
2023-10-30 20:26:39,431 Epoch: [362/484] Iter:[480/495], Time: 0.37, lr: [0.002872393154945113], Loss: 1.935987, Acc:0.803418, Semantic loss: 0.724757, BCE loss: 0.515148, SB loss: 0.696081
2023-10-30 20:26:42,892 Epoch: [362/484] Iter:[490/495], Time: 0.37, lr: [0.0028719616451110155], Loss: 1.934945, Acc:0.802993, Semantic loss: 0.724267, BCE loss: 0.514652, SB loss: 0.696026
2023-10-30 20:26:44,263 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:26:44,507 Loss: 1.993, MeanIU:  0.7289, Best_mIoU:  0.7309
2023-10-30 20:26:44,507 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697]
2023-10-30 20:26:46,677 Epoch: [363/484] Iter:[0/495], Time: 2.14, lr: [0.0028717458874925874], Loss: 2.386647, Acc:0.871300, Semantic loss: 0.887151, BCE loss: 0.717469, SB loss: 0.782027
2023-10-30 20:26:50,578 Epoch: [363/484] Iter:[10/495], Time: 0.55, lr: [0.0028713143668521474], Loss: 1.982901, Acc:0.803892, Semantic loss: 0.743760, BCE loss: 0.528946, SB loss: 0.710195
2023-10-30 20:26:54,219 Epoch: [363/484] Iter:[20/495], Time: 0.46, lr: [0.0028708828390058244], Loss: 1.901051, Acc:0.808371, Semantic loss: 0.713294, BCE loss: 0.506955, SB loss: 0.680802
2023-10-30 20:26:57,857 Epoch: [363/484] Iter:[30/495], Time: 0.43, lr: [0.0028704513039522965], Loss: 1.945778, Acc:0.815271, Semantic loss: 0.740064, BCE loss: 0.508009, SB loss: 0.697704
2023-10-30 20:27:01,548 Epoch: [363/484] Iter:[40/495], Time: 0.41, lr: [0.0028700197616902392], Loss: 1.961303, Acc:0.797633, Semantic loss: 0.754869, BCE loss: 0.501624, SB loss: 0.704810
2023-10-30 20:27:05,214 Epoch: [363/484] Iter:[50/495], Time: 0.41, lr: [0.002869588212218326], Loss: 1.942274, Acc:0.795270, Semantic loss: 0.745466, BCE loss: 0.498407, SB loss: 0.698400
2023-10-30 20:27:09,023 Epoch: [363/484] Iter:[60/495], Time: 0.40, lr: [0.0028691566555352314], Loss: 1.949460, Acc:0.800589, Semantic loss: 0.748198, BCE loss: 0.498932, SB loss: 0.702330
2023-10-30 20:27:12,662 Epoch: [363/484] Iter:[70/495], Time: 0.40, lr: [0.002868725091639633], Loss: 1.947282, Acc:0.801177, Semantic loss: 0.745614, BCE loss: 0.497723, SB loss: 0.703946
2023-10-30 20:27:16,289 Epoch: [363/484] Iter:[80/495], Time: 0.39, lr: [0.0028682935205302015], Loss: 1.951137, Acc:0.800780, Semantic loss: 0.747142, BCE loss: 0.501586, SB loss: 0.702409
2023-10-30 20:27:19,882 Epoch: [363/484] Iter:[90/495], Time: 0.39, lr: [0.002867861942205612], Loss: 1.942996, Acc:0.803264, Semantic loss: 0.737099, BCE loss: 0.504496, SB loss: 0.701400
2023-10-30 20:27:23,590 Epoch: [363/484] Iter:[100/495], Time: 0.39, lr: [0.002867430356664535], Loss: 1.924056, Acc:0.799559, Semantic loss: 0.727558, BCE loss: 0.499260, SB loss: 0.697237
2023-10-30 20:27:27,173 Epoch: [363/484] Iter:[110/495], Time: 0.38, lr: [0.002866998763905646], Loss: 1.933197, Acc:0.801312, Semantic loss: 0.729884, BCE loss: 0.504052, SB loss: 0.699261
2023-10-30 20:27:30,828 Epoch: [363/484] Iter:[120/495], Time: 0.38, lr: [0.0028665671639276154], Loss: 1.931416, Acc:0.801080, Semantic loss: 0.729021, BCE loss: 0.506449, SB loss: 0.695945
2023-10-30 20:27:34,385 Epoch: [363/484] Iter:[130/495], Time: 0.38, lr: [0.0028661355567291148], Loss: 1.927032, Acc:0.802624, Semantic loss: 0.726376, BCE loss: 0.502884, SB loss: 0.697772
2023-10-30 20:27:38,061 Epoch: [363/484] Iter:[140/495], Time: 0.38, lr: [0.0028657039423088146], Loss: 1.926694, Acc:0.802383, Semantic loss: 0.728039, BCE loss: 0.501138, SB loss: 0.697517
2023-10-30 20:27:41,683 Epoch: [363/484] Iter:[150/495], Time: 0.38, lr: [0.002865272320665387], Loss: 1.936081, Acc:0.805294, Semantic loss: 0.733009, BCE loss: 0.503329, SB loss: 0.699743
2023-10-30 20:27:45,299 Epoch: [363/484] Iter:[160/495], Time: 0.38, lr: [0.002864840691797501], Loss: 1.936146, Acc:0.804036, Semantic loss: 0.733943, BCE loss: 0.501144, SB loss: 0.701059
2023-10-30 20:27:48,940 Epoch: [363/484] Iter:[170/495], Time: 0.38, lr: [0.002864409055703826], Loss: 1.939055, Acc:0.800787, Semantic loss: 0.734876, BCE loss: 0.501391, SB loss: 0.702788
2023-10-30 20:27:52,657 Epoch: [363/484] Iter:[180/495], Time: 0.38, lr: [0.0028639774123830307], Loss: 1.940244, Acc:0.800187, Semantic loss: 0.736539, BCE loss: 0.501064, SB loss: 0.702642
2023-10-30 20:27:56,321 Epoch: [363/484] Iter:[190/495], Time: 0.38, lr: [0.002863545761833786], Loss: 1.947018, Acc:0.800251, Semantic loss: 0.739529, BCE loss: 0.503535, SB loss: 0.703953
2023-10-30 20:27:59,917 Epoch: [363/484] Iter:[200/495], Time: 0.37, lr: [0.002863114104054759], Loss: 1.944955, Acc:0.801035, Semantic loss: 0.738051, BCE loss: 0.503004, SB loss: 0.703899
2023-10-30 20:28:03,527 Epoch: [363/484] Iter:[210/495], Time: 0.37, lr: [0.002862682439044617], Loss: 1.939360, Acc:0.799976, Semantic loss: 0.736596, BCE loss: 0.498405, SB loss: 0.704359
2023-10-30 20:28:07,104 Epoch: [363/484] Iter:[220/495], Time: 0.37, lr: [0.0028622507668020266], Loss: 1.942712, Acc:0.800644, Semantic loss: 0.737627, BCE loss: 0.499004, SB loss: 0.706081
2023-10-30 20:28:10,821 Epoch: [363/484] Iter:[230/495], Time: 0.37, lr: [0.002861819087325656], Loss: 1.939709, Acc:0.801040, Semantic loss: 0.736143, BCE loss: 0.499362, SB loss: 0.704204
2023-10-30 20:28:14,392 Epoch: [363/484] Iter:[240/495], Time: 0.37, lr: [0.0028613874006141716], Loss: 1.942074, Acc:0.801324, Semantic loss: 0.737655, BCE loss: 0.499713, SB loss: 0.704706
2023-10-30 20:28:18,194 Epoch: [363/484] Iter:[250/495], Time: 0.37, lr: [0.002860955706666238], Loss: 1.944605, Acc:0.802614, Semantic loss: 0.739160, BCE loss: 0.502449, SB loss: 0.702997
2023-10-30 20:28:21,953 Epoch: [363/484] Iter:[260/495], Time: 0.37, lr: [0.0028605240054805216], Loss: 1.939515, Acc:0.802749, Semantic loss: 0.735527, BCE loss: 0.502916, SB loss: 0.701072
2023-10-30 20:28:25,634 Epoch: [363/484] Iter:[270/495], Time: 0.37, lr: [0.0028600922970556867], Loss: 1.940351, Acc:0.803461, Semantic loss: 0.735237, BCE loss: 0.503674, SB loss: 0.701440
2023-10-30 20:28:29,227 Epoch: [363/484] Iter:[280/495], Time: 0.37, lr: [0.0028596605813903993], Loss: 1.943011, Acc:0.803427, Semantic loss: 0.735551, BCE loss: 0.505386, SB loss: 0.702074
2023-10-30 20:28:32,949 Epoch: [363/484] Iter:[290/495], Time: 0.37, lr: [0.002859228858483322], Loss: 1.940242, Acc:0.802659, Semantic loss: 0.734285, BCE loss: 0.504659, SB loss: 0.701298
2023-10-30 20:28:36,550 Epoch: [363/484] Iter:[300/495], Time: 0.37, lr: [0.0028587971283331177], Loss: 1.939311, Acc:0.802202, Semantic loss: 0.733204, BCE loss: 0.505156, SB loss: 0.700951
2023-10-30 20:28:40,180 Epoch: [363/484] Iter:[310/495], Time: 0.37, lr: [0.002858365390938451], Loss: 1.940076, Acc:0.801960, Semantic loss: 0.733100, BCE loss: 0.505740, SB loss: 0.701237
2023-10-30 20:28:43,824 Epoch: [363/484] Iter:[320/495], Time: 0.37, lr: [0.002857933646297984], Loss: 1.943967, Acc:0.801983, Semantic loss: 0.735216, BCE loss: 0.506090, SB loss: 0.702660
2023-10-30 20:28:47,423 Epoch: [363/484] Iter:[330/495], Time: 0.37, lr: [0.002857501894410379], Loss: 1.948315, Acc:0.802882, Semantic loss: 0.736967, BCE loss: 0.508113, SB loss: 0.703234
2023-10-30 20:28:50,999 Epoch: [363/484] Iter:[340/495], Time: 0.37, lr: [0.0028570701352742954], Loss: 1.945380, Acc:0.802620, Semantic loss: 0.735487, BCE loss: 0.507094, SB loss: 0.702799
2023-10-30 20:28:54,745 Epoch: [363/484] Iter:[350/495], Time: 0.37, lr: [0.0028566383688883984], Loss: 1.943276, Acc:0.803199, Semantic loss: 0.734191, BCE loss: 0.506936, SB loss: 0.702149
2023-10-30 20:28:58,424 Epoch: [363/484] Iter:[360/495], Time: 0.37, lr: [0.002856206595251346], Loss: 1.943071, Acc:0.803759, Semantic loss: 0.734057, BCE loss: 0.507151, SB loss: 0.701864
2023-10-30 20:29:02,102 Epoch: [363/484] Iter:[370/495], Time: 0.37, lr: [0.002855774814361799], Loss: 1.948993, Acc:0.803322, Semantic loss: 0.738139, BCE loss: 0.507626, SB loss: 0.703228
2023-10-30 20:29:05,676 Epoch: [363/484] Iter:[380/495], Time: 0.37, lr: [0.002855343026218416], Loss: 1.953030, Acc:0.802504, Semantic loss: 0.740090, BCE loss: 0.508841, SB loss: 0.704098
2023-10-30 20:29:09,332 Epoch: [363/484] Iter:[390/495], Time: 0.37, lr: [0.002854911230819859], Loss: 1.950148, Acc:0.802392, Semantic loss: 0.738807, BCE loss: 0.507077, SB loss: 0.704264
2023-10-30 20:29:13,003 Epoch: [363/484] Iter:[400/495], Time: 0.37, lr: [0.002854479428164785], Loss: 1.951317, Acc:0.802149, Semantic loss: 0.738917, BCE loss: 0.508034, SB loss: 0.704367
2023-10-30 20:29:16,596 Epoch: [363/484] Iter:[410/495], Time: 0.37, lr: [0.0028540476182518527], Loss: 1.953483, Acc:0.802782, Semantic loss: 0.740005, BCE loss: 0.508850, SB loss: 0.704628
2023-10-30 20:29:20,204 Epoch: [363/484] Iter:[420/495], Time: 0.37, lr: [0.002853615801079718], Loss: 1.950938, Acc:0.802341, Semantic loss: 0.738240, BCE loss: 0.508303, SB loss: 0.704395
2023-10-30 20:29:23,829 Epoch: [363/484] Iter:[430/495], Time: 0.37, lr: [0.0028531839766470423], Loss: 1.952186, Acc:0.802842, Semantic loss: 0.739411, BCE loss: 0.508281, SB loss: 0.704495
2023-10-30 20:29:27,350 Epoch: [363/484] Iter:[440/495], Time: 0.37, lr: [0.0028527521449524798], Loss: 1.952066, Acc:0.802767, Semantic loss: 0.739342, BCE loss: 0.507898, SB loss: 0.704826
2023-10-30 20:29:31,057 Epoch: [363/484] Iter:[450/495], Time: 0.37, lr: [0.0028523203059946877], Loss: 1.951333, Acc:0.802246, Semantic loss: 0.739306, BCE loss: 0.506724, SB loss: 0.705303
2023-10-30 20:29:34,607 Epoch: [363/484] Iter:[460/495], Time: 0.37, lr: [0.0028518884597723204], Loss: 1.952435, Acc:0.802413, Semantic loss: 0.739442, BCE loss: 0.507356, SB loss: 0.705636
2023-10-30 20:29:38,196 Epoch: [363/484] Iter:[470/495], Time: 0.37, lr: [0.0028514566062840356], Loss: 1.952353, Acc:0.801334, Semantic loss: 0.740019, BCE loss: 0.506893, SB loss: 0.705441
2023-10-30 20:29:41,859 Epoch: [363/484] Iter:[480/495], Time: 0.37, lr: [0.002851024745528488], Loss: 1.954259, Acc:0.801077, Semantic loss: 0.740967, BCE loss: 0.507928, SB loss: 0.705365
2023-10-30 20:29:45,328 Epoch: [363/484] Iter:[490/495], Time: 0.37, lr: [0.0028505928775043317], Loss: 1.954889, Acc:0.800902, Semantic loss: 0.740951, BCE loss: 0.509011, SB loss: 0.704927
2023-10-30 20:29:46,696 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:29:46,930 Loss: 1.993, MeanIU:  0.7289, Best_mIoU:  0.7309
2023-10-30 20:29:46,930 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697]
2023-10-30 20:29:48,821 Epoch: [364/484] Iter:[0/495], Time: 1.86, lr: [0.0028503769407661034], Loss: 1.952837, Acc:0.816525, Semantic loss: 0.705291, BCE loss: 0.557936, SB loss: 0.689610
2023-10-30 20:29:52,853 Epoch: [364/484] Iter:[10/495], Time: 0.54, lr: [0.00284994506183651], Loss: 1.957933, Acc:0.817252, Semantic loss: 0.710806, BCE loss: 0.557319, SB loss: 0.689808
2023-10-30 20:29:56,488 Epoch: [364/484] Iter:[20/495], Time: 0.45, lr: [0.0028495131756349416], Loss: 1.942471, Acc:0.778458, Semantic loss: 0.740249, BCE loss: 0.498157, SB loss: 0.704064
2023-10-30 20:30:00,091 Epoch: [364/484] Iter:[30/495], Time: 0.42, lr: [0.002849081282160052], Loss: 1.957145, Acc:0.770667, Semantic loss: 0.739504, BCE loss: 0.510649, SB loss: 0.706992
2023-10-30 20:30:03,621 Epoch: [364/484] Iter:[40/495], Time: 0.41, lr: [0.0028486493814104917], Loss: 1.976920, Acc:0.778854, Semantic loss: 0.756407, BCE loss: 0.513259, SB loss: 0.707255
2023-10-30 20:30:07,305 Epoch: [364/484] Iter:[50/495], Time: 0.40, lr: [0.002848217473384916], Loss: 1.941558, Acc:0.776496, Semantic loss: 0.733807, BCE loss: 0.501616, SB loss: 0.706135
2023-10-30 20:30:10,897 Epoch: [364/484] Iter:[60/495], Time: 0.39, lr: [0.0028477855580819732], Loss: 1.960883, Acc:0.782781, Semantic loss: 0.753157, BCE loss: 0.501502, SB loss: 0.706224
2023-10-30 20:30:14,472 Epoch: [364/484] Iter:[70/495], Time: 0.39, lr: [0.002847353635500316], Loss: 1.976515, Acc:0.781170, Semantic loss: 0.760452, BCE loss: 0.507662, SB loss: 0.708400
2023-10-30 20:30:18,110 Epoch: [364/484] Iter:[80/495], Time: 0.38, lr: [0.0028469217056385932], Loss: 2.008660, Acc:0.776489, Semantic loss: 0.786928, BCE loss: 0.507170, SB loss: 0.714562
2023-10-30 20:30:21,769 Epoch: [364/484] Iter:[90/495], Time: 0.38, lr: [0.002846489768495457], Loss: 2.006567, Acc:0.783049, Semantic loss: 0.777863, BCE loss: 0.516367, SB loss: 0.712338
2023-10-30 20:30:25,449 Epoch: [364/484] Iter:[100/495], Time: 0.38, lr: [0.002846057824069556], Loss: 2.012625, Acc:0.785827, Semantic loss: 0.777757, BCE loss: 0.519908, SB loss: 0.714960
2023-10-30 20:30:29,058 Epoch: [364/484] Iter:[110/495], Time: 0.38, lr: [0.0028456258723595397], Loss: 2.010996, Acc:0.787937, Semantic loss: 0.775286, BCE loss: 0.519413, SB loss: 0.716297
2023-10-30 20:30:32,808 Epoch: [364/484] Iter:[120/495], Time: 0.38, lr: [0.0028451939133640543], Loss: 2.007199, Acc:0.791283, Semantic loss: 0.773794, BCE loss: 0.518694, SB loss: 0.714711
2023-10-30 20:30:36,486 Epoch: [364/484] Iter:[130/495], Time: 0.38, lr: [0.002844761947081751], Loss: 2.017488, Acc:0.793039, Semantic loss: 0.773345, BCE loss: 0.527538, SB loss: 0.716605
2023-10-30 20:30:40,021 Epoch: [364/484] Iter:[140/495], Time: 0.38, lr: [0.002844329973511276], Loss: 2.022880, Acc:0.794572, Semantic loss: 0.777003, BCE loss: 0.528614, SB loss: 0.717262
2023-10-30 20:30:43,623 Epoch: [364/484] Iter:[150/495], Time: 0.38, lr: [0.002843897992651277], Loss: 2.013378, Acc:0.793853, Semantic loss: 0.771792, BCE loss: 0.524904, SB loss: 0.716683
2023-10-30 20:30:47,383 Epoch: [364/484] Iter:[160/495], Time: 0.38, lr: [0.0028434660045003985], Loss: 2.012776, Acc:0.795129, Semantic loss: 0.772377, BCE loss: 0.524514, SB loss: 0.715885
2023-10-30 20:30:50,936 Epoch: [364/484] Iter:[170/495], Time: 0.37, lr: [0.00284303400905729], Loss: 2.007538, Acc:0.797683, Semantic loss: 0.767263, BCE loss: 0.526383, SB loss: 0.713892
2023-10-30 20:30:54,650 Epoch: [364/484] Iter:[180/495], Time: 0.37, lr: [0.0028426020063205956], Loss: 2.012843, Acc:0.797736, Semantic loss: 0.767400, BCE loss: 0.529127, SB loss: 0.716316
2023-10-30 20:30:58,287 Epoch: [364/484] Iter:[190/495], Time: 0.37, lr: [0.00284216999628896], Loss: 2.004158, Acc:0.797862, Semantic loss: 0.763355, BCE loss: 0.526843, SB loss: 0.713960
2023-10-30 20:31:01,942 Epoch: [364/484] Iter:[200/495], Time: 0.37, lr: [0.002841737978961028], Loss: 2.001628, Acc:0.797341, Semantic loss: 0.761428, BCE loss: 0.526523, SB loss: 0.713677
2023-10-30 20:31:05,563 Epoch: [364/484] Iter:[210/495], Time: 0.37, lr: [0.0028413059543354454], Loss: 2.003206, Acc:0.797622, Semantic loss: 0.761484, BCE loss: 0.527456, SB loss: 0.714265
2023-10-30 20:31:09,144 Epoch: [364/484] Iter:[220/495], Time: 0.37, lr: [0.002840873922410855], Loss: 2.001100, Acc:0.797646, Semantic loss: 0.760517, BCE loss: 0.528069, SB loss: 0.712514
2023-10-30 20:31:12,808 Epoch: [364/484] Iter:[230/495], Time: 0.37, lr: [0.0028404418831859], Loss: 1.993356, Acc:0.796761, Semantic loss: 0.756897, BCE loss: 0.525883, SB loss: 0.710576
2023-10-30 20:31:16,311 Epoch: [364/484] Iter:[240/495], Time: 0.37, lr: [0.0028400098366592216], Loss: 1.993608, Acc:0.796742, Semantic loss: 0.757709, BCE loss: 0.526111, SB loss: 0.709788
2023-10-30 20:31:20,021 Epoch: [364/484] Iter:[250/495], Time: 0.37, lr: [0.0028395777828294643], Loss: 1.987778, Acc:0.797252, Semantic loss: 0.755109, BCE loss: 0.523787, SB loss: 0.708882
2023-10-30 20:31:23,704 Epoch: [364/484] Iter:[260/495], Time: 0.37, lr: [0.0028391457216952703], Loss: 1.989543, Acc:0.797249, Semantic loss: 0.755732, BCE loss: 0.524439, SB loss: 0.709372
2023-10-30 20:31:27,249 Epoch: [364/484] Iter:[270/495], Time: 0.37, lr: [0.0028387136532552803], Loss: 1.986281, Acc:0.798050, Semantic loss: 0.752827, BCE loss: 0.524950, SB loss: 0.708505
2023-10-30 20:31:30,984 Epoch: [364/484] Iter:[280/495], Time: 0.37, lr: [0.002838281577508133], Loss: 1.982226, Acc:0.796695, Semantic loss: 0.751115, BCE loss: 0.523098, SB loss: 0.708013
2023-10-30 20:31:34,607 Epoch: [364/484] Iter:[290/495], Time: 0.37, lr: [0.002837849494452473], Loss: 1.983375, Acc:0.797111, Semantic loss: 0.751344, BCE loss: 0.524719, SB loss: 0.707312
2023-10-30 20:31:38,278 Epoch: [364/484] Iter:[300/495], Time: 0.37, lr: [0.002837417404086937], Loss: 1.979833, Acc:0.796123, Semantic loss: 0.750794, BCE loss: 0.521301, SB loss: 0.707738
2023-10-30 20:31:41,887 Epoch: [364/484] Iter:[310/495], Time: 0.37, lr: [0.0028369853064101657], Loss: 1.983251, Acc:0.795747, Semantic loss: 0.752750, BCE loss: 0.522394, SB loss: 0.708106
2023-10-30 20:31:45,564 Epoch: [364/484] Iter:[320/495], Time: 0.37, lr: [0.0028365532014207966], Loss: 1.981280, Acc:0.795933, Semantic loss: 0.750302, BCE loss: 0.523319, SB loss: 0.707658
2023-10-30 20:31:49,356 Epoch: [364/484] Iter:[330/495], Time: 0.37, lr: [0.002836121089117471], Loss: 1.978776, Acc:0.796667, Semantic loss: 0.747104, BCE loss: 0.524975, SB loss: 0.706697
2023-10-30 20:31:52,982 Epoch: [364/484] Iter:[340/495], Time: 0.37, lr: [0.002835688969498825], Loss: 1.981937, Acc:0.797376, Semantic loss: 0.749125, BCE loss: 0.525179, SB loss: 0.707634
2023-10-30 20:31:56,567 Epoch: [364/484] Iter:[350/495], Time: 0.37, lr: [0.0028352568425634955], Loss: 1.979340, Acc:0.796769, Semantic loss: 0.747608, BCE loss: 0.524135, SB loss: 0.707596
2023-10-30 20:32:00,205 Epoch: [364/484] Iter:[360/495], Time: 0.37, lr: [0.00283482470831012], Loss: 1.977360, Acc:0.795705, Semantic loss: 0.747286, BCE loss: 0.522462, SB loss: 0.707611
2023-10-30 20:32:03,863 Epoch: [364/484] Iter:[370/495], Time: 0.37, lr: [0.002834392566737336], Loss: 1.978770, Acc:0.795874, Semantic loss: 0.749155, BCE loss: 0.522141, SB loss: 0.707474
2023-10-30 20:32:07,487 Epoch: [364/484] Iter:[380/495], Time: 0.37, lr: [0.0028339604178437795], Loss: 1.976836, Acc:0.795821, Semantic loss: 0.747571, BCE loss: 0.522393, SB loss: 0.706872
2023-10-30 20:32:11,116 Epoch: [364/484] Iter:[390/495], Time: 0.37, lr: [0.002833528261628085], Loss: 1.972723, Acc:0.794806, Semantic loss: 0.746032, BCE loss: 0.520081, SB loss: 0.706610
2023-10-30 20:32:14,798 Epoch: [364/484] Iter:[400/495], Time: 0.37, lr: [0.002833096098088887], Loss: 1.972674, Acc:0.795603, Semantic loss: 0.746296, BCE loss: 0.520427, SB loss: 0.705951
2023-10-30 20:32:18,380 Epoch: [364/484] Iter:[410/495], Time: 0.37, lr: [0.002832663927224822], Loss: 1.968183, Acc:0.796054, Semantic loss: 0.744907, BCE loss: 0.518331, SB loss: 0.704945
2023-10-30 20:32:22,056 Epoch: [364/484] Iter:[420/495], Time: 0.37, lr: [0.002832231749034524], Loss: 1.967035, Acc:0.795425, Semantic loss: 0.744531, BCE loss: 0.517273, SB loss: 0.705231
2023-10-30 20:32:25,689 Epoch: [364/484] Iter:[430/495], Time: 0.37, lr: [0.0028317995635166256], Loss: 1.967351, Acc:0.795859, Semantic loss: 0.744987, BCE loss: 0.516996, SB loss: 0.705368
2023-10-30 20:32:29,357 Epoch: [364/484] Iter:[440/495], Time: 0.37, lr: [0.002831367370669759], Loss: 1.968962, Acc:0.795761, Semantic loss: 0.746157, BCE loss: 0.516641, SB loss: 0.706164
2023-10-30 20:32:33,063 Epoch: [364/484] Iter:[450/495], Time: 0.37, lr: [0.002830935170492559], Loss: 1.966896, Acc:0.795119, Semantic loss: 0.745429, BCE loss: 0.515491, SB loss: 0.705976
2023-10-30 20:32:36,721 Epoch: [364/484] Iter:[460/495], Time: 0.37, lr: [0.002830502962983657], Loss: 1.966993, Acc:0.795698, Semantic loss: 0.744825, BCE loss: 0.516010, SB loss: 0.706158
2023-10-30 20:32:40,433 Epoch: [364/484] Iter:[470/495], Time: 0.37, lr: [0.002830070748141684], Loss: 1.966133, Acc:0.795462, Semantic loss: 0.744584, BCE loss: 0.515769, SB loss: 0.705780
2023-10-30 20:32:44,227 Epoch: [364/484] Iter:[480/495], Time: 0.37, lr: [0.002829638525965271], Loss: 1.964927, Acc:0.796650, Semantic loss: 0.743171, BCE loss: 0.516739, SB loss: 0.705017
2023-10-30 20:32:47,685 Epoch: [364/484] Iter:[490/495], Time: 0.37, lr: [0.00282920629645305], Loss: 1.963905, Acc:0.796788, Semantic loss: 0.742188, BCE loss: 0.517290, SB loss: 0.704428
2023-10-30 20:32:49,065 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:32:49,322 Loss: 1.993, MeanIU:  0.7289, Best_mIoU:  0.7309
2023-10-30 20:32:49,322 [0.9787254  0.83689352 0.91582731 0.45923527 0.56323582 0.59979316
 0.68453096 0.75219558 0.9162349  0.58167946 0.94075398 0.79460867
 0.59050116 0.94056952 0.65729613 0.77957942 0.60275287 0.51297417
 0.74177697]
2023-10-30 20:32:51,462 Epoch: [365/484] Iter:[0/495], Time: 2.11, lr: [0.0028289901789455836], Loss: 1.743419, Acc:0.835523, Semantic loss: 0.704814, BCE loss: 0.298513, SB loss: 0.740092
2023-10-30 20:32:55,508 Epoch: [365/484] Iter:[10/495], Time: 0.56, lr: [0.0028285579384270815], Loss: 1.918913, Acc:0.795637, Semantic loss: 0.741954, BCE loss: 0.467315, SB loss: 0.709643
2023-10-30 20:32:59,254 Epoch: [365/484] Iter:[20/495], Time: 0.47, lr: [0.0028281256905693442], Loss: 1.907913, Acc:0.803303, Semantic loss: 0.705738, BCE loss: 0.502403, SB loss: 0.699772
2023-10-30 20:33:02,887 Epoch: [365/484] Iter:[30/495], Time: 0.44, lr: [0.0028276934353710028], Loss: 1.957317, Acc:0.798762, Semantic loss: 0.727867, BCE loss: 0.532442, SB loss: 0.697008
2023-10-30 20:33:06,497 Epoch: [365/484] Iter:[40/495], Time: 0.42, lr: [0.0028272611728306844], Loss: 1.959774, Acc:0.802167, Semantic loss: 0.729475, BCE loss: 0.532220, SB loss: 0.698080
2023-10-30 20:33:10,042 Epoch: [365/484] Iter:[50/495], Time: 0.41, lr: [0.0028268289029470184], Loss: 1.942307, Acc:0.797750, Semantic loss: 0.718457, BCE loss: 0.526892, SB loss: 0.696958
2023-10-30 20:33:13,729 Epoch: [365/484] Iter:[60/495], Time: 0.40, lr: [0.00282639662571863], Loss: 1.912822, Acc:0.792638, Semantic loss: 0.707304, BCE loss: 0.512864, SB loss: 0.692655
2023-10-30 20:33:17,442 Epoch: [365/484] Iter:[70/495], Time: 0.40, lr: [0.0028259643411441483], Loss: 1.925538, Acc:0.792865, Semantic loss: 0.712717, BCE loss: 0.518290, SB loss: 0.694531
2023-10-30 20:33:21,149 Epoch: [365/484] Iter:[80/495], Time: 0.39, lr: [0.002825532049222199], Loss: 1.950289, Acc:0.793527, Semantic loss: 0.725328, BCE loss: 0.525444, SB loss: 0.699517
2023-10-30 20:33:24,723 Epoch: [365/484] Iter:[90/495], Time: 0.39, lr: [0.0028250997499514085], Loss: 1.941888, Acc:0.799704, Semantic loss: 0.721385, BCE loss: 0.523329, SB loss: 0.697174
2023-10-30 20:33:28,504 Epoch: [365/484] Iter:[100/495], Time: 0.39, lr: [0.002824667443330401], Loss: 1.931276, Acc:0.803581, Semantic loss: 0.715412, BCE loss: 0.522205, SB loss: 0.693658
2023-10-30 20:33:32,228 Epoch: [365/484] Iter:[110/495], Time: 0.39, lr: [0.002824235129357803], Loss: 1.936829, Acc:0.806252, Semantic loss: 0.716681, BCE loss: 0.525324, SB loss: 0.694824
2023-10-30 20:33:35,869 Epoch: [365/484] Iter:[120/495], Time: 0.38, lr: [0.00282380280803224], Loss: 1.947968, Acc:0.807609, Semantic loss: 0.720057, BCE loss: 0.530807, SB loss: 0.697104
2023-10-30 20:33:39,551 Epoch: [365/484] Iter:[130/495], Time: 0.38, lr: [0.002823370479352334], Loss: 1.938013, Acc:0.805290, Semantic loss: 0.714867, BCE loss: 0.527933, SB loss: 0.695212
2023-10-30 20:33:43,266 Epoch: [365/484] Iter:[140/495], Time: 0.38, lr: [0.002822938143316709], Loss: 1.937323, Acc:0.806403, Semantic loss: 0.718609, BCE loss: 0.523704, SB loss: 0.695010
2023-10-30 20:33:46,942 Epoch: [365/484] Iter:[150/495], Time: 0.38, lr: [0.002822505799923989], Loss: 1.941376, Acc:0.808355, Semantic loss: 0.719487, BCE loss: 0.527279, SB loss: 0.694609
2023-10-30 20:33:50,560 Epoch: [365/484] Iter:[160/495], Time: 0.38, lr: [0.002822073449172796], Loss: 1.943863, Acc:0.808201, Semantic loss: 0.718909, BCE loss: 0.529892, SB loss: 0.695063
2023-10-30 20:33:54,202 Epoch: [365/484] Iter:[170/495], Time: 0.38, lr: [0.002821641091061753], Loss: 1.938909, Acc:0.808316, Semantic loss: 0.717788, BCE loss: 0.527288, SB loss: 0.693833
2023-10-30 20:33:57,934 Epoch: [365/484] Iter:[180/495], Time: 0.38, lr: [0.002821208725589479], Loss: 1.937549, Acc:0.809076, Semantic loss: 0.719364, BCE loss: 0.524248, SB loss: 0.693937
2023-10-30 20:34:01,588 Epoch: [365/484] Iter:[190/495], Time: 0.38, lr: [0.002820776352754598], Loss: 1.944141, Acc:0.809582, Semantic loss: 0.720608, BCE loss: 0.529202, SB loss: 0.694331
2023-10-30 20:34:05,396 Epoch: [365/484] Iter:[200/495], Time: 0.38, lr: [0.0028203439725557307], Loss: 1.946091, Acc:0.808116, Semantic loss: 0.725146, BCE loss: 0.526395, SB loss: 0.694550
2023-10-30 20:34:09,189 Epoch: [365/484] Iter:[210/495], Time: 0.38, lr: [0.0028199115849914954], Loss: 1.947667, Acc:0.807503, Semantic loss: 0.725754, BCE loss: 0.527292, SB loss: 0.694622
2023-10-30 20:34:12,768 Epoch: [365/484] Iter:[220/495], Time: 0.38, lr: [0.002819479190060511], Loss: 1.948382, Acc:0.807546, Semantic loss: 0.727015, BCE loss: 0.525701, SB loss: 0.695667
2023-10-30 20:34:16,472 Epoch: [365/484] Iter:[230/495], Time: 0.38, lr: [0.0028190467877614], Loss: 1.942359, Acc:0.806443, Semantic loss: 0.724604, BCE loss: 0.524119, SB loss: 0.693636
2023-10-30 20:34:20,079 Epoch: [365/484] Iter:[240/495], Time: 0.38, lr: [0.0028186143780927785], Loss: 1.942378, Acc:0.808617, Semantic loss: 0.724850, BCE loss: 0.524015, SB loss: 0.693513
2023-10-30 20:34:23,711 Epoch: [365/484] Iter:[250/495], Time: 0.38, lr: [0.002818181961053266], Loss: 1.953587, Acc:0.807583, Semantic loss: 0.733814, BCE loss: 0.524574, SB loss: 0.695199
2023-10-30 20:34:27,368 Epoch: [365/484] Iter:[260/495], Time: 0.38, lr: [0.0028177495366414787], Loss: 1.947448, Acc:0.806317, Semantic loss: 0.730440, BCE loss: 0.521723, SB loss: 0.695284
2023-10-30 20:34:31,064 Epoch: [365/484] Iter:[270/495], Time: 0.38, lr: [0.0028173171048560355], Loss: 1.947641, Acc:0.804948, Semantic loss: 0.730275, BCE loss: 0.521419, SB loss: 0.695946
2023-10-30 20:34:34,729 Epoch: [365/484] Iter:[280/495], Time: 0.37, lr: [0.0028168846656955516], Loss: 1.949946, Acc:0.805420, Semantic loss: 0.731743, BCE loss: 0.521968, SB loss: 0.696235
2023-10-30 20:34:38,406 Epoch: [365/484] Iter:[290/495], Time: 0.37, lr: [0.0028164522191586445], Loss: 1.950029, Acc:0.806109, Semantic loss: 0.731177, BCE loss: 0.522437, SB loss: 0.696415
2023-10-30 20:34:42,088 Epoch: [365/484] Iter:[300/495], Time: 0.37, lr: [0.002816019765243928], Loss: 1.953064, Acc:0.805945, Semantic loss: 0.732451, BCE loss: 0.523397, SB loss: 0.697216
2023-10-30 20:34:45,787 Epoch: [365/484] Iter:[310/495], Time: 0.37, lr: [0.002815587303950019], Loss: 1.952438, Acc:0.805395, Semantic loss: 0.730546, BCE loss: 0.524628, SB loss: 0.697264
2023-10-30 20:34:49,600 Epoch: [365/484] Iter:[320/495], Time: 0.37, lr: [0.0028151548352755326], Loss: 1.949809, Acc:0.805614, Semantic loss: 0.728977, BCE loss: 0.523509, SB loss: 0.697322
2023-10-30 20:34:53,214 Epoch: [365/484] Iter:[330/495], Time: 0.37, lr: [0.002814722359219081], Loss: 1.949484, Acc:0.805497, Semantic loss: 0.729088, BCE loss: 0.522874, SB loss: 0.697522
2023-10-30 20:34:56,849 Epoch: [365/484] Iter:[340/495], Time: 0.37, lr: [0.002814289875779279], Loss: 1.948188, Acc:0.804566, Semantic loss: 0.729810, BCE loss: 0.520619, SB loss: 0.697760
2023-10-30 20:35:00,585 Epoch: [365/484] Iter:[350/495], Time: 0.37, lr: [0.0028138573849547407], Loss: 1.944830, Acc:0.804010, Semantic loss: 0.728507, BCE loss: 0.519143, SB loss: 0.697179
2023-10-30 20:35:04,134 Epoch: [365/484] Iter:[360/495], Time: 0.37, lr: [0.002813424886744077], Loss: 1.944854, Acc:0.804569, Semantic loss: 0.729190, BCE loss: 0.517855, SB loss: 0.697810
2023-10-30 20:35:07,664 Epoch: [365/484] Iter:[370/495], Time: 0.37, lr: [0.0028129923811459007], Loss: 1.944614, Acc:0.804999, Semantic loss: 0.729180, BCE loss: 0.517972, SB loss: 0.697462
2023-10-30 20:35:11,313 Epoch: [365/484] Iter:[380/495], Time: 0.37, lr: [0.002812559868158825], Loss: 1.942196, Acc:0.803890, Semantic loss: 0.728855, BCE loss: 0.516463, SB loss: 0.696878
2023-10-30 20:35:14,910 Epoch: [365/484] Iter:[390/495], Time: 0.37, lr: [0.0028121273477814596], Loss: 1.940108, Acc:0.803828, Semantic loss: 0.727452, BCE loss: 0.516020, SB loss: 0.696636
2023-10-30 20:35:18,522 Epoch: [365/484] Iter:[400/495], Time: 0.37, lr: [0.002811694820012415], Loss: 1.938009, Acc:0.802735, Semantic loss: 0.726396, BCE loss: 0.515962, SB loss: 0.695652
2023-10-30 20:35:22,356 Epoch: [365/484] Iter:[410/495], Time: 0.37, lr: [0.0028112622848503023], Loss: 1.939144, Acc:0.803061, Semantic loss: 0.726920, BCE loss: 0.516404, SB loss: 0.695820
2023-10-30 20:35:26,076 Epoch: [365/484] Iter:[420/495], Time: 0.37, lr: [0.002810829742293731], Loss: 1.939915, Acc:0.803671, Semantic loss: 0.727292, BCE loss: 0.516460, SB loss: 0.696162
2023-10-30 20:35:29,830 Epoch: [365/484] Iter:[430/495], Time: 0.37, lr: [0.00281039719234131], Loss: 1.941540, Acc:0.804655, Semantic loss: 0.726860, BCE loss: 0.518049, SB loss: 0.696631
2023-10-30 20:35:33,602 Epoch: [365/484] Iter:[440/495], Time: 0.37, lr: [0.002809964634991649], Loss: 1.942624, Acc:0.805500, Semantic loss: 0.726989, BCE loss: 0.519799, SB loss: 0.695836
2023-10-30 20:35:37,339 Epoch: [365/484] Iter:[450/495], Time: 0.37, lr: [0.002809532070243354], Loss: 1.944456, Acc:0.805929, Semantic loss: 0.727204, BCE loss: 0.521411, SB loss: 0.695841
2023-10-30 20:35:40,966 Epoch: [365/484] Iter:[460/495], Time: 0.37, lr: [0.002809099498095036], Loss: 1.945909, Acc:0.806466, Semantic loss: 0.728862, BCE loss: 0.521238, SB loss: 0.695809
2023-10-30 20:35:44,617 Epoch: [365/484] Iter:[470/495], Time: 0.37, lr: [0.0028086669185452997], Loss: 1.943696, Acc:0.806219, Semantic loss: 0.727575, BCE loss: 0.520497, SB loss: 0.695624
2023-10-30 20:35:48,324 Epoch: [365/484] Iter:[480/495], Time: 0.37, lr: [0.002808234331592752], Loss: 1.942439, Acc:0.805428, Semantic loss: 0.726534, BCE loss: 0.520259, SB loss: 0.695646
2023-10-30 20:35:51,818 Epoch: [365/484] Iter:[490/495], Time: 0.37, lr: [0.002807801737235999], Loss: 1.942704, Acc:0.806082, Semantic loss: 0.726327, BCE loss: 0.520530, SB loss: 0.695846
2023-10-30 20:38:48,334 0 [0.95172657 0.6975357  0.840295   0.22864698 0.27805295 0.43280547
 0.4926192  0.60427782 0.89286583 0.48095511 0.88088734 0.62655641
 0.02854408 0.84499629 0.00238844 0.1303279  0.10960332 0.09616235
 0.62946709] 0.48677441323883713
2023-10-30 20:38:48,335 1 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774] 0.748659201871844
2023-10-30 20:38:48,338 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:38:48,700 Loss: 1.970, MeanIU:  0.7487, Best_mIoU:  0.7487
2023-10-30 20:38:48,700 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774]
2023-10-30 20:38:50,949 Epoch: [366/484] Iter:[0/495], Time: 2.22, lr: [0.002807585437280611], Loss: 1.726167, Acc:0.816671, Semantic loss: 0.607810, BCE loss: 0.447533, SB loss: 0.670824
2023-10-30 20:38:54,653 Epoch: [366/484] Iter:[10/495], Time: 0.54, lr: [0.002807152831814938], Loss: 1.890883, Acc:0.801184, Semantic loss: 0.682789, BCE loss: 0.502285, SB loss: 0.705810
2023-10-30 20:38:58,226 Epoch: [366/484] Iter:[20/495], Time: 0.45, lr: [0.0028067202189415736], Loss: 1.903190, Acc:0.795586, Semantic loss: 0.703541, BCE loss: 0.502506, SB loss: 0.697143
2023-10-30 20:39:01,797 Epoch: [366/484] Iter:[30/495], Time: 0.42, lr: [0.0028062875986591225], Loss: 1.916905, Acc:0.800442, Semantic loss: 0.713287, BCE loss: 0.511284, SB loss: 0.692334
2023-10-30 20:39:05,277 Epoch: [366/484] Iter:[40/495], Time: 0.40, lr: [0.0028058549709661868], Loss: 1.961357, Acc:0.791751, Semantic loss: 0.741843, BCE loss: 0.514059, SB loss: 0.705455
2023-10-30 20:39:08,777 Epoch: [366/484] Iter:[50/495], Time: 0.39, lr: [0.0028054223358613736], Loss: 1.946642, Acc:0.798047, Semantic loss: 0.734124, BCE loss: 0.515467, SB loss: 0.697050
2023-10-30 20:39:12,357 Epoch: [366/484] Iter:[60/495], Time: 0.39, lr: [0.0028049896933432833], Loss: 1.953506, Acc:0.801208, Semantic loss: 0.733239, BCE loss: 0.524794, SB loss: 0.695473
2023-10-30 20:39:15,873 Epoch: [366/484] Iter:[70/495], Time: 0.38, lr: [0.0028045570434105196], Loss: 1.932787, Acc:0.805600, Semantic loss: 0.722572, BCE loss: 0.522006, SB loss: 0.688209
2023-10-30 20:39:19,438 Epoch: [366/484] Iter:[80/495], Time: 0.38, lr: [0.002804124386061682], Loss: 1.944167, Acc:0.809165, Semantic loss: 0.726003, BCE loss: 0.527543, SB loss: 0.690621
2023-10-30 20:39:23,051 Epoch: [366/484] Iter:[90/495], Time: 0.38, lr: [0.0028036917212953755], Loss: 1.945089, Acc:0.809224, Semantic loss: 0.730489, BCE loss: 0.523675, SB loss: 0.690925
2023-10-30 20:39:26,627 Epoch: [366/484] Iter:[100/495], Time: 0.38, lr: [0.0028032590491101988], Loss: 1.939019, Acc:0.811343, Semantic loss: 0.728193, BCE loss: 0.520275, SB loss: 0.690551
2023-10-30 20:39:30,179 Epoch: [366/484] Iter:[110/495], Time: 0.37, lr: [0.0028028263695047536], Loss: 1.939984, Acc:0.811269, Semantic loss: 0.729226, BCE loss: 0.519152, SB loss: 0.691607
2023-10-30 20:39:33,722 Epoch: [366/484] Iter:[120/495], Time: 0.37, lr: [0.0028023936824776376], Loss: 1.941918, Acc:0.813037, Semantic loss: 0.728399, BCE loss: 0.521097, SB loss: 0.692422
2023-10-30 20:39:37,311 Epoch: [366/484] Iter:[130/495], Time: 0.37, lr: [0.0028019609880274533], Loss: 1.941459, Acc:0.810761, Semantic loss: 0.728908, BCE loss: 0.518136, SB loss: 0.694416
2023-10-30 20:39:40,877 Epoch: [366/484] Iter:[140/495], Time: 0.37, lr: [0.0028015282861527974], Loss: 1.928858, Acc:0.810600, Semantic loss: 0.723901, BCE loss: 0.512978, SB loss: 0.691979
2023-10-30 20:39:44,413 Epoch: [366/484] Iter:[150/495], Time: 0.37, lr: [0.0028010955768522695], Loss: 1.938663, Acc:0.811646, Semantic loss: 0.725779, BCE loss: 0.518193, SB loss: 0.694691
2023-10-30 20:39:48,030 Epoch: [366/484] Iter:[160/495], Time: 0.37, lr: [0.002800662860124466], Loss: 1.934410, Acc:0.811389, Semantic loss: 0.723534, BCE loss: 0.517061, SB loss: 0.693814
2023-10-30 20:39:51,796 Epoch: [366/484] Iter:[170/495], Time: 0.37, lr: [0.002800230135967986], Loss: 1.935784, Acc:0.811674, Semantic loss: 0.722570, BCE loss: 0.519799, SB loss: 0.693414
2023-10-30 20:39:55,493 Epoch: [366/484] Iter:[180/495], Time: 0.37, lr: [0.002799797404381426], Loss: 1.940121, Acc:0.812209, Semantic loss: 0.725033, BCE loss: 0.520128, SB loss: 0.694960
2023-10-30 20:39:59,131 Epoch: [366/484] Iter:[190/495], Time: 0.37, lr: [0.0027993646653633815], Loss: 1.940442, Acc:0.812112, Semantic loss: 0.726333, BCE loss: 0.518545, SB loss: 0.695564
2023-10-30 20:40:02,677 Epoch: [366/484] Iter:[200/495], Time: 0.37, lr: [0.0027989319189124498], Loss: 1.936468, Acc:0.810695, Semantic loss: 0.724600, BCE loss: 0.517622, SB loss: 0.694247
2023-10-30 20:40:06,324 Epoch: [366/484] Iter:[210/495], Time: 0.37, lr: [0.0027984991650272253], Loss: 1.937009, Acc:0.811843, Semantic loss: 0.723311, BCE loss: 0.519611, SB loss: 0.694087
2023-10-30 20:40:09,947 Epoch: [366/484] Iter:[220/495], Time: 0.37, lr: [0.002798066403706303], Loss: 1.937127, Acc:0.810317, Semantic loss: 0.723608, BCE loss: 0.518499, SB loss: 0.695020
2023-10-30 20:40:13,592 Epoch: [366/484] Iter:[230/495], Time: 0.37, lr: [0.0027976336349482766], Loss: 1.940257, Acc:0.810993, Semantic loss: 0.725235, BCE loss: 0.520304, SB loss: 0.694718
2023-10-30 20:40:17,091 Epoch: [366/484] Iter:[240/495], Time: 0.37, lr: [0.0027972008587517417], Loss: 1.936526, Acc:0.810328, Semantic loss: 0.723050, BCE loss: 0.517868, SB loss: 0.695608
2023-10-30 20:40:20,615 Epoch: [366/484] Iter:[250/495], Time: 0.37, lr: [0.0027967680751152905], Loss: 1.937351, Acc:0.809750, Semantic loss: 0.724314, BCE loss: 0.516161, SB loss: 0.696876
2023-10-30 20:40:24,254 Epoch: [366/484] Iter:[260/495], Time: 0.37, lr: [0.0027963352840375167], Loss: 1.935357, Acc:0.809819, Semantic loss: 0.722646, BCE loss: 0.516928, SB loss: 0.695783
2023-10-30 20:40:27,802 Epoch: [366/484] Iter:[270/495], Time: 0.37, lr: [0.0027959024855170106], Loss: 1.929553, Acc:0.809687, Semantic loss: 0.719516, BCE loss: 0.515363, SB loss: 0.694674
2023-10-30 20:40:31,294 Epoch: [366/484] Iter:[280/495], Time: 0.36, lr: [0.0027954696795523667], Loss: 1.926509, Acc:0.809593, Semantic loss: 0.718101, BCE loss: 0.513851, SB loss: 0.694557
2023-10-30 20:40:35,001 Epoch: [366/484] Iter:[290/495], Time: 0.37, lr: [0.002795036866142175], Loss: 1.925095, Acc:0.808448, Semantic loss: 0.717878, BCE loss: 0.512909, SB loss: 0.694308
2023-10-30 20:40:38,688 Epoch: [366/484] Iter:[300/495], Time: 0.37, lr: [0.0027946040452850257], Loss: 1.934235, Acc:0.806674, Semantic loss: 0.723369, BCE loss: 0.512699, SB loss: 0.698167
2023-10-30 20:40:42,344 Epoch: [366/484] Iter:[310/495], Time: 0.37, lr: [0.0027941712169795097], Loss: 1.933676, Acc:0.806628, Semantic loss: 0.722356, BCE loss: 0.512301, SB loss: 0.699019
2023-10-30 20:40:45,987 Epoch: [366/484] Iter:[320/495], Time: 0.37, lr: [0.002793738381224217], Loss: 1.935816, Acc:0.806989, Semantic loss: 0.724567, BCE loss: 0.512761, SB loss: 0.698487
2023-10-30 20:40:49,681 Epoch: [366/484] Iter:[330/495], Time: 0.37, lr: [0.0027933055380177374], Loss: 1.934212, Acc:0.805786, Semantic loss: 0.723830, BCE loss: 0.512189, SB loss: 0.698193
2023-10-30 20:40:53,323 Epoch: [366/484] Iter:[340/495], Time: 0.37, lr: [0.002792872687358659], Loss: 1.936410, Acc:0.805529, Semantic loss: 0.724394, BCE loss: 0.513508, SB loss: 0.698508
2023-10-30 20:40:56,918 Epoch: [366/484] Iter:[350/495], Time: 0.37, lr: [0.002792439829245569], Loss: 1.938449, Acc:0.806135, Semantic loss: 0.724159, BCE loss: 0.515838, SB loss: 0.698453
2023-10-30 20:41:00,666 Epoch: [366/484] Iter:[360/495], Time: 0.37, lr: [0.002792006963677058], Loss: 1.941030, Acc:0.806113, Semantic loss: 0.725140, BCE loss: 0.517241, SB loss: 0.698650
2023-10-30 20:41:04,272 Epoch: [366/484] Iter:[370/495], Time: 0.37, lr: [0.0027915740906517108], Loss: 1.943133, Acc:0.806166, Semantic loss: 0.725609, BCE loss: 0.518359, SB loss: 0.699165
2023-10-30 20:41:08,001 Epoch: [366/484] Iter:[380/495], Time: 0.37, lr: [0.002791141210168115], Loss: 1.942627, Acc:0.806331, Semantic loss: 0.725140, BCE loss: 0.518639, SB loss: 0.698848
2023-10-30 20:41:11,683 Epoch: [366/484] Iter:[390/495], Time: 0.37, lr: [0.002790708322224855], Loss: 1.947672, Acc:0.806283, Semantic loss: 0.728357, BCE loss: 0.519780, SB loss: 0.699536
2023-10-30 20:41:15,276 Epoch: [366/484] Iter:[400/495], Time: 0.37, lr: [0.0027902754268205204], Loss: 1.947634, Acc:0.806069, Semantic loss: 0.728645, BCE loss: 0.519529, SB loss: 0.699460
2023-10-30 20:41:18,951 Epoch: [366/484] Iter:[410/495], Time: 0.37, lr: [0.002789842523953693], Loss: 1.945764, Acc:0.806521, Semantic loss: 0.727589, BCE loss: 0.519248, SB loss: 0.698927
2023-10-30 20:41:22,562 Epoch: [366/484] Iter:[420/495], Time: 0.37, lr: [0.00278940961362296], Loss: 1.946553, Acc:0.806334, Semantic loss: 0.728391, BCE loss: 0.518657, SB loss: 0.699505
2023-10-30 20:41:26,108 Epoch: [366/484] Iter:[430/495], Time: 0.37, lr: [0.0027889766958269025], Loss: 1.947716, Acc:0.806112, Semantic loss: 0.728626, BCE loss: 0.519275, SB loss: 0.699815
2023-10-30 20:41:29,832 Epoch: [366/484] Iter:[440/495], Time: 0.37, lr: [0.002788543770564107], Loss: 1.946847, Acc:0.806388, Semantic loss: 0.728717, BCE loss: 0.518543, SB loss: 0.699587
2023-10-30 20:41:33,574 Epoch: [366/484] Iter:[450/495], Time: 0.37, lr: [0.0027881108378331556], Loss: 1.949390, Acc:0.806469, Semantic loss: 0.731261, BCE loss: 0.517362, SB loss: 0.700767
2023-10-30 20:41:37,195 Epoch: [366/484] Iter:[460/495], Time: 0.37, lr: [0.002787677897632631], Loss: 1.948760, Acc:0.807280, Semantic loss: 0.730549, BCE loss: 0.517615, SB loss: 0.700596
2023-10-30 20:41:40,894 Epoch: [366/484] Iter:[470/495], Time: 0.37, lr: [0.002787244949961114], Loss: 1.949889, Acc:0.806259, Semantic loss: 0.731128, BCE loss: 0.517804, SB loss: 0.700957
2023-10-30 20:41:44,712 Epoch: [366/484] Iter:[480/495], Time: 0.37, lr: [0.0027868119948171884], Loss: 1.950484, Acc:0.806047, Semantic loss: 0.731633, BCE loss: 0.517203, SB loss: 0.701649
2023-10-30 20:41:48,155 Epoch: [366/484] Iter:[490/495], Time: 0.37, lr: [0.002786379032199435], Loss: 1.950929, Acc:0.806428, Semantic loss: 0.731483, BCE loss: 0.517835, SB loss: 0.701611
2023-10-30 20:41:49,513 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:41:49,752 Loss: 1.970, MeanIU:  0.7487, Best_mIoU:  0.7487
2023-10-30 20:41:49,752 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774]
2023-10-30 20:41:51,906 Epoch: [367/484] Iter:[0/495], Time: 2.12, lr: [0.0027861625480874288], Loss: 1.946931, Acc:0.698546, Semantic loss: 0.649967, BCE loss: 0.668669, SB loss: 0.628296
2023-10-30 20:41:55,952 Epoch: [367/484] Iter:[10/495], Time: 0.56, lr: [0.0027857295742562695], Loss: 1.977463, Acc:0.797918, Semantic loss: 0.745772, BCE loss: 0.544363, SB loss: 0.687328
2023-10-30 20:41:59,533 Epoch: [367/484] Iter:[20/495], Time: 0.46, lr: [0.002785296592947733], Loss: 1.999235, Acc:0.807246, Semantic loss: 0.781259, BCE loss: 0.516366, SB loss: 0.701609
2023-10-30 20:42:03,165 Epoch: [367/484] Iter:[30/495], Time: 0.43, lr: [0.002784863604160398], Loss: 2.031987, Acc:0.806082, Semantic loss: 0.789494, BCE loss: 0.531148, SB loss: 0.711344
2023-10-30 20:42:06,732 Epoch: [367/484] Iter:[40/495], Time: 0.41, lr: [0.0027844306078928433], Loss: 1.983390, Acc:0.804800, Semantic loss: 0.758555, BCE loss: 0.518831, SB loss: 0.706004
2023-10-30 20:42:10,248 Epoch: [367/484] Iter:[50/495], Time: 0.40, lr: [0.002783997604143646], Loss: 1.962435, Acc:0.807282, Semantic loss: 0.747576, BCE loss: 0.513585, SB loss: 0.701274
2023-10-30 20:42:13,866 Epoch: [367/484] Iter:[60/495], Time: 0.39, lr: [0.0027835645929113854], Loss: 1.955043, Acc:0.803013, Semantic loss: 0.745975, BCE loss: 0.510509, SB loss: 0.698559
2023-10-30 20:42:17,535 Epoch: [367/484] Iter:[70/495], Time: 0.39, lr: [0.0027831315741946388], Loss: 1.946844, Acc:0.798882, Semantic loss: 0.739059, BCE loss: 0.507364, SB loss: 0.700421
2023-10-30 20:42:21,376 Epoch: [367/484] Iter:[80/495], Time: 0.39, lr: [0.0027826985479919818], Loss: 1.947504, Acc:0.799179, Semantic loss: 0.734829, BCE loss: 0.511286, SB loss: 0.701390
2023-10-30 20:42:24,904 Epoch: [367/484] Iter:[90/495], Time: 0.39, lr: [0.00278226551430199], Loss: 1.958161, Acc:0.799233, Semantic loss: 0.740949, BCE loss: 0.514038, SB loss: 0.703174
2023-10-30 20:42:28,524 Epoch: [367/484] Iter:[100/495], Time: 0.38, lr: [0.0027818324731232412], Loss: 1.962694, Acc:0.802868, Semantic loss: 0.742591, BCE loss: 0.514261, SB loss: 0.705842
2023-10-30 20:42:32,125 Epoch: [367/484] Iter:[110/495], Time: 0.38, lr: [0.0027813994244543093], Loss: 1.960170, Acc:0.800455, Semantic loss: 0.742119, BCE loss: 0.511800, SB loss: 0.706251
2023-10-30 20:42:35,798 Epoch: [367/484] Iter:[120/495], Time: 0.38, lr: [0.0027809663682937698], Loss: 1.975895, Acc:0.799142, Semantic loss: 0.747415, BCE loss: 0.518283, SB loss: 0.710197
2023-10-30 20:42:39,519 Epoch: [367/484] Iter:[130/495], Time: 0.38, lr: [0.002780533304640194], Loss: 1.980361, Acc:0.798628, Semantic loss: 0.751998, BCE loss: 0.516915, SB loss: 0.711448
2023-10-30 20:42:43,209 Epoch: [367/484] Iter:[140/495], Time: 0.38, lr: [0.0027801002334921594], Loss: 1.975466, Acc:0.799834, Semantic loss: 0.746828, BCE loss: 0.519699, SB loss: 0.708938
2023-10-30 20:42:46,784 Epoch: [367/484] Iter:[150/495], Time: 0.38, lr: [0.002779667154848237], Loss: 1.969353, Acc:0.800653, Semantic loss: 0.742260, BCE loss: 0.519684, SB loss: 0.707408
2023-10-30 20:42:50,392 Epoch: [367/484] Iter:[160/495], Time: 0.38, lr: [0.002779234068707], Loss: 1.972317, Acc:0.800025, Semantic loss: 0.744067, BCE loss: 0.519696, SB loss: 0.708554
2023-10-30 20:42:53,915 Epoch: [367/484] Iter:[170/495], Time: 0.38, lr: [0.002778800975067019], Loss: 1.972385, Acc:0.802034, Semantic loss: 0.741694, BCE loss: 0.522499, SB loss: 0.708192
2023-10-30 20:42:57,459 Epoch: [367/484] Iter:[180/495], Time: 0.37, lr: [0.0027783678739268683], Loss: 1.973506, Acc:0.799933, Semantic loss: 0.743601, BCE loss: 0.523130, SB loss: 0.706775
2023-10-30 20:43:01,029 Epoch: [367/484] Iter:[190/495], Time: 0.37, lr: [0.0027779347652851162], Loss: 1.971683, Acc:0.800407, Semantic loss: 0.740840, BCE loss: 0.524455, SB loss: 0.706389
2023-10-30 20:43:04,502 Epoch: [367/484] Iter:[200/495], Time: 0.37, lr: [0.0027775016491403347], Loss: 1.971210, Acc:0.798989, Semantic loss: 0.740559, BCE loss: 0.524029, SB loss: 0.706622
2023-10-30 20:43:08,257 Epoch: [367/484] Iter:[210/495], Time: 0.37, lr: [0.0027770685254910926], Loss: 1.968487, Acc:0.800172, Semantic loss: 0.737663, BCE loss: 0.523543, SB loss: 0.707281
2023-10-30 20:43:11,895 Epoch: [367/484] Iter:[220/495], Time: 0.37, lr: [0.0027766353943359614], Loss: 1.970176, Acc:0.799425, Semantic loss: 0.740700, BCE loss: 0.521222, SB loss: 0.708255
2023-10-30 20:43:15,538 Epoch: [367/484] Iter:[230/495], Time: 0.37, lr: [0.002776202255673508], Loss: 1.966408, Acc:0.800247, Semantic loss: 0.738527, BCE loss: 0.520502, SB loss: 0.707378
2023-10-30 20:43:19,168 Epoch: [367/484] Iter:[240/495], Time: 0.37, lr: [0.0027757691095023017], Loss: 1.966510, Acc:0.802019, Semantic loss: 0.737880, BCE loss: 0.521902, SB loss: 0.706728
2023-10-30 20:43:22,772 Epoch: [367/484] Iter:[250/495], Time: 0.37, lr: [0.0027753359558209097], Loss: 1.969583, Acc:0.801256, Semantic loss: 0.739450, BCE loss: 0.522891, SB loss: 0.707242
2023-10-30 20:43:26,449 Epoch: [367/484] Iter:[260/495], Time: 0.37, lr: [0.002774902794627901], Loss: 1.967927, Acc:0.801365, Semantic loss: 0.737616, BCE loss: 0.524013, SB loss: 0.706297
2023-10-30 20:43:30,053 Epoch: [367/484] Iter:[270/495], Time: 0.37, lr: [0.002774469625921841], Loss: 1.974370, Acc:0.802321, Semantic loss: 0.739907, BCE loss: 0.527669, SB loss: 0.706794
2023-10-30 20:43:33,750 Epoch: [367/484] Iter:[280/495], Time: 0.37, lr: [0.0027740364497012967], Loss: 1.976383, Acc:0.803994, Semantic loss: 0.741392, BCE loss: 0.527953, SB loss: 0.707038
2023-10-30 20:43:37,375 Epoch: [367/484] Iter:[290/495], Time: 0.37, lr: [0.002773603265964832], Loss: 1.970500, Acc:0.804162, Semantic loss: 0.738847, BCE loss: 0.525424, SB loss: 0.706229
2023-10-30 20:43:41,058 Epoch: [367/484] Iter:[300/495], Time: 0.37, lr: [0.002773170074711015], Loss: 1.969047, Acc:0.804470, Semantic loss: 0.737542, BCE loss: 0.525486, SB loss: 0.706019
2023-10-30 20:43:44,702 Epoch: [367/484] Iter:[310/495], Time: 0.37, lr: [0.002772736875938409], Loss: 1.968561, Acc:0.804597, Semantic loss: 0.736437, BCE loss: 0.526506, SB loss: 0.705617
2023-10-30 20:43:48,287 Epoch: [367/484] Iter:[320/495], Time: 0.37, lr: [0.002772303669645579], Loss: 1.970111, Acc:0.805649, Semantic loss: 0.736917, BCE loss: 0.527232, SB loss: 0.705963
2023-10-30 20:43:51,864 Epoch: [367/484] Iter:[330/495], Time: 0.37, lr: [0.002771870455831087], Loss: 1.967494, Acc:0.805673, Semantic loss: 0.736018, BCE loss: 0.526249, SB loss: 0.705227
2023-10-30 20:43:55,451 Epoch: [367/484] Iter:[340/495], Time: 0.37, lr: [0.0027714372344934987], Loss: 1.965603, Acc:0.804087, Semantic loss: 0.736663, BCE loss: 0.523489, SB loss: 0.705451
2023-10-30 20:43:59,077 Epoch: [367/484] Iter:[350/495], Time: 0.37, lr: [0.0027710040056313744], Loss: 1.967163, Acc:0.803577, Semantic loss: 0.739577, BCE loss: 0.521595, SB loss: 0.705990
2023-10-30 20:44:02,788 Epoch: [367/484] Iter:[360/495], Time: 0.37, lr: [0.002770570769243278], Loss: 1.969358, Acc:0.804658, Semantic loss: 0.739611, BCE loss: 0.523827, SB loss: 0.705920
2023-10-30 20:44:06,323 Epoch: [367/484] Iter:[370/495], Time: 0.37, lr: [0.002770137525327769], Loss: 1.970918, Acc:0.803307, Semantic loss: 0.739349, BCE loss: 0.524980, SB loss: 0.706590
2023-10-30 20:44:10,004 Epoch: [367/484] Iter:[380/495], Time: 0.37, lr: [0.002769704273883411], Loss: 1.972136, Acc:0.802712, Semantic loss: 0.740329, BCE loss: 0.525443, SB loss: 0.706365
2023-10-30 20:44:13,719 Epoch: [367/484] Iter:[390/495], Time: 0.37, lr: [0.0027692710149087637], Loss: 1.971824, Acc:0.802718, Semantic loss: 0.739018, BCE loss: 0.526912, SB loss: 0.705894
2023-10-30 20:44:17,369 Epoch: [367/484] Iter:[400/495], Time: 0.37, lr: [0.002768837748402386], Loss: 1.968537, Acc:0.802882, Semantic loss: 0.738590, BCE loss: 0.525064, SB loss: 0.704883
2023-10-30 20:44:21,030 Epoch: [367/484] Iter:[410/495], Time: 0.37, lr: [0.0027684044743628384], Loss: 1.966677, Acc:0.802657, Semantic loss: 0.737982, BCE loss: 0.524000, SB loss: 0.704695
2023-10-30 20:44:24,670 Epoch: [367/484] Iter:[420/495], Time: 0.37, lr: [0.00276797119278868], Loss: 1.966876, Acc:0.802370, Semantic loss: 0.737699, BCE loss: 0.524167, SB loss: 0.705010
2023-10-30 20:44:28,290 Epoch: [367/484] Iter:[430/495], Time: 0.37, lr: [0.0027675379036784693], Loss: 1.968212, Acc:0.803351, Semantic loss: 0.737861, BCE loss: 0.525302, SB loss: 0.705049
2023-10-30 20:44:31,843 Epoch: [367/484] Iter:[440/495], Time: 0.37, lr: [0.0027671046070307636], Loss: 1.966061, Acc:0.803120, Semantic loss: 0.736611, BCE loss: 0.524725, SB loss: 0.704724
2023-10-30 20:44:35,427 Epoch: [367/484] Iter:[450/495], Time: 0.37, lr: [0.0027666713028441196], Loss: 1.962880, Acc:0.802331, Semantic loss: 0.735632, BCE loss: 0.522829, SB loss: 0.704419
2023-10-30 20:44:39,071 Epoch: [367/484] Iter:[460/495], Time: 0.37, lr: [0.002766237991117097], Loss: 1.963681, Acc:0.803053, Semantic loss: 0.736362, BCE loss: 0.522745, SB loss: 0.704574
2023-10-30 20:44:42,658 Epoch: [367/484] Iter:[470/495], Time: 0.37, lr: [0.00276580467184825], Loss: 1.963581, Acc:0.803303, Semantic loss: 0.736062, BCE loss: 0.522787, SB loss: 0.704733
2023-10-30 20:44:46,276 Epoch: [367/484] Iter:[480/495], Time: 0.37, lr: [0.0027653713450361346], Loss: 1.964105, Acc:0.803769, Semantic loss: 0.734978, BCE loss: 0.524809, SB loss: 0.704318
2023-10-30 20:44:49,715 Epoch: [367/484] Iter:[490/495], Time: 0.37, lr: [0.002764938010679305], Loss: 1.962386, Acc:0.803904, Semantic loss: 0.734383, BCE loss: 0.524002, SB loss: 0.704000
2023-10-30 20:44:51,088 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:44:51,322 Loss: 1.970, MeanIU:  0.7487, Best_mIoU:  0.7487
2023-10-30 20:44:51,322 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774]
2023-10-30 20:44:53,442 Epoch: [368/484] Iter:[0/495], Time: 2.08, lr: [0.0027647213406711718], Loss: 1.794652, Acc:0.746174, Semantic loss: 0.703058, BCE loss: 0.422096, SB loss: 0.669498
2023-10-30 20:44:57,282 Epoch: [368/484] Iter:[10/495], Time: 0.54, lr: [0.0027642879949945644], Loss: 1.856416, Acc:0.798553, Semantic loss: 0.683282, BCE loss: 0.516661, SB loss: 0.656473
2023-10-30 20:45:00,842 Epoch: [368/484] Iter:[20/495], Time: 0.45, lr: [0.0027638546417696292], Loss: 1.890467, Acc:0.795600, Semantic loss: 0.702377, BCE loss: 0.512701, SB loss: 0.675389
2023-10-30 20:45:04,475 Epoch: [368/484] Iter:[30/495], Time: 0.42, lr: [0.00276342128099492], Loss: 1.864367, Acc:0.801203, Semantic loss: 0.681465, BCE loss: 0.508883, SB loss: 0.674018
2023-10-30 20:45:08,081 Epoch: [368/484] Iter:[40/495], Time: 0.41, lr: [0.002762987912668991], Loss: 1.872028, Acc:0.805133, Semantic loss: 0.678558, BCE loss: 0.514169, SB loss: 0.679302
2023-10-30 20:45:11,701 Epoch: [368/484] Iter:[50/495], Time: 0.40, lr: [0.0027625545367903942], Loss: 1.896352, Acc:0.804631, Semantic loss: 0.684785, BCE loss: 0.527020, SB loss: 0.684547
2023-10-30 20:45:15,377 Epoch: [368/484] Iter:[60/495], Time: 0.39, lr: [0.0027621211533576805], Loss: 1.890292, Acc:0.801565, Semantic loss: 0.686015, BCE loss: 0.521159, SB loss: 0.683117
2023-10-30 20:45:19,009 Epoch: [368/484] Iter:[70/495], Time: 0.39, lr: [0.0027616877623694008], Loss: 1.878903, Acc:0.803109, Semantic loss: 0.682118, BCE loss: 0.516552, SB loss: 0.680232
2023-10-30 20:45:22,683 Epoch: [368/484] Iter:[80/495], Time: 0.39, lr: [0.002761254363824108], Loss: 1.891002, Acc:0.804012, Semantic loss: 0.690849, BCE loss: 0.519274, SB loss: 0.680880
2023-10-30 20:45:26,399 Epoch: [368/484] Iter:[90/495], Time: 0.39, lr: [0.0027608209577203507], Loss: 1.894124, Acc:0.805117, Semantic loss: 0.692622, BCE loss: 0.519467, SB loss: 0.682035
2023-10-30 20:45:30,031 Epoch: [368/484] Iter:[100/495], Time: 0.38, lr: [0.00276038754405668], Loss: 1.906596, Acc:0.805378, Semantic loss: 0.700429, BCE loss: 0.516399, SB loss: 0.689767
2023-10-30 20:45:33,621 Epoch: [368/484] Iter:[110/495], Time: 0.38, lr: [0.0027599541228316422], Loss: 1.908317, Acc:0.803998, Semantic loss: 0.705360, BCE loss: 0.513909, SB loss: 0.689047
2023-10-30 20:45:37,218 Epoch: [368/484] Iter:[120/495], Time: 0.38, lr: [0.0027595206940437896], Loss: 1.906923, Acc:0.805932, Semantic loss: 0.708562, BCE loss: 0.509153, SB loss: 0.689209
2023-10-30 20:45:40,817 Epoch: [368/484] Iter:[130/495], Time: 0.38, lr: [0.0027590872576916687], Loss: 1.921741, Acc:0.805204, Semantic loss: 0.717698, BCE loss: 0.512378, SB loss: 0.691666
2023-10-30 20:45:44,356 Epoch: [368/484] Iter:[140/495], Time: 0.38, lr: [0.002758653813773827], Loss: 1.919836, Acc:0.808435, Semantic loss: 0.713507, BCE loss: 0.516090, SB loss: 0.690239
2023-10-30 20:45:48,032 Epoch: [368/484] Iter:[150/495], Time: 0.38, lr: [0.002758220362288811], Loss: 1.918896, Acc:0.807489, Semantic loss: 0.711344, BCE loss: 0.517343, SB loss: 0.690209
2023-10-30 20:45:51,603 Epoch: [368/484] Iter:[160/495], Time: 0.37, lr: [0.0027577869032351684], Loss: 1.920976, Acc:0.808236, Semantic loss: 0.712553, BCE loss: 0.516765, SB loss: 0.691658
2023-10-30 20:45:55,295 Epoch: [368/484] Iter:[170/495], Time: 0.37, lr: [0.002757353436611445], Loss: 1.919811, Acc:0.806894, Semantic loss: 0.714542, BCE loss: 0.513117, SB loss: 0.692152
2023-10-30 20:45:58,884 Epoch: [368/484] Iter:[180/495], Time: 0.37, lr: [0.0027569199624161863], Loss: 1.918863, Acc:0.806347, Semantic loss: 0.714415, BCE loss: 0.512291, SB loss: 0.692156
2023-10-30 20:46:02,472 Epoch: [368/484] Iter:[190/495], Time: 0.37, lr: [0.0027564864806479358], Loss: 1.917006, Acc:0.806534, Semantic loss: 0.715033, BCE loss: 0.511661, SB loss: 0.690312
2023-10-30 20:46:06,047 Epoch: [368/484] Iter:[200/495], Time: 0.37, lr: [0.0027560529913052394], Loss: 1.924492, Acc:0.806701, Semantic loss: 0.718439, BCE loss: 0.514661, SB loss: 0.691392
2023-10-30 20:46:09,740 Epoch: [368/484] Iter:[210/495], Time: 0.37, lr: [0.0027556194943866414], Loss: 1.922711, Acc:0.807039, Semantic loss: 0.718978, BCE loss: 0.512941, SB loss: 0.690791
2023-10-30 20:46:13,455 Epoch: [368/484] Iter:[220/495], Time: 0.37, lr: [0.0027551859898906845], Loss: 1.926993, Acc:0.806791, Semantic loss: 0.721212, BCE loss: 0.514212, SB loss: 0.691569
2023-10-30 20:46:16,992 Epoch: [368/484] Iter:[230/495], Time: 0.37, lr: [0.00275475247781591], Loss: 1.927066, Acc:0.807343, Semantic loss: 0.721271, BCE loss: 0.513593, SB loss: 0.692203
2023-10-30 20:46:20,604 Epoch: [368/484] Iter:[240/495], Time: 0.37, lr: [0.0027543189581608622], Loss: 1.927406, Acc:0.807185, Semantic loss: 0.721516, BCE loss: 0.512823, SB loss: 0.693068
2023-10-30 20:46:24,182 Epoch: [368/484] Iter:[250/495], Time: 0.37, lr: [0.002753885430924083], Loss: 1.927665, Acc:0.807570, Semantic loss: 0.721319, BCE loss: 0.513023, SB loss: 0.693323
2023-10-30 20:46:27,675 Epoch: [368/484] Iter:[260/495], Time: 0.37, lr: [0.002753451896104112], Loss: 1.930592, Acc:0.805723, Semantic loss: 0.723448, BCE loss: 0.512452, SB loss: 0.694693
2023-10-30 20:46:31,256 Epoch: [368/484] Iter:[270/495], Time: 0.37, lr: [0.00275301835369949], Loss: 1.932744, Acc:0.805152, Semantic loss: 0.723394, BCE loss: 0.513938, SB loss: 0.695413
2023-10-30 20:46:34,843 Epoch: [368/484] Iter:[280/495], Time: 0.37, lr: [0.002752584803708759], Loss: 1.929936, Acc:0.804562, Semantic loss: 0.722662, BCE loss: 0.512212, SB loss: 0.695062
2023-10-30 20:46:38,468 Epoch: [368/484] Iter:[290/495], Time: 0.37, lr: [0.002752151246130457], Loss: 1.929534, Acc:0.805553, Semantic loss: 0.722627, BCE loss: 0.512168, SB loss: 0.694739
2023-10-30 20:46:42,193 Epoch: [368/484] Iter:[300/495], Time: 0.37, lr: [0.002751717680963124], Loss: 1.929431, Acc:0.805279, Semantic loss: 0.722818, BCE loss: 0.511765, SB loss: 0.694848
2023-10-30 20:46:45,864 Epoch: [368/484] Iter:[310/495], Time: 0.37, lr: [0.002751284108205296], Loss: 1.927270, Acc:0.805854, Semantic loss: 0.722111, BCE loss: 0.510436, SB loss: 0.694724
2023-10-30 20:46:49,477 Epoch: [368/484] Iter:[320/495], Time: 0.37, lr: [0.0027508505278555145], Loss: 1.928212, Acc:0.806193, Semantic loss: 0.723713, BCE loss: 0.509331, SB loss: 0.695168
2023-10-30 20:46:53,154 Epoch: [368/484] Iter:[330/495], Time: 0.37, lr: [0.0027504169399123154], Loss: 1.930555, Acc:0.806750, Semantic loss: 0.724160, BCE loss: 0.511123, SB loss: 0.695271
2023-10-30 20:46:56,880 Epoch: [368/484] Iter:[340/495], Time: 0.37, lr: [0.002749983344374235], Loss: 1.929931, Acc:0.806343, Semantic loss: 0.724950, BCE loss: 0.510563, SB loss: 0.694418
2023-10-30 20:47:00,533 Epoch: [368/484] Iter:[350/495], Time: 0.37, lr: [0.0027495497412398096], Loss: 1.930881, Acc:0.806874, Semantic loss: 0.725276, BCE loss: 0.510373, SB loss: 0.695232
2023-10-30 20:47:04,098 Epoch: [368/484] Iter:[360/495], Time: 0.37, lr: [0.0027491161305075768], Loss: 1.931291, Acc:0.806272, Semantic loss: 0.725314, BCE loss: 0.510119, SB loss: 0.695858
2023-10-30 20:47:07,822 Epoch: [368/484] Iter:[370/495], Time: 0.37, lr: [0.00274868251217607], Loss: 1.932687, Acc:0.807066, Semantic loss: 0.726348, BCE loss: 0.509685, SB loss: 0.696654
2023-10-30 20:47:11,486 Epoch: [368/484] Iter:[380/495], Time: 0.37, lr: [0.0027482488862438253], Loss: 1.934595, Acc:0.807566, Semantic loss: 0.726759, BCE loss: 0.510827, SB loss: 0.697009
2023-10-30 20:47:15,205 Epoch: [368/484] Iter:[390/495], Time: 0.37, lr: [0.0027478152527093754], Loss: 1.936077, Acc:0.807515, Semantic loss: 0.726893, BCE loss: 0.511845, SB loss: 0.697339
2023-10-30 20:47:18,858 Epoch: [368/484] Iter:[400/495], Time: 0.37, lr: [0.002747381611571255], Loss: 1.937738, Acc:0.807806, Semantic loss: 0.728135, BCE loss: 0.512075, SB loss: 0.697528
2023-10-30 20:47:22,567 Epoch: [368/484] Iter:[410/495], Time: 0.37, lr: [0.0027469479628279975], Loss: 1.935297, Acc:0.806834, Semantic loss: 0.727190, BCE loss: 0.511035, SB loss: 0.697073
2023-10-30 20:47:26,244 Epoch: [368/484] Iter:[420/495], Time: 0.37, lr: [0.0027465143064781352], Loss: 1.935920, Acc:0.806908, Semantic loss: 0.727473, BCE loss: 0.511262, SB loss: 0.697185
2023-10-30 20:47:29,865 Epoch: [368/484] Iter:[430/495], Time: 0.37, lr: [0.002746080642520199], Loss: 1.937658, Acc:0.807333, Semantic loss: 0.727632, BCE loss: 0.512521, SB loss: 0.697504
2023-10-30 20:47:33,477 Epoch: [368/484] Iter:[440/495], Time: 0.37, lr: [0.002745646970952722], Loss: 1.936878, Acc:0.807128, Semantic loss: 0.727001, BCE loss: 0.512314, SB loss: 0.697563
2023-10-30 20:47:37,083 Epoch: [368/484] Iter:[450/495], Time: 0.37, lr: [0.0027452132917742352], Loss: 1.936287, Acc:0.807217, Semantic loss: 0.726889, BCE loss: 0.512243, SB loss: 0.697154
2023-10-30 20:47:40,701 Epoch: [368/484] Iter:[460/495], Time: 0.37, lr: [0.002744779604983268], Loss: 1.934952, Acc:0.807427, Semantic loss: 0.725895, BCE loss: 0.512836, SB loss: 0.696221
2023-10-30 20:47:44,401 Epoch: [368/484] Iter:[470/495], Time: 0.37, lr: [0.0027443459105783493], Loss: 1.935226, Acc:0.806708, Semantic loss: 0.726784, BCE loss: 0.512275, SB loss: 0.696167
2023-10-30 20:47:48,094 Epoch: [368/484] Iter:[480/495], Time: 0.37, lr: [0.002743912208558011], Loss: 1.934957, Acc:0.806208, Semantic loss: 0.726717, BCE loss: 0.511652, SB loss: 0.696588
2023-10-30 20:47:51,528 Epoch: [368/484] Iter:[490/495], Time: 0.37, lr: [0.002743478498920781], Loss: 1.934241, Acc:0.806099, Semantic loss: 0.725362, BCE loss: 0.512429, SB loss: 0.696450
2023-10-30 20:47:52,909 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:47:53,139 Loss: 1.970, MeanIU:  0.7487, Best_mIoU:  0.7487
2023-10-30 20:47:53,139 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774]
2023-10-30 20:47:55,035 Epoch: [369/484] Iter:[0/495], Time: 1.86, lr: [0.0027432616412453713], Loss: 1.975951, Acc:0.872556, Semantic loss: 0.719251, BCE loss: 0.499503, SB loss: 0.757197
2023-10-30 20:47:59,142 Epoch: [369/484] Iter:[10/495], Time: 0.54, lr: [0.0027428279201800426], Loss: 1.912191, Acc:0.819094, Semantic loss: 0.687167, BCE loss: 0.535518, SB loss: 0.689506
2023-10-30 20:48:02,761 Epoch: [369/484] Iter:[20/495], Time: 0.46, lr: [0.0027423941914941417], Loss: 1.901329, Acc:0.819348, Semantic loss: 0.692233, BCE loss: 0.526127, SB loss: 0.682968
2023-10-30 20:48:06,397 Epoch: [369/484] Iter:[30/495], Time: 0.43, lr: [0.0027419604551861963], Loss: 1.896752, Acc:0.803629, Semantic loss: 0.692168, BCE loss: 0.520212, SB loss: 0.684371
2023-10-30 20:48:09,959 Epoch: [369/484] Iter:[40/495], Time: 0.41, lr: [0.0027415267112547315], Loss: 1.943856, Acc:0.794675, Semantic loss: 0.729654, BCE loss: 0.514114, SB loss: 0.700088
2023-10-30 20:48:13,542 Epoch: [369/484] Iter:[50/495], Time: 0.40, lr: [0.002741092959698272], Loss: 1.968973, Acc:0.792453, Semantic loss: 0.741204, BCE loss: 0.525694, SB loss: 0.702076
2023-10-30 20:48:17,244 Epoch: [369/484] Iter:[60/495], Time: 0.39, lr: [0.002740659200515346], Loss: 1.974241, Acc:0.791179, Semantic loss: 0.739854, BCE loss: 0.533363, SB loss: 0.701023
2023-10-30 20:48:20,970 Epoch: [369/484] Iter:[70/495], Time: 0.39, lr: [0.0027402254337044758], Loss: 1.966446, Acc:0.800742, Semantic loss: 0.735774, BCE loss: 0.530061, SB loss: 0.700610
2023-10-30 20:48:24,580 Epoch: [369/484] Iter:[80/495], Time: 0.39, lr: [0.0027397916592641867], Loss: 1.965301, Acc:0.805692, Semantic loss: 0.732729, BCE loss: 0.528643, SB loss: 0.703928
2023-10-30 20:48:28,280 Epoch: [369/484] Iter:[90/495], Time: 0.39, lr: [0.002739357877193002], Loss: 1.961428, Acc:0.810539, Semantic loss: 0.728993, BCE loss: 0.528882, SB loss: 0.703553
2023-10-30 20:48:32,098 Epoch: [369/484] Iter:[100/495], Time: 0.39, lr: [0.0027389240874894443], Loss: 1.980005, Acc:0.811101, Semantic loss: 0.735460, BCE loss: 0.538302, SB loss: 0.706242
2023-10-30 20:48:35,684 Epoch: [369/484] Iter:[110/495], Time: 0.38, lr: [0.0027384902901520375], Loss: 1.978889, Acc:0.810812, Semantic loss: 0.733847, BCE loss: 0.538678, SB loss: 0.706365
2023-10-30 20:48:39,361 Epoch: [369/484] Iter:[120/495], Time: 0.38, lr: [0.0027380564851793025], Loss: 1.966883, Acc:0.809333, Semantic loss: 0.730834, BCE loss: 0.532611, SB loss: 0.703439
2023-10-30 20:48:42,980 Epoch: [369/484] Iter:[130/495], Time: 0.38, lr: [0.0027376226725697606], Loss: 1.971960, Acc:0.810214, Semantic loss: 0.733150, BCE loss: 0.535924, SB loss: 0.702885
2023-10-30 20:48:46,634 Epoch: [369/484] Iter:[140/495], Time: 0.38, lr: [0.0027371888523219333], Loss: 1.974307, Acc:0.807833, Semantic loss: 0.736243, BCE loss: 0.534125, SB loss: 0.703939
2023-10-30 20:48:50,278 Epoch: [369/484] Iter:[150/495], Time: 0.38, lr: [0.0027367550244343413], Loss: 1.970680, Acc:0.806011, Semantic loss: 0.734548, BCE loss: 0.532543, SB loss: 0.703589
2023-10-30 20:48:53,911 Epoch: [369/484] Iter:[160/495], Time: 0.38, lr: [0.002736321188905504], Loss: 1.963923, Acc:0.806117, Semantic loss: 0.729542, BCE loss: 0.532316, SB loss: 0.702064
2023-10-30 20:48:57,493 Epoch: [369/484] Iter:[170/495], Time: 0.38, lr: [0.002735887345733939], Loss: 1.965542, Acc:0.807111, Semantic loss: 0.729966, BCE loss: 0.533077, SB loss: 0.702499
2023-10-30 20:49:01,077 Epoch: [369/484] Iter:[180/495], Time: 0.38, lr: [0.0027354534949181673], Loss: 1.962362, Acc:0.806420, Semantic loss: 0.728949, BCE loss: 0.531067, SB loss: 0.702346
2023-10-30 20:49:04,722 Epoch: [369/484] Iter:[190/495], Time: 0.37, lr: [0.0027350196364567063], Loss: 1.959000, Acc:0.805911, Semantic loss: 0.730144, BCE loss: 0.528055, SB loss: 0.700801
2023-10-30 20:49:08,378 Epoch: [369/484] Iter:[200/495], Time: 0.37, lr: [0.0027345857703480743], Loss: 1.958199, Acc:0.805594, Semantic loss: 0.729173, BCE loss: 0.529474, SB loss: 0.699552
2023-10-30 20:49:11,979 Epoch: [369/484] Iter:[210/495], Time: 0.37, lr: [0.002734151896590786], Loss: 1.952685, Acc:0.806852, Semantic loss: 0.726590, BCE loss: 0.527471, SB loss: 0.698624
2023-10-30 20:49:15,587 Epoch: [369/484] Iter:[220/495], Time: 0.37, lr: [0.002733718015183361], Loss: 1.951557, Acc:0.806624, Semantic loss: 0.725745, BCE loss: 0.527260, SB loss: 0.698553
2023-10-30 20:49:19,195 Epoch: [369/484] Iter:[230/495], Time: 0.37, lr: [0.0027332841261243136], Loss: 1.954511, Acc:0.807879, Semantic loss: 0.726786, BCE loss: 0.528892, SB loss: 0.698833
2023-10-30 20:49:22,795 Epoch: [369/484] Iter:[240/495], Time: 0.37, lr: [0.002732850229412159], Loss: 1.951642, Acc:0.808320, Semantic loss: 0.725460, BCE loss: 0.528559, SB loss: 0.697623
2023-10-30 20:49:26,474 Epoch: [369/484] Iter:[250/495], Time: 0.37, lr: [0.0027324163250454126], Loss: 1.952740, Acc:0.808867, Semantic loss: 0.725938, BCE loss: 0.529599, SB loss: 0.697203
2023-10-30 20:49:30,117 Epoch: [369/484] Iter:[260/495], Time: 0.37, lr: [0.0027319824130225888], Loss: 1.955924, Acc:0.809056, Semantic loss: 0.726863, BCE loss: 0.530984, SB loss: 0.698078
2023-10-30 20:49:33,739 Epoch: [369/484] Iter:[270/495], Time: 0.37, lr: [0.002731548493342201], Loss: 1.956939, Acc:0.808274, Semantic loss: 0.728013, BCE loss: 0.529926, SB loss: 0.699001
2023-10-30 20:49:37,387 Epoch: [369/484] Iter:[280/495], Time: 0.37, lr: [0.0027311145660027635], Loss: 1.958214, Acc:0.808372, Semantic loss: 0.729029, BCE loss: 0.530045, SB loss: 0.699141
2023-10-30 20:49:40,997 Epoch: [369/484] Iter:[290/495], Time: 0.37, lr: [0.0027306806310027866], Loss: 1.961269, Acc:0.808932, Semantic loss: 0.731290, BCE loss: 0.530479, SB loss: 0.699500
2023-10-30 20:49:44,648 Epoch: [369/484] Iter:[300/495], Time: 0.37, lr: [0.0027302466883407845], Loss: 1.965912, Acc:0.806298, Semantic loss: 0.734530, BCE loss: 0.530105, SB loss: 0.701276
2023-10-30 20:49:48,212 Epoch: [369/484] Iter:[310/495], Time: 0.37, lr: [0.002729812738015268], Loss: 1.965525, Acc:0.806606, Semantic loss: 0.734166, BCE loss: 0.529827, SB loss: 0.701532
2023-10-30 20:49:51,802 Epoch: [369/484] Iter:[320/495], Time: 0.37, lr: [0.002729378780024749], Loss: 1.971544, Acc:0.806336, Semantic loss: 0.736036, BCE loss: 0.532212, SB loss: 0.703296
2023-10-30 20:49:55,506 Epoch: [369/484] Iter:[330/495], Time: 0.37, lr: [0.002728944814367736], Loss: 1.967506, Acc:0.806739, Semantic loss: 0.732681, BCE loss: 0.533161, SB loss: 0.701664
2023-10-30 20:49:59,184 Epoch: [369/484] Iter:[340/495], Time: 0.37, lr: [0.0027285108410427406], Loss: 1.970965, Acc:0.806957, Semantic loss: 0.735876, BCE loss: 0.532038, SB loss: 0.703051
2023-10-30 20:50:02,890 Epoch: [369/484] Iter:[350/495], Time: 0.37, lr: [0.002728076860048272], Loss: 1.970847, Acc:0.807608, Semantic loss: 0.735609, BCE loss: 0.531436, SB loss: 0.703802
2023-10-30 20:50:06,586 Epoch: [369/484] Iter:[360/495], Time: 0.37, lr: [0.002727642871382837], Loss: 1.971797, Acc:0.806605, Semantic loss: 0.736275, BCE loss: 0.531133, SB loss: 0.704388
2023-10-30 20:50:10,181 Epoch: [369/484] Iter:[370/495], Time: 0.37, lr: [0.0027272088750449476], Loss: 1.972670, Acc:0.806782, Semantic loss: 0.737874, BCE loss: 0.530491, SB loss: 0.704305
2023-10-30 20:50:13,804 Epoch: [369/484] Iter:[380/495], Time: 0.37, lr: [0.0027267748710331084], Loss: 1.971986, Acc:0.806777, Semantic loss: 0.737063, BCE loss: 0.531117, SB loss: 0.703806
2023-10-30 20:50:17,419 Epoch: [369/484] Iter:[390/495], Time: 0.37, lr: [0.002726340859345828], Loss: 1.968231, Acc:0.806875, Semantic loss: 0.735418, BCE loss: 0.529007, SB loss: 0.703806
2023-10-30 20:50:21,075 Epoch: [369/484] Iter:[400/495], Time: 0.37, lr: [0.0027259068399816113], Loss: 1.966318, Acc:0.807017, Semantic loss: 0.735018, BCE loss: 0.527919, SB loss: 0.703380
2023-10-30 20:50:24,706 Epoch: [369/484] Iter:[410/495], Time: 0.37, lr: [0.002725472812938966], Loss: 1.963416, Acc:0.807137, Semantic loss: 0.733409, BCE loss: 0.526708, SB loss: 0.703300
2023-10-30 20:50:28,323 Epoch: [369/484] Iter:[420/495], Time: 0.37, lr: [0.0027250387782163975], Loss: 1.965760, Acc:0.807598, Semantic loss: 0.734213, BCE loss: 0.528136, SB loss: 0.703411
2023-10-30 20:50:32,053 Epoch: [369/484] Iter:[430/495], Time: 0.37, lr: [0.0027246047358124104], Loss: 1.966437, Acc:0.806264, Semantic loss: 0.735237, BCE loss: 0.527515, SB loss: 0.703685
2023-10-30 20:50:35,635 Epoch: [369/484] Iter:[440/495], Time: 0.37, lr: [0.0027241706857255078], Loss: 1.965766, Acc:0.806882, Semantic loss: 0.735042, BCE loss: 0.527166, SB loss: 0.703558
2023-10-30 20:50:39,201 Epoch: [369/484] Iter:[450/495], Time: 0.37, lr: [0.002723736627954196], Loss: 1.966449, Acc:0.806375, Semantic loss: 0.735230, BCE loss: 0.527334, SB loss: 0.703885
2023-10-30 20:50:42,814 Epoch: [369/484] Iter:[460/495], Time: 0.37, lr: [0.0027233025624969764], Loss: 1.965003, Acc:0.806083, Semantic loss: 0.734962, BCE loss: 0.526670, SB loss: 0.703371
2023-10-30 20:50:46,398 Epoch: [369/484] Iter:[470/495], Time: 0.37, lr: [0.002722868489352352], Loss: 1.963859, Acc:0.805936, Semantic loss: 0.735272, BCE loss: 0.525925, SB loss: 0.702661
2023-10-30 20:50:50,006 Epoch: [369/484] Iter:[480/495], Time: 0.37, lr: [0.002722434408518825], Loss: 1.966188, Acc:0.805614, Semantic loss: 0.736696, BCE loss: 0.526061, SB loss: 0.703432
2023-10-30 20:50:53,520 Epoch: [369/484] Iter:[490/495], Time: 0.37, lr: [0.002722000319994897], Loss: 1.965012, Acc:0.805595, Semantic loss: 0.736872, BCE loss: 0.525020, SB loss: 0.703120
2023-10-30 20:50:54,892 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:50:55,122 Loss: 1.970, MeanIU:  0.7487, Best_mIoU:  0.7487
2023-10-30 20:50:55,122 [0.97719682 0.82123121 0.91932616 0.56956532 0.59340954 0.61225906
 0.68818661 0.75373142 0.91815461 0.61628298 0.93764645 0.79146941
 0.5781125  0.93730772 0.73265068 0.75854106 0.73844621 0.53127934
 0.74972774]
2023-10-30 20:50:57,257 Epoch: [370/484] Iter:[0/495], Time: 2.10, lr: [0.0027217832728485642], Loss: 1.776191, Acc:0.883705, Semantic loss: 0.627249, BCE loss: 0.524914, SB loss: 0.624028
2023-10-30 20:51:01,309 Epoch: [370/484] Iter:[10/495], Time: 0.56, lr: [0.002721349172786224], Loss: 1.992653, Acc:0.835577, Semantic loss: 0.730237, BCE loss: 0.549168, SB loss: 0.713249
2023-10-30 20:51:05,105 Epoch: [370/484] Iter:[20/495], Time: 0.47, lr: [0.0027209150650297355], Loss: 2.098655, Acc:0.824602, Semantic loss: 0.806864, BCE loss: 0.558206, SB loss: 0.733585
2023-10-30 20:51:08,806 Epoch: [370/484] Iter:[30/495], Time: 0.44, lr: [0.002720480949577595], Loss: 2.028233, Acc:0.823291, Semantic loss: 0.757696, BCE loss: 0.549665, SB loss: 0.720872
2023-10-30 20:51:12,457 Epoch: [370/484] Iter:[40/495], Time: 0.42, lr: [0.002720046826428305], Loss: 2.017882, Acc:0.819204, Semantic loss: 0.760111, BCE loss: 0.537347, SB loss: 0.720423
2023-10-30 20:51:16,075 Epoch: [370/484] Iter:[50/495], Time: 0.41, lr: [0.002719612695580363], Loss: 1.983293, Acc:0.818597, Semantic loss: 0.744585, BCE loss: 0.521605, SB loss: 0.717103
2023-10-30 20:51:19,583 Epoch: [370/484] Iter:[60/495], Time: 0.40, lr: [0.0027191785570322667], Loss: 1.983249, Acc:0.817375, Semantic loss: 0.741278, BCE loss: 0.526126, SB loss: 0.715846
2023-10-30 20:51:23,200 Epoch: [370/484] Iter:[70/495], Time: 0.39, lr: [0.002718744410782512], Loss: 1.975018, Acc:0.811680, Semantic loss: 0.736018, BCE loss: 0.525425, SB loss: 0.713576
2023-10-30 20:51:26,751 Epoch: [370/484] Iter:[80/495], Time: 0.39, lr: [0.0027183102568295986], Loss: 1.955289, Acc:0.809369, Semantic loss: 0.728352, BCE loss: 0.518990, SB loss: 0.707946
2023-10-30 20:51:30,338 Epoch: [370/484] Iter:[90/495], Time: 0.39, lr: [0.0027178760951720215], Loss: 1.968592, Acc:0.808215, Semantic loss: 0.737868, BCE loss: 0.518453, SB loss: 0.712271
2023-10-30 20:51:34,018 Epoch: [370/484] Iter:[100/495], Time: 0.38, lr: [0.002717441925808276], Loss: 1.960996, Acc:0.804729, Semantic loss: 0.735705, BCE loss: 0.512602, SB loss: 0.712689
2023-10-30 20:51:37,604 Epoch: [370/484] Iter:[110/495], Time: 0.38, lr: [0.002717007748736857], Loss: 1.962533, Acc:0.804955, Semantic loss: 0.735573, BCE loss: 0.515626, SB loss: 0.711334
2023-10-30 20:51:41,210 Epoch: [370/484] Iter:[120/495], Time: 0.38, lr: [0.00271657356395626], Loss: 1.972685, Acc:0.803860, Semantic loss: 0.740095, BCE loss: 0.519937, SB loss: 0.712653
2023-10-30 20:51:44,915 Epoch: [370/484] Iter:[130/495], Time: 0.38, lr: [0.0027161393714649784], Loss: 1.968502, Acc:0.805863, Semantic loss: 0.737900, BCE loss: 0.519549, SB loss: 0.711053
2023-10-30 20:51:48,554 Epoch: [370/484] Iter:[140/495], Time: 0.38, lr: [0.002715705171261507], Loss: 1.967954, Acc:0.808695, Semantic loss: 0.735458, BCE loss: 0.523413, SB loss: 0.709083
2023-10-30 20:51:52,159 Epoch: [370/484] Iter:[150/495], Time: 0.38, lr: [0.002715270963344335], Loss: 1.960958, Acc:0.807861, Semantic loss: 0.733059, BCE loss: 0.520190, SB loss: 0.707709
2023-10-30 20:51:55,762 Epoch: [370/484] Iter:[160/495], Time: 0.38, lr: [0.002714836747711959], Loss: 1.972692, Acc:0.808457, Semantic loss: 0.741276, BCE loss: 0.520939, SB loss: 0.710478
2023-10-30 20:51:59,428 Epoch: [370/484] Iter:[170/495], Time: 0.38, lr: [0.0027144025243628694], Loss: 1.962134, Acc:0.808288, Semantic loss: 0.736005, BCE loss: 0.518353, SB loss: 0.707776
2023-10-30 20:52:02,977 Epoch: [370/484] Iter:[180/495], Time: 0.37, lr: [0.0027139682932955556], Loss: 1.962492, Acc:0.808525, Semantic loss: 0.735513, BCE loss: 0.517881, SB loss: 0.709098
2023-10-30 20:52:06,620 Epoch: [370/484] Iter:[190/495], Time: 0.37, lr: [0.0027135340545085115], Loss: 1.966931, Acc:0.809571, Semantic loss: 0.737287, BCE loss: 0.520182, SB loss: 0.709462
2023-10-30 20:52:10,304 Epoch: [370/484] Iter:[200/495], Time: 0.37, lr: [0.0027130998080002245], Loss: 1.966911, Acc:0.809016, Semantic loss: 0.737003, BCE loss: 0.520584, SB loss: 0.709324
2023-10-30 20:52:13,909 Epoch: [370/484] Iter:[210/495], Time: 0.37, lr: [0.0027126655537691854], Loss: 1.963447, Acc:0.808369, Semantic loss: 0.736090, BCE loss: 0.519430, SB loss: 0.707927
2023-10-30 20:52:17,571 Epoch: [370/484] Iter:[220/495], Time: 0.37, lr: [0.0027122312918138815], Loss: 1.970180, Acc:0.808652, Semantic loss: 0.737435, BCE loss: 0.523341, SB loss: 0.709404
2023-10-30 20:52:21,243 Epoch: [370/484] Iter:[230/495], Time: 0.37, lr: [0.0027117970221328036], Loss: 1.975808, Acc:0.808275, Semantic loss: 0.741928, BCE loss: 0.524663, SB loss: 0.709217
2023-10-30 20:52:24,858 Epoch: [370/484] Iter:[240/495], Time: 0.37, lr: [0.002711362744724439], Loss: 1.976335, Acc:0.807943, Semantic loss: 0.742542, BCE loss: 0.525126, SB loss: 0.708666
2023-10-30 20:52:28,481 Epoch: [370/484] Iter:[250/495], Time: 0.37, lr: [0.0027109284595872737], Loss: 1.973775, Acc:0.808459, Semantic loss: 0.740799, BCE loss: 0.524566, SB loss: 0.708410
2023-10-30 20:52:32,103 Epoch: [370/484] Iter:[260/495], Time: 0.37, lr: [0.0027104941667197937], Loss: 1.976526, Acc:0.808631, Semantic loss: 0.742212, BCE loss: 0.525709, SB loss: 0.708604
2023-10-30 20:52:35,677 Epoch: [370/484] Iter:[270/495], Time: 0.37, lr: [0.0027100598661204877], Loss: 1.973009, Acc:0.807920, Semantic loss: 0.741968, BCE loss: 0.522982, SB loss: 0.708058
2023-10-30 20:52:39,270 Epoch: [370/484] Iter:[280/495], Time: 0.37, lr: [0.0027096255577878404], Loss: 1.967591, Acc:0.807458, Semantic loss: 0.739204, BCE loss: 0.521348, SB loss: 0.707040
2023-10-30 20:52:42,814 Epoch: [370/484] Iter:[290/495], Time: 0.37, lr: [0.002709191241720336], Loss: 1.965290, Acc:0.806882, Semantic loss: 0.738104, BCE loss: 0.520013, SB loss: 0.707174
2023-10-30 20:52:46,548 Epoch: [370/484] Iter:[300/495], Time: 0.37, lr: [0.002708756917916459], Loss: 1.966698, Acc:0.808216, Semantic loss: 0.739501, BCE loss: 0.519921, SB loss: 0.707276
2023-10-30 20:52:50,271 Epoch: [370/484] Iter:[310/495], Time: 0.37, lr: [0.002708322586374694], Loss: 1.969726, Acc:0.807762, Semantic loss: 0.741293, BCE loss: 0.519677, SB loss: 0.708755
2023-10-30 20:52:53,929 Epoch: [370/484] Iter:[320/495], Time: 0.37, lr: [0.0027078882470935243], Loss: 1.970478, Acc:0.807721, Semantic loss: 0.741368, BCE loss: 0.520674, SB loss: 0.708436
2023-10-30 20:52:57,600 Epoch: [370/484] Iter:[330/495], Time: 0.37, lr: [0.002707453900071432], Loss: 1.968581, Acc:0.807678, Semantic loss: 0.739943, BCE loss: 0.520489, SB loss: 0.708149
2023-10-30 20:53:01,247 Epoch: [370/484] Iter:[340/495], Time: 0.37, lr: [0.0027070195453068983], Loss: 1.965562, Acc:0.807052, Semantic loss: 0.739312, BCE loss: 0.518312, SB loss: 0.707937
2023-10-30 20:53:04,949 Epoch: [370/484] Iter:[350/495], Time: 0.37, lr: [0.002706585182798407], Loss: 1.963712, Acc:0.807498, Semantic loss: 0.737940, BCE loss: 0.518044, SB loss: 0.707728
2023-10-30 20:53:08,751 Epoch: [370/484] Iter:[360/495], Time: 0.37, lr: [0.002706150812544439], Loss: 1.966957, Acc:0.807981, Semantic loss: 0.739923, BCE loss: 0.519379, SB loss: 0.707654
2023-10-30 20:53:12,356 Epoch: [370/484] Iter:[370/495], Time: 0.37, lr: [0.002705716434543473], Loss: 1.968096, Acc:0.808954, Semantic loss: 0.740335, BCE loss: 0.519744, SB loss: 0.708017
2023-10-30 20:53:16,121 Epoch: [370/484] Iter:[380/495], Time: 0.37, lr: [0.002705282048793989], Loss: 1.962844, Acc:0.809227, Semantic loss: 0.738134, BCE loss: 0.518448, SB loss: 0.706263
2023-10-30 20:53:19,776 Epoch: [370/484] Iter:[390/495], Time: 0.37, lr: [0.002704847655294468], Loss: 1.962907, Acc:0.809821, Semantic loss: 0.737397, BCE loss: 0.519415, SB loss: 0.706094
2023-10-30 20:53:23,363 Epoch: [370/484] Iter:[400/495], Time: 0.37, lr: [0.0027044132540433876], Loss: 1.961677, Acc:0.809878, Semantic loss: 0.736596, BCE loss: 0.519381, SB loss: 0.705700
2023-10-30 20:53:26,936 Epoch: [370/484] Iter:[410/495], Time: 0.37, lr: [0.0027039788450392266], Loss: 1.958841, Acc:0.810281, Semantic loss: 0.735359, BCE loss: 0.518979, SB loss: 0.704503
2023-10-30 20:53:30,562 Epoch: [370/484] Iter:[420/495], Time: 0.37, lr: [0.0027035444282804606], Loss: 1.954345, Acc:0.809705, Semantic loss: 0.733741, BCE loss: 0.517353, SB loss: 0.703250
2023-10-30 20:53:34,221 Epoch: [370/484] Iter:[430/495], Time: 0.37, lr: [0.0027031100037655698], Loss: 1.954138, Acc:0.809792, Semantic loss: 0.733506, BCE loss: 0.517379, SB loss: 0.703253
2023-10-30 20:53:37,807 Epoch: [370/484] Iter:[440/495], Time: 0.37, lr: [0.0027026755714930286], Loss: 1.952774, Acc:0.809615, Semantic loss: 0.733046, BCE loss: 0.516908, SB loss: 0.702820
2023-10-30 20:53:41,349 Epoch: [370/484] Iter:[450/495], Time: 0.37, lr: [0.002702241131461314], Loss: 1.953533, Acc:0.809800, Semantic loss: 0.733144, BCE loss: 0.518016, SB loss: 0.702373
2023-10-30 20:53:44,934 Epoch: [370/484] Iter:[460/495], Time: 0.37, lr: [0.0027018066836688986], Loss: 1.950971, Acc:0.809460, Semantic loss: 0.731533, BCE loss: 0.517891, SB loss: 0.701547
2023-10-30 20:53:48,607 Epoch: [370/484] Iter:[470/495], Time: 0.37, lr: [0.002701372228114261], Loss: 1.952194, Acc:0.808829, Semantic loss: 0.731823, BCE loss: 0.518189, SB loss: 0.702182
2023-10-30 20:53:52,227 Epoch: [370/484] Iter:[480/495], Time: 0.37, lr: [0.002700937764795874], Loss: 1.952348, Acc:0.808629, Semantic loss: 0.731739, BCE loss: 0.518105, SB loss: 0.702504
2023-10-30 20:53:55,647 Epoch: [370/484] Iter:[490/495], Time: 0.37, lr: [0.00270050329371221], Loss: 1.949958, Acc:0.807798, Semantic loss: 0.730764, BCE loss: 0.517050, SB loss: 0.702144
2023-10-30 20:56:52,293 0 [0.95145529 0.6939683  0.83905264 0.14995413 0.27692161 0.44258721
 0.47475487 0.61711129 0.88961566 0.46575886 0.88170183 0.6415628
 0.03977016 0.83968914 0.00601173 0.15089074 0.06624943 0.07742534
 0.60621079] 0.4795100959445431
2023-10-30 20:56:52,294 1 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631] 0.7311039481807429
2023-10-30 20:56:52,298 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:56:52,539 Loss: 2.015, MeanIU:  0.7311, Best_mIoU:  0.7487
2023-10-30 20:56:52,539 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631]
2023-10-30 20:56:54,839 Epoch: [371/484] Iter:[0/495], Time: 2.27, lr: [0.0027002860552579225], Loss: 1.743532, Acc:0.745652, Semantic loss: 0.663948, BCE loss: 0.419385, SB loss: 0.660199
2023-10-30 20:56:58,750 Epoch: [371/484] Iter:[10/495], Time: 0.56, lr: [0.00269985157252348], Loss: 1.982957, Acc:0.826372, Semantic loss: 0.723925, BCE loss: 0.566913, SB loss: 0.692119
2023-10-30 20:57:02,327 Epoch: [371/484] Iter:[20/495], Time: 0.46, lr: [0.0026994170820199438], Loss: 1.987588, Acc:0.821327, Semantic loss: 0.744314, BCE loss: 0.546893, SB loss: 0.696381
2023-10-30 20:57:05,832 Epoch: [371/484] Iter:[30/495], Time: 0.43, lr: [0.0026989825837457847], Loss: 1.939580, Acc:0.813744, Semantic loss: 0.720466, BCE loss: 0.523606, SB loss: 0.695508
2023-10-30 20:57:09,344 Epoch: [371/484] Iter:[40/495], Time: 0.41, lr: [0.0026985480776994726], Loss: 1.907956, Acc:0.809208, Semantic loss: 0.708334, BCE loss: 0.511555, SB loss: 0.688068
2023-10-30 20:57:12,857 Epoch: [371/484] Iter:[50/495], Time: 0.40, lr: [0.0026981135638794794], Loss: 1.913744, Acc:0.807883, Semantic loss: 0.715660, BCE loss: 0.509312, SB loss: 0.688772
2023-10-30 20:57:16,298 Epoch: [371/484] Iter:[60/495], Time: 0.39, lr: [0.002697679042284275], Loss: 1.920714, Acc:0.808682, Semantic loss: 0.718617, BCE loss: 0.507950, SB loss: 0.694147
2023-10-30 20:57:19,846 Epoch: [371/484] Iter:[70/495], Time: 0.38, lr: [0.002697244512912328], Loss: 1.901957, Acc:0.805619, Semantic loss: 0.711372, BCE loss: 0.499229, SB loss: 0.691356
2023-10-30 20:57:23,447 Epoch: [371/484] Iter:[80/495], Time: 0.38, lr: [0.002696809975762106], Loss: 1.911729, Acc:0.803274, Semantic loss: 0.713878, BCE loss: 0.503404, SB loss: 0.694447
2023-10-30 20:57:27,185 Epoch: [371/484] Iter:[90/495], Time: 0.38, lr: [0.0026963754308320796], Loss: 1.916303, Acc:0.807139, Semantic loss: 0.714474, BCE loss: 0.509370, SB loss: 0.692459
2023-10-30 20:57:30,773 Epoch: [371/484] Iter:[100/495], Time: 0.38, lr: [0.002695940878120715], Loss: 1.920445, Acc:0.810515, Semantic loss: 0.714357, BCE loss: 0.514003, SB loss: 0.692086
2023-10-30 20:57:34,281 Epoch: [371/484] Iter:[110/495], Time: 0.38, lr: [0.0026955063176264792], Loss: 1.917368, Acc:0.809679, Semantic loss: 0.713306, BCE loss: 0.510574, SB loss: 0.693488
2023-10-30 20:57:37,815 Epoch: [371/484] Iter:[120/495], Time: 0.37, lr: [0.0026950717493478384], Loss: 1.917762, Acc:0.811430, Semantic loss: 0.714101, BCE loss: 0.508687, SB loss: 0.694974
2023-10-30 20:57:41,362 Epoch: [371/484] Iter:[130/495], Time: 0.37, lr: [0.002694637173283259], Loss: 1.914700, Acc:0.811242, Semantic loss: 0.714610, BCE loss: 0.505918, SB loss: 0.694172
2023-10-30 20:57:44,802 Epoch: [371/484] Iter:[140/495], Time: 0.37, lr: [0.0026942025894312067], Loss: 1.921317, Acc:0.811285, Semantic loss: 0.717367, BCE loss: 0.508357, SB loss: 0.695592
2023-10-30 20:57:48,357 Epoch: [371/484] Iter:[150/495], Time: 0.37, lr: [0.0026937679977901453], Loss: 1.913062, Acc:0.809903, Semantic loss: 0.714753, BCE loss: 0.504261, SB loss: 0.694049
2023-10-30 20:57:51,881 Epoch: [371/484] Iter:[160/495], Time: 0.37, lr: [0.002693333398358538], Loss: 1.913431, Acc:0.807888, Semantic loss: 0.715224, BCE loss: 0.504424, SB loss: 0.693783
2023-10-30 20:57:55,447 Epoch: [371/484] Iter:[170/495], Time: 0.37, lr: [0.0026928987911348508], Loss: 1.908453, Acc:0.808546, Semantic loss: 0.711023, BCE loss: 0.505429, SB loss: 0.692001
2023-10-30 20:57:59,104 Epoch: [371/484] Iter:[180/495], Time: 0.37, lr: [0.002692464176117545], Loss: 1.912150, Acc:0.808725, Semantic loss: 0.713700, BCE loss: 0.506835, SB loss: 0.691615
2023-10-30 20:58:02,727 Epoch: [371/484] Iter:[190/495], Time: 0.37, lr: [0.002692029553305084], Loss: 1.913475, Acc:0.808069, Semantic loss: 0.714734, BCE loss: 0.506214, SB loss: 0.692527
2023-10-30 20:58:06,430 Epoch: [371/484] Iter:[200/495], Time: 0.37, lr: [0.002691594922695927], Loss: 1.912798, Acc:0.807728, Semantic loss: 0.714826, BCE loss: 0.505934, SB loss: 0.692038
2023-10-30 20:58:10,026 Epoch: [371/484] Iter:[210/495], Time: 0.37, lr: [0.0026911602842885386], Loss: 1.916828, Acc:0.808606, Semantic loss: 0.717570, BCE loss: 0.506214, SB loss: 0.693044
2023-10-30 20:58:13,574 Epoch: [371/484] Iter:[220/495], Time: 0.37, lr: [0.002690725638081378], Loss: 1.926032, Acc:0.809106, Semantic loss: 0.722296, BCE loss: 0.509546, SB loss: 0.694189
2023-10-30 20:58:17,144 Epoch: [371/484] Iter:[230/495], Time: 0.37, lr: [0.0026902909840729045], Loss: 1.925412, Acc:0.809620, Semantic loss: 0.719827, BCE loss: 0.510906, SB loss: 0.694679
2023-10-30 20:58:20,766 Epoch: [371/484] Iter:[240/495], Time: 0.37, lr: [0.002689856322261578], Loss: 1.925276, Acc:0.809345, Semantic loss: 0.719286, BCE loss: 0.511382, SB loss: 0.694608
2023-10-30 20:58:24,505 Epoch: [371/484] Iter:[250/495], Time: 0.37, lr: [0.002689421652645858], Loss: 1.925922, Acc:0.809000, Semantic loss: 0.719291, BCE loss: 0.512097, SB loss: 0.694535
2023-10-30 20:58:28,087 Epoch: [371/484] Iter:[260/495], Time: 0.37, lr: [0.002688986975224203], Loss: 1.932498, Acc:0.809749, Semantic loss: 0.721449, BCE loss: 0.513877, SB loss: 0.697172
2023-10-30 20:58:31,751 Epoch: [371/484] Iter:[270/495], Time: 0.37, lr: [0.00268855228999507], Loss: 1.934928, Acc:0.810036, Semantic loss: 0.721009, BCE loss: 0.517039, SB loss: 0.696880
2023-10-30 20:58:35,385 Epoch: [371/484] Iter:[280/495], Time: 0.37, lr: [0.0026881175969569147], Loss: 1.938229, Acc:0.809762, Semantic loss: 0.721464, BCE loss: 0.519031, SB loss: 0.697734
2023-10-30 20:58:39,154 Epoch: [371/484] Iter:[290/495], Time: 0.37, lr: [0.0026876828961081975], Loss: 1.930417, Acc:0.810016, Semantic loss: 0.718583, BCE loss: 0.515075, SB loss: 0.696759
2023-10-30 20:58:42,874 Epoch: [371/484] Iter:[300/495], Time: 0.37, lr: [0.0026872481874473716], Loss: 1.931340, Acc:0.810452, Semantic loss: 0.719261, BCE loss: 0.515436, SB loss: 0.696643
2023-10-30 20:58:46,467 Epoch: [371/484] Iter:[310/495], Time: 0.37, lr: [0.0026868134709728923], Loss: 1.929657, Acc:0.810180, Semantic loss: 0.718638, BCE loss: 0.515368, SB loss: 0.695651
2023-10-30 20:58:50,012 Epoch: [371/484] Iter:[320/495], Time: 0.37, lr: [0.002686378746683215], Loss: 1.926374, Acc:0.809861, Semantic loss: 0.718227, BCE loss: 0.513292, SB loss: 0.694855
2023-10-30 20:58:53,561 Epoch: [371/484] Iter:[330/495], Time: 0.37, lr: [0.002685944014576795], Loss: 1.927072, Acc:0.808765, Semantic loss: 0.718819, BCE loss: 0.513547, SB loss: 0.694706
2023-10-30 20:58:57,294 Epoch: [371/484] Iter:[340/495], Time: 0.37, lr: [0.0026855092746520845], Loss: 1.924950, Acc:0.808633, Semantic loss: 0.717927, BCE loss: 0.512770, SB loss: 0.694252
2023-10-30 20:59:00,905 Epoch: [371/484] Iter:[350/495], Time: 0.37, lr: [0.002685074526907537], Loss: 1.924700, Acc:0.809204, Semantic loss: 0.719059, BCE loss: 0.511585, SB loss: 0.694056
2023-10-30 20:59:04,578 Epoch: [371/484] Iter:[360/495], Time: 0.37, lr: [0.0026846397713416043], Loss: 1.928913, Acc:0.809138, Semantic loss: 0.722621, BCE loss: 0.511473, SB loss: 0.694819
2023-10-30 20:59:08,252 Epoch: [371/484] Iter:[370/495], Time: 0.37, lr: [0.00268420500795274], Loss: 1.932123, Acc:0.809020, Semantic loss: 0.725020, BCE loss: 0.511450, SB loss: 0.695652
2023-10-30 20:59:11,828 Epoch: [371/484] Iter:[380/495], Time: 0.37, lr: [0.002683770236739394], Loss: 1.931041, Acc:0.809246, Semantic loss: 0.724168, BCE loss: 0.511340, SB loss: 0.695534
2023-10-30 20:59:15,462 Epoch: [371/484] Iter:[390/495], Time: 0.37, lr: [0.002683335457700018], Loss: 1.931872, Acc:0.807224, Semantic loss: 0.725323, BCE loss: 0.510867, SB loss: 0.695683
2023-10-30 20:59:18,994 Epoch: [371/484] Iter:[400/495], Time: 0.37, lr: [0.00268290067083306], Loss: 1.932166, Acc:0.807536, Semantic loss: 0.725992, BCE loss: 0.510336, SB loss: 0.695838
2023-10-30 20:59:22,675 Epoch: [371/484] Iter:[410/495], Time: 0.37, lr: [0.0026824658761369718], Loss: 1.929030, Acc:0.806965, Semantic loss: 0.724269, BCE loss: 0.509278, SB loss: 0.695483
2023-10-30 20:59:26,298 Epoch: [371/484] Iter:[420/495], Time: 0.37, lr: [0.0026820310736102027], Loss: 1.930229, Acc:0.806728, Semantic loss: 0.724597, BCE loss: 0.509223, SB loss: 0.696410
2023-10-30 20:59:30,020 Epoch: [371/484] Iter:[430/495], Time: 0.37, lr: [0.0026815962632511996], Loss: 1.932900, Acc:0.807466, Semantic loss: 0.725669, BCE loss: 0.510506, SB loss: 0.696725
2023-10-30 20:59:33,666 Epoch: [371/484] Iter:[440/495], Time: 0.37, lr: [0.0026811614450584094], Loss: 1.930923, Acc:0.807605, Semantic loss: 0.725187, BCE loss: 0.509783, SB loss: 0.695954
2023-10-30 20:59:37,301 Epoch: [371/484] Iter:[450/495], Time: 0.37, lr: [0.002680726619030282], Loss: 1.928731, Acc:0.807956, Semantic loss: 0.724987, BCE loss: 0.507987, SB loss: 0.695757
2023-10-30 20:59:40,839 Epoch: [371/484] Iter:[460/495], Time: 0.36, lr: [0.0026802917851652627], Loss: 1.930946, Acc:0.807415, Semantic loss: 0.726324, BCE loss: 0.507963, SB loss: 0.696659
2023-10-30 20:59:44,546 Epoch: [371/484] Iter:[470/495], Time: 0.37, lr: [0.0026798569434617974], Loss: 1.932765, Acc:0.807264, Semantic loss: 0.727362, BCE loss: 0.507989, SB loss: 0.697413
2023-10-30 20:59:48,209 Epoch: [371/484] Iter:[480/495], Time: 0.37, lr: [0.0026794220939183305], Loss: 1.934448, Acc:0.807441, Semantic loss: 0.728553, BCE loss: 0.507838, SB loss: 0.698057
2023-10-30 20:59:51,647 Epoch: [371/484] Iter:[490/495], Time: 0.36, lr: [0.002678987236533309], Loss: 1.934739, Acc:0.807293, Semantic loss: 0.727844, BCE loss: 0.508268, SB loss: 0.698628
2023-10-30 20:59:53,015 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 20:59:53,258 Loss: 2.015, MeanIU:  0.7311, Best_mIoU:  0.7487
2023-10-30 20:59:53,258 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631]
2023-10-30 20:59:55,269 Epoch: [372/484] Iter:[0/495], Time: 1.98, lr: [0.002678769804899729], Loss: 1.659965, Acc:0.815236, Semantic loss: 0.679111, BCE loss: 0.379836, SB loss: 0.601017
2023-10-30 20:59:59,217 Epoch: [372/484] Iter:[10/495], Time: 0.54, lr: [0.0026783349357494576], Loss: 1.812837, Acc:0.815847, Semantic loss: 0.683476, BCE loss: 0.465657, SB loss: 0.663704
2023-10-30 21:00:02,967 Epoch: [372/484] Iter:[20/495], Time: 0.46, lr: [0.002677900058753738], Loss: 1.953635, Acc:0.816575, Semantic loss: 0.726832, BCE loss: 0.525759, SB loss: 0.701044
2023-10-30 21:00:06,661 Epoch: [372/484] Iter:[30/495], Time: 0.43, lr: [0.0026774651739110166], Loss: 1.961676, Acc:0.828371, Semantic loss: 0.730620, BCE loss: 0.533162, SB loss: 0.697895
2023-10-30 21:00:10,342 Epoch: [372/484] Iter:[40/495], Time: 0.42, lr: [0.0026770302812197345], Loss: 1.966793, Acc:0.823390, Semantic loss: 0.738271, BCE loss: 0.527703, SB loss: 0.700819
2023-10-30 21:00:13,990 Epoch: [372/484] Iter:[50/495], Time: 0.41, lr: [0.002676595380678332], Loss: 1.961278, Acc:0.817614, Semantic loss: 0.731605, BCE loss: 0.526946, SB loss: 0.702726
2023-10-30 21:00:17,643 Epoch: [372/484] Iter:[60/495], Time: 0.40, lr: [0.002676160472285251], Loss: 1.959016, Acc:0.824348, Semantic loss: 0.726475, BCE loss: 0.531548, SB loss: 0.700994
2023-10-30 21:00:21,323 Epoch: [372/484] Iter:[70/495], Time: 0.39, lr: [0.0026757255560389327], Loss: 1.979179, Acc:0.823784, Semantic loss: 0.740919, BCE loss: 0.533461, SB loss: 0.704799
2023-10-30 21:00:24,971 Epoch: [372/484] Iter:[80/495], Time: 0.39, lr: [0.002675290631937816], Loss: 1.974381, Acc:0.824163, Semantic loss: 0.736762, BCE loss: 0.535881, SB loss: 0.701738
2023-10-30 21:00:28,578 Epoch: [372/484] Iter:[90/495], Time: 0.39, lr: [0.002674855699980341], Loss: 1.965406, Acc:0.824162, Semantic loss: 0.735352, BCE loss: 0.527680, SB loss: 0.702373
2023-10-30 21:00:32,208 Epoch: [372/484] Iter:[100/495], Time: 0.39, lr: [0.0026744207601649434], Loss: 1.954906, Acc:0.820832, Semantic loss: 0.731541, BCE loss: 0.522623, SB loss: 0.700742
2023-10-30 21:00:35,797 Epoch: [372/484] Iter:[110/495], Time: 0.38, lr: [0.0026739858124900655], Loss: 1.956446, Acc:0.817366, Semantic loss: 0.731332, BCE loss: 0.523553, SB loss: 0.701560
2023-10-30 21:00:39,404 Epoch: [372/484] Iter:[120/495], Time: 0.38, lr: [0.002673550856954143], Loss: 1.955888, Acc:0.812461, Semantic loss: 0.730488, BCE loss: 0.524384, SB loss: 0.701016
2023-10-30 21:00:43,023 Epoch: [372/484] Iter:[130/495], Time: 0.38, lr: [0.002673115893555612], Loss: 1.950301, Acc:0.812671, Semantic loss: 0.727484, BCE loss: 0.522764, SB loss: 0.700052
2023-10-30 21:00:46,743 Epoch: [372/484] Iter:[140/495], Time: 0.38, lr: [0.0026726809222929085], Loss: 1.944721, Acc:0.812376, Semantic loss: 0.727016, BCE loss: 0.518370, SB loss: 0.699335
2023-10-30 21:00:50,439 Epoch: [372/484] Iter:[150/495], Time: 0.38, lr: [0.0026722459431644703], Loss: 1.946240, Acc:0.812229, Semantic loss: 0.728108, BCE loss: 0.517847, SB loss: 0.700285
2023-10-30 21:00:54,090 Epoch: [372/484] Iter:[160/495], Time: 0.38, lr: [0.0026718109561687307], Loss: 1.962042, Acc:0.813008, Semantic loss: 0.732436, BCE loss: 0.526455, SB loss: 0.703151
2023-10-30 21:00:57,671 Epoch: [372/484] Iter:[170/495], Time: 0.38, lr: [0.0026713759613041254], Loss: 1.963736, Acc:0.813564, Semantic loss: 0.732685, BCE loss: 0.528616, SB loss: 0.702435
2023-10-30 21:01:01,306 Epoch: [372/484] Iter:[180/495], Time: 0.38, lr: [0.002670940958569086], Loss: 1.964206, Acc:0.811627, Semantic loss: 0.734245, BCE loss: 0.526777, SB loss: 0.703184
2023-10-30 21:01:05,020 Epoch: [372/484] Iter:[190/495], Time: 0.38, lr: [0.0026705059479620492], Loss: 1.962787, Acc:0.811435, Semantic loss: 0.733168, BCE loss: 0.527415, SB loss: 0.702205
2023-10-30 21:01:08,672 Epoch: [372/484] Iter:[200/495], Time: 0.38, lr: [0.002670070929481446], Loss: 1.962544, Acc:0.812026, Semantic loss: 0.732261, BCE loss: 0.528778, SB loss: 0.701504
2023-10-30 21:01:12,369 Epoch: [372/484] Iter:[210/495], Time: 0.37, lr: [0.002669635903125707], Loss: 1.972759, Acc:0.811615, Semantic loss: 0.739004, BCE loss: 0.530817, SB loss: 0.702938
2023-10-30 21:01:16,033 Epoch: [372/484] Iter:[220/495], Time: 0.37, lr: [0.0026692008688932655], Loss: 1.970418, Acc:0.811524, Semantic loss: 0.737686, BCE loss: 0.530766, SB loss: 0.701966
2023-10-30 21:01:19,649 Epoch: [372/484] Iter:[230/495], Time: 0.37, lr: [0.0026687658267825526], Loss: 1.973436, Acc:0.812436, Semantic loss: 0.740317, BCE loss: 0.529877, SB loss: 0.703241
2023-10-30 21:01:23,213 Epoch: [372/484] Iter:[240/495], Time: 0.37, lr: [0.0026683307767919984], Loss: 1.979597, Acc:0.810914, Semantic loss: 0.743979, BCE loss: 0.530664, SB loss: 0.704954
2023-10-30 21:01:26,847 Epoch: [372/484] Iter:[250/495], Time: 0.37, lr: [0.0026678957189200324], Loss: 1.971499, Acc:0.809007, Semantic loss: 0.738532, BCE loss: 0.528292, SB loss: 0.704675
2023-10-30 21:01:30,572 Epoch: [372/484] Iter:[260/495], Time: 0.37, lr: [0.0026674606531650823], Loss: 1.966848, Acc:0.808984, Semantic loss: 0.735298, BCE loss: 0.527552, SB loss: 0.703998
2023-10-30 21:01:34,122 Epoch: [372/484] Iter:[270/495], Time: 0.37, lr: [0.00266702557952558], Loss: 1.965728, Acc:0.806826, Semantic loss: 0.735271, BCE loss: 0.526330, SB loss: 0.704126
2023-10-30 21:01:37,699 Epoch: [372/484] Iter:[280/495], Time: 0.37, lr: [0.0026665904979999507], Loss: 1.961671, Acc:0.804653, Semantic loss: 0.733874, BCE loss: 0.523775, SB loss: 0.704022
2023-10-30 21:01:41,338 Epoch: [372/484] Iter:[290/495], Time: 0.37, lr: [0.0026661554085866223], Loss: 1.962484, Acc:0.804080, Semantic loss: 0.734114, BCE loss: 0.523882, SB loss: 0.704488
2023-10-30 21:01:44,993 Epoch: [372/484] Iter:[300/495], Time: 0.37, lr: [0.0026657203112840206], Loss: 1.961636, Acc:0.804573, Semantic loss: 0.732756, BCE loss: 0.524421, SB loss: 0.704459
2023-10-30 21:01:48,665 Epoch: [372/484] Iter:[310/495], Time: 0.37, lr: [0.0026652852060905746], Loss: 1.961168, Acc:0.804360, Semantic loss: 0.732898, BCE loss: 0.524145, SB loss: 0.704125
2023-10-30 21:01:52,266 Epoch: [372/484] Iter:[320/495], Time: 0.37, lr: [0.0026648500930047075], Loss: 1.962507, Acc:0.803839, Semantic loss: 0.734191, BCE loss: 0.523617, SB loss: 0.704699
2023-10-30 21:01:55,976 Epoch: [372/484] Iter:[330/495], Time: 0.37, lr: [0.002664414972024845], Loss: 1.960199, Acc:0.803516, Semantic loss: 0.733990, BCE loss: 0.522258, SB loss: 0.703951
2023-10-30 21:01:59,623 Epoch: [372/484] Iter:[340/495], Time: 0.37, lr: [0.0026639798431494104], Loss: 1.960091, Acc:0.802699, Semantic loss: 0.733488, BCE loss: 0.522143, SB loss: 0.704460
2023-10-30 21:02:03,321 Epoch: [372/484] Iter:[350/495], Time: 0.37, lr: [0.0026635447063768293], Loss: 1.958326, Acc:0.800954, Semantic loss: 0.733066, BCE loss: 0.521373, SB loss: 0.703887
2023-10-30 21:02:06,875 Epoch: [372/484] Iter:[360/495], Time: 0.37, lr: [0.002663109561705524], Loss: 1.957891, Acc:0.801278, Semantic loss: 0.732606, BCE loss: 0.521132, SB loss: 0.704153
2023-10-30 21:02:10,634 Epoch: [372/484] Iter:[370/495], Time: 0.37, lr: [0.0026626744091339167], Loss: 1.962546, Acc:0.801570, Semantic loss: 0.735509, BCE loss: 0.521698, SB loss: 0.705339
2023-10-30 21:02:14,243 Epoch: [372/484] Iter:[380/495], Time: 0.37, lr: [0.002662239248660428], Loss: 1.959210, Acc:0.801499, Semantic loss: 0.733583, BCE loss: 0.520817, SB loss: 0.704810
2023-10-30 21:02:17,970 Epoch: [372/484] Iter:[390/495], Time: 0.37, lr: [0.0026618040802834824], Loss: 1.956885, Acc:0.801115, Semantic loss: 0.731387, BCE loss: 0.521015, SB loss: 0.704483
2023-10-30 21:02:21,542 Epoch: [372/484] Iter:[400/495], Time: 0.37, lr: [0.002661368904001499], Loss: 1.958054, Acc:0.801218, Semantic loss: 0.731037, BCE loss: 0.522511, SB loss: 0.704507
2023-10-30 21:02:25,311 Epoch: [372/484] Iter:[410/495], Time: 0.37, lr: [0.0026609337198128975], Loss: 1.956711, Acc:0.801206, Semantic loss: 0.730475, BCE loss: 0.522301, SB loss: 0.703935
2023-10-30 21:02:28,925 Epoch: [372/484] Iter:[420/495], Time: 0.37, lr: [0.002660498527716097], Loss: 1.957257, Acc:0.801970, Semantic loss: 0.731186, BCE loss: 0.521533, SB loss: 0.704538
2023-10-30 21:02:32,653 Epoch: [372/484] Iter:[430/495], Time: 0.37, lr: [0.002660063327709518], Loss: 1.954007, Acc:0.802041, Semantic loss: 0.729832, BCE loss: 0.520236, SB loss: 0.703939
2023-10-30 21:02:36,212 Epoch: [372/484] Iter:[440/495], Time: 0.37, lr: [0.002659628119791579], Loss: 1.951846, Acc:0.802243, Semantic loss: 0.729061, BCE loss: 0.519480, SB loss: 0.703305
2023-10-30 21:02:39,852 Epoch: [372/484] Iter:[450/495], Time: 0.37, lr: [0.002659192903960696], Loss: 1.950471, Acc:0.802700, Semantic loss: 0.729152, BCE loss: 0.517785, SB loss: 0.703534
2023-10-30 21:02:43,541 Epoch: [372/484] Iter:[460/495], Time: 0.37, lr: [0.0026587576802152863], Loss: 1.950147, Acc:0.802450, Semantic loss: 0.729247, BCE loss: 0.517329, SB loss: 0.703571
2023-10-30 21:02:47,335 Epoch: [372/484] Iter:[470/495], Time: 0.37, lr: [0.0026583224485537678], Loss: 1.951720, Acc:0.802393, Semantic loss: 0.729471, BCE loss: 0.518207, SB loss: 0.704042
2023-10-30 21:02:51,063 Epoch: [372/484] Iter:[480/495], Time: 0.37, lr: [0.0026578872089745554], Loss: 1.950378, Acc:0.803459, Semantic loss: 0.728534, BCE loss: 0.518578, SB loss: 0.703265
2023-10-30 21:02:54,421 Epoch: [372/484] Iter:[490/495], Time: 0.37, lr: [0.0026574519614760645], Loss: 1.949788, Acc:0.802730, Semantic loss: 0.729139, BCE loss: 0.517655, SB loss: 0.702994
2023-10-30 21:02:55,786 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:02:56,027 Loss: 2.015, MeanIU:  0.7311, Best_mIoU:  0.7487
2023-10-30 21:02:56,027 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631]
2023-10-30 21:02:57,931 Epoch: [373/484] Iter:[0/495], Time: 1.86, lr: [0.0026572343347565936], Loss: 1.908323, Acc:0.687843, Semantic loss: 0.779647, BCE loss: 0.441066, SB loss: 0.687610
2023-10-30 21:03:02,025 Epoch: [373/484] Iter:[10/495], Time: 0.54, lr: [0.0026567990753762127], Loss: 1.898100, Acc:0.787011, Semantic loss: 0.707980, BCE loss: 0.513021, SB loss: 0.677099
2023-10-30 21:03:05,740 Epoch: [373/484] Iter:[20/495], Time: 0.46, lr: [0.002656363808072589], Loss: 1.907318, Acc:0.803795, Semantic loss: 0.702619, BCE loss: 0.527728, SB loss: 0.676971
2023-10-30 21:03:09,436 Epoch: [373/484] Iter:[30/495], Time: 0.43, lr: [0.0026559285328441357], Loss: 1.886643, Acc:0.805763, Semantic loss: 0.692465, BCE loss: 0.515863, SB loss: 0.678315
2023-10-30 21:03:12,987 Epoch: [373/484] Iter:[40/495], Time: 0.41, lr: [0.002655493249689264], Loss: 1.908013, Acc:0.809956, Semantic loss: 0.708196, BCE loss: 0.517070, SB loss: 0.682747
2023-10-30 21:03:16,588 Epoch: [373/484] Iter:[50/495], Time: 0.40, lr: [0.0026550579586063884], Loss: 1.905322, Acc:0.810749, Semantic loss: 0.709376, BCE loss: 0.516717, SB loss: 0.679229
2023-10-30 21:03:20,071 Epoch: [373/484] Iter:[60/495], Time: 0.39, lr: [0.0026546226595939187], Loss: 1.910675, Acc:0.805613, Semantic loss: 0.714762, BCE loss: 0.508954, SB loss: 0.686960
2023-10-30 21:03:23,686 Epoch: [373/484] Iter:[70/495], Time: 0.39, lr: [0.0026541873526502668], Loss: 1.906605, Acc:0.794411, Semantic loss: 0.714673, BCE loss: 0.501739, SB loss: 0.690193
2023-10-30 21:03:27,346 Epoch: [373/484] Iter:[80/495], Time: 0.39, lr: [0.0026537520377738406], Loss: 1.910326, Acc:0.800114, Semantic loss: 0.710758, BCE loss: 0.510936, SB loss: 0.688632
2023-10-30 21:03:30,977 Epoch: [373/484] Iter:[90/495], Time: 0.38, lr: [0.0026533167149630516], Loss: 1.911856, Acc:0.800226, Semantic loss: 0.714119, BCE loss: 0.505873, SB loss: 0.691864
2023-10-30 21:03:34,591 Epoch: [373/484] Iter:[100/495], Time: 0.38, lr: [0.0026528813842163087], Loss: 1.921113, Acc:0.803189, Semantic loss: 0.715766, BCE loss: 0.512723, SB loss: 0.692624
2023-10-30 21:03:38,207 Epoch: [373/484] Iter:[110/495], Time: 0.38, lr: [0.0026524460455320193], Loss: 1.927778, Acc:0.804315, Semantic loss: 0.717455, BCE loss: 0.515120, SB loss: 0.695203
2023-10-30 21:03:41,956 Epoch: [373/484] Iter:[120/495], Time: 0.38, lr: [0.0026520106989085905], Loss: 1.932685, Acc:0.804494, Semantic loss: 0.719902, BCE loss: 0.516066, SB loss: 0.696718
2023-10-30 21:03:45,576 Epoch: [373/484] Iter:[130/495], Time: 0.38, lr: [0.0026515753443444316], Loss: 1.935467, Acc:0.803666, Semantic loss: 0.721187, BCE loss: 0.516265, SB loss: 0.698015
2023-10-30 21:03:49,165 Epoch: [373/484] Iter:[140/495], Time: 0.38, lr: [0.0026511399818379476], Loss: 1.934449, Acc:0.804660, Semantic loss: 0.721398, BCE loss: 0.514814, SB loss: 0.698237
2023-10-30 21:03:52,665 Epoch: [373/484] Iter:[150/495], Time: 0.37, lr: [0.002650704611387545], Loss: 1.927649, Acc:0.805374, Semantic loss: 0.718787, BCE loss: 0.511336, SB loss: 0.697526
2023-10-30 21:03:56,229 Epoch: [373/484] Iter:[160/495], Time: 0.37, lr: [0.002650269232991627], Loss: 1.929233, Acc:0.803650, Semantic loss: 0.726654, BCE loss: 0.504203, SB loss: 0.698376
2023-10-30 21:03:59,925 Epoch: [373/484] Iter:[170/495], Time: 0.37, lr: [0.002649833846648601], Loss: 1.935370, Acc:0.801352, Semantic loss: 0.728629, BCE loss: 0.507729, SB loss: 0.699012
2023-10-30 21:04:03,570 Epoch: [373/484] Iter:[180/495], Time: 0.37, lr: [0.0026493984523568706], Loss: 1.941753, Acc:0.802050, Semantic loss: 0.729793, BCE loss: 0.512595, SB loss: 0.699366
2023-10-30 21:04:07,236 Epoch: [373/484] Iter:[190/495], Time: 0.37, lr: [0.0026489630501148383], Loss: 1.941432, Acc:0.802923, Semantic loss: 0.728647, BCE loss: 0.513447, SB loss: 0.699338
2023-10-30 21:04:10,892 Epoch: [373/484] Iter:[200/495], Time: 0.37, lr: [0.0026485276399209057], Loss: 1.941513, Acc:0.803399, Semantic loss: 0.728282, BCE loss: 0.514584, SB loss: 0.698647
2023-10-30 21:04:14,510 Epoch: [373/484] Iter:[210/495], Time: 0.37, lr: [0.0026480922217734775], Loss: 1.940887, Acc:0.803249, Semantic loss: 0.727732, BCE loss: 0.515085, SB loss: 0.698070
2023-10-30 21:04:18,119 Epoch: [373/484] Iter:[220/495], Time: 0.37, lr: [0.0026476567956709544], Loss: 1.939802, Acc:0.801481, Semantic loss: 0.728124, BCE loss: 0.513854, SB loss: 0.697824
2023-10-30 21:04:21,828 Epoch: [373/484] Iter:[230/495], Time: 0.37, lr: [0.002647221361611738], Loss: 1.940182, Acc:0.800780, Semantic loss: 0.728984, BCE loss: 0.511368, SB loss: 0.699830
2023-10-30 21:04:25,470 Epoch: [373/484] Iter:[240/495], Time: 0.37, lr: [0.0026467859195942254], Loss: 1.941517, Acc:0.800548, Semantic loss: 0.728840, BCE loss: 0.512311, SB loss: 0.700366
2023-10-30 21:04:29,082 Epoch: [373/484] Iter:[250/495], Time: 0.37, lr: [0.002646350469616821], Loss: 1.939239, Acc:0.800716, Semantic loss: 0.727394, BCE loss: 0.512245, SB loss: 0.699599
2023-10-30 21:04:32,788 Epoch: [373/484] Iter:[260/495], Time: 0.37, lr: [0.0026459150116779216], Loss: 1.942306, Acc:0.800876, Semantic loss: 0.728249, BCE loss: 0.514054, SB loss: 0.700004
2023-10-30 21:04:36,459 Epoch: [373/484] Iter:[270/495], Time: 0.37, lr: [0.002645479545775926], Loss: 1.942427, Acc:0.800889, Semantic loss: 0.729670, BCE loss: 0.512695, SB loss: 0.700063
2023-10-30 21:04:40,148 Epoch: [373/484] Iter:[280/495], Time: 0.37, lr: [0.00264504407190923], Loss: 1.939940, Acc:0.800784, Semantic loss: 0.728292, BCE loss: 0.512619, SB loss: 0.699030
2023-10-30 21:04:43,836 Epoch: [373/484] Iter:[290/495], Time: 0.37, lr: [0.0026446085900762345], Loss: 1.936899, Acc:0.800720, Semantic loss: 0.726404, BCE loss: 0.512901, SB loss: 0.697594
2023-10-30 21:04:47,580 Epoch: [373/484] Iter:[300/495], Time: 0.37, lr: [0.002644173100275335], Loss: 1.935668, Acc:0.801191, Semantic loss: 0.725997, BCE loss: 0.512612, SB loss: 0.697059
2023-10-30 21:04:51,203 Epoch: [373/484] Iter:[310/495], Time: 0.37, lr: [0.0026437376025049263], Loss: 1.936121, Acc:0.802694, Semantic loss: 0.726186, BCE loss: 0.512886, SB loss: 0.697049
2023-10-30 21:04:54,914 Epoch: [373/484] Iter:[320/495], Time: 0.37, lr: [0.0026433020967634034], Loss: 1.938363, Acc:0.802272, Semantic loss: 0.727748, BCE loss: 0.513213, SB loss: 0.697402
2023-10-30 21:04:58,495 Epoch: [373/484] Iter:[330/495], Time: 0.37, lr: [0.0026428665830491643], Loss: 1.937580, Acc:0.802288, Semantic loss: 0.727532, BCE loss: 0.512800, SB loss: 0.697248
2023-10-30 21:05:02,163 Epoch: [373/484] Iter:[340/495], Time: 0.37, lr: [0.002642431061360601], Loss: 1.935098, Acc:0.802118, Semantic loss: 0.727865, BCE loss: 0.510546, SB loss: 0.696687
2023-10-30 21:05:05,751 Epoch: [373/484] Iter:[350/495], Time: 0.37, lr: [0.002641995531696106], Loss: 1.937259, Acc:0.801106, Semantic loss: 0.730328, BCE loss: 0.508911, SB loss: 0.698020
2023-10-30 21:05:09,430 Epoch: [373/484] Iter:[360/495], Time: 0.37, lr: [0.0026415599940540742], Loss: 1.938093, Acc:0.800700, Semantic loss: 0.730374, BCE loss: 0.508497, SB loss: 0.699221
2023-10-30 21:05:13,152 Epoch: [373/484] Iter:[370/495], Time: 0.37, lr: [0.002641124448432898], Loss: 1.939200, Acc:0.801008, Semantic loss: 0.731211, BCE loss: 0.507622, SB loss: 0.700367
2023-10-30 21:05:16,701 Epoch: [373/484] Iter:[380/495], Time: 0.37, lr: [0.002640688894830968], Loss: 1.942571, Acc:0.799818, Semantic loss: 0.733274, BCE loss: 0.506846, SB loss: 0.702451
2023-10-30 21:05:20,388 Epoch: [373/484] Iter:[390/495], Time: 0.37, lr: [0.002640253333246675], Loss: 1.941835, Acc:0.800253, Semantic loss: 0.732300, BCE loss: 0.507388, SB loss: 0.702146
2023-10-30 21:05:23,949 Epoch: [373/484] Iter:[400/495], Time: 0.37, lr: [0.002639817763678411], Loss: 1.944279, Acc:0.801289, Semantic loss: 0.733759, BCE loss: 0.508062, SB loss: 0.702458
2023-10-30 21:05:27,533 Epoch: [373/484] Iter:[410/495], Time: 0.37, lr: [0.0026393821861245654], Loss: 1.951165, Acc:0.801526, Semantic loss: 0.739091, BCE loss: 0.508975, SB loss: 0.703099
2023-10-30 21:05:31,111 Epoch: [373/484] Iter:[420/495], Time: 0.37, lr: [0.002638946600583527], Loss: 1.953128, Acc:0.801079, Semantic loss: 0.739923, BCE loss: 0.509869, SB loss: 0.703336
2023-10-30 21:05:34,790 Epoch: [373/484] Iter:[430/495], Time: 0.37, lr: [0.0026385110070536837], Loss: 1.955092, Acc:0.801504, Semantic loss: 0.739851, BCE loss: 0.511748, SB loss: 0.703492
2023-10-30 21:05:38,405 Epoch: [373/484] Iter:[440/495], Time: 0.37, lr: [0.0026380754055334256], Loss: 1.956755, Acc:0.801686, Semantic loss: 0.739550, BCE loss: 0.513253, SB loss: 0.703952
2023-10-30 21:05:42,023 Epoch: [373/484] Iter:[450/495], Time: 0.37, lr: [0.0026376397960211385], Loss: 1.958411, Acc:0.801661, Semantic loss: 0.740592, BCE loss: 0.513633, SB loss: 0.704186
2023-10-30 21:05:45,630 Epoch: [373/484] Iter:[460/495], Time: 0.37, lr: [0.0026372041785152098], Loss: 1.958366, Acc:0.801443, Semantic loss: 0.741070, BCE loss: 0.512726, SB loss: 0.704570
2023-10-30 21:05:49,262 Epoch: [373/484] Iter:[470/495], Time: 0.37, lr: [0.002636768553014024], Loss: 1.957872, Acc:0.801129, Semantic loss: 0.741281, BCE loss: 0.511602, SB loss: 0.704989
2023-10-30 21:05:52,831 Epoch: [373/484] Iter:[480/495], Time: 0.37, lr: [0.00263633291951597], Loss: 1.956706, Acc:0.801223, Semantic loss: 0.740354, BCE loss: 0.511627, SB loss: 0.704725
2023-10-30 21:05:56,280 Epoch: [373/484] Iter:[490/495], Time: 0.37, lr: [0.0026358972780194294], Loss: 1.953951, Acc:0.801285, Semantic loss: 0.739564, BCE loss: 0.510421, SB loss: 0.703967
2023-10-30 21:05:57,637 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:05:57,874 Loss: 2.015, MeanIU:  0.7311, Best_mIoU:  0.7487
2023-10-30 21:05:57,874 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631]
2023-10-30 21:05:59,844 Epoch: [374/484] Iter:[0/495], Time: 1.94, lr: [0.002635679454271223], Loss: 2.038327, Acc:0.818060, Semantic loss: 0.846497, BCE loss: 0.414436, SB loss: 0.777394
2023-10-30 21:06:03,887 Epoch: [374/484] Iter:[10/495], Time: 0.54, lr: [0.0026352438007739253], Loss: 1.935353, Acc:0.786555, Semantic loss: 0.718223, BCE loss: 0.498036, SB loss: 0.719094
2023-10-30 21:06:07,580 Epoch: [374/484] Iter:[20/495], Time: 0.46, lr: [0.002634808139274101], Loss: 1.918444, Acc:0.811887, Semantic loss: 0.696315, BCE loss: 0.525530, SB loss: 0.696599
2023-10-30 21:06:11,345 Epoch: [374/484] Iter:[30/495], Time: 0.43, lr: [0.0026343724697701354], Loss: 1.923968, Acc:0.812115, Semantic loss: 0.704357, BCE loss: 0.521577, SB loss: 0.698034
2023-10-30 21:06:14,865 Epoch: [374/484] Iter:[40/495], Time: 0.41, lr: [0.002633936792260408], Loss: 1.908275, Acc:0.818921, Semantic loss: 0.705939, BCE loss: 0.508232, SB loss: 0.694104
2023-10-30 21:06:18,552 Epoch: [374/484] Iter:[50/495], Time: 0.40, lr: [0.0026335011067433016], Loss: 1.934139, Acc:0.818210, Semantic loss: 0.717926, BCE loss: 0.517919, SB loss: 0.698294
2023-10-30 21:06:22,229 Epoch: [374/484] Iter:[60/495], Time: 0.40, lr: [0.0026330654132171957], Loss: 1.918521, Acc:0.816821, Semantic loss: 0.716078, BCE loss: 0.504942, SB loss: 0.697501
2023-10-30 21:06:25,999 Epoch: [374/484] Iter:[70/495], Time: 0.40, lr: [0.002632629711680472], Loss: 1.912556, Acc:0.817894, Semantic loss: 0.712131, BCE loss: 0.503766, SB loss: 0.696659
2023-10-30 21:06:29,610 Epoch: [374/484] Iter:[80/495], Time: 0.39, lr: [0.0026321940021315094], Loss: 1.917246, Acc:0.815300, Semantic loss: 0.718507, BCE loss: 0.501652, SB loss: 0.697086
2023-10-30 21:06:33,296 Epoch: [374/484] Iter:[90/495], Time: 0.39, lr: [0.0026317582845686873], Loss: 1.921973, Acc:0.813292, Semantic loss: 0.719622, BCE loss: 0.505993, SB loss: 0.696357
2023-10-30 21:06:36,904 Epoch: [374/484] Iter:[100/495], Time: 0.39, lr: [0.002631322558990383], Loss: 1.938461, Acc:0.811943, Semantic loss: 0.732837, BCE loss: 0.504953, SB loss: 0.700672
2023-10-30 21:06:40,664 Epoch: [374/484] Iter:[110/495], Time: 0.39, lr: [0.0026308868253949753], Loss: 1.943271, Acc:0.812681, Semantic loss: 0.732033, BCE loss: 0.511026, SB loss: 0.700212
2023-10-30 21:06:44,322 Epoch: [374/484] Iter:[120/495], Time: 0.38, lr: [0.0026304510837808414], Loss: 1.936915, Acc:0.814011, Semantic loss: 0.728738, BCE loss: 0.510955, SB loss: 0.697222
2023-10-30 21:06:47,866 Epoch: [374/484] Iter:[130/495], Time: 0.38, lr: [0.0026300153341463567], Loss: 1.933435, Acc:0.813819, Semantic loss: 0.727834, BCE loss: 0.508339, SB loss: 0.697262
2023-10-30 21:06:51,453 Epoch: [374/484] Iter:[140/495], Time: 0.38, lr: [0.002629579576489897], Loss: 1.933135, Acc:0.811935, Semantic loss: 0.727808, BCE loss: 0.505787, SB loss: 0.699540
2023-10-30 21:06:55,105 Epoch: [374/484] Iter:[150/495], Time: 0.38, lr: [0.0026291438108098394], Loss: 1.934089, Acc:0.810981, Semantic loss: 0.727692, BCE loss: 0.506287, SB loss: 0.700109
2023-10-30 21:06:58,665 Epoch: [374/484] Iter:[160/495], Time: 0.38, lr: [0.002628708037104557], Loss: 1.930577, Acc:0.810160, Semantic loss: 0.725225, BCE loss: 0.506304, SB loss: 0.699048
2023-10-30 21:07:02,217 Epoch: [374/484] Iter:[170/495], Time: 0.38, lr: [0.0026282722553724242], Loss: 1.926744, Acc:0.806800, Semantic loss: 0.724386, BCE loss: 0.503642, SB loss: 0.698716
2023-10-30 21:07:05,836 Epoch: [374/484] Iter:[180/495], Time: 0.38, lr: [0.0026278364656118127], Loss: 1.930288, Acc:0.807909, Semantic loss: 0.725712, BCE loss: 0.506502, SB loss: 0.698074
2023-10-30 21:07:09,514 Epoch: [374/484] Iter:[190/495], Time: 0.37, lr: [0.0026274006678210977], Loss: 1.934060, Acc:0.809046, Semantic loss: 0.726967, BCE loss: 0.508645, SB loss: 0.698447
2023-10-30 21:07:13,158 Epoch: [374/484] Iter:[200/495], Time: 0.37, lr: [0.0026269648619986503], Loss: 1.930534, Acc:0.808884, Semantic loss: 0.727121, BCE loss: 0.505608, SB loss: 0.697806
2023-10-30 21:07:16,779 Epoch: [374/484] Iter:[210/495], Time: 0.37, lr: [0.00262652904814284], Loss: 1.928979, Acc:0.807569, Semantic loss: 0.726749, BCE loss: 0.504843, SB loss: 0.697386
2023-10-30 21:07:20,404 Epoch: [374/484] Iter:[220/495], Time: 0.37, lr: [0.002626093226252041], Loss: 1.933494, Acc:0.808390, Semantic loss: 0.730388, BCE loss: 0.504879, SB loss: 0.698227
2023-10-30 21:07:24,073 Epoch: [374/484] Iter:[230/495], Time: 0.37, lr: [0.002625657396324622], Loss: 1.926468, Acc:0.807272, Semantic loss: 0.726705, BCE loss: 0.503053, SB loss: 0.696711
2023-10-30 21:07:27,780 Epoch: [374/484] Iter:[240/495], Time: 0.37, lr: [0.0026252215583589525], Loss: 1.933006, Acc:0.804832, Semantic loss: 0.733950, BCE loss: 0.501415, SB loss: 0.697642
2023-10-30 21:07:31,557 Epoch: [374/484] Iter:[250/495], Time: 0.37, lr: [0.0026247857123533995], Loss: 1.943213, Acc:0.804707, Semantic loss: 0.737522, BCE loss: 0.505301, SB loss: 0.700390
2023-10-30 21:07:35,219 Epoch: [374/484] Iter:[260/495], Time: 0.37, lr: [0.0026243498583063346], Loss: 1.941694, Acc:0.805323, Semantic loss: 0.735444, BCE loss: 0.504828, SB loss: 0.701423
2023-10-30 21:07:38,814 Epoch: [374/484] Iter:[270/495], Time: 0.37, lr: [0.002623913996216124], Loss: 1.946067, Acc:0.805809, Semantic loss: 0.736609, BCE loss: 0.507737, SB loss: 0.701721
2023-10-30 21:07:42,417 Epoch: [374/484] Iter:[280/495], Time: 0.37, lr: [0.002623478126081134], Loss: 1.941873, Acc:0.806177, Semantic loss: 0.732912, BCE loss: 0.508354, SB loss: 0.700607
2023-10-30 21:07:46,080 Epoch: [374/484] Iter:[290/495], Time: 0.37, lr: [0.002623042247899731], Loss: 1.941858, Acc:0.806669, Semantic loss: 0.732255, BCE loss: 0.508438, SB loss: 0.701165
2023-10-30 21:07:49,684 Epoch: [374/484] Iter:[300/495], Time: 0.37, lr: [0.0026226063616702822], Loss: 1.943230, Acc:0.804789, Semantic loss: 0.732738, BCE loss: 0.509212, SB loss: 0.701280
2023-10-30 21:07:53,272 Epoch: [374/484] Iter:[310/495], Time: 0.37, lr: [0.0026221704673911523], Loss: 1.951328, Acc:0.804777, Semantic loss: 0.737063, BCE loss: 0.510529, SB loss: 0.703736
2023-10-30 21:07:56,831 Epoch: [374/484] Iter:[320/495], Time: 0.37, lr: [0.002621734565060705], Loss: 1.949619, Acc:0.803804, Semantic loss: 0.736236, BCE loss: 0.509659, SB loss: 0.703723
2023-10-30 21:08:00,458 Epoch: [374/484] Iter:[330/495], Time: 0.37, lr: [0.002621298654677303], Loss: 1.949941, Acc:0.804178, Semantic loss: 0.734885, BCE loss: 0.511067, SB loss: 0.703989
2023-10-30 21:08:04,103 Epoch: [374/484] Iter:[340/495], Time: 0.37, lr: [0.0026208627362393124], Loss: 1.947937, Acc:0.804128, Semantic loss: 0.733767, BCE loss: 0.510111, SB loss: 0.704059
2023-10-30 21:08:07,781 Epoch: [374/484] Iter:[350/495], Time: 0.37, lr: [0.0026204268097450947], Loss: 1.952125, Acc:0.804779, Semantic loss: 0.736505, BCE loss: 0.510307, SB loss: 0.705313
2023-10-30 21:08:11,411 Epoch: [374/484] Iter:[360/495], Time: 0.37, lr: [0.0026199908751930105], Loss: 1.950943, Acc:0.804677, Semantic loss: 0.736580, BCE loss: 0.509637, SB loss: 0.704727
2023-10-30 21:08:15,273 Epoch: [374/484] Iter:[370/495], Time: 0.37, lr: [0.0026195549325814214], Loss: 1.951917, Acc:0.805585, Semantic loss: 0.737038, BCE loss: 0.510150, SB loss: 0.704728
2023-10-30 21:08:18,889 Epoch: [374/484] Iter:[380/495], Time: 0.37, lr: [0.0026191189819086903], Loss: 1.958672, Acc:0.805457, Semantic loss: 0.737972, BCE loss: 0.515333, SB loss: 0.705367
2023-10-30 21:08:22,515 Epoch: [374/484] Iter:[390/495], Time: 0.37, lr: [0.002618683023173175], Loss: 1.959365, Acc:0.805150, Semantic loss: 0.738316, BCE loss: 0.515347, SB loss: 0.705702
2023-10-30 21:08:26,128 Epoch: [374/484] Iter:[400/495], Time: 0.37, lr: [0.0026182470563732357], Loss: 1.961286, Acc:0.805704, Semantic loss: 0.738736, BCE loss: 0.516626, SB loss: 0.705924
2023-10-30 21:08:29,739 Epoch: [374/484] Iter:[410/495], Time: 0.37, lr: [0.0026178110815072305], Loss: 1.965385, Acc:0.805246, Semantic loss: 0.740863, BCE loss: 0.518242, SB loss: 0.706280
2023-10-30 21:08:33,283 Epoch: [374/484] Iter:[420/495], Time: 0.37, lr: [0.0026173750985735186], Loss: 1.961958, Acc:0.804867, Semantic loss: 0.739276, BCE loss: 0.516660, SB loss: 0.706023
2023-10-30 21:08:36,929 Epoch: [374/484] Iter:[430/495], Time: 0.37, lr: [0.0026169391075704564], Loss: 1.962378, Acc:0.804828, Semantic loss: 0.740642, BCE loss: 0.516025, SB loss: 0.705711
2023-10-30 21:08:40,634 Epoch: [374/484] Iter:[440/495], Time: 0.37, lr: [0.002616503108496402], Loss: 1.960739, Acc:0.803872, Semantic loss: 0.739845, BCE loss: 0.515635, SB loss: 0.705259
2023-10-30 21:08:44,324 Epoch: [374/484] Iter:[450/495], Time: 0.37, lr: [0.002616067101349709], Loss: 1.965139, Acc:0.803507, Semantic loss: 0.741271, BCE loss: 0.517340, SB loss: 0.706528
2023-10-30 21:08:47,940 Epoch: [374/484] Iter:[460/495], Time: 0.37, lr: [0.0026156310861287363], Loss: 1.962868, Acc:0.803310, Semantic loss: 0.740191, BCE loss: 0.516622, SB loss: 0.706056
2023-10-30 21:08:51,503 Epoch: [374/484] Iter:[470/495], Time: 0.37, lr: [0.0026151950628318372], Loss: 1.963590, Acc:0.803085, Semantic loss: 0.741137, BCE loss: 0.516171, SB loss: 0.706281
2023-10-30 21:08:55,106 Epoch: [374/484] Iter:[480/495], Time: 0.37, lr: [0.002614759031457366], Loss: 1.961422, Acc:0.803490, Semantic loss: 0.739669, BCE loss: 0.515888, SB loss: 0.705866
2023-10-30 21:08:58,577 Epoch: [374/484] Iter:[490/495], Time: 0.37, lr: [0.0026143229920036755], Loss: 1.960176, Acc:0.804144, Semantic loss: 0.739183, BCE loss: 0.515477, SB loss: 0.705515
2023-10-30 21:08:59,949 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:09:00,187 Loss: 2.015, MeanIU:  0.7311, Best_mIoU:  0.7487
2023-10-30 21:09:00,187 [0.97757123 0.82837618 0.91683704 0.55211651 0.56682842 0.61138572
 0.66807086 0.74949574 0.91601622 0.61781468 0.93986982 0.79363272
 0.5705122  0.93538431 0.66248915 0.79619276 0.59034641 0.46909873
 0.72893631]
2023-10-30 21:09:02,316 Epoch: [375/484] Iter:[0/495], Time: 2.10, lr: [0.0026141049692466095], Loss: 2.006403, Acc:0.771282, Semantic loss: 0.703488, BCE loss: 0.558020, SB loss: 0.744896
2023-10-30 21:09:06,354 Epoch: [375/484] Iter:[10/495], Time: 0.56, lr: [0.002613668917671004], Loss: 1.993298, Acc:0.790299, Semantic loss: 0.739423, BCE loss: 0.529929, SB loss: 0.723946
2023-10-30 21:09:10,151 Epoch: [375/484] Iter:[20/495], Time: 0.47, lr: [0.002613232858012061], Loss: 1.940783, Acc:0.809988, Semantic loss: 0.717260, BCE loss: 0.524882, SB loss: 0.698642
2023-10-30 21:09:13,761 Epoch: [375/484] Iter:[30/495], Time: 0.44, lr: [0.0026127967902681323], Loss: 1.956206, Acc:0.824772, Semantic loss: 0.727305, BCE loss: 0.520015, SB loss: 0.708886
2023-10-30 21:09:17,469 Epoch: [375/484] Iter:[40/495], Time: 0.42, lr: [0.0026123607144375688], Loss: 1.981275, Acc:0.830859, Semantic loss: 0.744805, BCE loss: 0.525134, SB loss: 0.711336
2023-10-30 21:09:21,099 Epoch: [375/484] Iter:[50/495], Time: 0.41, lr: [0.0026119246305187213], Loss: 1.966738, Acc:0.822716, Semantic loss: 0.735938, BCE loss: 0.523573, SB loss: 0.707226
2023-10-30 21:09:24,766 Epoch: [375/484] Iter:[60/495], Time: 0.40, lr: [0.0026114885385099375], Loss: 1.948710, Acc:0.812509, Semantic loss: 0.730514, BCE loss: 0.513224, SB loss: 0.704972
2023-10-30 21:09:28,411 Epoch: [375/484] Iter:[70/495], Time: 0.40, lr: [0.0026110524384095665], Loss: 1.969173, Acc:0.813070, Semantic loss: 0.738399, BCE loss: 0.521746, SB loss: 0.709028
2023-10-30 21:09:32,032 Epoch: [375/484] Iter:[80/495], Time: 0.39, lr: [0.002610616330215958], Loss: 1.950066, Acc:0.812169, Semantic loss: 0.726305, BCE loss: 0.519704, SB loss: 0.704057
2023-10-30 21:09:35,579 Epoch: [375/484] Iter:[90/495], Time: 0.39, lr: [0.002610180213927459], Loss: 1.948383, Acc:0.808889, Semantic loss: 0.728394, BCE loss: 0.516420, SB loss: 0.703570
2023-10-30 21:09:39,180 Epoch: [375/484] Iter:[100/495], Time: 0.39, lr: [0.0026097440895424162], Loss: 1.951502, Acc:0.806214, Semantic loss: 0.731818, BCE loss: 0.513926, SB loss: 0.705758
2023-10-30 21:09:42,760 Epoch: [375/484] Iter:[110/495], Time: 0.38, lr: [0.0026093079570591745], Loss: 1.956626, Acc:0.803989, Semantic loss: 0.736148, BCE loss: 0.513369, SB loss: 0.707109
2023-10-30 21:09:46,310 Epoch: [375/484] Iter:[120/495], Time: 0.38, lr: [0.002608871816476081], Loss: 1.952007, Acc:0.803336, Semantic loss: 0.734267, BCE loss: 0.510908, SB loss: 0.706831
2023-10-30 21:09:49,955 Epoch: [375/484] Iter:[130/495], Time: 0.38, lr: [0.002608435667791481], Loss: 1.946134, Acc:0.799804, Semantic loss: 0.731464, BCE loss: 0.508435, SB loss: 0.706235
2023-10-30 21:09:53,681 Epoch: [375/484] Iter:[140/495], Time: 0.38, lr: [0.0026079995110037187], Loss: 1.946810, Acc:0.798821, Semantic loss: 0.732161, BCE loss: 0.507580, SB loss: 0.707069
2023-10-30 21:09:57,254 Epoch: [375/484] Iter:[150/495], Time: 0.38, lr: [0.0026075633461111352], Loss: 1.950000, Acc:0.801347, Semantic loss: 0.731679, BCE loss: 0.512392, SB loss: 0.705929
2023-10-30 21:10:00,861 Epoch: [375/484] Iter:[160/495], Time: 0.38, lr: [0.002607127173112077], Loss: 1.950733, Acc:0.803714, Semantic loss: 0.732024, BCE loss: 0.513777, SB loss: 0.704932
2023-10-30 21:10:04,525 Epoch: [375/484] Iter:[170/495], Time: 0.38, lr: [0.0026066909920048854], Loss: 1.951322, Acc:0.803634, Semantic loss: 0.730767, BCE loss: 0.516025, SB loss: 0.704530
2023-10-30 21:10:08,126 Epoch: [375/484] Iter:[180/495], Time: 0.38, lr: [0.0026062548027879014], Loss: 1.950907, Acc:0.802969, Semantic loss: 0.727648, BCE loss: 0.520005, SB loss: 0.703254
2023-10-30 21:10:11,751 Epoch: [375/484] Iter:[190/495], Time: 0.37, lr: [0.0026058186054594657], Loss: 1.946938, Acc:0.804303, Semantic loss: 0.726480, BCE loss: 0.519241, SB loss: 0.701216
2023-10-30 21:10:15,407 Epoch: [375/484] Iter:[200/495], Time: 0.37, lr: [0.00260538240001792], Loss: 1.950204, Acc:0.804631, Semantic loss: 0.730277, BCE loss: 0.519364, SB loss: 0.700563
2023-10-30 21:10:19,108 Epoch: [375/484] Iter:[210/495], Time: 0.37, lr: [0.0026049461864616043], Loss: 1.940024, Acc:0.804893, Semantic loss: 0.725960, BCE loss: 0.516090, SB loss: 0.697974
2023-10-30 21:10:22,827 Epoch: [375/484] Iter:[220/495], Time: 0.37, lr: [0.0026045099647888565], Loss: 1.936244, Acc:0.803876, Semantic loss: 0.726115, BCE loss: 0.512679, SB loss: 0.697450
2023-10-30 21:10:26,318 Epoch: [375/484] Iter:[230/495], Time: 0.37, lr: [0.0026040737349980144], Loss: 1.938506, Acc:0.802850, Semantic loss: 0.727001, BCE loss: 0.512592, SB loss: 0.698913
2023-10-30 21:10:29,971 Epoch: [375/484] Iter:[240/495], Time: 0.37, lr: [0.0026036374970874183], Loss: 1.944175, Acc:0.802507, Semantic loss: 0.733559, BCE loss: 0.511902, SB loss: 0.698713
2023-10-30 21:10:33,555 Epoch: [375/484] Iter:[250/495], Time: 0.37, lr: [0.0026032012510554038], Loss: 1.938116, Acc:0.803192, Semantic loss: 0.730025, BCE loss: 0.510923, SB loss: 0.697168
2023-10-30 21:10:37,158 Epoch: [375/484] Iter:[260/495], Time: 0.37, lr: [0.002602764996900308], Loss: 1.935621, Acc:0.802101, Semantic loss: 0.730016, BCE loss: 0.508639, SB loss: 0.696966
2023-10-30 21:10:40,723 Epoch: [375/484] Iter:[270/495], Time: 0.37, lr: [0.0026023287346204657], Loss: 1.933962, Acc:0.801671, Semantic loss: 0.730752, BCE loss: 0.506462, SB loss: 0.696748
2023-10-30 21:10:44,328 Epoch: [375/484] Iter:[280/495], Time: 0.37, lr: [0.0026018924642142133], Loss: 1.938572, Acc:0.801614, Semantic loss: 0.733690, BCE loss: 0.507426, SB loss: 0.697456
2023-10-30 21:10:47,890 Epoch: [375/484] Iter:[290/495], Time: 0.37, lr: [0.0026014561856798854], Loss: 1.940123, Acc:0.802107, Semantic loss: 0.733719, BCE loss: 0.508941, SB loss: 0.697462
2023-10-30 21:10:51,596 Epoch: [375/484] Iter:[300/495], Time: 0.37, lr: [0.0026010198990158158], Loss: 1.938168, Acc:0.802386, Semantic loss: 0.732938, BCE loss: 0.507785, SB loss: 0.697445
2023-10-30 21:10:55,313 Epoch: [375/484] Iter:[310/495], Time: 0.37, lr: [0.0026005836042203357], Loss: 1.943422, Acc:0.802107, Semantic loss: 0.733209, BCE loss: 0.512141, SB loss: 0.698072
2023-10-30 21:10:58,916 Epoch: [375/484] Iter:[320/495], Time: 0.37, lr: [0.0026001473012917816], Loss: 1.941168, Acc:0.801996, Semantic loss: 0.731647, BCE loss: 0.511867, SB loss: 0.697654
2023-10-30 21:11:02,551 Epoch: [375/484] Iter:[330/495], Time: 0.37, lr: [0.002599710990228483], Loss: 1.942181, Acc:0.801965, Semantic loss: 0.732214, BCE loss: 0.512510, SB loss: 0.697457
2023-10-30 21:11:06,165 Epoch: [375/484] Iter:[340/495], Time: 0.37, lr: [0.002599274671028771], Loss: 1.941960, Acc:0.801639, Semantic loss: 0.732608, BCE loss: 0.512177, SB loss: 0.697175
2023-10-30 21:11:09,802 Epoch: [375/484] Iter:[350/495], Time: 0.37, lr: [0.0025988383436909763], Loss: 1.943047, Acc:0.802394, Semantic loss: 0.732869, BCE loss: 0.512174, SB loss: 0.698004
2023-10-30 21:11:13,385 Epoch: [375/484] Iter:[360/495], Time: 0.37, lr: [0.002598402008213431], Loss: 1.943403, Acc:0.802021, Semantic loss: 0.732126, BCE loss: 0.512860, SB loss: 0.698417
2023-10-30 21:11:16,946 Epoch: [375/484] Iter:[370/495], Time: 0.37, lr: [0.0025979656645944626], Loss: 1.942864, Acc:0.801072, Semantic loss: 0.732957, BCE loss: 0.511162, SB loss: 0.698745
2023-10-30 21:11:20,657 Epoch: [375/484] Iter:[380/495], Time: 0.37, lr: [0.0025975293128324], Loss: 1.945021, Acc:0.800155, Semantic loss: 0.734629, BCE loss: 0.511097, SB loss: 0.699295
2023-10-30 21:11:24,252 Epoch: [375/484] Iter:[390/495], Time: 0.37, lr: [0.002597092952925571], Loss: 1.945653, Acc:0.799663, Semantic loss: 0.735430, BCE loss: 0.510807, SB loss: 0.699416
2023-10-30 21:11:27,889 Epoch: [375/484] Iter:[400/495], Time: 0.37, lr: [0.002596656584872304], Loss: 1.944481, Acc:0.799758, Semantic loss: 0.734301, BCE loss: 0.511072, SB loss: 0.699108
2023-10-30 21:11:31,491 Epoch: [375/484] Iter:[410/495], Time: 0.37, lr: [0.0025962202086709254], Loss: 1.944334, Acc:0.800390, Semantic loss: 0.733124, BCE loss: 0.512003, SB loss: 0.699206
2023-10-30 21:11:35,338 Epoch: [375/484] Iter:[420/495], Time: 0.37, lr: [0.002595783824319761], Loss: 1.947725, Acc:0.801136, Semantic loss: 0.733939, BCE loss: 0.513896, SB loss: 0.699891
2023-10-30 21:11:38,990 Epoch: [375/484] Iter:[430/495], Time: 0.37, lr: [0.0025953474318171346], Loss: 1.944854, Acc:0.801054, Semantic loss: 0.732698, BCE loss: 0.513024, SB loss: 0.699132
2023-10-30 21:11:42,696 Epoch: [375/484] Iter:[440/495], Time: 0.37, lr: [0.0025949110311613744], Loss: 1.946853, Acc:0.801073, Semantic loss: 0.733579, BCE loss: 0.514127, SB loss: 0.699146
2023-10-30 21:11:46,278 Epoch: [375/484] Iter:[450/495], Time: 0.37, lr: [0.0025944746223508027], Loss: 1.945759, Acc:0.801353, Semantic loss: 0.732676, BCE loss: 0.513772, SB loss: 0.699311
2023-10-30 21:11:49,830 Epoch: [375/484] Iter:[460/495], Time: 0.37, lr: [0.0025940382053837425], Loss: 1.946288, Acc:0.801398, Semantic loss: 0.733657, BCE loss: 0.512884, SB loss: 0.699747
2023-10-30 21:11:53,495 Epoch: [375/484] Iter:[470/495], Time: 0.37, lr: [0.002593601780258516], Loss: 1.946106, Acc:0.801358, Semantic loss: 0.734145, BCE loss: 0.512100, SB loss: 0.699861
2023-10-30 21:11:57,150 Epoch: [375/484] Iter:[480/495], Time: 0.37, lr: [0.002593165346973448], Loss: 1.945076, Acc:0.801345, Semantic loss: 0.734333, BCE loss: 0.510681, SB loss: 0.700063
2023-10-30 21:12:00,632 Epoch: [375/484] Iter:[490/495], Time: 0.37, lr: [0.0025927289055268582], Loss: 1.945223, Acc:0.801857, Semantic loss: 0.733544, BCE loss: 0.511687, SB loss: 0.699993
2023-10-30 21:14:58,232 0 [0.94245034 0.64749282 0.82826831 0.19519937 0.28010229 0.42437166
 0.46561872 0.59446364 0.88701648 0.4791447  0.86956227 0.5706508
 0.06248649 0.81822998 0.0046957  0.15981272 0.06196838 0.0877558
 0.59960184] 0.47257328047612335
2023-10-30 21:14:58,232 1 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617] 0.6832800700649568
2023-10-30 21:14:58,236 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:14:58,475 Loss: 2.031, MeanIU:  0.6833, Best_mIoU:  0.7487
2023-10-30 21:14:58,475 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617]
2023-10-30 21:15:00,748 Epoch: [376/484] Iter:[0/495], Time: 2.24, lr: [0.0025925106817424677], Loss: 1.950922, Acc:0.804231, Semantic loss: 0.708253, BCE loss: 0.534068, SB loss: 0.708601
2023-10-30 21:15:04,544 Epoch: [376/484] Iter:[10/495], Time: 0.55, lr: [0.0025920742280504455], Loss: 2.029192, Acc:0.803068, Semantic loss: 0.782413, BCE loss: 0.499352, SB loss: 0.747428
2023-10-30 21:15:08,029 Epoch: [376/484] Iter:[20/495], Time: 0.45, lr: [0.002591637766192704], Loss: 2.045114, Acc:0.792087, Semantic loss: 0.782998, BCE loss: 0.528045, SB loss: 0.734071
2023-10-30 21:15:11,716 Epoch: [376/484] Iter:[30/495], Time: 0.43, lr: [0.0025912012961675605], Loss: 1.999340, Acc:0.799830, Semantic loss: 0.766892, BCE loss: 0.518810, SB loss: 0.713638
2023-10-30 21:15:15,302 Epoch: [376/484] Iter:[40/495], Time: 0.41, lr: [0.0025907648179733338], Loss: 2.018930, Acc:0.802123, Semantic loss: 0.769603, BCE loss: 0.531373, SB loss: 0.717954
2023-10-30 21:15:18,743 Epoch: [376/484] Iter:[50/495], Time: 0.40, lr: [0.002590328331608341], Loss: 2.007566, Acc:0.806617, Semantic loss: 0.758520, BCE loss: 0.534999, SB loss: 0.714046
2023-10-30 21:15:22,235 Epoch: [376/484] Iter:[60/495], Time: 0.39, lr: [0.002589891837070901], Loss: 2.058865, Acc:0.794743, Semantic loss: 0.802425, BCE loss: 0.530413, SB loss: 0.726026
2023-10-30 21:15:25,780 Epoch: [376/484] Iter:[70/495], Time: 0.38, lr: [0.002589455334359329], Loss: 2.034104, Acc:0.797362, Semantic loss: 0.785160, BCE loss: 0.530160, SB loss: 0.718784
2023-10-30 21:15:29,200 Epoch: [376/484] Iter:[80/495], Time: 0.38, lr: [0.002589018823471942], Loss: 2.012584, Acc:0.798024, Semantic loss: 0.773593, BCE loss: 0.520215, SB loss: 0.718775
2023-10-30 21:15:32,733 Epoch: [376/484] Iter:[90/495], Time: 0.38, lr: [0.002588582304407053], Loss: 1.994956, Acc:0.792672, Semantic loss: 0.765842, BCE loss: 0.514509, SB loss: 0.714605
2023-10-30 21:15:36,250 Epoch: [376/484] Iter:[100/495], Time: 0.37, lr: [0.002588145777162979], Loss: 1.984120, Acc:0.791040, Semantic loss: 0.761028, BCE loss: 0.510036, SB loss: 0.713056
2023-10-30 21:15:39,870 Epoch: [376/484] Iter:[110/495], Time: 0.37, lr: [0.0025877092417380333], Loss: 1.984570, Acc:0.794298, Semantic loss: 0.759545, BCE loss: 0.513787, SB loss: 0.711238
2023-10-30 21:15:43,547 Epoch: [376/484] Iter:[120/495], Time: 0.37, lr: [0.0025872726981305285], Loss: 1.973177, Acc:0.797895, Semantic loss: 0.750680, BCE loss: 0.513825, SB loss: 0.708672
2023-10-30 21:15:47,109 Epoch: [376/484] Iter:[130/495], Time: 0.37, lr: [0.0025868361463387756], Loss: 1.972396, Acc:0.801073, Semantic loss: 0.747189, BCE loss: 0.516645, SB loss: 0.708562
2023-10-30 21:15:50,653 Epoch: [376/484] Iter:[140/495], Time: 0.37, lr: [0.00258639958636109], Loss: 1.963352, Acc:0.802609, Semantic loss: 0.744036, BCE loss: 0.510373, SB loss: 0.708942
2023-10-30 21:15:54,098 Epoch: [376/484] Iter:[150/495], Time: 0.37, lr: [0.002585963018195781], Loss: 1.969503, Acc:0.801183, Semantic loss: 0.744742, BCE loss: 0.515276, SB loss: 0.709484
2023-10-30 21:15:57,597 Epoch: [376/484] Iter:[160/495], Time: 0.37, lr: [0.002585526441841159], Loss: 1.966514, Acc:0.801276, Semantic loss: 0.743001, BCE loss: 0.515584, SB loss: 0.707929
2023-10-30 21:16:01,164 Epoch: [376/484] Iter:[170/495], Time: 0.37, lr: [0.0025850898572955332], Loss: 1.961758, Acc:0.802937, Semantic loss: 0.741139, BCE loss: 0.514233, SB loss: 0.706387
2023-10-30 21:16:04,835 Epoch: [376/484] Iter:[180/495], Time: 0.37, lr: [0.002584653264557215], Loss: 1.957466, Acc:0.804320, Semantic loss: 0.739347, BCE loss: 0.513850, SB loss: 0.704268
2023-10-30 21:16:08,526 Epoch: [376/484] Iter:[190/495], Time: 0.37, lr: [0.002584216663624511], Loss: 1.953637, Acc:0.804430, Semantic loss: 0.737709, BCE loss: 0.513872, SB loss: 0.702056
2023-10-30 21:16:12,135 Epoch: [376/484] Iter:[200/495], Time: 0.37, lr: [0.0025837800544957308], Loss: 1.954647, Acc:0.805334, Semantic loss: 0.738699, BCE loss: 0.513805, SB loss: 0.702143
2023-10-30 21:16:15,808 Epoch: [376/484] Iter:[210/495], Time: 0.37, lr: [0.002583343437169179], Loss: 1.954505, Acc:0.805757, Semantic loss: 0.738530, BCE loss: 0.513831, SB loss: 0.702144
2023-10-30 21:16:19,424 Epoch: [376/484] Iter:[220/495], Time: 0.37, lr: [0.002582906811643165], Loss: 1.950536, Acc:0.805942, Semantic loss: 0.736538, BCE loss: 0.512715, SB loss: 0.701283
2023-10-30 21:16:23,058 Epoch: [376/484] Iter:[230/495], Time: 0.37, lr: [0.0025824701779159926], Loss: 1.949614, Acc:0.804258, Semantic loss: 0.735659, BCE loss: 0.512357, SB loss: 0.701597
2023-10-30 21:16:26,685 Epoch: [376/484] Iter:[240/495], Time: 0.37, lr: [0.002582033535985969], Loss: 1.949363, Acc:0.803435, Semantic loss: 0.736600, BCE loss: 0.512365, SB loss: 0.700398
2023-10-30 21:16:30,272 Epoch: [376/484] Iter:[250/495], Time: 0.37, lr: [0.0025815968858513955], Loss: 1.950512, Acc:0.804267, Semantic loss: 0.736346, BCE loss: 0.513867, SB loss: 0.700299
2023-10-30 21:16:33,959 Epoch: [376/484] Iter:[260/495], Time: 0.37, lr: [0.00258116022751058], Loss: 1.952987, Acc:0.805366, Semantic loss: 0.735222, BCE loss: 0.517146, SB loss: 0.700619
2023-10-30 21:16:37,539 Epoch: [376/484] Iter:[270/495], Time: 0.37, lr: [0.0025807235609618235], Loss: 1.953586, Acc:0.806177, Semantic loss: 0.735397, BCE loss: 0.517771, SB loss: 0.700419
2023-10-30 21:16:41,040 Epoch: [376/484] Iter:[280/495], Time: 0.36, lr: [0.0025802868862034286], Loss: 1.952139, Acc:0.806437, Semantic loss: 0.735719, BCE loss: 0.516357, SB loss: 0.700063
2023-10-30 21:16:44,672 Epoch: [376/484] Iter:[290/495], Time: 0.36, lr: [0.002579850203233696], Loss: 1.946788, Acc:0.806353, Semantic loss: 0.733129, BCE loss: 0.514980, SB loss: 0.698678
2023-10-30 21:16:48,272 Epoch: [376/484] Iter:[300/495], Time: 0.36, lr: [0.00257941351205093], Loss: 1.945755, Acc:0.805012, Semantic loss: 0.731690, BCE loss: 0.515242, SB loss: 0.698823
2023-10-30 21:16:51,879 Epoch: [376/484] Iter:[310/495], Time: 0.36, lr: [0.002578976812653429], Loss: 1.946030, Acc:0.804239, Semantic loss: 0.731415, BCE loss: 0.515723, SB loss: 0.698892
2023-10-30 21:16:55,532 Epoch: [376/484] Iter:[320/495], Time: 0.36, lr: [0.002578540105039493], Loss: 1.945595, Acc:0.805017, Semantic loss: 0.731326, BCE loss: 0.515587, SB loss: 0.698682
2023-10-30 21:16:59,238 Epoch: [376/484] Iter:[330/495], Time: 0.36, lr: [0.0025781033892074206], Loss: 1.945602, Acc:0.805747, Semantic loss: 0.730592, BCE loss: 0.516475, SB loss: 0.698534
2023-10-30 21:17:02,718 Epoch: [376/484] Iter:[340/495], Time: 0.36, lr: [0.0025776666651555124], Loss: 1.942387, Acc:0.804841, Semantic loss: 0.729783, BCE loss: 0.514904, SB loss: 0.697701
2023-10-30 21:17:06,341 Epoch: [376/484] Iter:[350/495], Time: 0.36, lr: [0.002577229932882065], Loss: 1.943465, Acc:0.804464, Semantic loss: 0.730404, BCE loss: 0.515083, SB loss: 0.697978
2023-10-30 21:17:09,947 Epoch: [376/484] Iter:[360/495], Time: 0.36, lr: [0.002576793192385375], Loss: 1.939919, Acc:0.804237, Semantic loss: 0.729343, BCE loss: 0.513846, SB loss: 0.696731
2023-10-30 21:17:13,705 Epoch: [376/484] Iter:[370/495], Time: 0.36, lr: [0.0025763564436637383], Loss: 1.940447, Acc:0.803835, Semantic loss: 0.730404, BCE loss: 0.512645, SB loss: 0.697398
2023-10-30 21:17:17,342 Epoch: [376/484] Iter:[380/495], Time: 0.36, lr: [0.0025759196867154535], Loss: 1.940187, Acc:0.804459, Semantic loss: 0.729872, BCE loss: 0.512707, SB loss: 0.697608
2023-10-30 21:17:21,078 Epoch: [376/484] Iter:[390/495], Time: 0.36, lr: [0.002575482921538813], Loss: 1.937095, Acc:0.804893, Semantic loss: 0.728623, BCE loss: 0.511919, SB loss: 0.696554
2023-10-30 21:17:24,638 Epoch: [376/484] Iter:[400/495], Time: 0.36, lr: [0.0025750461481321135], Loss: 1.936448, Acc:0.804912, Semantic loss: 0.727603, BCE loss: 0.512993, SB loss: 0.695852
2023-10-30 21:17:28,385 Epoch: [376/484] Iter:[410/495], Time: 0.36, lr: [0.002574609366493646], Loss: 1.938369, Acc:0.804848, Semantic loss: 0.728362, BCE loss: 0.513739, SB loss: 0.696267
2023-10-30 21:17:32,012 Epoch: [376/484] Iter:[420/495], Time: 0.36, lr: [0.002574172576621706], Loss: 1.939741, Acc:0.805581, Semantic loss: 0.729210, BCE loss: 0.513466, SB loss: 0.697065
2023-10-30 21:17:35,695 Epoch: [376/484] Iter:[430/495], Time: 0.36, lr: [0.0025737357785145854], Loss: 1.940315, Acc:0.805036, Semantic loss: 0.729326, BCE loss: 0.513569, SB loss: 0.697420
2023-10-30 21:17:39,297 Epoch: [376/484] Iter:[440/495], Time: 0.36, lr: [0.0025732989721705757], Loss: 1.940803, Acc:0.805612, Semantic loss: 0.729011, BCE loss: 0.514214, SB loss: 0.697579
2023-10-30 21:17:42,972 Epoch: [376/484] Iter:[450/495], Time: 0.36, lr: [0.0025728621575879674], Loss: 1.938899, Acc:0.805994, Semantic loss: 0.727939, BCE loss: 0.513781, SB loss: 0.697179
2023-10-30 21:17:46,570 Epoch: [376/484] Iter:[460/495], Time: 0.36, lr: [0.0025724253347650518], Loss: 1.939749, Acc:0.806225, Semantic loss: 0.729111, BCE loss: 0.513098, SB loss: 0.697539
2023-10-30 21:17:50,202 Epoch: [376/484] Iter:[470/495], Time: 0.36, lr: [0.002571988503700119], Loss: 1.939447, Acc:0.805501, Semantic loss: 0.729062, BCE loss: 0.512390, SB loss: 0.697995
2023-10-30 21:17:53,858 Epoch: [376/484] Iter:[480/495], Time: 0.36, lr: [0.0025715516643914573], Loss: 1.938816, Acc:0.806059, Semantic loss: 0.728384, BCE loss: 0.512251, SB loss: 0.698181
2023-10-30 21:17:57,316 Epoch: [376/484] Iter:[490/495], Time: 0.36, lr: [0.002571114816837353], Loss: 1.937525, Acc:0.806273, Semantic loss: 0.728018, BCE loss: 0.511797, SB loss: 0.697710
2023-10-30 21:17:58,694 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:17:58,932 Loss: 2.031, MeanIU:  0.6833, Best_mIoU:  0.7487
2023-10-30 21:17:58,932 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617]
2023-10-30 21:18:00,958 Epoch: [377/484] Iter:[0/495], Time: 1.99, lr: [0.002570896389967727], Loss: 1.571010, Acc:0.769891, Semantic loss: 0.570401, BCE loss: 0.421077, SB loss: 0.579532
2023-10-30 21:18:05,015 Epoch: [377/484] Iter:[10/495], Time: 0.55, lr: [0.0025704595300422533], Loss: 1.904105, Acc:0.743214, Semantic loss: 0.726422, BCE loss: 0.439322, SB loss: 0.738361
2023-10-30 21:18:08,594 Epoch: [377/484] Iter:[20/495], Time: 0.46, lr: [0.0025700226618670568], Loss: 1.936716, Acc:0.758178, Semantic loss: 0.753185, BCE loss: 0.455388, SB loss: 0.728143
2023-10-30 21:18:12,278 Epoch: [377/484] Iter:[30/495], Time: 0.43, lr: [0.0025695857854404233], Loss: 1.953776, Acc:0.763696, Semantic loss: 0.754012, BCE loss: 0.475520, SB loss: 0.724245
2023-10-30 21:18:15,918 Epoch: [377/484] Iter:[40/495], Time: 0.41, lr: [0.0025691489007606395], Loss: 1.924555, Acc:0.773497, Semantic loss: 0.731282, BCE loss: 0.479591, SB loss: 0.713681
2023-10-30 21:18:19,373 Epoch: [377/484] Iter:[50/495], Time: 0.40, lr: [0.002568712007825989], Loss: 1.909855, Acc:0.775220, Semantic loss: 0.726327, BCE loss: 0.473142, SB loss: 0.710386
2023-10-30 21:18:22,887 Epoch: [377/484] Iter:[60/495], Time: 0.39, lr: [0.002568275106634756], Loss: 1.917434, Acc:0.775237, Semantic loss: 0.736018, BCE loss: 0.473545, SB loss: 0.707870
2023-10-30 21:18:26,569 Epoch: [377/484] Iter:[70/495], Time: 0.39, lr: [0.002567838197185223], Loss: 1.916895, Acc:0.781996, Semantic loss: 0.729129, BCE loss: 0.482107, SB loss: 0.705660
2023-10-30 21:18:30,264 Epoch: [377/484] Iter:[80/495], Time: 0.39, lr: [0.002567401279475674], Loss: 1.916553, Acc:0.785830, Semantic loss: 0.725643, BCE loss: 0.488387, SB loss: 0.702523
2023-10-30 21:18:33,842 Epoch: [377/484] Iter:[90/495], Time: 0.38, lr: [0.00256696435350439], Loss: 1.925062, Acc:0.786030, Semantic loss: 0.727867, BCE loss: 0.493414, SB loss: 0.703781
2023-10-30 21:18:37,416 Epoch: [377/484] Iter:[100/495], Time: 0.38, lr: [0.002566527419269653], Loss: 1.917188, Acc:0.783124, Semantic loss: 0.721973, BCE loss: 0.491925, SB loss: 0.703290
2023-10-30 21:18:41,031 Epoch: [377/484] Iter:[110/495], Time: 0.38, lr: [0.0025660904767697418], Loss: 1.918512, Acc:0.781910, Semantic loss: 0.723872, BCE loss: 0.492468, SB loss: 0.702171
2023-10-30 21:18:44,603 Epoch: [377/484] Iter:[120/495], Time: 0.38, lr: [0.002565653526002939], Loss: 1.913319, Acc:0.784314, Semantic loss: 0.720311, BCE loss: 0.494200, SB loss: 0.698808
2023-10-30 21:18:48,172 Epoch: [377/484] Iter:[130/495], Time: 0.38, lr: [0.0025652165669675215], Loss: 1.905124, Acc:0.783935, Semantic loss: 0.714504, BCE loss: 0.494331, SB loss: 0.696289
2023-10-30 21:18:51,855 Epoch: [377/484] Iter:[140/495], Time: 0.38, lr: [0.002564779599661769], Loss: 1.904186, Acc:0.785331, Semantic loss: 0.713663, BCE loss: 0.493470, SB loss: 0.697053
2023-10-30 21:18:55,681 Epoch: [377/484] Iter:[150/495], Time: 0.38, lr: [0.0025643426240839575], Loss: 1.918534, Acc:0.788917, Semantic loss: 0.719196, BCE loss: 0.501198, SB loss: 0.698139
2023-10-30 21:18:59,351 Epoch: [377/484] Iter:[160/495], Time: 0.38, lr: [0.0025639056402323667], Loss: 1.921380, Acc:0.790651, Semantic loss: 0.719088, BCE loss: 0.504967, SB loss: 0.697325
2023-10-30 21:19:03,002 Epoch: [377/484] Iter:[170/495], Time: 0.37, lr: [0.0025634686481052714], Loss: 1.926032, Acc:0.792898, Semantic loss: 0.719959, BCE loss: 0.507769, SB loss: 0.698304
2023-10-30 21:19:06,703 Epoch: [377/484] Iter:[180/495], Time: 0.37, lr: [0.0025630316477009483], Loss: 1.925584, Acc:0.794672, Semantic loss: 0.720270, BCE loss: 0.508067, SB loss: 0.697248
2023-10-30 21:19:10,350 Epoch: [377/484] Iter:[190/495], Time: 0.37, lr: [0.0025625946390176713], Loss: 1.928936, Acc:0.794825, Semantic loss: 0.721172, BCE loss: 0.510515, SB loss: 0.697250
2023-10-30 21:19:14,044 Epoch: [377/484] Iter:[200/495], Time: 0.37, lr: [0.0025621576220537156], Loss: 1.926232, Acc:0.794005, Semantic loss: 0.720415, BCE loss: 0.508449, SB loss: 0.697368
2023-10-30 21:19:17,662 Epoch: [377/484] Iter:[210/495], Time: 0.37, lr: [0.0025617205968073552], Loss: 1.928294, Acc:0.793999, Semantic loss: 0.719564, BCE loss: 0.512009, SB loss: 0.696721
2023-10-30 21:19:21,291 Epoch: [377/484] Iter:[220/495], Time: 0.37, lr: [0.002561283563276863], Loss: 1.923776, Acc:0.794874, Semantic loss: 0.717339, BCE loss: 0.510609, SB loss: 0.695829
2023-10-30 21:19:24,849 Epoch: [377/484] Iter:[230/495], Time: 0.37, lr: [0.002560846521460509], Loss: 1.925391, Acc:0.796083, Semantic loss: 0.717410, BCE loss: 0.511654, SB loss: 0.696327
2023-10-30 21:19:28,520 Epoch: [377/484] Iter:[240/495], Time: 0.37, lr: [0.002560409471356569], Loss: 1.924889, Acc:0.795651, Semantic loss: 0.718404, BCE loss: 0.510508, SB loss: 0.695977
2023-10-30 21:19:32,300 Epoch: [377/484] Iter:[250/495], Time: 0.37, lr: [0.0025599724129633113], Loss: 1.922521, Acc:0.796273, Semantic loss: 0.716748, BCE loss: 0.510460, SB loss: 0.695313
2023-10-30 21:19:35,886 Epoch: [377/484] Iter:[260/495], Time: 0.37, lr: [0.0025595353462790063], Loss: 1.928674, Acc:0.795911, Semantic loss: 0.719653, BCE loss: 0.513589, SB loss: 0.695432
2023-10-30 21:19:39,659 Epoch: [377/484] Iter:[270/495], Time: 0.37, lr: [0.002559098271301923], Loss: 1.928851, Acc:0.796401, Semantic loss: 0.720585, BCE loss: 0.512683, SB loss: 0.695583
2023-10-30 21:19:43,308 Epoch: [377/484] Iter:[280/495], Time: 0.37, lr: [0.0025586611880303325], Loss: 1.932373, Acc:0.797384, Semantic loss: 0.723545, BCE loss: 0.512424, SB loss: 0.696404
2023-10-30 21:19:46,939 Epoch: [377/484] Iter:[290/495], Time: 0.37, lr: [0.0025582240964625016], Loss: 1.930425, Acc:0.796962, Semantic loss: 0.722154, BCE loss: 0.511329, SB loss: 0.696942
2023-10-30 21:19:50,594 Epoch: [377/484] Iter:[300/495], Time: 0.37, lr: [0.002557786996596697], Loss: 1.926371, Acc:0.796072, Semantic loss: 0.721021, BCE loss: 0.508429, SB loss: 0.696921
2023-10-30 21:19:54,256 Epoch: [377/484] Iter:[310/495], Time: 0.37, lr: [0.0025573498884311863], Loss: 1.924224, Acc:0.795261, Semantic loss: 0.720522, BCE loss: 0.506435, SB loss: 0.697267
2023-10-30 21:19:57,865 Epoch: [377/484] Iter:[320/495], Time: 0.37, lr: [0.0025569127719642366], Loss: 1.925340, Acc:0.795469, Semantic loss: 0.720845, BCE loss: 0.506798, SB loss: 0.697696
2023-10-30 21:20:01,410 Epoch: [377/484] Iter:[330/495], Time: 0.37, lr: [0.002556475647194112], Loss: 1.923886, Acc:0.795385, Semantic loss: 0.720194, BCE loss: 0.506471, SB loss: 0.697222
2023-10-30 21:20:05,112 Epoch: [377/484] Iter:[340/495], Time: 0.37, lr: [0.0025560385141190777], Loss: 1.924376, Acc:0.795399, Semantic loss: 0.720607, BCE loss: 0.507095, SB loss: 0.696673
2023-10-30 21:20:08,727 Epoch: [377/484] Iter:[350/495], Time: 0.37, lr: [0.002555601372737397], Loss: 1.928004, Acc:0.795920, Semantic loss: 0.722204, BCE loss: 0.509008, SB loss: 0.696792
2023-10-30 21:20:12,586 Epoch: [377/484] Iter:[360/495], Time: 0.37, lr: [0.002555164223047335], Loss: 1.924440, Acc:0.796080, Semantic loss: 0.720131, BCE loss: 0.508563, SB loss: 0.695746
2023-10-30 21:20:16,323 Epoch: [377/484] Iter:[370/495], Time: 0.37, lr: [0.0025547270650471527], Loss: 1.924136, Acc:0.797138, Semantic loss: 0.719785, BCE loss: 0.508243, SB loss: 0.696108
2023-10-30 21:20:19,856 Epoch: [377/484] Iter:[380/495], Time: 0.37, lr: [0.002554289898735112], Loss: 1.924775, Acc:0.797544, Semantic loss: 0.719998, BCE loss: 0.508986, SB loss: 0.695790
2023-10-30 21:20:23,358 Epoch: [377/484] Iter:[390/495], Time: 0.37, lr: [0.002553852724109476], Loss: 1.923360, Acc:0.797103, Semantic loss: 0.719986, BCE loss: 0.507506, SB loss: 0.695868
2023-10-30 21:20:27,022 Epoch: [377/484] Iter:[400/495], Time: 0.37, lr: [0.002553415541168504], Loss: 1.920673, Acc:0.796574, Semantic loss: 0.719115, BCE loss: 0.506308, SB loss: 0.695250
2023-10-30 21:20:30,660 Epoch: [377/484] Iter:[410/495], Time: 0.37, lr: [0.0025529783499104557], Loss: 1.926154, Acc:0.797290, Semantic loss: 0.720687, BCE loss: 0.508075, SB loss: 0.697391
2023-10-30 21:20:34,396 Epoch: [377/484] Iter:[420/495], Time: 0.37, lr: [0.0025525411503335895], Loss: 1.927308, Acc:0.797337, Semantic loss: 0.720698, BCE loss: 0.509226, SB loss: 0.697384
2023-10-30 21:20:38,043 Epoch: [377/484] Iter:[430/495], Time: 0.37, lr: [0.0025521039424361664], Loss: 1.929325, Acc:0.798027, Semantic loss: 0.721527, BCE loss: 0.510143, SB loss: 0.697655
2023-10-30 21:20:41,665 Epoch: [377/484] Iter:[440/495], Time: 0.37, lr: [0.002551666726216442], Loss: 1.929994, Acc:0.798525, Semantic loss: 0.721504, BCE loss: 0.510709, SB loss: 0.697780
2023-10-30 21:20:45,235 Epoch: [377/484] Iter:[450/495], Time: 0.37, lr: [0.002551229501672675], Loss: 1.932917, Acc:0.798318, Semantic loss: 0.723433, BCE loss: 0.511166, SB loss: 0.698318
2023-10-30 21:20:48,864 Epoch: [377/484] Iter:[460/495], Time: 0.37, lr: [0.0025507922688031187], Loss: 1.933087, Acc:0.797689, Semantic loss: 0.724951, BCE loss: 0.509966, SB loss: 0.698170
2023-10-30 21:20:52,552 Epoch: [377/484] Iter:[470/495], Time: 0.37, lr: [0.002550355027606033], Loss: 1.931700, Acc:0.797772, Semantic loss: 0.724588, BCE loss: 0.508803, SB loss: 0.698309
2023-10-30 21:20:56,273 Epoch: [377/484] Iter:[480/495], Time: 0.37, lr: [0.0025499177780796706], Loss: 1.931213, Acc:0.798239, Semantic loss: 0.724311, BCE loss: 0.508857, SB loss: 0.698045
2023-10-30 21:20:59,658 Epoch: [377/484] Iter:[490/495], Time: 0.37, lr: [0.0025494805202222865], Loss: 1.930138, Acc:0.798562, Semantic loss: 0.723505, BCE loss: 0.509484, SB loss: 0.697149
2023-10-30 21:21:01,050 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:21:01,295 Loss: 2.031, MeanIU:  0.6833, Best_mIoU:  0.7487
2023-10-30 21:21:01,295 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617]
2023-10-30 21:21:03,233 Epoch: [378/484] Iter:[0/495], Time: 1.90, lr: [0.002549261888168915], Loss: 1.814333, Acc:0.700514, Semantic loss: 0.708107, BCE loss: 0.445758, SB loss: 0.660468
2023-10-30 21:21:07,270 Epoch: [378/484] Iter:[10/495], Time: 0.54, lr: [0.0025488246178117214], Loss: 1.919013, Acc:0.802460, Semantic loss: 0.705932, BCE loss: 0.523251, SB loss: 0.689830
2023-10-30 21:21:11,009 Epoch: [378/484] Iter:[20/495], Time: 0.46, lr: [0.00254838733911914], Loss: 1.985194, Acc:0.796025, Semantic loss: 0.762167, BCE loss: 0.517339, SB loss: 0.705689
2023-10-30 21:21:14,577 Epoch: [378/484] Iter:[30/495], Time: 0.43, lr: [0.0025479500520894207], Loss: 1.954457, Acc:0.811513, Semantic loss: 0.748158, BCE loss: 0.508984, SB loss: 0.697315
2023-10-30 21:21:18,171 Epoch: [378/484] Iter:[40/495], Time: 0.41, lr: [0.002547512756720815], Loss: 1.971023, Acc:0.811159, Semantic loss: 0.760883, BCE loss: 0.511603, SB loss: 0.698537
2023-10-30 21:21:21,771 Epoch: [378/484] Iter:[50/495], Time: 0.40, lr: [0.0025470754530115725], Loss: 1.963598, Acc:0.808967, Semantic loss: 0.756414, BCE loss: 0.505760, SB loss: 0.701424
2023-10-30 21:21:25,350 Epoch: [378/484] Iter:[60/495], Time: 0.39, lr: [0.002546638140959945], Loss: 1.942416, Acc:0.810831, Semantic loss: 0.738156, BCE loss: 0.506560, SB loss: 0.697701
2023-10-30 21:21:29,010 Epoch: [378/484] Iter:[70/495], Time: 0.39, lr: [0.0025462008205641797], Loss: 1.957135, Acc:0.814157, Semantic loss: 0.733280, BCE loss: 0.527489, SB loss: 0.696366
2023-10-30 21:21:32,652 Epoch: [378/484] Iter:[80/495], Time: 0.39, lr: [0.002545763491822526], Loss: 1.942882, Acc:0.810257, Semantic loss: 0.724534, BCE loss: 0.526282, SB loss: 0.692065
2023-10-30 21:21:36,374 Epoch: [378/484] Iter:[90/495], Time: 0.39, lr: [0.0025453261547332302], Loss: 1.945838, Acc:0.809156, Semantic loss: 0.725599, BCE loss: 0.524509, SB loss: 0.695730
2023-10-30 21:21:40,031 Epoch: [378/484] Iter:[100/495], Time: 0.38, lr: [0.0025448888092945415], Loss: 1.942932, Acc:0.809941, Semantic loss: 0.721599, BCE loss: 0.527507, SB loss: 0.693826
2023-10-30 21:21:43,704 Epoch: [378/484] Iter:[110/495], Time: 0.38, lr: [0.0025444514555047044], Loss: 1.947404, Acc:0.810313, Semantic loss: 0.724855, BCE loss: 0.529039, SB loss: 0.693510
2023-10-30 21:21:47,337 Epoch: [378/484] Iter:[120/495], Time: 0.38, lr: [0.0025440140933619656], Loss: 1.950482, Acc:0.809511, Semantic loss: 0.723280, BCE loss: 0.533916, SB loss: 0.693286
2023-10-30 21:21:50,911 Epoch: [378/484] Iter:[130/495], Time: 0.38, lr: [0.0025435767228645673], Loss: 1.957193, Acc:0.810369, Semantic loss: 0.724093, BCE loss: 0.539209, SB loss: 0.693891
2023-10-30 21:21:54,561 Epoch: [378/484] Iter:[140/495], Time: 0.38, lr: [0.0025431393440107576], Loss: 1.953859, Acc:0.808544, Semantic loss: 0.724301, BCE loss: 0.536346, SB loss: 0.693211
2023-10-30 21:21:58,224 Epoch: [378/484] Iter:[150/495], Time: 0.38, lr: [0.002542701956798777], Loss: 1.948804, Acc:0.807942, Semantic loss: 0.722946, BCE loss: 0.532397, SB loss: 0.693461
2023-10-30 21:22:01,872 Epoch: [378/484] Iter:[160/495], Time: 0.38, lr: [0.0025422645612268695], Loss: 1.940191, Acc:0.808073, Semantic loss: 0.721258, BCE loss: 0.527793, SB loss: 0.691139
2023-10-30 21:22:05,530 Epoch: [378/484] Iter:[170/495], Time: 0.38, lr: [0.002541827157293276], Loss: 1.938197, Acc:0.808761, Semantic loss: 0.719266, BCE loss: 0.527656, SB loss: 0.691274
2023-10-30 21:22:09,176 Epoch: [378/484] Iter:[180/495], Time: 0.37, lr: [0.0025413897449962394], Loss: 1.953242, Acc:0.810048, Semantic loss: 0.732406, BCE loss: 0.527655, SB loss: 0.693181
2023-10-30 21:22:12,876 Epoch: [378/484] Iter:[190/495], Time: 0.37, lr: [0.0025409523243339993], Loss: 1.953329, Acc:0.810691, Semantic loss: 0.728858, BCE loss: 0.531506, SB loss: 0.692965
2023-10-30 21:22:16,519 Epoch: [378/484] Iter:[200/495], Time: 0.37, lr: [0.0025405148953047945], Loss: 1.955202, Acc:0.810854, Semantic loss: 0.730281, BCE loss: 0.531439, SB loss: 0.693481
2023-10-30 21:22:20,213 Epoch: [378/484] Iter:[210/495], Time: 0.37, lr: [0.002540077457906867], Loss: 1.955486, Acc:0.811569, Semantic loss: 0.729172, BCE loss: 0.533021, SB loss: 0.693292
2023-10-30 21:22:23,879 Epoch: [378/484] Iter:[220/495], Time: 0.37, lr: [0.002539640012138454], Loss: 1.955716, Acc:0.811434, Semantic loss: 0.731428, BCE loss: 0.530825, SB loss: 0.693463
2023-10-30 21:22:27,522 Epoch: [378/484] Iter:[230/495], Time: 0.37, lr: [0.0025392025579977925], Loss: 1.957780, Acc:0.809711, Semantic loss: 0.733194, BCE loss: 0.530253, SB loss: 0.694334
2023-10-30 21:22:31,161 Epoch: [378/484] Iter:[240/495], Time: 0.37, lr: [0.002538765095483119], Loss: 1.961368, Acc:0.809468, Semantic loss: 0.734654, BCE loss: 0.531309, SB loss: 0.695404
2023-10-30 21:22:34,816 Epoch: [378/484] Iter:[250/495], Time: 0.37, lr: [0.002538327624592672], Loss: 1.967641, Acc:0.807381, Semantic loss: 0.737881, BCE loss: 0.532844, SB loss: 0.696917
2023-10-30 21:22:38,565 Epoch: [378/484] Iter:[260/495], Time: 0.37, lr: [0.002537890145324686], Loss: 1.969319, Acc:0.808813, Semantic loss: 0.736715, BCE loss: 0.535150, SB loss: 0.697454
2023-10-30 21:22:42,144 Epoch: [378/484] Iter:[270/495], Time: 0.37, lr: [0.002537452657677396], Loss: 1.972221, Acc:0.810194, Semantic loss: 0.740011, BCE loss: 0.534458, SB loss: 0.697753
2023-10-30 21:22:45,855 Epoch: [378/484] Iter:[280/495], Time: 0.37, lr: [0.0025370151616490354], Loss: 1.967423, Acc:0.808867, Semantic loss: 0.738928, BCE loss: 0.531145, SB loss: 0.697351
2023-10-30 21:22:49,586 Epoch: [378/484] Iter:[290/495], Time: 0.37, lr: [0.0025365776572378396], Loss: 1.965879, Acc:0.809768, Semantic loss: 0.737569, BCE loss: 0.530743, SB loss: 0.697567
2023-10-30 21:22:53,294 Epoch: [378/484] Iter:[300/495], Time: 0.37, lr: [0.0025361401444420405], Loss: 1.965131, Acc:0.808949, Semantic loss: 0.736915, BCE loss: 0.530296, SB loss: 0.697920
2023-10-30 21:22:56,992 Epoch: [378/484] Iter:[310/495], Time: 0.37, lr: [0.0025357026232598703], Loss: 1.964955, Acc:0.809413, Semantic loss: 0.736320, BCE loss: 0.530644, SB loss: 0.697991
2023-10-30 21:23:00,685 Epoch: [378/484] Iter:[320/495], Time: 0.37, lr: [0.002535265093689559], Loss: 1.964511, Acc:0.808795, Semantic loss: 0.736735, BCE loss: 0.530003, SB loss: 0.697774
2023-10-30 21:23:04,307 Epoch: [378/484] Iter:[330/495], Time: 0.37, lr: [0.0025348275557293388], Loss: 1.966073, Acc:0.809822, Semantic loss: 0.737359, BCE loss: 0.530610, SB loss: 0.698104
2023-10-30 21:23:08,010 Epoch: [378/484] Iter:[340/495], Time: 0.37, lr: [0.00253439000937744], Loss: 1.965270, Acc:0.808283, Semantic loss: 0.737611, BCE loss: 0.529057, SB loss: 0.698601
2023-10-30 21:23:11,611 Epoch: [378/484] Iter:[350/495], Time: 0.37, lr: [0.002533952454632091], Loss: 1.967761, Acc:0.809044, Semantic loss: 0.738480, BCE loss: 0.529824, SB loss: 0.699458
2023-10-30 21:23:15,214 Epoch: [378/484] Iter:[360/495], Time: 0.37, lr: [0.0025335148914915192], Loss: 1.969626, Acc:0.809562, Semantic loss: 0.738530, BCE loss: 0.532256, SB loss: 0.698840
2023-10-30 21:23:18,818 Epoch: [378/484] Iter:[370/495], Time: 0.37, lr: [0.0025330773199539547], Loss: 1.968253, Acc:0.808325, Semantic loss: 0.738140, BCE loss: 0.532211, SB loss: 0.697902
2023-10-30 21:23:22,351 Epoch: [378/484] Iter:[380/495], Time: 0.37, lr: [0.002532639740017624], Loss: 1.967381, Acc:0.808007, Semantic loss: 0.737958, BCE loss: 0.531056, SB loss: 0.698368
2023-10-30 21:23:25,954 Epoch: [378/484] Iter:[390/495], Time: 0.37, lr: [0.002532202151680753], Loss: 1.965076, Acc:0.808859, Semantic loss: 0.736372, BCE loss: 0.530970, SB loss: 0.697734
2023-10-30 21:23:29,525 Epoch: [378/484] Iter:[400/495], Time: 0.37, lr: [0.0025317645549415664], Loss: 1.962855, Acc:0.809239, Semantic loss: 0.734806, BCE loss: 0.530216, SB loss: 0.697833
2023-10-30 21:23:33,312 Epoch: [378/484] Iter:[410/495], Time: 0.37, lr: [0.002531326949798291], Loss: 1.963415, Acc:0.808833, Semantic loss: 0.735254, BCE loss: 0.529595, SB loss: 0.698566
2023-10-30 21:23:36,960 Epoch: [378/484] Iter:[420/495], Time: 0.37, lr: [0.00253088933624915], Loss: 1.961008, Acc:0.809062, Semantic loss: 0.733516, BCE loss: 0.528722, SB loss: 0.698770
2023-10-30 21:23:40,559 Epoch: [378/484] Iter:[430/495], Time: 0.37, lr: [0.0025304517142923683], Loss: 1.964545, Acc:0.809383, Semantic loss: 0.734957, BCE loss: 0.529232, SB loss: 0.700356
2023-10-30 21:23:44,210 Epoch: [378/484] Iter:[440/495], Time: 0.37, lr: [0.002530014083926166], Loss: 1.963935, Acc:0.809872, Semantic loss: 0.733872, BCE loss: 0.530067, SB loss: 0.699997
2023-10-30 21:23:47,805 Epoch: [378/484] Iter:[450/495], Time: 0.37, lr: [0.002529576445148767], Loss: 1.961628, Acc:0.809381, Semantic loss: 0.733689, BCE loss: 0.528742, SB loss: 0.699197
2023-10-30 21:23:51,386 Epoch: [378/484] Iter:[460/495], Time: 0.37, lr: [0.002529138797958394], Loss: 1.960406, Acc:0.808733, Semantic loss: 0.733267, BCE loss: 0.528055, SB loss: 0.699084
2023-10-30 21:23:55,171 Epoch: [378/484] Iter:[470/495], Time: 0.37, lr: [0.0025287011423532654], Loss: 1.958865, Acc:0.808217, Semantic loss: 0.732946, BCE loss: 0.527088, SB loss: 0.698831
2023-10-30 21:23:58,899 Epoch: [378/484] Iter:[480/495], Time: 0.37, lr: [0.0025282634783316007], Loss: 1.959859, Acc:0.808354, Semantic loss: 0.732825, BCE loss: 0.528544, SB loss: 0.698490
2023-10-30 21:24:02,380 Epoch: [378/484] Iter:[490/495], Time: 0.37, lr: [0.0025278258058916213], Loss: 1.955322, Acc:0.807923, Semantic loss: 0.731085, BCE loss: 0.527002, SB loss: 0.697235
2023-10-30 21:24:03,751 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:24:03,991 Loss: 2.031, MeanIU:  0.6833, Best_mIoU:  0.7487
2023-10-30 21:24:03,991 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617]
2023-10-30 21:24:05,950 Epoch: [379/484] Iter:[0/495], Time: 1.93, lr: [0.0025276069665142067], Loss: 1.444073, Acc:0.737160, Semantic loss: 0.561825, BCE loss: 0.273075, SB loss: 0.609172
2023-10-30 21:24:09,931 Epoch: [379/484] Iter:[10/495], Time: 0.54, lr: [0.0025271692814434134], Loss: 1.914256, Acc:0.803767, Semantic loss: 0.729888, BCE loss: 0.499898, SB loss: 0.684470
2023-10-30 21:24:13,669 Epoch: [379/484] Iter:[20/495], Time: 0.46, lr: [0.0025267315879498493], Loss: 1.987827, Acc:0.810771, Semantic loss: 0.762870, BCE loss: 0.524830, SB loss: 0.700126
2023-10-30 21:24:17,299 Epoch: [379/484] Iter:[30/495], Time: 0.43, lr: [0.0025262938860317295], Loss: 1.954183, Acc:0.817044, Semantic loss: 0.727957, BCE loss: 0.531873, SB loss: 0.694353
2023-10-30 21:24:20,898 Epoch: [379/484] Iter:[40/495], Time: 0.41, lr: [0.0025258561756872733], Loss: 1.922471, Acc:0.814394, Semantic loss: 0.713581, BCE loss: 0.518733, SB loss: 0.690156
2023-10-30 21:24:24,637 Epoch: [379/484] Iter:[50/495], Time: 0.40, lr: [0.002525418456914694], Loss: 1.909182, Acc:0.810853, Semantic loss: 0.707952, BCE loss: 0.516470, SB loss: 0.684760
2023-10-30 21:24:28,242 Epoch: [379/484] Iter:[60/495], Time: 0.40, lr: [0.0025249807297122056], Loss: 1.931575, Acc:0.810183, Semantic loss: 0.716377, BCE loss: 0.524648, SB loss: 0.690549
2023-10-30 21:24:31,837 Epoch: [379/484] Iter:[70/495], Time: 0.39, lr: [0.0025245429940780233], Loss: 1.926630, Acc:0.806121, Semantic loss: 0.716695, BCE loss: 0.519945, SB loss: 0.689989
2023-10-30 21:24:35,640 Epoch: [379/484] Iter:[80/495], Time: 0.39, lr: [0.00252410525001036], Loss: 1.931172, Acc:0.801763, Semantic loss: 0.717809, BCE loss: 0.521288, SB loss: 0.692075
2023-10-30 21:24:39,418 Epoch: [379/484] Iter:[90/495], Time: 0.39, lr: [0.0025236674975074275], Loss: 1.938978, Acc:0.803169, Semantic loss: 0.719117, BCE loss: 0.524464, SB loss: 0.695396
2023-10-30 21:24:43,015 Epoch: [379/484] Iter:[100/495], Time: 0.39, lr: [0.002523229736567436], Loss: 1.944590, Acc:0.805032, Semantic loss: 0.722300, BCE loss: 0.524323, SB loss: 0.697967
2023-10-30 21:24:46,667 Epoch: [379/484] Iter:[110/495], Time: 0.38, lr: [0.0025227919671885995], Loss: 1.937196, Acc:0.806511, Semantic loss: 0.717305, BCE loss: 0.526260, SB loss: 0.693630
2023-10-30 21:24:50,285 Epoch: [379/484] Iter:[120/495], Time: 0.38, lr: [0.0025223541893691272], Loss: 1.937749, Acc:0.804165, Semantic loss: 0.719926, BCE loss: 0.522615, SB loss: 0.695208
2023-10-30 21:24:53,871 Epoch: [379/484] Iter:[130/495], Time: 0.38, lr: [0.002521916403107227], Loss: 1.924022, Acc:0.802936, Semantic loss: 0.715847, BCE loss: 0.514714, SB loss: 0.693462
2023-10-30 21:24:57,470 Epoch: [379/484] Iter:[140/495], Time: 0.38, lr: [0.0025214786084011083], Loss: 1.943110, Acc:0.801823, Semantic loss: 0.731500, BCE loss: 0.517087, SB loss: 0.694523
2023-10-30 21:25:01,113 Epoch: [379/484] Iter:[150/495], Time: 0.38, lr: [0.0025210408052489803], Loss: 1.943922, Acc:0.802608, Semantic loss: 0.731727, BCE loss: 0.517125, SB loss: 0.695070
2023-10-30 21:25:04,820 Epoch: [379/484] Iter:[160/495], Time: 0.38, lr: [0.00252060299364905], Loss: 1.945711, Acc:0.804543, Semantic loss: 0.733159, BCE loss: 0.515157, SB loss: 0.697395
2023-10-30 21:25:08,487 Epoch: [379/484] Iter:[170/495], Time: 0.38, lr: [0.0025201651735995228], Loss: 1.943466, Acc:0.806355, Semantic loss: 0.731413, BCE loss: 0.515799, SB loss: 0.696254
2023-10-30 21:25:12,274 Epoch: [379/484] Iter:[180/495], Time: 0.38, lr: [0.002519727345098605], Loss: 1.945176, Acc:0.807178, Semantic loss: 0.732033, BCE loss: 0.517386, SB loss: 0.695756
2023-10-30 21:25:15,866 Epoch: [379/484] Iter:[190/495], Time: 0.38, lr: [0.0025192895081445022], Loss: 1.947280, Acc:0.805397, Semantic loss: 0.732426, BCE loss: 0.517830, SB loss: 0.697025
2023-10-30 21:25:19,512 Epoch: [379/484] Iter:[200/495], Time: 0.38, lr: [0.002518851662735419], Loss: 1.946662, Acc:0.804864, Semantic loss: 0.732797, BCE loss: 0.518639, SB loss: 0.695225
2023-10-30 21:25:23,093 Epoch: [379/484] Iter:[210/495], Time: 0.37, lr: [0.0025184138088695583], Loss: 1.943697, Acc:0.804790, Semantic loss: 0.731394, BCE loss: 0.517558, SB loss: 0.694745
2023-10-30 21:25:26,693 Epoch: [379/484] Iter:[220/495], Time: 0.37, lr: [0.0025179759465451222], Loss: 1.937847, Acc:0.804412, Semantic loss: 0.728669, BCE loss: 0.515830, SB loss: 0.693347
2023-10-30 21:25:30,256 Epoch: [379/484] Iter:[230/495], Time: 0.37, lr: [0.0025175380757603157], Loss: 1.941774, Acc:0.805584, Semantic loss: 0.729783, BCE loss: 0.517659, SB loss: 0.694333
2023-10-30 21:25:33,905 Epoch: [379/484] Iter:[240/495], Time: 0.37, lr: [0.002517100196513338], Loss: 1.946833, Acc:0.805292, Semantic loss: 0.732209, BCE loss: 0.519726, SB loss: 0.694898
2023-10-30 21:25:37,602 Epoch: [379/484] Iter:[250/495], Time: 0.37, lr: [0.002516662308802391], Loss: 1.953941, Acc:0.806023, Semantic loss: 0.734973, BCE loss: 0.521322, SB loss: 0.697647
2023-10-30 21:25:41,324 Epoch: [379/484] Iter:[260/495], Time: 0.37, lr: [0.0025162244126256724], Loss: 1.951573, Acc:0.807939, Semantic loss: 0.732851, BCE loss: 0.521366, SB loss: 0.697356
2023-10-30 21:25:45,130 Epoch: [379/484] Iter:[270/495], Time: 0.37, lr: [0.0025157865079813847], Loss: 1.952256, Acc:0.807057, Semantic loss: 0.733512, BCE loss: 0.521307, SB loss: 0.697437
2023-10-30 21:25:48,833 Epoch: [379/484] Iter:[280/495], Time: 0.37, lr: [0.0025153485948677247], Loss: 1.953244, Acc:0.807983, Semantic loss: 0.734223, BCE loss: 0.521577, SB loss: 0.697444
2023-10-30 21:25:52,516 Epoch: [379/484] Iter:[290/495], Time: 0.37, lr: [0.002514910673282891], Loss: 1.951589, Acc:0.807217, Semantic loss: 0.732955, BCE loss: 0.521022, SB loss: 0.697612
2023-10-30 21:25:56,153 Epoch: [379/484] Iter:[300/495], Time: 0.37, lr: [0.002514472743225078], Loss: 1.952943, Acc:0.806966, Semantic loss: 0.733282, BCE loss: 0.521276, SB loss: 0.698385
2023-10-30 21:25:59,808 Epoch: [379/484] Iter:[310/495], Time: 0.37, lr: [0.002514034804692486], Loss: 1.948259, Acc:0.806031, Semantic loss: 0.731377, BCE loss: 0.519088, SB loss: 0.697794
2023-10-30 21:26:03,403 Epoch: [379/484] Iter:[320/495], Time: 0.37, lr: [0.0025135968576833084], Loss: 1.947609, Acc:0.807096, Semantic loss: 0.732658, BCE loss: 0.517739, SB loss: 0.697212
2023-10-30 21:26:07,111 Epoch: [379/484] Iter:[330/495], Time: 0.37, lr: [0.0025131589021957414], Loss: 1.949922, Acc:0.807856, Semantic loss: 0.732955, BCE loss: 0.519692, SB loss: 0.697275
2023-10-30 21:26:10,682 Epoch: [379/484] Iter:[340/495], Time: 0.37, lr: [0.0025127209382279766], Loss: 1.949820, Acc:0.808755, Semantic loss: 0.732641, BCE loss: 0.520372, SB loss: 0.696807
2023-10-30 21:26:14,290 Epoch: [379/484] Iter:[350/495], Time: 0.37, lr: [0.00251228296577821], Loss: 1.949123, Acc:0.808073, Semantic loss: 0.732034, BCE loss: 0.520500, SB loss: 0.696589
2023-10-30 21:26:17,905 Epoch: [379/484] Iter:[360/495], Time: 0.37, lr: [0.0025118449848446334], Loss: 1.947628, Acc:0.807623, Semantic loss: 0.731043, BCE loss: 0.520096, SB loss: 0.696490
2023-10-30 21:26:21,465 Epoch: [379/484] Iter:[370/495], Time: 0.37, lr: [0.0025114069954254386], Loss: 1.945922, Acc:0.808553, Semantic loss: 0.729389, BCE loss: 0.520373, SB loss: 0.696160
2023-10-30 21:26:25,188 Epoch: [379/484] Iter:[380/495], Time: 0.37, lr: [0.0025109689975188155], Loss: 1.945519, Acc:0.807700, Semantic loss: 0.729125, BCE loss: 0.520112, SB loss: 0.696281
2023-10-30 21:26:28,779 Epoch: [379/484] Iter:[390/495], Time: 0.37, lr: [0.002510530991122958], Loss: 1.945172, Acc:0.808188, Semantic loss: 0.729179, BCE loss: 0.519593, SB loss: 0.696401
2023-10-30 21:26:32,440 Epoch: [379/484] Iter:[400/495], Time: 0.37, lr: [0.002510092976236053], Loss: 1.939989, Acc:0.807153, Semantic loss: 0.726906, BCE loss: 0.518070, SB loss: 0.695013
2023-10-30 21:26:36,109 Epoch: [379/484] Iter:[410/495], Time: 0.37, lr: [0.0025096549528562904], Loss: 1.937850, Acc:0.807574, Semantic loss: 0.726138, BCE loss: 0.516747, SB loss: 0.694965
2023-10-30 21:26:39,703 Epoch: [379/484] Iter:[420/495], Time: 0.37, lr: [0.002509216920981858], Loss: 1.936187, Acc:0.807324, Semantic loss: 0.726321, BCE loss: 0.514909, SB loss: 0.694957
2023-10-30 21:26:43,371 Epoch: [379/484] Iter:[430/495], Time: 0.37, lr: [0.0025087788806109437], Loss: 1.937388, Acc:0.807219, Semantic loss: 0.727263, BCE loss: 0.514831, SB loss: 0.695293
2023-10-30 21:26:47,075 Epoch: [379/484] Iter:[440/495], Time: 0.37, lr: [0.002508340831741735], Loss: 1.941294, Acc:0.807981, Semantic loss: 0.728696, BCE loss: 0.517388, SB loss: 0.695210
2023-10-30 21:26:50,617 Epoch: [379/484] Iter:[450/495], Time: 0.37, lr: [0.002507902774372417], Loss: 1.939247, Acc:0.807770, Semantic loss: 0.728563, BCE loss: 0.515814, SB loss: 0.694870
2023-10-30 21:26:54,388 Epoch: [379/484] Iter:[460/495], Time: 0.37, lr: [0.0025074647085011736], Loss: 1.939990, Acc:0.807889, Semantic loss: 0.728889, BCE loss: 0.515948, SB loss: 0.695153
2023-10-30 21:26:57,992 Epoch: [379/484] Iter:[470/495], Time: 0.37, lr: [0.002507026634126193], Loss: 1.938778, Acc:0.807887, Semantic loss: 0.728095, BCE loss: 0.515622, SB loss: 0.695060
2023-10-30 21:27:01,655 Epoch: [379/484] Iter:[480/495], Time: 0.37, lr: [0.002506588551245656], Loss: 1.937244, Acc:0.808230, Semantic loss: 0.726888, BCE loss: 0.516076, SB loss: 0.694280
2023-10-30 21:27:05,139 Epoch: [379/484] Iter:[490/495], Time: 0.37, lr: [0.0025061504598577473], Loss: 1.935837, Acc:0.807614, Semantic loss: 0.726120, BCE loss: 0.515803, SB loss: 0.693914
2023-10-30 21:27:06,511 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:27:06,744 Loss: 2.031, MeanIU:  0.6833, Best_mIoU:  0.7487
2023-10-30 21:27:06,744 [0.97654819 0.82181311 0.91213002 0.47002746 0.56813034 0.60719563
 0.66279698 0.74902728 0.91812165 0.62689863 0.93823518 0.77504947
 0.55052914 0.91025942 0.4682246  0.6296902  0.17739169 0.49021616
 0.73003617]
2023-10-30 21:27:08,952 Epoch: [380/484] Iter:[0/495], Time: 2.17, lr: [0.002505931410972959], Loss: 1.937709, Acc:0.783597, Semantic loss: 0.788057, BCE loss: 0.468140, SB loss: 0.681512
2023-10-30 21:27:12,812 Epoch: [380/484] Iter:[10/495], Time: 0.55, lr: [0.002505493306820584], Loss: 1.955249, Acc:0.777242, Semantic loss: 0.749264, BCE loss: 0.517462, SB loss: 0.688524
2023-10-30 21:27:16,452 Epoch: [380/484] Iter:[20/495], Time: 0.46, lr: [0.0025050551941562904], Loss: 1.940824, Acc:0.780702, Semantic loss: 0.740587, BCE loss: 0.518053, SB loss: 0.682184
2023-10-30 21:27:20,054 Epoch: [380/484] Iter:[30/495], Time: 0.43, lr: [0.0025046170729782595], Loss: 1.904849, Acc:0.787657, Semantic loss: 0.726936, BCE loss: 0.496919, SB loss: 0.680993
2023-10-30 21:27:23,736 Epoch: [380/484] Iter:[40/495], Time: 0.41, lr: [0.00250417894328467], Loss: 1.877560, Acc:0.792280, Semantic loss: 0.703838, BCE loss: 0.496032, SB loss: 0.677690
2023-10-30 21:27:27,334 Epoch: [380/484] Iter:[50/495], Time: 0.40, lr: [0.002503740805073703], Loss: 1.895010, Acc:0.799626, Semantic loss: 0.708081, BCE loss: 0.505817, SB loss: 0.681112
2023-10-30 21:27:30,888 Epoch: [380/484] Iter:[60/495], Time: 0.40, lr: [0.0025033026583435357], Loss: 1.899714, Acc:0.805037, Semantic loss: 0.706878, BCE loss: 0.511006, SB loss: 0.681830
2023-10-30 21:27:34,618 Epoch: [380/484] Iter:[70/495], Time: 0.39, lr: [0.0025028645030923456], Loss: 1.890015, Acc:0.800572, Semantic loss: 0.702456, BCE loss: 0.507304, SB loss: 0.680256
2023-10-30 21:27:38,221 Epoch: [380/484] Iter:[80/495], Time: 0.39, lr: [0.002502426339318308], Loss: 1.908662, Acc:0.804226, Semantic loss: 0.711258, BCE loss: 0.514000, SB loss: 0.683404
2023-10-30 21:27:41,816 Epoch: [380/484] Iter:[90/495], Time: 0.39, lr: [0.0025019881670196023], Loss: 1.904355, Acc:0.804438, Semantic loss: 0.708163, BCE loss: 0.513499, SB loss: 0.682692
2023-10-30 21:27:45,550 Epoch: [380/484] Iter:[100/495], Time: 0.38, lr: [0.0025015499861944014], Loss: 1.901831, Acc:0.803633, Semantic loss: 0.708942, BCE loss: 0.509973, SB loss: 0.682916
2023-10-30 21:27:49,143 Epoch: [380/484] Iter:[110/495], Time: 0.38, lr: [0.0025011117968408805], Loss: 1.913707, Acc:0.805485, Semantic loss: 0.723332, BCE loss: 0.509375, SB loss: 0.681000
2023-10-30 21:27:52,701 Epoch: [380/484] Iter:[120/495], Time: 0.38, lr: [0.0025006735989572117], Loss: 1.918513, Acc:0.803741, Semantic loss: 0.723392, BCE loss: 0.511983, SB loss: 0.683137
2023-10-30 21:27:56,331 Epoch: [380/484] Iter:[130/495], Time: 0.38, lr: [0.0025002353925415704], Loss: 1.924952, Acc:0.804873, Semantic loss: 0.722313, BCE loss: 0.515741, SB loss: 0.686897
2023-10-30 21:28:00,008 Epoch: [380/484] Iter:[140/495], Time: 0.38, lr: [0.0024997971775921287], Loss: 1.917898, Acc:0.804974, Semantic loss: 0.720252, BCE loss: 0.511157, SB loss: 0.686489
2023-10-30 21:28:03,707 Epoch: [380/484] Iter:[150/495], Time: 0.38, lr: [0.002499358954107057], Loss: 1.918979, Acc:0.807005, Semantic loss: 0.719660, BCE loss: 0.513433, SB loss: 0.685886
2023-10-30 21:28:07,344 Epoch: [380/484] Iter:[160/495], Time: 0.38, lr: [0.0024989207220845254], Loss: 1.921710, Acc:0.804873, Semantic loss: 0.720632, BCE loss: 0.515692, SB loss: 0.685386
2023-10-30 21:28:10,970 Epoch: [380/484] Iter:[170/495], Time: 0.38, lr: [0.0024984824815227065], Loss: 1.928823, Acc:0.805777, Semantic loss: 0.724189, BCE loss: 0.516021, SB loss: 0.688613
2023-10-30 21:28:14,647 Epoch: [380/484] Iter:[180/495], Time: 0.37, lr: [0.0024980442324197684], Loss: 1.932663, Acc:0.804326, Semantic loss: 0.727219, BCE loss: 0.514194, SB loss: 0.691250
2023-10-30 21:28:18,290 Epoch: [380/484] Iter:[190/495], Time: 0.37, lr: [0.002497605974773879], Loss: 1.926937, Acc:0.803435, Semantic loss: 0.725241, BCE loss: 0.510799, SB loss: 0.690897
2023-10-30 21:28:21,927 Epoch: [380/484] Iter:[200/495], Time: 0.37, lr: [0.002497167708583206], Loss: 1.930734, Acc:0.802086, Semantic loss: 0.726675, BCE loss: 0.511126, SB loss: 0.692933
2023-10-30 21:28:25,623 Epoch: [380/484] Iter:[210/495], Time: 0.37, lr: [0.0024967294338459176], Loss: 1.939402, Acc:0.801022, Semantic loss: 0.733919, BCE loss: 0.510493, SB loss: 0.694990
2023-10-30 21:28:29,347 Epoch: [380/484] Iter:[220/495], Time: 0.37, lr: [0.0024962911505601796], Loss: 1.945206, Acc:0.801700, Semantic loss: 0.734983, BCE loss: 0.513163, SB loss: 0.697060
2023-10-30 21:28:32,922 Epoch: [380/484] Iter:[230/495], Time: 0.37, lr: [0.002495852858724158], Loss: 1.946917, Acc:0.801645, Semantic loss: 0.736238, BCE loss: 0.512123, SB loss: 0.698556
2023-10-30 21:28:36,502 Epoch: [380/484] Iter:[240/495], Time: 0.37, lr: [0.0024954145583360155], Loss: 1.951802, Acc:0.800033, Semantic loss: 0.740324, BCE loss: 0.511396, SB loss: 0.700082
2023-10-30 21:28:40,127 Epoch: [380/484] Iter:[250/495], Time: 0.37, lr: [0.002494976249393919], Loss: 1.945863, Acc:0.800581, Semantic loss: 0.737600, BCE loss: 0.509037, SB loss: 0.699226
2023-10-30 21:28:43,689 Epoch: [380/484] Iter:[260/495], Time: 0.37, lr: [0.0024945379318960306], Loss: 1.947410, Acc:0.801246, Semantic loss: 0.737321, BCE loss: 0.510694, SB loss: 0.699396
2023-10-30 21:28:47,248 Epoch: [380/484] Iter:[270/495], Time: 0.37, lr: [0.002494099605840513], Loss: 1.947790, Acc:0.800849, Semantic loss: 0.737989, BCE loss: 0.510719, SB loss: 0.699083
2023-10-30 21:28:51,065 Epoch: [380/484] Iter:[280/495], Time: 0.37, lr: [0.002493661271225526], Loss: 1.945885, Acc:0.801195, Semantic loss: 0.737161, BCE loss: 0.510006, SB loss: 0.698718
2023-10-30 21:28:54,730 Epoch: [380/484] Iter:[290/495], Time: 0.37, lr: [0.002493222928049234], Loss: 1.949576, Acc:0.800741, Semantic loss: 0.739296, BCE loss: 0.510479, SB loss: 0.699801
2023-10-30 21:28:58,360 Epoch: [380/484] Iter:[300/495], Time: 0.37, lr: [0.0024927845763097955], Loss: 1.947624, Acc:0.800786, Semantic loss: 0.738652, BCE loss: 0.508765, SB loss: 0.700206
2023-10-30 21:29:01,977 Epoch: [380/484] Iter:[310/495], Time: 0.37, lr: [0.00249234621600537], Loss: 1.945729, Acc:0.799831, Semantic loss: 0.737689, BCE loss: 0.508192, SB loss: 0.699848
2023-10-30 21:29:05,591 Epoch: [380/484] Iter:[320/495], Time: 0.37, lr: [0.0024919078471341153], Loss: 1.944417, Acc:0.799728, Semantic loss: 0.736091, BCE loss: 0.508915, SB loss: 0.699411
2023-10-30 21:29:09,265 Epoch: [380/484] Iter:[330/495], Time: 0.37, lr: [0.002491469469694192], Loss: 1.944333, Acc:0.799976, Semantic loss: 0.736057, BCE loss: 0.509433, SB loss: 0.698843
2023-10-30 21:29:12,969 Epoch: [380/484] Iter:[340/495], Time: 0.37, lr: [0.0024910310836837556], Loss: 1.948199, Acc:0.801029, Semantic loss: 0.737908, BCE loss: 0.511395, SB loss: 0.698897
2023-10-30 21:29:16,607 Epoch: [380/484] Iter:[350/495], Time: 0.37, lr: [0.002490592689100963], Loss: 1.948962, Acc:0.801759, Semantic loss: 0.737114, BCE loss: 0.513116, SB loss: 0.698732
2023-10-30 21:29:20,269 Epoch: [380/484] Iter:[360/495], Time: 0.37, lr: [0.0024901542859439695], Loss: 1.950528, Acc:0.802273, Semantic loss: 0.737221, BCE loss: 0.514136, SB loss: 0.699171
2023-10-30 21:29:23,893 Epoch: [380/484] Iter:[370/495], Time: 0.37, lr: [0.0024897158742109306], Loss: 1.948479, Acc:0.802501, Semantic loss: 0.736352, BCE loss: 0.514291, SB loss: 0.697836
2023-10-30 21:29:27,628 Epoch: [380/484] Iter:[380/495], Time: 0.37, lr: [0.002489277453900001], Loss: 1.945788, Acc:0.802703, Semantic loss: 0.734748, BCE loss: 0.513571, SB loss: 0.697469
2023-10-30 21:29:31,363 Epoch: [380/484] Iter:[390/495], Time: 0.37, lr: [0.0024888390250093336], Loss: 1.945171, Acc:0.803150, Semantic loss: 0.734657, BCE loss: 0.513663, SB loss: 0.696851
2023-10-30 21:29:35,071 Epoch: [380/484] Iter:[400/495], Time: 0.37, lr: [0.0024884005875370793], Loss: 1.946304, Acc:0.804571, Semantic loss: 0.734185, BCE loss: 0.515109, SB loss: 0.697010
2023-10-30 21:29:38,758 Epoch: [380/484] Iter:[410/495], Time: 0.37, lr: [0.0024879621414813937], Loss: 1.942800, Acc:0.804764, Semantic loss: 0.731882, BCE loss: 0.515027, SB loss: 0.695890
2023-10-30 21:29:42,467 Epoch: [380/484] Iter:[420/495], Time: 0.37, lr: [0.0024875236868404254], Loss: 1.944115, Acc:0.805087, Semantic loss: 0.732134, BCE loss: 0.515710, SB loss: 0.696271
2023-10-30 21:29:46,218 Epoch: [380/484] Iter:[430/495], Time: 0.37, lr: [0.002487085223612326], Loss: 1.946482, Acc:0.805325, Semantic loss: 0.733201, BCE loss: 0.516433, SB loss: 0.696847
2023-10-30 21:29:49,781 Epoch: [380/484] Iter:[440/495], Time: 0.37, lr: [0.0024866467517952436], Loss: 1.946709, Acc:0.805575, Semantic loss: 0.733160, BCE loss: 0.516260, SB loss: 0.697289
2023-10-30 21:29:53,393 Epoch: [380/484] Iter:[450/495], Time: 0.37, lr: [0.002486208271387329], Loss: 1.945852, Acc:0.806118, Semantic loss: 0.732308, BCE loss: 0.516402, SB loss: 0.697142
2023-10-30 21:29:56,972 Epoch: [380/484] Iter:[460/495], Time: 0.37, lr: [0.00248576978238673], Loss: 1.947932, Acc:0.806280, Semantic loss: 0.733034, BCE loss: 0.517973, SB loss: 0.696925
2023-10-30 21:30:00,772 Epoch: [380/484] Iter:[470/495], Time: 0.37, lr: [0.002485331284791593], Loss: 1.945395, Acc:0.806958, Semantic loss: 0.732103, BCE loss: 0.516592, SB loss: 0.696700
2023-10-30 21:30:04,437 Epoch: [380/484] Iter:[480/495], Time: 0.37, lr: [0.002484892778600065], Loss: 1.948315, Acc:0.807841, Semantic loss: 0.731888, BCE loss: 0.519623, SB loss: 0.696804
2023-10-30 21:30:07,848 Epoch: [380/484] Iter:[490/495], Time: 0.37, lr: [0.0024844542638102923], Loss: 1.949547, Acc:0.806874, Semantic loss: 0.733429, BCE loss: 0.519188, SB loss: 0.696931
2023-10-30 21:33:05,235 0 [0.93839701 0.66671624 0.81023517 0.17977807 0.2680122  0.4061942
 0.45560087 0.60171919 0.85802797 0.46158446 0.87170875 0.58467381
 0.02165324 0.79406875 0.00288324 0.11203288 0.06375076 0.05098679
 0.61181109] 0.46104393101715513
2023-10-30 21:33:05,235 1 [0.97241684 0.78708683 0.88027432 0.42399814 0.52720158 0.57866627
 0.65022382 0.74316484 0.859541   0.55564734 0.94082324 0.78087113
 0.55781094 0.92870239 0.61335145 0.74762822 0.59227551 0.50694143
 0.73760673] 0.7044332638979787
2023-10-30 21:33:05,239 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:33:05,476 Loss: 2.085, MeanIU:  0.7044, Best_mIoU:  0.7487
2023-10-30 21:33:05,476 [0.97241684 0.78708683 0.88027432 0.42399814 0.52720158 0.57866627
 0.65022382 0.74316484 0.859541   0.55564734 0.94082324 0.78087113
 0.55781094 0.92870239 0.61335145 0.74762822 0.59227551 0.50694143
 0.73760673]
2023-10-30 21:33:07,844 Epoch: [381/484] Iter:[0/495], Time: 2.33, lr: [0.0024842350031904843], Loss: 1.504779, Acc:0.745103, Semantic loss: 0.516266, BCE loss: 0.397312, SB loss: 0.591202
2023-10-30 21:33:11,729 Epoch: [381/484] Iter:[10/495], Time: 0.57, lr: [0.0024837964754998664], Loss: 1.900409, Acc:0.779346, Semantic loss: 0.687292, BCE loss: 0.517879, SB loss: 0.695238
2023-10-30 21:33:15,226 Epoch: [381/484] Iter:[20/495], Time: 0.46, lr: [0.0024833579392063636], Loss: 1.946449, Acc:0.798682, Semantic loss: 0.731496, BCE loss: 0.522470, SB loss: 0.692484
2023-10-30 21:33:18,736 Epoch: [381/484] Iter:[30/495], Time: 0.43, lr: [0.002482919394308121], Loss: 1.945528, Acc:0.784575, Semantic loss: 0.730855, BCE loss: 0.513789, SB loss: 0.700884
2023-10-30 21:33:22,385 Epoch: [381/484] Iter:[40/495], Time: 0.41, lr: [0.0024824808408032807], Loss: 1.918665, Acc:0.795883, Semantic loss: 0.721754, BCE loss: 0.500853, SB loss: 0.696058
2023-10-30 21:33:25,782 Epoch: [381/484] Iter:[50/495], Time: 0.40, lr: [0.002482042278689984], Loss: 1.930178, Acc:0.803592, Semantic loss: 0.727694, BCE loss: 0.508199, SB loss: 0.694285
2023-10-30 21:33:29,262 Epoch: [381/484] Iter:[60/495], Time: 0.39, lr: [0.0024816037079663706], Loss: 1.927531, Acc:0.801926, Semantic loss: 0.721702, BCE loss: 0.512934, SB loss: 0.692895
2023-10-30 21:33:32,789 Epoch: [381/484] Iter:[70/495], Time: 0.38, lr: [0.0024811651286305828], Loss: 1.914222, Acc:0.803509, Semantic loss: 0.716417, BCE loss: 0.505735, SB loss: 0.692070
2023-10-30 21:33:36,371 Epoch: [381/484] Iter:[80/495], Time: 0.38, lr: [0.0024807265406807592], Loss: 1.914734, Acc:0.801215, Semantic loss: 0.720872, BCE loss: 0.502232, SB loss: 0.691631
2023-10-30 21:33:39,944 Epoch: [381/484] Iter:[90/495], Time: 0.38, lr: [0.002480287944115038], Loss: 1.916908, Acc:0.803598, Semantic loss: 0.722379, BCE loss: 0.504743, SB loss: 0.689786
2023-10-30 21:33:43,413 Epoch: [381/484] Iter:[100/495], Time: 0.38, lr: [0.002479849338931556], Loss: 1.911626, Acc:0.804638, Semantic loss: 0.719798, BCE loss: 0.504049, SB loss: 0.687779
2023-10-30 21:33:46,937 Epoch: [381/484] Iter:[110/495], Time: 0.37, lr: [0.0024794107251284525], Loss: 1.903962, Acc:0.806624, Semantic loss: 0.714895, BCE loss: 0.502884, SB loss: 0.686182
2023-10-30 21:33:50,478 Epoch: [381/484] Iter:[120/495], Time: 0.37, lr: [0.0024789721027038626], Loss: 1.909469, Acc:0.809866, Semantic loss: 0.717346, BCE loss: 0.502593, SB loss: 0.689529
2023-10-30 21:33:53,976 Epoch: [381/484] Iter:[130/495], Time: 0.37, lr: [0.002478533471655922], Loss: 1.916966, Acc:0.810770, Semantic loss: 0.720075, BCE loss: 0.504675, SB loss: 0.692217
2023-10-30 21:33:57,536 Epoch: [381/484] Iter:[140/495], Time: 0.37, lr: [0.002478094831982764], Loss: 1.909529, Acc:0.810025, Semantic loss: 0.716453, BCE loss: 0.502316, SB loss: 0.690760
2023-10-30 21:34:01,102 Epoch: [381/484] Iter:[150/495], Time: 0.37, lr: [0.0024776561836825253], Loss: 1.908521, Acc:0.806442, Semantic loss: 0.716888, BCE loss: 0.500263, SB loss: 0.691371
2023-10-30 21:34:04,706 Epoch: [381/484] Iter:[160/495], Time: 0.37, lr: [0.002477217526753338], Loss: 1.919817, Acc:0.805535, Semantic loss: 0.723077, BCE loss: 0.502971, SB loss: 0.693769
2023-10-30 21:34:08,319 Epoch: [381/484] Iter:[170/495], Time: 0.37, lr: [0.002476778861193334], Loss: 1.923434, Acc:0.807191, Semantic loss: 0.724641, BCE loss: 0.503879, SB loss: 0.694913
2023-10-30 21:34:11,939 Epoch: [381/484] Iter:[180/495], Time: 0.37, lr: [0.0024763401870006438], Loss: 1.922637, Acc:0.808609, Semantic loss: 0.723396, BCE loss: 0.505523, SB loss: 0.693718
2023-10-30 21:34:15,534 Epoch: [381/484] Iter:[190/495], Time: 0.37, lr: [0.0024759015041734005], Loss: 1.924111, Acc:0.809300, Semantic loss: 0.721864, BCE loss: 0.508604, SB loss: 0.693643
2023-10-30 21:34:19,147 Epoch: [381/484] Iter:[200/495], Time: 0.37, lr: [0.0024754628127097336], Loss: 1.927848, Acc:0.808672, Semantic loss: 0.722548, BCE loss: 0.512109, SB loss: 0.693191
2023-10-30 21:34:22,781 Epoch: [381/484] Iter:[210/495], Time: 0.37, lr: [0.0024750241126077726], Loss: 1.930125, Acc:0.807757, Semantic loss: 0.724580, BCE loss: 0.511115, SB loss: 0.694430
2023-10-30 21:34:26,568 Epoch: [381/484] Iter:[220/495], Time: 0.37, lr: [0.002474585403865644], Loss: 1.929900, Acc:0.807217, Semantic loss: 0.723566, BCE loss: 0.513029, SB loss: 0.693305
2023-10-30 21:34:30,164 Epoch: [381/484] Iter:[230/495], Time: 0.37, lr: [0.002474146686481479], Loss: 1.929163, Acc:0.807671, Semantic loss: 0.724315, BCE loss: 0.511938, SB loss: 0.692910
2023-10-30 21:34:33,727 Epoch: [381/484] Iter:[240/495], Time: 0.37, lr: [0.0024737079604534025], Loss: 1.932574, Acc:0.806345, Semantic loss: 0.726356, BCE loss: 0.513205, SB loss: 0.693012
2023-10-30 21:34:37,366 Epoch: [381/484] Iter:[250/495], Time: 0.37, lr: [0.002473269225779541], Loss: 1.930837, Acc:0.806059, Semantic loss: 0.725851, BCE loss: 0.511754, SB loss: 0.693233
2023-10-30 21:34:40,986 Epoch: [381/484] Iter:[260/495], Time: 0.37, lr: [0.0024728304824580194], Loss: 1.930377, Acc:0.805262, Semantic loss: 0.725807, BCE loss: 0.511163, SB loss: 0.693407
2023-10-30 21:34:44,757 Epoch: [381/484] Iter:[270/495], Time: 0.37, lr: [0.0024723917304869635], Loss: 1.926105, Acc:0.805576, Semantic loss: 0.724399, BCE loss: 0.508847, SB loss: 0.692859
2023-10-30 21:34:48,455 Epoch: [381/484] Iter:[280/495], Time: 0.37, lr: [0.0024719529698644972], Loss: 1.928202, Acc:0.805511, Semantic loss: 0.724744, BCE loss: 0.509824, SB loss: 0.693633
2023-10-30 21:34:51,994 Epoch: [381/484] Iter:[290/495], Time: 0.37, lr: [0.0024715142005887433], Loss: 1.930581, Acc:0.805911, Semantic loss: 0.725342, BCE loss: 0.510929, SB loss: 0.694310
2023-10-30 21:34:55,619 Epoch: [381/484] Iter:[300/495], Time: 0.37, lr: [0.002471075422657823], Loss: 1.929324, Acc:0.805276, Semantic loss: 0.723830, BCE loss: 0.511573, SB loss: 0.693921
2023-10-30 21:34:59,228 Epoch: [381/484] Iter:[310/495], Time: 0.37, lr: [0.00247063663606986], Loss: 1.926205, Acc:0.804602, Semantic loss: 0.722488, BCE loss: 0.510238, SB loss: 0.693480
2023-10-30 21:35:02,919 Epoch: [381/484] Iter:[320/495], Time: 0.37, lr: [0.0024701978408229737], Loss: 1.921663, Acc:0.803804, Semantic loss: 0.720624, BCE loss: 0.508924, SB loss: 0.692115
2023-10-30 21:35:06,580 Epoch: [381/484] Iter:[330/495], Time: 0.37, lr: [0.002469759036915285], Loss: 1.919379, Acc:0.805648, Semantic loss: 0.719296, BCE loss: 0.508570, SB loss: 0.691514
2023-10-30 21:35:10,254 Epoch: [381/484] Iter:[340/495], Time: 0.37, lr: [0.0024693202243449112], Loss: 1.921350, Acc:0.805944, Semantic loss: 0.720938, BCE loss: 0.507855, SB loss: 0.692557
2023-10-30 21:35:13,906 Epoch: [381/484] Iter:[350/495], Time: 0.37, lr: [0.0024688814031099734], Loss: 1.923026, Acc:0.804684, Semantic loss: 0.722411, BCE loss: 0.506666, SB loss: 0.693949
2023-10-30 21:35:17,601 Epoch: [381/484] Iter:[360/495], Time: 0.37, lr: [0.002468442573208588], Loss: 1.921501, Acc:0.805274, Semantic loss: 0.721504, BCE loss: 0.506372, SB loss: 0.693625
2023-10-30 21:35:21,413 Epoch: [381/484] Iter:[370/495], Time: 0.37, lr: [0.0024680037346388704], Loss: 1.922051, Acc:0.805314, Semantic loss: 0.721778, BCE loss: 0.506453, SB loss: 0.693820
2023-10-30 21:35:25,079 Epoch: [381/484] Iter:[380/495], Time: 0.37, lr: [0.00246756488739894], Loss: 1.924062, Acc:0.805302, Semantic loss: 0.722172, BCE loss: 0.508014, SB loss: 0.693876
2023-10-30 21:35:28,738 Epoch: [381/484] Iter:[390/495], Time: 0.37, lr: [0.0024671260314869103], Loss: 1.926007, Acc:0.805830, Semantic loss: 0.722393, BCE loss: 0.509136, SB loss: 0.694478
2023-10-30 21:35:32,343 Epoch: [381/484] Iter:[400/495], Time: 0.37, lr: [0.0024666871669008963], Loss: 1.936075, Acc:0.805549, Semantic loss: 0.727472, BCE loss: 0.512088, SB loss: 0.696514
2023-10-30 21:35:35,926 Epoch: [381/484] Iter:[410/495], Time: 0.37, lr: [0.0024662482936390097], Loss: 1.933798, Acc:0.805687, Semantic loss: 0.725735, BCE loss: 0.511524, SB loss: 0.696539
2023-10-30 21:35:39,626 Epoch: [381/484] Iter:[420/495], Time: 0.37, lr: [0.0024658094116993667], Loss: 1.930954, Acc:0.805181, Semantic loss: 0.724276, BCE loss: 0.510489, SB loss: 0.696189
2023-10-30 21:35:43,264 Epoch: [381/484] Iter:[430/495], Time: 0.37, lr: [0.002465370521080078], Loss: 1.935985, Acc:0.805372, Semantic loss: 0.727087, BCE loss: 0.511714, SB loss: 0.697184
2023-10-30 21:35:46,884 Epoch: [381/484] Iter:[440/495], Time: 0.37, lr: [0.002464931621779255], Loss: 1.935522, Acc:0.805601, Semantic loss: 0.726927, BCE loss: 0.511056, SB loss: 0.697538
2023-10-30 21:35:50,451 Epoch: [381/484] Iter:[450/495], Time: 0.37, lr: [0.0024644927137950075], Loss: 1.937750, Acc:0.805593, Semantic loss: 0.727883, BCE loss: 0.511557, SB loss: 0.698310
2023-10-30 21:35:54,137 Epoch: [381/484] Iter:[460/495], Time: 0.37, lr: [0.002464053797125447], Loss: 1.937654, Acc:0.806149, Semantic loss: 0.728069, BCE loss: 0.510768, SB loss: 0.698818
2023-10-30 21:35:57,840 Epoch: [381/484] Iter:[470/495], Time: 0.37, lr: [0.0024636148717686822], Loss: 1.940258, Acc:0.806668, Semantic loss: 0.728132, BCE loss: 0.513079, SB loss: 0.699048
2023-10-30 21:36:01,366 Epoch: [381/484] Iter:[480/495], Time: 0.37, lr: [0.0024631759377228206], Loss: 1.939564, Acc:0.806412, Semantic loss: 0.728629, BCE loss: 0.512639, SB loss: 0.698296
2023-10-30 21:36:04,787 Epoch: [381/484] Iter:[490/495], Time: 0.37, lr: [0.002462736994985969], Loss: 1.940322, Acc:0.806304, Semantic loss: 0.728532, BCE loss: 0.513281, SB loss: 0.698509
2023-10-30 21:36:06,160 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:36:06,404 Loss: 2.085, MeanIU:  0.7044, Best_mIoU:  0.7487
2023-10-30 21:36:06,404 [0.97241684 0.78708683 0.88027432 0.42399814 0.52720158 0.57866627
 0.65022382 0.74316484 0.859541   0.55564734 0.94082324 0.78087113
 0.55781094 0.92870239 0.61335145 0.74762822 0.59227551 0.50694143
 0.73760673]
2023-10-30 21:36:08,462 Epoch: [382/484] Iter:[0/495], Time: 2.03, lr: [0.002462517520357832], Loss: 2.101620, Acc:0.905999, Semantic loss: 0.685058, BCE loss: 0.802752, SB loss: 0.613810
2023-10-30 21:36:12,346 Epoch: [382/484] Iter:[10/495], Time: 0.54, lr: [0.0024620785645809483], Loss: 1.906900, Acc:0.783147, Semantic loss: 0.699370, BCE loss: 0.525171, SB loss: 0.682359
2023-10-30 21:36:15,986 Epoch: [382/484] Iter:[20/495], Time: 0.45, lr: [0.002461639600108341], Loss: 1.959147, Acc:0.800916, Semantic loss: 0.732566, BCE loss: 0.524817, SB loss: 0.701764
2023-10-30 21:36:19,553 Epoch: [382/484] Iter:[30/495], Time: 0.42, lr: [0.0024612006269381145], Loss: 1.943685, Acc:0.802013, Semantic loss: 0.715468, BCE loss: 0.533680, SB loss: 0.694537
2023-10-30 21:36:23,095 Epoch: [382/484] Iter:[40/495], Time: 0.41, lr: [0.002460761645068372], Loss: 1.933969, Acc:0.806973, Semantic loss: 0.715430, BCE loss: 0.526050, SB loss: 0.692489
2023-10-30 21:36:26,847 Epoch: [382/484] Iter:[50/495], Time: 0.40, lr: [0.0024603226544972195], Loss: 1.932805, Acc:0.813063, Semantic loss: 0.715084, BCE loss: 0.524969, SB loss: 0.692752
2023-10-30 21:36:30,448 Epoch: [382/484] Iter:[60/495], Time: 0.39, lr: [0.002459883655222757], Loss: 1.919180, Acc:0.814389, Semantic loss: 0.712380, BCE loss: 0.517003, SB loss: 0.689796
2023-10-30 21:36:34,129 Epoch: [382/484] Iter:[70/495], Time: 0.39, lr: [0.0024594446472430867], Loss: 1.912646, Acc:0.816507, Semantic loss: 0.714456, BCE loss: 0.507927, SB loss: 0.690263
2023-10-30 21:36:37,703 Epoch: [382/484] Iter:[80/495], Time: 0.39, lr: [0.0024590056305563083], Loss: 1.910544, Acc:0.810980, Semantic loss: 0.713007, BCE loss: 0.508601, SB loss: 0.688936
2023-10-30 21:36:41,274 Epoch: [382/484] Iter:[90/495], Time: 0.38, lr: [0.0024585666051605243], Loss: 1.910483, Acc:0.810758, Semantic loss: 0.712479, BCE loss: 0.508902, SB loss: 0.689103
2023-10-30 21:36:44,909 Epoch: [382/484] Iter:[100/495], Time: 0.38, lr: [0.0024581275710538323], Loss: 1.927334, Acc:0.807074, Semantic loss: 0.718400, BCE loss: 0.516425, SB loss: 0.692509
2023-10-30 21:36:48,461 Epoch: [382/484] Iter:[110/495], Time: 0.38, lr: [0.002457688528234331], Loss: 1.925866, Acc:0.807921, Semantic loss: 0.720929, BCE loss: 0.512991, SB loss: 0.691946
2023-10-30 21:36:52,066 Epoch: [382/484] Iter:[120/495], Time: 0.38, lr: [0.0024572494767001168], Loss: 1.925232, Acc:0.807008, Semantic loss: 0.720634, BCE loss: 0.513368, SB loss: 0.691230
2023-10-30 21:36:55,641 Epoch: [382/484] Iter:[130/495], Time: 0.38, lr: [0.002456810416449288], Loss: 1.924777, Acc:0.806296, Semantic loss: 0.720545, BCE loss: 0.512910, SB loss: 0.691323
2023-10-30 21:36:59,214 Epoch: [382/484] Iter:[140/495], Time: 0.37, lr: [0.0024563713474799413], Loss: 1.934260, Acc:0.803708, Semantic loss: 0.725444, BCE loss: 0.513362, SB loss: 0.695455
2023-10-30 21:37:02,814 Epoch: [382/484] Iter:[150/495], Time: 0.37, lr: [0.0024559322697901708], Loss: 1.933765, Acc:0.806073, Semantic loss: 0.722863, BCE loss: 0.515790, SB loss: 0.695112
2023-10-30 21:37:06,503 Epoch: [382/484] Iter:[160/495], Time: 0.37, lr: [0.0024554931833780692], Loss: 1.923159, Acc:0.803967, Semantic loss: 0.718384, BCE loss: 0.510911, SB loss: 0.693864
2023-10-30 21:37:10,189 Epoch: [382/484] Iter:[170/495], Time: 0.37, lr: [0.0024550540882417337], Loss: 1.934403, Acc:0.802122, Semantic loss: 0.722622, BCE loss: 0.513616, SB loss: 0.698165
2023-10-30 21:37:14,108 Epoch: [382/484] Iter:[180/495], Time: 0.37, lr: [0.0024546149843792556], Loss: 1.935937, Acc:0.802937, Semantic loss: 0.722241, BCE loss: 0.513831, SB loss: 0.699865
2023-10-30 21:37:17,778 Epoch: [382/484] Iter:[190/495], Time: 0.37, lr: [0.0024541758717887266], Loss: 1.939569, Acc:0.806133, Semantic loss: 0.723373, BCE loss: 0.516201, SB loss: 0.699995
2023-10-30 21:37:21,454 Epoch: [382/484] Iter:[200/495], Time: 0.37, lr: [0.002453736750468237], Loss: 1.946096, Acc:0.802093, Semantic loss: 0.728499, BCE loss: 0.516421, SB loss: 0.701176
2023-10-30 21:37:24,952 Epoch: [382/484] Iter:[210/495], Time: 0.37, lr: [0.0024532976204158794], Loss: 1.948035, Acc:0.802187, Semantic loss: 0.728453, BCE loss: 0.518682, SB loss: 0.700899
2023-10-30 21:37:28,473 Epoch: [382/484] Iter:[220/495], Time: 0.37, lr: [0.0024528584816297426], Loss: 1.944678, Acc:0.800694, Semantic loss: 0.727912, BCE loss: 0.515921, SB loss: 0.700845
2023-10-30 21:37:32,080 Epoch: [382/484] Iter:[230/495], Time: 0.37, lr: [0.0024524193341079145], Loss: 1.944070, Acc:0.799845, Semantic loss: 0.727978, BCE loss: 0.514546, SB loss: 0.701547
2023-10-30 21:37:35,989 Epoch: [382/484] Iter:[240/495], Time: 0.37, lr: [0.002451980177848485], Loss: 1.960284, Acc:0.800329, Semantic loss: 0.736227, BCE loss: 0.517662, SB loss: 0.706395
2023-10-30 21:37:39,756 Epoch: [382/484] Iter:[250/495], Time: 0.37, lr: [0.0024515410128495407], Loss: 1.958716, Acc:0.800543, Semantic loss: 0.735255, BCE loss: 0.517424, SB loss: 0.706038
2023-10-30 21:37:43,696 Epoch: [382/484] Iter:[260/495], Time: 0.37, lr: [0.0024511018391091674], Loss: 1.960249, Acc:0.800830, Semantic loss: 0.735615, BCE loss: 0.517925, SB loss: 0.706710
2023-10-30 21:37:47,378 Epoch: [382/484] Iter:[270/495], Time: 0.37, lr: [0.0024506626566254503], Loss: 1.964134, Acc:0.800388, Semantic loss: 0.737040, BCE loss: 0.520665, SB loss: 0.706429
2023-10-30 21:37:51,127 Epoch: [382/484] Iter:[280/495], Time: 0.37, lr: [0.002450223465396476], Loss: 1.965037, Acc:0.799731, Semantic loss: 0.738172, BCE loss: 0.520780, SB loss: 0.706085
2023-10-30 21:37:54,704 Epoch: [382/484] Iter:[290/495], Time: 0.37, lr: [0.0024497842654203285], Loss: 1.966466, Acc:0.800233, Semantic loss: 0.738755, BCE loss: 0.521269, SB loss: 0.706442
2023-10-30 21:37:58,374 Epoch: [382/484] Iter:[300/495], Time: 0.37, lr: [0.0024493450566950895], Loss: 1.967443, Acc:0.799789, Semantic loss: 0.738458, BCE loss: 0.523010, SB loss: 0.705975
2023-10-30 21:38:01,992 Epoch: [382/484] Iter:[310/495], Time: 0.37, lr: [0.0024489058392188415], Loss: 1.967691, Acc:0.800048, Semantic loss: 0.737936, BCE loss: 0.524242, SB loss: 0.705513
2023-10-30 21:38:05,745 Epoch: [382/484] Iter:[320/495], Time: 0.37, lr: [0.002448466612989668], Loss: 1.966704, Acc:0.800998, Semantic loss: 0.736915, BCE loss: 0.524831, SB loss: 0.704958
2023-10-30 21:38:09,348 Epoch: [382/484] Iter:[330/495], Time: 0.37, lr: [0.0024480273780056487], Loss: 1.964380, Acc:0.802154, Semantic loss: 0.735950, BCE loss: 0.524356, SB loss: 0.704074
2023-10-30 21:38:12,874 Epoch: [382/484] Iter:[340/495], Time: 0.37, lr: [0.0024475881342648637], Loss: 1.962888, Acc:0.801476, Semantic loss: 0.735300, BCE loss: 0.523365, SB loss: 0.704223
2023-10-30 21:38:16,498 Epoch: [382/484] Iter:[350/495], Time: 0.37, lr: [0.0024471488817653913], Loss: 1.965165, Acc:0.801631, Semantic loss: 0.737221, BCE loss: 0.523423, SB loss: 0.704522
2023-10-30 21:38:20,087 Epoch: [382/484] Iter:[360/495], Time: 0.37, lr: [0.0024467096205053117], Loss: 1.961728, Acc:0.802378, Semantic loss: 0.735677, BCE loss: 0.521955, SB loss: 0.704096
2023-10-30 21:38:23,725 Epoch: [382/484] Iter:[370/495], Time: 0.37, lr: [0.0024462703504827023], Loss: 1.963482, Acc:0.802231, Semantic loss: 0.736628, BCE loss: 0.522503, SB loss: 0.704352
2023-10-30 21:38:27,399 Epoch: [382/484] Iter:[380/495], Time: 0.37, lr: [0.0024458310716956393], Loss: 1.963245, Acc:0.802471, Semantic loss: 0.736987, BCE loss: 0.521700, SB loss: 0.704558
2023-10-30 21:38:30,983 Epoch: [382/484] Iter:[390/495], Time: 0.37, lr: [0.0024453917841421972], Loss: 1.961511, Acc:0.803004, Semantic loss: 0.736643, BCE loss: 0.521092, SB loss: 0.703776
2023-10-30 21:38:34,703 Epoch: [382/484] Iter:[400/495], Time: 0.37, lr: [0.0024449524878204544], Loss: 1.960138, Acc:0.803948, Semantic loss: 0.735354, BCE loss: 0.521477, SB loss: 0.703307
2023-10-30 21:38:38,296 Epoch: [382/484] Iter:[410/495], Time: 0.37, lr: [0.002444513182728484], Loss: 1.960424, Acc:0.804274, Semantic loss: 0.735586, BCE loss: 0.520827, SB loss: 0.704010
2023-10-30 21:38:41,853 Epoch: [382/484] Iter:[420/495], Time: 0.37, lr: [0.0024440738688643595], Loss: 1.961171, Acc:0.804126, Semantic loss: 0.736396, BCE loss: 0.520968, SB loss: 0.703806
2023-10-30 21:38:45,387 Epoch: [382/484] Iter:[430/495], Time: 0.37, lr: [0.002443634546226152], Loss: 1.957740, Acc:0.802818, Semantic loss: 0.734998, BCE loss: 0.519663, SB loss: 0.703079
2023-10-30 21:38:48,937 Epoch: [382/484] Iter:[440/495], Time: 0.37, lr: [0.002443195214811937], Loss: 1.957764, Acc:0.802462, Semantic loss: 0.735282, BCE loss: 0.519438, SB loss: 0.703044
2023-10-30 21:38:52,655 Epoch: [382/484] Iter:[450/495], Time: 0.37, lr: [0.0024427558746197833], Loss: 1.957201, Acc:0.802823, Semantic loss: 0.735333, BCE loss: 0.518917, SB loss: 0.702951
2023-10-30 21:38:56,267 Epoch: [382/484] Iter:[460/495], Time: 0.37, lr: [0.002442316525647762], Loss: 1.955918, Acc:0.803113, Semantic loss: 0.734566, BCE loss: 0.518722, SB loss: 0.702630
2023-10-30 21:38:59,844 Epoch: [382/484] Iter:[470/495], Time: 0.37, lr: [0.0024418771678939412], Loss: 1.954778, Acc:0.802978, Semantic loss: 0.734301, BCE loss: 0.518191, SB loss: 0.702285
2023-10-30 21:39:03,349 Epoch: [382/484] Iter:[480/495], Time: 0.37, lr: [0.0024414378013563917], Loss: 1.954587, Acc:0.803049, Semantic loss: 0.734470, BCE loss: 0.517793, SB loss: 0.702324
2023-10-30 21:39:06,794 Epoch: [382/484] Iter:[490/495], Time: 0.37, lr: [0.002440998426033181], Loss: 1.953906, Acc:0.802911, Semantic loss: 0.733555, BCE loss: 0.518400, SB loss: 0.701951
2023-10-30 21:39:08,164 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:39:08,400 Loss: 2.085, MeanIU:  0.7044, Best_mIoU:  0.7487
2023-10-30 21:39:08,400 [0.97241684 0.78708683 0.88027432 0.42399814 0.52720158 0.57866627
 0.65022382 0.74316484 0.859541   0.55564734 0.94082324 0.78087113
 0.55781094 0.92870239 0.61335145 0.74762822 0.59227551 0.50694143
 0.73760673]
2023-10-30 21:39:10,354 Epoch: [383/484] Iter:[0/495], Time: 1.92, lr: [0.002440778735076349], Loss: 1.865495, Acc:0.706065, Semantic loss: 0.715878, BCE loss: 0.417726, SB loss: 0.731891
2023-10-30 21:39:14,347 Epoch: [383/484] Iter:[10/495], Time: 0.54, lr: [0.002440339346571021], Loss: 1.954430, Acc:0.788426, Semantic loss: 0.724389, BCE loss: 0.527408, SB loss: 0.702632
2023-10-30 21:39:18,099 Epoch: [383/484] Iter:[20/495], Time: 0.46, lr: [0.0024398999492751977], Loss: 1.869316, Acc:0.799003, Semantic loss: 0.671118, BCE loss: 0.516260, SB loss: 0.681937
2023-10-30 21:39:21,669 Epoch: [383/484] Iter:[30/495], Time: 0.43, lr: [0.0024394605431869447], Loss: 1.918396, Acc:0.797726, Semantic loss: 0.711308, BCE loss: 0.517100, SB loss: 0.689988
2023-10-30 21:39:25,454 Epoch: [383/484] Iter:[40/495], Time: 0.42, lr: [0.0024390211283043263], Loss: 1.958204, Acc:0.799403, Semantic loss: 0.735167, BCE loss: 0.526481, SB loss: 0.696556
2023-10-30 21:39:29,181 Epoch: [383/484] Iter:[50/495], Time: 0.41, lr: [0.0024385817046254045], Loss: 1.947866, Acc:0.801138, Semantic loss: 0.728948, BCE loss: 0.524299, SB loss: 0.694619
2023-10-30 21:39:32,918 Epoch: [383/484] Iter:[60/495], Time: 0.40, lr: [0.002438142272148244], Loss: 1.959373, Acc:0.802534, Semantic loss: 0.725005, BCE loss: 0.534194, SB loss: 0.700174
2023-10-30 21:39:36,443 Epoch: [383/484] Iter:[70/495], Time: 0.39, lr: [0.0024377028308709054], Loss: 1.949778, Acc:0.798349, Semantic loss: 0.720771, BCE loss: 0.529673, SB loss: 0.699333
2023-10-30 21:39:40,269 Epoch: [383/484] Iter:[80/495], Time: 0.39, lr: [0.0024372633807914503], Loss: 1.937273, Acc:0.793712, Semantic loss: 0.715160, BCE loss: 0.524348, SB loss: 0.697766
2023-10-30 21:39:43,991 Epoch: [383/484] Iter:[90/495], Time: 0.39, lr: [0.002436823921907937], Loss: 1.936033, Acc:0.795300, Semantic loss: 0.713583, BCE loss: 0.526602, SB loss: 0.695848
2023-10-30 21:39:47,691 Epoch: [383/484] Iter:[100/495], Time: 0.39, lr: [0.0024363844542184283], Loss: 1.931801, Acc:0.793799, Semantic loss: 0.711319, BCE loss: 0.521444, SB loss: 0.699038
2023-10-30 21:39:51,364 Epoch: [383/484] Iter:[110/495], Time: 0.39, lr: [0.0024359449777209803], Loss: 1.924053, Acc:0.794029, Semantic loss: 0.709055, BCE loss: 0.517932, SB loss: 0.697066
2023-10-30 21:39:55,062 Epoch: [383/484] Iter:[120/495], Time: 0.39, lr: [0.002435505492413652], Loss: 1.926773, Acc:0.797189, Semantic loss: 0.711420, BCE loss: 0.519679, SB loss: 0.695674
2023-10-30 21:39:59,059 Epoch: [383/484] Iter:[130/495], Time: 0.39, lr: [0.002435065998294499], Loss: 1.922314, Acc:0.797900, Semantic loss: 0.710476, BCE loss: 0.517433, SB loss: 0.694405
2023-10-30 21:40:02,722 Epoch: [383/484] Iter:[140/495], Time: 0.39, lr: [0.0024346264953615786], Loss: 1.922946, Acc:0.799151, Semantic loss: 0.713117, BCE loss: 0.515682, SB loss: 0.694147
2023-10-30 21:40:06,516 Epoch: [383/484] Iter:[150/495], Time: 0.38, lr: [0.0024341869836129464], Loss: 1.918477, Acc:0.801347, Semantic loss: 0.711089, BCE loss: 0.514656, SB loss: 0.692732
2023-10-30 21:40:10,122 Epoch: [383/484] Iter:[160/495], Time: 0.38, lr: [0.0024337474630466557], Loss: 1.924860, Acc:0.799635, Semantic loss: 0.716329, BCE loss: 0.515422, SB loss: 0.693109
2023-10-30 21:40:13,765 Epoch: [383/484] Iter:[170/495], Time: 0.38, lr: [0.00243330793366076], Loss: 1.926442, Acc:0.800845, Semantic loss: 0.716970, BCE loss: 0.516788, SB loss: 0.692684
2023-10-30 21:40:17,431 Epoch: [383/484] Iter:[180/495], Time: 0.38, lr: [0.0024328683954533137], Loss: 1.925249, Acc:0.799930, Semantic loss: 0.717566, BCE loss: 0.515773, SB loss: 0.691910
2023-10-30 21:40:21,007 Epoch: [383/484] Iter:[190/495], Time: 0.38, lr: [0.002432428848422368], Loss: 1.929745, Acc:0.802197, Semantic loss: 0.720658, BCE loss: 0.516699, SB loss: 0.692389
2023-10-30 21:40:24,564 Epoch: [383/484] Iter:[200/495], Time: 0.38, lr: [0.0024319892925659743], Loss: 1.928479, Acc:0.801633, Semantic loss: 0.720033, BCE loss: 0.517666, SB loss: 0.690780
2023-10-30 21:40:28,231 Epoch: [383/484] Iter:[210/495], Time: 0.38, lr: [0.0024315497278821815], Loss: 1.925085, Acc:0.800857, Semantic loss: 0.718098, BCE loss: 0.516615, SB loss: 0.690371
2023-10-30 21:40:31,787 Epoch: [383/484] Iter:[220/495], Time: 0.38, lr: [0.002431110154369042], Loss: 1.920697, Acc:0.801012, Semantic loss: 0.716897, BCE loss: 0.514180, SB loss: 0.689620
2023-10-30 21:40:35,392 Epoch: [383/484] Iter:[230/495], Time: 0.38, lr: [0.0024306705720246024], Loss: 1.923016, Acc:0.802397, Semantic loss: 0.719216, BCE loss: 0.514163, SB loss: 0.689637
2023-10-30 21:40:39,004 Epoch: [383/484] Iter:[240/495], Time: 0.38, lr: [0.002430230980846912], Loss: 1.921588, Acc:0.802676, Semantic loss: 0.718826, BCE loss: 0.513208, SB loss: 0.689554
2023-10-30 21:40:42,645 Epoch: [383/484] Iter:[250/495], Time: 0.38, lr: [0.0024297913808340155], Loss: 1.920840, Acc:0.802371, Semantic loss: 0.719543, BCE loss: 0.512139, SB loss: 0.689158
2023-10-30 21:40:46,302 Epoch: [383/484] Iter:[260/495], Time: 0.37, lr: [0.002429351771983962], Loss: 1.920535, Acc:0.802640, Semantic loss: 0.718574, BCE loss: 0.514048, SB loss: 0.687913
2023-10-30 21:40:49,972 Epoch: [383/484] Iter:[270/495], Time: 0.37, lr: [0.0024289121542947958], Loss: 1.918619, Acc:0.802448, Semantic loss: 0.717266, BCE loss: 0.514536, SB loss: 0.686816
2023-10-30 21:40:53,667 Epoch: [383/484] Iter:[280/495], Time: 0.37, lr: [0.0024284725277645613], Loss: 1.922617, Acc:0.803535, Semantic loss: 0.717581, BCE loss: 0.517481, SB loss: 0.687555
2023-10-30 21:40:57,305 Epoch: [383/484] Iter:[290/495], Time: 0.37, lr: [0.0024280328923913016], Loss: 1.927496, Acc:0.802876, Semantic loss: 0.720336, BCE loss: 0.518655, SB loss: 0.688504
2023-10-30 21:41:00,979 Epoch: [383/484] Iter:[300/495], Time: 0.37, lr: [0.0024275932481730616], Loss: 1.929131, Acc:0.802970, Semantic loss: 0.720038, BCE loss: 0.520805, SB loss: 0.688288
2023-10-30 21:41:04,696 Epoch: [383/484] Iter:[310/495], Time: 0.37, lr: [0.0024271535951078823], Loss: 1.932328, Acc:0.802937, Semantic loss: 0.722474, BCE loss: 0.521249, SB loss: 0.688605
2023-10-30 21:41:08,327 Epoch: [383/484] Iter:[320/495], Time: 0.37, lr: [0.002426713933193805], Loss: 1.929889, Acc:0.804339, Semantic loss: 0.721539, BCE loss: 0.520649, SB loss: 0.687701
2023-10-30 21:41:12,002 Epoch: [383/484] Iter:[330/495], Time: 0.37, lr: [0.002426274262428869], Loss: 1.933528, Acc:0.806035, Semantic loss: 0.723397, BCE loss: 0.522501, SB loss: 0.687630
2023-10-30 21:41:15,703 Epoch: [383/484] Iter:[340/495], Time: 0.37, lr: [0.0024258345828111166], Loss: 1.934804, Acc:0.807022, Semantic loss: 0.723917, BCE loss: 0.522791, SB loss: 0.688096
2023-10-30 21:41:19,295 Epoch: [383/484] Iter:[350/495], Time: 0.37, lr: [0.0024253948943385854], Loss: 1.937929, Acc:0.807412, Semantic loss: 0.725210, BCE loss: 0.523681, SB loss: 0.689038
2023-10-30 21:41:22,957 Epoch: [383/484] Iter:[360/495], Time: 0.37, lr: [0.0024249551970093133], Loss: 1.934746, Acc:0.808321, Semantic loss: 0.723962, BCE loss: 0.522039, SB loss: 0.688745
2023-10-30 21:41:26,640 Epoch: [383/484] Iter:[370/495], Time: 0.37, lr: [0.002424515490821336], Loss: 1.936549, Acc:0.807900, Semantic loss: 0.726332, BCE loss: 0.520209, SB loss: 0.690008
2023-10-30 21:41:30,277 Epoch: [383/484] Iter:[380/495], Time: 0.37, lr: [0.0024240757757726925], Loss: 1.936861, Acc:0.808508, Semantic loss: 0.726104, BCE loss: 0.520303, SB loss: 0.690454
2023-10-30 21:41:33,882 Epoch: [383/484] Iter:[390/495], Time: 0.37, lr: [0.002423636051861417], Loss: 1.936276, Acc:0.809162, Semantic loss: 0.726260, BCE loss: 0.520121, SB loss: 0.689894
2023-10-30 21:41:37,548 Epoch: [383/484] Iter:[400/495], Time: 0.37, lr: [0.0024231963190855443], Loss: 1.935860, Acc:0.808870, Semantic loss: 0.726239, BCE loss: 0.520021, SB loss: 0.689599
2023-10-30 21:41:41,211 Epoch: [383/484] Iter:[410/495], Time: 0.37, lr: [0.002422756577443107], Loss: 1.935436, Acc:0.808966, Semantic loss: 0.725780, BCE loss: 0.520049, SB loss: 0.689607
2023-10-30 21:41:44,840 Epoch: [383/484] Iter:[420/495], Time: 0.37, lr: [0.0024223168269321407], Loss: 1.935359, Acc:0.808245, Semantic loss: 0.725869, BCE loss: 0.519788, SB loss: 0.689702
2023-10-30 21:41:48,414 Epoch: [383/484] Iter:[430/495], Time: 0.37, lr: [0.002421877067550676], Loss: 1.938792, Acc:0.807945, Semantic loss: 0.727310, BCE loss: 0.520824, SB loss: 0.690658
2023-10-30 21:41:52,090 Epoch: [383/484] Iter:[440/495], Time: 0.37, lr: [0.0024214372992967447], Loss: 1.938594, Acc:0.807320, Semantic loss: 0.727783, BCE loss: 0.520279, SB loss: 0.690532
2023-10-30 21:41:55,723 Epoch: [383/484] Iter:[450/495], Time: 0.37, lr: [0.002420997522168375], Loss: 1.937764, Acc:0.806932, Semantic loss: 0.727616, BCE loss: 0.519588, SB loss: 0.690559
2023-10-30 21:41:59,240 Epoch: [383/484] Iter:[460/495], Time: 0.37, lr: [0.002420557736163601], Loss: 1.935918, Acc:0.806218, Semantic loss: 0.727131, BCE loss: 0.517806, SB loss: 0.690980
2023-10-30 21:42:02,866 Epoch: [383/484] Iter:[470/495], Time: 0.37, lr: [0.0024201179412804484], Loss: 1.935949, Acc:0.805601, Semantic loss: 0.727664, BCE loss: 0.517243, SB loss: 0.691042
2023-10-30 21:42:06,491 Epoch: [383/484] Iter:[480/495], Time: 0.37, lr: [0.002419678137516946], Loss: 1.933348, Acc:0.805843, Semantic loss: 0.726169, BCE loss: 0.516544, SB loss: 0.690635
2023-10-30 21:42:09,883 Epoch: [383/484] Iter:[490/495], Time: 0.37, lr: [0.00241923832487112], Loss: 1.934819, Acc:0.805705, Semantic loss: 0.726481, BCE loss: 0.517370, SB loss: 0.690967
2023-10-30 21:42:11,259 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:42:11,524 Loss: 2.085, MeanIU:  0.7044, Best_mIoU:  0.7487
2023-10-30 21:42:11,524 [0.97241684 0.78708683 0.88027432 0.42399814 0.52720158 0.57866627
 0.65022382 0.74316484 0.859541   0.55564734 0.94082324 0.78087113
 0.55781094 0.92870239 0.61335145 0.74762822 0.59227551 0.50694143
 0.73760673]
2023-10-30 21:42:13,630 Epoch: [384/484] Iter:[0/495], Time: 2.07, lr: [0.0024190184152167193], Loss: 2.035423, Acc:0.812546, Semantic loss: 0.767470, BCE loss: 0.592386, SB loss: 0.675567
2023-10-30 21:42:17,640 Epoch: [384/484] Iter:[10/495], Time: 0.55, lr: [0.0024185785892437096], Loss: 1.858349, Acc:0.838506, Semantic loss: 0.678632, BCE loss: 0.512779, SB loss: 0.666938
2023-10-30 21:42:21,347 Epoch: [384/484] Iter:[20/495], Time: 0.47, lr: [0.002418138754383441], Loss: 1.878768, Acc:0.821804, Semantic loss: 0.681556, BCE loss: 0.525388, SB loss: 0.671824
2023-10-30 21:42:24,970 Epoch: [384/484] Iter:[30/495], Time: 0.43, lr: [0.0024176989106339374], Loss: 1.928220, Acc:0.824741, Semantic loss: 0.700165, BCE loss: 0.546279, SB loss: 0.681775
2023-10-30 21:42:28,567 Epoch: [384/484] Iter:[40/495], Time: 0.41, lr: [0.002417259057993224], Loss: 1.913219, Acc:0.810217, Semantic loss: 0.700877, BCE loss: 0.527242, SB loss: 0.685099
2023-10-30 21:42:32,124 Epoch: [384/484] Iter:[50/495], Time: 0.40, lr: [0.0024168191964593225], Loss: 1.908821, Acc:0.807634, Semantic loss: 0.703352, BCE loss: 0.523219, SB loss: 0.682249
2023-10-30 21:42:35,698 Epoch: [384/484] Iter:[60/495], Time: 0.40, lr: [0.002416379326030254], Loss: 1.922444, Acc:0.807048, Semantic loss: 0.706456, BCE loss: 0.527157, SB loss: 0.688831
2023-10-30 21:42:39,356 Epoch: [384/484] Iter:[70/495], Time: 0.39, lr: [0.0024159394467040394], Loss: 1.911295, Acc:0.798509, Semantic loss: 0.706384, BCE loss: 0.514402, SB loss: 0.690508
2023-10-30 21:42:42,994 Epoch: [384/484] Iter:[80/495], Time: 0.39, lr: [0.0024154995584786997], Loss: 1.910079, Acc:0.802718, Semantic loss: 0.702376, BCE loss: 0.520164, SB loss: 0.687540
2023-10-30 21:42:46,556 Epoch: [384/484] Iter:[90/495], Time: 0.38, lr: [0.002415059661352254], Loss: 1.923075, Acc:0.799833, Semantic loss: 0.711638, BCE loss: 0.520669, SB loss: 0.690769
2023-10-30 21:42:50,164 Epoch: [384/484] Iter:[100/495], Time: 0.38, lr: [0.0024146197553227204], Loss: 1.933378, Acc:0.796932, Semantic loss: 0.718807, BCE loss: 0.520410, SB loss: 0.694161
2023-10-30 21:42:53,745 Epoch: [384/484] Iter:[110/495], Time: 0.38, lr: [0.002414179840388115], Loss: 1.925199, Acc:0.797465, Semantic loss: 0.718190, BCE loss: 0.515828, SB loss: 0.691180
2023-10-30 21:42:57,302 Epoch: [384/484] Iter:[120/495], Time: 0.38, lr: [0.002413739916546456], Loss: 1.930162, Acc:0.795838, Semantic loss: 0.720283, BCE loss: 0.519049, SB loss: 0.690830
2023-10-30 21:43:00,916 Epoch: [384/484] Iter:[130/495], Time: 0.38, lr: [0.00241329998379576], Loss: 1.926597, Acc:0.795307, Semantic loss: 0.719977, BCE loss: 0.516548, SB loss: 0.690072
2023-10-30 21:43:04,604 Epoch: [384/484] Iter:[140/495], Time: 0.38, lr: [0.0024128600421340404], Loss: 1.925692, Acc:0.796455, Semantic loss: 0.721277, BCE loss: 0.514408, SB loss: 0.690007
2023-10-30 21:43:08,560 Epoch: [384/484] Iter:[150/495], Time: 0.38, lr: [0.0024124200915593107], Loss: 1.930336, Acc:0.797619, Semantic loss: 0.720978, BCE loss: 0.518447, SB loss: 0.690912
2023-10-30 21:43:12,206 Epoch: [384/484] Iter:[160/495], Time: 0.38, lr: [0.002411980132069587], Loss: 1.934018, Acc:0.799188, Semantic loss: 0.726581, BCE loss: 0.517738, SB loss: 0.689699
2023-10-30 21:43:15,817 Epoch: [384/484] Iter:[170/495], Time: 0.38, lr: [0.00241154016366288], Loss: 1.932607, Acc:0.800213, Semantic loss: 0.723395, BCE loss: 0.520516, SB loss: 0.688696
2023-10-30 21:43:19,554 Epoch: [384/484] Iter:[180/495], Time: 0.38, lr: [0.002411100186337201], Loss: 1.941900, Acc:0.801805, Semantic loss: 0.729488, BCE loss: 0.520881, SB loss: 0.691530
2023-10-30 21:43:23,163 Epoch: [384/484] Iter:[190/495], Time: 0.37, lr: [0.0024106602000905602], Loss: 1.934760, Acc:0.803545, Semantic loss: 0.723113, BCE loss: 0.521578, SB loss: 0.690069
2023-10-30 21:43:26,817 Epoch: [384/484] Iter:[200/495], Time: 0.37, lr: [0.0024102202049209693], Loss: 1.931082, Acc:0.800314, Semantic loss: 0.722110, BCE loss: 0.517878, SB loss: 0.691095
2023-10-30 21:43:30,430 Epoch: [384/484] Iter:[210/495], Time: 0.37, lr: [0.002409780200826437], Loss: 1.929118, Acc:0.798834, Semantic loss: 0.721097, BCE loss: 0.515551, SB loss: 0.692470
2023-10-30 21:43:34,153 Epoch: [384/484] Iter:[220/495], Time: 0.37, lr: [0.0024093401878049706], Loss: 1.924693, Acc:0.797957, Semantic loss: 0.719039, BCE loss: 0.514462, SB loss: 0.691193
2023-10-30 21:43:37,870 Epoch: [384/484] Iter:[230/495], Time: 0.37, lr: [0.002408900165854577], Loss: 1.928138, Acc:0.799752, Semantic loss: 0.720952, BCE loss: 0.515643, SB loss: 0.691543
2023-10-30 21:43:41,535 Epoch: [384/484] Iter:[240/495], Time: 0.37, lr: [0.0024084601349732646], Loss: 1.930448, Acc:0.801259, Semantic loss: 0.721945, BCE loss: 0.516917, SB loss: 0.691586
2023-10-30 21:43:45,090 Epoch: [384/484] Iter:[250/495], Time: 0.37, lr: [0.002408020095159038], Loss: 1.926560, Acc:0.801144, Semantic loss: 0.720574, BCE loss: 0.514791, SB loss: 0.691195
2023-10-30 21:43:48,786 Epoch: [384/484] Iter:[260/495], Time: 0.37, lr: [0.0024075800464099023], Loss: 1.928863, Acc:0.801264, Semantic loss: 0.721533, BCE loss: 0.514938, SB loss: 0.692393
2023-10-30 21:43:52,504 Epoch: [384/484] Iter:[270/495], Time: 0.37, lr: [0.0024071399887238597], Loss: 1.937689, Acc:0.800652, Semantic loss: 0.725294, BCE loss: 0.518694, SB loss: 0.693701
2023-10-30 21:43:56,103 Epoch: [384/484] Iter:[280/495], Time: 0.37, lr: [0.0024066999220989163], Loss: 1.931386, Acc:0.799960, Semantic loss: 0.723580, BCE loss: 0.515476, SB loss: 0.692330
2023-10-30 21:43:59,775 Epoch: [384/484] Iter:[290/495], Time: 0.37, lr: [0.002406259846533073], Loss: 1.933525, Acc:0.801596, Semantic loss: 0.724401, BCE loss: 0.516803, SB loss: 0.692321
2023-10-30 21:44:03,367 Epoch: [384/484] Iter:[300/495], Time: 0.37, lr: [0.002405819762024331], Loss: 1.929711, Acc:0.800176, Semantic loss: 0.722998, BCE loss: 0.514553, SB loss: 0.692160
2023-10-30 21:44:07,012 Epoch: [384/484] Iter:[310/495], Time: 0.37, lr: [0.0024053796685706893], Loss: 1.932791, Acc:0.799438, Semantic loss: 0.724645, BCE loss: 0.515371, SB loss: 0.692775
2023-10-30 21:44:10,710 Epoch: [384/484] Iter:[320/495], Time: 0.37, lr: [0.0024049395661701507], Loss: 1.933298, Acc:0.799716, Semantic loss: 0.723294, BCE loss: 0.517524, SB loss: 0.692480
2023-10-30 21:44:14,499 Epoch: [384/484] Iter:[330/495], Time: 0.37, lr: [0.002404499454820713], Loss: 1.933692, Acc:0.801054, Semantic loss: 0.722325, BCE loss: 0.518775, SB loss: 0.692592
2023-10-30 21:44:18,227 Epoch: [384/484] Iter:[340/495], Time: 0.37, lr: [0.0024040593345203733], Loss: 1.940893, Acc:0.801748, Semantic loss: 0.730680, BCE loss: 0.517715, SB loss: 0.692498
2023-10-30 21:44:21,814 Epoch: [384/484] Iter:[350/495], Time: 0.37, lr: [0.0024036192052671284], Loss: 1.939114, Acc:0.802401, Semantic loss: 0.727975, BCE loss: 0.519099, SB loss: 0.692041
2023-10-30 21:44:25,425 Epoch: [384/484] Iter:[360/495], Time: 0.37, lr: [0.002403179067058976], Loss: 1.932658, Acc:0.802424, Semantic loss: 0.724898, BCE loss: 0.515978, SB loss: 0.691782
2023-10-30 21:44:29,087 Epoch: [384/484] Iter:[370/495], Time: 0.37, lr: [0.0024027389198939117], Loss: 1.932090, Acc:0.802410, Semantic loss: 0.723557, BCE loss: 0.516064, SB loss: 0.692469
2023-10-30 21:44:32,839 Epoch: [384/484] Iter:[380/495], Time: 0.37, lr: [0.0024022987637699286], Loss: 1.933893, Acc:0.803192, Semantic loss: 0.723554, BCE loss: 0.517598, SB loss: 0.692741
2023-10-30 21:44:36,470 Epoch: [384/484] Iter:[390/495], Time: 0.37, lr: [0.00240185859868502], Loss: 1.938005, Acc:0.804106, Semantic loss: 0.724472, BCE loss: 0.519914, SB loss: 0.693620
2023-10-30 21:44:40,054 Epoch: [384/484] Iter:[400/495], Time: 0.37, lr: [0.002401418424637181], Loss: 1.938022, Acc:0.803892, Semantic loss: 0.725720, BCE loss: 0.518109, SB loss: 0.694192
2023-10-30 21:44:43,702 Epoch: [384/484] Iter:[410/495], Time: 0.37, lr: [0.0024009782416244026], Loss: 1.935978, Acc:0.803765, Semantic loss: 0.725277, BCE loss: 0.516838, SB loss: 0.693862
2023-10-30 21:44:47,308 Epoch: [384/484] Iter:[420/495], Time: 0.37, lr: [0.0024005380496446758], Loss: 1.933481, Acc:0.803237, Semantic loss: 0.723761, BCE loss: 0.516498, SB loss: 0.693222
2023-10-30 21:44:50,854 Epoch: [384/484] Iter:[430/495], Time: 0.37, lr: [0.0024000978486959897], Loss: 1.930485, Acc:0.802799, Semantic loss: 0.722598, BCE loss: 0.515790, SB loss: 0.692097
2023-10-30 21:44:54,515 Epoch: [384/484] Iter:[440/495], Time: 0.37, lr: [0.002399657638776336], Loss: 1.926944, Acc:0.801926, Semantic loss: 0.722071, BCE loss: 0.513377, SB loss: 0.691496
2023-10-30 21:44:58,073 Epoch: [384/484] Iter:[450/495], Time: 0.37, lr: [0.0023992174198837015], Loss: 1.928919, Acc:0.802301, Semantic loss: 0.723258, BCE loss: 0.513241, SB loss: 0.692420
2023-10-30 21:45:01,793 Epoch: [384/484] Iter:[460/495], Time: 0.37, lr: [0.002398777192016075], Loss: 1.929374, Acc:0.802669, Semantic loss: 0.722986, BCE loss: 0.513758, SB loss: 0.692630
2023-10-30 21:45:05,359 Epoch: [384/484] Iter:[470/495], Time: 0.37, lr: [0.0023983369551714416], Loss: 1.928886, Acc:0.802706, Semantic loss: 0.723987, BCE loss: 0.512288, SB loss: 0.692611
2023-10-30 21:45:08,918 Epoch: [384/484] Iter:[480/495], Time: 0.37, lr: [0.0023978967093477898], Loss: 1.930007, Acc:0.802970, Semantic loss: 0.724610, BCE loss: 0.513157, SB loss: 0.692241
2023-10-30 21:45:12,327 Epoch: [384/484] Iter:[490/495], Time: 0.37, lr: [0.002397456454543103], Loss: 1.928423, Acc:0.802009, Semantic loss: 0.724082, BCE loss: 0.512195, SB loss: 0.692146
2023-10-30 21:48:09,223 0 [0.95022237 0.69138889 0.84181041 0.15156721 0.21552563 0.45082802
 0.51365569 0.59832887 0.89064488 0.49346583 0.88308644 0.6160572
 0.02713074 0.83970877 0.0081117  0.15460297 0.07676834 0.06865538
 0.61574673] 0.4782792660860965
2023-10-30 21:48:09,224 1 [0.97559013 0.81498302 0.91555519 0.46647921 0.49529295 0.61805809
 0.69939561 0.74692225 0.91081661 0.55473212 0.94373688 0.79660168
 0.57554296 0.9419921  0.69943184 0.8198255  0.7395645  0.57454945
 0.74895453] 0.7388434006060025
2023-10-30 21:48:09,227 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:48:09,466 Loss: 1.950, MeanIU:  0.7388, Best_mIoU:  0.7487
2023-10-30 21:48:09,466 [0.97559013 0.81498302 0.91555519 0.46647921 0.49529295 0.61805809
 0.69939561 0.74692225 0.91081661 0.55473212 0.94373688 0.79660168
 0.57554296 0.9419921  0.69943184 0.8198255  0.7395645  0.57454945
 0.74895453]
2023-10-30 21:48:11,488 Epoch: [385/484] Iter:[0/495], Time: 1.99, lr: [0.0023972363237722417], Loss: 1.768327, Acc:0.861297, Semantic loss: 0.621710, BCE loss: 0.485050, SB loss: 0.661567
2023-10-30 21:48:15,169 Epoch: [385/484] Iter:[10/495], Time: 0.52, lr: [0.002396796055492222], Loss: 1.781223, Acc:0.740469, Semantic loss: 0.674812, BCE loss: 0.415731, SB loss: 0.690680
2023-10-30 21:48:18,670 Epoch: [385/484] Iter:[20/495], Time: 0.44, lr: [0.0023963557782261283], Loss: 1.835516, Acc:0.788513, Semantic loss: 0.687721, BCE loss: 0.454836, SB loss: 0.692960
2023-10-30 21:48:22,136 Epoch: [385/484] Iter:[30/495], Time: 0.41, lr: [0.0023959154919719404], Loss: 1.882050, Acc:0.798197, Semantic loss: 0.702007, BCE loss: 0.487908, SB loss: 0.692135
2023-10-30 21:48:25,518 Epoch: [385/484] Iter:[40/495], Time: 0.39, lr: [0.0023954751967276405], Loss: 1.881671, Acc:0.800185, Semantic loss: 0.702057, BCE loss: 0.493113, SB loss: 0.686501
2023-10-30 21:48:28,942 Epoch: [385/484] Iter:[50/495], Time: 0.38, lr: [0.0023950348924912076], Loss: 1.873450, Acc:0.799306, Semantic loss: 0.703294, BCE loss: 0.483705, SB loss: 0.686452
2023-10-30 21:48:32,527 Epoch: [385/484] Iter:[60/495], Time: 0.38, lr: [0.002394594579260623], Loss: 1.885447, Acc:0.800151, Semantic loss: 0.698615, BCE loss: 0.499420, SB loss: 0.687412
2023-10-30 21:48:36,108 Epoch: [385/484] Iter:[70/495], Time: 0.37, lr: [0.0023941542570338646], Loss: 1.899133, Acc:0.800929, Semantic loss: 0.706687, BCE loss: 0.500043, SB loss: 0.692404
2023-10-30 21:48:39,547 Epoch: [385/484] Iter:[80/495], Time: 0.37, lr: [0.00239371392580891], Loss: 1.901646, Acc:0.806035, Semantic loss: 0.705537, BCE loss: 0.505925, SB loss: 0.690184
2023-10-30 21:48:43,020 Epoch: [385/484] Iter:[90/495], Time: 0.37, lr: [0.0023932735855837347], Loss: 1.898937, Acc:0.805745, Semantic loss: 0.703230, BCE loss: 0.507394, SB loss: 0.688314
2023-10-30 21:48:46,501 Epoch: [385/484] Iter:[100/495], Time: 0.37, lr: [0.002392833236356318], Loss: 1.910115, Acc:0.805720, Semantic loss: 0.707453, BCE loss: 0.509622, SB loss: 0.693040
2023-10-30 21:48:50,219 Epoch: [385/484] Iter:[110/495], Time: 0.37, lr: [0.0023923928781246326], Loss: 1.903530, Acc:0.804336, Semantic loss: 0.705785, BCE loss: 0.506767, SB loss: 0.690978
2023-10-30 21:48:53,840 Epoch: [385/484] Iter:[120/495], Time: 0.37, lr: [0.0023919525108866534], Loss: 1.912565, Acc:0.803152, Semantic loss: 0.709980, BCE loss: 0.508783, SB loss: 0.693802
2023-10-30 21:48:57,372 Epoch: [385/484] Iter:[130/495], Time: 0.37, lr: [0.0023915121346403524], Loss: 1.926108, Acc:0.804897, Semantic loss: 0.716065, BCE loss: 0.516022, SB loss: 0.694021
2023-10-30 21:49:00,986 Epoch: [385/484] Iter:[140/495], Time: 0.37, lr: [0.0023910717493837055], Loss: 1.925360, Acc:0.805927, Semantic loss: 0.715172, BCE loss: 0.516436, SB loss: 0.693752
2023-10-30 21:49:04,490 Epoch: [385/484] Iter:[150/495], Time: 0.36, lr: [0.0023906313551146814], Loss: 1.922928, Acc:0.804321, Semantic loss: 0.714330, BCE loss: 0.517079, SB loss: 0.691520
2023-10-30 21:49:08,076 Epoch: [385/484] Iter:[160/495], Time: 0.36, lr: [0.002390190951831252], Loss: 1.920086, Acc:0.803980, Semantic loss: 0.715755, BCE loss: 0.513736, SB loss: 0.690595
2023-10-30 21:49:11,773 Epoch: [385/484] Iter:[170/495], Time: 0.36, lr: [0.0023897505395313865], Loss: 1.920697, Acc:0.804130, Semantic loss: 0.715960, BCE loss: 0.512879, SB loss: 0.691858
2023-10-30 21:49:15,419 Epoch: [385/484] Iter:[180/495], Time: 0.36, lr: [0.002389310118213055], Loss: 1.915693, Acc:0.803604, Semantic loss: 0.715562, BCE loss: 0.506912, SB loss: 0.693219
2023-10-30 21:49:18,966 Epoch: [385/484] Iter:[190/495], Time: 0.36, lr: [0.0023888696878742255], Loss: 1.916092, Acc:0.806780, Semantic loss: 0.714205, BCE loss: 0.508866, SB loss: 0.693021
2023-10-30 21:49:22,486 Epoch: [385/484] Iter:[200/495], Time: 0.36, lr: [0.002388429248512865], Loss: 1.915138, Acc:0.806196, Semantic loss: 0.715268, BCE loss: 0.507715, SB loss: 0.692154
2023-10-30 21:49:26,080 Epoch: [385/484] Iter:[210/495], Time: 0.36, lr: [0.0023879888001269384], Loss: 1.911895, Acc:0.806601, Semantic loss: 0.714092, BCE loss: 0.507036, SB loss: 0.690767
2023-10-30 21:49:29,646 Epoch: [385/484] Iter:[220/495], Time: 0.36, lr: [0.002387548342714414], Loss: 1.912771, Acc:0.807163, Semantic loss: 0.713995, BCE loss: 0.508605, SB loss: 0.690170
2023-10-30 21:49:33,241 Epoch: [385/484] Iter:[230/495], Time: 0.36, lr: [0.002387107876273255], Loss: 1.916928, Acc:0.807970, Semantic loss: 0.714137, BCE loss: 0.513048, SB loss: 0.689744
2023-10-30 21:49:36,859 Epoch: [385/484] Iter:[240/495], Time: 0.36, lr: [0.0023866674008014253], Loss: 1.921015, Acc:0.810204, Semantic loss: 0.715458, BCE loss: 0.516187, SB loss: 0.689370
2023-10-30 21:49:40,361 Epoch: [385/484] Iter:[250/495], Time: 0.36, lr: [0.0023862269162968873], Loss: 1.924881, Acc:0.809938, Semantic loss: 0.716557, BCE loss: 0.517614, SB loss: 0.690710
2023-10-30 21:49:44,202 Epoch: [385/484] Iter:[260/495], Time: 0.36, lr: [0.0023857864227576045], Loss: 1.919600, Acc:0.808640, Semantic loss: 0.714984, BCE loss: 0.514729, SB loss: 0.689888
2023-10-30 21:49:47,886 Epoch: [385/484] Iter:[270/495], Time: 0.36, lr: [0.0023853459201815374], Loss: 1.924268, Acc:0.809559, Semantic loss: 0.716794, BCE loss: 0.516793, SB loss: 0.690682
2023-10-30 21:49:51,442 Epoch: [385/484] Iter:[280/495], Time: 0.36, lr: [0.0023849054085666455], Loss: 1.920982, Acc:0.809929, Semantic loss: 0.714948, BCE loss: 0.516159, SB loss: 0.689875
2023-10-30 21:49:54,978 Epoch: [385/484] Iter:[290/495], Time: 0.36, lr: [0.0023844648879108882], Loss: 1.921089, Acc:0.809401, Semantic loss: 0.715362, BCE loss: 0.516144, SB loss: 0.689583
2023-10-30 21:49:58,535 Epoch: [385/484] Iter:[300/495], Time: 0.36, lr: [0.0023840243582122253], Loss: 1.919179, Acc:0.809198, Semantic loss: 0.714800, BCE loss: 0.514961, SB loss: 0.689418
2023-10-30 21:50:02,135 Epoch: [385/484] Iter:[310/495], Time: 0.36, lr: [0.002383583819468614], Loss: 1.919375, Acc:0.808767, Semantic loss: 0.715953, BCE loss: 0.513692, SB loss: 0.689730
2023-10-30 21:50:05,850 Epoch: [385/484] Iter:[320/495], Time: 0.36, lr: [0.0023831432716780107], Loss: 1.916654, Acc:0.808465, Semantic loss: 0.714658, BCE loss: 0.513236, SB loss: 0.688761
2023-10-30 21:50:09,484 Epoch: [385/484] Iter:[330/495], Time: 0.36, lr: [0.0023827027148383704], Loss: 1.916805, Acc:0.806189, Semantic loss: 0.715834, BCE loss: 0.511938, SB loss: 0.689033
2023-10-30 21:50:12,945 Epoch: [385/484] Iter:[340/495], Time: 0.36, lr: [0.0023822621489476502], Loss: 1.917175, Acc:0.806707, Semantic loss: 0.716820, BCE loss: 0.510954, SB loss: 0.689402
2023-10-30 21:50:16,496 Epoch: [385/484] Iter:[350/495], Time: 0.36, lr: [0.002381821574003803], Loss: 1.914779, Acc:0.807022, Semantic loss: 0.715597, BCE loss: 0.510149, SB loss: 0.689033
2023-10-30 21:50:20,173 Epoch: [385/484] Iter:[360/495], Time: 0.36, lr: [0.0023813809900047824], Loss: 1.914206, Acc:0.806878, Semantic loss: 0.716200, BCE loss: 0.508896, SB loss: 0.689110
2023-10-30 21:50:23,760 Epoch: [385/484] Iter:[370/495], Time: 0.36, lr: [0.002380940396948539], Loss: 1.915091, Acc:0.806965, Semantic loss: 0.716752, BCE loss: 0.508574, SB loss: 0.689764
2023-10-30 21:50:27,389 Epoch: [385/484] Iter:[380/495], Time: 0.36, lr: [0.0023804997948330265], Loss: 1.916685, Acc:0.806842, Semantic loss: 0.717580, BCE loss: 0.509191, SB loss: 0.689914
2023-10-30 21:50:31,041 Epoch: [385/484] Iter:[390/495], Time: 0.36, lr: [0.0023800591836561956], Loss: 1.920354, Acc:0.806598, Semantic loss: 0.719520, BCE loss: 0.510163, SB loss: 0.690671
2023-10-30 21:50:34,528 Epoch: [385/484] Iter:[400/495], Time: 0.36, lr: [0.0023796185634159936], Loss: 1.921265, Acc:0.806288, Semantic loss: 0.720455, BCE loss: 0.509907, SB loss: 0.690902
2023-10-30 21:50:38,126 Epoch: [385/484] Iter:[410/495], Time: 0.36, lr: [0.002379177934110372], Loss: 1.920864, Acc:0.805759, Semantic loss: 0.720647, BCE loss: 0.509486, SB loss: 0.690731
2023-10-30 21:50:41,726 Epoch: [385/484] Iter:[420/495], Time: 0.36, lr: [0.0023787372957372777], Loss: 1.920233, Acc:0.805495, Semantic loss: 0.720588, BCE loss: 0.509225, SB loss: 0.690420
2023-10-30 21:50:45,336 Epoch: [385/484] Iter:[430/495], Time: 0.36, lr: [0.0023782966482946573], Loss: 1.921037, Acc:0.804808, Semantic loss: 0.720736, BCE loss: 0.509218, SB loss: 0.691082
2023-10-30 21:50:48,860 Epoch: [385/484] Iter:[440/495], Time: 0.36, lr: [0.0023778559917804563], Loss: 1.922813, Acc:0.804524, Semantic loss: 0.721240, BCE loss: 0.510208, SB loss: 0.691365
2023-10-30 21:50:52,544 Epoch: [385/484] Iter:[450/495], Time: 0.36, lr: [0.002377415326192622], Loss: 1.924203, Acc:0.804160, Semantic loss: 0.721654, BCE loss: 0.510981, SB loss: 0.691567
2023-10-30 21:50:56,163 Epoch: [385/484] Iter:[460/495], Time: 0.36, lr: [0.0023769746515290976], Loss: 1.921710, Acc:0.804345, Semantic loss: 0.720291, BCE loss: 0.510319, SB loss: 0.691100
2023-10-30 21:50:59,847 Epoch: [385/484] Iter:[470/495], Time: 0.36, lr: [0.002376533967787827], Loss: 1.921833, Acc:0.803598, Semantic loss: 0.720214, BCE loss: 0.510744, SB loss: 0.690875
2023-10-30 21:51:03,453 Epoch: [385/484] Iter:[480/495], Time: 0.36, lr: [0.002376093274966751], Loss: 1.922141, Acc:0.803467, Semantic loss: 0.720331, BCE loss: 0.511105, SB loss: 0.690705
2023-10-30 21:51:06,897 Epoch: [385/484] Iter:[490/495], Time: 0.36, lr: [0.002375652573063814], Loss: 1.920836, Acc:0.803449, Semantic loss: 0.719598, BCE loss: 0.510892, SB loss: 0.690347
2023-10-30 21:54:04,678 0 [0.95011753 0.6919894  0.84848321 0.15193881 0.32440954 0.4307893
 0.48981473 0.62790766 0.89032421 0.45940222 0.88568687 0.62842347
 0.0718344  0.82410735 0.00479605 0.13724152 0.09804662 0.05870311
 0.62908317] 0.48437364098217633
2023-10-30 21:54:04,678 1 [0.97764668 0.82176935 0.91637324 0.48393428 0.57289515 0.59564066
 0.68738159 0.76338014 0.91834838 0.59670016 0.9381097  0.79813426
 0.58379903 0.94163995 0.71376983 0.79178286 0.68151611 0.56050382
 0.75179992] 0.741848689890589
2023-10-30 21:54:04,682 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 21:54:04,913 Loss: 1.983, MeanIU:  0.7418, Best_mIoU:  0.7487
2023-10-30 21:54:04,913 [0.97764668 0.82176935 0.91637324 0.48393428 0.57289515 0.59564066
 0.68738159 0.76338014 0.91834838 0.59670016 0.9381097  0.79813426
 0.58379903 0.94163995 0.71376983 0.79178286 0.68151611 0.56050382
 0.75179992]
2023-10-30 21:54:07,068 Epoch: [386/484] Iter:[0/495], Time: 2.12, lr: [0.0023754322187060036], Loss: 2.028636, Acc:0.838886, Semantic loss: 0.832675, BCE loss: 0.451317, SB loss: 0.744644
2023-10-30 21:54:10,859 Epoch: [386/484] Iter:[10/495], Time: 0.54, lr: [0.002374991503176412], Loss: 1.938455, Acc:0.832562, Semantic loss: 0.714572, BCE loss: 0.542444, SB loss: 0.681439
2023-10-30 21:54:14,426 Epoch: [386/484] Iter:[20/495], Time: 0.45, lr: [0.002374550778559808], Loss: 1.891488, Acc:0.827757, Semantic loss: 0.687052, BCE loss: 0.535687, SB loss: 0.668749
2023-10-30 21:54:17,902 Epoch: [386/484] Iter:[30/495], Time: 0.42, lr: [0.0023741100448541304], Loss: 1.925636, Acc:0.841935, Semantic loss: 0.702891, BCE loss: 0.543625, SB loss: 0.679119
2023-10-30 21:54:21,390 Epoch: [386/484] Iter:[40/495], Time: 0.40, lr: [0.002373669302057318], Loss: 1.929163, Acc:0.827867, Semantic loss: 0.712921, BCE loss: 0.534042, SB loss: 0.682200
2023-10-30 21:54:24,855 Epoch: [386/484] Iter:[50/495], Time: 0.39, lr: [0.002373228550167307], Loss: 1.935143, Acc:0.830464, Semantic loss: 0.711324, BCE loss: 0.540041, SB loss: 0.683778
2023-10-30 21:54:28,348 Epoch: [386/484] Iter:[60/495], Time: 0.38, lr: [0.0023727877891820326], Loss: 1.943557, Acc:0.827280, Semantic loss: 0.714935, BCE loss: 0.544903, SB loss: 0.683719
2023-10-30 21:54:31,885 Epoch: [386/484] Iter:[70/495], Time: 0.38, lr: [0.0023723470190994294], Loss: 1.948640, Acc:0.824284, Semantic loss: 0.719792, BCE loss: 0.542051, SB loss: 0.686798
2023-10-30 21:54:35,437 Epoch: [386/484] Iter:[80/495], Time: 0.38, lr: [0.0023719062399174336], Loss: 1.954771, Acc:0.819782, Semantic loss: 0.736676, BCE loss: 0.530826, SB loss: 0.687268
2023-10-30 21:54:38,962 Epoch: [386/484] Iter:[90/495], Time: 0.37, lr: [0.002371465451633977], Loss: 1.940795, Acc:0.820737, Semantic loss: 0.732119, BCE loss: 0.519530, SB loss: 0.689145
2023-10-30 21:54:42,427 Epoch: [386/484] Iter:[100/495], Time: 0.37, lr: [0.0023710246542469923], Loss: 1.944069, Acc:0.817721, Semantic loss: 0.733902, BCE loss: 0.521119, SB loss: 0.689048
2023-10-30 21:54:45,994 Epoch: [386/484] Iter:[110/495], Time: 0.37, lr: [0.0023705838477544095], Loss: 1.942534, Acc:0.814171, Semantic loss: 0.731917, BCE loss: 0.520502, SB loss: 0.690115
2023-10-30 21:54:49,536 Epoch: [386/484] Iter:[120/495], Time: 0.37, lr: [0.0023701430321541616], Loss: 1.942558, Acc:0.814873, Semantic loss: 0.731048, BCE loss: 0.520176, SB loss: 0.691334
2023-10-30 21:54:53,125 Epoch: [386/484] Iter:[130/495], Time: 0.37, lr: [0.0023697022074441773], Loss: 1.937569, Acc:0.813751, Semantic loss: 0.730887, BCE loss: 0.516068, SB loss: 0.690614
2023-10-30 21:54:56,678 Epoch: [386/484] Iter:[140/495], Time: 0.37, lr: [0.0023692613736223844], Loss: 1.941597, Acc:0.815877, Semantic loss: 0.727924, BCE loss: 0.523322, SB loss: 0.690351
2023-10-30 21:55:00,228 Epoch: [386/484] Iter:[150/495], Time: 0.37, lr: [0.0023688205306867105], Loss: 1.942666, Acc:0.811373, Semantic loss: 0.727886, BCE loss: 0.523696, SB loss: 0.691084
2023-10-30 21:55:03,736 Epoch: [386/484] Iter:[160/495], Time: 0.37, lr: [0.0023683796786350846], Loss: 1.935969, Acc:0.812067, Semantic loss: 0.723868, BCE loss: 0.522052, SB loss: 0.690049
2023-10-30 21:55:07,218 Epoch: [386/484] Iter:[170/495], Time: 0.36, lr: [0.0023679388174654317], Loss: 1.943191, Acc:0.814106, Semantic loss: 0.726377, BCE loss: 0.525563, SB loss: 0.691251
2023-10-30 21:55:10,822 Epoch: [386/484] Iter:[180/495], Time: 0.36, lr: [0.0023674979471756765], Loss: 1.941853, Acc:0.813122, Semantic loss: 0.725146, BCE loss: 0.525793, SB loss: 0.690915
2023-10-30 21:55:14,478 Epoch: [386/484] Iter:[190/495], Time: 0.36, lr: [0.0023670570677637426], Loss: 1.937907, Acc:0.813646, Semantic loss: 0.724761, BCE loss: 0.523808, SB loss: 0.689338
2023-10-30 21:55:18,097 Epoch: [386/484] Iter:[200/495], Time: 0.36, lr: [0.002366616179227555], Loss: 1.935232, Acc:0.812002, Semantic loss: 0.723531, BCE loss: 0.522591, SB loss: 0.689110
2023-10-30 21:55:21,652 Epoch: [386/484] Iter:[210/495], Time: 0.36, lr: [0.0023661752815650355], Loss: 1.932425, Acc:0.810476, Semantic loss: 0.722274, BCE loss: 0.521992, SB loss: 0.688159
2023-10-30 21:55:25,227 Epoch: [386/484] Iter:[220/495], Time: 0.36, lr: [0.0023657343747741045], Loss: 1.930930, Acc:0.811428, Semantic loss: 0.721384, BCE loss: 0.521868, SB loss: 0.687677
2023-10-30 21:55:28,831 Epoch: [386/484] Iter:[230/495], Time: 0.36, lr: [0.0023652934588526847], Loss: 1.929373, Acc:0.811675, Semantic loss: 0.721662, BCE loss: 0.520023, SB loss: 0.687688
2023-10-30 21:55:32,383 Epoch: [386/484] Iter:[240/495], Time: 0.36, lr: [0.0023648525337986942], Loss: 1.928363, Acc:0.810467, Semantic loss: 0.721360, BCE loss: 0.519326, SB loss: 0.687676
2023-10-30 21:55:35,971 Epoch: [386/484] Iter:[250/495], Time: 0.36, lr: [0.0023644115996100524], Loss: 1.931444, Acc:0.809570, Semantic loss: 0.723127, BCE loss: 0.519850, SB loss: 0.688467
2023-10-30 21:55:39,484 Epoch: [386/484] Iter:[260/495], Time: 0.36, lr: [0.002363970656284676], Loss: 1.923768, Acc:0.808661, Semantic loss: 0.720047, BCE loss: 0.516344, SB loss: 0.687377
2023-10-30 21:55:43,180 Epoch: [386/484] Iter:[270/495], Time: 0.36, lr: [0.0023635297038204846], Loss: 1.924088, Acc:0.807716, Semantic loss: 0.720128, BCE loss: 0.516097, SB loss: 0.687863
2023-10-30 21:55:46,793 Epoch: [386/484] Iter:[280/495], Time: 0.36, lr: [0.002363088742215392], Loss: 1.919412, Acc:0.807494, Semantic loss: 0.718187, BCE loss: 0.513947, SB loss: 0.687279
2023-10-30 21:55:50,373 Epoch: [386/484] Iter:[290/495], Time: 0.36, lr: [0.0023626477714673148], Loss: 1.922964, Acc:0.807307, Semantic loss: 0.719556, BCE loss: 0.514884, SB loss: 0.688524
2023-10-30 21:55:53,942 Epoch: [386/484] Iter:[300/495], Time: 0.36, lr: [0.002362206791574165], Loss: 1.927400, Acc:0.809007, Semantic loss: 0.720811, BCE loss: 0.517277, SB loss: 0.689312
2023-10-30 21:55:57,614 Epoch: [386/484] Iter:[310/495], Time: 0.36, lr: [0.002361765802533859], Loss: 1.924704, Acc:0.807707, Semantic loss: 0.720415, BCE loss: 0.515342, SB loss: 0.688947
2023-10-30 21:56:01,246 Epoch: [386/484] Iter:[320/495], Time: 0.36, lr: [0.002361324804344308], Loss: 1.926010, Acc:0.807585, Semantic loss: 0.721984, BCE loss: 0.515386, SB loss: 0.688639
2023-10-30 21:56:05,035 Epoch: [386/484] Iter:[330/495], Time: 0.36, lr: [0.0023608837970034227], Loss: 1.925970, Acc:0.808203, Semantic loss: 0.721926, BCE loss: 0.515645, SB loss: 0.688399
2023-10-30 21:56:08,629 Epoch: [386/484] Iter:[340/495], Time: 0.36, lr: [0.0023604427805091134], Loss: 1.923033, Acc:0.809057, Semantic loss: 0.720549, BCE loss: 0.514930, SB loss: 0.687554
2023-10-30 21:56:12,163 Epoch: [386/484] Iter:[350/495], Time: 0.36, lr: [0.0023600017548592923], Loss: 1.922374, Acc:0.809089, Semantic loss: 0.720677, BCE loss: 0.513918, SB loss: 0.687779
2023-10-30 21:56:15,736 Epoch: [386/484] Iter:[360/495], Time: 0.36, lr: [0.0023595607200518664], Loss: 1.921665, Acc:0.809253, Semantic loss: 0.720720, BCE loss: 0.513350, SB loss: 0.687596
2023-10-30 21:56:19,419 Epoch: [386/484] Iter:[370/495], Time: 0.36, lr: [0.002359119676084744], Loss: 1.926125, Acc:0.809806, Semantic loss: 0.723314, BCE loss: 0.513762, SB loss: 0.689049
2023-10-30 21:56:23,090 Epoch: [386/484] Iter:[380/495], Time: 0.36, lr: [0.002358678622955831], Loss: 1.925664, Acc:0.810392, Semantic loss: 0.723070, BCE loss: 0.513565, SB loss: 0.689029
2023-10-30 21:56:26,672 Epoch: [386/484] Iter:[390/495], Time: 0.36, lr: [0.0023582375606630355], Loss: 1.930584, Acc:0.810389, Semantic loss: 0.726929, BCE loss: 0.513543, SB loss: 0.690113
2023-10-30 21:56:30,278 Epoch: [386/484] Iter:[400/495], Time: 0.36, lr: [0.002357796489204262], Loss: 1.929564, Acc:0.809750, Semantic loss: 0.726061, BCE loss: 0.513677, SB loss: 0.689825
2023-10-30 21:56:33,910 Epoch: [386/484] Iter:[410/495], Time: 0.36, lr: [0.002357355408577414], Loss: 1.933323, Acc:0.809407, Semantic loss: 0.726154, BCE loss: 0.515453, SB loss: 0.691716
2023-10-30 21:56:37,475 Epoch: [386/484] Iter:[420/495], Time: 0.36, lr: [0.002356914318780394], Loss: 1.934100, Acc:0.809740, Semantic loss: 0.725348, BCE loss: 0.516718, SB loss: 0.692034
2023-10-30 21:56:41,047 Epoch: [386/484] Iter:[430/495], Time: 0.36, lr: [0.002356473219811107], Loss: 1.932287, Acc:0.810058, Semantic loss: 0.724611, BCE loss: 0.516280, SB loss: 0.691396
2023-10-30 21:56:44,540 Epoch: [386/484] Iter:[440/495], Time: 0.36, lr: [0.0023560321116674527], Loss: 1.932969, Acc:0.809539, Semantic loss: 0.725200, BCE loss: 0.515311, SB loss: 0.692458
2023-10-30 21:56:48,177 Epoch: [386/484] Iter:[450/495], Time: 0.36, lr: [0.0023555909943473326], Loss: 1.930567, Acc:0.809414, Semantic loss: 0.724472, BCE loss: 0.513833, SB loss: 0.692263
2023-10-30 21:56:51,741 Epoch: [386/484] Iter:[460/495], Time: 0.36, lr: [0.0023551498678486445], Loss: 1.928669, Acc:0.809913, Semantic loss: 0.723374, BCE loss: 0.513236, SB loss: 0.692059
2023-10-30 21:56:55,441 Epoch: [386/484] Iter:[470/495], Time: 0.36, lr: [0.0023547087321692897], Loss: 1.930225, Acc:0.809584, Semantic loss: 0.724122, BCE loss: 0.513388, SB loss: 0.692714
2023-10-30 21:56:59,056 Epoch: [386/484] Iter:[480/495], Time: 0.36, lr: [0.0023542675873071644], Loss: 1.934623, Acc:0.810194, Semantic loss: 0.726635, BCE loss: 0.514345, SB loss: 0.693643
2023-10-30 21:57:02,430 Epoch: [386/484] Iter:[490/495], Time: 0.36, lr: [0.0023538264332601663], Loss: 1.933200, Acc:0.810022, Semantic loss: 0.726589, BCE loss: 0.513364, SB loss: 0.693247
2023-10-30 21:59:59,871 0 [0.94720759 0.68916045 0.84613447 0.13298775 0.2794945  0.4454921
 0.50010953 0.60918405 0.8918229  0.48902653 0.8795222  0.62603185
 0.10273186 0.82478668 0.01625145 0.14296495 0.07945677 0.13263664
 0.62277765] 0.4872515749926338
2023-10-30 21:59:59,871 1 [0.97183023 0.78843796 0.91244397 0.4301268  0.55437798 0.60892396
 0.68375555 0.7543885  0.9169945  0.58609917 0.93467371 0.79627349
 0.58011045 0.93263877 0.65521038 0.78242201 0.66021686 0.42711212
 0.74851608] 0.7223448677347862
2023-10-30 21:59:59,875 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 22:00:00,112 Loss: 1.927, MeanIU:  0.7223, Best_mIoU:  0.7487
2023-10-30 22:00:00,112 [0.97183023 0.78843796 0.91244397 0.4301268  0.55437798 0.60892396
 0.68375555 0.7543885  0.9169945  0.58609917 0.93467371 0.79627349
 0.58011045 0.93263877 0.65521038 0.78242201 0.66021686 0.42711212
 0.74851608]
2023-10-30 22:00:02,413 Epoch: [387/484] Iter:[0/495], Time: 2.27, lr: [0.0023536058527916827], Loss: 1.671034, Acc:0.900246, Semantic loss: 0.550668, BCE loss: 0.511294, SB loss: 0.609072
2023-10-30 22:00:06,103 Epoch: [387/484] Iter:[10/495], Time: 0.54, lr: [0.0023531646849634285], Loss: 1.830564, Acc:0.813297, Semantic loss: 0.628913, BCE loss: 0.527511, SB loss: 0.674140
2023-10-30 22:00:09,619 Epoch: [387/484] Iter:[20/495], Time: 0.45, lr: [0.0023527235079450403], Loss: 1.895475, Acc:0.813590, Semantic loss: 0.688249, BCE loss: 0.499757, SB loss: 0.707468
2023-10-30 22:00:13,016 Epoch: [387/484] Iter:[30/495], Time: 0.42, lr: [0.0023522823217344106], Loss: 1.856478, Acc:0.818799, Semantic loss: 0.660424, BCE loss: 0.506878, SB loss: 0.689176
2023-10-30 22:00:16,500 Epoch: [387/484] Iter:[40/495], Time: 0.40, lr: [0.002351841126329432], Loss: 1.842030, Acc:0.805402, Semantic loss: 0.666459, BCE loss: 0.494570, SB loss: 0.681001
2023-10-30 22:00:20,002 Epoch: [387/484] Iter:[50/495], Time: 0.39, lr: [0.002351399921727998], Loss: 1.879554, Acc:0.803363, Semantic loss: 0.688181, BCE loss: 0.504354, SB loss: 0.687019
2023-10-30 22:00:23,603 Epoch: [387/484] Iter:[60/495], Time: 0.38, lr: [0.0023509587079279977], Loss: 1.882740, Acc:0.800838, Semantic loss: 0.691864, BCE loss: 0.504765, SB loss: 0.686112
2023-10-30 22:00:27,092 Epoch: [387/484] Iter:[70/495], Time: 0.38, lr: [0.0023505174849273217], Loss: 1.877480, Acc:0.802026, Semantic loss: 0.689704, BCE loss: 0.501045, SB loss: 0.686730
2023-10-30 22:00:30,613 Epoch: [387/484] Iter:[80/495], Time: 0.38, lr: [0.0023500762527238583], Loss: 1.892783, Acc:0.802673, Semantic loss: 0.696372, BCE loss: 0.508369, SB loss: 0.688042
2023-10-30 22:00:34,272 Epoch: [387/484] Iter:[90/495], Time: 0.37, lr: [0.0023496350113154972], Loss: 1.901730, Acc:0.802950, Semantic loss: 0.699637, BCE loss: 0.511492, SB loss: 0.690601
2023-10-30 22:00:37,748 Epoch: [387/484] Iter:[100/495], Time: 0.37, lr: [0.002349193760700125], Loss: 1.903898, Acc:0.801247, Semantic loss: 0.699111, BCE loss: 0.514889, SB loss: 0.689898
2023-10-30 22:00:41,285 Epoch: [387/484] Iter:[110/495], Time: 0.37, lr: [0.002348752500875628], Loss: 1.902438, Acc:0.801884, Semantic loss: 0.697702, BCE loss: 0.515336, SB loss: 0.689401
2023-10-30 22:00:44,986 Epoch: [387/484] Iter:[120/495], Time: 0.37, lr: [0.00234831123183989], Loss: 1.904782, Acc:0.802379, Semantic loss: 0.701349, BCE loss: 0.513884, SB loss: 0.689549
2023-10-30 22:00:48,406 Epoch: [387/484] Iter:[130/495], Time: 0.37, lr: [0.002347869953590798], Loss: 1.903541, Acc:0.800063, Semantic loss: 0.702077, BCE loss: 0.512521, SB loss: 0.688943
2023-10-30 22:00:51,918 Epoch: [387/484] Iter:[140/495], Time: 0.37, lr: [0.0023474286661262344], Loss: 1.901815, Acc:0.797612, Semantic loss: 0.703828, BCE loss: 0.508863, SB loss: 0.689124
2023-10-30 22:00:55,466 Epoch: [387/484] Iter:[150/495], Time: 0.37, lr: [0.0023469873694440817], Loss: 1.904232, Acc:0.798664, Semantic loss: 0.705210, BCE loss: 0.510275, SB loss: 0.688746
2023-10-30 22:00:58,948 Epoch: [387/484] Iter:[160/495], Time: 0.37, lr: [0.0023465460635422202], Loss: 1.907902, Acc:0.798388, Semantic loss: 0.706712, BCE loss: 0.510278, SB loss: 0.690912
2023-10-30 22:01:02,564 Epoch: [387/484] Iter:[170/495], Time: 0.36, lr: [0.0023461047484185336], Loss: 1.910910, Acc:0.795553, Semantic loss: 0.708966, BCE loss: 0.509105, SB loss: 0.692838
2023-10-30 22:01:06,104 Epoch: [387/484] Iter:[180/495], Time: 0.36, lr: [0.0023456634240709], Loss: 1.906043, Acc:0.796884, Semantic loss: 0.706843, BCE loss: 0.507684, SB loss: 0.691516
2023-10-30 22:01:09,773 Epoch: [387/484] Iter:[190/495], Time: 0.36, lr: [0.0023452220904971984], Loss: 1.909018, Acc:0.796984, Semantic loss: 0.707430, BCE loss: 0.510611, SB loss: 0.690976
2023-10-30 22:01:13,375 Epoch: [387/484] Iter:[200/495], Time: 0.36, lr: [0.0023447807476953053], Loss: 1.905316, Acc:0.799562, Semantic loss: 0.707566, BCE loss: 0.507726, SB loss: 0.690023
2023-10-30 22:01:16,935 Epoch: [387/484] Iter:[210/495], Time: 0.36, lr: [0.0023443393956631003], Loss: 1.904543, Acc:0.799715, Semantic loss: 0.707787, BCE loss: 0.507610, SB loss: 0.689146
2023-10-30 22:01:20,458 Epoch: [387/484] Iter:[220/495], Time: 0.36, lr: [0.0023438980343984585], Loss: 1.900326, Acc:0.801053, Semantic loss: 0.706008, BCE loss: 0.505926, SB loss: 0.688392
2023-10-30 22:01:24,050 Epoch: [387/484] Iter:[230/495], Time: 0.36, lr: [0.002343456663899255], Loss: 1.896066, Acc:0.801378, Semantic loss: 0.704105, BCE loss: 0.504301, SB loss: 0.687660
2023-10-30 22:01:27,744 Epoch: [387/484] Iter:[240/495], Time: 0.36, lr: [0.0023430152841633625], Loss: 1.891782, Acc:0.801382, Semantic loss: 0.703677, BCE loss: 0.501487, SB loss: 0.686618
2023-10-30 22:01:31,340 Epoch: [387/484] Iter:[250/495], Time: 0.36, lr: [0.0023425738951886564], Loss: 1.893528, Acc:0.802465, Semantic loss: 0.704863, BCE loss: 0.502169, SB loss: 0.686496
2023-10-30 22:01:34,900 Epoch: [387/484] Iter:[260/495], Time: 0.36, lr: [0.0023421324969730086], Loss: 1.890016, Acc:0.802108, Semantic loss: 0.704151, BCE loss: 0.499642, SB loss: 0.686224
2023-10-30 22:01:38,519 Epoch: [387/484] Iter:[270/495], Time: 0.36, lr: [0.0023416910895142896], Loss: 1.889964, Acc:0.801360, Semantic loss: 0.705192, BCE loss: 0.497660, SB loss: 0.687112
2023-10-30 22:01:42,151 Epoch: [387/484] Iter:[280/495], Time: 0.36, lr: [0.0023412496728103696], Loss: 1.889653, Acc:0.800204, Semantic loss: 0.706514, BCE loss: 0.495677, SB loss: 0.687462
2023-10-30 22:01:45,852 Epoch: [387/484] Iter:[290/495], Time: 0.36, lr: [0.00234080824685912], Loss: 1.890131, Acc:0.801502, Semantic loss: 0.706917, BCE loss: 0.495666, SB loss: 0.687547
2023-10-30 22:01:49,447 Epoch: [387/484] Iter:[300/495], Time: 0.36, lr: [0.0023403668116584084], Loss: 1.894254, Acc:0.801521, Semantic loss: 0.708190, BCE loss: 0.498030, SB loss: 0.688035
2023-10-30 22:01:53,106 Epoch: [387/484] Iter:[310/495], Time: 0.36, lr: [0.002339925367206102], Loss: 1.898533, Acc:0.801286, Semantic loss: 0.709895, BCE loss: 0.499354, SB loss: 0.689285
2023-10-30 22:01:56,709 Epoch: [387/484] Iter:[320/495], Time: 0.36, lr: [0.002339483913500067], Loss: 1.899521, Acc:0.801396, Semantic loss: 0.710143, BCE loss: 0.499998, SB loss: 0.689379
2023-10-30 22:02:00,239 Epoch: [387/484] Iter:[330/495], Time: 0.36, lr: [0.0023390424505381714], Loss: 1.903561, Acc:0.801959, Semantic loss: 0.711637, BCE loss: 0.502106, SB loss: 0.689819
2023-10-30 22:02:03,803 Epoch: [387/484] Iter:[340/495], Time: 0.36, lr: [0.002338600978318278], Loss: 1.903689, Acc:0.802456, Semantic loss: 0.711815, BCE loss: 0.502317, SB loss: 0.689556
2023-10-30 22:02:07,458 Epoch: [387/484] Iter:[350/495], Time: 0.36, lr: [0.0023381594968382518], Loss: 1.907211, Acc:0.803211, Semantic loss: 0.713960, BCE loss: 0.502969, SB loss: 0.690281
2023-10-30 22:02:11,114 Epoch: [387/484] Iter:[360/495], Time: 0.36, lr: [0.002337718006095954], Loss: 1.908157, Acc:0.803603, Semantic loss: 0.714537, BCE loss: 0.502931, SB loss: 0.690689
2023-10-30 22:02:14,786 Epoch: [387/484] Iter:[370/495], Time: 0.36, lr: [0.002337276506089249], Loss: 1.909513, Acc:0.803870, Semantic loss: 0.715323, BCE loss: 0.503528, SB loss: 0.690662
2023-10-30 22:02:18,397 Epoch: [387/484] Iter:[380/495], Time: 0.36, lr: [0.0023368349968159972], Loss: 1.910826, Acc:0.805174, Semantic loss: 0.715136, BCE loss: 0.504765, SB loss: 0.690925
2023-10-30 22:02:21,899 Epoch: [387/484] Iter:[390/495], Time: 0.36, lr: [0.002336393478274058], Loss: 1.911209, Acc:0.805195, Semantic loss: 0.715319, BCE loss: 0.505196, SB loss: 0.690694
2023-10-30 22:02:25,486 Epoch: [387/484] Iter:[400/495], Time: 0.36, lr: [0.0023359519504612893], Loss: 1.912149, Acc:0.804600, Semantic loss: 0.715491, BCE loss: 0.505901, SB loss: 0.690757
2023-10-30 22:02:29,093 Epoch: [387/484] Iter:[410/495], Time: 0.36, lr: [0.0023355104133755524], Loss: 1.913493, Acc:0.805134, Semantic loss: 0.715963, BCE loss: 0.507457, SB loss: 0.690073
2023-10-30 22:02:32,812 Epoch: [387/484] Iter:[420/495], Time: 0.36, lr: [0.002335068867014703], Loss: 1.914219, Acc:0.806296, Semantic loss: 0.715975, BCE loss: 0.508861, SB loss: 0.689383
2023-10-30 22:02:36,421 Epoch: [387/484] Iter:[430/495], Time: 0.36, lr: [0.0023346273113765974], Loss: 1.922085, Acc:0.806355, Semantic loss: 0.720113, BCE loss: 0.510935, SB loss: 0.691037
2023-10-30 22:02:40,153 Epoch: [387/484] Iter:[440/495], Time: 0.36, lr: [0.0023341857464590906], Loss: 1.921096, Acc:0.805702, Semantic loss: 0.718347, BCE loss: 0.511384, SB loss: 0.691365
2023-10-30 22:02:43,782 Epoch: [387/484] Iter:[450/495], Time: 0.36, lr: [0.002333744172260038], Loss: 1.926704, Acc:0.806113, Semantic loss: 0.720018, BCE loss: 0.513583, SB loss: 0.693103
2023-10-30 22:02:47,516 Epoch: [387/484] Iter:[460/495], Time: 0.36, lr: [0.0023333025887772928], Loss: 1.923207, Acc:0.805988, Semantic loss: 0.719097, BCE loss: 0.511804, SB loss: 0.692306
2023-10-30 22:02:51,117 Epoch: [387/484] Iter:[470/495], Time: 0.36, lr: [0.0023328609960087078], Loss: 1.923001, Acc:0.805858, Semantic loss: 0.719861, BCE loss: 0.510614, SB loss: 0.692527
2023-10-30 22:02:54,695 Epoch: [387/484] Iter:[480/495], Time: 0.36, lr: [0.002332419393952133], Loss: 1.923934, Acc:0.805932, Semantic loss: 0.720172, BCE loss: 0.511025, SB loss: 0.692737
2023-10-30 22:02:58,107 Epoch: [387/484] Iter:[490/495], Time: 0.36, lr: [0.0023319777826054213], Loss: 1.923873, Acc:0.805989, Semantic loss: 0.719930, BCE loss: 0.511612, SB loss: 0.692331
2023-10-30 22:05:54,375 0 [0.9477274  0.68180969 0.83367413 0.10793345 0.22902057 0.44737667
 0.51737766 0.61458752 0.89051632 0.4781882  0.849992   0.5966243
 0.03492341 0.83544983 0.01332213 0.13374812 0.06607347 0.10898239
 0.60506105] 0.4732835952537928
2023-10-30 22:05:54,375 1 [0.97645476 0.82047086 0.90971253 0.37762581 0.56771686 0.61761832
 0.68325181 0.75634078 0.91850018 0.61769958 0.93224631 0.7843284
 0.57423279 0.93829594 0.65653735 0.73223499 0.72624119 0.52107244
 0.74823504] 0.7294113655251805
2023-10-30 22:05:54,379 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 22:05:54,615 Loss: 1.950, MeanIU:  0.7294, Best_mIoU:  0.7487
2023-10-30 22:05:54,616 [0.97645476 0.82047086 0.90971253 0.37762581 0.56771686 0.61761832
 0.68325181 0.75634078 0.91850018 0.61769958 0.93224631 0.7843284
 0.57423279 0.93829594 0.65653735 0.73223499 0.72624119 0.52107244
 0.74823504]
2023-10-30 22:05:56,828 Epoch: [388/484] Iter:[0/495], Time: 2.18, lr: [0.0023317569734475916], Loss: 1.877734, Acc:0.792080, Semantic loss: 0.665811, BCE loss: 0.533421, SB loss: 0.678502
2023-10-30 22:06:00,710 Epoch: [388/484] Iter:[10/495], Time: 0.55, lr: [0.002331315348161641], Loss: 1.886111, Acc:0.800885, Semantic loss: 0.676794, BCE loss: 0.535425, SB loss: 0.673891
2023-10-30 22:06:04,261 Epoch: [388/484] Iter:[20/495], Time: 0.46, lr: [0.002330873713580174], Loss: 1.924282, Acc:0.800378, Semantic loss: 0.739770, BCE loss: 0.502376, SB loss: 0.682136
2023-10-30 22:06:07,754 Epoch: [388/484] Iter:[30/495], Time: 0.42, lr: [0.00233043206970104], Loss: 1.937421, Acc:0.795955, Semantic loss: 0.735789, BCE loss: 0.520338, SB loss: 0.681294
2023-10-30 22:06:11,197 Epoch: [388/484] Iter:[40/495], Time: 0.40, lr: [0.002329990416522084], Loss: 1.930146, Acc:0.802541, Semantic loss: 0.727562, BCE loss: 0.521260, SB loss: 0.681324
2023-10-30 22:06:14,804 Epoch: [388/484] Iter:[50/495], Time: 0.40, lr: [0.002329548754041152], Loss: 1.938389, Acc:0.796676, Semantic loss: 0.725277, BCE loss: 0.529874, SB loss: 0.683238
2023-10-30 22:06:18,213 Epoch: [388/484] Iter:[60/495], Time: 0.39, lr: [0.002329107082256087], Loss: 1.936157, Acc:0.798584, Semantic loss: 0.730539, BCE loss: 0.521677, SB loss: 0.683941
2023-10-30 22:06:21,722 Epoch: [388/484] Iter:[70/495], Time: 0.38, lr: [0.0023286654011647344], Loss: 1.923146, Acc:0.793949, Semantic loss: 0.725725, BCE loss: 0.514174, SB loss: 0.683247
2023-10-30 22:06:25,247 Epoch: [388/484] Iter:[80/495], Time: 0.38, lr: [0.002328223710764937], Loss: 1.919164, Acc:0.794171, Semantic loss: 0.716542, BCE loss: 0.520819, SB loss: 0.681804
2023-10-30 22:06:28,852 Epoch: [388/484] Iter:[90/495], Time: 0.38, lr: [0.002327782011054535], Loss: 1.921507, Acc:0.800263, Semantic loss: 0.713700, BCE loss: 0.525833, SB loss: 0.681975
2023-10-30 22:06:32,370 Epoch: [388/484] Iter:[100/495], Time: 0.37, lr: [0.0023273403020313685], Loss: 1.944074, Acc:0.799910, Semantic loss: 0.724229, BCE loss: 0.529700, SB loss: 0.690145
2023-10-30 22:06:35,988 Epoch: [388/484] Iter:[110/495], Time: 0.37, lr: [0.002326898583693279], Loss: 1.936843, Acc:0.799241, Semantic loss: 0.721679, BCE loss: 0.525066, SB loss: 0.690097
2023-10-30 22:06:39,592 Epoch: [388/484] Iter:[120/495], Time: 0.37, lr: [0.002326456856038105], Loss: 1.942097, Acc:0.798199, Semantic loss: 0.724201, BCE loss: 0.526040, SB loss: 0.691856
2023-10-30 22:06:43,130 Epoch: [388/484] Iter:[130/495], Time: 0.37, lr: [0.0023260151190636837], Loss: 1.946193, Acc:0.797575, Semantic loss: 0.725584, BCE loss: 0.528984, SB loss: 0.691624
2023-10-30 22:06:46,731 Epoch: [388/484] Iter:[140/495], Time: 0.37, lr: [0.002325573372767851], Loss: 1.940449, Acc:0.798453, Semantic loss: 0.719999, BCE loss: 0.529407, SB loss: 0.691043
2023-10-30 22:06:50,230 Epoch: [388/484] Iter:[150/495], Time: 0.37, lr: [0.002325131617148444], Loss: 1.947798, Acc:0.800595, Semantic loss: 0.722464, BCE loss: 0.531487, SB loss: 0.693846
2023-10-30 22:06:53,958 Epoch: [388/484] Iter:[160/495], Time: 0.37, lr: [0.0023246898522032984], Loss: 1.938657, Acc:0.800471, Semantic loss: 0.719634, BCE loss: 0.526963, SB loss: 0.692060
2023-10-30 22:06:57,528 Epoch: [388/484] Iter:[170/495], Time: 0.37, lr: [0.002324248077930247], Loss: 1.938148, Acc:0.803282, Semantic loss: 0.719011, BCE loss: 0.527905, SB loss: 0.691231
2023-10-30 22:07:01,149 Epoch: [388/484] Iter:[180/495], Time: 0.37, lr: [0.0023238062943271216], Loss: 1.939989, Acc:0.802034, Semantic loss: 0.721824, BCE loss: 0.525573, SB loss: 0.692593
2023-10-30 22:07:04,752 Epoch: [388/484] Iter:[190/495], Time: 0.37, lr: [0.0023233645013917563], Loss: 1.933328, Acc:0.803213, Semantic loss: 0.718458, BCE loss: 0.524228, SB loss: 0.690642
2023-10-30 22:07:08,197 Epoch: [388/484] Iter:[200/495], Time: 0.37, lr: [0.002322922699121982], Loss: 1.933443, Acc:0.801859, Semantic loss: 0.718669, BCE loss: 0.524304, SB loss: 0.690471
2023-10-30 22:07:11,768 Epoch: [388/484] Iter:[210/495], Time: 0.37, lr: [0.0023224808875156283], Loss: 1.933351, Acc:0.803646, Semantic loss: 0.718218, BCE loss: 0.524724, SB loss: 0.690410
2023-10-30 22:07:15,416 Epoch: [388/484] Iter:[220/495], Time: 0.37, lr: [0.0023220390665705222], Loss: 1.933778, Acc:0.803809, Semantic loss: 0.719587, BCE loss: 0.523809, SB loss: 0.690381
2023-10-30 22:07:19,019 Epoch: [388/484] Iter:[230/495], Time: 0.37, lr: [0.0023215972362844958], Loss: 1.934934, Acc:0.804325, Semantic loss: 0.719723, BCE loss: 0.523465, SB loss: 0.691745
2023-10-30 22:07:22,685 Epoch: [388/484] Iter:[240/495], Time: 0.37, lr: [0.0023211553966553744], Loss: 1.928934, Acc:0.803920, Semantic loss: 0.717343, BCE loss: 0.521182, SB loss: 0.690409
2023-10-30 22:07:26,456 Epoch: [388/484] Iter:[250/495], Time: 0.37, lr: [0.002320713547680984], Loss: 1.925080, Acc:0.804322, Semantic loss: 0.715077, BCE loss: 0.521619, SB loss: 0.688384
2023-10-30 22:07:30,318 Epoch: [388/484] Iter:[260/495], Time: 0.37, lr: [0.0023202716893591492], Loss: 1.923695, Acc:0.805835, Semantic loss: 0.714496, BCE loss: 0.520866, SB loss: 0.688333
2023-10-30 22:07:34,188 Epoch: [388/484] Iter:[270/495], Time: 0.37, lr: [0.0023198298216876964], Loss: 1.926370, Acc:0.805538, Semantic loss: 0.715289, BCE loss: 0.521121, SB loss: 0.689960
2023-10-30 22:07:37,787 Epoch: [388/484] Iter:[280/495], Time: 0.37, lr: [0.0023193879446644482], Loss: 1.928243, Acc:0.804876, Semantic loss: 0.716448, BCE loss: 0.522138, SB loss: 0.689657
2023-10-30 22:07:41,478 Epoch: [388/484] Iter:[290/495], Time: 0.37, lr: [0.002318946058287226], Loss: 1.925860, Acc:0.804840, Semantic loss: 0.715305, BCE loss: 0.522061, SB loss: 0.688495
2023-10-30 22:07:45,040 Epoch: [388/484] Iter:[300/495], Time: 0.37, lr: [0.002318504162553851], Loss: 1.926688, Acc:0.804303, Semantic loss: 0.715283, BCE loss: 0.523376, SB loss: 0.688029
2023-10-30 22:07:48,569 Epoch: [388/484] Iter:[310/495], Time: 0.37, lr: [0.002318062257462145], Loss: 1.927743, Acc:0.805224, Semantic loss: 0.715282, BCE loss: 0.523902, SB loss: 0.688558
2023-10-30 22:07:52,160 Epoch: [388/484] Iter:[320/495], Time: 0.37, lr: [0.0023176203430099276], Loss: 1.927390, Acc:0.804965, Semantic loss: 0.715316, BCE loss: 0.522918, SB loss: 0.689156
2023-10-30 22:07:55,719 Epoch: [388/484] Iter:[330/495], Time: 0.37, lr: [0.0023171784191950164], Loss: 1.926602, Acc:0.805876, Semantic loss: 0.716212, BCE loss: 0.521454, SB loss: 0.688936
2023-10-30 22:07:59,237 Epoch: [388/484] Iter:[340/495], Time: 0.37, lr: [0.002316736486015228], Loss: 1.924397, Acc:0.806477, Semantic loss: 0.715813, BCE loss: 0.519834, SB loss: 0.688750
2023-10-30 22:08:02,863 Epoch: [388/484] Iter:[350/495], Time: 0.37, lr: [0.0023162945434683814], Loss: 1.922219, Acc:0.806881, Semantic loss: 0.715050, BCE loss: 0.519101, SB loss: 0.688068
2023-10-30 22:08:06,542 Epoch: [388/484] Iter:[360/495], Time: 0.37, lr: [0.002315852591552291], Loss: 1.923109, Acc:0.807214, Semantic loss: 0.715603, BCE loss: 0.519109, SB loss: 0.688397
2023-10-30 22:08:10,444 Epoch: [388/484] Iter:[370/495], Time: 0.37, lr: [0.002315410630264771], Loss: 1.926428, Acc:0.807760, Semantic loss: 0.716158, BCE loss: 0.521318, SB loss: 0.688953
2023-10-30 22:08:14,338 Epoch: [388/484] Iter:[380/495], Time: 0.37, lr: [0.002314968659603634], Loss: 1.924054, Acc:0.806834, Semantic loss: 0.715673, BCE loss: 0.520020, SB loss: 0.688361
2023-10-30 22:08:18,043 Epoch: [388/484] Iter:[390/495], Time: 0.37, lr: [0.0023145266795666954], Loss: 1.925228, Acc:0.806884, Semantic loss: 0.716616, BCE loss: 0.520197, SB loss: 0.688416
2023-10-30 22:08:21,771 Epoch: [388/484] Iter:[400/495], Time: 0.37, lr: [0.0023140846901517657], Loss: 1.925434, Acc:0.807445, Semantic loss: 0.716522, BCE loss: 0.520733, SB loss: 0.688179
2023-10-30 22:08:25,373 Epoch: [388/484] Iter:[410/495], Time: 0.37, lr: [0.0023136426913566554], Loss: 1.926537, Acc:0.807169, Semantic loss: 0.716858, BCE loss: 0.520834, SB loss: 0.688845
2023-10-30 22:08:29,028 Epoch: [388/484] Iter:[420/495], Time: 0.37, lr: [0.0023132006831791726], Loss: 1.926163, Acc:0.806904, Semantic loss: 0.717136, BCE loss: 0.519864, SB loss: 0.689164
2023-10-30 22:08:32,745 Epoch: [388/484] Iter:[430/495], Time: 0.37, lr: [0.0023127586656171294], Loss: 1.924193, Acc:0.807392, Semantic loss: 0.716353, BCE loss: 0.519379, SB loss: 0.688460
2023-10-30 22:08:36,309 Epoch: [388/484] Iter:[440/495], Time: 0.37, lr: [0.002312316638668332], Loss: 1.922984, Acc:0.807333, Semantic loss: 0.716277, BCE loss: 0.518051, SB loss: 0.688656
2023-10-30 22:08:39,965 Epoch: [388/484] Iter:[450/495], Time: 0.37, lr: [0.0023118746023305867], Loss: 1.919278, Acc:0.807422, Semantic loss: 0.714800, BCE loss: 0.516669, SB loss: 0.687810
2023-10-30 22:08:43,540 Epoch: [388/484] Iter:[460/495], Time: 0.37, lr: [0.0023114325566016987], Loss: 1.921027, Acc:0.807399, Semantic loss: 0.715651, BCE loss: 0.517620, SB loss: 0.687755
2023-10-30 22:08:47,098 Epoch: [388/484] Iter:[470/495], Time: 0.37, lr: [0.0023109905014794753], Loss: 1.921537, Acc:0.807581, Semantic loss: 0.716302, BCE loss: 0.517667, SB loss: 0.687568
2023-10-30 22:08:50,660 Epoch: [388/484] Iter:[480/495], Time: 0.37, lr: [0.002310548436961719], Loss: 1.920719, Acc:0.807278, Semantic loss: 0.716546, BCE loss: 0.516886, SB loss: 0.687287
2023-10-30 22:08:54,009 Epoch: [388/484] Iter:[490/495], Time: 0.37, lr: [0.0023101063630462325], Loss: 1.922093, Acc:0.807228, Semantic loss: 0.717136, BCE loss: 0.517170, SB loss: 0.687787
2023-10-30 22:11:50,157 0 [0.94058366 0.65703259 0.84090624 0.15157143 0.30374607 0.44269462
 0.50806705 0.5922891  0.88620296 0.4486398  0.87448359 0.62156372
 0.06177896 0.81703552 0.00811192 0.11797371 0.06620427 0.10298888
 0.61725124] 0.476796069586043
2023-10-30 22:11:50,157 1 [0.97565605 0.81501627 0.91572667 0.3830511  0.55376283 0.61644347
 0.69002201 0.7476122  0.91154651 0.53242768 0.93747054 0.79422793
 0.58704795 0.92172487 0.4878426  0.50380115 0.7201047  0.44687291
 0.73269664] 0.698581793135595
2023-10-30 22:11:50,161 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 22:11:50,399 Loss: 2.044, MeanIU:  0.6986, Best_mIoU:  0.7487
2023-10-30 22:11:50,399 [0.97565605 0.81501627 0.91572667 0.3830511  0.55376283 0.61644347
 0.69002201 0.7476122  0.91154651 0.53242768 0.93747054 0.79422793
 0.58704795 0.92172487 0.4878426  0.50380115 0.7201047  0.44687291
 0.73269664]
2023-10-30 22:11:52,619 Epoch: [389/484] Iter:[0/495], Time: 2.19, lr: [0.0023098853225636527], Loss: 2.242650, Acc:0.933502, Semantic loss: 0.784826, BCE loss: 0.738854, SB loss: 0.718970
2023-10-30 22:11:56,530 Epoch: [389/484] Iter:[10/495], Time: 0.55, lr: [0.0023094432345474496], Loss: 1.864344, Acc:0.817235, Semantic loss: 0.720206, BCE loss: 0.462176, SB loss: 0.681962
2023-10-30 22:12:00,068 Epoch: [389/484] Iter:[20/495], Time: 0.46, lr: [0.002309001137128019], Loss: 1.863912, Acc:0.815728, Semantic loss: 0.702299, BCE loss: 0.480792, SB loss: 0.680821
2023-10-30 22:12:03,534 Epoch: [389/484] Iter:[30/495], Time: 0.42, lr: [0.002308559030303161], Loss: 1.881565, Acc:0.815433, Semantic loss: 0.700808, BCE loss: 0.489449, SB loss: 0.691308
2023-10-30 22:12:07,072 Epoch: [389/484] Iter:[40/495], Time: 0.41, lr: [0.002308116914070673], Loss: 1.886202, Acc:0.818893, Semantic loss: 0.706899, BCE loss: 0.495725, SB loss: 0.683578
2023-10-30 22:12:10,674 Epoch: [389/484] Iter:[50/495], Time: 0.40, lr: [0.0023076747884283543], Loss: 1.909810, Acc:0.811914, Semantic loss: 0.718703, BCE loss: 0.498324, SB loss: 0.692784
2023-10-30 22:12:14,162 Epoch: [389/484] Iter:[60/495], Time: 0.39, lr: [0.0023072326533740005], Loss: 1.921262, Acc:0.813010, Semantic loss: 0.719333, BCE loss: 0.507471, SB loss: 0.694457
2023-10-30 22:12:17,623 Epoch: [389/484] Iter:[70/495], Time: 0.38, lr: [0.002306790508905407], Loss: 1.927673, Acc:0.814973, Semantic loss: 0.719040, BCE loss: 0.518012, SB loss: 0.690621
2023-10-30 22:12:21,146 Epoch: [389/484] Iter:[80/495], Time: 0.38, lr: [0.0023063483550203674], Loss: 1.924456, Acc:0.817605, Semantic loss: 0.717924, BCE loss: 0.518783, SB loss: 0.687749
2023-10-30 22:12:24,624 Epoch: [389/484] Iter:[90/495], Time: 0.38, lr: [0.002305906191716677], Loss: 1.926377, Acc:0.819657, Semantic loss: 0.718473, BCE loss: 0.520611, SB loss: 0.687294
2023-10-30 22:12:28,200 Epoch: [389/484] Iter:[100/495], Time: 0.37, lr: [0.002305464018992128], Loss: 1.923802, Acc:0.821002, Semantic loss: 0.716345, BCE loss: 0.521425, SB loss: 0.686032
2023-10-30 22:12:31,703 Epoch: [389/484] Iter:[110/495], Time: 0.37, lr: [0.002305021836844511], Loss: 1.915336, Acc:0.820353, Semantic loss: 0.711189, BCE loss: 0.520472, SB loss: 0.683676
2023-10-30 22:12:35,262 Epoch: [389/484] Iter:[120/495], Time: 0.37, lr: [0.0023045796452716167], Loss: 1.912611, Acc:0.820778, Semantic loss: 0.710746, BCE loss: 0.517906, SB loss: 0.683959
2023-10-30 22:12:38,696 Epoch: [389/484] Iter:[130/495], Time: 0.37, lr: [0.002304137444271236], Loss: 1.927524, Acc:0.822699, Semantic loss: 0.718263, BCE loss: 0.521974, SB loss: 0.687286
2023-10-30 22:12:42,283 Epoch: [389/484] Iter:[140/495], Time: 0.37, lr: [0.002303695233841156], Loss: 1.931588, Acc:0.821825, Semantic loss: 0.721338, BCE loss: 0.521025, SB loss: 0.689225
2023-10-30 22:12:45,802 Epoch: [389/484] Iter:[150/495], Time: 0.37, lr: [0.0023032530139791662], Loss: 1.938459, Acc:0.820598, Semantic loss: 0.720987, BCE loss: 0.527765, SB loss: 0.689707
2023-10-30 22:12:49,273 Epoch: [389/484] Iter:[160/495], Time: 0.37, lr: [0.0023028107846830496], Loss: 1.932829, Acc:0.818918, Semantic loss: 0.718337, BCE loss: 0.525557, SB loss: 0.688935
2023-10-30 22:12:52,878 Epoch: [389/484] Iter:[170/495], Time: 0.37, lr: [0.002302368545950596], Loss: 1.928328, Acc:0.817466, Semantic loss: 0.718290, BCE loss: 0.520851, SB loss: 0.689187
2023-10-30 22:12:56,323 Epoch: [389/484] Iter:[180/495], Time: 0.36, lr: [0.002301926297779588], Loss: 1.922317, Acc:0.818059, Semantic loss: 0.716295, BCE loss: 0.519266, SB loss: 0.686756
2023-10-30 22:12:59,884 Epoch: [389/484] Iter:[190/495], Time: 0.36, lr: [0.00230148404016781], Loss: 1.913919, Acc:0.816664, Semantic loss: 0.713651, BCE loss: 0.515852, SB loss: 0.684416
2023-10-30 22:13:03,431 Epoch: [389/484] Iter:[200/495], Time: 0.36, lr: [0.0023010417731130425], Loss: 1.918255, Acc:0.815502, Semantic loss: 0.715961, BCE loss: 0.517274, SB loss: 0.685019
2023-10-30 22:13:07,014 Epoch: [389/484] Iter:[210/495], Time: 0.36, lr: [0.00230059949661307], Loss: 1.916923, Acc:0.814154, Semantic loss: 0.716809, BCE loss: 0.515818, SB loss: 0.684295
2023-10-30 22:13:10,548 Epoch: [389/484] Iter:[220/495], Time: 0.36, lr: [0.002300157210665672], Loss: 1.920165, Acc:0.815059, Semantic loss: 0.718078, BCE loss: 0.517029, SB loss: 0.685057
2023-10-30 22:13:14,211 Epoch: [389/484] Iter:[230/495], Time: 0.36, lr: [0.0022997149152686283], Loss: 1.921566, Acc:0.816086, Semantic loss: 0.717961, BCE loss: 0.518220, SB loss: 0.685385
2023-10-30 22:13:17,906 Epoch: [389/484] Iter:[240/495], Time: 0.36, lr: [0.002299272610419716], Loss: 1.916605, Acc:0.815663, Semantic loss: 0.715788, BCE loss: 0.516640, SB loss: 0.684177
2023-10-30 22:13:21,453 Epoch: [389/484] Iter:[250/495], Time: 0.36, lr: [0.0022988302961167153], Loss: 1.915769, Acc:0.815304, Semantic loss: 0.715571, BCE loss: 0.516673, SB loss: 0.683525
2023-10-30 22:13:25,035 Epoch: [389/484] Iter:[260/495], Time: 0.36, lr: [0.0022983879723574015], Loss: 1.921340, Acc:0.814291, Semantic loss: 0.718464, BCE loss: 0.518166, SB loss: 0.684710
2023-10-30 22:13:28,603 Epoch: [389/484] Iter:[270/495], Time: 0.36, lr: [0.0022979456391395508], Loss: 1.918387, Acc:0.813406, Semantic loss: 0.717417, BCE loss: 0.516626, SB loss: 0.684343
2023-10-30 22:13:32,288 Epoch: [389/484] Iter:[280/495], Time: 0.36, lr: [0.0022975032964609367], Loss: 1.923540, Acc:0.813384, Semantic loss: 0.720567, BCE loss: 0.516778, SB loss: 0.686194
2023-10-30 22:13:35,894 Epoch: [389/484] Iter:[290/495], Time: 0.36, lr: [0.002297060944319334], Loss: 1.920010, Acc:0.812171, Semantic loss: 0.718582, BCE loss: 0.515641, SB loss: 0.685787
2023-10-30 22:13:39,553 Epoch: [389/484] Iter:[300/495], Time: 0.36, lr: [0.002296618582712516], Loss: 1.923122, Acc:0.810953, Semantic loss: 0.719015, BCE loss: 0.517307, SB loss: 0.686799
2023-10-30 22:13:43,178 Epoch: [389/484] Iter:[310/495], Time: 0.36, lr: [0.0022961762116382534], Loss: 1.925431, Acc:0.811377, Semantic loss: 0.719826, BCE loss: 0.517840, SB loss: 0.687765
2023-10-30 22:13:46,957 Epoch: [389/484] Iter:[320/495], Time: 0.36, lr: [0.0022957338310943157], Loss: 1.925270, Acc:0.811720, Semantic loss: 0.720030, BCE loss: 0.517644, SB loss: 0.687596
2023-10-30 22:13:50,534 Epoch: [389/484] Iter:[330/495], Time: 0.36, lr: [0.002295291441078475], Loss: 1.922277, Acc:0.813175, Semantic loss: 0.718580, BCE loss: 0.516622, SB loss: 0.687075
2023-10-30 22:13:54,168 Epoch: [389/484] Iter:[340/495], Time: 0.36, lr: [0.0022948490415884986], Loss: 1.920107, Acc:0.812598, Semantic loss: 0.717597, BCE loss: 0.515750, SB loss: 0.686761
2023-10-30 22:13:57,720 Epoch: [389/484] Iter:[350/495], Time: 0.36, lr: [0.0022944066326221545], Loss: 1.925332, Acc:0.812437, Semantic loss: 0.720415, BCE loss: 0.516749, SB loss: 0.688168
2023-10-30 22:14:01,286 Epoch: [389/484] Iter:[360/495], Time: 0.36, lr: [0.0022939642141772084], Loss: 1.923290, Acc:0.811729, Semantic loss: 0.719327, BCE loss: 0.516060, SB loss: 0.687904
2023-10-30 22:14:05,028 Epoch: [389/484] Iter:[370/495], Time: 0.36, lr: [0.002293521786251428], Loss: 1.925199, Acc:0.811527, Semantic loss: 0.720680, BCE loss: 0.515855, SB loss: 0.688664
2023-10-30 22:14:08,633 Epoch: [389/484] Iter:[380/495], Time: 0.36, lr: [0.002293079348842576], Loss: 1.925016, Acc:0.811252, Semantic loss: 0.720132, BCE loss: 0.515938, SB loss: 0.688946
2023-10-30 22:14:12,276 Epoch: [389/484] Iter:[390/495], Time: 0.36, lr: [0.002292636901948416], Loss: 1.923697, Acc:0.811316, Semantic loss: 0.719734, BCE loss: 0.515535, SB loss: 0.688428
2023-10-30 22:14:15,917 Epoch: [389/484] Iter:[400/495], Time: 0.36, lr: [0.0022921944455667124], Loss: 1.924779, Acc:0.811427, Semantic loss: 0.719697, BCE loss: 0.516136, SB loss: 0.688946
2023-10-30 22:14:19,513 Epoch: [389/484] Iter:[410/495], Time: 0.36, lr: [0.0022917519796952263], Loss: 1.922547, Acc:0.811994, Semantic loss: 0.719473, BCE loss: 0.514610, SB loss: 0.688464
2023-10-30 22:14:23,257 Epoch: [389/484] Iter:[420/495], Time: 0.36, lr: [0.002291309504331718], Loss: 1.921004, Acc:0.811552, Semantic loss: 0.719269, BCE loss: 0.513444, SB loss: 0.688292
2023-10-30 22:14:26,888 Epoch: [389/484] Iter:[430/495], Time: 0.36, lr: [0.002290867019473945], Loss: 1.920914, Acc:0.812196, Semantic loss: 0.719627, BCE loss: 0.513088, SB loss: 0.688199
2023-10-30 22:14:30,491 Epoch: [389/484] Iter:[440/495], Time: 0.36, lr: [0.0022904245251196696], Loss: 1.919539, Acc:0.812097, Semantic loss: 0.719179, BCE loss: 0.511923, SB loss: 0.688437
2023-10-30 22:14:34,136 Epoch: [389/484] Iter:[450/495], Time: 0.36, lr: [0.0022899820212666476], Loss: 1.921572, Acc:0.812297, Semantic loss: 0.719376, BCE loss: 0.513960, SB loss: 0.688236
2023-10-30 22:14:37,662 Epoch: [389/484] Iter:[460/495], Time: 0.36, lr: [0.0022895395079126357], Loss: 1.920856, Acc:0.812379, Semantic loss: 0.719017, BCE loss: 0.513644, SB loss: 0.688194
2023-10-30 22:14:41,358 Epoch: [389/484] Iter:[470/495], Time: 0.36, lr: [0.002289096985055388], Loss: 1.919411, Acc:0.812327, Semantic loss: 0.717723, BCE loss: 0.513911, SB loss: 0.687777
2023-10-30 22:14:45,002 Epoch: [389/484] Iter:[480/495], Time: 0.36, lr: [0.0022886544526926618], Loss: 1.918447, Acc:0.812532, Semantic loss: 0.717208, BCE loss: 0.513394, SB loss: 0.687845
2023-10-30 22:14:48,467 Epoch: [389/484] Iter:[490/495], Time: 0.36, lr: [0.0022882119108222094], Loss: 1.919544, Acc:0.813132, Semantic loss: 0.717493, BCE loss: 0.514168, SB loss: 0.687882
2023-10-30 22:17:44,820 0 [0.94628783 0.6512306  0.84678256 0.21056658 0.22972171 0.43654042
 0.50349123 0.61479733 0.88886911 0.45453654 0.8901809  0.65211871
 0.06914173 0.84251173 0.01096364 0.13038105 0.10647725 0.09507705
 0.63213501] 0.48483215772319604
2023-10-30 22:17:44,820 1 [0.97517108 0.81673366 0.91836654 0.53426525 0.58772281 0.60333269
 0.68936878 0.76869813 0.91862733 0.6034785  0.94069673 0.79541378
 0.55948356 0.94556371 0.78366779 0.84521302 0.65276773 0.57667227
 0.7470049 ] 0.7506446452498033
2023-10-30 22:17:44,823 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 22:17:45,185 Loss: 2.001, MeanIU:  0.7506, Best_mIoU:  0.7506
2023-10-30 22:17:45,186 [0.97517108 0.81673366 0.91836654 0.53426525 0.58772281 0.60333269
 0.68936878 0.76869813 0.91862733 0.6034785  0.94069673 0.79541378
 0.55948356 0.94556371 0.78366779 0.84521302 0.65276773 0.57667227
 0.7470049 ]
2023-10-30 22:17:47,294 Epoch: [390/484] Iter:[0/495], Time: 2.08, lr: [0.0022879906363208837], Loss: 2.182243, Acc:0.772580, Semantic loss: 0.874668, BCE loss: 0.514066, SB loss: 0.793508
2023-10-30 22:17:51,100 Epoch: [390/484] Iter:[10/495], Time: 0.53, lr: [0.0022875480801846275], Loss: 1.916990, Acc:0.816557, Semantic loss: 0.695608, BCE loss: 0.553794, SB loss: 0.667588
2023-10-30 22:17:54,731 Epoch: [390/484] Iter:[20/495], Time: 0.45, lr: [0.002287105514535023], Loss: 1.885552, Acc:0.802461, Semantic loss: 0.688243, BCE loss: 0.531227, SB loss: 0.666082
2023-10-30 22:17:58,161 Epoch: [390/484] Iter:[30/495], Time: 0.42, lr: [0.002286662939369823], Loss: 1.889182, Acc:0.803695, Semantic loss: 0.702124, BCE loss: 0.519542, SB loss: 0.667516
2023-10-30 22:18:01,849 Epoch: [390/484] Iter:[40/495], Time: 0.41, lr: [0.002286220354686775], Loss: 1.877536, Acc:0.803366, Semantic loss: 0.701652, BCE loss: 0.507906, SB loss: 0.667978
2023-10-30 22:18:05,519 Epoch: [390/484] Iter:[50/495], Time: 0.40, lr: [0.002285777760483627], Loss: 1.891010, Acc:0.806075, Semantic loss: 0.715241, BCE loss: 0.501455, SB loss: 0.674314
2023-10-30 22:18:09,047 Epoch: [390/484] Iter:[60/495], Time: 0.39, lr: [0.002285335156758125], Loss: 1.915413, Acc:0.801666, Semantic loss: 0.718661, BCE loss: 0.515614, SB loss: 0.681138
2023-10-30 22:18:12,514 Epoch: [390/484] Iter:[70/495], Time: 0.38, lr: [0.0022848925435080174], Loss: 1.900193, Acc:0.804963, Semantic loss: 0.713703, BCE loss: 0.508494, SB loss: 0.677996
2023-10-30 22:18:16,118 Epoch: [390/484] Iter:[80/495], Time: 0.38, lr: [0.002284449920731047], Loss: 1.900779, Acc:0.804751, Semantic loss: 0.711673, BCE loss: 0.512141, SB loss: 0.676965
2023-10-30 22:18:19,680 Epoch: [390/484] Iter:[90/495], Time: 0.38, lr: [0.0022840072884249586], Loss: 1.903309, Acc:0.807520, Semantic loss: 0.712417, BCE loss: 0.513105, SB loss: 0.677787
2023-10-30 22:18:23,197 Epoch: [390/484] Iter:[100/495], Time: 0.38, lr: [0.0022835646465874933], Loss: 1.909562, Acc:0.807506, Semantic loss: 0.713064, BCE loss: 0.518101, SB loss: 0.678397
2023-10-30 22:18:26,653 Epoch: [390/484] Iter:[110/495], Time: 0.37, lr: [0.002283121995216396], Loss: 1.913317, Acc:0.809202, Semantic loss: 0.713074, BCE loss: 0.520744, SB loss: 0.679499
2023-10-30 22:18:30,259 Epoch: [390/484] Iter:[120/495], Time: 0.37, lr: [0.002282679334309406], Loss: 1.915137, Acc:0.809132, Semantic loss: 0.713542, BCE loss: 0.522209, SB loss: 0.679386
2023-10-30 22:18:33,744 Epoch: [390/484] Iter:[130/495], Time: 0.37, lr: [0.0022822366638642626], Loss: 1.921175, Acc:0.809210, Semantic loss: 0.714369, BCE loss: 0.526609, SB loss: 0.680196
2023-10-30 22:18:37,364 Epoch: [390/484] Iter:[140/495], Time: 0.37, lr: [0.002281793983878704], Loss: 1.927204, Acc:0.809655, Semantic loss: 0.716825, BCE loss: 0.528345, SB loss: 0.682033
2023-10-30 22:18:40,795 Epoch: [390/484] Iter:[150/495], Time: 0.37, lr: [0.0022813512943504703], Loss: 1.934633, Acc:0.809811, Semantic loss: 0.721682, BCE loss: 0.526877, SB loss: 0.686074
2023-10-30 22:18:44,416 Epoch: [390/484] Iter:[160/495], Time: 0.37, lr: [0.0022809085952772965], Loss: 1.933936, Acc:0.807767, Semantic loss: 0.720886, BCE loss: 0.525657, SB loss: 0.687393
2023-10-30 22:18:48,038 Epoch: [390/484] Iter:[170/495], Time: 0.37, lr: [0.002280465886656919], Loss: 1.930647, Acc:0.807283, Semantic loss: 0.719578, BCE loss: 0.525687, SB loss: 0.685382
2023-10-30 22:18:51,528 Epoch: [390/484] Iter:[180/495], Time: 0.37, lr: [0.0022800231684870706], Loss: 1.927283, Acc:0.808346, Semantic loss: 0.718768, BCE loss: 0.523270, SB loss: 0.685245
2023-10-30 22:18:55,131 Epoch: [390/484] Iter:[190/495], Time: 0.37, lr: [0.002279580440765488], Loss: 1.924569, Acc:0.805029, Semantic loss: 0.718379, BCE loss: 0.520536, SB loss: 0.685654
2023-10-30 22:18:58,618 Epoch: [390/484] Iter:[200/495], Time: 0.37, lr: [0.0022791377034899023], Loss: 1.927091, Acc:0.803884, Semantic loss: 0.719937, BCE loss: 0.520864, SB loss: 0.686290
2023-10-30 22:19:02,136 Epoch: [390/484] Iter:[210/495], Time: 0.36, lr: [0.002278694956658044], Loss: 1.932322, Acc:0.805639, Semantic loss: 0.720355, BCE loss: 0.524901, SB loss: 0.687066
2023-10-30 22:19:05,665 Epoch: [390/484] Iter:[220/495], Time: 0.36, lr: [0.002278252200267646], Loss: 1.927976, Acc:0.805098, Semantic loss: 0.719259, BCE loss: 0.523039, SB loss: 0.685678
2023-10-30 22:19:09,289 Epoch: [390/484] Iter:[230/495], Time: 0.36, lr: [0.0022778094343164365], Loss: 1.920559, Acc:0.803778, Semantic loss: 0.716888, BCE loss: 0.519114, SB loss: 0.684557
2023-10-30 22:19:12,893 Epoch: [390/484] Iter:[240/495], Time: 0.36, lr: [0.002277366658802144], Loss: 1.920249, Acc:0.804065, Semantic loss: 0.716597, BCE loss: 0.519528, SB loss: 0.684124
2023-10-30 22:19:16,486 Epoch: [390/484] Iter:[250/495], Time: 0.36, lr: [0.0022769238737224955], Loss: 1.922518, Acc:0.804772, Semantic loss: 0.717106, BCE loss: 0.520282, SB loss: 0.685130
2023-10-30 22:19:20,133 Epoch: [390/484] Iter:[260/495], Time: 0.36, lr: [0.0022764810790752185], Loss: 1.918101, Acc:0.807245, Semantic loss: 0.714948, BCE loss: 0.519418, SB loss: 0.683735
2023-10-30 22:19:23,798 Epoch: [390/484] Iter:[270/495], Time: 0.36, lr: [0.0022760382748580384], Loss: 1.920536, Acc:0.807025, Semantic loss: 0.714890, BCE loss: 0.521424, SB loss: 0.684222
2023-10-30 22:19:27,326 Epoch: [390/484] Iter:[280/495], Time: 0.36, lr: [0.002275595461068679], Loss: 1.919971, Acc:0.808323, Semantic loss: 0.714339, BCE loss: 0.521756, SB loss: 0.683876
2023-10-30 22:19:31,035 Epoch: [390/484] Iter:[290/495], Time: 0.36, lr: [0.0022751526377048628], Loss: 1.918757, Acc:0.807589, Semantic loss: 0.714581, BCE loss: 0.520636, SB loss: 0.683541
2023-10-30 22:19:34,659 Epoch: [390/484] Iter:[300/495], Time: 0.36, lr: [0.0022747098047643144], Loss: 1.925162, Acc:0.808388, Semantic loss: 0.717967, BCE loss: 0.521995, SB loss: 0.685201
2023-10-30 22:19:38,236 Epoch: [390/484] Iter:[310/495], Time: 0.36, lr: [0.0022742669622447535], Loss: 1.924470, Acc:0.808804, Semantic loss: 0.718167, BCE loss: 0.520906, SB loss: 0.685398
2023-10-30 22:19:41,848 Epoch: [390/484] Iter:[320/495], Time: 0.36, lr: [0.0022738241101439008], Loss: 1.922698, Acc:0.809545, Semantic loss: 0.717430, BCE loss: 0.520512, SB loss: 0.684757
2023-10-30 22:19:45,436 Epoch: [390/484] Iter:[330/495], Time: 0.36, lr: [0.0022733812484594744], Loss: 1.923513, Acc:0.809195, Semantic loss: 0.717761, BCE loss: 0.520592, SB loss: 0.685160
2023-10-30 22:19:49,018 Epoch: [390/484] Iter:[340/495], Time: 0.36, lr: [0.0022729383771891943], Loss: 1.921224, Acc:0.808678, Semantic loss: 0.716491, BCE loss: 0.519288, SB loss: 0.685445
2023-10-30 22:19:52,688 Epoch: [390/484] Iter:[350/495], Time: 0.36, lr: [0.0022724954963307766], Loss: 1.922252, Acc:0.808574, Semantic loss: 0.717166, BCE loss: 0.519379, SB loss: 0.685707
2023-10-30 22:19:56,304 Epoch: [390/484] Iter:[360/495], Time: 0.36, lr: [0.002272052605881938], Loss: 1.922259, Acc:0.808360, Semantic loss: 0.717323, BCE loss: 0.518466, SB loss: 0.686470
2023-10-30 22:19:59,825 Epoch: [390/484] Iter:[370/495], Time: 0.36, lr: [0.0022716097058403917], Loss: 1.923397, Acc:0.807272, Semantic loss: 0.717865, BCE loss: 0.518718, SB loss: 0.686814
2023-10-30 22:20:03,475 Epoch: [390/484] Iter:[380/495], Time: 0.36, lr: [0.0022711667962038544], Loss: 1.920792, Acc:0.806530, Semantic loss: 0.717000, BCE loss: 0.516661, SB loss: 0.687131
2023-10-30 22:20:07,067 Epoch: [390/484] Iter:[390/495], Time: 0.36, lr: [0.002270723876970038], Loss: 1.918073, Acc:0.805800, Semantic loss: 0.716392, BCE loss: 0.515232, SB loss: 0.686448
2023-10-30 22:20:10,738 Epoch: [390/484] Iter:[400/495], Time: 0.36, lr: [0.002270280948136654], Loss: 1.917475, Acc:0.806025, Semantic loss: 0.717334, BCE loss: 0.513487, SB loss: 0.686655
2023-10-30 22:20:14,311 Epoch: [390/484] Iter:[410/495], Time: 0.36, lr: [0.0022698380097014126], Loss: 1.919503, Acc:0.806446, Semantic loss: 0.717990, BCE loss: 0.514832, SB loss: 0.686681
2023-10-30 22:20:17,877 Epoch: [390/484] Iter:[420/495], Time: 0.36, lr: [0.0022693950616620253], Loss: 1.919235, Acc:0.806451, Semantic loss: 0.718102, BCE loss: 0.514563, SB loss: 0.686570
2023-10-30 22:20:21,460 Epoch: [390/484] Iter:[430/495], Time: 0.36, lr: [0.002268952104016201], Loss: 1.918206, Acc:0.807298, Semantic loss: 0.718570, BCE loss: 0.513357, SB loss: 0.686279
2023-10-30 22:20:25,072 Epoch: [390/484] Iter:[440/495], Time: 0.36, lr: [0.002268509136761646], Loss: 1.917633, Acc:0.807955, Semantic loss: 0.718867, BCE loss: 0.511854, SB loss: 0.686912
2023-10-30 22:20:28,732 Epoch: [390/484] Iter:[450/495], Time: 0.36, lr: [0.002268066159896067], Loss: 1.917543, Acc:0.808352, Semantic loss: 0.718965, BCE loss: 0.511305, SB loss: 0.687273
2023-10-30 22:20:32,358 Epoch: [390/484] Iter:[460/495], Time: 0.36, lr: [0.002267623173417171], Loss: 1.916589, Acc:0.808493, Semantic loss: 0.717918, BCE loss: 0.511556, SB loss: 0.687115
2023-10-30 22:20:35,858 Epoch: [390/484] Iter:[470/495], Time: 0.36, lr: [0.0022671801773226623], Loss: 1.915156, Acc:0.808476, Semantic loss: 0.717391, BCE loss: 0.511211, SB loss: 0.686553
2023-10-30 22:20:39,399 Epoch: [390/484] Iter:[480/495], Time: 0.36, lr: [0.0022667371716102442], Loss: 1.913836, Acc:0.808616, Semantic loss: 0.716519, BCE loss: 0.511047, SB loss: 0.686269
2023-10-30 22:20:42,898 Epoch: [390/484] Iter:[490/495], Time: 0.36, lr: [0.0022662941562776183], Loss: 1.913808, Acc:0.808226, Semantic loss: 0.716027, BCE loss: 0.511795, SB loss: 0.685986
2023-10-30 22:23:41,035 0 [0.95092011 0.69329182 0.85148349 0.143605   0.31312768 0.44356269
 0.51193108 0.63117513 0.89275842 0.47682395 0.87916428 0.62435963
 0.05200479 0.83254595 0.00380647 0.14296087 0.10378836 0.07254771
 0.63888754] 0.4873023661583732
2023-10-30 22:23:41,035 1 [0.97874025 0.83463779 0.91662253 0.39160148 0.60099187 0.61160231
 0.69187771 0.74110926 0.9172786  0.5956284  0.93541268 0.78726365
 0.58084902 0.9419201  0.67228403 0.82197993 0.73890344 0.50229253
 0.73907416] 0.7368457758786587
2023-10-30 22:23:41,039 => saving checkpoint to output/cityscapes/pidnet_small_cityscapes_myconfigcheckpoint.pth.tar
2023-10-30 22:23:41,278 Loss: 1.996, MeanIU:  0.7368, Best_mIoU:  0.7506
2023-10-30 22:23:41,278 [0.97874025 0.83463779 0.91662253 0.39160148 0.60099187 0.61160231
 0.69187771 0.74110926 0.9172786  0.5956284  0.93541268 0.78726365
 0.58084902 0.9419201  0.67228403 0.82197993 0.73890344 0.50229253
 0.73907416]
2023-10-30 22:23:43,395 Epoch: [391/484] Iter:[0/495], Time: 2.08, lr: [0.00226607264500301], Loss: 1.703976, Acc:0.851960, Semantic loss: 0.666890, BCE loss: 0.371879, SB loss: 0.665206
2023-10-30 22:23:47,217 Epoch: [391/484] Iter:[10/495], Time: 0.54, lr: [0.0022656296152357646], Loss: 1.845253, Acc:0.830590, Semantic loss: 0.689839, BCE loss: 0.493440, SB loss: 0.661974
2023-10-30 22:23:50,802 Epoch: [391/484] Iter:[20/495], Time: 0.45, lr: [0.0022651865758425644], Loss: 1.843782, Acc:0.812478, Semantic loss: 0.688586, BCE loss: 0.486815, SB loss: 0.668381
2023-10-30 22:23:54,445 Epoch: [391/484] Iter:[30/495], Time: 0.42, lr: [0.0022647435268211076], Loss: 1.878846, Acc:0.814311, Semantic loss: 0.720658, BCE loss: 0.480953, SB loss: 0.677235
2023-10-30 22:23:57,938 Epoch: [391/484] Iter:[40/495], Time: 0.41, lr: [0.0022643004681690915], Loss: 1.875995, Acc:0.814608, Semantic loss: 0.718510, BCE loss: 0.481474, SB loss: 0.676011
2023-10-30 22:24:01,459 Epoch: [391/484] Iter:[50/495], Time: 0.40, lr: [0.0022638573998842145], Loss: 1.923835, Acc:0.821692, Semantic loss: 0.739028, BCE loss: 0.498430, SB loss: 0.686377
2023-10-30 22:24:04,952 Epoch: [391/484] Iter:[60/495], Time: 0.39, lr: [0.002263414321964172], Loss: 1.923153, Acc:0.822593, Semantic loss: 0.723486, BCE loss: 0.520173, SB loss: 0.679495
2023-10-30 22:24:08,457 Epoch: [391/484] Iter:[70/495], Time: 0.38, lr: [0.0022629712344066568], Loss: 1.915947, Acc:0.815466, Semantic loss: 0.723430, BCE loss: 0.511276, SB loss: 0.681241
2023-10-30 22:24:11,910 Epoch: [391/484] Iter:[80/495], Time: 0.38, lr: [0.002262528137209365], Loss: 1.908847, Acc:0.817192, Semantic loss: 0.718178, BCE loss: 0.511868, SB loss: 0.678800
2023-10-30 22:24:15,574 Epoch: [391/484] Iter:[90/495], Time: 0.38, lr: [0.0022620850303699887], Loss: 1.924149, Acc:0.815462, Semantic loss: 0.728475, BCE loss: 0.514042, SB loss: 0.681633
2023-10-30 22:24:19,252 Epoch: [391/484] Iter:[100/495], Time: 0.38, lr: [0.002261641913886218], Loss: 1.919831, Acc:0.814617, Semantic loss: 0.723889, BCE loss: 0.514526, SB loss: 0.681417
2023-10-30 22:24:22,763 Epoch: [391/484] Iter:[110/495], Time: 0.37, lr: [0.0022611987877557433], Loss: 1.932089, Acc:0.813171, Semantic loss: 0.726573, BCE loss: 0.522588, SB loss: 0.682928
2023-10-30 22:24:26,310 Epoch: [391/484] Iter:[120/495], Time: 0.37, lr: [0.002260755651976256], Loss: 1.931539, Acc:0.812205, Semantic loss: 0.725980, BCE loss: 0.521301, SB loss: 0.684257
2023-10-30 22:24:29,998 Epoch: [391/484] Iter:[130/495], Time: 0.37, lr: [0.002260312506545443], Loss: 1.927842, Acc:0.812305, Semantic loss: 0.724702, BCE loss: 0.520006, SB loss: 0.683135
2023-10-30 22:24:33,597 Epoch: [391/484] Iter:[140/495], Time: 0.37, lr: [0.002259869351460992], Loss: 1.927039, Acc:0.811540, Semantic loss: 0.723572, BCE loss: 0.518664, SB loss: 0.684803
2023-10-30 22:24:37,105 Epoch: [391/484] Iter:[150/495], Time: 0.37, lr: [0.0022594261867205884], Loss: 1.929750, Acc:0.811128, Semantic loss: 0.724093, BCE loss: 0.519675, SB loss: 0.685981
2023-10-30 22:24:40,688 Epoch: [391/484] Iter:[160/495], Time: 0.37, lr: [0.0022589830123219182], Loss: 1.923899, Acc:0.811590, Semantic loss: 0.719968, BCE loss: 0.519577, SB loss: 0.684355
2023-10-30 22:24:44,394 Epoch: [391/484] Iter:[170/495], Time: 0.37, lr: [0.002258539828262666], Loss: 1.924266, Acc:0.810984, Semantic loss: 0.720523, BCE loss: 0.518465, SB loss: 0.685278
2023-10-30 22:24:47,914 Epoch: [391/484] Iter:[180/495], Time: 0.37, lr: [0.0022580966345405137], Loss: 1.918580, Acc:0.813598, Semantic loss: 0.716951, BCE loss: 0.518251, SB loss: 0.683378
2023-10-30 22:24:51,432 Epoch: [391/484] Iter:[190/495], Time: 0.37, lr: [0.0022576534311531424], Loss: 1.917057, Acc:0.813616, Semantic loss: 0.716515, BCE loss: 0.516791, SB loss: 0.683750
2023-10-30 22:24:55,154 Epoch: [391/484] Iter:[200/495], Time: 0.37, lr: [0.0022572102180982356], Loss: 1.915110, Acc:0.813711, Semantic loss: 0.716897, BCE loss: 0.514748, SB loss: 0.683464
2023-10-30 22:24:58,714 Epoch: [391/484] Iter:[210/495], Time: 0.37, lr: [0.002256766995373472], Loss: 1.909932, Acc:0.812150, Semantic loss: 0.714386, BCE loss: 0.513285, SB loss: 0.682262
2023-10-30 22:25:02,295 Epoch: [391/484] Iter:[220/495], Time: 0.37, lr: [0.00225632376297653], Loss: 1.906848, Acc:0.811641, Semantic loss: 0.713479, BCE loss: 0.511829, SB loss: 0.681539
2023-10-30 22:25:05,981 Epoch: [391/484] Iter:[230/495], Time: 0.37, lr: [0.0022558805209050865], Loss: 1.906775, Acc:0.811839, Semantic loss: 0.715195, BCE loss: 0.509635, SB loss: 0.681945
2023-10-30 22:25:09,673 Epoch: [391/484] Iter:[240/495], Time: 0.37, lr: [0.0022554372691568204], Loss: 1.906993, Acc:0.812140, Semantic loss: 0.715630, BCE loss: 0.509845, SB loss: 0.681517
2023-10-30 22:25:13,226 Epoch: [391/484] Iter:[250/495], Time: 0.37, lr: [0.002254994007729406], Loss: 1.903671, Acc:0.813211, Semantic loss: 0.713369, BCE loss: 0.509594, SB loss: 0.680708
2023-10-30 22:25:16,886 Epoch: [391/484] Iter:[260/495], Time: 0.37, lr: [0.0022545507366205178], Loss: 1.909338, Acc:0.813094, Semantic loss: 0.717385, BCE loss: 0.509140, SB loss: 0.682813
2023-10-30 22:25:20,450 Epoch: [391/484] Iter:[270/495], Time: 0.37, lr: [0.0022541074558278286], Loss: 1.908357, Acc:0.811360, Semantic loss: 0.718131, BCE loss: 0.507699, SB loss: 0.682527
2023-10-30 22:25:24,121 Epoch: [391/484] Iter:[280/495], Time: 0.37, lr: [0.0022536641653490125], Loss: 1.916304, Acc:0.811879, Semantic loss: 0.721499, BCE loss: 0.510412, SB loss: 0.684393
2023-10-30 22:25:27,766 Epoch: [391/484] Iter:[290/495], Time: 0.37, lr: [0.0022532208651817403], Loss: 1.918535, Acc:0.812186, Semantic loss: 0.721688, BCE loss: 0.512824, SB loss: 0.684023
2023-10-30 22:25:31,325 Epoch: [391/484] Iter:[300/495], Time: 0.37, lr: [0.002252777555323681], Loss: 1.918625, Acc:0.810847, Semantic loss: 0.721735, BCE loss: 0.511558, SB loss: 0.685332
